<paper>
<cited id="ZE0">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we enhance this approach to model long-range reorderings by introducing discontinuous rules.we tested this new approach on german english translation task and could significantly improve the translation quality, byup to 0.8 bleu points, compared to system which already uses continuous pos based rules to model short-range reorderings.
</prevsent>
<prevsent>statistical machine translation (smt) is currently the most promising approach to machine translation of large vocabulary tasks.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the approach was first presented by brown et al (1993) <papid> J93-2003 </papid>and has since been used in many translation systems (wang and waibel, 1998), (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2000), (vogel et al, 2003).</citsent>
<aftsection>
<nextsent>stateof-the-art smt systems often use translation models based on phrases to describe translation correspondences and word reordering between two languages.
</nextsent>
<nextsent>the reordering of words is one of the main difficulties in machine translation.
</nextsent>
<nextsent>phrase-based translation models by themselves have only limited capability to model different word orders in the source and target language, by capturing local reorderings within phrase pairs.
</nextsent>
<nextsent>in addition, the decoder can reorder phrases, subject to constraints such as confining reorderings to relatively small window.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we enhance this approach to model long-range reorderings by introducing discontinuous rules.we tested this new approach on german english translation task and could significantly improve the translation quality, byup to 0.8 bleu points, compared to system which already uses continuous pos based rules to model short-range reorderings.
</prevsent>
<prevsent>statistical machine translation (smt) is currently the most promising approach to machine translation of large vocabulary tasks.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
the approach was first presented by brown et al (1993) <papid> J93-2003 </papid>and has since been used in many translation systems (wang and waibel, 1998), (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2000), (vogel et al, 2003).</citsent>
<aftsection>
<nextsent>stateof-the-art smt systems often use translation models based on phrases to describe translation correspondences and word reordering between two languages.
</nextsent>
<nextsent>the reordering of words is one of the main difficulties in machine translation.
</nextsent>
<nextsent>phrase-based translation models by themselves have only limited capability to model different word orders in the source and target language, by capturing local reorderings within phrase pairs.
</nextsent>
<nextsent>in addition, the decoder can reorder phrases, subject to constraints such as confining reorderings to relatively small window.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the model will be evaluated in section 7, and conclusion is given in section 8.
</prevsent>
<prevsent>several approaches have been proposed to address the problem of word reordering in smt.
</prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
wu(1996) <papid> P96-1021 </papid>and berger et al (1996), <papid> J96-1002 </papid>for example, restrict the possible reorderings either during decoding time or during the alignment, but do not useany additional linguistic knowledge.</citsent>
<aftsection>
<nextsent>a comparison of both methods can be found in zens and ney (2003).<papid> P03-1019 </papid>furthermore, techniques to use additional linguistic knowledge to improve the word order have been developed.</nextsent>
<nextsent>shen et al (2004) <papid> N04-1023 </papid>and och et al (2004) <papid> N04-1021 </papid>presented approaches to re-rank the output of the decoder using syntactic information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the model will be evaluated in section 7, and conclusion is given in section 8.
</prevsent>
<prevsent>several approaches have been proposed to address the problem of word reordering in smt.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
wu(1996) <papid> P96-1021 </papid>and berger et al (1996), <papid> J96-1002 </papid>for example, restrict the possible reorderings either during decoding time or during the alignment, but do not useany additional linguistic knowledge.</citsent>
<aftsection>
<nextsent>a comparison of both methods can be found in zens and ney (2003).<papid> P03-1019 </papid>furthermore, techniques to use additional linguistic knowledge to improve the word order have been developed.</nextsent>
<nextsent>shen et al (2004) <papid> N04-1023 </papid>and och et al (2004) <papid> N04-1021 </papid>presented approaches to re-rank the output of the decoder using syntactic information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several approaches have been proposed to address the problem of word reordering in smt.
</prevsent>
<prevsent>wu(1996) <papid> P96-1021 </papid>and berger et al (1996), <papid> J96-1002 </papid>for example, restrict the possible reorderings either during decoding time or during the alignment, but do not useany additional linguistic knowledge.</prevsent>
</prevsection>
<citsent citstr=" P03-1019 ">
a comparison of both methods can be found in zens and ney (2003).<papid> P03-1019 </papid>furthermore, techniques to use additional linguistic knowledge to improve the word order have been developed.</citsent>
<aftsection>
<nextsent>shen et al (2004) <papid> N04-1023 </papid>and och et al (2004) <papid> N04-1021 </papid>presented approaches to re-rank the output of the decoder using syntactic information.</nextsent>
<nextsent>furthermore, lexical block-oriented reordering models have been developed in tillmann and zhang(2005) <papid> P05-1069 </papid>and koehn et al (2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE5">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wu(1996) <papid> P96-1021 </papid>and berger et al (1996), <papid> J96-1002 </papid>for example, restrict the possible reorderings either during decoding time or during the alignment, but do not useany additional linguistic knowledge.</prevsent>
<prevsent>a comparison of both methods can be found in zens and ney (2003).<papid> P03-1019 </papid>furthermore, techniques to use additional linguistic knowledge to improve the word order have been developed.</prevsent>
</prevsection>
<citsent citstr=" N04-1023 ">
shen et al (2004) <papid> N04-1023 </papid>and och et al (2004) <papid> N04-1021 </papid>presented approaches to re-rank the output of the decoder using syntactic information.</citsent>
<aftsection>
<nextsent>furthermore, lexical block-oriented reordering models have been developed in tillmann and zhang(2005) <papid> P05-1069 </papid>and koehn et al (2005).</nextsent>
<nextsent>these models decide during decoding time forgiven phrase, if 206 the next phrase should be aligned to the left or to the right.in recent years several approaches using reordering rules on the source side have been applied successfully in different systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE6">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wu(1996) <papid> P96-1021 </papid>and berger et al (1996), <papid> J96-1002 </papid>for example, restrict the possible reorderings either during decoding time or during the alignment, but do not useany additional linguistic knowledge.</prevsent>
<prevsent>a comparison of both methods can be found in zens and ney (2003).<papid> P03-1019 </papid>furthermore, techniques to use additional linguistic knowledge to improve the word order have been developed.</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
shen et al (2004) <papid> N04-1023 </papid>and och et al (2004) <papid> N04-1021 </papid>presented approaches to re-rank the output of the decoder using syntactic information.</citsent>
<aftsection>
<nextsent>furthermore, lexical block-oriented reordering models have been developed in tillmann and zhang(2005) <papid> P05-1069 </papid>and koehn et al (2005).</nextsent>
<nextsent>these models decide during decoding time forgiven phrase, if 206 the next phrase should be aligned to the left or to the right.in recent years several approaches using reordering rules on the source side have been applied successfully in different systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE7">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a comparison of both methods can be found in zens and ney (2003).<papid> P03-1019 </papid>furthermore, techniques to use additional linguistic knowledge to improve the word order have been developed.</prevsent>
<prevsent>shen et al (2004) <papid> N04-1023 </papid>and och et al (2004) <papid> N04-1021 </papid>presented approaches to re-rank the output of the decoder using syntactic information.</prevsent>
</prevsection>
<citsent citstr=" P05-1069 ">
furthermore, lexical block-oriented reordering models have been developed in tillmann and zhang(2005) <papid> P05-1069 </papid>and koehn et al (2005).</citsent>
<aftsection>
<nextsent>these models decide during decoding time forgiven phrase, if 206 the next phrase should be aligned to the left or to the right.in recent years several approaches using reordering rules on the source side have been applied successfully in different systems.
</nextsent>
<nextsent>these rules can be used in rescoring as in chen et al (2006) or can be used in preprocessing step.
</nextsent>
<nextsent>the aim of this step is to monotonize the source and target sentence.
</nextsent>
<nextsent>in collins et al (2005) <papid> P05-1066 </papid>and popovic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE8">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules can be used in rescoring as in chen et al (2006) or can be used in preprocessing step.
</prevsent>
<prevsent>the aim of this step is to monotonize the source and target sentence.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
in collins et al (2005) <papid> P05-1066 </papid>and popovic?</citsent>
<aftsection>
<nextsent>and ney (2006) hand-made rules were used to reorder the source side depending on information from syntax tree or based on pos information.
</nextsent>
<nextsent>these rules had to be created manually, but only few rules were needed and they were able to model long-range reorderings.
</nextsent>
<nextsent>consequently, for every language pair these rules have to be created anew.
</nextsent>
<nextsent>in contrast, other authors propose data-driven methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE10">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in costa-jussa` and fonollosa (2006)the source sentence is first translated into an auxiliary sentence, whose word order is similar tothe one of the target sentences.
</prevsent>
<prevsent>thereby statistical word classes were used.
</prevsent>
</prevsection>
<citsent citstr=" W07-0401 ">
rottmann and vogel (2007),zhang et al (2007) <papid> W07-0401 </papid>and crego and habash (2008) <papid> W08-0307 </papid>used rules to reorder the source side and store different possible reorderings in word lat tice.</citsent>
<aftsection>
<nextsent>they use pos tags and in the latter two cases also chunk tags to generalize the rules.
</nextsent>
<nextsent>the different reorderings are assigned weights depending on their relative frequencies (rottmann and vogel, 2007) or depending on source side language model (zhang et al, 2007).<papid> W07-0401 </papid></nextsent>
<nextsent>in the presented work we will use discontinuous rules in addition to the rules used in rottmann and vogel (2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE11">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in costa-jussa` and fonollosa (2006)the source sentence is first translated into an auxiliary sentence, whose word order is similar tothe one of the target sentences.
</prevsent>
<prevsent>thereby statistical word classes were used.
</prevsent>
</prevsection>
<citsent citstr=" W08-0307 ">
rottmann and vogel (2007),zhang et al (2007) <papid> W07-0401 </papid>and crego and habash (2008) <papid> W08-0307 </papid>used rules to reorder the source side and store different possible reorderings in word lat tice.</citsent>
<aftsection>
<nextsent>they use pos tags and in the latter two cases also chunk tags to generalize the rules.
</nextsent>
<nextsent>the different reorderings are assigned weights depending on their relative frequencies (rottmann and vogel, 2007) or depending on source side language model (zhang et al, 2007).<papid> W07-0401 </papid></nextsent>
<nextsent>in the presented work we will use discontinuous rules in addition to the rules used in rottmann and vogel (2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE13">
<title id=" W09-0435.xml">a pos based model for lon grange reorderings in smt </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the data was preprocessed and we applied compound splitting to the german corpus for the tasks translating from german.
</prevsent>
<prevsent>afterwards, the word alignment was generated with the giza++-toolkit and the alignments of the two directions were combined using the grow-diag-final-and heuristic.
</prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
then the phrase tables were created where we performed additional smoothing of the relative frequencies(foster et al, 2006).<papid> W06-1607 </papid></citsent>
<aftsection>
<nextsent>furthermore, the phrase table applied in the news task was adapted to this domain.
</nextsent>
<nextsent>in addition, 4-gram language model was trained on both corpora.
</nextsent>
<nextsent>the rules were extracted using the pos tags generated by the tree tagger (schmid, 1994).
</nextsent>
<nextsent>in the end beam-search decoder as described in vogel (2003) was used to optimize the weights using the mer-training on the development sets provided for the different task by the workshop.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE16">
<title id=" W08-1803.xml">simple is best experiments with different document segmentation strategies for passage retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is also called index-time pass aging and refers to one-step process of retrieving appropriate textual units for subsequent answer extraction modules (roberts and gaizauskas, 2004; greenwood, 2004).
</prevsent>
<prevsent>this is in contrast toother strategies using two-step procedure consisting of document retrieval and search-time passag ing thereafter.
</prevsent>
</prevsection>
<citsent citstr=" P00-1071 ">
here, we can distinguish between approaches that only return one passage per relevant document (see, for example, (robertson etal., 1992)) and the ones that allow multiple passages per document (see, for example (moldovanet al, 2000)).<papid> P00-1071 </papid></citsent>
<aftsection>
<nextsent>in general, allowing multiple passages per document is preferable for qa as possible answers can be contained at various positions in document (roberts and gaizauskas, 2004).for this, an index-time approach has the advantage that the retrieval of multiple passages per documents is straightforward because all of them compete which each other in the same index using the same metric for ranking.a comparison between index-time and search 17 time pass aging has been carried out in (roberts and gaizauskas, 2004).
</nextsent>
<nextsent>in their experiments,index-time pass aging performs similarly to search time pass aging in terms of coverage and redundancy (measures which have been introduced inthe same paper; see section 4.2 for more informa tion).
</nextsent>
<nextsent>significant differences between the various approaches can only be observed in redundancy on higher ranks (above 50).
</nextsent>
<nextsent>however, as we will see later in our experiments (section 4.2), redundancy is not as important as coverage for our qa system . furthermore, retrieving more than about 40 pas-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE17">
<title id=" W08-1803.xml">simple is best experiments with different document segmentation strategies for passage retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we refer to such approaches as semantically motivated document segmentation.another approach is to cut documents into arbitrary pieces ignoring any other type of information.
</prevsent>
<prevsent>for example, we can use fixed-sized windows to divide documents into passages of similar size.
</prevsent>
</prevsection>
<citsent citstr=" W02-1906 ">
such windows can be defined in terms of words and characters (kaszkiel and zobel, 2001; monz, 2003) or sentences and paragraphs (zobelet al, 1995; llopis et al, 2002).<papid> W02-1906 </papid></citsent>
<aftsection>
<nextsent>it is also possible to allow varying window sizes and overlapping sections to be indexed (kaszkiel and zobel, 2001; monz, 2003).
</nextsent>
<nextsent>in this case it is up to their engine 18 to decide which of the competing window types is preferred and it may even return overlapping sections multiple times.
</nextsent>
<nextsent>in the following sections we will discuss two techniques of semantically motivated document segmentation and compare them to simplewindow-based techniques in terms of passage retrieval and qa performance.
</nextsent>
<nextsent>our qa system is an open-domain question answering system for dutch.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE18">
<title id=" W08-1803.xml">simple is best experiments with different document segmentation strategies for passage retrieval </title>
<section> toch werd [hij].  </section>
<citcontext>
<prevsection>
<prevsent>the resolution system yields precision of 67.9% and recall of 45.6% (f-score = 54.5%) using muc scores (vilain et al, 1993) on the annotated test corpus developed by (hoste, 2005) which consist of articles taken from knack, flemish weekly news magazine.
</prevsent>
<prevsent>3.2 texttiling.
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
text tiling is well-known algorithm for segmenting texts into sub topic passages (hearst, 1997).<papid> J97-1003 </papid></citsent>
<aftsection>
<nextsent>it is based on the assumption that significant portion of set of lexical items in use during the course of given sub topic discussion changes when that sub topic in the text changes.topic shifts are found by searching for lexical co-occurrence patterns and comparing adjacent blocks.
</nextsent>
<nextsent>first the text is subdivided into pseudo-sentences of predefined size rather than using syntactically-determined sentences.
</nextsent>
<nextsent>these pseudo-sentences are called token-sequences by hearst.
</nextsent>
<nextsent>the algorithm identifies discourse boundaries by calculating score for each token-sequence gap.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE19">
<title id=" W08-1103.xml">generating textual summaries of bar charts </title>
<section> organizing coherent summaries.  </section>
<citcontext>
<prevsection>
<prevsent>once the propositions to be included in the summary are identified, we assign them to one of these three classes.
</prevsent>
<prevsent>we hypothesize that the message-related class of propositions should be presented first since this places emphasis on the core message of the graphic.we anticipate that the user will ask follow-up questions after receiving the initial summary.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
therefore, it is appropriate to close the initial summary with propositions from the computational class so thatthe whole graphic is in the users focus of attention (grosz and sidner, 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>thus we hypothesize that good ordering of propositions in the initial summary is the message-related class, the specific class, and finally the computational class.
</nextsent>
<nextsent>this produces partial ordering of the propositions to be included in the summary.each proposition can be realized as single sentence.
</nextsent>
<nextsent>for example, shows(graphic,trend) can be realized as the graphic shows trend?
</nextsent>
<nextsent>or there is trend in the graphic?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE20">
<title id=" W08-1103.xml">generating textual summaries of bar charts </title>
<section> organizing coherent summaries.  </section>
<citcontext>
<prevsection>
<prevsent>the most straightforward way of realizing tree would be con joining the realizations of subtrees rooted by an and predicate, embedding the realization of subtree rooted by which predicate as relative clause, and realizing subtree that consists solely of an attributive predicate as an adjective or prepositional phrase.
</prevsent>
<prevsent>however, care must be taken that the sentence realization of tree is not too complex.
</prevsent>
</prevsection>
<citsent citstr=" W07-1001 ">
research has used number of different measures to assess syntactic complexity of written text and spoken language samples (roark et al, 2007).<papid> W07-1001 </papid></citsent>
<aftsection>
<nextsent>weapply the notion of syntactic complexity to evaluate the semantic units (predicates) that will be realized.
</nextsent>
<nextsent>the revised d-level sentence complexity scale (covington et al, 2006) forms the core of our syntactic complexity measure.
</nextsent>
<nextsent>the d-level scale measures the complexity of sentence according to the sequence in which children acquire the ability to use different types of sentences.
</nextsent>
<nextsent>the sentence types with the lowest score are those that children acquire first and therefore are the simplest types.among the seven levels defined in the revised level scale, the levels of interest in our work are(in order of increasing complexity): simple sentences, conjoined sentences, sentences with rela 11 message related:the graphic shows an increasing trend in the mean dollar value of jury awards over the period from 1997 to 2002.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE21">
<title id=" W08-1103.xml">generating textual summaries of bar charts </title>
<section> realizing summaries.  </section>
<citcontext>
<prevsection>
<prevsent>to be consistent with the motivation behind the initial groupings of the propositions, we do not allow movements from the message related class or any movement that will empty the computationalclass.
</prevsent>
<prevsent>table 1 presents the summary that our system generates for the graphic in figure 2 before the movements between classes, and table 2 presents the summary after the movements.
</prevsent>
</prevsection>
<citsent citstr=" W96-0501 ">
to realize the summaries in natural language, we use the fuf/surge surface realizer (elhadad and robin, 1996) <papid> W96-0501 </papid>with some changes made to address few problems encountered with respect to the use of conjunctions and subject-ellipsises.</citsent>
<aftsection>
<nextsent>different strategies are defined in the system for aggregating the realizations of trees that are linked with operators.
</nextsent>
<nextsent>the strategy selected by the system is based on the relation (such as concession) that holds between the propositions at the root of the trees and the syntactic forms of their realization opportunities.
</nextsent>
<nextsent>for example, the system uses different strategies for aggregating the trees rooted by the and predicates in figure 4, where the tree rooted by and(period) is realized as combination of prepositional phrases and the tree rooted by and(trend) is realized as full sentence containing set of prepositional phrases.
</nextsent>
<nextsent>5.1 descriptor for the dependent axisthe dependent axis of an information graphic is often not labelled with full descriptor of what is being measured and therefore mechanism for extracting an appropriate descriptor had to be developed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE22">
<title id=" W09-1314.xml">user driven development of text mining resources for cancer risk assessment </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the automatic classification could be improved by the use of more sophisticated features extracted using nlp tools that have been tuned for biomedical texts, such as parsers, e.g.
</prevsent>
<prevsent>(tsuruoka et al  2005), and named entity recognizers, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W07-1008 ">
(corbett et al 2007), <papid> W07-1008 </papid>and exploiting resources such as the biolex ion (sasaki et al  2008).</citsent>
<aftsection>
<nextsent>our long term goal is to develop tm tool specifically designed for cra.
</nextsent>
<nextsent>some tools have recently been built to assist other critical activities of biomedicine (e.g. literature cur ation for genetics).a few of them have been evaluated for their practical usefulness in real-world scenario (karamanis et al  2008, demaine et al  2006).
</nextsent>
<nextsent>such tools and evaluations act as an important proof of concept for biomedical tm and help to develop technology for the needs of practical applications.according to the interviews we conducted (sec tion 2), tool capable of identifying, ranking and classifying articles based on the evidence they contain, displaying the results to experts, and assisting also in subsequent steps of cra would be particularly welcome.
</nextsent>
<nextsent>such tool, if developed in close collaboration with users, could significantly increase the productivity of cra and enable risk assessors to concentrate on what they are best at: the expert judgement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE23">
<title id=" W09-0607.xml">generating approximate geographic descriptions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation studies show that nlg systems, because they can analyse input data exhaustively, can produce more fine-grained geographic descriptions that are more useful to end users than those generated by human experts.
</prevsent>
<prevsent>disciplines such as environmental studies, geography,geology, planning and business marketing make extensive use of geographical information systems (gis); however, despite an explosion of available mapping software, gis remains specialist tool with specialist skills required to analyse and understand the information presented using map displays.
</prevsent>
</prevsection>
<citsent citstr=" E06-2020 ">
complementing such displays with textual summaries therefore provides an immediate niche for nlg systems.recently, research into nlg systems that generate text from geo referenced data has begun to emerge (dale et al, 2005; turner et al, 2006; <papid> E06-2020 </papid>turner et al, 2008b; thomas and sripada, 2008).<papid> W08-1115 </papid></citsent>
<aftsection>
<nextsent>these systems are required to textually describe the geographic distribution of domain variables such as road surface temperature and unemployment rates.
</nextsent>
<nextsent>for example, descriptions such as road surface temperatures will fall below zero in some places in the southwest?
</nextsent>
<nextsent>and unemployment is highest in the rural areas?
</nextsent>
<nextsent>need to be generated by these systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE24">
<title id=" W09-0607.xml">generating approximate geographic descriptions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation studies show that nlg systems, because they can analyse input data exhaustively, can produce more fine-grained geographic descriptions that are more useful to end users than those generated by human experts.
</prevsent>
<prevsent>disciplines such as environmental studies, geography,geology, planning and business marketing make extensive use of geographical information systems (gis); however, despite an explosion of available mapping software, gis remains specialist tool with specialist skills required to analyse and understand the information presented using map displays.
</prevsent>
</prevsection>
<citsent citstr=" W08-1115 ">
complementing such displays with textual summaries therefore provides an immediate niche for nlg systems.recently, research into nlg systems that generate text from geo referenced data has begun to emerge (dale et al, 2005; turner et al, 2006; <papid> E06-2020 </papid>turner et al, 2008b; thomas and sripada, 2008).<papid> W08-1115 </papid></citsent>
<aftsection>
<nextsent>these systems are required to textually describe the geographic distribution of domain variables such as road surface temperature and unemployment rates.
</nextsent>
<nextsent>for example, descriptions such as road surface temperatures will fall below zero in some places in the southwest?
</nextsent>
<nextsent>and unemployment is highest in the rural areas?
</nextsent>
<nextsent>need to be generated by these systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE25">
<title id=" W09-0607.xml">generating approximate geographic descriptions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in 5 we present qualitative discussion of aspects of geographic description from the evaluations of road safe that were carried out, and how this relates to future possible work on this topic.
</prevsent>
<prevsent>much work on generation of spatial descriptions has concentrated on smaller scale spaces that are immediately perceivable.
</prevsent>
</prevsection>
<citsent citstr=" P06-1131 ">
for example, spatial description shave been studied from the perspective of robot communication (kelleher and kruijff, 2006), <papid> P06-1131 </papid>3d animation (towns et al, 1998) and basic visual scenes (vi ethen and dale, 2008; ebert et al, 1996).</citsent>
<aftsection>
<nextsent>in more geographical context route description generation systems such as (dale et al, 2005) and (moulin and ket tani, 1999) have had wide appeal to nlg researchers.(varges, 2005) <papid> W05-1627 </papid>also generate landmark based spatial descriptions using maps from the map task dialogue cor pus.roadsafe is an nlg system that has been operationally deployed at aerospace and marine international (ami) to produce weather forecast texts for winter road maintenance.</nextsent>
<nextsent>it generates forecast texts describing various weather conditions on road network as shown in figure 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE26">
<title id=" W09-0607.xml">generating approximate geographic descriptions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>much work on generation of spatial descriptions has concentrated on smaller scale spaces that are immediately perceivable.
</prevsent>
<prevsent>for example, spatial description shave been studied from the perspective of robot communication (kelleher and kruijff, 2006), <papid> P06-1131 </papid>3d animation (towns et al, 1998) and basic visual scenes (vi ethen and dale, 2008; ebert et al, 1996).</prevsent>
</prevsection>
<citsent citstr=" W05-1627 ">
in more geographical context route description generation systems such as (dale et al, 2005) and (moulin and ket tani, 1999) have had wide appeal to nlg researchers.(varges, 2005) <papid> W05-1627 </papid>also generate landmark based spatial descriptions using maps from the map task dialogue cor pus.roadsafe is an nlg system that has been operationally deployed at aerospace and marine international (ami) to produce weather forecast texts for winter road maintenance.</citsent>
<aftsection>
<nextsent>it generates forecast texts describing various weather conditions on road network as shown in figure 1.
</nextsent>
<nextsent>the input to the system is dataset consisting of numerical weather predictions (nwp) calculated over large set of point locations across road network.
</nextsent>
<nextsent>an example static snapshot of the input to road safe forone parameter is shown in figure 2.
</nextsent>
<nextsent>the complete input is series of such snapshots for number of parameters (see (turner et al, 2008b) for details).in applications such as road safe, the same geographical situation can be expressed in variety of different ways dependent upon the perspective employed,henceforth termed as frame of reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE29">
<title id=" W09-1205.xml">a latent variable model of synchronous syntactic semantic parsing for multiple languages </title>
<section> the synchronous model.  </section>
<citcontext>
<prevsection>
<prevsent>the use of synchronous parsing allows separate structures for syntax and semantics, while still modeling their joint probability.
</prevsent>
<prevsent>we use the approach to synchronous parsing proposed in henderson et al (2008), where we start with two separate derivations specifying each of the two structures, then synchronise these derivations at each word.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
the individual derivations are based on nivres shift-reduce-style parsing algorithm (nivre et al, 2006), <papid> W06-2933 </papid>as discussed further below.</citsent>
<aftsection>
<nextsent>first we illustrate the high-level structure of the model, discussed in more detail in henderson et al (2008).
</nextsent>
<nextsent>let td be syntactic dependency tree with derivation d1d, ..., dmdd , and ts be semantic dependency graph with derivation d1s , ..., dmss . to define derivations for the joint structure td, ts, we divide the two derivations into the chunks between shifting each word onto the stack, ctd = db d , ..., etd and cts = db ss , ..., de ss , where dbtd1d = db s1s = shiftt1 and de d+1 = de s+1s = shiftt.
</nextsent>
<nextsent>then the actions of the synchronous derivations consist of quadruples ct = (ctd, switch, cts, shiftt), where switch means switching from syntactic to semantic mode.
</nextsent>
<nextsent>this gives us the following joint probability model, where is the number of words in the input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE30">
<title id=" W09-1205.xml">a latent variable model of synchronous syntactic semantic parsing for multiple languages </title>
<section> the synchronous model.  </section>
<citcontext>
<prevsection>
<prevsent>this allows words to be processed in different orders during different 38 portions of the parse, so some arcs can be specified using one ordering, then other arcs can be specified using another ordering.
</prevsent>
<prevsent>titov et al (2009) found that only using the swap action as last resort is the best strategy for english (compared to using it preemp tively to address future crossing arcs) and we use the same strategy here for all languages.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
syntactic graphs do not use swap action.we adopt the head method of nivre and nilsson (2005) <papid> P05-1013 </papid>to de-projectivise syntactic dependencies outside of parsing.1</citsent>
<aftsection>
<nextsent>the synchronous derivations described above are modelled with type of bayesian network called an incremental sigmoid belief network (isbn) (titov and henderson, 2007a).
</nextsent>
<nextsent>as in henderson et al (2008), the isbn model distinguishes two types of latent states: syntactic states, when syntactic decisions are considered, and semantic states, when semantic decision are considered.
</nextsent>
<nextsent>latent states are vectors of binary latent variables, which are conditioned on variables from previous states via pattern of connecting edges determined by the previous decisions.
</nextsent>
<nextsent>these latent-to-latent connections are usedto engineer soft biases which reflect the relevant domains of locality in the structure being built.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE31">
<title id=" W09-0410.xml">the rwth machine translation system for wmt 2009 </title>
<section> translation models.  </section>
<citcontext>
<prevsection>
<prevsent>the hierarchical phrase-based approach can be considered as an extension of the standard phrase based model.
</prevsent>
<prevsent>in this model we allow the phrases to have gaps?, i.e. we allow non-contiguous partsof the source sentence to be translated into possibly non-contiguous parts of the target sentence.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
the model can be formalized as synchronous context-free grammar (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>the model also included some additional heuristics which have shown to be helpful for improving translation quality, as proposed in (vilar et al, 2008).the first step in the hierarchical phrase extraction is the same as for the phrased-based model.
</nextsent>
<nextsent>having set of initial phrases, we search for phrases which contain other smaller sub-phrasesand produce new phrase with gaps.
</nextsent>
<nextsent>in our system, we restricted the number of non-terminals for each hierarchical phrase to maximum of two, which were also not allowed to be adjacent.
</nextsent>
<nextsent>the scores of the phrases are again computed as relative frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE32">
<title id=" W09-0410.xml">the rwth machine translation system for wmt 2009 </title>
<section> morpho-syntactic transformations.  </section>
<citcontext>
<prevsection>
<prevsent>for the translation from english to german, infiniti ves and past participles were moved to the end of clause, where punctuation marks,subordinate conjunctions and finite verbs are considered as the beginning of the next clause.
</prevsent>
<prevsent>3.2 german compound words.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
for the translation from german into english, german compounds were split using the frequency based method described in (koehn and knight,2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>for the other translation direction, the english text was first translated into the modified german language with split compounds.
</nextsent>
<nextsent>the generated output was then post processed, i.e. the components were merged using the method described in (popovic?
</nextsent>
<nextsent>et al, 2006): list of compounds and list of components are extracted from the original german training corpus.
</nextsent>
<nextsent>if the word in the generated output is in the component list, check if this word merged with the next word is in the compound list.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE33">
<title id=" W09-0410.xml">the rwth machine translation system for wmt 2009 </title>
<section> system combination.  </section>
<citcontext>
<prevsection>
<prevsent>if the word in the generated output is in the component list, check if this word merged with the next word is in the compound list.
</prevsent>
<prevsent>if it is, merge the two words.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
for system combination we used the approach described in (matusov et al, 2006).<papid> E06-1005 </papid></citsent>
<aftsection>
<nextsent>the method isbased on the generation of consensus translation out of the output of different translation systems.
</nextsent>
<nextsent>the core of the method consists in build inga confusion network for each sentence by aligning and combining the (single-best) translation hypothesis from one mt system with the translations produced by the other mt systems (and the other translations from the same system, if n-best lists are used in combination).
</nextsent>
<nextsent>for each sentence, each mt system is selected once as primary?
</nextsent>
<nextsent>system,and the other hypotheses are aligned to this hypothesis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE34">
<title id=" W09-0410.xml">the rwth machine translation system for wmt 2009 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>for the tasks including system combination, the parameters for the system combination 67 were also trained on the dev-b?
</prevsent>
<prevsent>set.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the reported evaluation metrics are the bleu score and two syntax-oriented metrics which have shown high correlation with human evaluations: the pbleu score (bleu calculated on pos sequences) and the pos-f-score pf (similar to the bleu score but based on the f-measure instead of precision and on arithmetic mean instead of geometric mean).the pos tags used for reorderings and for syntactic evaluation metrics for the english and the german corpora were generated using the statistical n-gram-based tnt-tagger (brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>the spanish corpora are annotated using the free ling analyser (carreras et al, 2004), and the french texts using the treetagger1.
</nextsent>
<nextsent>5.2 translation results.
</nextsent>
<nextsent>table 1 presents the results for the german english language pair.
</nextsent>
<nextsent>for translation from german into english, results for the phrase-based system with and without verb reordering and compound splitting are shown.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE35">
<title id=" W09-1317.xml">identifying interaction sentences from biological literature using automatically extracted patterns </title>
<section> biological text preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>in the following sections, we will describe each component.
</prevsent>
<prevsent>4.1 sentence preparation.
</prevsent>
</prevsection>
<citsent citstr=" J02-3002 ">
a heuristic method is implemented to detect sentence boundaries (mikheev, 2002) <papid> J02-3002 </papid>based on the assumption that sentences are usually demarcated by some indicative delimiting punctuation marks in order to segment the biological texts into sentence units.</citsent>
<aftsection>
<nextsent>captions and headings that are not grammatically valid sentences are therefore detected and further eliminated for our work.
</nextsent>
<nextsent>134 4.2 part-of-speech tagging.
</nextsent>
<nextsent>pos tagging is then performed to associate each word in sentence with its most likely pos tag.
</nextsent>
<nextsent>because subsequent processing steps typically depend on the taggers output, high performance at this level is crucial for success in later stages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE36">
<title id=" W09-1317.xml">identifying interaction sentences from biological literature using automatically extracted patterns </title>
<section> biological text preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>we decided to remove these tags to prevent the combinatorial effect that these would induce within the set of extracted patterns.
</prevsent>
<prevsent>4.4 text chunking.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
next, rule-based text chunker (ramshaw and marcus, 1995) <papid> W95-0107 </papid>is applied on the tagged sentences to further identify phrasal units, such as base noun phrases np and verbal units vb.</citsent>
<aftsection>
<nextsent>this allows us to focus on the holistic structure of each sentence.
</nextsent>
<nextsent>text chunking is not applied on the identified biological terms.
</nextsent>
<nextsent>in order to achieve more generalized interaction patterns, unified tag vb?
</nextsent>
<nextsent>is used to represent every verbal unit instead of employing different tags for various tenses of verbs.as result of preprocessing, every sentence is represented by its generalized form as sequence of corresponding tags consisting of pos tags and predefined tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE37">
<title id=" W09-1317.xml">identifying interaction sentences from biological literature using automatically extracted patterns </title>
<section> interaction pattern extraction.  </section>
<citcontext>
<prevsection>
<prevsent>a patricia tree uses path compression by grouping common sequences intonodes.
</prevsent>
<prevsent>this structure provides an efficient way of storing values while maintaining the lookup time for key of o(n).
</prevsent>
</prevsection>
<citsent citstr=" P98-1038 ">
it has been applied to many large information retrieval problems (chien, 1997; chen et al, 1998).<papid> P98-1038 </papid></citsent>
<aftsection>
<nextsent>in our work, patricia tree is used for the first time to facilitate the automatic extraction of interaction patterns.
</nextsent>
<nextsent>all training sentences are inserted and stored in generic patricia tree from which the common patterns of pos tags can be efficiently stored and the tree structure used to compute relevant usage statistics.
</nextsent>
<nextsent>5.2 potential pattern extraction.
</nextsent>
<nextsent>patterns of straightforward biological interactions are frequently encountered in range of actual sentences.conversely, vague relationships or complex interactions patterns are seldom repeated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE38">
<title id=" W08-2129.xml">a puris tic approach for joint dependency parsing and semantic role labeling </title>
<section> syntactic parsing.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" N07-1050 ">
our syntactic dependency parser is variant of the incremental non-projective dependency parser described in nivre (2007).<papid> N07-1050 </papid></citsent>
<aftsection>
<nextsent>nivres?
</nextsent>
<nextsent>parser is incremental in the sense, that although the complete list of words of sentence is known, construction of the dependency tree is performed strictly from left to right.
</nextsent>
<nextsent>it uses treebank induced classifiers to deterministically predict the actions of the parser.
</nextsent>
<nextsent>the classifiers are trained using support vector machines (svm).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE49">
<title id=" W08-2129.xml">a puris tic approach for joint dependency parsing and semantic role labeling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>for example, applying the decoupled edge labeling model directly on the given unlabeled dependency trees of the development set (i.e. we assume an ual of 100%) gave as an lal of 92.88%.
</prevsent>
<prevsent>beside this, we will also re-investigate interleaved strategies of unlabeled edge and edge labeling prediction as basis for (mildly-) strict incremental parsing.
</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
here, it might be useful to relax the strict linear control regime by exploring beam search strategies, e.g. along the lines of collins and roark (2004).<papid> P04-1015 </papid></citsent>
<aftsection>
<nextsent>we have presented puris tic approach for joint dependency parsing and semantic role labeling.
</nextsent>
<nextsent>since, the development of our approach has been started from scratch, we didnt manage to deal with all problems.
</nextsent>
<nextsent>our focus was on setting up workable backbone, and then on trying to do as much feature engineering as possible.
</nextsent>
<nextsent>our bad results on the conll 2008 suggest that our current strategy was bit too optimistic and risky, and that the strict incremental deterministic parsing regime seemed to have failed in its current form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE50">
<title id=" W08-1114.xml">simple but  effective feedback generation  to tutor abstract  problem solving </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(fox, 1993; moore et al, 2004), itss mostly provide negative feedback, as they react to student errors.in this paper, we will first briefly describe our tutorial dialog collection.
</prevsent>
<prevsent>we will then present the planning architecture that underlies our feedbackgenerator.
</prevsent>
</prevsection>
<citsent citstr=" A00-1008 ">
even if our its does not currently allow for student input, our generation architecture is inspired by state-of-the art tutorial dialog management (freedman, 2000; <papid> A00-1008 </papid>jordan et al, 2001; zinn et al., 2002).</citsent>
<aftsection>
<nextsent>one limitation of these approaches is that plan operators are difficult to maintain and extend, partly because they are manually defined and tuned.crucially, our plan operators are automatically derived via the association rules mined from our corpus.
</nextsent>
<nextsent>finally, we will devote substantial amount of space to evaluation.
</nextsent>
<nextsent>our work is among the first to show not only that more sophisticated language interface results in more learning, but that it favorably compares with human tutors.
</nextsent>
<nextsent>full details on our work can be found in (lu, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE51">
<title id=" W08-1121.xml">degree of abstraction in referring expression generation and its relation with the construction of the contrast set </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the appropriate use of referring expressions to compete with human-generated texts involves certaindifficulty.
</prevsent>
<prevsent>according to reiter and dale (2000), referring expression must communicate enough infor 161 mation to identify uni vocally the intended referent within the context of the current discourse, but always avoiding unnecessary or redundant modifiers.
</prevsent>
</prevsection>
<citsent citstr=" C92-1038 ">
reiter and dale (1992) <papid> C92-1038 </papid>describe fast algorithm for generating referring expressions in the context of natural language generation system.</citsent>
<aftsection>
<nextsent>their algorithm relies on the following set of assumptions about the underlying knowledge base that must be used: (1) every entity is characterized in terms of collection of attributes and their values, (2) every entity has as one of its attributes type, and (3) the knowledge base may organize some attribute value sas subsumption hierarchy.
</nextsent>
<nextsent>additionally, each object represented in the system should have an associated basic level value, which corresponds to the concept which is preferred when referring to that object.
</nextsent>
<nextsent>these assumptions are satisfied if description logic ontology is used for this purpose.
</nextsent>
<nextsent>entities would correspond to instances of concepts from the ontology, the attribute corresponding to the type would be the concept of which they are immediate instances, and the taxonomical structure of the ontology of concepts would provide the subsumption hierarchy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE52">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe this approach will broaden the class of applications in which grammar based generation may feasibly be deployed.
</prevsent>
<prevsent>in principle, grammar-based generation offers significant advantages for many applications, when compared with simpler template-based or canned text output solutions, by providing productive coverage and greater output variety.
</prevsent>
</prevsection>
<citsent citstr=" W98-1425 ">
however, realizing these advantages can require significant development costs (busemann and horacek, 1998).<papid> W98-1425 </papid>one possible strategy is to exploit wide coverage realizer that aims for applicability in multiple application domains (white et al, 2007; cahill and van genabith, 2006; <papid> P06-1130 </papid>zhong and stent, 2005; langkilde-geary, 2002; langkilde and knight, 1998; <papid> P98-1116 </papid>elhadad, 1991).</citsent>
<aftsection>
<nextsent>these realizers prov idea sound wide-coverage grammar (or robust wide coverage language model) for free, but demand specific input format that is otherwise foreign toan existing application.
</nextsent>
<nextsent>unfortunately, the development burden of implementing the translation between the systems available semantic representations and the required input format can be quite substantial (busemann and horacek, 1998).<papid> W98-1425 </papid></nextsent>
<nextsent>indeed, implementing the translation might require as much effort as would be required to build simple customgenerator; cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE54">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe this approach will broaden the class of applications in which grammar based generation may feasibly be deployed.
</prevsent>
<prevsent>in principle, grammar-based generation offers significant advantages for many applications, when compared with simpler template-based or canned text output solutions, by providing productive coverage and greater output variety.
</prevsent>
</prevsection>
<citsent citstr=" P06-1130 ">
however, realizing these advantages can require significant development costs (busemann and horacek, 1998).<papid> W98-1425 </papid>one possible strategy is to exploit wide coverage realizer that aims for applicability in multiple application domains (white et al, 2007; cahill and van genabith, 2006; <papid> P06-1130 </papid>zhong and stent, 2005; langkilde-geary, 2002; langkilde and knight, 1998; <papid> P98-1116 </papid>elhadad, 1991).</citsent>
<aftsection>
<nextsent>these realizers prov idea sound wide-coverage grammar (or robust wide coverage language model) for free, but demand specific input format that is otherwise foreign toan existing application.
</nextsent>
<nextsent>unfortunately, the development burden of implementing the translation between the systems available semantic representations and the required input format can be quite substantial (busemann and horacek, 1998).<papid> W98-1425 </papid></nextsent>
<nextsent>indeed, implementing the translation might require as much effort as would be required to build simple customgenerator; cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE55">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe this approach will broaden the class of applications in which grammar based generation may feasibly be deployed.
</prevsent>
<prevsent>in principle, grammar-based generation offers significant advantages for many applications, when compared with simpler template-based or canned text output solutions, by providing productive coverage and greater output variety.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
however, realizing these advantages can require significant development costs (busemann and horacek, 1998).<papid> W98-1425 </papid>one possible strategy is to exploit wide coverage realizer that aims for applicability in multiple application domains (white et al, 2007; cahill and van genabith, 2006; <papid> P06-1130 </papid>zhong and stent, 2005; langkilde-geary, 2002; langkilde and knight, 1998; <papid> P98-1116 </papid>elhadad, 1991).</citsent>
<aftsection>
<nextsent>these realizers prov idea sound wide-coverage grammar (or robust wide coverage language model) for free, but demand specific input format that is otherwise foreign toan existing application.
</nextsent>
<nextsent>unfortunately, the development burden of implementing the translation between the systems available semantic representations and the required input format can be quite substantial (busemann and horacek, 1998).<papid> W98-1425 </papid></nextsent>
<nextsent>indeed, implementing the translation might require as much effort as would be required to build simple customgenerator; cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE58">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach can be initially attractive to system builders because it allows syntactic cover age and semantic modeling to be tailored directly to application needs.
</prevsent>
<prevsent>however, writing grammatical rules by hand ultimately requires painstaking,time-consuming effort by developer who has detailed linguistic knowledge as well as detailed application knowledge.
</prevsent>
</prevsection>
<citsent citstr=" N07-1022 ">
further, the resulting coverage is inevitably limited to the set of linguistic constructions that have been selected for careful modeling.a third strategy is to use an example-based approach (wong and mooney, 2007; <papid> N07-1022 </papid>stone, 2003; varges and mellish, 2001) <papid> N01-1001 </papid>in which the connection 77between available application semantic representations and desired output utterances is specified by example.</citsent>
<aftsection>
<nextsent>example-based approaches aim to allow system builders to specify productive generation capacity while leaving the representations andrea soning that underlie that productive capacity mostly implicit in set of training examples.
</nextsent>
<nextsent>this methodology insulates system builders from the detailed expertise and technical infrastructure needed to implement the productive capacity directly, and has made example-based approaches attractive not only in text generation but also in related areas such as concate native speech synthesis and motion capture based animation; see, e.g., (stone et al, 2004).
</nextsent>
<nextsent>the technique we present in this paper is newexample-based approach to specifying application specific text generation.
</nextsent>
<nextsent>as in other hand-craftedand example-based approaches, our technique allows syntactic coverage and semantic modeling to follow the needs and available semantic representations in an application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE59">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach can be initially attractive to system builders because it allows syntactic cover age and semantic modeling to be tailored directly to application needs.
</prevsent>
<prevsent>however, writing grammatical rules by hand ultimately requires painstaking,time-consuming effort by developer who has detailed linguistic knowledge as well as detailed application knowledge.
</prevsent>
</prevsection>
<citsent citstr=" N01-1001 ">
further, the resulting coverage is inevitably limited to the set of linguistic constructions that have been selected for careful modeling.a third strategy is to use an example-based approach (wong and mooney, 2007; <papid> N07-1022 </papid>stone, 2003; varges and mellish, 2001) <papid> N01-1001 </papid>in which the connection 77between available application semantic representations and desired output utterances is specified by example.</citsent>
<aftsection>
<nextsent>example-based approaches aim to allow system builders to specify productive generation capacity while leaving the representations andrea soning that underlie that productive capacity mostly implicit in set of training examples.
</nextsent>
<nextsent>this methodology insulates system builders from the detailed expertise and technical infrastructure needed to implement the productive capacity directly, and has made example-based approaches attractive not only in text generation but also in related areas such as concate native speech synthesis and motion capture based animation; see, e.g., (stone et al, 2004).
</nextsent>
<nextsent>the technique we present in this paper is newexample-based approach to specifying application specific text generation.
</nextsent>
<nextsent>as in other hand-craftedand example-based approaches, our technique allows syntactic coverage and semantic modeling to follow the needs and available semantic representations in an application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE61">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> case study: doctor perez.  </section>
<citcontext>
<prevsection>
<prevsent>the human trainee who talks to the doctor plays the role of u.s. army captain named captain kirk.
</prevsent>
<prevsent>the design goals for doctor perez createa number of requirements for practical nlg component.
</prevsent>
</prevsection>
<citsent citstr=" W08-0130 ">
we briefly summarize these requirements here; see (devault et al, 2008) <papid> W08-0130 </papid>for more details.</citsent>
<aftsection>
<nextsent>doctor perez has relatively rich internal mental state including beliefs, goals, plans, and emotions.
</nextsent>
<nextsent>he uses an attribute-value matrix (avm) semantic representation to describe an utterance as set of core speech acts and other dialogue acts.
</nextsent>
<nextsent>speech acts generally have semantic contents that describe propositions and questions about states and action sin the domain.
</nextsent>
<nextsent>to facilitate inter process communication, and statistical processing, this avm structure is linear ized into frame?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE62">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>wherever possible, it is better if any developer can improve any aspect of doctor perezs language processing; e.g., if programmer discov 78 ers bug or dis fluency in the nlg output, it is bette rif she can fix it directly rather than requiring (com putational) linguist to do so.
</prevsent>
<prevsent>our approach builds on recently developed techniques in statistical parsing, lexicalized syntax modeling, generation with lexicalized grammars, and search optimization to automatically construct all the resources needed for high-quality run-time generation component.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
in particular, we leverage the increasing availability of off-the-shelf parsers suchas (charniak, 2001; <papid> P01-1017 </papid>charniak, 2005) to automatically (or semi-automatically) assign syntactic analyses to set of suggested output sentences.</citsent>
<aftsection>
<nextsent>we then draw on lexicalization techniques for statistical language models (magerman, 1995; <papid> P95-1037 </papid>collins, 1999;chiang, 2000; <papid> P00-1058 </papid>chiang, 2003) to induce probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides.</nextsent>
<nextsent>the final step is to use the training examples to learn an effective search policy so that our run-timegeneration component can find good output sentences in reasonable time frame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE63">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>our approach builds on recently developed techniques in statistical parsing, lexicalized syntax modeling, generation with lexicalized grammars, and search optimization to automatically construct all the resources needed for high-quality run-time generation component.
</prevsent>
<prevsent>in particular, we leverage the increasing availability of off-the-shelf parsers suchas (charniak, 2001; <papid> P01-1017 </papid>charniak, 2005) to automatically (or semi-automatically) assign syntactic analyses to set of suggested output sentences.</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
we then draw on lexicalization techniques for statistical language models (magerman, 1995; <papid> P95-1037 </papid>collins, 1999;chiang, 2000; <papid> P00-1058 </papid>chiang, 2003) to induce probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides.</citsent>
<aftsection>
<nextsent>the final step is to use the training examples to learn an effective search policy so that our run-timegeneration component can find good output sentences in reasonable timeframe.
</nextsent>
<nextsent>in particular, we use variants of existing search optimization (daum?
</nextsent>
<nextsent>and marcu, 2005) and ranking algorithms (collins and koo, 2005) <papid> J05-1003 </papid>to train our run-time component to find good outputs within specified time window; see also (stent et al, 2004; <papid> P04-1011 </papid>walker et al, 2001).<papid> N01-1003 </papid></nextsent>
<nextsent>the result is run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which time/performance trade off is necessary (such as real-time dialogue).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE65">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>our approach builds on recently developed techniques in statistical parsing, lexicalized syntax modeling, generation with lexicalized grammars, and search optimization to automatically construct all the resources needed for high-quality run-time generation component.
</prevsent>
<prevsent>in particular, we leverage the increasing availability of off-the-shelf parsers suchas (charniak, 2001; <papid> P01-1017 </papid>charniak, 2005) to automatically (or semi-automatically) assign syntactic analyses to set of suggested output sentences.</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
we then draw on lexicalization techniques for statistical language models (magerman, 1995; <papid> P95-1037 </papid>collins, 1999;chiang, 2000; <papid> P00-1058 </papid>chiang, 2003) to induce probabilistic, lexicalized tree-adjoining grammar that supports the derivation of all the suggested output sentences, and many others besides.</citsent>
<aftsection>
<nextsent>the final step is to use the training examples to learn an effective search policy so that our run-timegeneration component can find good output sentences in reasonable timeframe.
</nextsent>
<nextsent>in particular, we use variants of existing search optimization (daum?
</nextsent>
<nextsent>and marcu, 2005) and ranking algorithms (collins and koo, 2005) <papid> J05-1003 </papid>to train our run-time component to find good outputs within specified time window; see also (stent et al, 2004; <papid> P04-1011 </papid>walker et al, 2001).<papid> N01-1003 </papid></nextsent>
<nextsent>the result is run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which time/performance trade off is necessary (such as real-time dialogue).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE66">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>the final step is to use the training examples to learn an effective search policy so that our run-timegeneration component can find good output sentences in reasonable timeframe.
</prevsent>
<prevsent>in particular, we use variants of existing search optimization (daum?
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
and marcu, 2005) and ranking algorithms (collins and koo, 2005) <papid> J05-1003 </papid>to train our run-time component to find good outputs within specified time window; see also (stent et al, 2004; <papid> P04-1011 </papid>walker et al, 2001).<papid> N01-1003 </papid></citsent>
<aftsection>
<nextsent>the result is run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which time/performance trade off is necessary (such as real-time dialogue).
</nextsent>
<nextsent>3.1 specification of training examples.
</nextsent>
<nextsent>each training example in our approach specifies target output utterance (string), its syntax, and set of links between sub strings with inthe utterance and system semantic representations.
</nextsent>
<nextsent>formally, training example takes the form (u, syntax(u), semantics(u)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE67">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>the final step is to use the training examples to learn an effective search policy so that our run-timegeneration component can find good output sentences in reasonable timeframe.
</prevsent>
<prevsent>in particular, we use variants of existing search optimization (daum?
</prevsent>
</prevsection>
<citsent citstr=" P04-1011 ">
and marcu, 2005) and ranking algorithms (collins and koo, 2005) <papid> J05-1003 </papid>to train our run-time component to find good outputs within specified time window; see also (stent et al, 2004; <papid> P04-1011 </papid>walker et al, 2001).<papid> N01-1003 </papid></citsent>
<aftsection>
<nextsent>the result is run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which time/performance trade off is necessary (such as real-time dialogue).
</nextsent>
<nextsent>3.1 specification of training examples.
</nextsent>
<nextsent>each training example in our approach specifies target output utterance (string), its syntax, and set of links between sub strings with inthe utterance and system semantic representations.
</nextsent>
<nextsent>formally, training example takes the form (u, syntax(u), semantics(u)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE68">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>the final step is to use the training examples to learn an effective search policy so that our run-timegeneration component can find good output sentences in reasonable timeframe.
</prevsent>
<prevsent>in particular, we use variants of existing search optimization (daum?
</prevsent>
</prevsection>
<citsent citstr=" N01-1003 ">
and marcu, 2005) and ranking algorithms (collins and koo, 2005) <papid> J05-1003 </papid>to train our run-time component to find good outputs within specified time window; see also (stent et al, 2004; <papid> P04-1011 </papid>walker et al, 2001).<papid> N01-1003 </papid></citsent>
<aftsection>
<nextsent>the result is run-time component that treats generation as an anytime search problem, and is thus suitable for applications in which time/performance trade off is necessary (such as real-time dialogue).
</nextsent>
<nextsent>3.1 specification of training examples.
</nextsent>
<nextsent>each training example in our approach specifies target output utterance (string), its syntax, and set of links between sub strings with inthe utterance and system semantic representations.
</nextsent>
<nextsent>formally, training example takes the form (u, syntax(u), semantics(u)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE69">
<title id=" W08-1111.xml">practical grammar based nlg from examples </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>we adopt essentially the probabilistic tree-adjoininggrammar (ptag) formalism and grammar induction technique of (chiang, 2003).
</prevsent>
<prevsent>our approach makes three modifications, however.
</prevsent>
</prevsection>
<citsent citstr=" W02-0111 ">
first, while chiangs model includes both full adjunction and sister adjunction operations, our grammar has only sister adjunction (left and right), exactly as in thetaglet grammar formalism of (stone, 2002).<papid> W02-0111 </papid></citsent>
<aftsection>
<nextsent>second, to support lexicalization at an arbitrary granularity, we allow chiangs tree templates to be associated with more than one lexical anchor.
</nextsent>
<nextsent>third, to unify syntactic and semantic reasoning in search,we augment lexical anchors with semantic information.
</nextsent>
<nextsent>formally, wherever chiangs model has lexical anchor w, ours has pair (w1, ..., wn?,m ?), where ? ?
</nextsent>
<nextsent>m is connected to lexical anchors w1, ..., wn?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE77">
<title id=" W08-2139.xml">probabilistic model for syntactic and semantic dependency parsing </title>
<section> experiments and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>wsj test set covers section 23 of treebank.
</prevsent>
<prevsent>brown test set covers sections ck01, ck02, and ck03 of the brown corpus.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the maximum entropy classier (berger et al 1996) <papid> J96-1002 </papid>used is le zhang maximum entropy modeling toolkit and the l-bfgs parameter estimation algorithm with gaussian prior smoothing (chen and rosenfeld, 1999).</citsent>
<aftsection>
<nextsent>the gaussian prior is set to 2 and the iteration count is set to 500.
</nextsent>
<nextsent>all results we list here are post-evaluated.
</nextsent>
<nextsent>because there are some small modifications.
</nextsent>
<nextsent>the experiments are performed on pc with amd athlon?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE78">
<title id=" W09-0602.xml">towards a generation based semantic web authoring tool </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the purpose of such tool is to support knowledge editing onthe semantic web, which at present requires training in graphical user interfaces like protege?
</prevsent>
<prevsent>(rec tor et al, 2004), or direct coding in owl and rdf.
</prevsent>
</prevsection>
<citsent citstr=" P98-2173 ">
linking owl to controlled natural language is currently the topic of an owl1-1 taskforce, and several groups are already working in this area (schwitter and til brook, 2004; thompson et al, 2005; bernstein and kaufmann, 2006; pool, 2006; dongilli, 2007); the novelty in our approach is that we rely entirely on natural language generation (nlg), extending the wysiwym (or conceptualauthoring) method (power and scott, 1998; <papid> P98-2173 </papid>hallett et al, 2007) so that it supports knowledge editing for ontologies as well as for assertions about individuals.the idea of linking formal and natural languages can be traced back to frege (1879), who observed that mathematical proofs were made upof formulae interspersed with passages in natural language, and invented formal logicas way of rendering these passages in precise notation.</citsent>
<aftsection>
<nextsent>with the arrival of artificial intelligence in the 1950s, formal logic became the foundation for knowledge representation and automatic reasoning ? trend leading to the recent concept of asemantic web?
</nextsent>
<nextsent>that would open up knowledge encoding and utilisation to world-wide community (berners-lee et al, 2001).
</nextsent>
<nextsent>however, accessible knowledge management requires accessible pre sentation: hence the current interest in methods of sugaring?
</nextsent>
<nextsent>formal logic into natural language text(ranta, 1994; horacek, 1999), thus in sense turning frege upside-down.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE79">
<title id=" W09-0602.xml">towards a generation based semantic web authoring tool </title>
<section> extensibility: domain experts can extend.  </section>
<citcontext>
<prevsection>
<prevsent>if we propose to use generated cnl as an interface to knowledge base, it is important that generation should be reliable.
</prevsent>
<prevsent>a minimal test of reliability is that the grammar and lexicon are complete, in the sense that they produce text for any well-formed semantic input.
</prevsent>
</prevsection>
<citsent citstr=" W08-0508 ">
elsewhere, we have described generation method that allows completeness to be checked by computer program (hardcastle and power, 2008).<papid> W08-0508 </papid></citsent>
<aftsection>
<nextsent>for any non-trivialdl the set of classes is infinite (e.g., through recur sion on ud or r.c); however, completeness can be proved through an enumeration of all local contexts for which linguistic realisation rule isneeded.
</nextsent>
<nextsent>as well as guaranteeing reliability, completeness checking is obviously useful as an aid to grammar development.
</nextsent>
<nextsent>2.2 uniqueness.
</nextsent>
<nextsent>although necessary, completeness is not sufficient condition on the grammar of cnl, since it could be trivially met by generating the same string (perhaps hallo world?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE80">
<title id=" W09-1308.xml">investigation of unsupervised pattern learning techniques for bootstrap construction of a medical treatment lexicon </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it remained to be demonstrated that these bootstrapping techniques are indeed rapidly retarget able and can be extended to other situations, and so we have extended our scope to investigate medical treatment names in addition to disease terms in this work.
</prevsent>
<prevsent>our approach is inspired by the framework adopted in several bootstrapping systems for learning term dictionaries, including (brin, 1998), (?), and (agichtein, 2000).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
these approaches are based on set of surface patterns (hearst , 1992), <papid> C92-2082 </papid>which are matched to the text collection and used to find instance-concept relations.</citsent>
<aftsection>
<nextsent>similar systems include that of snow and colleagues (snow, 2005), which integrates syntactic dependency structure into pattern representation and has been applied to the task of learning instance-of relations, and the approach developed of caprosaso, et al (caprosaso, 2007) which focussed on learning text context patterns to identify mentions of point mutations.all iterative learning systems suffer from the inevitable problem of spurious patterns and instances introduced in the iterative process.
</nextsent>
<nextsent>to analyze different approaches to addressing this issue, we have compared three different approaches to ranking extracted patterns and three different approaches to ranking extracted instances.
</nextsent>
<nextsent>because such systems also depend on an initial seeding with either seed pattern or term instance, an important question is whether these different starting points lead to different results.
</nextsent>
<nextsent>we investigated this issue by starting from each point separately and compared the final results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE81">
<title id=" W09-1401.xml">overview of bionlprsquo09 shared task on event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of these teams, 24 submitted final results.
</prevsent>
<prevsent>the evaluation results are encouraging, indicating that state-of-the-art performance is approaching practically applicable level and revealing some remaining challenges.
</prevsent>
</prevsection>
<citsent citstr=" M98-1001 ">
the history of text mining (tm) shows that shared tasks based on carefully curated resources, such as those organized in the muc (chinchor, 1998), <papid> M98-1001 </papid>trec (voorhees, 2007) and ace (strassel et al, 2008) events, have significantly contributed to the progress of their respective fields.</citsent>
<aftsection>
<nextsent>this has also beenthe case in bio-tm.
</nextsent>
<nextsent>examples include the trec ge nomics track (hersh et al, 2007), jnlpba (kim et al., 2004), lll (nedellec, 2005), and biocreative(hirschman et al, 2007).
</nextsent>
<nextsent>while the first two addressed bio-ir (information retrieval) and bio-ner (named entity recognition), respectively, the last two focused on bio-ie (information extraction), seeking relations between bio-molecules.
</nextsent>
<nextsent>with the emergence of ner systems with performance capable of supporting practical applications, the recent interest of the bio-tm community is shifting toward ie.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE82">
<title id=" W09-1401.xml">overview of bionlprsquo09 shared task on event extraction </title>
<section> supporting resources.  </section>
<citcontext>
<prevsection>
<prevsent>participants were also provided with the syntactic analyses created by selection of parsers.
</prevsent>
<prevsent>we applied two mainstream penn treebank (ptb) phrase structure parsers: the bikel parser3, implementing collins?
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
parsing model (bikel, 2004) <papid> J04-4004 </papid>and trained on ptb, and the reranking parser of (charniakand johnson, 2005) <papid> P05-1022 </papid>with the self-trained biomedical parsing model of (mcclosky and charniak,2008)<papid> P08-2026 </papid>4.</citsent>
<aftsection>
<nextsent>we also applied the gdep5, native dependency parser trained on the genia treebank 2http://u-compare.org/ 3http://www.cis.upenn.edu/dbikel/software.html 4http://www.cs.brown.edu/dmcc/biomedical.html 5http://www.cs.cmu.edu/sagae/parser/gdep/ 5 nlp task team task org word chunking parsing trigger argument ext.
</nextsent>
<nextsent>resources uturku 1-- 3c+2bi porter mc svm svm (svmlight) julie lab 1-- 1c+2l+2b opennlp opennlp gdep dict+stat svm(libsvm) uniprot, mesh, porter me(mallet) goa, umls concordu 1-3 3c stanford stanford dict+stat rules wordnet, verbnet, umls ut+dbcls 12- 2c porter mc dict mln(thebeast) ccg vib ghent 1-3 2c+1b porter, stanford dict svm(libsvm) utokyo 1-- 3c gtag gdep, dict me(liblinear) uima enju unsw 1-- 1c+1b gdep crf rules wordnet, metamap uzurich 1-- 3c ling pipe, ltchunk pro3gres dict rules morpha asu+hu+bu 123 6c+2bi porter biolg, dict rules lucene charniak rules cam 1-- 3c porter rasp dict rules uantwerp 12- 3c gtag gdep mbl mbl(timbl) rules uniman 1-- 4c+2bi porter gdep dict, crf svm mesh, go gtag rules scai 1-- 1c rules uaveiro 1-- 1c+1l nooj nooj rules bio lexicon uszeged 1-3 3c+1b gtag dict, vsm c4.5(weka) bio scope rules nicta 1-3 4c gtag erg crf(crf++) rules julie cnb madrid 12- 2c+1b porter, gtag cbr gtag rules ccp-btmg 123 7c ling pipe ling pipe opendmap ling pipe, cm rules go, so, mio, uima cips-asu 1-- 3c monty tagger custom stanford crf(abner) rules, nb(weka) umich 1-- 2c stanford mc dict svm(svmlight) pikb 1-- 5c+2b mira mira koreau 1-- 5c gtag gdep rules, me me wsj table 4: profiles of the participants: gtag=geniatagger, mln=markov logic network, umls=umls specialist lexicon/tools, mc=mcclosky-charniak, gdep=genia dependency parser, stanford=stanford parser, cbr=case-based reasoning, cm=conceptmapper.
</nextsent>
<nextsent>(tateisi et al, 2005), and version of the c&c; ccg deep parser6 adapted to biomedical text (rimell and clark, 2008).the text of all documents was segmented and tokenized using the genia sentence splitter and the genia tagger, provided by u-compare.
</nextsent>
<nextsent>the same segmentation was enforced for all parsers, which were run using default settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE83">
<title id=" W09-1401.xml">overview of bionlprsquo09 shared task on event extraction </title>
<section> supporting resources.  </section>
<citcontext>
<prevsection>
<prevsent>participants were also provided with the syntactic analyses created by selection of parsers.
</prevsent>
<prevsent>we applied two mainstream penn treebank (ptb) phrase structure parsers: the bikel parser3, implementing collins?
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
parsing model (bikel, 2004) <papid> J04-4004 </papid>and trained on ptb, and the reranking parser of (charniakand johnson, 2005) <papid> P05-1022 </papid>with the self-trained biomedical parsing model of (mcclosky and charniak,2008)<papid> P08-2026 </papid>4.</citsent>
<aftsection>
<nextsent>we also applied the gdep5, native dependency parser trained on the genia treebank 2http://u-compare.org/ 3http://www.cis.upenn.edu/dbikel/software.html 4http://www.cs.brown.edu/dmcc/biomedical.html 5http://www.cs.cmu.edu/sagae/parser/gdep/ 5 nlp task team task org word chunking parsing trigger argument ext.
</nextsent>
<nextsent>resources uturku 1-- 3c+2bi porter mc svm svm (svmlight) julie lab 1-- 1c+2l+2b opennlp opennlp gdep dict+stat svm(libsvm) uniprot, mesh, porter me(mallet) goa, umls concordu 1-3 3c stanford stanford dict+stat rules wordnet, verbnet, umls ut+dbcls 12- 2c porter mc dict mln(thebeast) ccg vib ghent 1-3 2c+1b porter, stanford dict svm(libsvm) utokyo 1-- 3c gtag gdep, dict me(liblinear) uima enju unsw 1-- 1c+1b gdep crf rules wordnet, metamap uzurich 1-- 3c ling pipe, ltchunk pro3gres dict rules morpha asu+hu+bu 123 6c+2bi porter biolg, dict rules lucene charniak rules cam 1-- 3c porter rasp dict rules uantwerp 12- 3c gtag gdep mbl mbl(timbl) rules uniman 1-- 4c+2bi porter gdep dict, crf svm mesh, go gtag rules scai 1-- 1c rules uaveiro 1-- 1c+1l nooj nooj rules bio lexicon uszeged 1-3 3c+1b gtag dict, vsm c4.5(weka) bio scope rules nicta 1-3 4c gtag erg crf(crf++) rules julie cnb madrid 12- 2c+1b porter, gtag cbr gtag rules ccp-btmg 123 7c ling pipe ling pipe opendmap ling pipe, cm rules go, so, mio, uima cips-asu 1-- 3c monty tagger custom stanford crf(abner) rules, nb(weka) umich 1-- 2c stanford mc dict svm(svmlight) pikb 1-- 5c+2b mira mira koreau 1-- 5c gtag gdep rules, me me wsj table 4: profiles of the participants: gtag=geniatagger, mln=markov logic network, umls=umls specialist lexicon/tools, mc=mcclosky-charniak, gdep=genia dependency parser, stanford=stanford parser, cbr=case-based reasoning, cm=conceptmapper.
</nextsent>
<nextsent>(tateisi et al, 2005), and version of the c&c; ccg deep parser6 adapted to biomedical text (rimell and clark, 2008).the text of all documents was segmented and tokenized using the genia sentence splitter and the genia tagger, provided by u-compare.
</nextsent>
<nextsent>the same segmentation was enforced for all parsers, which were run using default settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE84">
<title id=" W09-1401.xml">overview of bionlprsquo09 shared task on event extraction </title>
<section> supporting resources.  </section>
<citcontext>
<prevsection>
<prevsent>participants were also provided with the syntactic analyses created by selection of parsers.
</prevsent>
<prevsent>we applied two mainstream penn treebank (ptb) phrase structure parsers: the bikel parser3, implementing collins?
</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
parsing model (bikel, 2004) <papid> J04-4004 </papid>and trained on ptb, and the reranking parser of (charniakand johnson, 2005) <papid> P05-1022 </papid>with the self-trained biomedical parsing model of (mcclosky and charniak,2008)<papid> P08-2026 </papid>4.</citsent>
<aftsection>
<nextsent>we also applied the gdep5, native dependency parser trained on the genia treebank 2http://u-compare.org/ 3http://www.cis.upenn.edu/dbikel/software.html 4http://www.cs.brown.edu/dmcc/biomedical.html 5http://www.cs.cmu.edu/sagae/parser/gdep/ 5 nlp task team task org word chunking parsing trigger argument ext.
</nextsent>
<nextsent>resources uturku 1-- 3c+2bi porter mc svm svm (svmlight) julie lab 1-- 1c+2l+2b opennlp opennlp gdep dict+stat svm(libsvm) uniprot, mesh, porter me(mallet) goa, umls concordu 1-3 3c stanford stanford dict+stat rules wordnet, verbnet, umls ut+dbcls 12- 2c porter mc dict mln(thebeast) ccg vib ghent 1-3 2c+1b porter, stanford dict svm(libsvm) utokyo 1-- 3c gtag gdep, dict me(liblinear) uima enju unsw 1-- 1c+1b gdep crf rules wordnet, metamap uzurich 1-- 3c ling pipe, ltchunk pro3gres dict rules morpha asu+hu+bu 123 6c+2bi porter biolg, dict rules lucene charniak rules cam 1-- 3c porter rasp dict rules uantwerp 12- 3c gtag gdep mbl mbl(timbl) rules uniman 1-- 4c+2bi porter gdep dict, crf svm mesh, go gtag rules scai 1-- 1c rules uaveiro 1-- 1c+1l nooj nooj rules bio lexicon uszeged 1-3 3c+1b gtag dict, vsm c4.5(weka) bio scope rules nicta 1-3 4c gtag erg crf(crf++) rules julie cnb madrid 12- 2c+1b porter, gtag cbr gtag rules ccp-btmg 123 7c ling pipe ling pipe opendmap ling pipe, cm rules go, so, mio, uima cips-asu 1-- 3c monty tagger custom stanford crf(abner) rules, nb(weka) umich 1-- 2c stanford mc dict svm(svmlight) pikb 1-- 5c+2b mira mira koreau 1-- 5c gtag gdep rules, me me wsj table 4: profiles of the participants: gtag=geniatagger, mln=markov logic network, umls=umls specialist lexicon/tools, mc=mcclosky-charniak, gdep=genia dependency parser, stanford=stanford parser, cbr=case-based reasoning, cm=conceptmapper.
</nextsent>
<nextsent>(tateisi et al, 2005), and version of the c&c; ccg deep parser6 adapted to biomedical text (rimell and clark, 2008).the text of all documents was segmented and tokenized using the genia sentence splitter and the genia tagger, provided by u-compare.
</nextsent>
<nextsent>the same segmentation was enforced for all parsers, which were run using default settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE85">
<title id=" W08-1402.xml">learning to match names across languages </title>
<section> basic approaches.  </section>
<citcontext>
<prevsection>
<prevsent>we present results of large-scale machine-learning for matching personal names in chinese and english, along with some preliminary results for english and urdu.
</prevsent>
<prevsent>2.1 cross-lingual approach.
</prevsent>
</prevsection>
<citsent citstr=" N06-1060 ">
our cross-lingual approach (called mlev) is based on (freeman et al 2006), <papid> N06-1060 </papid>who used modified levenshtein string edit-distance algorithm to match arabic script person names against their corresponding english versions.</citsent>
<aftsection>
<nextsent>the levenshtein edit-distance algorithm counts the minimum number of insertions, deletions or substitutions required to make pair of strings match.
</nextsent>
<nextsent>freeman et al (2006) <papid> N06-1060 </papid>used (1) insights about phonological differences between the two languages to create rules for equivalence classes of characters that are treated as identical in the computation of edit-distance and (2) the use of normalization rules applied to the english and transliterated arabic names based on mappings between characters in the respective writing systems.</nextsent>
<nextsent>for example, characters corresponding to low diphthongs in english are normalized as w?, the transliteration for the arabic character, while high diphthongs are mapped to y?, the transliteration for the arabic ???</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE88">
<title id=" W08-1402.xml">learning to match names across languages </title>
<section> basic approaches.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 monolingual approach.
</prevsent>
<prevsent>instead of relying on rules that require extensive knowledge of differences between language pair2, the monolingual approach first builds phonemic representations for each name, and then aligns them.
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
earlier research by (kondrak 2000) <papid> A00-2038 </papid>used dynamic programming to align strings of phonemes, representing the phonemes as vectors of phonological features, which are associated with scores to produce similarity values.</citsent>
<aftsection>
<nextsent>his program aline includes skip?
</nextsent>
<nextsent>function in the alignment operations that can be exploited for handling epenthetic segments, and in addition to 1:1 alignments, it also handles 1:2 and 2:1 alignments.
</nextsent>
<nextsent>in this research, we made extensive modifications to aline to add the phonological features for languages like chinese and arabic and to normalize the similarity scores, producing system called maline.
</nextsent>
<nextsent>in table 1, the maline row3 shows that the english name has palato-alveolar modification 2as (freeman et al, 2006) <papid> N06-1060 </papid>point out, these insights are not easy to come by: these rules are based on first author dr. andrew freemans experience with reading and translating arabic language texts for more than 16 years?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE91">
<title id=" W08-1402.xml">learning to match names across languages </title>
<section> from svmlight.joachims.org..  </section>
<citcontext>
<prevsection>
<prevsent>(2005) use conditional random fields (crfs) to learn edit costs, arguing in favor of discriminative training approaches and against generative approaches, based in part on the fact that the latter approaches cannot benefit from negative evidence from pairs of strings that (while partially overlapping) should be considered dissimilar?.
</prevsent>
<prevsent>such crfs model the conditional probability of label sequence (an alignment of two strings) given sequence of observations (the strings).
</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
a related thread of research is work on automatic transliteration, where training sets are typically used to compute probabilities for mappings in weighted finite state transducers (al-onaizan and knight 2002; gao et al 2004) or source-channel models (knight and graehl 1997; <papid> P97-1017 </papid>li et al 2004).<papid> P04-1021 </papid></citsent>
<aftsection>
<nextsent>(sproat et al 2006) <papid> P06-1010 </papid>have compared names from comparable and contemporaneous english and chinese texts, scoring matches by training learning algorithm to compare the phonemic representations of the names in the pair, in addition to taking into account the frequency distribution of the pair over time.</nextsent>
<nextsent>(tao et al 2006) obtain similar results using frequency and similarity score based on phonetic cost matrix the above approaches have all developed special-purpose machine-learning architectures to address the matching of string sequences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE92">
<title id=" W08-1402.xml">learning to match names across languages </title>
<section> from svmlight.joachims.org..  </section>
<citcontext>
<prevsection>
<prevsent>(2005) use conditional random fields (crfs) to learn edit costs, arguing in favor of discriminative training approaches and against generative approaches, based in part on the fact that the latter approaches cannot benefit from negative evidence from pairs of strings that (while partially overlapping) should be considered dissimilar?.
</prevsent>
<prevsent>such crfs model the conditional probability of label sequence (an alignment of two strings) given sequence of observations (the strings).
</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
a related thread of research is work on automatic transliteration, where training sets are typically used to compute probabilities for mappings in weighted finite state transducers (al-onaizan and knight 2002; gao et al 2004) or source-channel models (knight and graehl 1997; <papid> P97-1017 </papid>li et al 2004).<papid> P04-1021 </papid></citsent>
<aftsection>
<nextsent>(sproat et al 2006) <papid> P06-1010 </papid>have compared names from comparable and contemporaneous english and chinese texts, scoring matches by training learning algorithm to compare the phonemic representations of the names in the pair, in addition to taking into account the frequency distribution of the pair over time.</nextsent>
<nextsent>(tao et al 2006) obtain similar results using frequency and similarity score based on phonetic cost matrix the above approaches have all developed special-purpose machine-learning architectures to address the matching of string sequences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE93">
<title id=" W08-1402.xml">learning to match names across languages </title>
<section> from svmlight.joachims.org..  </section>
<citcontext>
<prevsection>
<prevsent>such crfs model the conditional probability of label sequence (an alignment of two strings) given sequence of observations (the strings).
</prevsent>
<prevsent>a related thread of research is work on automatic transliteration, where training sets are typically used to compute probabilities for mappings in weighted finite state transducers (al-onaizan and knight 2002; gao et al 2004) or source-channel models (knight and graehl 1997; <papid> P97-1017 </papid>li et al 2004).<papid> P04-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1010 ">
(sproat et al 2006) <papid> P06-1010 </papid>have compared names from comparable and contemporaneous english and chinese texts, scoring matches by training learning algorithm to compare the phonemic representations of the names in the pair, in addition to taking into account the frequency distribution of the pair over time.</citsent>
<aftsection>
<nextsent>(tao et al 2006) obtain similar results using frequency and similarity score based on phonetic cost matrix the above approaches have all developed special-purpose machine-learning architectures to address the matching of string sequences.
</nextsent>
<nextsent>they take pairs of strings that havent been aligned, and learn costs or mappings from them, and once trained, search for the best match given the learned representation positive threshold examples method r accuracy .65 660 svm light 90.62 87.88 89.22 89.39 .65 660 weka smo 80.6 83.3 81.92 81.66 .65 660 ada boost m1 84.9 78.5 81.57 82.27 table 3: comparison of different classifiers method positive threshold examples r weka smo .55 (maline) 206 (maline) 84.8 [81.5] 86.4 [93.3] 85.6 [87.0] weka smo .85 (mlev) 584 (mlev) 89.9 [93.2] 94.7 [91.2] 92.3 [92.2] table 4: urdu-roman name matching results with random negatives (baseline scores in square brackets) 8 our approach, by contrast, takes pairs of strings along with an alignment, and using features derived from the alignments, trains learner to derive the best match given the features.
</nextsent>
<nextsent>this offers the advantage of modularity, in that any type of alignment model can be combined with svms or other classifiers (we have preferred svms since they offer discriminative training).
</nextsent>
<nextsent>our approach allows leveraging of any existing alignments, which can lead to starting the learning from higher baseline and less training data to get to the same level of performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE94">
<title id=" W09-1301.xml">static relations a piece in the biomedical information extraction puzzle </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>motivated by the needs of biologists and e.g. database cur ation efforts, most domain re efforts target relations involving biologically relevant changes in the involved entities, commonly to the complete exclusion of static relations.
</prevsent>
<prevsent>however,static relations such as entity membership in family and one entity being part of another are not only relevant ie targets in themselves but can also play an important supporting role in ie systems not primarily targeting them.in this paper, we investigate the role of static relations in causal re and event extraction.
</prevsent>
</prevsection>
<citsent citstr=" M95-1002 ">
here, we use relation extraction in the muc and ace (sundheim, 1995; <papid> M95-1002 </papid>doddington et al, 2004) sense torefer to the task of extracting binary relations, ordered pairs of entities, where both participating entities must be specified and their roles (agent, patient,etc.) are fixed by the relation.</citsent>
<aftsection>
<nextsent>by contrast, event extraction is understood to involve events (things that happen) and representations where the number and roles of participants may vary more freely.
</nextsent>
<nextsent>we refer to relations where one one entity causes another to change as causal relations; typical domain examples are phosphorylation and activation.
</nextsent>
<nextsent>static relations, by contrast, hold between two entities without implication of change or causality: examples fromthe ace ie task include physical.located and part whole.artifact.
</nextsent>
<nextsent>in the following, we argue that static relations are relevant to much of current biomedical ie work, present task setting making these relations explicit, and discuss applications of static relation annotation and extraction methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE96">
<title id=" W09-1301.xml">static relations a piece in the biomedical information extraction puzzle </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition (ner) is well studied and several biomed 1 ical ner systems are available (see e.g.
</prevsent>
<prevsent>(wilbur et al, 2007; leaman and gonzalez, 2008)), andmost domain ie approaches are ne-driven: typical way to cast there task is as deciding for each pair of co-occurring nes whether relevant relation is stated for them in context.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
like the previous lll and biocreative2-ppi relation extraction tasks (nedellec, 2005; krallinger et al, 2007), the bionlp09 shared task on event extraction (kim et al., 2009) <papid> W09-1401 </papid>similarly proceeds from nes, requiring participants to detect events and determine the roles given nes play in them.</citsent>
<aftsection>
<nextsent>any domain ie approach targeting non trivial causal ne relations or events necessarily involves decisions relating to static relations.
</nextsent>
<nextsent>consider, for example, the decision whether to extract relation between ne1 and ne2 in the following cases (affects should here be understood as place holder for any relevant statement of causal relation): 1) ne1 affects ne2 gene 2) ne1 affects ne2 promoter 3) ne1 affects ne2 mutant 4) ne1 affects ne2 antibody 5) ne1 affects ne2 activator the decision here depends on the interpretation ofthe noun compounds (ncs) ne2 gene, ne2 promoter, etc. depending on the ie setting, one might, for example, judge that statements (1)?(3) justify the extraction of an (ne1, ne2) relation, while (4) and (5) do not.
</nextsent>
<nextsent>this question is rarely formalized asa separate (sub)task in domain studies, and methods targeting e.g. the lll, biocreative2-ppi and bionlp09 shared task relations and events must learn to resolve this question together with the separate issue of which words and syntactic structures express relevant causal relations.
</nextsent>
<nextsent>2.2 task setting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE97">
<title id=" W09-1301.xml">static relations a piece in the biomedical information extraction puzzle </title>
<section> relations.  </section>
<citcontext>
<prevsection>
<prevsent>one significant class of cases annotated as variant includes expressions such as ne gene and ne protein, under the interpretation that ne refer sto the abstract information that is realized?
</prevsent>
<prevsent>as either dna, rna or protein form, and the entity toone of these realizations (for alternative interpretations, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
(rosario and hearst, 2001; <papid> W01-0511 </papid>heimonen et al, 2008)).the variant relation is also used to annotate ne entity relations where the entity expresses different state of the ne, such as phosphorylated or mutatedstate.</citsent>
<aftsection>
<nextsent>while each possible post-translational modification, for example, could alternatively be assigned specific relation type, in the present ie context these would only increase the difficulty of the task without increasing the applicability of the resulting annotation.
</nextsent>
<nextsent>3.4 other/out annotation.
</nextsent>
<nextsent>we apply catch-all category, other/out, for annotating candidate (ne, entity) pairs between which there is no relevant static relation.
</nextsent>
<nextsent>this label is thus applied to number of quite different cases: causal relations, both implied (e.g. ne receptors, ne response element) and explicitly stated (ne binds the [site]), relations where the entity is considered toofar removed from the ne to support reliable inference of role for the ne in causal relations/events involving the entity (e.g. [antibodies] for ne), and cases where no relation is stated (e.g. ne and other [proteins]).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE98">
<title id=" W09-1301.xml">static relations a piece in the biomedical information extraction puzzle </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>truncation mutants of the ne promoter1.
</prevsent>
<prevsent>while this result is likely affected by number of complex factors (annotation criteria, ne and entity types, granularity of relations, etc.), we find the outcome ? which was neither planned for nor forced on the data ? very encouraging sign of the sufficiency of the task setting for this and related domain ie tasks.
</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
we created the dataset by building on the annotation of the genia event corpus (kim et al, 2008), making use of the rich set of annotations already contained in the corpus: term annotation fornes and other entities (ohta et al, 2002), annotation of events between these terms, and treebank structure closely following the penn treebank scheme (tateisi et al, 2005).<papid> I05-2038 </papid></citsent>
<aftsection>
<nextsent>4.1 annotation.
</nextsent>
<nextsent>the existing genia annotations served as the basisof the new annotation.
</nextsent>
<nextsent>we initially selected as candidates entities annotated as participating in events considered in the bionlp09 shared task.as the term annotation includes nesting of entities, nes contained within these relevant entities were used as the starting point for the annotation.we first performed preliminary study of the relevant static relations occurring between the entities and nes occurring within them to determine the set of relations to annotate.
</nextsent>
<nextsent>next, all unique cases where selected entity contained an ne were annotated with the appropriate relation based on the contained text of the entity, with the text of the containedne normalized away.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE103">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>co-occurrence based approaches (jenssen et al,2001; ding et al, 2002) to biological relation extraction provide high recall at the expense of low 119 precision.
</prevsent>
<prevsent>shallow parsing and syntactic templates(blaschke et al, 1999; rindflesch et al, 2000; friedman et al, 2001; blaschke and valencia, 2001; leroy et al, 2003; ahlers et al, 2007), as well as full parsing (daraselia et al, 2004; yakushiji et al,2005), have also been explored as the basis for relation extraction.
</prevsent>
</prevsection>
<citsent citstr=" W06-3307 ">
in contrast to co-occurrence based methods, these more sophisticated approaches provide higher precision at the expense of lower recall.approaches combining the strengths of complementary models have also been proposed (bunescu et al, 2006) <papid> W06-3307 </papid>for high recall and precision.</citsent>
<aftsection>
<nextsent>more recently, dependency parse representation has found considerable use in relation extraction,particularly in extraction of protein-protein interactions (ppi).
</nextsent>
<nextsent>fundel et al (2007) use stanford dependency parses of medline abstracts as the basis for rules that extract gene/protein interactions.
</nextsent>
<nextsent>rinaldi et al (2007) extract relations combining hand written grammar based on dependency parsing witha statistical language model.
</nextsent>
<nextsent>airola et al (2008) extract protein-protein interactions from scientific literature using supervised machine learning based on an all-dependency-paths kernel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE104">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the speculative aspect of the biomedical literature (also referred to as hedging) has been the focus of several recent studies.
</prevsent>
<prevsent>these studies primarily dealt with distinguishing speculative sentences from non speculative ones.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
supervised machine learning techniques mostly dominate this area of research (light et al, 2004; <papid> W04-3103 </papid>medlock and briscoe, 2007; <papid> P07-1125 </papid>szarvas,2008).</citsent>
<aftsection>
<nextsent>a more linguistically-based approach, relying on lexical and syntactic patterns, has been explored as well (kilicoglu and bergler, 2008).
</nextsent>
<nextsent>the scope of speculative statements is annotated in thebioscope corpus (vincze et al, 2008); however, experiments in detecting speculation scope have yet to be reported.
</nextsent>
<nextsent>recognizing whether extracted events are negated is crucial, as negation reverses the meaning of proposition.
</nextsent>
<nextsent>most of the work on negation in the biomedical domain focused on finding negated terms or concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE105">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the speculative aspect of the biomedical literature (also referred to as hedging) has been the focus of several recent studies.
</prevsent>
<prevsent>these studies primarily dealt with distinguishing speculative sentences from non speculative ones.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
supervised machine learning techniques mostly dominate this area of research (light et al, 2004; <papid> W04-3103 </papid>medlock and briscoe, 2007; <papid> P07-1125 </papid>szarvas,2008).</citsent>
<aftsection>
<nextsent>a more linguistically-based approach, relying on lexical and syntactic patterns, has been explored as well (kilicoglu and bergler, 2008).
</nextsent>
<nextsent>the scope of speculative statements is annotated in thebioscope corpus (vincze et al, 2008); however, experiments in detecting speculation scope have yet to be reported.
</nextsent>
<nextsent>recognizing whether extracted events are negated is crucial, as negation reverses the meaning of proposition.
</nextsent>
<nextsent>most of the work on negation in the biomedical domain focused on finding negated terms or concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE106">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of the work on negation in the biomedical domain focused on finding negated terms or concepts.
</prevsent>
<prevsent>some of these systems arerule-based and relyon lexical or syntactic information (mutalik et al, 2001; chapman et al, 2001; sanchez-graillet and poesio, 2007); while others (averbuch et al, 2004; goldin and chapman, 2003)experiment with machine learning techniques.
</prevsent>
</prevsection>
<citsent citstr=" D08-1075 ">
a recent study (morante et al, 2008) <papid> D08-1075 </papid>focuses on learning negation scope using memory-based classifiers trained on the bio scope corpus.</citsent>
<aftsection>
<nextsent>our approach to task 1 is most similar to workof fundel et al (2007) as it builds on dependency based heuristics.
</nextsent>
<nextsent>however, we address larger number of event classes, including regulatory events allowing participation of other events.
</nextsent>
<nextsent>in addition,event triggers are central to our approach, contrasting with their system and most other ppi systems that relyon finding dependency paths between entities.
</nextsent>
<nextsent>we extended prior work for task 3 and obtained state of the art results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE107">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> event detection and characterization.  </section>
<citcontext>
<prevsection>
<prevsent>our event detection and characterization pipeline requires xml representation of document as in put.
</prevsent>
<prevsent>here, the xml representation of document contains sentences, their offset positions and dependency parses as well as entities (proteins) and their offset positions in addition to word information (tokens, part-of-speech tags, indexes and lemmas).
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we used the stanford lexicalized parser (klein and manning, 2003) <papid> P03-1054 </papid>to extract word-related information, as well as for dependency parsing.</citsent>
<aftsection>
<nextsent>3.2 event triggers.
</nextsent>
<nextsent>after parsing the training corpus and creating an enriched document representation, we proceeded with constructing dictionary of event triggers, drawing from training corpus annotations of triggers and making further refinements, as described below.
</nextsent>
<nextsent>we view event triggers essentially as predicates and thus restricted event triggers to words carrying verb, noun or adjective part-of-speech tags.
</nextsent>
<nextsent>our analysis suggests that, in general, trigger words with other pos tags are tenuously annotated event triggers and in fact require more context to qualify as 120 event triggers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE108">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> event detection and characterization.  </section>
<citcontext>
<prevsection>
<prevsent>dobj(examined,effect) prep on(examined,expression) this dependency path occurs almost exclusively with pp attachment errors involving on, leading usto stipulate corrective?
</prevsent>
<prevsent>dependency path, implemented for certain trigger words (e.g., effect, influence, impact in this case).
</prevsent>
</prevsection>
<citsent citstr=" W06-3312 ">
post nominal prepositional attachment heuristics detailed in schuman and bergler (2006) <papid> W06-3312 </papid>helped determine 6 such patterns.</citsent>
<aftsection>
<nextsent>two common verbs (require and involve) deserve special attention, as the semantic roles of their sub ject/object constituents differ from typical verbs.
</nextsent>
<nextsent>the prototypical cause dependency, nsubj, indicates theme in the following sentence: (3) regulation of interleukin-1beta transcription by epstein-barr virus involves number of latent proteins via their interaction with rbp.
</nextsent>
<nextsent>nsubj(involves,regulation) for these two verbs, participant identification rules are reversed.an interesting phenomenon is nps with hyphenated adjectival modifiers, occurring frequently in molecular biology texts (e.g., ?...
</nextsent>
<nextsent>lps-mediatedtf expression...?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE109">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> any combination of the above.  </section>
<citcontext>
<prevsection>
<prevsent>it is fairly easy to add rule to address such occurrences.we have not attempted to resolve anaphoric expressions for the shared task, which led to fair number of recall errors.
</prevsent>
<prevsent>in similar vein, we ignored events spanning multiple sentences.
</prevsent>
</prevsection>
<citsent citstr=" C08-1033 ">
we expect that several studies addressing anaphora resolution in biomedical text (castano et al, 2002; gasperin and briscoe, 2008) <papid> C08-1033 </papid>will inform our near future efforts in this area.</citsent>
<aftsection>
<nextsent>evaluation results regarding task 3 may seem poor at first; however, most of the errors concern misidentified or missed base events.
</nextsent>
<nextsent>thus, in this section, we focus on errors specifically triggered by speculation and negation module.
</nextsent>
<nextsent>in the development corpus, we identified 39 speculation instances,4 of which were errors due to speculation processing.
</nextsent>
<nextsent>of 95 annotated speculation instances, 7 were missed due to deficiencies in speculation processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE110">
<title id=" W09-1418.xml">syntactic dependency based heuristics for biological event extraction </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we plan to address anaphora resolution and multiple sentence spanning events in the near future.
</prevsent>
<prevsent>our nave approach to event triggers needs refinement and we believe that sophisticated supervised machine learning techniques may be helpful.in addition, biomedical lexical resources, including umls specialist lexicon (mccray et al, 1994), may be useful in improving event trigger detection.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
finally, dependency relations based on the stanford parser provided better performance in our case, in contrast to general consensus that those based on charniak parser (charniak and johnson,2005) <papid> P05-1022 </papid>are superior, and this, too, deserves further in vestigation.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE111">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>translation systems are complex, and most metrics do little to pinpoint causes of error or isolate system differences.
</prevsent>
<prevsent>we use simple technique to discover induction errors, which occur when good translations are absent from model search spaces.our results show that common pruning heuristic drastically increases induction error, and also strongly suggest thatthe search spaces of phrase-based and hierarchical phrase-based models are highly overlapping despite the well known structural differences.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
most empirical work in translation analyzes models and algorithms using bleu (papineni et al,2002) <papid> P02-1040 </papid>and related metrics.</citsent>
<aftsection>
<nextsent>though such metrics are useful as sanity checks in iterative system development, they are less useful as analytical tools.
</nextsent>
<nextsent>the performance of translation system depends on the complex interaction of several different components.
</nextsent>
<nextsent>since metrics assess only out put, they fail to inform us about the consequences of these interactions, and thus provide no insight into the errors made by system, or into the design tradeoffs of competing systems.in this work, we show that it is possible to obtain such insights by analyzing translation system components in isolation.
</nextsent>
<nextsent>we focus on model search spaces (2), posing very simple question: given model and sentence pair, does the search space contain the sentence pair?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE112">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> models, search spaces, and errors.  </section>
<citcontext>
<prevsection>
<prevsent>second, we find that the high-probability regions in the search spaces of phrase-based and hierarchical systems are nearly identical(4).
</prevsent>
<prevsent>this means that reported differences between the models are due to their rankings of competing hypotheses, rather than structural differences of the derivations they produce.
</prevsent>
</prevsection>
<citsent citstr=" C08-1064 ">
a translation model consists of two distinct elements: an unweighted ruleset, and parameterization (lopez, 2008<papid> C08-1064 </papid>a; 2009).</citsent>
<aftsection>
<nextsent>a ruleset licenses the steps by which source string f1...fi may be rewritten as target string e1...ej . parameterization defines weight function over every sequence of rule applications.
</nextsent>
<nextsent>in phrase-based model, the ruleset is simply the unweighted phrase table, where each phrase pair fi...fi?/ej ...ej?
</nextsent>
<nextsent>states that phrase fi...fi?
</nextsent>
<nextsent>inthe source can be rewritten as ej ...ej?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE115">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> how similar are model search spaces?.  </section>
<citcontext>
<prevsection>
<prevsent>the underlying assumption in most discussions of these models is that these differences in their generative stories are responsible for differences in performance.
</prevsent>
<prevsent>we believe that this assumption should be investigated empirically.
</prevsent>
</prevsection>
<citsent citstr=" C08-1144 ">
in an interesting analysis of phrase-based and hierarchical translation, zollmann et al (2008)<papid> C08-1144 </papid>forced phrase-based system to produce the translations generated by hierarchical system.</citsent>
<aftsection>
<nextsent>unfortunately, their analysis is incomplete; they do not perform the analysis in both directions.
</nextsent>
<nextsent>in 5.5 we extend their work by requiring each system to generate the 1-best output of the other.
</nextsent>
<nextsent>this allows us to see how their search spaces differ.
</nextsent>
<nextsent>we analyse rule sets in isolation, removing the influence of the parametrization and heuristics as much as possible for each system as follows: first, we disabled beam search to avoid pruning based on parametrization weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE116">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this leaves only some search restrictions such as the distortion limit for the phrase-based system for which we controlled, or the maximum number of source words involved in rule application for the hierarchical system.
</prevsent>
<prevsent>5.1 experimental systems.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our phrase-based system is moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we set its stack size to 105, disabled the beam threshold, and varied the translation option limit tol.
</nextsent>
<nextsent>forced translation was implemented by schwartz (2008) who ensures that hypothesis are prefix of the reference to be generated.
</nextsent>
<nextsent>our hierarchical system is hiero (chiang, 2007), modified to construct rules from small sample of occurrences of each source phrase in training as described by lopez (2008<papid> C08-1064 </papid>b).</nextsent>
<nextsent>the search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE119">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 experimental data.
</prevsent>
<prevsent>we conducted experiments in french-english translation, attempting to make the experimental conditions for both systems as equal as possible.each system was trained on french-english eu roparl (koehn, 2005), version 3 (40m words).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the corpus was aligned with giza++ (och and ney,2003) <papid> J03-1002 </papid>and symmetrized with the grow-diag-final and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>a trigram language model with modified kneser-ney discounting and interpolation was used as produced by the srilm toolkit (stolcke, 2002).
</nextsent>
<nextsent>systems were optimized on the wmt08 french-englishdevelopment data (2000 sentences) using minimum error rate training (och, 2003) <papid> P03-1021 </papid>and tested on the wmt08 test data (2000 sentences).</nextsent>
<nextsent>rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con 226 20 50 100 200 400 800 all10 15 20 25 30 35 translation option limit rea chab ility (%) dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16 figure 2: coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE120">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 experimental data.
</prevsent>
<prevsent>we conducted experiments in french-english translation, attempting to make the experimental conditions for both systems as equal as possible.each system was trained on french-english eu roparl (koehn, 2005), version 3 (40m words).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the corpus was aligned with giza++ (och and ney,2003) <papid> J03-1002 </papid>and symmetrized with the grow-diag-final and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>a trigram language model with modified kneser-ney discounting and interpolation was used as produced by the srilm toolkit (stolcke, 2002).
</nextsent>
<nextsent>systems were optimized on the wmt08 french-englishdevelopment data (2000 sentences) using minimum error rate training (och, 2003) <papid> P03-1021 </papid>and tested on the wmt08 test data (2000 sentences).</nextsent>
<nextsent>rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con 226 20 50 100 200 400 800 all10 15 20 25 30 35 translation option limit rea chab ility (%) dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16 figure 2: coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE121">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus was aligned with giza++ (och and ney,2003) <papid> J03-1002 </papid>and symmetrized with the grow-diag-final and heuristic (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>a trigram language model with modified kneser-ney discounting and interpolation was used as produced by the srilm toolkit (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
systems were optimized on the wmt08 french-englishdevelopment data (2000 sentences) using minimum error rate training (och, 2003) <papid> P03-1021 </papid>and tested on the wmt08 test data (2000 sentences).</citsent>
<aftsection>
<nextsent>rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con 226 20 50 100 200 400 800 all10 15 20 25 30 35 translation option limit rea chab ility (%) dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16 figure 2: coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl).
</nextsent>
<nextsent>straint.
</nextsent>
<nextsent>ayan and dorr (2006) <papid> P06-1002 </papid>showed that under certain conditions, this constraint could have significant impact on system performance.</nextsent>
<nextsent>the maximum phrase lengths for both the hierarchical and phrase-based system were set to 7.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE122">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con 226 20 50 100 200 400 800 all10 15 20 25 30 35 translation option limit rea chab ility (%) dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16 figure 2: coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl).
</prevsent>
<prevsent>straint.
</prevsent>
</prevsection>
<citsent citstr=" P06-1002 ">
ayan and dorr (2006) <papid> P06-1002 </papid>showed that under certain conditions, this constraint could have significant impact on system performance.</citsent>
<aftsection>
<nextsent>the maximum phrase lengths for both the hierarchical and phrase-based system were set to 7.
</nextsent>
<nextsent>the distortion limit (dl) for the phrase-based system was set to 6 unless otherwise mentioned.
</nextsent>
<nextsent>all other settings were left at their default values as described by chiang (2007) and koehn et al (2007).<papid> P07-2045 </papid></nextsent>
<nextsent>5.3 metric: reference reachability.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE124">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> related work and open questions.  </section>
<citcontext>
<prevsection>
<prevsent>this shows that the 1-best regions of both systems are nearly identical despite the differences discussed in 4.
</prevsent>
<prevsent>this means that difference sin observed system performance are probably attributable to the degree of model error and search error in each system.
</prevsent>
</prevsection>
<citsent citstr=" C08-1136 ">
zhang et al (2008) <papid> C08-1136 </papid>and wellington et al (2006)<papid> P06-1123 </papid>answer the question: what is the minimal grammar that can be induced to completely describe training set?</citsent>
<aftsection>
<nextsent>we look at the related question of what heuristic ally induced ruleset can translate in an unseen test set, considering both phrase- and grammar-based models.
</nextsent>
<nextsent>we also extend the workof zollmann et al (2008)<papid> C08-1144 </papid> on chinese-english, performing the analysis in both directions and providing detailed qualitative explanation.</nextsent>
<nextsent>our focus has been on the induction error of models, previously unstudied cause of transla 230 source: concurrence des services postaux reference: competition between postal services hierarchical: postal services deviation: ( [0-4: @s -  @x1 | @x1 ] ( [0-4: @x -  concurrence @x1 postaux | postal @x1 ] postal ( [1-3: @x -  des services | services ] services ) ) ) figure 5: derivation of hierarchical translation which cannot be generated by the phrase-based system, in the format of zollmann et al (2008)<papid> C08-1144 </papid>.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE125">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> related work and open questions.  </section>
<citcontext>
<prevsection>
<prevsent>this shows that the 1-best regions of both systems are nearly identical despite the differences discussed in 4.
</prevsent>
<prevsent>this means that difference sin observed system performance are probably attributable to the degree of model error and search error in each system.
</prevsent>
</prevsection>
<citsent citstr=" P06-1123 ">
zhang et al (2008) <papid> C08-1136 </papid>and wellington et al (2006)<papid> P06-1123 </papid>answer the question: what is the minimal grammar that can be induced to completely describe training set?</citsent>
<aftsection>
<nextsent>we look at the related question of what heuristic ally induced ruleset can translate in an unseen test set, considering both phrase- and grammar-based models.
</nextsent>
<nextsent>we also extend the workof zollmann et al (2008)<papid> C08-1144 </papid> on chinese-english, performing the analysis in both directions and providing detailed qualitative explanation.</nextsent>
<nextsent>our focus has been on the induction error of models, previously unstudied cause of transla 230 source: concurrence des services postaux reference: competition between postal services hierarchical: postal services deviation: ( [0-4: @s -  @x1 | @x1 ] ( [0-4: @x -  concurrence @x1 postaux | postal @x1 ] postal ( [1-3: @x -  des services | services ] services ) ) ) figure 5: derivation of hierarchical translation which cannot be generated by the phrase-based system, in the format of zollmann et al (2008)<papid> C08-1144 </papid>.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE128">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>sparse distributions are common in natural language processing, and machine translation is no exception.
</prevsent>
<prevsent>we showed that utilizing more of the entire distribution can dramatically improve the coverage of translation models, and possibly their accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
accounting for sparsity explicitly has achieved significant improvements in other areas such as in part of speech tagging (goldwater and griffiths, 2007).<papid> P07-1094 </papid></citsent>
<aftsection>
<nextsent>considering the entire tail is challenging, since the search space grows exponentially with the number of translation options.
</nextsent>
<nextsent>a first step might be to use features that facilitate more variety in the top 20 translation options.
</nextsent>
<nextsent>a more elaborate aim is to look into alternatives to maximum likelihood hood estimation such as in blunsom and osborne (2008).<papid> D08-1023 </papid></nextsent>
<nextsent>additionally, our expressiveness analysis shows clearly that the 1-best region of hierarchical andphrase-based models is nearly identical.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE129">
<title id=" W09-0437.xml">a systematic analysis of translation model search spaces </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>considering the entire tail is challenging, since the search space grows exponentially with the number of translation options.
</prevsent>
<prevsent>a first step might be to use features that facilitate more variety in the top 20 translation options.
</prevsent>
</prevsection>
<citsent citstr=" D08-1023 ">
a more elaborate aim is to look into alternatives to maximum likelihood hood estimation such as in blunsom and osborne (2008).<papid> D08-1023 </papid></citsent>
<aftsection>
<nextsent>additionally, our expressiveness analysis shows clearly that the 1-best region of hierarchical andphrase-based models is nearly identical.
</nextsent>
<nextsent>discounting cases in which systems handle unaligned words differently, we observe an overlap of between 96% and 99% across three language pairs.
</nextsent>
<nextsent>this implies that the main difference between the models is in their parameterization, rather than inthe structural differences in the types of translations they can produce.
</nextsent>
<nextsent>our results also suggest that the search spaces of both models are highlyoverlapping: the results for the 1-best regional low the conjecture that also other parts of the search space are behaving similarly since it appears rather unlikely that spaces are nearly disjoint with only the 1-best region being nearly identical.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE130">
<title id=" W09-1405.xml">biomedical event extraction without training data </title>
<section> trigger identification.  </section>
<citcontext>
<prevsection>
<prevsent>each of these stages are described in detail in subsequent sections, followed by experiments and discussion.
</prevsent>
<prevsent>we perform trigger identification using the assumption that events are triggered in text either by verbal or nominal prdicates (cohen et al, 2008).to build dictionary of verbs and their associated event classes we use the triggers annotated inthe training data.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
we lemmatize and stem the triggers with the morphology component of the rasptoolkit (briscoe et al, 2006)<papid> P06-4020 </papid>1 and the porter stem mer2 respectively.</citsent>
<aftsection>
<nextsent>we sort the trigger stem - event class pairs found according to their frequency in the training data and we keep only those pairs that appear at least 10 times.
</nextsent>
<nextsent>the trigger stems arethen mapped to verbs.
</nextsent>
<nextsent>this excludes some relatively common triggers, which will reduce recall, but, given that we rely exclusively on the parser for 1http://www.cogs.susx.ac.uk/lab/nlp/rasp/ 2http://www.tartarus.org/martin/porterstemmer 37 argument extraction, such triggers would be difficult to handle.
</nextsent>
<nextsent>for verbs with more than one event class we keep only the most frequent one.we consider the assumption that each verb denotes single event class to be reasonable one given the restricted task domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE131">
<title id=" W09-1405.xml">biomedical event extraction without training data </title>
<section> trigger identification.  </section>
<citcontext>
<prevsection>
<prevsent>for verbs with more than one event class we keep only the most frequent one.we consider the assumption that each verb denotes single event class to be reasonable one given the restricted task domain.
</prevsent>
<prevsent>it hinders us from dealing with triggers denoting multiple event classes but it simplifies the task so that we do not need annotated data.
</prevsent>
</prevsection>
<citsent citstr=" C08-1057 ">
while we use the training data triggers to obtain the list of verbs and their corresponding event types, we believe that such lists could be obtained by clustering (korhonen et al, 2008) <papid> C08-1057 </papid>with editing and labelling by domain experts.</citsent>
<aftsection>
<nextsent>this is the only use of the training data we make in our system.
</nextsent>
<nextsent>during testing, using the tokenized text provided, we attempt to match each token with one of the verbs associated with an event type.
</nextsent>
<nextsent>we perform this by relaxing the matching successively, using the token lemma, then stem, and finally allowing partial match in order to deal with particles (so that e.g. co-transfect matches transfect).
</nextsent>
<nextsent>this process returns single-token candidate triggers which, while they do not reproduce the trigger annotation, are likely to be adequate for event extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE132">
<title id=" W09-1405.xml">biomedical event extraction without training data </title>
<section> argument extraction.  </section>
<citcontext>
<prevsection>
<prevsent>while we expect that parser adapted to the biomedical domain may perform better, we want to preserve the domain-independence of the system and explore its potential.
</prevsent>
<prevsent>the only adjustment we make is to change the pos tags of tokens that are part of protein nameto proper names tags.
</prevsent>
</prevsection>
<citsent citstr=" W07-1022 ">
we consider such an adjustment domain-independent given that ner is available in many domains (lewin, 2007).<papid> W07-1022 </papid></citsent>
<aftsection>
<nextsent>following haghighi et al(2005), in order to ameliorate parsing errors, we use the top-10 parses and return aset of bilexical head-dependent grammatical relations (grs) weighted according to the proportion and probability of the top parses supporting that gr.
</nextsent>
<nextsent>the grs produced by the parser define directed graphs between tokens in the sentence, and partial event is formed when path that connects trigger with an appropriate argument is identified.
</nextsent>
<nextsent>gr paths that are likely to generate events are selected using the development data, which does not contradict the goals of our approach because we do not require annotated training data.
</nextsent>
<nextsent>development data is always needed in order to build and test system, and such supervision could be provided by human expert, albeit not as easily as for the list of trigger verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE133">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast, corpus-based methods can learn specialized terminology directly from domain-specific corpus, but accuracy can be problem because most corpora are relatively small.
</prevsent>
<prevsent>in this paper, we seek to exploit the best of both worlds by combining weakly supervised corpus based method for semantic lexicon induction with statistics obtained from the web.
</prevsent>
</prevsection>
<citsent citstr=" W02-1028 ">
first, we use bootstrapping algorithm, basilisk (thelen and riloff, 2002), <papid> W02-1028 </papid>to automatically induce semantic lexicon from domain-specific corpus.</citsent>
<aftsection>
<nextsent>this produces set of words that are hypothesized to be long to the targeted semantic category.
</nextsent>
<nextsent>second, we use the web as source of corroborating evidence to confirm, or dis confirm, whether each term truly belongs to the semantic category.
</nextsent>
<nextsent>for each candidate word, we search the web for pages that contain both the word and semantically related term.
</nextsent>
<nextsent>we expect that true semantic category members willco-occur with semantically similar words more of ten than non-members.this paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE134">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our research focuses on semantic lexicon induction, where the goal is to create list of words that belong to desired semantic class.
</prevsent>
<prevsent>a substantial amount of previous work has been done on weakly supervised and unsupervised creation of semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
weakly supervised corpus-basedmethods have utilized noun co-occurrence statistics (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>syntactic information (widdows and dorow, 2002; <papid> C02-1114 </papid>phillips and riloff, 2002; <papid> W02-1017 </papid>pantel and ravichandran, 2004; <papid> N04-1041 </papid>tanev and magnini, 2006),<papid> E06-1003 </papid>and lexico-syntactic contextual patterns (e.g., resides in  location ?</citsent>
<aftsection>
<nextsent>or moved to  location ?)
</nextsent>
<nextsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></nextsent>
<nextsent>due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE135">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our research focuses on semantic lexicon induction, where the goal is to create list of words that belong to desired semantic class.
</prevsent>
<prevsent>a substantial amount of previous work has been done on weakly supervised and unsupervised creation of semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
weakly supervised corpus-basedmethods have utilized noun co-occurrence statistics (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>syntactic information (widdows and dorow, 2002; <papid> C02-1114 </papid>phillips and riloff, 2002; <papid> W02-1017 </papid>pantel and ravichandran, 2004; <papid> N04-1041 </papid>tanev and magnini, 2006),<papid> E06-1003 </papid>and lexico-syntactic contextual patterns (e.g., resides in  location ?</citsent>
<aftsection>
<nextsent>or moved to  location ?)
</nextsent>
<nextsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></nextsent>
<nextsent>due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE136">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our research focuses on semantic lexicon induction, where the goal is to create list of words that belong to desired semantic class.
</prevsent>
<prevsent>a substantial amount of previous work has been done on weakly supervised and unsupervised creation of semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
weakly supervised corpus-basedmethods have utilized noun co-occurrence statistics (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>syntactic information (widdows and dorow, 2002; <papid> C02-1114 </papid>phillips and riloff, 2002; <papid> W02-1017 </papid>pantel and ravichandran, 2004; <papid> N04-1041 </papid>tanev and magnini, 2006),<papid> E06-1003 </papid>and lexico-syntactic contextual patterns (e.g., resides in  location ?</citsent>
<aftsection>
<nextsent>or moved to  location ?)
</nextsent>
<nextsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></nextsent>
<nextsent>due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE137">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our research focuses on semantic lexicon induction, where the goal is to create list of words that belong to desired semantic class.
</prevsent>
<prevsent>a substantial amount of previous work has been done on weakly supervised and unsupervised creation of semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" W02-1017 ">
weakly supervised corpus-basedmethods have utilized noun co-occurrence statistics (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>syntactic information (widdows and dorow, 2002; <papid> C02-1114 </papid>phillips and riloff, 2002; <papid> W02-1017 </papid>pantel and ravichandran, 2004; <papid> N04-1041 </papid>tanev and magnini, 2006),<papid> E06-1003 </papid>and lexico-syntactic contextual patterns (e.g., resides in  location ?</citsent>
<aftsection>
<nextsent>or moved to  location ?)
</nextsent>
<nextsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></nextsent>
<nextsent>due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE138">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our research focuses on semantic lexicon induction, where the goal is to create list of words that belong to desired semantic class.
</prevsent>
<prevsent>a substantial amount of previous work has been done on weakly supervised and unsupervised creation of semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" N04-1041 ">
weakly supervised corpus-basedmethods have utilized noun co-occurrence statistics (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>syntactic information (widdows and dorow, 2002; <papid> C02-1114 </papid>phillips and riloff, 2002; <papid> W02-1017 </papid>pantel and ravichandran, 2004; <papid> N04-1041 </papid>tanev and magnini, 2006),<papid> E06-1003 </papid>and lexico-syntactic contextual patterns (e.g., resides in  location ?</citsent>
<aftsection>
<nextsent>or moved to  location ?)
</nextsent>
<nextsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></nextsent>
<nextsent>due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE139">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our research focuses on semantic lexicon induction, where the goal is to create list of words that belong to desired semantic class.
</prevsent>
<prevsent>a substantial amount of previous work has been done on weakly supervised and unsupervised creation of semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" E06-1003 ">
weakly supervised corpus-basedmethods have utilized noun co-occurrence statistics (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>syntactic information (widdows and dorow, 2002; <papid> C02-1114 </papid>phillips and riloff, 2002; <papid> W02-1017 </papid>pantel and ravichandran, 2004; <papid> N04-1041 </papid>tanev and magnini, 2006),<papid> E06-1003 </papid>and lexico-syntactic contextual patterns (e.g., resides in  location ?</citsent>
<aftsection>
<nextsent>or moved to  location ?)
</nextsent>
<nextsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></nextsent>
<nextsent>due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE143">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>or moved to  location ?)
</prevsent>
<prevsent>(riloff and jones, 1999; thelen and riloff, 2002).<papid> W02-1028 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1111 ">
due to the need for pos tagging and/or parsing, these types of methods have been evaluated only on fixed corpora1, although (pantel et al, 2004) <papid> C04-1111 </papid>demonstrated how to scale up their algorithms for the web.</citsent>
<aftsection>
<nextsent>the goal of our work is to improve uponcorpus-based bootstrapping algorithms by using cooccurrence statistics obtained from the web to re rank and filter the hypothesized category members.
</nextsent>
<nextsent>techniques for semantic class learning have also been developed specifically for the web.
</nextsent>
<nextsent>several web-based semantic class learners build upon hearsts early work (hearst, 1992) <papid> C92-2082 </papid>with hyponym patterns.</nextsent>
<nextsent>hearst exploited patterns that explicitly identify hyponym relation between semantic class and word (e.g., such authors as  ?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE144">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of our work is to improve uponcorpus-based bootstrapping algorithms by using cooccurrence statistics obtained from the web to re rank and filter the hypothesized category members.
</prevsent>
<prevsent>techniques for semantic class learning have also been developed specifically for the web.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
several web-based semantic class learners build upon hearsts early work (hearst, 1992) <papid> C92-2082 </papid>with hyponym patterns.</citsent>
<aftsection>
<nextsent>hearst exploited patterns that explicitly identify hyponym relation between semantic class and word (e.g., such authors as  ?)
</nextsent>
<nextsent>to automatically acquire new hyponyms.
</nextsent>
<nextsent>(pasca, 2004)applied hyponym patterns to the web and learned semantic class instances and groups by acquiring contexts around the patterns.
</nextsent>
<nextsent>later, (pasca, 2007) created context vectors for group of seed instances by searching web query logs, and used them to learn similar instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE145">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>later, (pasca, 2007) created context vectors for group of seed instances by searching web query logs, and used them to learn similar instances.
</prevsent>
<prevsent>the knowitall system (etzioni et al, 2005) also uses hyponym patterns to extract class instances from the web and evaluates them further by computing mutual information scores based on web queries.
</prevsent>
</prevsection>
<citsent citstr=" P08-1119 ">
(kozareva et al, 2008) <papid> P08-1119 </papid>proposed the use of doubly-anchored hyponym pattern anda graph to represent the links between hyponym occurrences in these patterns.our work builds upon turneys work on semantic orientation (turney, 2002) <papid> P02-1053 </papid>and synonym learning(turney, 2001), in which he used pmi-ir algorithm to measure the similarity of words and phrases based on web queries.</citsent>
<aftsection>
<nextsent>we use similar pmi (point wise mutual information) metric for the purposes of semantic class verification.
</nextsent>
<nextsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</nextsent>
<nextsent>19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</nextsent>
<nextsent>another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE146">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>later, (pasca, 2007) created context vectors for group of seed instances by searching web query logs, and used them to learn similar instances.
</prevsent>
<prevsent>the knowitall system (etzioni et al, 2005) also uses hyponym patterns to extract class instances from the web and evaluates them further by computing mutual information scores based on web queries.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
(kozareva et al, 2008) <papid> P08-1119 </papid>proposed the use of doubly-anchored hyponym pattern anda graph to represent the links between hyponym occurrences in these patterns.our work builds upon turneys work on semantic orientation (turney, 2002) <papid> P02-1053 </papid>and synonym learning(turney, 2001), in which he used pmi-ir algorithm to measure the similarity of words and phrases based on web queries.</citsent>
<aftsection>
<nextsent>we use similar pmi (point wise mutual information) metric for the purposes of semantic class verification.
</nextsent>
<nextsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</nextsent>
<nextsent>19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</nextsent>
<nextsent>another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE148">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we use similar pmi (point wise mutual information) metric for the purposes of semantic class verification.
</prevsent>
<prevsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</prevsent>
</prevsection>
<citsent citstr=" C02-1144 ">
19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</citsent>
<aftsection>
<nextsent>another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></nextsent>
<nextsent>web-based corroboration our approach combines weakly supervised learning algorithm for corpus-based semantic lexicon induction with follow-on procedure that gathers corroborating statistical evidence from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE149">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we use similar pmi (point wise mutual information) metric for the purposes of semantic class verification.
</prevsent>
<prevsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</prevsent>
</prevsection>
<citsent citstr=" P06-1038 ">
19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</citsent>
<aftsection>
<nextsent>another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></nextsent>
<nextsent>web-based corroboration our approach combines weakly supervised learning algorithm for corpus-based semantic lexicon induction with follow-on procedure that gathers corroborating statistical evidence from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE150">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we use similar pmi (point wise mutual information) metric for the purposes of semantic class verification.
</prevsent>
<prevsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</prevsent>
</prevsection>
<citsent citstr=" P07-1030 ">
19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</citsent>
<aftsection>
<nextsent>another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></nextsent>
<nextsent>web-based corroboration our approach combines weakly supervised learning algorithm for corpus-based semantic lexicon induction with follow-on procedure that gathers corroborating statistical evidence from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE151">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</prevsent>
<prevsent>19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></citsent>
<aftsection>
<nextsent>web-based corroboration our approach combines weakly supervised learning algorithm for corpus-based semantic lexicon induction with follow-on procedure that gathers corroborating statistical evidence from the web.
</nextsent>
<nextsent>in this section, we describe both of these components.first, we give brief overview of the basilisk bootstrapping algorithm that we use for corpus-based semantic lexicon induction.
</nextsent>
<nextsent>second, we present ournew strategies for acquiring and utilizing corroborating statistical evidence from the web.
</nextsent>
<nextsent>3.1 corpus-based semantic lexicon induction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE152">
<title id=" W09-1703.xml">corpus based semantic lexicon induction with web based corroboration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there has also been work on fully unsupervised 1meta-bootstrapping (riloff and jones, 1999) was evaluated on web pages, but used pre compiled corpus of downloaded web pages.
</prevsent>
<prevsent>19semantic clustering (e.g., (lin, 1998; lin and pan tel, 2002; <papid> C02-1144 </papid>davidov and rappoport, 2006; <papid> P06-1038 </papid>davidov et al., 2007)), <papid> P07-1030 </papid>however clustering methods may or maynot produce the types and granularities of semantic classes desired by user.</prevsent>
</prevsection>
<citsent citstr=" W02-1111 ">
another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (caraballo, 1999; <papid> P99-1016 </papid>cimiano and volker, 2005; mann, 2002)).<papid> W02-1111 </papid></citsent>
<aftsection>
<nextsent>web-based corroboration our approach combines weakly supervised learning algorithm for corpus-based semantic lexicon induction with follow-on procedure that gathers corroborating statistical evidence from the web.
</nextsent>
<nextsent>in this section, we describe both of these components.first, we give brief overview of the basilisk bootstrapping algorithm that we use for corpus-based semantic lexicon induction.
</nextsent>
<nextsent>second, we present ournew strategies for acquiring and utilizing corroborating statistical evidence from the web.
</nextsent>
<nextsent>3.1 corpus-based semantic lexicon induction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE171">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so automated metrics are also used in addition toor instead ofhuman studies.
</prevsent>
<prevsent>when automatically evaluating generated output,the goal is to find metrics that can easily be computed and that can also be shown to correlate with human judgements of quality.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
such metrics have been introduced in other fields, including paradise (walker et al, 1997) <papid> P97-1035 </papid>for spoken dialogue systems, bleu (papineni et al, 2002) <papid> P02-1040 </papid>for machine translation,1 and rouge (lin, 2004) <papid> W04-1013 </papid>for sum marisation.</citsent>
<aftsection>
<nextsent>many automated generation evaluations measure the similarity between the generated output and corpus of gold-standard?
</nextsent>
<nextsent>target outputs, often using measures such as precision and recall.
</nextsent>
<nextsent>such measures of corpus similarity are straightforward to compute and easy to interpret; however, they are not always appropriate for generation systems.
</nextsent>
<nextsent>one ofthe main advantages of choosing dynamic generation over canned output is its flexibility and its ability to produce range of different outputs; as pointed out by paris et al (2007), ?[e]valuation studies that ignore the potential of the system to generate range of appropriate outputs will be necessarily limited.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE172">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so automated metrics are also used in addition toor instead ofhuman studies.
</prevsent>
<prevsent>when automatically evaluating generated output,the goal is to find metrics that can easily be computed and that can also be shown to correlate with human judgements of quality.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
such metrics have been introduced in other fields, including paradise (walker et al, 1997) <papid> P97-1035 </papid>for spoken dialogue systems, bleu (papineni et al, 2002) <papid> P02-1040 </papid>for machine translation,1 and rouge (lin, 2004) <papid> W04-1013 </papid>for sum marisation.</citsent>
<aftsection>
<nextsent>many automated generation evaluations measure the similarity between the generated output and corpus of gold-standard?
</nextsent>
<nextsent>target outputs, often using measures such as precision and recall.
</nextsent>
<nextsent>such measures of corpus similarity are straightforward to compute and easy to interpret; however, they are not always appropriate for generation systems.
</nextsent>
<nextsent>one ofthe main advantages of choosing dynamic generation over canned output is its flexibility and its ability to produce range of different outputs; as pointed out by paris et al (2007), ?[e]valuation studies that ignore the potential of the system to generate range of appropriate outputs will be necessarily limited.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE173">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so automated metrics are also used in addition toor instead ofhuman studies.
</prevsent>
<prevsent>when automatically evaluating generated output,the goal is to find metrics that can easily be computed and that can also be shown to correlate with human judgements of quality.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
such metrics have been introduced in other fields, including paradise (walker et al, 1997) <papid> P97-1035 </papid>for spoken dialogue systems, bleu (papineni et al, 2002) <papid> P02-1040 </papid>for machine translation,1 and rouge (lin, 2004) <papid> W04-1013 </papid>for sum marisation.</citsent>
<aftsection>
<nextsent>many automated generation evaluations measure the similarity between the generated output and corpus of gold-standard?
</nextsent>
<nextsent>target outputs, often using measures such as precision and recall.
</nextsent>
<nextsent>such measures of corpus similarity are straightforward to compute and easy to interpret; however, they are not always appropriate for generation systems.
</nextsent>
<nextsent>one ofthe main advantages of choosing dynamic generation over canned output is its flexibility and its ability to produce range of different outputs; as pointed out by paris et al (2007), ?[e]valuation studies that ignore the potential of the system to generate range of appropriate outputs will be necessarily limited.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE174">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such measures of corpus similarity are straightforward to compute and easy to interpret; however, they are not always appropriate for generation systems.
</prevsent>
<prevsent>one ofthe main advantages of choosing dynamic generation over canned output is its flexibility and its ability to produce range of different outputs; as pointed out by paris et al (2007), ?[e]valuation studies that ignore the potential of the system to generate range of appropriate outputs will be necessarily limited.?
</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
indeed, several recent studies (stent et al, 2005; belz and reiter, 2006; <papid> E06-1040 </papid>foster and white, 2007) have shown that strict corpus-similarity measures tend to favour repetitive generation strategies that do not diverge much, on average, from the corpus data, while human judges often prefer output with more variety.</citsent>
<aftsection>
<nextsent>1although callison-burch et al (2006) have recently called into question the utility of bleu.
</nextsent>
<nextsent>95 automated metrics that take into account other properties than strict corpus similarity have also been used to evaluate the output of generation systems.
</nextsent>
<nextsent>walker (2005) describes several evaluations that used corpus data in different way: each of the corpus examples was associated with some reward function (e.g., subjective user evaluation or task success), and machine-learning techniques such as reinforcement learning or boosting were then used to train the output planner.
</nextsent>
<nextsent>foster and white (2007) found that automated metrics based on factors other than corpus similarity (e.g., the amount of variation in the output) agreed better with user preferences than did the corpus-similarity scores.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE175">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>walker (2005) describes several evaluations that used corpus data in different way: each of the corpus examples was associated with some reward function (e.g., subjective user evaluation or task success), and machine-learning techniques such as reinforcement learning or boosting were then used to train the output planner.
</prevsent>
<prevsent>foster and white (2007) found that automated metrics based on factors other than corpus similarity (e.g., the amount of variation in the output) agreed better with user preferences than did the corpus-similarity scores.
</prevsent>
</prevsection>
<citsent citstr=" P08-2050 ">
belz and gatt(2008) <papid> P08-2050 </papid>compare the predictions of range of measures, both intrinsic and extrinsic, that were usedto evaluate the systems in shared-task referring expression generation challenge.</citsent>
<aftsection>
<nextsent>one main finding from this comparison was that there was no significant correlation between the intrinsic and extrinsic (task success) measures for this task.
</nextsent>
<nextsent>all of the above studies considered only systems that generate text, but many of the same factors also apply to the generation of non-verbal behaviours for an embodied conversational agent (eca) (cassellet al, 2000).
</nextsent>
<nextsent>the behaviour of such an agent is normally based on recorded human behaviour, which can provide targets similar to those used in corpus based evaluations of text-generation systems.
</nextsent>
<nextsent>how ever, just as in text generation, multimodal system that scores well on corpus similarity tends to produce highly repetitive non-verbal behaviours, so it is equally important to gather human judgements to accompany any automated evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE176">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> corpus-based generation of facial.  </section>
<citcontext>
<prevsection>
<prevsent>the first evaluation study uses human judges to compare the output of the selection methods against one another, while the second study uses range of automated metrics: several corpus reproduction measures, along with metrics based on intrinsic properties of the outputs.
</prevsent>
<prevsent>the results of the two studies are compared using multiple regression, and the implications are discussed.
</prevsent>
</prevsection>
<citsent citstr=" P05-3012 ">
displays for an ecathe experiments in this paper make use of the out put components of the comic multimodal dialogue system (foster et al, 2005), <papid> P05-3012 </papid>which adds multimodal talking-head interface to cad-style system for redesigning bathrooms.</citsent>
<aftsection>
<nextsent>the studies focus on the task of selecting appropriate eca head and eyebrow motions to accompany the turns in which the system describes and compares the options for tiling the room, as those are the parts of the output with the most interesting and varied content.
</nextsent>
<nextsent>the implementations were based on corpus of conversational facial displays derived from the behaviour of single speaker reading approximately 450 scripted sentences generated by the comicoutput-generation system.
</nextsent>
<nextsent>the openccg syntactic derivation trees (white, 2006) for the sentences form the basis of the corpus.
</nextsent>
<nextsent>the leaf nodes in these trees correspond to the individual words, while the internal nodes correspond to multi-word constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE177">
<title id=" W08-1113.xml">automated metrics that agree with human judgements on generated output for an embodied conversational agent </title>
<section> corpus-based generation of facial.  </section>
<citcontext>
<prevsection>
<prevsent>every node in each tree was initially labelled with all of the applicable contextual features produced by the output planner: the user preference evaluation of the tile design being described (positive/negative/neutral), the information status (given/new) of each piece of information, andthe predicted speech-synthesiser prosody.
</prevsent>
<prevsent>the annotators then linked each facial display produced by the speaker to the node or span of nodes in the derivation tree covering the words temporally associated with the display.
</prevsent>
</prevsection>
<citsent citstr=" W07-1504 ">
full details of this corpus are given in foster (2007<papid> W07-1504 </papid>a).</citsent>
<aftsection>
<nextsent>the most common display used by the speaker was downward nod, while the user-preference evaluation had the single largest differential effect on the displays used.
</nextsent>
<nextsent>when the speaker described features of the design that the user was expected to like, he was relatively more likely to turn to the right and to raise his eyebrows (figure 1(a)); on features that the user was expected to dislike, on the other hand, there was higher probability of left leaning, lowered eyebrows, and narrowed eyes (figure 1(b)).
</nextsent>
<nextsent>in previous study, users were generally able to recognise these positive?
</nextsent>
<nextsent>and negative?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE180">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>sense disambiguation of any noun, incorporating both similarity and relatedness measures.
</prevsent>
</prevsection>
<citsent citstr=" P06-1013 ">
as explained in (brody et al, 2006), <papid> P06-1013 </papid>there are generally two approaches to unsupervised wsd.the first is referred to as token based, which compares the relatedness of target word to other words in its context.</citsent>
<aftsection>
<nextsent>the second approach is type based, which uses or identifies the most commonsense of word over discourse or corpus, and annotates all instances of word with the most common sense.
</nextsent>
<nextsent>although the type based approach is clearly bound to fail occasionally, it is commonly found to produce the strongest results, rivaling supervised systems (mccarthy et al, 2004).<papid> P04-1036 </papid></nextsent>
<nextsent>we identify third approach through the use of selectors, first introduced by (lin, 1997), <papid> P97-1009 </papid>which help to disambiguate word by comparing it to other words that may replace it within the same local context.we approach the problem of word sense disambiguation through relatively straightforward method that incorporates ideas from the token, type, and selector approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE181">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as explained in (brody et al, 2006), <papid> P06-1013 </papid>there are generally two approaches to unsupervised wsd.the first is referred to as token based, which compares the relatedness of target word to other words in its context.</prevsent>
<prevsent>the second approach is type based, which uses or identifies the most commonsense of word over discourse or corpus, and annotates all instances of word with the most common sense.</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
although the type based approach is clearly bound to fail occasionally, it is commonly found to produce the strongest results, rivaling supervised systems (mccarthy et al, 2004).<papid> P04-1036 </papid></citsent>
<aftsection>
<nextsent>we identify third approach through the use of selectors, first introduced by (lin, 1997), <papid> P97-1009 </papid>which help to disambiguate word by comparing it to other words that may replace it within the same local context.we approach the problem of word sense disambiguation through relatively straightforward method that incorporates ideas from the token, type, and selector approaches.</nextsent>
<nextsent>in particular, we expand the use of selectors in several ways.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE182">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second approach is type based, which uses or identifies the most commonsense of word over discourse or corpus, and annotates all instances of word with the most common sense.
</prevsent>
<prevsent>although the type based approach is clearly bound to fail occasionally, it is commonly found to produce the strongest results, rivaling supervised systems (mccarthy et al, 2004).<papid> P04-1036 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
we identify third approach through the use of selectors, first introduced by (lin, 1997), <papid> P97-1009 </papid>which help to disambiguate word by comparing it to other words that may replace it within the same local context.we approach the problem of word sense disambiguation through relatively straightforward method that incorporates ideas from the token, type, and selector approaches.</citsent>
<aftsection>
<nextsent>in particular, we expand the use of selectors in several ways.
</nextsent>
<nextsent>first, we revise the method for acquiring selectors to be applicable to the web, corpus that is, practically speaking, impossible to parse in whole.
</nextsent>
<nextsent>second, we describe path-based similarity measure that is more suited for portion of our method than the relatedness measures used by token based systems.
</nextsent>
<nextsent>finally, we expand the use of selectors to help with disambiguating nouns other than the one replaced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE184">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>monose mous relatives are words which are similar to 105 sense of the target word, but which only have one sense.
</prevsent>
<prevsent>by searching text for these words, one can build training data for each sense of target word.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
this idea was proposed by (leacock et al, 1998).<papid> J98-1006 </papid>more recently, the idea has been used to automatically create sense tagged corpora (mihalcea,2002; agirre and martinez, 2004) . <papid> W04-3204 </papid>these methods queried large corpora with relatives rather than with the context.with some resemblances to our approach, (mar tinez et al, 2006) present the relatives in context method.</citsent>
<aftsection>
<nextsent>a key similarity of this method with oursis the use of context in the web queries.
</nextsent>
<nextsent>they produce queries with relatives in place of the target word in context with window size of up to 6.
</nextsent>
<nextsent>similarly, (yuret, 2007) first chooses substitute sand determines sense by looking at the probability of substitute taking the place of the target word within the web1t corpus.
</nextsent>
<nextsent>the number of hits each query has on the web is then used to pick the correct sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE185">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>monose mous relatives are words which are similar to 105 sense of the target word, but which only have one sense.
</prevsent>
<prevsent>by searching text for these words, one can build training data for each sense of target word.
</prevsent>
</prevsection>
<citsent citstr=" W04-3204 ">
this idea was proposed by (leacock et al, 1998).<papid> J98-1006 </papid>more recently, the idea has been used to automatically create sense tagged corpora (mihalcea,2002; agirre and martinez, 2004) . <papid> W04-3204 </papid>these methods queried large corpora with relatives rather than with the context.with some resemblances to our approach, (mar tinez et al, 2006) present the relatives in context method.</citsent>
<aftsection>
<nextsent>a key similarity of this method with oursis the use of context in the web queries.
</nextsent>
<nextsent>they produce queries with relatives in place of the target word in context with window size of up to 6.
</nextsent>
<nextsent>similarly, (yuret, 2007) first chooses substitute sand determines sense by looking at the probability of substitute taking the place of the target word within the web1t corpus.
</nextsent>
<nextsent>the number of hits each query has on the web is then used to pick the correct sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE189">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 similarity and relatedness measures.
</prevsent>
<prevsent>semantic similarity and relatedness measures have an extensive history.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
the measures reported in this work were included based on appropriateness withour approach and because of past success according to various evaluations (patwardhan et al, 2003; budanitsky and hirst, 2006).<papid> J06-1003 </papid></citsent>
<aftsection>
<nextsent>many similarity measures have been created which only use paths in the wordnet ontology.
</nextsent>
<nextsent>one approach is to simply compute the length of the shortest path between two concepts over the hypernym/hyponym relationship (rada et al, 1989).
</nextsent>
<nextsent>other methods attempt to compensate for the uniformity problem, the idea that some areas of the ontology are more dense than others, and thus all edges are not equal.
</nextsent>
<nextsent>(wu and palmer, 1994) <papid> P94-1019 </papid>uses the path length from the root to the lowest common subsumer(lcs) of two concepts scaled by the distance from the lcs to each concept.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE190">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>one approach is to simply compute the length of the shortest path between two concepts over the hypernym/hyponym relationship (rada et al, 1989).
</prevsent>
<prevsent>other methods attempt to compensate for the uniformity problem, the idea that some areas of the ontology are more dense than others, and thus all edges are not equal.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
(wu and palmer, 1994) <papid> P94-1019 </papid>uses the path length from the root to the lowest common subsumer(lcs) of two concepts scaled by the distance from the lcs to each concept.</citsent>
<aftsection>
<nextsent>another method, by (leacock et al, 1998), <papid> J98-1006 </papid>normalizes path distance based on the depth of hierar chy.</nextsent>
<nextsent>our method attempts to produce normalized depth based on the average depth of all concepts which are leaf nodes below the lowest common subsumer in tree.we employ several other measures in our sys tem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE201">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this task avoids the issues of fine granular sense inventory, which provides senses 109 type insts avgsels target 1108 68.5 noun context 1108 68.5 verb context 591 70.1 adj context 362 37.3 pro context 372 31.9 table 1: total word instances for which selectors were acquired (insts), and average number of selectors acquired for use in each instance (avgsels).
</prevsent>
<prevsent>that are difficult even for humans to distinguish.additionally, considering how recent the event occurred, there is lot of up-to-date data about the performance of other disambiguation systems to compare with.
</prevsent>
</prevsection>
<citsent citstr=" W07-2006 ">
(navigli et al, 2007)<papid> W07-2006 </papid>out of 2269 noun, verb, adjective, or adverb instances we are concerned with disambiguating the 1108 noun instances from the 245 sentences in the corpus . these noun instances represent 593 different words.</citsent>
<aftsection>
<nextsent>since we did not use the coarse-grained senses within our algorithm, the predicted senses were correct if they mapped to the correct coarse grained sense.
</nextsent>
<nextsent>the average instance had 2.5 possible coarse-grained senses.
</nextsent>
<nextsent>the average number of selectors acquired for each word is given in table 1.
</nextsent>
<nextsent>the bottom of table 2 shows the random base-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE206">
<title id=" W08-2114.xml">acquiring knowledge from the web to be used as selectors for noun sense disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 comparison with other systems.
</prevsent>
<prevsent>table 5 shows the results of our method (sel) compared with few systems participating in the semeval coarse-grained all-words task.
</prevsent>
</prevsection>
<citsent citstr=" W07-2097 ">
these results include the median of all participating systems, the top system not using training data (upv wsd) (buscaldi and rosso, 2007), <papid> W07-2097 </papid>and the top system using training data (nus-pt) (chan et al., 2007).</citsent>
<aftsection>
<nextsent>the best performance reported on the sel med upv-wsd nus-pt ssi 80.2 71.1 79.33 82.31 84.12 table 5: comparison of noun f1 values with various participants in the semeval2007 coarse grained all-words task.
</nextsent>
<nextsent>nouns for the semeval coarse-grained task, was actually from system by the authors of the task (ssi) (navigli and velardi, 2005).
</nextsent>
<nextsent>all systems performing better than the mfs used the heuristic as backoff strategy when unable to output asense (navigli et al, 2007)<papid> W07-2006 </papid>.</nextsent>
<nextsent>also, the systems performing better than ours (including ssi) used more sources of sense annotated data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE208">
<title id=" W09-0414.xml">the talpupc phrase based translation system for eaclwmt 2009 </title>
<section> talp-upc phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>the system developed for this years shared task is based on state-of-the-art smt system implemented within the open-source moses toolkit (koehn et al, 2007).
</prevsent>
<prevsent>a phrase-based translation is considered as three step algorithm: (1) the source sequence of words is segmented in phrases, (2) each phrase is translated into target language using translation table, (3) the target phrases are reordered to be inherent in the target language.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
a bilingual phrase (which in the context of smt do not necessarily coincide with their linguistic analogies) is any pair of source words and target words that satisfies two basic constraints: (1) words are consecutive along both sides of the bilingual phrase and (2) no word on either side of the phrase is aligned to word outside the phrase.given sentence pair and corresponding wordto-word alignment, phrases are extracted following the criterion in (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>the probability of the phrases is estimated by relative frequencies of their appearance in the training corpus.
</nextsent>
<nextsent>85 classically, phrase-based translation system implements log-linear model in which foreign language sentence fj1 = f1, f2, ..., fj is translated into another language ei1 = e1, e2, ..., ei by searching for the translation hypothesis ei1 maximizing log-linear combination of several feature models (brown et al, 1990): <papid> J90-2002 </papid>ei1 = argmaxei1 { m?</nextsent>
<nextsent>m=1 mhm(ei1, fj1 ) } where the feature functions hm refer to the system models and the set of refers to the weights corresponding to these models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE209">
<title id=" W09-0414.xml">the talpupc phrase based translation system for eaclwmt 2009 </title>
<section> talp-upc phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>a bilingual phrase (which in the context of smt do not necessarily coincide with their linguistic analogies) is any pair of source words and target words that satisfies two basic constraints: (1) words are consecutive along both sides of the bilingual phrase and (2) no word on either side of the phrase is aligned to word outside the phrase.given sentence pair and corresponding wordto-word alignment, phrases are extracted following the criterion in (och and ney, 2004).<papid> J04-4002 </papid></prevsent>
<prevsent>the probability of the phrases is estimated by relative frequencies of their appearance in the training cor pus.</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
85 classically, phrase-based translation system implements log-linear model in which foreign language sentence fj1 = f1, f2, ..., fj is translated into another language ei1 = e1, e2, ..., ei by searching for the translation hypothesis ei1 maximizing log-linear combination of several feature models (brown et al, 1990): <papid> J90-2002 </papid>ei1 = argmaxei1 { m?</citsent>
<aftsection>
<nextsent>m=1 mhm(ei1, fj1 ) } where the feature functions hm refer to the system models and the set of refers to the weights corresponding to these models.
</nextsent>
<nextsent>2.1 translation models interpolation.
</nextsent>
<nextsent>we implemented tm interpolation strategy following the ideas proposed in (schwenk and estve, 2008), where the authors present promising technique of target lms linear interpolation; in (koehn and schroeder, 2007) <papid> W07-0733 </papid>where log-linearcombination of tms is performed; and specifically in (foster and kuhn, 2007) where the authors present various ways of tm combination and analyze in detail the tm domain adaptation.</nextsent>
<nextsent>in the framework of the evaluation campaign,there were two spanish-to-english parallel training corpora available: europarl v.4 corpus (about 50m tokens) and news commentary (nc) corpus (about 2m tokens).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE210">
<title id=" W09-0414.xml">the talpupc phrase based translation system for eaclwmt 2009 </title>
<section> talp-upc phrase-based smt.  </section>
<citcontext>
<prevsection>
<prevsent>m=1 mhm(ei1, fj1 ) } where the feature functions hm refer to the system models and the set of refers to the weights corresponding to these models.
</prevsent>
<prevsent>2.1 translation models interpolation.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
we implemented tm interpolation strategy following the ideas proposed in (schwenk and estve, 2008), where the authors present promising technique of target lms linear interpolation; in (koehn and schroeder, 2007) <papid> W07-0733 </papid>where log-linearcombination of tms is performed; and specifically in (foster and kuhn, 2007) where the authors present various ways of tm combination and analyze in detail the tm domain adaptation.</citsent>
<aftsection>
<nextsent>in the framework of the evaluation campaign,there were two spanish-to-english parallel training corpora available: europarl v.4 corpus (about 50m tokens) and news commentary (nc) corpus (about 2m tokens).
</nextsent>
<nextsent>the test dataset provided bythe organizers this year was from the news domain, so we considered the europarl training corpus as  out-of-domain  data and the news commentary as  in-domain  training material.
</nextsent>
<nextsent>unfortunately, the in-domain corpus is much smaller in size, however the europarl corpus can be also usedto increase the final translation and reordering tables inspite of its different nature.a straightforward approach to the tm interpolation would be an iterative tm reconstruction adjusting scale coefficients on each step of the loop with use of the highest bleu score as maximization criterion.
</nextsent>
<nextsent>however, we did not expect significant gain from this time-consumption strategy and we decided to follow simpler approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE211">
<title id=" W09-0414.xml">the talpupc phrase based translation system for eaclwmt 2009 </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>the system combination is performed on the 200-best lists which are generated by the three systems: (1) moses-based system without pre-translation monotonization (baseline), (2) moses-based smt enhanced with smr monotonization and (3)moses-based smt augmented with sbr mono tonization.
</prevsent>
<prevsent>the results presented in table 4 show that the combined output significantly outperforms the baseline system configuration.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
we followed the evaluation baseline instructions 1 to train the moses-based translation system.in some experiments we used mbr decoding (kumar and byrne, 2004) <papid> N04-1022 </papid>with the smoothed bleu score as similarity criteria, that allowed gaining 0.2 bleu points comparing to the standard procedure of out putting the translation with the highest probability (hp).</citsent>
<aftsection>
<nextsent>we applied the moses implementation of this algorithm to the list 1http://www.statmt.org/wmt09/baseline.htmlof 200 best translations generated by the talp upc system.
</nextsent>
<nextsent>the results obtained over the official 2009 test dataset can be found in table 2..
</nextsent>
<nextsent>task hp mbr esen 24.48 24.62 enes 23.46 23.64 table 2: mbr versus mert decoding.the  recase  script provided within the baseline was supplemented with and additional module, which restore the original case for unknown words (many of them are proper names and loosing of case information leads to significant performance degradation).
</nextsent>
<nextsent>3.1 language models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE212">
<title id=" W08-1303.xml">toward an underspecifiable corpus annotation scheme </title>
<section> toward unified scheme.  </section>
<citcontext>
<prevsection>
<prevsent>if labels are properly decomposed into set of feature values, and hierarchy of values is provided for each feature, the annotation labels can be more flexible and it is easier for an annotator to choose label that can encode the desired information.
</prevsent>
<prevsent>the distinction of syntax/semantics (or there may be more levels) can be incorporated into one of the features.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
other possible features include the grammatical categories of head and dependent, argument/modifier distinction, and role of arguments or modifiers like the one annotated in propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>decomposing labels into features have another use.
</nextsent>
<nextsent>it would make the mapping between one scheme and another more transparent.
</nextsent>
<nextsent>as the dependency structure of sentence is encoded into list of local information in de 22pendency schemes, it can be suggested that taking the union of the annotation of different schemes can achieve the encoding of the union of information that the individual schemes can encode, except for conflicting representations such as the head of coordinated structures, and the head of modifiers in hpsg.
</nextsent>
<nextsent>if the current labels are decomposed into features, it would enable one to take non-redundant union of information, and mapping from the union to particular scheme would be more systematic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE213">
<title id=" W09-0603.xml">system building cost vs output quality in datatotext generation </title>
<section> four ways to build an nlg systems.  </section>
<citcontext>
<prevsection>
<prevsent>the meaning representation (mr) into its constituent structure, and, in the opposite direction, (ii) assembling strings of words corresponding to constituent parts of the input mr into sentence or text that realises the entire mr. we used the wasp1 method (wong and mooney, 2006; wong and mooney, 2007) which 18 provides way in which probabilistic scfg can be constructed for the most part automatically.the training process requires two resources as in put: cfg of mrs and set of sentences paired with their mrs. as output, it produces probabilistic scfg.
</prevsent>
<prevsent>the training process works in two phases, producing (non-probabilistic) scfg in the lexical acquisition phase?, and associating the rules with probabilities in the parameter estimation phase?.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the lexical acquisition phase uses the giza++ word-alignment tool, an implementation (och and ney, 2003) of ibm model 5 (brown et al, 1993) <papid> J93-2003 </papid>to construct an alignment of mrs with nl strings.</citsent>
<aftsection>
<nextsent>an scfg is then constructed by using the mr cfg as skeleton and inferring the nl grammar from the alignment.
</nextsent>
<nextsent>for the parameter estimation phase, wasp1 uses log-linear model from koehn et al (2003)which defines conditional probability distribution over derivations given an input mr as pr ?
</nextsent>
<nextsent>(d|f) ? pr(e(d))1 ? dd w?(r(d)) where w?(r(d)) is the weight an individual rule used in derivation, defined as w?(a ? e, f?)
</nextsent>
<nextsent>= (f |e)2p (e|f)3pw(f |e)4pw(e|f)5exp(?|?|)6where (?|?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE214">
<title id=" W09-0603.xml">system building cost vs output quality in datatotext generation </title>
<section> evaluation methods.  </section>
<citcontext>
<prevsection>
<prevsent>we did not use factored translation model (the words used in weather forecasts did not vary sufficiently), or tuning.
</prevsent>
<prevsent>5.1 automatic evaluation methods.
</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
the two automatic metrics used in the evaluations, nist2 and bleu3, have been shown to correlate well with expert judgments (pearsons = 0.82 and 0.79 respectively) in the sumtime domain (belz and reiter, 2006).<papid> E06-1040 </papid></citsent>
<aftsection>
<nextsent>2http://cio.nist.gov/esd/emaildir/ lists/mt_list/bin00000.bin 3ftp://jaguar.ncsl.nist.gov/mt/ resources/mteval-v11b.pl 20 bleu-x is an n-gram based string comparison measure, originally proposed by papineni et al (2001) for evaluation of mt systems.
</nextsent>
<nextsent>it computes the proportion of word n-grams of length andless that system output shares with several reference outputs.
</nextsent>
<nextsent>setting = 4 (i.e. considering all ngrams of length ? 4) is standard.
</nextsent>
<nextsent>nist (dodding ton, 2002) is version of bleu, but where bleu gives equal weight to all n-grams, nist gives more importance to less frequent (hence more informative) n-grams, and the range of nist scores depends on the size of the test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE218">
<title id=" W08-1138.xml">graph the costs of redundancy in referring expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for realisation, it turns out that in some cases higher attribute selection accuracy leads to larger differences between system-generated and human descriptions.
</prevsent>
<prevsent>referring expression generation (reg) is keytask in nlg, and the topic of the reg 2008 chal lenge.1 in this context, referring expressions are understood as distinguishing descriptions: descriptions that uniquely characterize target object in avisual scene (e.g., the red sofa?), and do not apply to any of the other objects in the scene (the distractors).
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
generating such descriptions is usually assumed to be two-step procedure: first, it has to be decided which attributes of the target suffice to characterize it uniquely, and then the selected set of attributes should be converted into natural language.for the first step, attribute selection, we use version of the graph-based reg algorithm of krahmer et al  (2003).<papid> J03-1003 </papid></citsent>
<aftsection>
<nextsent>in this approach, visual scene is represented as directed labelled graph, where vertices represent the objects in the scene and edges their attributes.
</nextsent>
<nextsent>a key ingredient of the approach is that 1see http://www.itri.brighton.ac.uk/research/reg08/.
</nextsent>
<nextsent>costs can be assigned to attributes; the generation of referring expressions can then be defined as graph search problem, which outputs the cheapest distinguishing graph (if one exists) given particular cost function.
</nextsent>
<nextsent>for the second step, realisation, we use simple template-based realiser written by irene langkilde-geary from brighton university that was made available to all reg 2008 participants.a version of the graph-based algorithm was submitted for the asgre 2007 challenge (theune etal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE220">
<title id=" W08-2006.xml">affinity measures based on the graph laplacian </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>sim (i, j) is function of the commute time between vertex and vertex j.
</prevsent>
<prevsent>we evaluate each of the similarity measure we consider by using linguistically motivated task of finding lexical similarity.
</prevsent>
</prevsection>
<citsent citstr=" P05-3019 ">
deriving lexical relatedness between terms has been topic of interest with applications in word sense disambiguation (patwardhan et al, 2005), <papid> P05-3019 </papid>paraphrasing (kauchak and barzilay, 2006), <papid> N06-1058 </papid>question answering (prager et al, 2001), and machine translation (blatz et al, 2004) <papid> C04-1046 </papid>to name few.</citsent>
<aftsection>
<nextsent>lexical relatedness between terms could be derived either from thesaurus like wordnet or fromraw monolingual corpora via distributional similarity (pereira et al, 1993).<papid> P93-1024 </papid></nextsent>
<nextsent>wordnet is an interesting graph-structured thesaurus where the vertices are the words and the edges represent relations between the words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE221">
<title id=" W08-2006.xml">affinity measures based on the graph laplacian </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>sim (i, j) is function of the commute time between vertex and vertex j.
</prevsent>
<prevsent>we evaluate each of the similarity measure we consider by using linguistically motivated task of finding lexical similarity.
</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
deriving lexical relatedness between terms has been topic of interest with applications in word sense disambiguation (patwardhan et al, 2005), <papid> P05-3019 </papid>paraphrasing (kauchak and barzilay, 2006), <papid> N06-1058 </papid>question answering (prager et al, 2001), and machine translation (blatz et al, 2004) <papid> C04-1046 </papid>to name few.</citsent>
<aftsection>
<nextsent>lexical relatedness between terms could be derived either from thesaurus like wordnet or fromraw monolingual corpora via distributional similarity (pereira et al, 1993).<papid> P93-1024 </papid></nextsent>
<nextsent>wordnet is an interesting graph-structured thesaurus where the vertices are the words and the edges represent relations between the words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE222">
<title id=" W08-2006.xml">affinity measures based on the graph laplacian </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>sim (i, j) is function of the commute time between vertex and vertex j.
</prevsent>
<prevsent>we evaluate each of the similarity measure we consider by using linguistically motivated task of finding lexical similarity.
</prevsent>
</prevsection>
<citsent citstr=" C04-1046 ">
deriving lexical relatedness between terms has been topic of interest with applications in word sense disambiguation (patwardhan et al, 2005), <papid> P05-3019 </papid>paraphrasing (kauchak and barzilay, 2006), <papid> N06-1058 </papid>question answering (prager et al, 2001), and machine translation (blatz et al, 2004) <papid> C04-1046 </papid>to name few.</citsent>
<aftsection>
<nextsent>lexical relatedness between terms could be derived either from thesaurus like wordnet or fromraw monolingual corpora via distributional similarity (pereira et al, 1993).<papid> P93-1024 </papid></nextsent>
<nextsent>wordnet is an interesting graph-structured thesaurus where the vertices are the words and the edges represent relations between the words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE223">
<title id=" W08-2006.xml">affinity measures based on the graph laplacian </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate each of the similarity measure we consider by using linguistically motivated task of finding lexical similarity.
</prevsent>
<prevsent>deriving lexical relatedness between terms has been topic of interest with applications in word sense disambiguation (patwardhan et al, 2005), <papid> P05-3019 </papid>paraphrasing (kauchak and barzilay, 2006), <papid> N06-1058 </papid>question answering (prager et al, 2001), and machine translation (blatz et al, 2004) <papid> C04-1046 </papid>to name few.</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
lexical relatedness between terms could be derived either from thesaurus like wordnet or fromraw monolingual corpora via distributional similarity (pereira et al, 1993).<papid> P93-1024 </papid></citsent>
<aftsection>
<nextsent>wordnet is an interesting graph-structured thesaurus where the vertices are the words and the edges represent relations between the words.
</nextsent>
<nextsent>for the purpose of this work, we only consider relations like hypernymy, hyponymy, and synonymy.
</nextsent>
<nextsent>the importance of this problem has generated copious literature in the past ? see (pedersen et al, 2004) or (budanitsky and hirst, 2006) <papid> J06-1003 </papid>for detailed review of various lexical relatedness measures on wordnet.</nextsent>
<nextsent>our focus in this paper is not to derive the best similarity measure for wordnet but to use wordnet andthe lexical relatedness task as method to evaluate the various random walk based similarity measures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE224">
<title id=" W08-2006.xml">affinity measures based on the graph laplacian </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>wordnet is an interesting graph-structured thesaurus where the vertices are the words and the edges represent relations between the words.
</prevsent>
<prevsent>for the purpose of this work, we only consider relations like hypernymy, hyponymy, and synonymy.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
the importance of this problem has generated copious literature in the past ? see (pedersen et al, 2004) or (budanitsky and hirst, 2006) <papid> J06-1003 </papid>for detailed review of various lexical relatedness measures on wordnet.</citsent>
<aftsection>
<nextsent>our focus in this paper is not to derive the best similarity measure for wordnet but to use wordnet andthe lexical relatedness task as method to evaluate the various random walk based similarity measures.
</nextsent>
<nextsent>following the tradition in previous literature we evaluate on the miller and charles (1991) dataset.
</nextsent>
<nextsent>this data consists of 30 word-pairs along with human judgements which is real value between 1 and 4.
</nextsent>
<nextsent>for every measure we consider, we derive similarity scores and compare with the human judgements using the spearman rank correlation coefficient.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE227">
<title id=" W08-2006.xml">affinity measures based on the graph laplacian </title>
<section> shortest path based measure.  </section>
<citcontext>
<prevsection>
<prevsent>observe that these results are method spearman correlation page rank js-divergence 0.379 page rank cosine 0.393 table 3: similarity via page rank (?
</prevsent>
<prevsent>= 0.1).better than the best bounded walk result.
</prevsent>
</prevsection>
<citsent citstr=" D07-1061 ">
we further note that our results are different from thatof (hughes and ramage, 2007) <papid> D07-1061 </papid>as they use extensive feature engineering and weight tuning during the graph generation process that we have not been able to reproduce.</citsent>
<aftsection>
<nextsent>hence for simplicity we stuck to simpler graph generation process.
</nextsent>
<nextsent>nevertheless,the result in table 3.
</nextsent>
<nextsent>is still useful as we are interested in the performance of the various spectral similarity measures rather than achieving the best performance on the lexical relatedness task.
</nextsent>
<nextsent>the graphs we use in all methods are identical making comparisons across methods possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE228">
<title id=" W09-1110.xml">interactive feature space construction using semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this statement suggests thatone method for learning robust classifiers is to incorporate semantic information through features extracted from the more descriptive representation: his father was rushed to westlake [healthcare institution], an [subsidiary] of resurrection healthcare, [locative preposition] [compass direction] suburban chicagoland.
</prevsent>
<prevsent>66deriving discriminative features from this representation often results in more informative features and correspondingly simpler classification task.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
although effective approaches along this vein have been shown to induce more accurate classifiers (boggess et al, 1991; miller et al, 2004; <papid> N04-1043 </papid>li and roth, 2005), naive approaches may instead result in higher sample complexity due to increased ambiguity introduced through these semantic resources.</citsent>
<aftsection>
<nextsent>features based upon srwls must therefore balance the tradeoff between descriptive ness and noise.
</nextsent>
<nextsent>this paper introduces the interactive feature space construction (ifsc) protocol, which facilitates coordination between domain expert and learning algorithm to interactively define the feature space during training.
</nextsent>
<nextsent>this paper describes the particular instance of the ifsc protocol where semantic information is introduced through abstraction of lexical terms in the feature space with their srwllabels.
</nextsent>
<nextsent>specifically, there are two notable contributions of this work: (1) an interactive method for the expert to directly encode semantic knowledge into the feature space with minimal effort and (2) querying function which uses both the current state of the learner and properties of the available srwls to select informative instances for presentation to the expert.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE229">
<title id=" W09-1110.xml">interactive feature space construction using semantic information </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>entity classification begins with the results of the segmentation classifier and classifies each segment into ?{person, location, organization}.
</prevsent>
<prevsent>finally, relation classification labels each predicted entity pair with ? {located in, work for, org based in, live in, kill} ? {left, right}+ no relation.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
the data used for empirical evaluation was taken from (roth and yih, 2004) <papid> W04-2401 </papid>and consists of 1436 sentences, which is split into 1149 (80%) sentence training set and 287 (20%) sentence testing setsuch that all have at least one active relation.</citsent>
<aftsection>
<nextsent>sr wls are provided by (pantel and lin, 2002) and experiments were conducted using custom graphical user interface (gui) designed specifically for the ifsc protocol.
</nextsent>
<nextsent>the learning algorithm used for each stage of the classification task is regularized variant of the structured perceptron (collins, 2002).<papid> W02-1001 </papid></nextsent>
<nextsent>resources used to perform experiments are available at http://l2r.cs.uiuc.edu/cogcomp/.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE230">
<title id=" W09-1110.xml">interactive feature space construction using semantic information </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the data used for empirical evaluation was taken from (roth and yih, 2004) <papid> W04-2401 </papid>and consists of 1436 sentences, which is split into 1149 (80%) sentence training set and 287 (20%) sentence testing setsuch that all have at least one active relation.</prevsent>
<prevsent>sr wls are provided by (pantel and lin, 2002) and experiments were conducted using custom graphical user interface (gui) designed specifically for the ifsc protocol.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the learning algorithm used for each stage of the classification task is regularized variant of the structured perceptron (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>resources used to perform experiments are available at http://l2r.cs.uiuc.edu/cogcomp/.
</nextsent>
<nextsent>we extract features in method similar to (roth and small, 2008), except that we do not include gazetteer features in ?(d)0 as we will include this type of external information interactively.
</nextsent>
<nextsent>secondly,we use srwl features as introduced.
</nextsent>
<nextsent>the segmentation features include the word/srwl itself along with the word/srwl of three words before and two words after, bigrams of the word/srwl surrounding the word, capitalization of the word, and capitalization of its neighbor on each side.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE231">
<title id=" W09-1110.xml">interactive feature space construction using semantic information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the interactive protocol (interactive) outperforms the baseline lexical system (base line) trained on all 1149 sentences even when trained with significantly smaller subset of labeled data.
</prevsent>
<prevsent>there has been significant recent work on designing learning algorithms which attempt to reduce annotation requirements through more sophisticated annotation method.
</prevsent>
</prevsection>
<citsent citstr=" N07-1033 ">
these methods allow the annotator to directly specify information about the feature space in addition to providing labels, which is then incorporated into the learning algorithm (huang and mitchell, 2006; raghavan and allan, 2007; zaidan et al, 2007; <papid> N07-1033 </papid>druck et al, 2008; zaidan and eisner,2008).<papid> D08-1004 </papid></citsent>
<aftsection>
<nextsent>additionally, there has been recent work using explanation-based learning techniques to encode more expressive feature space (lim et al, 2007).
</nextsent>
<nextsent>amongst these works, the only interactive learning protocol is (raghavan and allan, 2007) where instances are presented to an expert and features are labeled which are then emphasized by the learning algorithm.
</nextsent>
<nextsent>thus, in this case, although additional information is provided the feature space itself remains static.
</nextsent>
<nextsent>to the best of our knowledge, this is the first work that interactively modifies the feature space by abstracting the fgfs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE232">
<title id=" W09-1110.xml">interactive feature space construction using semantic information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the interactive protocol (interactive) outperforms the baseline lexical system (base line) trained on all 1149 sentences even when trained with significantly smaller subset of labeled data.
</prevsent>
<prevsent>there has been significant recent work on designing learning algorithms which attempt to reduce annotation requirements through more sophisticated annotation method.
</prevsent>
</prevsection>
<citsent citstr=" D08-1004 ">
these methods allow the annotator to directly specify information about the feature space in addition to providing labels, which is then incorporated into the learning algorithm (huang and mitchell, 2006; raghavan and allan, 2007; zaidan et al, 2007; <papid> N07-1033 </papid>druck et al, 2008; zaidan and eisner,2008).<papid> D08-1004 </papid></citsent>
<aftsection>
<nextsent>additionally, there has been recent work using explanation-based learning techniques to encode more expressive feature space (lim et al, 2007).
</nextsent>
<nextsent>amongst these works, the only interactive learning protocol is (raghavan and allan, 2007) where instances are presented to an expert and features are labeled which are then emphasized by the learning algorithm.
</nextsent>
<nextsent>thus, in this case, although additional information is provided the feature space itself remains static.
</nextsent>
<nextsent>to the best of our knowledge, this is the first work that interactively modifies the feature space by abstracting the fgfs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE233">
<title id=" W09-1110.xml">interactive feature space construction using semantic information </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the most immediate task is effectively quantifying interaction costs with user study, including the impact of including users with varying levels of expertise.
</prevsent>
<prevsent>recent work on modeling the costs of the active learning protocol (settles et al, 2009; haertel et al,2009) provides some insight on modeling costs associated with interactive learning protocols.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
a second potentially interesting direction would be to incorporate other semantic resources such as lexical patterns (hearst, 1992) <papid> C92-2082 </papid>or wikipedia-generated gazette ers (toral and munoz, 2006).</citsent>
<aftsection>
<nextsent>acknowledgments the authors would like to thank ming-wei chang,margaret fleck, julia hockenmaier, alex klementiev, ivan titov, and the anonymous reviewers for their valuable suggestions.
</nextsent>
<nextsent>this work is supported by darpa funding under the bootstrap learning program and by mias, dhs-ids center for multimodal information access and synthesis at uiuc.
</nextsent>
<nextsent>73
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE234">
<title id=" W09-0205.xml">bagpack a general framework to represent semantic relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we introduce way to represent word pairs instantiating arbitrary semantic relations that keeps track of the contexts in which the wordsin the pair occur both together and independently.
</prevsent>
<prevsent>the resulting features are of sufficient generality to allow us, with the help of standard supervised machine learning algorithm, to tackle variety of unrelated semantic tasks with good results and almost no task-specific tailoring.
</prevsent>
</prevsection>
<citsent citstr=" J06-3003 ">
co-occurrence statistics extracted from corpora lead to good performance on wide range of tasks that involve the identification of the semantic relation between two words or concepts (sahlgren, 2006; turney, 2006).<papid> J06-3003 </papid></citsent>
<aftsection>
<nextsent>however, the difficulty of such tasks and the fact that they are apparently unrelated has led to the development of largely ad-hoc solutions, tuned to specific challenges.
</nextsent>
<nextsent>for many practical applications, this isa drawback: given the large number of semantic relations that might be relevant to one or the other task, weneed multi-purpose approach that, given an appropriate representation and training examples instantiating an arbitrary target relation, can automatically mine new pairs characterized by the same relation.
</nextsent>
<nextsent>building on recent proposal in this direction by turney (2008), <papid> C08-1114 </papid>we propose generic method of this sort, and we test it on set of unrelated tasks, reporting good performance across the board with very little task-specific tweaking.</nextsent>
<nextsent>there has been much previous work on corpus-based models to extract broad classes of related words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE235">
<title id=" W09-0205.xml">bagpack a general framework to represent semantic relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the difficulty of such tasks and the fact that they are apparently unrelated has led to the development of largely ad-hoc solutions, tuned to specific challenges.
</prevsent>
<prevsent>for many practical applications, this isa drawback: given the large number of semantic relations that might be relevant to one or the other task, weneed multi-purpose approach that, given an appropriate representation and training examples instantiating an arbitrary target relation, can automatically mine new pairs characterized by the same relation.
</prevsent>
</prevsection>
<citsent citstr=" C08-1114 ">
building on recent proposal in this direction by turney (2008), <papid> C08-1114 </papid>we propose generic method of this sort, and we test it on set of unrelated tasks, reporting good performance across the board with very little task-specific tweaking.</citsent>
<aftsection>
<nextsent>there has been much previous work on corpus-based models to extract broad classes of related words.
</nextsent>
<nextsent>the literature on word space models (sahlgren, 2006) has focused on taxonomic similarity (synonyms, antonyms,co-hyponyms.
</nextsent>
<nextsent>) and general association (e.g., finding topically related words), exploiting the idea that taxonomic ally or associated words will tend to occurin similar contexts, and thus share vector of cooccurring words.
</nextsent>
<nextsent>the literature on relational similarity, on the other hand, has focused on pairs of words, devising various methods to compare how similar the contexts in which target pairs appear are to the contexts of other pairs that instantiate relation of interest (tur ney, 2006; <papid> J06-3003 </papid>pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE237">
<title id=" W09-0205.xml">bagpack a general framework to represent semantic relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the literature on word space models (sahlgren, 2006) has focused on taxonomic similarity (synonyms, antonyms,co-hyponyms.
</prevsent>
<prevsent>) and general association (e.g., finding topically related words), exploiting the idea that taxonomic ally or associated words will tend to occurin similar contexts, and thus share vector of cooccurring words.
</prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
the literature on relational similarity, on the other hand, has focused on pairs of words, devising various methods to compare how similar the contexts in which target pairs appear are to the contexts of other pairs that instantiate relation of interest (tur ney, 2006; <papid> J06-3003 </papid>pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></citsent>
<aftsection>
<nextsent>beyond these domains, purely corpus-based methods play an increasingly important role in modeling constraints on composition of words, in particular verbal selectional preferences ? finding out that, say, children are more likely to eat than apples, whereas the latter are more likely to be eaten (erk, 2007; <papid> P07-1028 </papid>pad?</nextsent>
<nextsent>et al, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE238">
<title id=" W09-0205.xml">bagpack a general framework to represent semantic relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>) and general association (e.g., finding topically related words), exploiting the idea that taxonomic ally or associated words will tend to occurin similar contexts, and thus share vector of cooccurring words.
</prevsent>
<prevsent>the literature on relational similarity, on the other hand, has focused on pairs of words, devising various methods to compare how similar the contexts in which target pairs appear are to the contexts of other pairs that instantiate relation of interest (tur ney, 2006; <papid> J06-3003 </papid>pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1028 ">
beyond these domains, purely corpus-based methods play an increasingly important role in modeling constraints on composition of words, in particular verbal selectional preferences ? finding out that, say, children are more likely to eat than apples, whereas the latter are more likely to be eaten (erk, 2007; <papid> P07-1028 </papid>pad?</citsent>
<aftsection>
<nextsent>et al, 2007).
</nextsent>
<nextsent>tasks of this sort differ from relation extraction in that we need to capture productive patterns: we want to find out that shabu shabu (a japanese meat dish) is eaten whereas ink is not, even if in our corpus neither noun is attested in proximity to forms of the verb to eat.turney (2008) <papid> C08-1114 </papid>is the first, to the best of our knowledge, to raise the issue of unified approach.</nextsent>
<nextsent>in particular, he treats synonymy and association as special cases of relational similarity: in the same way in which we might be able to tell that hands and arms are in part-of relation by comparing the contexts in which they co-occur to the contexts of known part-of pairs, we can guess that cars and automobiles are synonyms by comparing the contexts in which they co-occur to the contexts linking known synonym pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE243">
<title id=" W09-0205.xml">bagpack a general framework to represent semantic relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, he treats synonymy and association as special cases of relational similarity: in the same way in which we might be able to tell that hands and arms are in part-of relation by comparing the contexts in which they co-occur to the contexts of known part-of pairs, we can guess that cars and automobiles are synonyms by comparing the contexts in which they co-occur to the contexts linking known synonym pairs.
</prevsent>
<prevsent>here, we build on turneys work, adding two main methodological innovations that allow us further generalization.
</prevsent>
</prevsection>
<citsent citstr=" P06-2075 ">
first, merging classic approaches to taxonomic and relational similarity, we represent concept pairs by vector that concatenates information about the contexts in which the two words occur independently, and the contexts in which they co-occur (mirkinet al 2006 <papid> P06-2075 </papid>also integrate information from the lexical patterns in which two words co-occur and similarity of the contexts in which each word occurs on its own, to improve performance in lexical entailment acquisition).</citsent>
<aftsection>
<nextsent>second, we represent contexts as bag ofwords and bigrams, rather than strings of words (pat terns?)
</nextsent>
<nextsent>of arbitrary length: we leave it to the machine learning algorithm to zero in on the most interesting words/bigrams.
</nextsent>
<nextsent>thanks to the concatenated vector, we can tackle tasks in which the two words are not expected toco-occur even in very large corpora (such as selectional preference).
</nextsent>
<nextsent>concatenation, together with un igram/bigram representation of context, allows us to scale down the approach to smaller training corpora (turney used corpus of more than 50 billion words),since we do not need to see the words directly cooccurring, and the unigram/bigram dimensions of the 33 vectors are less sparse than dimensions based on longer strings of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE253">
<title id=" W08-1407.xml">evaluating automatically generated user focused multi document summaries for geo referenced images </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>the automatic captioning procedure requires summarizing multiple web documents that contain information related to images?
</prevsent>
<prevsent>location.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
we use summa (saggion and gaizauskas, 2005) to generate generic and query-based multi-document summaries and evaluate them using rouge evaluation metrics (lin, 2004) <papid> W04-1013 </papid>relative to human generated summaries.</citsent>
<aftsection>
<nextsent>results show that,even though query-based summaries perform better than generic ones, they are still not selecting the information that human participants do.
</nextsent>
<nextsent>in particular, the areas of interest that human summaries display (history, travel information, etc.) are not contained in the query-based summaries.
</nextsent>
<nextsent>for our future work in automatic image captioning this result suggests that developing the query-based summarizer further and biasing it to account for user-specific requirements will prove worthwhile.
</nextsent>
<nextsent>retrieving textual information related to location shown in an image has many potential applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE254">
<title id=" W08-1407.xml">evaluating automatically generated user focused multi document summaries for geo referenced images </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we focus on geo-referenced images, i.e. images tagged with coordinates (latitude and longi tude) and compass information, that show things with fixed locations (e.g. buildings, mountains, etc.).
</prevsent>
<prevsent>attempts towards automatic generation of image-related textual information or captions have been previously reported.
</prevsent>
</prevsection>
<citsent citstr=" P07-1126 ">
deschacht and moens (2007) <papid> P07-1126 </papid>and mori et al (2000) generate image captions automatically by analyzing image-related text from the immediate context of the image, i.e. existing image captions, surrounding text in html documents, text contained in the image, etc. the authors identify named entities and other noun phrases in the image-related text and assign these to the image as captions.</citsent>
<aftsection>
<nextsent>other approaches create image captions by taking into consideration image features as well as image-related text (westerveld, 2000; barnard et al, 2003; pan et al., 2004).
</nextsent>
<nextsent>these approaches can address all kinds of images, but focus mostly on images of people.
</nextsent>
<nextsent>they analyze only the immediate textual context ofthe image on the web and are concerned with describing what is in the image only.
</nextsent>
<nextsent>consequently, background information about the objects in the image is not provided.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE255">
<title id=" W08-1407.xml">evaluating automatically generated user focused multi document summaries for geo referenced images </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summa and mead generate both generic and query-based multi-document summaries.
</prevsent>
<prevsent>boros et al (2001) create only generic summaries, while classy and cats create only query-basedsummaries from multiple documents.
</prevsent>
</prevsection>
<citsent citstr=" W03-0509 ">
the performance of these tools has been reported for duc tasks 1 . as sekine and nobata (2003) <papid> W03-0509 </papid>note, al-.</citsent>
<aftsection>
<nextsent>though duc tasks provide common evaluation standard, they are restricted in topic and are some what idealized.
</nextsent>
<nextsent>for our purposes the summarizer needs to create summaries from unrestricted web input, for which there are no previous performance reports.
</nextsent>
<nextsent>for this reason we evaluate the performance of both generic and query-based summarizer and use summa which provides both summarizationmodes.
</nextsent>
<nextsent>we hypothesize that query-based sum marizer will better address the problem of creating summaries tailored to users?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE257">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in section 2 we describe the baseline model,section 3 describes the various strategies we employed to address the challenges just listed, and section 4 summarizes the final translation system.
</prevsent>
<prevsent>our translation system makes use of hierarchical phrase-based translation model (chiang, 2007), which we argue is strong baseline for these language pairs.
</prevsent>
</prevsection>
<citsent citstr=" C08-1064 ">
first, such system makes useof lexical information when modeling reordering (lopez, 2008), <papid> C08-1064 </papid>which has previously been shown to be useful in german-to-english translation (koehn et al, 2008).<papid> W08-0318 </papid></citsent>
<aftsection>
<nextsent>additionally, since the decoder is based on cky parser, it can consider all licensed reorderings of the input in polynomial time, and german and hungarian may require quite substantial reordering.
</nextsent>
<nextsent>although such decoders and models have been common for several years, there have been no published results for these language pairs.
</nextsent>
<nextsent>the baseline system translates lower cased and tokenized source sentences into lower cased targetsentences.
</nextsent>
<nextsent>the features used were the rule translation relative frequency (e?|f?), the lexical?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE258">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in section 2 we describe the baseline model,section 3 describes the various strategies we employed to address the challenges just listed, and section 4 summarizes the final translation system.
</prevsent>
<prevsent>our translation system makes use of hierarchical phrase-based translation model (chiang, 2007), which we argue is strong baseline for these language pairs.
</prevsent>
</prevsection>
<citsent citstr=" W08-0318 ">
first, such system makes useof lexical information when modeling reordering (lopez, 2008), <papid> C08-1064 </papid>which has previously been shown to be useful in german-to-english translation (koehn et al, 2008).<papid> W08-0318 </papid></citsent>
<aftsection>
<nextsent>additionally, since the decoder is based on cky parser, it can consider all licensed reorderings of the input in polynomial time, and german and hungarian may require quite substantial reordering.
</nextsent>
<nextsent>although such decoders and models have been common for several years, there have been no published results for these language pairs.
</nextsent>
<nextsent>the baseline system translates lower cased and tokenized source sentences into lower cased targetsentences.
</nextsent>
<nextsent>the features used were the rule translation relative frequency (e?|f?), the lexical?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE259">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the features used were the rule translation relative frequency (e?|f?), the lexical?
</prevsent>
<prevsent>translation probabilities plex(e?|f?) and plex(f? |e?), rule count, target language word count, the target(english) language model (ei1), and pass through?
</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
penalty for passing source language word to the target side.1 the rule feature values were computed online during decoding using the suffix array method described by lopez (2007).<papid> D07-1104 </papid>1the pass-through?</citsent>
<aftsection>
<nextsent>penalty was necessary since the english language modeling data contained large amount of source-language text.
</nextsent>
<nextsent>145 2.1 training and development data.
</nextsent>
<nextsent>to construct the translation suffix arrays used to compute the translation grammar, we used the parallel training data provided.
</nextsent>
<nextsent>the preprocessed training data was filtered for length and aligned using the giza++ implementation of ibm model4 (och and ney, 2003) <papid> J03-1002 </papid>in both directions and sym metrized using the grow-diag-final-and heuristic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE260">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>145 2.1 training and development data.
</prevsent>
<prevsent>to construct the translation suffix arrays used to compute the translation grammar, we used the parallel training data provided.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the preprocessed training data was filtered for length and aligned using the giza++ implementation of ibm model4 (och and ney, 2003) <papid> J03-1002 </papid>in both directions and sym metrized using the grow-diag-final-and heuristic.</citsent>
<aftsection>
<nextsent>we trained 5-gram language model from the provided english monolingual training data and the non-europarl portions of the parallel training data using modified kneser-ney smoothing as implemented in the sri language modeling toolkit (kneser and ney, 1995; stolcke, 2002).
</nextsent>
<nextsent>we divided the 2008 workshop news test?
</nextsent>
<nextsent>sets into two halves of approximately 1000 sentences each and designated one the dev set and the other the dev-test set.
</nextsent>
<nextsent>2.2 automatic evaluation metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE261">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>sets into two halves of approximately 1000 sentences each and designated one the dev set and the other the dev-test set.
</prevsent>
<prevsent>2.2 automatic evaluation metric.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
since the official evaluation criterion for wmt09 is human sentence ranking, we chose to minimize linear combination of two common evaluation metrics, bleu and ter (papineni et al, 2002; <papid> P02-1040 </papid>snover et al, 2006), during system development and tuning: ter ? bleu 2although we are not aware of any work demonstrating that this combination of metrics correlates better than either individually in sentence ranking,yaser al-onaizan (personal communication) reports that it correlates well with the human evaluation metric hter.</citsent>
<aftsection>
<nextsent>in this paper, we report uncased ter and bleu individually.
</nextsent>
<nextsent>2.3 forest minimum error training.
</nextsent>
<nextsent>to tune the feature weights of our system, we used variant of the minimum error training algorithm (och, 2003) <papid> P03-1021 </papid>that computes the error statistics from the target sentences from the translation search space (represented by packed forest) that are exactly those that are minimally discriminable by changing the feature weights along single vector in the dimensions of the feature space (macherey et al, 2008).<papid> D08-1076 </papid></nextsent>
<nextsent>the loss function we used was the linear combination of ter and bleu described in the previous section.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE262">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we report uncased ter and bleu individually.
</prevsent>
<prevsent>2.3 forest minimum error training.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
to tune the feature weights of our system, we used variant of the minimum error training algorithm (och, 2003) <papid> P03-1021 </papid>that computes the error statistics from the target sentences from the translation search space (represented by packed forest) that are exactly those that are minimally discriminable by changing the feature weights along single vector in the dimensions of the feature space (macherey et al, 2008).<papid> D08-1076 </papid></citsent>
<aftsection>
<nextsent>the loss function we used was the linear combination of ter and bleu described in the previous section.
</nextsent>
<nextsent>this section describes the experimental variants explored.
</nextsent>
<nextsent>3.1 word segmentation lattices.
</nextsent>
<nextsent>both german and hungarian have large number of compound words that are created by concatenating several morphemes to form single orthographic token.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE263">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we report uncased ter and bleu individually.
</prevsent>
<prevsent>2.3 forest minimum error training.
</prevsent>
</prevsection>
<citsent citstr=" D08-1076 ">
to tune the feature weights of our system, we used variant of the minimum error training algorithm (och, 2003) <papid> P03-1021 </papid>that computes the error statistics from the target sentences from the translation search space (represented by packed forest) that are exactly those that are minimally discriminable by changing the feature weights along single vector in the dimensions of the feature space (macherey et al, 2008).<papid> D08-1076 </papid></citsent>
<aftsection>
<nextsent>the loss function we used was the linear combination of ter and bleu described in the previous section.
</nextsent>
<nextsent>this section describes the experimental variants explored.
</nextsent>
<nextsent>3.1 word segmentation lattices.
</nextsent>
<nextsent>both german and hungarian have large number of compound words that are created by concatenating several morphemes to form single orthographic token.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE265">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>to deal with productive compounding, we employ word segmentation lattices, which are word lattices that encode alternative possiblesegmentations of compound words.
</prevsent>
<prevsent>doing so enables us to use possibly inaccurate approaches toguess the segmentation of compound words, allowing the decoder to decide which to use during translation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
this is further development of our general source-lattice approach to decoding (dyer et al, 2008).<papid> P08-1115 </papid>to construct the segmentation lattices, we define log-linear model of compound word segmentation inspired by koehn and knight (2003),<papid> E03-1076 </papid>making use of features including number of morphemes hypothesized, frequency of the segments as free-standing morphemes in training corpus, and letters in each segment.</citsent>
<aftsection>
<nextsent>to tune the model parameters, we selected set of compound words from subset of the german development set,manually created linguistically plausible segmentation of these words, and used this to select the parameters of the log-linear model using lattice minimum error training algorithm to minimize wer (macherey et al, 2008).<papid> D08-1076 </papid></nextsent>
<nextsent>we reused the same features and weights to create the hungarian lattices.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE266">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>to deal with productive compounding, we employ word segmentation lattices, which are word lattices that encode alternative possiblesegmentations of compound words.
</prevsent>
<prevsent>doing so enables us to use possibly inaccurate approaches toguess the segmentation of compound words, allowing the decoder to decide which to use during translation.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
this is further development of our general source-lattice approach to decoding (dyer et al, 2008).<papid> P08-1115 </papid>to construct the segmentation lattices, we define log-linear model of compound word segmentation inspired by koehn and knight (2003),<papid> E03-1076 </papid>making use of features including number of morphemes hypothesized, frequency of the segments as free-standing morphemes in training corpus, and letters in each segment.</citsent>
<aftsection>
<nextsent>to tune the model parameters, we selected set of compound words from subset of the german development set,manually created linguistically plausible segmentation of these words, and used this to select the parameters of the log-linear model using lattice minimum error training algorithm to minimize wer (macherey et al, 2008).<papid> D08-1076 </papid></nextsent>
<nextsent>we reused the same features and weights to create the hungarian lattices.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE269">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>in typical cky decoders, the beginning and endsof the sentence (which often have special charac teristics) are not conclusively determined until the whole sentence has been translated and the probabilities for the beginning and end sentence probabilities can be added.
</prevsent>
<prevsent>however, by this point it isoften the case that possibly better sentence beginning has been pruned away.
</prevsent>
</prevsection>
<citsent citstr=" I08-1066 ">
to address this, we explicitly generate beginning and end sentence markers as part of the translation process, as suggested by xiong et al (2008).<papid> I08-1066 </papid></citsent>
<aftsection>
<nextsent>the results of doing this are shown in table 2.
</nextsent>
<nextsent>source condition bleu ter german baseline 21.3 59.9 +boundary 21.6 60.1 hungarian baseline 12.3 70.4 +boundary 12.8 70.4 table 2: impact of modeling sentence boundaries.
</nextsent>
<nextsent>3.3 source language paraphrases.
</nextsent>
<nextsent>in order to deal with the sparsity associated witha rich source language morphology and limited size parallel corpora (bitexts), we experimented with novel approach to paraphrasing out-of vocabulary (oov) source language phrases in our hungarian-english system, using monolingual contextual similarity rather than phrase-table pivoting (callison-burch et al, 2006) or monolingual bitexts (barzilay and mckeown, 2001; <papid> P01-1008 </papid>dolan et al, 2004).<papid> C04-1051 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE270">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>source condition bleu ter german baseline 21.3 59.9 +boundary 21.6 60.1 hungarian baseline 12.3 70.4 +boundary 12.8 70.4 table 2: impact of modeling sentence boundaries.
</prevsent>
<prevsent>3.3 source language paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
in order to deal with the sparsity associated witha rich source language morphology and limited size parallel corpora (bitexts), we experimented with novel approach to paraphrasing out-of vocabulary (oov) source language phrases in our hungarian-english system, using monolingual contextual similarity rather than phrase-table pivoting (callison-burch et al, 2006) or monolingual bitexts (barzilay and mckeown, 2001; <papid> P01-1008 </papid>dolan et al, 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>distributional profiles for source phrases were represented as context vectors over sliding window of size 6, with vectors defined using log-likelihood ratios (cf.
</nextsent>
<nextsent>rapp (1999), <papid> P99-1067 </papid>dunning (1993)) <papid> J93-1003 </papid>but using cosine rather than city block distance to measure profile similarity.</nextsent>
<nextsent>the 20 distributionally most similar source phrases were treated as paraphrases, considering candidate phrases up to width of 6 tokens and filtering out paraphrase candidates with cosine similarity to the original of less than 0.6.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE271">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>source condition bleu ter german baseline 21.3 59.9 +boundary 21.6 60.1 hungarian baseline 12.3 70.4 +boundary 12.8 70.4 table 2: impact of modeling sentence boundaries.
</prevsent>
<prevsent>3.3 source language paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
in order to deal with the sparsity associated witha rich source language morphology and limited size parallel corpora (bitexts), we experimented with novel approach to paraphrasing out-of vocabulary (oov) source language phrases in our hungarian-english system, using monolingual contextual similarity rather than phrase-table pivoting (callison-burch et al, 2006) or monolingual bitexts (barzilay and mckeown, 2001; <papid> P01-1008 </papid>dolan et al, 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>distributional profiles for source phrases were represented as context vectors over sliding window of size 6, with vectors defined using log-likelihood ratios (cf.
</nextsent>
<nextsent>rapp (1999), <papid> P99-1067 </papid>dunning (1993)) <papid> J93-1003 </papid>but using cosine rather than city block distance to measure profile similarity.</nextsent>
<nextsent>the 20 distributionally most similar source phrases were treated as paraphrases, considering candidate phrases up to width of 6 tokens and filtering out paraphrase candidates with cosine similarity to the original of less than 0.6.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE272">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>in order to deal with the sparsity associated witha rich source language morphology and limited size parallel corpora (bitexts), we experimented with novel approach to paraphrasing out-of vocabulary (oov) source language phrases in our hungarian-english system, using monolingual contextual similarity rather than phrase-table pivoting (callison-burch et al, 2006) or monolingual bitexts (barzilay and mckeown, 2001; <papid> P01-1008 </papid>dolan et al, 2004).<papid> C04-1051 </papid></prevsent>
<prevsent>distributional profiles for source phrases were represented as context vectors over sliding window of size 6, with vectors defined using log-likelihood ratios (cf.</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
rapp (1999), <papid> P99-1067 </papid>dunning (1993)) <papid> J93-1003 </papid>but using cosine rather than city block distance to measure profile similarity.</citsent>
<aftsection>
<nextsent>the 20 distributionally most similar source phrases were treated as paraphrases, considering candidate phrases up to width of 6 tokens and filtering out paraphrase candidates with cosine similarity to the original of less than 0.6.
</nextsent>
<nextsent>the two most likely translations for each paraphrase were added to the grammar in order to provide mappings to english for oov hungarian phrases.this attempt at monolingually-derived source side paraphrasing did not yield improvements over baseline.
</nextsent>
<nextsent>preliminary analysis suggests that the approach does well at identifying many content words in translating extracted paraphrases of oov phrases (e.g., kommunista part vezetaje ? , leader of the communist party or ra tervezettuntil the planned to), but at the cost of more frequently omitting target words in the output.
</nextsent>
<nextsent>3.4 dominance feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE273">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>in order to deal with the sparsity associated witha rich source language morphology and limited size parallel corpora (bitexts), we experimented with novel approach to paraphrasing out-of vocabulary (oov) source language phrases in our hungarian-english system, using monolingual contextual similarity rather than phrase-table pivoting (callison-burch et al, 2006) or monolingual bitexts (barzilay and mckeown, 2001; <papid> P01-1008 </papid>dolan et al, 2004).<papid> C04-1051 </papid></prevsent>
<prevsent>distributional profiles for source phrases were represented as context vectors over sliding window of size 6, with vectors defined using log-likelihood ratios (cf.</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
rapp (1999), <papid> P99-1067 </papid>dunning (1993)) <papid> J93-1003 </papid>but using cosine rather than city block distance to measure profile similarity.</citsent>
<aftsection>
<nextsent>the 20 distributionally most similar source phrases were treated as paraphrases, considering candidate phrases up to width of 6 tokens and filtering out paraphrase candidates with cosine similarity to the original of less than 0.6.
</nextsent>
<nextsent>the two most likely translations for each paraphrase were added to the grammar in order to provide mappings to english for oov hungarian phrases.this attempt at monolingually-derived source side paraphrasing did not yield improvements over baseline.
</nextsent>
<nextsent>preliminary analysis suggests that the approach does well at identifying many content words in translating extracted paraphrases of oov phrases (e.g., kommunista part vezetaje ? , leader of the communist party or ra tervezettuntil the planned to), but at the cost of more frequently omitting target words in the output.
</nextsent>
<nextsent>3.4 dominance feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE274">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>briefly, the premise of this feature is that the function words in the sentence hold the key reordering information, and therefore function words are used to model the phrases being moved.
</prevsent>
<prevsent>the feature assesses the quality of reordering by looking at the phrase alignment between pairs of 147 function words.
</prevsent>
</prevsection>
<citsent citstr=" P07-1090 ">
in our experiments, we treated the 128 most frequent words in the corpus as function words, similar to setiawan et al (2007).<papid> P07-1090 </papid></citsent>
<aftsection>
<nextsent>due to space constraints, we will discuss the details in another publication.
</nextsent>
<nextsent>as table 3 reports, the use of this feature yields positive results.
</nextsent>
<nextsent>source condition bleu ter german baseline 21.6 60.1 +dom 22.2 59.8 hungarian baseline 12.8 70.4 +dom 12.6 70.0 table 3: impact of alignment dominance feature.
</nextsent>
<nextsent>3.5 minimum bayes risk decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE275">
<title id=" W09-0426.xml">the university of maryland statistical machine translation system for the fourth workshop on machine translation </title>
<section> experimental variations.  </section>
<citcontext>
<prevsection>
<prevsent>source condition bleu ter german baseline 21.6 60.1 +dom 22.2 59.8 hungarian baseline 12.8 70.4 +dom 12.6 70.0 table 3: impact of alignment dominance feature.
</prevsent>
<prevsent>3.5 minimum bayes risk decoding.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
although during minimum error training we assume decoder that uses the maximum derivation decision rule, we find benefits to translating using minimum risk decision rule on test set (kumar and byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>this seeks the translation of the input lattice that has the least expected loss, measured by some loss function l: e?
</nextsent>
<nextsent>= arg min e?
</nextsent>
<nextsent>ep (e|f)[l(e,e ?)] (1) = arg min e?
</nextsent>
<nextsent>e (e|f)l(e,e?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE276">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, kernel function can be directly calculated on the object.
</prevsent>
<prevsent>the advantages are that the original topological information is to large extent preserved and the introduction of additional noise may be avoided.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
thus structure-based kernels can well model syntactic parse tree in variety of applications, such as relationextraction(zelenko et al, 2003), named entity recognition(culotta and sorensen, 2004), <papid> P04-1054 </papid>semantic role labeling(moschitti et al, 2008) <papid> J08-2003 </papid>and so on.</citsent>
<aftsection>
<nextsent>to compute the structural kernel function, haussler (1999) introduced general type of kernel function, called?
</nextsent>
<nextsent>convolution kernel?.
</nextsent>
<nextsent>based on this work, collins and duffy (2002)<papid> P02-1034 </papid>proposed tree kernel calculation by counting the common subtrees.</nextsent>
<nextsent>in other words, two trees are considered if and only if these two trees are exactly same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE277">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, kernel function can be directly calculated on the object.
</prevsent>
<prevsent>the advantages are that the original topological information is to large extent preserved and the introduction of additional noise may be avoided.
</prevsent>
</prevsection>
<citsent citstr=" J08-2003 ">
thus structure-based kernels can well model syntactic parse tree in variety of applications, such as relationextraction(zelenko et al, 2003), named entity recognition(culotta and sorensen, 2004), <papid> P04-1054 </papid>semantic role labeling(moschitti et al, 2008) <papid> J08-2003 </papid>and so on.</citsent>
<aftsection>
<nextsent>to compute the structural kernel function, haussler (1999) introduced general type of kernel function, called?
</nextsent>
<nextsent>convolution kernel?.
</nextsent>
<nextsent>based on this work, collins and duffy (2002)<papid> P02-1034 </papid>proposed tree kernel calculation by counting the common subtrees.</nextsent>
<nextsent>in other words, two trees are considered if and only if these two trees are exactly same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE278">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to compute the structural kernel function, haussler (1999) introduced general type of kernel function, called?
</prevsent>
<prevsent>convolution kernel?.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
based on this work, collins and duffy (2002)<papid> P02-1034 </papid>proposed tree kernel calculation by counting the common subtrees.</citsent>
<aftsection>
<nextsent>in other words, two trees are considered if and only if these two trees are exactly same.
</nextsent>
<nextsent>in real sentences, some structural alternations within given phrase are permitted without changing its us age.
</nextsent>
<nextsent>therefore, moschitti (2004) <papid> P04-1043 </papid>proposed partial trees to partially match between subtrees.</nextsent>
<nextsent>kashima and koyanagi (2002) generalize the tree kernel to labeled order tree kernel with more flexible match.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE279">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other words, two trees are considered if and only if these two trees are exactly same.
</prevsent>
<prevsent>in real sentences, some structural alternations within given phrase are permitted without changing its us age.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
therefore, moschitti (2004) <papid> P04-1043 </papid>proposed partial trees to partially match between subtrees.</citsent>
<aftsection>
<nextsent>kashima and koyanagi (2002) generalize the tree kernel to labeled order tree kernel with more flexible match.
</nextsent>
<nextsent>and from the idea of introducing linguistical knowledge, zhang et al (2007) <papid> P07-1026 </papid>proposed grammar-driven tree kernel, in which two subtrees are same if and only if the corresponding two productions arein the same manually defined set.</nextsent>
<nextsent>in addition, the problem of hard matching can be alleviated by processing or mapping the trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE280">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, moschitti (2004) <papid> P04-1043 </papid>proposed partial trees to partially match between subtrees.</prevsent>
<prevsent>kashima and koyanagi (2002) generalize the tree kernel to labeled order tree kernel with more flexible match.</prevsent>
</prevsection>
<citsent citstr=" P07-1026 ">
and from the idea of introducing linguistical knowledge, zhang et al (2007) <papid> P07-1026 </papid>proposed grammar-driven tree kernel, in which two subtrees are same if and only if the corresponding two productions arein the same manually defined set.</citsent>
<aftsection>
<nextsent>in addition, the problem of hard matching can be alleviated by processing or mapping the trees.
</nextsent>
<nextsent>for example, tai mapping (kuboyama et al, 2006) generalized the kernel from counting subtrees to counting the function of mapping.
</nextsent>
<nextsent>moreover multi-source knowledge can benefit kernel calculation, such as using dependency information to dynamically determine the tree span (qian et al, 2008).<papid> C08-1088 </papid>in this paper, we propose tree kernel calculation algorithm by allowing variations in productions.</nextsent>
<nextsent>the variation is measured with local alignment score between two derivative pos sequences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE281">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, the problem of hard matching can be alleviated by processing or mapping the trees.
</prevsent>
<prevsent>for example, tai mapping (kuboyama et al, 2006) generalized the kernel from counting subtrees to counting the function of mapping.
</prevsent>
</prevsection>
<citsent citstr=" C08-1088 ">
moreover multi-source knowledge can benefit kernel calculation, such as using dependency information to dynamically determine the tree span (qian et al, 2008).<papid> C08-1088 </papid>in this paper, we propose tree kernel calculation algorithm by allowing variations in productions.</citsent>
<aftsection>
<nextsent>the variation is measured with local alignment score between two derivative pos sequences.
</nextsent>
<nextsent>to reduce the computation complexity, we use the dynamic programming algorithm to compute the score of any alignment.
</nextsent>
<nextsent>and the top alignments are considered in the kernel.
</nextsent>
<nextsent>25 another problem in collins and duffys tree kernel is context-free.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE288">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for svm multi-classifier, the one-vs-all (ova) strategy is selected.
</prevsent>
<prevsent>in all, we prepare the data for each semantic role (r) as following:(1) given sentence and its correct full syntactic parse tree;(2) let be the predicate.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
its potential arguments are extracted according to (xue and palmer, 2004) (<papid> W04-3212 </papid>3) for each pair   p,  ?</citsent>
<aftsection>
<nextsent>p ? a: if covers exactly the words of semantic role of p, put minimal subtree   p,   into positive example set (t+r ); else put it in the negative examples (tr ) in our experiments, we set ? = 0.5.
</nextsent>
<nextsent>4.1.2 experimental results the classification performance is evaluated with respect to accuracy, precision(p), recall(r) and f1 = 2pr/(p+ r).
</nextsent>
<nextsent>accuracy(%) (collins and duffy, 2002) <papid> P02-1034 </papid>84.35 (moschitti, 2004) <papid> P04-1043 </papid>86.72 (zhang et al, 2007) <papid> P07-1026 </papid>87.96 our kernel 88.48 table 2: performance comparison between different kernel performance on wsj data 1http://dit.unitn.it/ moschitt/tree-kernel.htm p(%) r(%) f?=1 development 81.03 68.91 74.48 wsj test 84.97 79.45 82.11 brown test 76.95 70.94 73.51 wsj+brown 82.98 75.40 79.01 wsj p(%) r(%) a0 81.28 83.90 82.56 a1 84.22 66.39 74.25 a2 77.27 62.36 69.02 a3 93.33 21.21 34.57 a4 82.61 51.35 63.33 a5 100.00 40.00 57.41 am-adv 74.21 56.21 63.92 am-cau 75.00 46.09 57.09 am-dir 57.14 16.00 25.00 am-dis 77.78 70.00 73.68 am-ext 75.00 53.10 62.18 am-loc 89.66 74.83 81.57 am-mnr 84.62 48.20 61.41 am-mod 96.64 92.00 94.26 am-neg 99.30 95.30 97.26 am-pnc 48.20 28.31 35.67 am-prd 50.00 30.00 37.50 am-tmp 87.87 73.43 80.00 r-a0 81.08 67.80 73.85 r-a1 77.50 49.60 60.49 r-a2 58.00 42.67 49.17 r-am-cau 100.00 25.00 40.00 r-am-ext 100.00 100.00 100.00 r-am-loc 100.00 55.00 70.97 r-am-mnr 50.00 25.00 33.33 r-am-tmp 85.71 52.94 65.46 table 3: top: overall performance result on datasets ; bottom: detail result on wsj data table 2 compares the performance of our method and other three famous kernels on wsj test data.</nextsent>
<nextsent>we implemented these three methods with the same settings described in the papers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE294">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in our implementation, we use wordnet::similarity package3(patwardhan et al., 2003) and the noun hierarchy of wordnet.
</prevsent>
<prevsent>in table 4, dep is the length of path from node to its global root, lso(c1, c2) represents the lowest super-ordinate of c1 and c2.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
the detail definitions can be found in (budanitsky and hirst, 2006) .<papid> J06-1003 </papid>as an alternative, latent semantic anal ysis(lsa) is technique.</citsent>
<aftsection>
<nextsent>it calculates the words similarities by means of occurrence of terms in documents.
</nextsent>
<nextsent>given term-bydocument matrix , its singular value decomposition is: = uv , where ? is diagonal matrix with singular values in decreasing arrangement.
</nextsent>
<nextsent>the column of are singular vectors corresponding to the individual singular value.
</nextsent>
<nextsent>then the latent semantic similarity kernel of terms ti and tj is: simlsa =  ik(u jk)t   (8) where uk = iku is to project onto its first dimensions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE295">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>and ik is the i-th row ofthe matrix uk.
</prevsent>
<prevsent>from equation (8), the lsa based similarity between two terms is the inner product of the two projected vectors.
</prevsent>
</prevsection>
<citsent citstr=" W01-0514 ">
the details of lsa can be found in (cristianini et al., 2002; choi et al, 2001).<papid> W01-0514 </papid></citsent>
<aftsection>
<nextsent>4.2.2 experiment resultsin this set of experiment, we evaluate different types of kernels for question classification(qc) task.
</nextsent>
<nextsent>the duty of qc is to categorize questions into different classes.
</nextsent>
<nextsent>in 3http://search.cpan.org/dist/wordnet-similarity 30 accuracy(%) 1000 2000 3000 4000 5500 bow 77.1 83.3 87.2 87.3 89.2 tk 80.2 86.2 87.4 88.6 91.2 latk 80.4 86.5 87.5 88.8 91.6 ? = 1 wup 81.3 87.3 88.0 89.8 92.5 res 81.0 87.1 87.9 89.5 92.2 lin 81.1 87.0 88.0 89.3 92.4 lsa(k = 50) 80.8 86.9 87.8 89.3 91.7 table 5: classification accuracy of different kernels on different data sets this paper we use the same dataset as introduced in(li and roth, 2002).<papid> C02-1150 </papid></nextsent>
<nextsent>the dataset is divided4 into 5500 questions for training and 500 questions from trec 20 for testing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE296">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>4.2.2 experiment resultsin this set of experiment, we evaluate different types of kernels for question classification(qc) task.
</prevsent>
<prevsent>the duty of qc is to categorize questions into different classes.
</prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
in 3http://search.cpan.org/dist/wordnet-similarity 30 accuracy(%) 1000 2000 3000 4000 5500 bow 77.1 83.3 87.2 87.3 89.2 tk 80.2 86.2 87.4 88.6 91.2 latk 80.4 86.5 87.5 88.8 91.6 ? = 1 wup 81.3 87.3 88.0 89.8 92.5 res 81.0 87.1 87.9 89.5 92.2 lin 81.1 87.0 88.0 89.3 92.4 lsa(k = 50) 80.8 86.9 87.8 89.3 91.7 table 5: classification accuracy of different kernels on different data sets this paper we use the same dataset as introduced in(li and roth, 2002).<papid> C02-1150 </papid></citsent>
<aftsection>
<nextsent>the dataset is divided4 into 5500 questions for training and 500 questions from trec 20 for testing.
</nextsent>
<nextsent>the total training samples are randomly divided into 5 subsets with sizes 1,000, 2,000, 3,000,4,000 and 5,500 respectively.
</nextsent>
<nextsent>all the questions are labeled into 6 coarse grained categories and 50 fine grained categories: abbreviations (abbreviation and expansion), entity(animal, body, color, creation, currency, medical, event, food, instrument, language, letter, plant, product, religion, sport, substance,symbol, technique, term, vehicle, word), description (definition, description, manner, rea son), human (description, group, individual, title), location (city, country, mountain, state) and numeric (code, count, date, distance,money, order, percent, period, speed, temperature, size, weight).in this paper, we compare the linear kernel based on bag-of-word (bow), the original tree kernel (tk), the local alignment tree kernel (section 3, latk) and its correspondences with lsa similarity and set of semantic enriched latk with different similarity metrics.
</nextsent>
<nextsent>to obtain the parse tree, we use charniakparser5 for every question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE297">
<title id=" W09-0204.xml">a study of convolution tree kernel with local alignment </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>finally experiments are carried ontwo different applications (semantic role labeling and question classification).for further work, we plan to study exploiting semantic knowledge in the kernel.
</prevsent>
<prevsent>a promising direction is to study the different effects of these semantic similarities.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
we are interested in some distributional similarities (lee, 1999) <papid> P99-1004 </papid>given certain context.</citsent>
<aftsection>
<nextsent>also theeffectivenss of the semantic-enriched tree kernel in srl is another problem.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE298">
<title id=" W09-1702.xml">utilizing contextually relevant terms in bilingual lexicon extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>discussion and conclusion are in section 6 and 7.
</prevsent>
<prevsent>respectively.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
koehn and knight (2002)<papid> W02-0902 </papid>describe few potential clues that may help in extracting bilingual lexicon from two monolingual corpora such as identical words, similar spelling, and similar context fea tures.</citsent>
<aftsection>
<nextsent>in reporting our work, we treat both identical word pairs and similar spelling word pairs as cog nate pairs.
</nextsent>
<nextsent>koehn and knight (2002)<papid> W02-0902 </papid>map 976 identical word pairs that are found in their two monolingual german-english corpora and report that 88.0percent of them are correct.</nextsent>
<nextsent>they propose to restrict the word length, at least of length 6, to in crease the accuracy of the collected word pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE318">
<title id=" W09-1702.xml">utilizing contextually relevant terms in bilingual lexicon extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>koehn and knight (2002)<papid> W02-0902 </papid>mention few related works that use different measurement to compute the similarity, such as longest common sub sequence ratio (melamed, 1995) and string edit distance (mann 10 and yarowski, 2001).</prevsent>
<prevsent>however, koehn and knight (2002)<papid> W02-0902 </papid>point out that majority of their word pairs do not show much resemblance at all since they use german-english language pair.</prevsent>
</prevsection>
<citsent citstr=" P08-1088 ">
haghighi et al(2008) <papid> P08-1088 </papid>mention one disadvantage of using edit distance, that is, precision quickly degrades with higher recall.</citsent>
<aftsection>
<nextsent>instead, they propose assigning feature to each substring of length of three or less for each word.
</nextsent>
<nextsent>for approaches based on contextual features or context similarity, we assume that for word that occurs in certain context, its translation equivalent also occurs in equivalent contexts.
</nextsent>
<nextsent>contextual features are the frequency counts of context words occurring in the surrounding of target word w. context vector for each is then constructed, with only context words found in the seed lexicon.
</nextsent>
<nextsent>the context vectors are then translated into the target language before their similarity is measured.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE321">
<title id=" W09-1702.xml">utilizing contextually relevant terms in bilingual lexicon extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>contextual features are the frequency counts of context words occurring in the surrounding of target word w. context vector for each is then constructed, with only context words found in the seed lexicon.
</prevsent>
<prevsent>the context vectors are then translated into the target language before their similarity is measured.
</prevsent>
</prevsection>
<citsent citstr=" P98-1069 ">
fung and yee (1998) <papid> P98-1069 </papid>point out that not only the number of common words in context gives some similarity clue to word and its translation, but the actual ranking of the context word frequencies also provides important clue to the similarity between bilingual word pair.</citsent>
<aftsection>
<nextsent>this fact has motivated fung and yee (1998) <papid> P98-1069 </papid>to use tfidf weighting to compute the vectors.</nextsent>
<nextsent>this idea is similar to rapp (1999) <papid> P99-1067 </papid>who proposed to transform all co-occurrence vectors using log likelihood ratio instead of just using the frequency counts of the co-occurrences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE325">
<title id=" W09-1702.xml">utilizing contextually relevant terms in bilingual lexicon extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>fung and yee (1998) <papid> P98-1069 </papid>point out that not only the number of common words in context gives some similarity clue to word and its translation, but the actual ranking of the context word frequencies also provides important clue to the similarity between bilingual word pair.</prevsent>
<prevsent>this fact has motivated fung and yee (1998) <papid> P98-1069 </papid>to use tfidf weighting to compute the vectors.</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
this idea is similar to rapp (1999) <papid> P99-1067 </papid>who proposed to transform all co-occurrence vectors using log likelihood ratio instead of just using the frequency counts of the co-occurrences.</citsent>
<aftsection>
<nextsent>these values are used to define whether the context words are highly associated with the or not.
</nextsent>
<nextsent>earlier work relies on large bilingual dictionary as their seed lexicon (rapp, 1999; <papid> P99-1067 </papid>fung and yee, 1998; <papid> P98-1069 </papid>among others).</nextsent>
<nextsent>koehn and knight (2002)<papid> W02-0902 </papid>present one interesting idea of using extracted cog nate pairs from corpus as the seed words in orderto alleviate the need of huge, initial bilingual lexicon.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE335">
<title id=" W09-1702.xml">utilizing contextually relevant terms in bilingual lexicon extraction </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we only take the first part, about 400k sentences of europarl spanish (year 1996 - 1999) and 2nd part, also about 400k from europarlenglish (year 2000 - 2003).
</prevsent>
<prevsent>we refer the particular part taken from the source language corpus as and the other part of the target language corpus as t.this approach is quite common in order to obtain non-parallel but comparable (or same domain)corpus.
</prevsent>
</prevsection>
<citsent citstr=" W04-3208 ">
examples can be found in fung and cheung (2004), <papid> W04-3208 </papid>followed by haghighi et al (2008).<papid> P08-1088 </papid></citsent>
<aftsection>
<nextsent>for corpus pre-processing, we only use sentence boundary detection and tokenization on raw text.we decided that large quantities of raw text requiring minimum processing could also be considered as minimal since they are inexpensive and not limited.
</nextsent>
<nextsent>these should contribute to low or medium density languages for which annotated resources are limited.
</nextsent>
<nextsent>we also clean all tags and filter out stop words from the corpus.
</nextsent>
<nextsent>4.2 evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE351">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated in both the french english and english-french news tasks.
</prevsent>
<prevsent>in these two tasks, we employ three individual mt system which are 1) baseline: phrase-based system (pb); 2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chun ker (gough and way, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
3) hpb: typical hierarchical phrase-based system (chiang, 2005).<papid> P05-1033 </papid>meanwhile, we also use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final result.</citsent>
<aftsection>
<nextsent>for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</nextsent>
<nextsent>we then build the cn using the ter metric (snover et al, 2006), and finally search and generate the translation.the remainder of this paper is organised as fol lows: section 2 details the various components ofour system, in particular the multi-engine strategies used for the shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE353">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated in both the french english and english-french news tasks.
</prevsent>
<prevsent>in these two tasks, we employ three individual mt system which are 1) baseline: phrase-based system (pb); 2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chun ker (gough and way, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
3) hpb: typical hierarchical phrase-based system (chiang, 2005).<papid> P05-1033 </papid>meanwhile, we also use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final result.</citsent>
<aftsection>
<nextsent>for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</nextsent>
<nextsent>we then build the cn using the ter metric (snover et al, 2006), and finally search and generate the translation.the remainder of this paper is organised as fol lows: section 2 details the various components ofour system, in particular the multi-engine strategies used for the shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE354">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these two tasks, we employ three individual mt system which are 1) baseline: phrase-based system (pb); 2) ebmt: monolingually chunking both source and target sides of the dataset using marker-based chun ker (gough and way, 2004).
</prevsent>
<prevsent>3) hpb: typical hierarchical phrase-based system (chiang, 2005).<papid> P05-1033 </papid>meanwhile, we also use word-level combination framework (rosti et al, 2007) <papid> N07-1029 </papid>to combine the multiple translation hypotheses and employ new rescoring model to generate the final result.</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
for the system combination task, we first use the minimum bayes-risk (mbr) (kumar and byrne, 2004) <papid> N04-1022 </papid>decoder to select the best hypothesis as the alignment reference for the confusion network (cn) (mangu et al, 2000).</citsent>
<aftsection>
<nextsent>we then build the cn using the ter metric (snover et al, 2006), and finally search and generate the translation.the remainder of this paper is organised as fol lows: section 2 details the various components ofour system, in particular the multi-engine strategies used for the shared task.
</nextsent>
<nextsent>in section 3, we outline the complete system setup for the shared task and provide results on the development and test sets.
</nextsent>
<nextsent>section 4 is our conclusion.
</nextsent>
<nextsent>2.1 system architecture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE357">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 system combination.
</prevsent>
<prevsent>for multiple system combination, we implement an mbr-cn framework as shown in figure 1.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
instead of using single system output as the skeleton, we employ minimum bayes-risk decoder to select the best single system output from th emerged -best list by minimizing the bleu (pa pineni et al, 2002) <papid> P02-1040 </papid>loss.</citsent>
<aftsection>
<nextsent>the confusion network is built by the output of mbr as the backbone which determines the word order of the combination.
</nextsent>
<nextsent>the other hypotheses are aligned against the backbone based on the ter metric.
</nextsent>
<nextsent>null words are allowed in the alignment.
</nextsent>
<nextsent>each arc in the cn represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE358">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>null words are allowed in the alignment.
</prevsent>
<prevsent>each arc in the cn represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the features we used are as follows: ? word posterior probability (fiscus, 1997); ? 3, 4-gram target language model; ? word length penalty; ? null word length penalty; also, we use mert (och, 2003) <papid> P03-1021 </papid>to tune the weights of confusion network.</citsent>
<aftsection>
<nextsent>2.5 rescore.
</nextsent>
<nextsent>rescore is very important part in post-processingwhich can select better hypothesis from the best list.
</nextsent>
<nextsent>we add some new global features inrescore model.
</nextsent>
<nextsent>the features we used are as fol lows: ? direct and inverse ibm model; ? 3, 4-gram target language model;?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE359">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>we add some new global features inrescore model.
</prevsent>
<prevsent>the features we used are as fol lows: ? direct and inverse ibm model; ? 3, 4-gram target language model;?
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
3, 4, 5-gram pos language model (ratna parkhi, 1996; <papid> W96-0213 </papid>schmid, 1994); 96 ? sentence length posterior probability (zens and ney, 2006);?</citsent>
<aftsection>
<nextsent>n -gram posterior probabilities within the best list (zens and ney, 2006); ? minimum bayes risk probability;?
</nextsent>
<nextsent>length ratio between source and target sen tence; the weights are optimized via mert algorithm.
</nextsent>
<nextsent>the following section describes the system and experimental setup for the french-english and english-french translation tasks.
</nextsent>
<nextsent>3.1 statistics of data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE360">
<title id=" W09-0416.xml">matrex the dcu mt system for wmt 2009 </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>however the sentence was dropped if the length ratio between english and french was larger than 1.5 or less than 0.67.
</prevsent>
<prevsent>3.3 system configuration.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
the two language models were done using thesrilm employing linear interpolation and modified k-n discounting (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>the configuration for the three systems is listed in table 3.
</nextsent>
<nextsent>system p-table length lm features baseline-e 55.9m 7 2 15 baseline-g 58.4m 7 2 15 ebmt 59.4m 7 2 15 hpb 122m 5 1 8 table 3: statistics of mt systems in this table, indicates the europarl corpus 97 which is used for all three systems, and stands for the giga corpus which is only used for the baseline system.
</nextsent>
<nextsent>we can see from table 3 that the size of the hpb phrase-table is more than 2 times as large as the other phrase tables.
</nextsent>
<nextsent>how to filter and process such huge hierarchical table is challenging problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE361">
<title id=" W09-0802.xml">the karamel system and semitic languages structured multitiered morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for natural language processing, it may be used for morphological analysis, transliteration, parsing, etc. this paper is dedicated to the application of karamel to the morphological analysis of semitic languages,for which both multiple tapes and complex structures are useful.
</prevsent>
<prevsent>some descriptions of the morphology of semitic languages use several tiers.
</prevsent>
</prevsection>
<citsent citstr=" W98-1007 ">
for instance, (mccarthy, 1981) uses four tiers, one for prefixes,one for the root, one for the template (consonantvowel pattern) and the last one for the vocaliza tion.such multi-tiered description may be implemented using cascade of 2-tape machines (beesley, 1998) <papid> W98-1007 </papid>or using multi-tape transducer where each tier is described by tape and the surface form by an additional tape.</citsent>
<aftsection>
<nextsent>this is the approach of g. a. kiraz for the syriac language (kiraz, 2000).<papid> J00-1006 </papid></nextsent>
<nextsent>karamel is designed for the later solu tion.the multi-tape feature is also interesting forde scribing related dialects, whenever great part ofthe analysis may be shared.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE362">
<title id=" W09-0802.xml">the karamel system and semitic languages structured multitiered morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some descriptions of the morphology of semitic languages use several tiers.
</prevsent>
<prevsent>for instance, (mccarthy, 1981) uses four tiers, one for prefixes,one for the root, one for the template (consonantvowel pattern) and the last one for the vocaliza tion.such multi-tiered description may be implemented using cascade of 2-tape machines (beesley, 1998) <papid> W98-1007 </papid>or using multi-tape transducer where each tier is described by tape and the surface form by an additional tape.</prevsent>
</prevsection>
<citsent citstr=" J00-1006 ">
this is the approach of g. a. kiraz for the syriac language (kiraz, 2000).<papid> J00-1006 </papid></citsent>
<aftsection>
<nextsent>karamel is designed for the later solu tion.the multi-tape feature is also interesting forde scribing related dialects, whenever great part ofthe analysis may be shared.
</nextsent>
<nextsent>a separate tape is dedicated to the surface form in each dialect.
</nextsent>
<nextsent>the semitic morphology is strongly structured by the roots.
</nextsent>
<nextsent>the basis of an analysis is the identification of the root.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE366">
<title id=" W09-0802.xml">the karamel system and semitic languages structured multitiered morphology </title>
<section> an example: the akkadian verb.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we compare karamelwith some of them which are specialized in morphological descriptions.
</prevsent>
<prevsent>the most popular system is probably the xerox finite state tool (beesley and karttunen, 2003).it has been used, among others, for the description of arabic morphology (beesley, 1998).<papid> W98-1007 </papid></prevsent>
</prevsection>
<citsent citstr=" P95-1003 ">
the interdigitation is handled using compile-replace process using the replace operator (karttunen and beesley, 2000) (karttunen, 1995).<papid> P95-1003 </papid></citsent>
<aftsection>
<nextsent>the computational model is sequential one, where two-tape transducers are merged using the 2there is akkadian verb with 3 weak consonants as root.composition operation.
</nextsent>
<nextsent>the descriptions are oriented, with an input and an output, but the transduction has not to be deterministic and the machines are invertible.
</nextsent>
<nextsent>the strings are not structured, but some structure may be marked using auxiliary symbols inserted when necessary by the user.
</nextsent>
<nextsent>in order to fulfill the constraints that there are only two tapes, grammars often put heterogeneous data on tape.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE367">
<title id=" W09-0802.xml">the karamel system and semitic languages structured multitiered morphology </title>
<section> an example: the akkadian verb.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, xfst is more efficient.the structure information is put only where necessary.
</prevsent>
<prevsent>xfst is distributed under commercial license.
</prevsent>
</prevsection>
<citsent citstr=" P06-1086 ">
the system magead is another system offinite-state morphology developed for arabic dialects (habash and rambow, 2006).<papid> P06-1086 </papid></citsent>
<aftsection>
<nextsent>it follows the multi-tape approach proposed by george anton kiraz for the syriac language (kiraz, 2000).<papid> J00-1006 </papid></nextsent>
<nextsent>it has rule-based language following the principles of (grimley-evans et al, 1996) in which notion of partition splits forms in sequence of units comparable to kara mels units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE374">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation on these tasks shows that the proposed approach is viable and can result inaccurate automatic annotations.
</prevsent>
<prevsent>in recent years, the integration of manually-built lexical resources into nlp systems has received growing interest.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
in particular, resources annotated with the surface realization of semantic roles, like framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmeret al , 2005) <papid> J05-1004 </papid>have shown to convey an improvement in several nlp tasks, from question answering (shen and lapata, 2007) <papid> D07-1002 </papid>to textual entailment(burchardt et al , 2007) <papid> W07-1402 </papid>and shallow semantic parsing (giuglea and moschitti, 2006).<papid> P06-1117 </papid></citsent>
<aftsection>
<nextsent>nonetheless, themain limitation of such resources is their poor coverage, particularly as regards framenet.
</nextsent>
<nextsent>indeed, the latest framenet release (v. 1.3) contains 10,195 lexical units (lus), 3,380 of which are described only by lexicographic definition without any example sentence.
</nextsent>
<nextsent>in order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with broader coverage.
</nextsent>
<nextsent>we believe that wordnet (fellbaum, 1998), with 210,000entries inversion 3.0, can represent suitable resource for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE375">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation on these tasks shows that the proposed approach is viable and can result inaccurate automatic annotations.
</prevsent>
<prevsent>in recent years, the integration of manually-built lexical resources into nlp systems has received growing interest.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
in particular, resources annotated with the surface realization of semantic roles, like framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmeret al , 2005) <papid> J05-1004 </papid>have shown to convey an improvement in several nlp tasks, from question answering (shen and lapata, 2007) <papid> D07-1002 </papid>to textual entailment(burchardt et al , 2007) <papid> W07-1402 </papid>and shallow semantic parsing (giuglea and moschitti, 2006).<papid> P06-1117 </papid></citsent>
<aftsection>
<nextsent>nonetheless, themain limitation of such resources is their poor coverage, particularly as regards framenet.
</nextsent>
<nextsent>indeed, the latest framenet release (v. 1.3) contains 10,195 lexical units (lus), 3,380 of which are described only by lexicographic definition without any example sentence.
</nextsent>
<nextsent>in order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with broader coverage.
</nextsent>
<nextsent>we believe that wordnet (fellbaum, 1998), with 210,000entries inversion 3.0, can represent suitable resource for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE376">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation on these tasks shows that the proposed approach is viable and can result inaccurate automatic annotations.
</prevsent>
<prevsent>in recent years, the integration of manually-built lexical resources into nlp systems has received growing interest.
</prevsent>
</prevsection>
<citsent citstr=" D07-1002 ">
in particular, resources annotated with the surface realization of semantic roles, like framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmeret al , 2005) <papid> J05-1004 </papid>have shown to convey an improvement in several nlp tasks, from question answering (shen and lapata, 2007) <papid> D07-1002 </papid>to textual entailment(burchardt et al , 2007) <papid> W07-1402 </papid>and shallow semantic parsing (giuglea and moschitti, 2006).<papid> P06-1117 </papid></citsent>
<aftsection>
<nextsent>nonetheless, themain limitation of such resources is their poor coverage, particularly as regards framenet.
</nextsent>
<nextsent>indeed, the latest framenet release (v. 1.3) contains 10,195 lexical units (lus), 3,380 of which are described only by lexicographic definition without any example sentence.
</nextsent>
<nextsent>in order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with broader coverage.
</nextsent>
<nextsent>we believe that wordnet (fellbaum, 1998), with 210,000entries inversion 3.0, can represent suitable resource for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE377">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation on these tasks shows that the proposed approach is viable and can result inaccurate automatic annotations.
</prevsent>
<prevsent>in recent years, the integration of manually-built lexical resources into nlp systems has received growing interest.
</prevsent>
</prevsection>
<citsent citstr=" W07-1402 ">
in particular, resources annotated with the surface realization of semantic roles, like framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmeret al , 2005) <papid> J05-1004 </papid>have shown to convey an improvement in several nlp tasks, from question answering (shen and lapata, 2007) <papid> D07-1002 </papid>to textual entailment(burchardt et al , 2007) <papid> W07-1402 </papid>and shallow semantic parsing (giuglea and moschitti, 2006).<papid> P06-1117 </papid></citsent>
<aftsection>
<nextsent>nonetheless, themain limitation of such resources is their poor coverage, particularly as regards framenet.
</nextsent>
<nextsent>indeed, the latest framenet release (v. 1.3) contains 10,195 lexical units (lus), 3,380 of which are described only by lexicographic definition without any example sentence.
</nextsent>
<nextsent>in order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with broader coverage.
</nextsent>
<nextsent>we believe that wordnet (fellbaum, 1998), with 210,000entries inversion 3.0, can represent suitable resource for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE379">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our evaluation on these tasks shows that the proposed approach is viable and can result inaccurate automatic annotations.
</prevsent>
<prevsent>in recent years, the integration of manually-built lexical resources into nlp systems has received growing interest.
</prevsent>
</prevsection>
<citsent citstr=" P06-1117 ">
in particular, resources annotated with the surface realization of semantic roles, like framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmeret al , 2005) <papid> J05-1004 </papid>have shown to convey an improvement in several nlp tasks, from question answering (shen and lapata, 2007) <papid> D07-1002 </papid>to textual entailment(burchardt et al , 2007) <papid> W07-1402 </papid>and shallow semantic parsing (giuglea and moschitti, 2006).<papid> P06-1117 </papid></citsent>
<aftsection>
<nextsent>nonetheless, themain limitation of such resources is their poor coverage, particularly as regards framenet.
</nextsent>
<nextsent>indeed, the latest framenet release (v. 1.3) contains 10,195 lexical units (lus), 3,380 of which are described only by lexicographic definition without any example sentence.
</nextsent>
<nextsent>in order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with broader coverage.
</nextsent>
<nextsent>we believe that wordnet (fellbaum, 1998), with 210,000entries inversion 3.0, can represent suitable resource for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE381">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several experiments have been carried out to develop framenet-wordnet mapping and test its applications.
</prevsent>
<prevsent>shi and mihalcea (2005) described semi-automatic approach to exploit verbnet as bridge between framenet and wordnet for verbs,using synonym and hyponym relations and similarity between levins verb classes and framenetframes.
</prevsent>
</prevsection>
<citsent citstr=" N04-3006 ">
their mapping was used to develop rule based semantic parser (shi and mihalcea, 2004) <papid> N04-3006 </papid>as well as to detect target words and assign frames for verbs in an open text (honnibal and hawker, 2005).</citsent>
<aftsection>
<nextsent>burchardt et al  (2005) presented rule-based system for the assignment of framenet frames by way of detour via wordnet?.
</nextsent>
<nextsent>they applied wordnet-based wsd system to annotate lexical units in unseen texts with their contextually determined wordnet synsets and then exploited synonyms and hypernyms information to assign the best frame to the lexical units.
</nextsent>
<nextsent>the system was integrated into the salsa rte system for textual entailment (burchardt et al , 2007) <papid> W07-1402 </papid>to cope with sparse data problems in the automatic assignment of frame labels.</nextsent>
<nextsent>johansson and nugues (2007) created feature representation for every wordnet lemma and used it to train an svm classifier for each frame that tells whether lemma belongs to the frame or not.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE384">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>johansson and nugues (2007) created feature representation for every wordnet lemma and used it to train an svm classifier for each frame that tells whether lemma belongs to the frame or not.
</prevsent>
<prevsent>thebest-performing feature representation was built using the sequence of unique identifiers for each synsetin its hypernym tree and weigthing the synsets according to their relative frequency in the semcor corpus.
</prevsent>
</prevsection>
<citsent citstr=" W07-2018 ">
they used the mapping in the semeval-2007 task on frame-semantic structure extraction (baker et al , 2007) <papid> W07-2018 </papid>in order to find target words in open text and assign frames.crespo and buitelaar (2008) carried out an automatic mapping of medical-oriented frames to wordnet synsets applying statistical hypothesis testing to select synsets attached to lexical unit that were statistically significant using given reference corpus.</citsent>
<aftsection>
<nextsent>the mapping obtained was used to expand spanish framenet using euro wordnet (vossen, 1998) and evaluation was carried out on the spanish lexical units obtained after mapping.
</nextsent>
<nextsent>given set of lexical units, de cao et al  (2008)propose method to detect the set of suitable wordnet senses able to evoke frame by applying similarity function that exploits different wordnet information, namely conceptual density for nouns, syn onymy and co-hyponymy for verbs and synonymy for adjectives.
</nextsent>
<nextsent>the mapping approach was applied also to lu induction for the english framenet and for italian frames via multiwordnet.
</nextsent>
<nextsent>our objective is to be able to assign to every lexical unit l, belonging to frame fi defined in the framenet database, one or more wordnet senses that best express the meaning of l. more specifically, for every ? fi, we consider the set of all wordnet senses where appears, candset, and then find the best wordnet sense(s) bests ? candset that express the meaning of l. for example, the lexical unit rouse.v belonging to the cause to wake frame, is defined in frame netas bring out of sleep; awaken?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE385">
<title id=" W09-1127.xml">new features for framenet  wordnet mapping </title>
<section> feature description.  </section>
<citcontext>
<prevsection>
<prevsent>allcandset, 6= j, then we add another boolean feature to encode this information.
</prevsent>
<prevsent>cross-lingual parallelism our idea is that, if an english lexical unit and its italian translation belong to the same frame, they are likely to appear also in the same multi wordnet synset, and the latter wouldbe good candidate for mapping.
</prevsent>
</prevsection>
<citsent citstr=" L08-1550 ">
in fact, in multi wordnet the italian wordnet is strictly aligned with the princeton wordnet 1.6, with synsets having thesame id for both languages, and also semantic relations are preserved in the multilingual hierarchy.since no italian framenet is available yet, we extended the parallel english-italian corpus annotated on both sides with frame information described in tonelli and pianta (2008) <papid> L08-1550 </papid>by adding and annotating400 new parallel sentences.</citsent>
<aftsection>
<nextsent>the final corpus contains about 1,000 pairs of parallel sentences where the english and the italian lexical unit belong to the same frame.
</nextsent>
<nextsent>given pair l, s?, we check if appears also in the corpus with the frame label fi and extract its italian translation lit.
</nextsent>
<nextsent>if lit appears also in the italian version of synset in multi wordnet, we consider as good candidate for the mapping of and encode this information as binary feature.
</nextsent>
<nextsent>simple synset-frame overlap intuitively, the more lemmas frame and synset have in common, the more semantically similar they are.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE386">
<title id=" W09-0403.xml">a simple automatic mt evaluation metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper also includes evaluation on the data from the previous smt workshop for several language pairs.
</prevsent>
<prevsent>the problem of finding reliable machine translation metrics corresponding with human judgment has recently returned to the centre of attention.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
after brief period following the introduction of generally accepted and widely used metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and nist (dod dington, 2002), when it seemed that this persistent problem has finally been solved, the researchers active in the field of machine translation (mt) started to express their worries that although these metrics are simple, fast and able to provide consistent results for particular system during its development, they are not sufficiently reliable for the comparison of different systems or different language pairs.</citsent>
<aftsection>
<nextsent>the results of the nist evaluation in 2005 (le and przybocki, 2005) have also strengthened the suspicion that the correlation between human judgment and the bleu and nist measures is notas strong as it was widely believed.
</nextsent>
<nextsent>both measures seem to favor the mt output created by systems based on n-gram architecture, they are unable to take into account certain factors which are very important for the human judges of translation quality.the article (callison-burch et al, 2006) thoroughly discusses the deficits of the bleu and similar metrics.
</nextsent>
<nextsent>the authors claim that the existing automatic metrics, including some of the new and seemingly more reliable ones as e.g. meteor (cf.
</nextsent>
<nextsent>(banerjee and lavie, 2005)) ?.<papid> W05-0909 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE387">
<title id=" W09-0403.xml">a simple automatic mt evaluation metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both measures seem to favor the mt output created by systems based on n-gram architecture, they are unable to take into account certain factors which are very important for the human judges of translation quality.the article (callison-burch et al, 2006) thoroughly discusses the deficits of the bleu and similar metrics.
</prevsent>
<prevsent>the authors claim that the existing automatic metrics, including some of the new and seemingly more reliable ones as e.g. meteor (cf.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
(banerjee and lavie, 2005)) ?.<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>they are all quite rough measures of translation similarity, and have inexact models of allowable variation in transla tion.?
</nextsent>
<nextsent>this claim is supported by construction of translation variations which have identical bleu score, but which are very different for humanjudge.
</nextsent>
<nextsent>the authors identify three prominent factors which contribute to the inadequacy of bleu ? the failure to deal with synonyms and paraphrases, no penalties for missing content, and the crudeness of the brevity penalty.let us add some more factors based on our experiments with languages typo logically different than english, arabic or chinese, which are probably the languages most frequently used in recent shared-task mt evaluations.
</nextsent>
<nextsent>the highly inflected languages and languages with higher degree ofword-order freedom may provide additional examples of sentences in which relatively small alterations of correct word forms may have dire effect on the bleu score while the sentence still remains understandable and acceptable for human evaluators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE388">
<title id=" W09-0403.xml">a simple automatic mt evaluation metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, the matching algorithm of trados gives results which to great extent correspond to much simpler traditional metric, to the lev enshteins edit distance.
</prevsent>
<prevsent>the use of this metric may help to refine very strict treatment of word form differences by bleu.
</prevsent>
</prevsection>
<citsent citstr=" W08-0312 ">
a similar approach at the level of unigram matching has been used by the well-known meteor metric (agarwal and lavie, 2008), <papid> W08-0312 </papid>which proved its qualities during the previous mt evaluation task in 2008 (callison burch et al, 2008).</citsent>
<aftsection>
<nextsent>meteor uses porter stemmer as one step in the word alignment algorithm.
</nextsent>
<nextsent>it also relies on synonymy relations in wordnet.
</nextsent>
<nextsent>when designing our metric, we have decided to follow two general strategies ? to use as simple means as possible and to avoid using any language dependent tools or resources.
</nextsent>
<nextsent>levenshtein metric (or its modification for word-level edit distance)therefore seemed to be the best candidate for several aspects of the proposed measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE389">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we address the question of the suitability of the stanford scheme for parser evaluation.
</prevsent>
<prevsent>the stanford typed dependencies representation was designed to provide simple description of the grammatical relationships in sentence that could easily be understood and effectively used by people without linguistic expertise who wanted to extract textual relations.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
the representation was not designed for the purpose of parser evaluation.nevertheless, we agree with the widespread sentiment that dependency-based evaluation of parsers avoids many of the problems of the traditional parseval measures (black et al, 1991), <papid> H91-1060 </papid>and to the extent that the stanford dependency representation is an effective representation for the tasks envisioned, it is perhaps closer to an appropriate task based evaluation than some of the alternative dependency representations available.</citsent>
<aftsection>
<nextsent>in this paper ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>we examine the representation and its underlying design principles, look at how this representation compares with other dependency representation sin ways that reflect the design principles, and consider its suitability for parser evaluation.a major problem for the natural language processing (nlp) community is how to make the very impressive and practical technology which has been developed over the last two decades approachable to and usable by everyone who has text understanding needs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE390">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we examine the representation and its underlying design principles, look at how this representation compares with other dependency representation sin ways that reflect the design principles, and consider its suitability for parser evaluation.a major problem for the natural language processing (nlp) community is how to make the very impressive and practical technology which has been developed over the last two decades approachable to and usable by everyone who has text understanding needs.
</prevsent>
<prevsent>that is, usable not only by computational linguists, but also by the computer science community more generally and by all sorts of information professionals including biologists, medical researchers, political scientists, law firms, business and market analysts, etc. thinking about this issue, we were struck by two facts.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
first, we noted how frequently wordnet (fellbaum, 1998) gets used compared to other resources, such as framenet (fillmore et al, 2003) or the penn tree bank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>we believe that muchof the explanation for this fact lies in the difference of complexity of the representation used by the resources.
</nextsent>
<nextsent>it is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of wordnet.
</nextsent>
<nextsent>second, we noted the widespread use of mini par (lin, 1998) and the link parser (sleator and temperley, 1993).
</nextsent>
<nextsent>this clearly shows that (i) it isvery easy for non-linguist thinking in relation extraction terms to see how to make use of dependency representation (whereas phrase structure representation seems much more foreign and for bidding), and (ii) the availability of high quality, easy-to-use (and preferably free) tools is essential for driving broader use of nlp tools.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE391">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the representation aimsto provide simple, habitable design.
</prevsent>
<prevsent>all information is represented as binary relations.
</prevsent>
</prevsection>
<citsent citstr=" P01-1052 ">
this maps straightforwardly on to common representations of potential users, including the logic forms of moldovan andrus (moldovan andrus, 2001), <papid> P01-1052 </papid>2 semantic web resource description framework (rdf) triples (http://www.w3.org/rdf/), and graph representations (with labeled edges and nodes).unlike many linguistic formalisms, excessive detail is viewed as defect: information that users donot understand or wish to process detracts from uptake and usability.</citsent>
<aftsection>
<nextsent>the user-centered design process saw the key goal as representing semantically content ful relations suitable for relation extraction and more general information extraction uses.
</nextsent>
<nextsent>the design supports this use by favoring relations between content words, by maintaining semantically useful closed class word information while ignoring linguistic decisions less relevant to users, andby not representing less used material about linguistic features such as tense and agreement.
</nextsent>
<nextsent>thesd scheme thus provides semantic representation simple and natural enough for people who are not (computational) linguists but can benefit from nlp tools.
</nextsent>
<nextsent>2.1 design principles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE392">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> stanford dependencies in practice.  </section>
<citcontext>
<prevsection>
<prevsent>5
</prevsent>
<prevsent>sd has been successfully used by researchers in different domains.
</prevsent>
</prevsection>
<citsent citstr=" P04-1042 ">
in the pascal recognizing 5 as possible future work, we have thought of using tool such as the one of levy and manning (2004) <papid> P04-1042 </papid>to correctly determine long distance dependencies, as input to the current dependency conversion system.</citsent>
<aftsection>
<nextsent>this would presumably be effective, but would make the conversion process much heavier weight.
</nextsent>
<nextsent>5 textual entailment (rte) challenges (dagan et al, 2006; giampiccolo et al, 2007), <papid> W07-1401 </papid>the increase in the use of sd is clearly apparent.</nextsent>
<nextsent>the goal in these challenges consists of identifying whether one sentence follows from piece of text and general background knowledge, according to the intuitions of an intelligent human reader.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE393">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> stanford dependencies in practice.  </section>
<citcontext>
<prevsection>
<prevsent>in the pascal recognizing 5 as possible future work, we have thought of using tool such as the one of levy and manning (2004) <papid> P04-1042 </papid>to correctly determine long distance dependencies, as input to the current dependency conversion system.</prevsent>
<prevsent>this would presumably be effective, but would make the conversion process much heavier weight.</prevsent>
</prevsection>
<citsent citstr=" W07-1401 ">
5 textual entailment (rte) challenges (dagan et al, 2006; giampiccolo et al, 2007), <papid> W07-1401 </papid>the increase in the use of sd is clearly apparent.</citsent>
<aftsection>
<nextsent>the goal in these challenges consists of identifying whether one sentence follows from piece of text and general background knowledge, according to the intuitions of an intelligent human reader.
</nextsent>
<nextsent>in 2007, outof the 21 systems which participated in the challenge, 5 used the sd representation, whereas the year before only the stanford entry was using it.
</nextsent>
<nextsent>sd is also widely present in the bioinformatic world where it is used with success (erkan et al, 2007; <papid> D07-1024 </papid>greenwood and stevenson, 2007; urbain et al., 2007; clegg, 2008).</nextsent>
<nextsent>fundel et al (2007) found that, in extraction of relations between genes and proteins, system based on the sd scheme greatly outperformed the previous best system on the lll challenge dataset (by an 18% absolute improvement in f-measure).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE394">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> stanford dependencies in practice.  </section>
<citcontext>
<prevsection>
<prevsent>the goal in these challenges consists of identifying whether one sentence follows from piece of text and general background knowledge, according to the intuitions of an intelligent human reader.
</prevsent>
<prevsent>in 2007, outof the 21 systems which participated in the challenge, 5 used the sd representation, whereas the year before only the stanford entry was using it.
</prevsent>
</prevsection>
<citsent citstr=" D07-1024 ">
sd is also widely present in the bioinformatic world where it is used with success (erkan et al, 2007; <papid> D07-1024 </papid>greenwood and stevenson, 2007; urbain et al., 2007; clegg, 2008).</citsent>
<aftsection>
<nextsent>fundel et al (2007) found that, in extraction of relations between genes and proteins, system based on the sd scheme greatly outperformed the previous best system on the lll challenge dataset (by an 18% absolute improvement in f-measure).
</nextsent>
<nextsent>airola et al (2008) <papid> W08-0601 </papid>provide more systematic results on number of protein protein interaction datasets.</nextsent>
<nextsent>their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE395">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> stanford dependencies in practice.  </section>
<citcontext>
<prevsection>
<prevsent>sd is also widely present in the bioinformatic world where it is used with success (erkan et al, 2007; <papid> D07-1024 </papid>greenwood and stevenson, 2007; urbain et al., 2007; clegg, 2008).</prevsent>
<prevsent>fundel et al (2007) found that, in extraction of relations between genes and proteins, system based on the sd scheme greatly outperformed the previous best system on the lll challenge dataset (by an 18% absolute improvement in f-measure).</prevsent>
</prevsection>
<citsent citstr=" W08-0601 ">
airola et al (2008) <papid> W08-0601 </papid>provide more systematic results on number of protein protein interaction datasets.</citsent>
<aftsection>
<nextsent>their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs.
</nextsent>
<nextsent>their system is based on the sd scheme, and they demonstrate state-of-the-art performance for this approach.
</nextsent>
<nextsent>in the biomedical domain, sd has recently been used in evaluations of parsers (clegg and shepherd, 2007; pyysalo et al, 2007<papid> W07-1004 </papid>a).</nextsent>
<nextsent>pyysalo et al (2007<papid> W07-1004 </papid>a) assessed the suitability of the sd scheme over the link grammar dependency scheme in an application-oriented evaluation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE396">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> stanford dependencies in practice.  </section>
<citcontext>
<prevsection>
<prevsent>their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs.
</prevsent>
<prevsent>their system is based on the sd scheme, and they demonstrate state-of-the-art performance for this approach.
</prevsent>
</prevsection>
<citsent citstr=" W07-1004 ">
in the biomedical domain, sd has recently been used in evaluations of parsers (clegg and shepherd, 2007; pyysalo et al, 2007<papid> W07-1004 </papid>a).</citsent>
<aftsection>
<nextsent>pyysalo et al (2007<papid> W07-1004 </papid>a) assessed the suitability of the sd scheme over the link grammar dependency scheme in an application-oriented evaluation.</nextsent>
<nextsent>the link parser indeed uses very fine-grained set of relations, which often makes distinctions of structural rather than semantic nature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE407">
<title id=" W08-1301.xml">the stanford typed dependencies representation </title>
<section> suitability for parser evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to do so, they used the sd scheme, which provides de facto standard for comparing variety of constituent parsers and treebanks at the dependency level,?
</prevsent>
<prevsent>and they assessed its suitability for evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
they found that the sd scheme better illuminates the performance differences between higher ranked parsers (e.g., charniak-lease parser (lease and charniak, 2005)), and lower ranked parsers (e.g., the stanford parser (klein and manning, 2003)).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>their parser evaluation accommodates user needs: they used the collapsed version of the dependency graphs offered by the sd scheme, arguing that this is the kind of graph one would find most useful in an information extraction project.
</nextsent>
<nextsent>although clegg and shepherd (2007) also favor dependency graph representations for parser evaluation, they advocate retention of parse trees so information lost in the dependency structures can be accessed.
</nextsent>
<nextsent>in essence, any existing dependency scheme could be adopted as the gold-standard for evaluation.
</nextsent>
<nextsent>however if one believes in ultimately valuing extrinsic task-based evaluation, dependency representation which proposes suitable design for users and user tasks is probably the best surrogate for intrinsic evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE408">
<title id=" W08-1605.xml">personalized interactive question answering on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
<prevsent>some rights reserved.
</prevsent>
</prevsection>
<citsent citstr=" W03-1206 ">
been proposed, which involves the integration of qasystems with dialogue interfaces in order to encourage and accommodate the submission of multiple related questions and handle the users requests for clarification in less artificial setting (maybury, 2002); however, interactive qa (iqa) systems are still at an early stage or applied to closed domains (small et al,2003; <papid> W03-1206 </papid>kato et al, 2006).<papid> W06-3002 </papid></citsent>
<aftsection>
<nextsent>also, the complex, interactive qa?
</nextsent>
<nextsent>trec track (www.umiacs.umd.edu/ ? jimmylin/ciqa/) has been organized, but herethe interactive aspect refers to the evaluators being enabled to interact with the systems rather than to dialogue perse.
</nextsent>
<nextsent>in this paper, we first present an adaptation of user modelling (kobsa, 2001) to the design of personalizedqa, and secondly we design and implement an interactive open-domain qa system, yourqa.
</nextsent>
<nextsent>section 2 briefly introduces the baseline architecture of yourqa.in section 3, we show how model of the users reading abilities and personal interests can be used to efficiently improve the quality of the information returned by qa system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE409">
<title id=" W08-1605.xml">personalized interactive question answering on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
<prevsent>some rights reserved.
</prevsent>
</prevsection>
<citsent citstr=" W06-3002 ">
been proposed, which involves the integration of qasystems with dialogue interfaces in order to encourage and accommodate the submission of multiple related questions and handle the users requests for clarification in less artificial setting (maybury, 2002); however, interactive qa (iqa) systems are still at an early stage or applied to closed domains (small et al,2003; <papid> W03-1206 </papid>kato et al, 2006).<papid> W06-3002 </papid></citsent>
<aftsection>
<nextsent>also, the complex, interactive qa?
</nextsent>
<nextsent>trec track (www.umiacs.umd.edu/ ? jimmylin/ciqa/) has been organized, but herethe interactive aspect refers to the evaluators being enabled to interact with the systems rather than to dialogue perse.
</nextsent>
<nextsent>in this paper, we first present an adaptation of user modelling (kobsa, 2001) to the design of personalizedqa, and secondly we design and implement an interactive open-domain qa system, yourqa.
</nextsent>
<nextsent>section 2 briefly introduces the baseline architecture of yourqa.in section 3, we show how model of the users reading abilities and personal interests can be used to efficiently improve the quality of the information returned by qa system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE410">
<title id=" W08-1605.xml">personalized interactive question answering on the web </title>
<section> baseline system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>thisis for two reasons: we believe that providing context to the exact answer is important and we have been mostly focusing on non-factoids, such as definitions,which it makes sense to provide in the form of sentence.
</prevsent>
<prevsent>a thorough evaluation of yourqa is reported in e.g.
</prevsent>
</prevsection>
<citsent citstr=" P07-1098 ">
(moschitti et al, 2007); <papid> P07-1098 </papid>it shows an f1 of 48?.7 for non-factoids on web data, further improved by svm-based re-ranker.in the following sections, we describe how the baseline architecture is enhanced to accommodate personalization and interactivity.</citsent>
<aftsection>
<nextsent>our model of personalization is centered on user model which represents students searching for information on the web according to three attributes: 1.
</nextsent>
<nextsent>age range ? {7?
</nextsent>
<nextsent>10, 11?
</nextsent>
<nextsent>16, adult}, 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE411">
<title id=" W08-1605.xml">personalized interactive question answering on the web </title>
<section> interactivity.  </section>
<citcontext>
<prevsection>
<prevsent>among traditional methods for implementinginformation-seeking dialogue management, finite state (fs) approaches are the simplest.
</prevsent>
<prevsent>here, the dialogue manager is represented as finite-state machine, where each state models separate phase of the conversation, and each dialogue move encodes transition to subsequent state (sutton, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W00-0302 ">
however, an issue with fs models is that they allow very limited freedom in the range of user utterances: since each dialogue move must be pre-encoded in the models, there is scala bility issue when addressing open domain dialogue.on the other hand, we believe that other dialogue approaches such as the information state (is) (larsson et al., 2000) <papid> W00-0302 </papid>are primarily suited to applications requiring planning component such as closed-domain dialogue systems and to lesser extent to open-domain qa.as an alternative approach, we studied conversational agents (chatbots?)</citsent>
<aftsection>
<nextsent>based on aiml (artificial intelligence markup language), such as alice 6 . chat-.
</nextsent>
<nextsent>bots are based on the pattern matching technique, which consists in matching the last user utterance against arange of dialogue patterns known to the system.
</nextsent>
<nextsent>a coherent answer is created by following range of tem plate?
</nextsent>
<nextsent>responses associated with such patterns.as its primary application is small-talk, chatbot dialogue appears more natural than in fs and is systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE412">
<title id=" W08-1408.xml">story tracking linking similar news over time and across languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>identified in the previous weeks and months.
</prevsent>
<prevsent>in our jargon, stories are thus groups of articles talking about similar event or theme over time.
</prevsent>
</prevsection>
<citsent citstr=" C04-1138 ">
we work with the daily clusters computed by the news explorer application (pouliquen et al 2004).<papid> C04-1138 </papid></citsent>
<aftsection>
<nextsent>for each daily cluster in currently nineteen languages, the similarity to all clusters produced during the previous seven days is computed and link is established if the similarity is above certain threshold.
</nextsent>
<nextsent>it is on the basis of these individual links that stories are built, i.e. longer chains of news clusters related over time.
</nextsent>
<nextsent>the current news explorer application additionally identifies for all news clusters, whether there are related clusters in the other languages.
</nextsent>
<nextsent>these daily cross-lingual links are used to link the longer-lasting stories across languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE420">
<title id=" W08-2007.xml">semantic structure from correspondence analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the structure that ca discovers may be an important step in representing similarity.
</prevsent>
<prevsent>we have performed an analysis for italian verbs and nouns, and confirmed that similar structures are found for english.
</prevsent>
</prevsection>
<citsent citstr=" W06-3812 ">
over the past years, distributional methods have been used to explore the semantic behaviour ofverbs, looking at their contexts in corpora (lan dauer and laham, 1998; redington and finch,1998; biemann, 2006, <papid> W06-3812 </papid>inter al.).</citsent>
<aftsection>
<nextsent>we follow general approach suggested already by firth (1957), to associate distributional similarity with semantic similarity.one question concerns the syntax-semantics interface.
</nextsent>
<nextsent>results using distributions of verbs in context had an impact on verb classification (levin, 1993), automatic verb clustering (schulte imwalde, 2003), and selectional preference acquisition (resnik, 1993; li and abe, 1995; mccarthy, 2001; agirre and martinez, 2001, <papid> W01-0703 </papid>inter al.).in automatic verb clustering, verbs are represented by vectors of multidimensional space whose dimensions (variables) are identified by some linguistic features, ranging, for example, from subcategorization frames to participation in ? 2008.</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE421">
<title id=" W08-2007.xml">semantic structure from correspondence analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>over the past years, distributional methods have been used to explore the semantic behaviour ofverbs, looking at their contexts in corpora (lan dauer and laham, 1998; redington and finch,1998; biemann, 2006, <papid> W06-3812 </papid>inter al.).</prevsent>
<prevsent>we follow general approach suggested already by firth (1957), to associate distributional similarity with semantic similarity.one question concerns the syntax-semantics interface.</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
results using distributions of verbs in context had an impact on verb classification (levin, 1993), automatic verb clustering (schulte imwalde, 2003), and selectional preference acquisition (resnik, 1993; li and abe, 1995; mccarthy, 2001; agirre and martinez, 2001, <papid> W01-0703 </papid>inter al.).in automatic verb clustering, verbs are represented by vectors of multidimensional space whose dimensions (variables) are identified by some linguistic features, ranging, for example, from subcategorization frames to participation in ? 2008.</citsent>
<aftsection>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.diathesis alternations and lexical selectional preferences.
</nextsent>
<nextsent>the verbs cluster on co-occurrence with the features chosen, and such information provide generalisation over the verbs with respect to the variables.
</nextsent>
<nextsent>in the case of selectional preference acquisition, verb (or verb class) is associated to class of nouns that can be the lexical fillers of case frame slot for the verb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE422">
<title id=" W08-2007.xml">semantic structure from correspondence analysis </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the main dimensions of the italian corpus are topical (crime related vs. natural catastrophes, and laws vs. political institutions).
</prevsent>
<prevsent>semantic relatedness were observed in closely mapped words.
</prevsent>
</prevsection>
<citsent citstr=" P06-1117 ">
both global and local structure is found, and we can speculate that this helps representing lexical units in semantic labeling (giuglea and moschitti, 2006) <papid> P06-1117 </papid>for machine learning tasks.</citsent>
<aftsection>
<nextsent>we can conceptualize text graphs in two distinct usages: knowledge re-presenting (e.g. framenet) and visualizing relations in dataset.
</nextsent>
<nextsent>our method belongs in the second category.
</nextsent>
<nextsent>acknowledgements the first author is multi lingua fellow at uni.
</nextsent>
<nextsent>bergen, financially supported by marie curie action (european commission).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE423">
<title id=" W09-1415.xml">a multi phase approach to biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it is still not easy for researchers to access necessary information quickly since it is lost within large volumes of text.
</prevsent>
<prevsent>this is the reason that the study of information extraction is receiving the attention of biomedical and natural language processing (nlp) researchers today.in the shared task, the organizers provide participants with raw biomedical text, tagged biomedical terms (proteins), and the analyzed data with various nlp techniques such as tokenization, pos-tagging, phrase structure and dependency parsing and so on.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the expected results are the events, which exist inthe given text, consisting of trigger and its partici pant(s) (kim et al, 2009).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>the proposed system consists of three phases; event trigger detection phase(td phase), event type classification phase(tc phase), relation recognition and event composition phase(re phase).
</nextsent>
<nextsent>it works in the following manner.
</nextsent>
<nextsent>firstly, it identifies triggers ofa given biomedical sentence.
</nextsent>
<nextsent>then, it classifies triggers into nine pre-defined classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE424">
<title id=" W09-1415.xml">a multi phase approach to biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lastly, the system finds the relations between triggers and participant candidates by examining each trigger whether it has relations with participant candidates, and composites events with the extracted relations.
</prevsent>
<prevsent>in the last phase, multiple relations of the same trigger can be combined into an event for binding eventtype.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
in addition, multiple relations can be combined and their participant types can be classified into not only theme but also cause for three regulation event types.in this paper, we mainly use dependency parsing information of the analyzed data because several previous studies for srl have improved their performance by using features extracted from this information (hacioglu, 2004; <papid> C04-1186 </papid>tsai et al, 2006).<papid> W06-3308 </papid></citsent>
<aftsection>
<nextsent>in the experimental results, the proposed system showed 68.46 f-score in td phase, 85.20 accuracy in tc phase, 89.91 f-score in the initial step of re phase and 81.24 f-score in the iterative step of re phase, but officially achieved 61.65 precision, 9.40recall and 16.31 f-score in approximate span matching.
</nextsent>
<nextsent>these figures were the lowest among twenty four shared-task participants.
</nextsent>
<nextsent>however, we found that the threshold tuning for re phase had caused negative effect.
</nextsent>
<nextsent>it deteriorates the f-score of the 107 event trigger detector event type classifier relation recognizer &amp; event compositor initial step iterative step source data analyzed data result of event extraction figure 1: system architecture proposed system by enlarging the gap between precision and recall.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE426">
<title id=" W09-1415.xml">a multi phase approach to biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lastly, the system finds the relations between triggers and participant candidates by examining each trigger whether it has relations with participant candidates, and composites events with the extracted relations.
</prevsent>
<prevsent>in the last phase, multiple relations of the same trigger can be combined into an event for binding eventtype.
</prevsent>
</prevsection>
<citsent citstr=" W06-3308 ">
in addition, multiple relations can be combined and their participant types can be classified into not only theme but also cause for three regulation event types.in this paper, we mainly use dependency parsing information of the analyzed data because several previous studies for srl have improved their performance by using features extracted from this information (hacioglu, 2004; <papid> C04-1186 </papid>tsai et al, 2006).<papid> W06-3308 </papid></citsent>
<aftsection>
<nextsent>in the experimental results, the proposed system showed 68.46 f-score in td phase, 85.20 accuracy in tc phase, 89.91 f-score in the initial step of re phase and 81.24 f-score in the iterative step of re phase, but officially achieved 61.65 precision, 9.40recall and 16.31 f-score in approximate span matching.
</nextsent>
<nextsent>these figures were the lowest among twenty four shared-task participants.
</nextsent>
<nextsent>however, we found that the threshold tuning for re phase had caused negative effect.
</nextsent>
<nextsent>it deteriorates the f-score of the 107 event trigger detector event type classifier relation recognizer &amp; event compositor initial step iterative step source data analyzed data result of event extraction figure 1: system architecture proposed system by enlarging the gap between precision and recall.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE430">
<title id=" W09-1415.xml">a multi phase approach to biomedical event extraction </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>filter out tokens that are biomedical named entity.?
</prevsent>
<prevsent>filter out sentences that do not have any proteins.
</prevsent>
</prevsection>
<citsent citstr=" W06-0901 ">
proposed features for the binary classification of tokens include both features similar to those used in (hacioglu, 2004; <papid> C04-1186 </papid>tsai et al, 2006; <papid> W06-3308 </papid>ahn, 2006) <papid> W06-0901 </papid>and novel ones.</citsent>
<aftsection>
<nextsent>the selected feature set is showed in table 1.
</nextsent>
<nextsent>2.2 event type classification.
</nextsent>
<nextsent>in tc phase, tokens recognized as trigger are classified into nine pre-defined classes.
</nextsent>
<nextsent>although more than dozen features had been tested, the features except word and lemma features hardly contributed to the performance improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE432">
<title id=" W08-1601.xml">semantic chunk annotation for complex questions using conditional random field </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the early research efforts and evaluations in q&a; were focused mainly on factoid questions asking for named entities, such as time, numbers, and locations and so on.
</prevsent>
<prevsent>the questions in the test corpus of trec and other organizations are also in short and simple form.
</prevsent>
</prevsection>
<citsent citstr=" W01-1203 ">
complex hierarchy in question types (dragomir radev et al 2001), question templates (min-yuh day et al 2005), question parsing (ulf hermjakob, 2001) <papid> W01-1203 </papid>and various machine learning methods (dell zhang and wee sun lee, 2003)are used for factoid question analysis, aiming to find what named entity is asked in the question.</citsent>
<aftsection>
<nextsent>there are some questions which are very complicated or even need domain restricted knowledge and reasoning technique.
</nextsent>
<nextsent>automatic q&a; system can not deal with such questions with current technique.
</nextsent>
<nextsent>in china, there is new kind of web based q&a; system which is special kind of discussion group.
</nextsent>
<nextsent>unlike common discussion group, in the web based q&a; system one user posts question, other users can give answers to it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE433">
<title id=" W08-1601.xml">semantic chunk annotation for complex questions using conditional random field </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the targets of national programs aquaint and quetal are all at new interface and new enhancements to current state of-the-art q&a; systems to handle more complex inputs and situations.
</prevsent>
<prevsent>a few researchers and institutions serve as pioneers in complex questions study.
</prevsent>
</prevsection>
<citsent citstr=" W03-1605 ">
different technologies, such as definitions of different sets of question types, templates and sentence patterns (noriko tomuro, 2003) (<papid> W03-1605 </papid>hyo-jung oh et al 2005) machine learning methods (radu soricut and eric brill, 2004), language translation model (jiwoon jeon, et al 2005), composition of information needs of the complex question (sanda harabagiu et al 2006) and so on, have been experimented on the processing of complex question, gearing the acquired information to the facility of other q&a; modules.</citsent>
<aftsection>
<nextsent>several major problems faced now by researcher of complex questions are stated as follow: first: unlike factoid questions, it is very difficult to define comprehensive type hierarchy for complex questions.
</nextsent>
<nextsent>different domains under research may require definitions of different sets of question types, as shown in (hyo-jung oh et al, 2005).
</nextsent>
<nextsent>especially, the types of certain ques 2 http://zhidao.baidu.com/ 3 http://iask.sina.com.cn/ 2 tions are ambiguous and hard to identify.
</nextsent>
<nextsent>for example: this question type can be treated as definition, procedure or entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE434">
<title id=" W08-1601.xml">semantic chunk annotation for complex questions using conditional random field </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, after the question processing step in most systems, the semantic meaning of large part of complex questions still remain vague.
</prevsent>
<prevsent>besides, confining users input only within the selection of provided pattern may lead to unfriendly and unwelcome user interface.
</prevsent>
</prevsection>
<citsent citstr=" P01-1070 ">
(ingrid zukerman and eric horvitz, 2001) <papid> P01-1070 </papid>used decision tree to model and recognize the information need, question and answer coverage, topic, focus and restrictions of question.</citsent>
<aftsection>
<nextsent>although features employed in the experiments were described in detail, no selection process of those feature, or comparison between them was mentioned.
</nextsent>
<nextsent>this paper presents general method for chinese question analyzing.
</nextsent>
<nextsent>our goal is to annotate the semantic chunks for the question automatically.
</nextsent>
<nextsent>chinese language differs lot from english in many aspects.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE435">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two limitations stand out in the bulk of existing work.
</prevsent>
<prevsent>firstly,most existing evaluations are essentially speaker oriented, focussing on the degree of humanlikeness?
</prevsent>
</prevsection>
<citsent citstr=" W06-1421 ">
of the generated descriptions, disregarding their effectiveness (e.g. mellish and dale (1998), gupta and stent (2005), van deemter et al(2006), belz and kilgarriff (2006), <papid> W06-1421 </papid>belz andre iter (2006), <papid> E06-1040 </papid>paris et al (2006), <papid> W06-1419 </papid>viethen and dale(2006), gatt and belz (2008)).<papid> W08-1108 </papid></citsent>
<aftsection>
<nextsent>the limited number of exceptions to this rule indicate that the differences between the two approaches to evaluation can be substantial (gatt and belz, 2008).<papid> W08-1108 </papid></nextsent>
<nextsent>secondly, most evaluations have focussed on these mantic content of the generated descriptions, as produced by the content determination stage ofa gre algorithm; this means that linguistic realisation (i.e. the choice of words and linguistic constructions) is usually not addressed (exceptionsare: stone and webber (1998), <papid> W98-1419 </papid>krahmer and the une (2002), siddharthan and copestake (2004)).<papid> P04-1052 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE436">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two limitations stand out in the bulk of existing work.
</prevsent>
<prevsent>firstly,most existing evaluations are essentially speaker oriented, focussing on the degree of humanlikeness?
</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
of the generated descriptions, disregarding their effectiveness (e.g. mellish and dale (1998), gupta and stent (2005), van deemter et al(2006), belz and kilgarriff (2006), <papid> W06-1421 </papid>belz andre iter (2006), <papid> E06-1040 </papid>paris et al (2006), <papid> W06-1419 </papid>viethen and dale(2006), gatt and belz (2008)).<papid> W08-1108 </papid></citsent>
<aftsection>
<nextsent>the limited number of exceptions to this rule indicate that the differences between the two approaches to evaluation can be substantial (gatt and belz, 2008).<papid> W08-1108 </papid></nextsent>
<nextsent>secondly, most evaluations have focussed on these mantic content of the generated descriptions, as produced by the content determination stage ofa gre algorithm; this means that linguistic realisation (i.e. the choice of words and linguistic constructions) is usually not addressed (exceptionsare: stone and webber (1998), <papid> W98-1419 </papid>krahmer and the une (2002), siddharthan and copestake (2004)).<papid> P04-1052 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE437">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two limitations stand out in the bulk of existing work.
</prevsent>
<prevsent>firstly,most existing evaluations are essentially speaker oriented, focussing on the degree of humanlikeness?
</prevsent>
</prevsection>
<citsent citstr=" W06-1419 ">
of the generated descriptions, disregarding their effectiveness (e.g. mellish and dale (1998), gupta and stent (2005), van deemter et al(2006), belz and kilgarriff (2006), <papid> W06-1421 </papid>belz andre iter (2006), <papid> E06-1040 </papid>paris et al (2006), <papid> W06-1419 </papid>viethen and dale(2006), gatt and belz (2008)).<papid> W08-1108 </papid></citsent>
<aftsection>
<nextsent>the limited number of exceptions to this rule indicate that the differences between the two approaches to evaluation can be substantial (gatt and belz, 2008).<papid> W08-1108 </papid></nextsent>
<nextsent>secondly, most evaluations have focussed on these mantic content of the generated descriptions, as produced by the content determination stage ofa gre algorithm; this means that linguistic realisation (i.e. the choice of words and linguistic constructions) is usually not addressed (exceptionsare: stone and webber (1998), <papid> W98-1419 </papid>krahmer and the une (2002), siddharthan and copestake (2004)).<papid> P04-1052 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE438">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two limitations stand out in the bulk of existing work.
</prevsent>
<prevsent>firstly,most existing evaluations are essentially speaker oriented, focussing on the degree of humanlikeness?
</prevsent>
</prevsection>
<citsent citstr=" W08-1108 ">
of the generated descriptions, disregarding their effectiveness (e.g. mellish and dale (1998), gupta and stent (2005), van deemter et al(2006), belz and kilgarriff (2006), <papid> W06-1421 </papid>belz andre iter (2006), <papid> E06-1040 </papid>paris et al (2006), <papid> W06-1419 </papid>viethen and dale(2006), gatt and belz (2008)).<papid> W08-1108 </papid></citsent>
<aftsection>
<nextsent>the limited number of exceptions to this rule indicate that the differences between the two approaches to evaluation can be substantial (gatt and belz, 2008).<papid> W08-1108 </papid></nextsent>
<nextsent>secondly, most evaluations have focussed on these mantic content of the generated descriptions, as produced by the content determination stage ofa gre algorithm; this means that linguistic realisation (i.e. the choice of words and linguistic constructions) is usually not addressed (exceptionsare: stone and webber (1998), <papid> W98-1419 </papid>krahmer and the une (2002), siddharthan and copestake (2004)).<papid> P04-1052 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE440">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of the generated descriptions, disregarding their effectiveness (e.g. mellish and dale (1998), gupta and stent (2005), van deemter et al(2006), belz and kilgarriff (2006), <papid> W06-1421 </papid>belz andre iter (2006), <papid> E06-1040 </papid>paris et al (2006), <papid> W06-1419 </papid>viethen and dale(2006), gatt and belz (2008)).<papid> W08-1108 </papid></prevsent>
<prevsent>the limited number of exceptions to this rule indicate that the differences between the two approaches to evaluation can be substantial (gatt and belz, 2008).<papid> W08-1108 </papid></prevsent>
</prevsection>
<citsent citstr=" W98-1419 ">
secondly, most evaluations have focussed on these mantic content of the generated descriptions, as produced by the content determination stage ofa gre algorithm; this means that linguistic realisation (i.e. the choice of words and linguistic constructions) is usually not addressed (exceptionsare: stone and webber (1998), <papid> W98-1419 </papid>krahmer and the une (2002), siddharthan and copestake (2004)).<papid> P04-1052 </papid></citsent>
<aftsection>
<nextsent>our aim is to build gre algorithms that produce referring expressions that are of optimal benefit to hearer.
</nextsent>
<nextsent>that is, we are interested in generating descriptions that are easy to read and understand.but the readability and intelligibility of description can crucially depend on the way in which it is ? this work is supported by university of aberdeen sixth century studentship, and epsrc grant ep/e011764/1.
</nextsent>
<nextsent>worded.
</nextsent>
<nextsent>this happens particularly when there is potential for misunderstanding, as can happen in the case of attachment and scope ambiguities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE441">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of the generated descriptions, disregarding their effectiveness (e.g. mellish and dale (1998), gupta and stent (2005), van deemter et al(2006), belz and kilgarriff (2006), <papid> W06-1421 </papid>belz andre iter (2006), <papid> E06-1040 </papid>paris et al (2006), <papid> W06-1419 </papid>viethen and dale(2006), gatt and belz (2008)).<papid> W08-1108 </papid></prevsent>
<prevsent>the limited number of exceptions to this rule indicate that the differences between the two approaches to evaluation can be substantial (gatt and belz, 2008).<papid> W08-1108 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1052 ">
secondly, most evaluations have focussed on these mantic content of the generated descriptions, as produced by the content determination stage ofa gre algorithm; this means that linguistic realisation (i.e. the choice of words and linguistic constructions) is usually not addressed (exceptionsare: stone and webber (1998), <papid> W98-1419 </papid>krahmer and the une (2002), siddharthan and copestake (2004)).<papid> P04-1052 </papid></citsent>
<aftsection>
<nextsent>our aim is to build gre algorithms that produce referring expressions that are of optimal benefit to hearer.
</nextsent>
<nextsent>that is, we are interested in generating descriptions that are easy to read and understand.but the readability and intelligibility of description can crucially depend on the way in which it is ? this work is supported by university of aberdeen sixth century studentship, and epsrc grant ep/e011764/1.
</nextsent>
<nextsent>worded.
</nextsent>
<nextsent>this happens particularly when there is potential for misunderstanding, as can happen in the case of attachment and scope ambiguities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE442">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it might be risky to express this as the radical students and teachers are agreed?, since the reader1 might be inclined to interpret this as pertaining to all teachers rather than only the radical ones.
</prevsent>
<prevsent>for this reason, gre program might opt for the longer noun phrase the radical students and the radical teach ers?.
</prevsent>
</prevsection>
<citsent citstr=" C08-1055 ">
but because this expression is lengthier, the choice involves compromise between comprehensibiliity and brevity, special case of difficult trade-off that is typical of generation as well as interpretation of language (van deemter, 2004).we previously reported the design of an algorithm (based on an earlier work on expressions referring to sets (gatt, 2007)), which was derived from experiments in which readers were asked to express their preference between different descriptions and to respond to instructions which used variety of phrasings (khan et al, 2008).<papid> C08-1055 </papid></citsent>
<aftsection>
<nextsent>here we discuss the issues that arise when such an algorithm is evaluated in terms of its benefits for readers.
</nextsent>
<nextsent>in order to study specific data, we have focussed on the construction illustrated in section 1 above:potentially ambiguous noun phrases of the general form the adj nouni and nounj . for such phrases, there are potentially two interpretations: wide scope (adj modifies both nouni and nounj) or narrow scope (adj modifies nouni but not nounj).our algorithm starts from an unambiguous set theoretic formula over lexical items (i.e. words1in this paper, we use the word reader and hearer interchangeably.
</nextsent>
<nextsent>98 have already been chosen), and thus has to choose between number of different realisations.
</nextsent>
<nextsent>the possible phrasings for the wide scope meaning are: (1) the adj noun1 and noun2, (2) the adj noun2 and noun1, (3) the adj noun1 and the adj noun2,and (4) the adj noun2 and the adj noun1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE446">
<title id=" W09-0615.xml">a hearer oriented evaluation of referring expression generation </title>
<section> issues emerging from this study.  </section>
<citcontext>
<prevsection>
<prevsent>dressed, this raises the question of how these two dimensions should be traded off against each other.
</prevsent>
<prevsent>if one algorithms output was read more quickly than that of another, but understood more slowly than the second, which of the two should be preferred?
</prevsent>
</prevsection>
<citsent citstr=" W06-1409 ">
perhaps there is legitimate role here for meta linguistic judgments after all, in which participants are asked to express their preference between expressions (see paraboni et al (2006) <papid> W06-1409 </papid>for discussion)?</citsent>
<aftsection>
<nextsent>an alternative point of view is that these questions are impossible to answer independent of realistic setting in which participants utter sentences with concrete communicative purpose in mind.
</nextsent>
<nextsent>if utterances were made in order to accomplish concrete task (e.g., to win game) then task-based evaluation would be possible.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>even though this paper has not focussed on de-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE447">
<title id=" W08-2125.xml">collective semantic role labelling with markov logic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many srl systems use two-stage pipeline that first extracts possible argument candidates (argu ment identification) and then assigns argument labels to these candidates (argument classification) (xue and palmer, 2004).
</prevsent>
<prevsent>if we also consider the necessary previous step of identifying the predicates and their senses (predicate identification) this yields three-stage pipeline: predicate identification, argument identification and argument classification.
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
our system, on the other hand, follows joint approach in the spirit of toutanova et al (2005)<papid> P05-1073 </papid>and performs the above steps collectively . we decided to use markov logic (ml, richardson and domingos, 2005), first order probabilistic language, to develop global probabilistic model of srl.</citsent>
<aftsection>
<nextsent>by using ml we are able to incorporate the dependencies between the decisions of different stages in the pipeline and the well-known global correlations between the arguments of predicate (punyakanok et al, 2005).
</nextsent>
<nextsent>and since learning ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE451">
<title id=" W08-1807.xml">using lexico semantic information for query expansion in passage retrieval for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.1the cross-language evaluation forum (http://clef qa.itc.it/) often discrepancy between the terminology usedby the user and the terminology used in the document collection to describe the same concept.
</prevsent>
<prevsent>adocument might hold the answer to the users question, but it will not be found due to the terminological gap.
</prevsent>
</prevsection>
<citsent citstr=" P02-1005 ">
moldovan et al (2002) <papid> P02-1005 </papid>show that their system fails to answer many questions (25.7%), because of the terminological gap, i.e.keyword expansion would be desirable but is missing.</citsent>
<aftsection>
<nextsent>query expansion techniques have been developed to bridge this gap.
</nextsent>
<nextsent>however, we believe that there is more than just terminological gap.
</nextsent>
<nextsent>there is also knowledge gap.
</nextsent>
<nextsent>documents are missed or do not end up high in the ranks, because additional world knowledge is missing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE452">
<title id=" W08-1807.xml">using lexico semantic information for query expansion in passage retrieval for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they evaluated their system on question sets of trec-8 and trec-9.
</prevsent>
<prevsent>for trec8 they reach precision score of 55.3% without including any alternations for question keywords, 67.6% if lexical alternations are allowed and 73.7% if both lexical and semantic alternations are allowed.
</prevsent>
</prevsection>
<citsent citstr=" E03-1070 ">
however, yang and chua (2003) <papid> E03-1070 </papid>report that adding additional terms from wordnets synsets and glosses adds more noise than information to the query.</citsent>
<aftsection>
<nextsent>also, voorhees (1993) concludes that expanding by automatically generated synonym sets from ewn can degrade results.
</nextsent>
<nextsent>in yang et al (2003) the authors use external knowledge extracted from wordnet and the web to expand queries for qa.
</nextsent>
<nextsent>minor improvements are attained when the web is used to retrieve list of nearby (one sentence or snippet) non-trivial terms.
</nextsent>
<nextsent>when wordnet is used to rank the retrieved terms, the improvement is reduced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE453">
<title id=" W08-1807.xml">using lexico semantic information for query expansion in passage retrieval for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>expansions are selected based on the similarity to the query concept, i.e. all words in the query together, andnot based on the single words in the query independently.
</prevsent>
<prevsent>the results they get are promising.
</prevsent>
</prevsection>
<citsent citstr=" N04-1041 ">
pantel and ravichandran (2004) <papid> N04-1041 </papid>have used method that is not related to query expansion,but yet very related to our work.</citsent>
<aftsection>
<nextsent>they have semantically indexed the trec-2002 ir collection with the isa-relations found by their system for 179 questions that had an explicit semantic answer type, such as what band was jerry garcia with?
</nextsent>
<nextsent>they show small gains in performance of their output using the semantically indexed collection.
</nextsent>
<nextsent>recent work (shen and lapata, 2007; <papid> D07-1002 </papid>kaisser and webber, 2007) <papid> W07-1206 </papid>that falls outside the scope ofthis paper, but that is worth mentioning successfully applies semantic roles to question answering.</nextsent>
<nextsent>we have used several types of lexico-semantic information as sources for candidate expansion terms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE454">
<title id=" W08-1807.xml">using lexico semantic information for query expansion in passage retrieval for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they have semantically indexed the trec-2002 ir collection with the isa-relations found by their system for 179 questions that had an explicit semantic answer type, such as what band was jerry garcia with?
</prevsent>
<prevsent>they show small gains in performance of their output using the semantically indexed collection.
</prevsent>
</prevsection>
<citsent citstr=" D07-1002 ">
recent work (shen and lapata, 2007; <papid> D07-1002 </papid>kaisser and webber, 2007) <papid> W07-1206 </papid>that falls outside the scope ofthis paper, but that is worth mentioning successfully applies semantic roles to question answering.</citsent>
<aftsection>
<nextsent>we have used several types of lexico-semantic information as sources for candidate expansion terms.
</nextsent>
<nextsent>the first three are automatically acquired 2i.e. words that appear in the same documents and that share the first three, four or five letters.
</nextsent>
<nextsent>51 from corpora by means of distributional methods.
</nextsent>
<nextsent>nearest neighbours from proximity-based distributional similarity?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE455">
<title id=" W08-1807.xml">using lexico semantic information for query expansion in passage retrieval for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they have semantically indexed the trec-2002 ir collection with the isa-relations found by their system for 179 questions that had an explicit semantic answer type, such as what band was jerry garcia with?
</prevsent>
<prevsent>they show small gains in performance of their output using the semantically indexed collection.
</prevsent>
</prevsection>
<citsent citstr=" W07-1206 ">
recent work (shen and lapata, 2007; <papid> D07-1002 </papid>kaisser and webber, 2007) <papid> W07-1206 </papid>that falls outside the scope ofthis paper, but that is worth mentioning successfully applies semantic roles to question answering.</citsent>
<aftsection>
<nextsent>we have used several types of lexico-semantic information as sources for candidate expansion terms.
</nextsent>
<nextsent>the first three are automatically acquired 2i.e. words that appear in the same documents and that share the first three, four or five letters.
</nextsent>
<nextsent>51 from corpora by means of distributional methods.
</nextsent>
<nextsent>nearest neighbours from proximity-based distributional similarity?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE456">
<title id=" W08-1807.xml">using lexico semantic information for query expansion in passage retrieval for question answering </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the association pope belongs to rome in the religious sense, the place where the catholic church is seated.
</prevsent>
<prevsent>rome is often referred to as the catholic church itself, as in henry viii broke from rome.
</prevsent>
</prevsection>
<citsent citstr=" W98-0705 ">
gonzalo et al (1998) <papid> W98-0705 </papid>showed in an experiment, where words were manually disambiguated, that substantial increase in performance is obtained when query words are disambiguated, before they are expanded.</citsent>
<aftsection>
<nextsent>we tried to take care of these ambiguities by using an overlap method.
</nextsent>
<nextsent>the overlap method selects expansions that were found in the nearest neighbours of more than two query words.
</nextsent>
<nextsent>unfortunately, as navigli and velardi (2003),who implement similar technique, using lexico semantic information from wordnet, note, the common nodes expansion technique works very badly.
</nextsent>
<nextsent>also, voorhees (1993) who uses similar method to select expansions concludes that the method has the tendency to select very general terms that have more than one sense themselves.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE458">
<title id=" W08-1002.xml">parse selection with a german hpsg grammar </title>
<section> the grammar.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 discusses the tree banking effort we have undertaken(3.1), followed by presentation of the parse selection results we achieve using probabilistic models trained on different feature sets (3.2).
</prevsent>
<prevsent>the grammar used in the experiments reported herehas originally been developed, at dfki, in the context of the verb mobil project (muller and kasper,2000).
</prevsent>
</prevsection>
<citsent citstr=" C94-1072 ">
developed initially for the page development and processing platform (uszkoreit et al, 1994), <papid> C94-1072 </papid>the grammar has subsequently been ported to lkb (copestake, 2001) and pet (callmeier, 2000) by stefan muller.</citsent>
<aftsection>
<nextsent>since 2002, the grammar has been extended and modified by berthold crysmann (crysmann, 2003; crysmann, 2005; crysmann, 2007).<papid> W07-1219 </papid></nextsent>
<nextsent>the grammar, codename gg, is large scale hpsg grammar for german, freely available under an open-source license: it consists of roughly4000 types, out of which 290 are parametrised lexical types, used in the definition of about 35,000 lexical entries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE459">
<title id=" W08-1002.xml">parse selection with a german hpsg grammar </title>
<section> the grammar.  </section>
<citcontext>
<prevsection>
<prevsent>the grammar used in the experiments reported herehas originally been developed, at dfki, in the context of the verb mobil project (muller and kasper,2000).
</prevsent>
<prevsent>developed initially for the page development and processing platform (uszkoreit et al, 1994), <papid> C94-1072 </papid>the grammar has subsequently been ported to lkb (copestake, 2001) and pet (callmeier, 2000) by stefan muller.</prevsent>
</prevsection>
<citsent citstr=" W07-1219 ">
since 2002, the grammar has been extended and modified by berthold crysmann (crysmann, 2003; crysmann, 2005; crysmann, 2007).<papid> W07-1219 </papid></citsent>
<aftsection>
<nextsent>the grammar, codename gg, is large scale hpsg grammar for german, freely available under an open-source license: it consists of roughly4000 types, out of which 290 are parametrised lexical types, used in the definition of about 35,000 lexical entries.
</nextsent>
<nextsent>the lexicon is further extended by 44 lexical rules and about 300 inflectional rules.
</nextsent>
<nextsent>on the syntactic side, the grammar has about 80 phrase structure rules.
</nextsent>
<nextsent>the grammar covers all major aspects of germanclausal and phrasal syntax, including free word order in the clausal domain, long-distance dependencies, complex predicates, pass ives, and extraposition(crysmann, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE460">
<title id=" W08-1002.xml">parse selection with a german hpsg grammar </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>the results obtained here for german compare quite well to the results previously achieved for the erg, broad coverage hpsg for english: using similar treebank1 (toutanova et al, 2002) report 81.80 exact match accuracy for log-linear model with local trees plus ancestor information, the model which is closest to the models we have evaluated here.
</prevsent>
<prevsent>the baseline in their experiments is 25.81.
</prevsent>
</prevsection>
<citsent citstr=" W07-1203 ">
thebest model they obtain includes semantic dependencies, as well, yielding 82.65 exact match accuracy.probably the most advanced approach to parse selection for german is (forst, 2007): <papid> W07-1203 </papid>using broad coverage lfg grammar, he reports an f-score of 83% of correctly assigned dependency triples for reference corpus of manually annotated newspaper text.</citsent>
<aftsection>
<nextsent>however, it is unclear how these figures relate to the exact match accuracy used here.
</nextsent>
<nextsent>relevant, in principle, to our discussion here, are also the results obtained with treebank grammars for german: (dubey and keller, 2003) <papid> P03-1013 </papid>have trained apcfg on the negra corpus (skut et al, 1998), reporting labelled precision and recall between 70 and 75%.</nextsent>
<nextsent>(kubler et al, 2006) essentially confirm these results for the negra treebank, but argue instead that probabilistic parsing for german can reach far better results (around 89%), once different treebank is chosen, e.g. tuba-d/z. however, it is quite difficult to interpret the significance of these two tree bank parsers for our purposes here: not only is the evaluation metric an entirely different one, but so are the parsing task and the corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE461">
<title id=" W08-1002.xml">parse selection with a german hpsg grammar </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>thebest model they obtain includes semantic dependencies, as well, yielding 82.65 exact match accuracy.probably the most advanced approach to parse selection for german is (forst, 2007): <papid> W07-1203 </papid>using broad coverage lfg grammar, he reports an f-score of 83% of correctly assigned dependency triples for reference corpus of manually annotated newspaper text.</prevsent>
<prevsent>however, it is unclear how these figures relate to the exact match accuracy used here.</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
relevant, in principle, to our discussion here, are also the results obtained with treebank grammars for german: (dubey and keller, 2003) <papid> P03-1013 </papid>have trained apcfg on the negra corpus (skut et al, 1998), reporting labelled precision and recall between 70 and 75%.</citsent>
<aftsection>
<nextsent>(kubler et al, 2006) essentially confirm these results for the negra treebank, but argue instead that probabilistic parsing for german can reach far better results (around 89%), once different treebank is chosen, e.g. tuba-d/z. however, it is quite difficult to interpret the significance of these two tree bank parsers for our purposes here: not only is the evaluation metric an entirely different one, but so are the parsing task and the corpus.
</nextsent>
<nextsent>in an less recent paper, however, (ruland, 2000) reports on probabilistic parsing of verb mobil data using probabilistic lr-parser.
</nextsent>
<nextsent>the parser has be entrained on set of 19,750 manually annotated sentences.
</nextsent>
<nextsent>evaluation of the parser was then performed on hold-out set of 1000 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE462">
<title id=" W09-1412.xml">tunable domain independent event extraction in the mira framework </title>
<section> one-best mira and loss functions.  </section>
<citcontext>
<prevsection>
<prevsent>given weight vector w, the dot-product ? f(x, y) ranks the possible labelings of x; we will denote the top scoring labeling as yw(x).
</prevsent>
<prevsent>as with hidden markov models (rabiner, 1989), yw(x) can be computed efficiently for suitable feature functions using dynamic programming.the learning portion of our method requires finding weight vector that scores the correct labeling of the training data higher than any incorrect labeling.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
we used one-best version of mira (cram mer, 2004; mcdonald et al, 2005) <papid> P05-1012 </papid>to choose w. mira is an online learning algorithm that updates the weight vector for each training sentence xi according to the following rule: 95 wnew = argmin w ? wold?</citsent>
<aftsection>
<nextsent>s.t. ? f(xi, yi) ? ? f(x, y?)
</nextsent>
<nextsent>l(yi, y?)where l(yi, y) is measure of the loss of using instead of the correct labeling yi, and y?
</nextsent>
<nextsent>is shorthand for ywold(xi).
</nextsent>
<nextsent>in case of single constraint, this program has closed-form solution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE463">
<title id=" W09-1412.xml">tunable domain independent event extraction in the mira framework </title>
<section> trigger word tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the training and the development abstracts were first tokenized and split into sentences using maximum entropy models trained on the genia3 corpora.
</prevsent>
<prevsent>subsequently, we trained several sequence taggers in order to identify the trigger words in text.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
all our experiments used the standard bio encoding (ramshaw and marcus, 1995) <papid> W95-0107 </papid>with different feature sets and learning procedures.</citsent>
<aftsection>
<nextsent>we focused on recall since it determines the upper bound on the performance of our final system.
</nextsent>
<nextsent>in our experiments, we found that simultaneously identifying trigger words and the event types they trigger yielded low recall; thus, we settled on identifying trigger words in text as one kind of entity, regardless of event types.in our initial experiments, we used crf based sequence tagger (lafferty et al, 2001), which yielded r=43.51%.
</nextsent>
<nextsent>we further tried feature induction (mccallum, 2003) and second-order markov assumptions for the crf, achieving 44.72% and 49.64% recall, respectively.
</nextsent>
<nextsent>3http://www-tsujii.is.s.u-tokyo.ac.jp/genia/home/wiki.cgi feature set p f1 baseline (current word) 44.82 2.86 05.38 + pos &amp; char 3-gram 77.41 27.96 41.09 + previous pos tag 79.77 29.32 42.88 + lexicon (final tagger) 80.44 29.65 43.33 table 1: recall (r), precision (p), and f1-measure for the trigger words tagger (in %s) on the development dataset for different feature sets using mira training with false negatives as loss function.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE464">
<title id=" W09-1412.xml">tunable domain independent event extraction in the mira framework </title>
<section> trigger word tagging.  </section>
<citcontext>
<prevsection>
<prevsent>in order toboost recall, we defined the loss function as the number of false negative trigger chunks.
</prevsent>
<prevsent>thus, larger loss update was made whenever the model failed to discover trigger word, while discovering spurious trigger words was penalized less severely.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
we experimented with popular feature sets previously used for named entity (mccallum and li, 2003) <papid> W03-0430 </papid>and gene (mcdonald and pereira, 2005) recognition including orthographic, part-of-speech (pos), shallow parsing and gazetteers.</citsent>
<aftsection>
<nextsent>however, we found that only small number of them was really helpful; summary is presented in table 1.
</nextsent>
<nextsent>in order to boost recall even further, we prepared gazetteer of trigger chunks derived from the training data, and we extended it with the corresponding wordnet synsets; we thus achieved 80.44% recall for our final tagger.
</nextsent>
<nextsent>the input to our event extraction algorithm is listof trigger words and list of genes or gene prod 96 ucts (e.g., proteins); the output is set of relations as defined for task 1.
</nextsent>
<nextsent>our algorithm works in two stages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE466">
<title id=" W09-1504.xml">integrated nlp evaluation system for plug gable evaluation metrics with extensive interoperable toolkit </title>
<section> interoperable components and utili-.  </section>
<citcontext>
<prevsection>
<prevsent>in the uima framework, component which generates cases is called collection reader.
</prevsent>
<prevsent>we have developed several collection readers which read annotated corpora and generates annotations using the u-compare type system.
</prevsent>
</prevsection>
<citsent citstr=" W05-0304 ">
because our primary target domain was biomedical field, there are corpus readers for the biomedical corpora; aimed corpus (bunescu et al., 2006) reader and bionlp 09 shared task format reader generate event annotations like protein-protein interaction annotations; readers for bio/iob format, bio1 corpus (tateisi et al, 2000), bio creative (hirschman et al, 2004) task 1a format, bioie corpus (bies et al, 2005), <papid> W05-0304 </papid>nlpba shared task dataset (kim et al, 2004), texas corpus (bunescu et al, 2005), yapex corpus (kristofer franzen et al, 2002), generate biomedical named entities, and genia treebank corpus (tateisi et al, 2005) reader generates penn treebank (marcus et al, 1993) style bracketing and part-of-speech annotations.</citsent>
<aftsection>
<nextsent>format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users?
</nextsent>
<nextsent>demand.
</nextsent>
<nextsent>in addition, there is file system collection reader from apache uima which reads files as plain text.
</nextsent>
<nextsent>we have developed an online interactive text reader, named input text reader.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE467">
<title id=" W09-0618.xml">a japanese corpus of referring expressions used in a situated collaboration task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this has more recently developed into creating situated corpora in order to analyse the referring expressions occurring in situated collaborative tasks.
</prevsent>
<prevsent>the coconut corpus (di eugenio et al, 2000) is collected fromkeyboard-input dialogues between two participants who are collaboratively working on simple 2-d design task (buying and arranging furniture for two rooms).
</prevsent>
</prevsection>
<citsent citstr=" L08-1033 ">
in contrast, the quake corpus (byron et al, 2005) ? as well as the more recent scare corpus (stoia et al, 2008), <papid> L08-1033 </papid>which isan extension of quake ? is based on an interaction captured in 3-d virtual reality (vr) world where two participants collaboratively carry out treasure hunting task.</citsent>
<aftsection>
<nextsent>there has been ongoing work to exploit these two resources for research on different aspects of referring expressions (pamela w. jordan, 2005; byron, 2005).
</nextsent>
<nextsent>however, while these resources have inspired new research into different aspects of referring expressions, at the same time they have clear limitations.
</nextsent>
<nextsent>the coconut corpus is collected from dialogues in which participants refer to symbol like objects in 2-d world.
</nextsent>
<nextsent>it thus resembles the more recent (non-collaborative) tuna corpus (van deemter, 2007) intending to encourage very simple types of expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE468">
<title id=" W08-0906.xml">answering learners questions by retrieving question paraphrases from social qa sites </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the specific features of question paraphrasing have also already been investigated (section 2.3).
</prevsent>
<prevsent>2.1 sentence paraphrase identification.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
paraphrases are alternative ways to convey the same information (barzilay and mckeown, 2001).<papid> P01-1008 </papid></citsent>
<aftsection>
<nextsent>paraphrases can be found at different levels of linguistic structure: words, phrases and whole sentences.
</nextsent>
<nextsent>while word and phrasal paraphrases canbe assimilated to the well-studied notion of syn onymy, sentence level paraphrasing is more difficult to grasp and cannot be equated with word-for-wordor phrase-by-phrase substitution since it might entail changes in the structure of the sentence (barzilay and lee, 2003).<papid> N03-1003 </papid></nextsent>
<nextsent>in practice, sentence paraphrases are identified using various string and semantic similarity measures which aim at capturing the semantic equivalence of the sentences being compared.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE469">
<title id=" W08-0906.xml">answering learners questions by retrieving question paraphrases from social qa sites </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>paraphrases are alternative ways to convey the same information (barzilay and mckeown, 2001).<papid> P01-1008 </papid></prevsent>
<prevsent>paraphrases can be found at different levels of linguistic structure: words, phrases and whole sen tences.</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
while word and phrasal paraphrases canbe assimilated to the well-studied notion of syn onymy, sentence level paraphrasing is more difficult to grasp and cannot be equated with word-for-wordor phrase-by-phrase substitution since it might entail changes in the structure of the sentence (barzilay and lee, 2003).<papid> N03-1003 </papid></citsent>
<aftsection>
<nextsent>in practice, sentence paraphrases are identified using various string and semantic similarity measures which aim at capturing the semantic equivalence of the sentences being compared.
</nextsent>
<nextsent>string similarity metrics, when applied to sentences, consist in comparing the words contained in the sentences.
</nextsent>
<nextsent>there exist many different string similarity measures: word overlap (tomuro and lytinen, 2004), longest common sub sequence (islam and inkpen, 2007), levenshtein edit distance (dolan et al, 2004), <papid> C04-1051 </papid>word n-gram overlap (barzilay and lee, 2003) <papid> N03-1003 </papid>etc. semantic similarity measures are obtained by first computing the semantic similarity of the words contained in the sentences beingcompared.</nextsent>
<nextsent>mihalcea et al (2006) use both corpus based and knowledge-based measures of the semantic similarity between words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE470">
<title id=" W08-0906.xml">answering learners questions by retrieving question paraphrases from social qa sites </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in practice, sentence paraphrases are identified using various string and semantic similarity measures which aim at capturing the semantic equivalence of the sentences being compared.
</prevsent>
<prevsent>string similarity metrics, when applied to sentences, consist in comparing the words contained in the sentences.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
there exist many different string similarity measures: word overlap (tomuro and lytinen, 2004), longest common sub sequence (islam and inkpen, 2007), levenshtein edit distance (dolan et al, 2004), <papid> C04-1051 </papid>word n-gram overlap (barzilay and lee, 2003) <papid> N03-1003 </papid>etc. semantic similarity measures are obtained by first computing the semantic similarity of the words contained in the sentences beingcompared.</citsent>
<aftsection>
<nextsent>mihalcea et al (2006) use both corpus based and knowledge-based measures of the semantic similarity between words.
</nextsent>
<nextsent>both string similarity and semantic similarity might be combined: for instance, islam and inkpen (2007) combine semantic similarity with longest common sub sequence string similarity, while li et al (2006) make additional use of word order similarity.
</nextsent>
<nextsent>2.2 query paraphrasing.
</nextsent>
<nextsent>in information retrieval, research on paraphrasing is dedicated to query paraphrasing which consists in identifying semantically similar queries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE472">
<title id=" W08-0906.xml">answering learners questions by retrieving question paraphrases from social qa sites </title>
<section> question and answer repositories.  </section>
<citcontext>
<prevsection>
<prevsent>user generated gold standards have been increasingly used in recent years for research evaluation purposes, since they can be easily created from user annotated content.
</prevsent>
<prevsent>for instance, mihalcea and csomai (2007) use manually annotated keywords (links to other articles) in wikipedia articles to evaluate their automatic keyword extraction and word sense disambiguation algorithms.
</prevsent>
</prevsection>
<citsent citstr=" P07-2032 ">
similarly, quality assessments provided by users in social media have been used as gold 1http://wiki.answers.com/ 2http://educator.answers.com/standards for the automatic assessment of post quality in forum discussions (weimer et al, 2007).<papid> P07-2032 </papid></citsent>
<aftsection>
<nextsent>it should however be kept in mind that user generated gold standards are not perfect, as already noticed by (mihalcea and csomai, 2007), and thus constitute trade-off solution.for the experiments described hereafter, we randomly extracted collection of 1,000 questions along with their paraphrases (totalling 7,434 question paraphrases) from 100 randomly selected faq files in the education category of the wikianswersweb site.
</nextsent>
<nextsent>in what follows, the corpus of 1,000 questions is called the target questions collection, while the 7,434 question paraphrases constitute the input questions collection.
</nextsent>
<nextsent>the objective of the task is to retrieve the corresponding target question for each input question.
</nextsent>
<nextsent>the target question selected is the one which maximises the question similarity value (see section 4.2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE474">
<title id=" W08-2117.xml">a nearest neighbor approach to the automatic analysis of ancient greek morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this procedure becomes extremely labor-intensive for small words that overlap with other common words (crane, 1991).
</prevsent>
<prevsent>automatic morphological analysis of ancient greek would be useful for both educational and research purposes.
</prevsent>
</prevsection>
<citsent citstr=" C73-2026 ">
in fact, one of the first analyzers was developed as pedagogical tool (packard,1973).<papid> C73-2026 </papid></citsent>
<aftsection>
<nextsent>today, widely used analyzer is embedded in the perseus digital library (crane, 1996), an internet resource utilized by both students and researchers.
</nextsent>
<nextsent>this paper presents an analyzer of ancient greek that infers the root form of word.
</nextsent>
<nextsent>it introduces two innovations.
</nextsent>
<nextsent>first, it utilizes nearest neighbor framework that requires no hand-crafted rules, and provides analogies to facilitate learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE475">
<title id=" W08-2117.xml">a nearest neighbor approach to the automatic analysis of ancient greek morphology </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in the recent pascal challenge, the best results were achieved by (keshava and pitler, 2006).
</prevsent>
<prevsent>their algorithm discovers affixes by considering words that appear as sub strings of other words, and by estimating probabilities for morpheme boundaries.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
another successful ap 128 proach is the use of minimum description length,which iteratively shortens the length of the morphological grammar (goldsmith, 2001).<papid> J01-2001 </papid></citsent>
<aftsection>
<nextsent>spelling changes at morpheme boundaries (e.g., deny but deni-al) can be captured by orthographic rules such as change y- to i- when the suffix is-al?.
</nextsent>
<nextsent>such rules are specified manually in the two level model of morphology (koskenniemi, 1983),but they can also be induced (dasgupta, 2007).
</nextsent>
<nextsent>allomorphs (e.g., deni?
</nextsent>
<nextsent>and deny?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE476">
<title id=" W08-2117.xml">a nearest neighbor approach to the automatic analysis of ancient greek morphology </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the same may be expected of ancient greek.
</prevsent>
<prevsent>indeed, for these languages, predicting novel roots is challenging problem.
</prevsent>
</prevsection>
<citsent citstr=" P08-1083 ">
this task has been tackled in (adler et al, 2008) <papid> P08-1083 </papid>for modern hebrew, and in (linden, 2008) for finnish.</citsent>
<aftsection>
<nextsent>in the former, features such as letter n-grams and word-formation patterns are used to predict the morphology of hebrew words unknown to an existing analyzer.
</nextsent>
<nextsent>in the latter, probabilistic approach is used for harvesting prefixes and suffixes in finnish words, favoring the longer ones.
</nextsent>
<nextsent>however, no strategy was proposed for irregular spelling in stems.
</nextsent>
<nextsent>3the root forms of contract verbs, e.g. pleroo, are not even inflected forms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE478">
<title id=" W09-1007.xml">language models for contextual error detection and correction </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>the situation with to, too , and two, affect and effect , or there , their , and theyre in english) (sandra et al, 2001; vanden bosch and daelemans, 2007).
</prevsent>
<prevsent>41 most work on con fusible disambiguation using machine learning concentrates on hand-selected sets of notorious confusibles.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
the con fusible sets are typically very small (two or three elements) and the machine learner will only see training examples of the members of the con fusible set.this approach is similar to approaches used in accent restoration (yarowsky, 1994; <papid> P94-1013 </papid>golding, 1995;<papid> W95-0104 </papid>mangu and brill, 1997; wu et al, 1999; even zohar and roth, 2000; banko and brill, 2001; <papid> P01-1005 </papid>huang and powers, 2001; vanden bosch, 2006).the task of the machine learner is to decide, using features describing information from the context, which word taken from the con fusible set really belongs in the position of the confusible.</citsent>
<aftsection>
<nextsent>using the example above, the classifier has to decide which word belongs on the position of the in she owns cars , where the possible answers for are to , too , or two.
</nextsent>
<nextsent>we call x, the con fusible that is under consideration, the focus word.another way of looking at the problem of con fusible disambiguation is to see it as very specialized case of word prediction.
</nextsent>
<nextsent>the problem is then to predict which word belongs at specific position.
</nextsent>
<nextsent>using similarities between these cases, we can use techniques from the field of language modeling to solve the problem of selecting the best alternative from con fusible sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE479">
<title id=" W09-1007.xml">language models for contextual error detection and correction </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>the situation with to, too , and two, affect and effect , or there , their , and theyre in english) (sandra et al, 2001; vanden bosch and daelemans, 2007).
</prevsent>
<prevsent>41 most work on con fusible disambiguation using machine learning concentrates on hand-selected sets of notorious confusibles.
</prevsent>
</prevsection>
<citsent citstr=" W95-0104 ">
the con fusible sets are typically very small (two or three elements) and the machine learner will only see training examples of the members of the con fusible set.this approach is similar to approaches used in accent restoration (yarowsky, 1994; <papid> P94-1013 </papid>golding, 1995;<papid> W95-0104 </papid>mangu and brill, 1997; wu et al, 1999; even zohar and roth, 2000; banko and brill, 2001; <papid> P01-1005 </papid>huang and powers, 2001; vanden bosch, 2006).the task of the machine learner is to decide, using features describing information from the context, which word taken from the con fusible set really belongs in the position of the confusible.</citsent>
<aftsection>
<nextsent>using the example above, the classifier has to decide which word belongs on the position of the in she owns cars , where the possible answers for are to , too , or two.
</nextsent>
<nextsent>we call x, the con fusible that is under consideration, the focus word.another way of looking at the problem of con fusible disambiguation is to see it as very specialized case of word prediction.
</nextsent>
<nextsent>the problem is then to predict which word belongs at specific position.
</nextsent>
<nextsent>using similarities between these cases, we can use techniques from the field of language modeling to solve the problem of selecting the best alternative from con fusible sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE480">
<title id=" W09-1007.xml">language models for contextual error detection and correction </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>the situation with to, too , and two, affect and effect , or there , their , and theyre in english) (sandra et al, 2001; vanden bosch and daelemans, 2007).
</prevsent>
<prevsent>41 most work on con fusible disambiguation using machine learning concentrates on hand-selected sets of notorious confusibles.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
the con fusible sets are typically very small (two or three elements) and the machine learner will only see training examples of the members of the con fusible set.this approach is similar to approaches used in accent restoration (yarowsky, 1994; <papid> P94-1013 </papid>golding, 1995;<papid> W95-0104 </papid>mangu and brill, 1997; wu et al, 1999; even zohar and roth, 2000; banko and brill, 2001; <papid> P01-1005 </papid>huang and powers, 2001; vanden bosch, 2006).the task of the machine learner is to decide, using features describing information from the context, which word taken from the con fusible set really belongs in the position of the confusible.</citsent>
<aftsection>
<nextsent>using the example above, the classifier has to decide which word belongs on the position of the in she owns cars , where the possible answers for are to , too , or two.
</nextsent>
<nextsent>we call x, the con fusible that is under consideration, the focus word.another way of looking at the problem of con fusible disambiguation is to see it as very specialized case of word prediction.
</nextsent>
<nextsent>the problem is then to predict which word belongs at specific position.
</nextsent>
<nextsent>using similarities between these cases, we can use techniques from the field of language modeling to solve the problem of selecting the best alternative from con fusible sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE481">
<title id=" W09-1007.xml">language models for contextual error detection and correction </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>to reduce this problem we can either use back-off or smoothing when the probability of an n-gram is zero.
</prevsent>
<prevsent>in the case of back-off, the probabilities of lower order n-grams are taken into account when needed.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
alternatively, smoothing techniques (chen and goodman, 1996) <papid> P96-1041 </papid>redistribute the probabilities, taking into account previously unseen word sequences.</citsent>
<aftsection>
<nextsent>even though the language models provide us with probabilities of entire sequences, we are only interested in the n-grams directly around the con fusible when using the language models in the context of con fusible disambiguation.
</nextsent>
<nextsent>the probabilities of the rest of the sequence will remain the same whichever alternative confusibleis inserted in the focus word position.
</nextsent>
<nextsent>figure 1 illustrates that the probability of for examplep (analysts had expected ) is irrelevant for the decision between then and than because it occurs in both sequences.
</nextsent>
<nextsent>the different language models we will consider here are essentially the same.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE482">
<title id=" W09-1007.xml">language models for contextual error detection and correction </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>during testing, similar instance is generated.
</prevsent>
<prevsent>the classifier decides what the corresponding class, and hence, which word should be the focus word.
</prevsent>
</prevsection>
<citsent citstr=" P97-1056 ">
model (zavrel and daelemans, 1997), <papid> P97-1056 </papid>while still being generic classifier that supports any number and type of features.</citsent>
<aftsection>
<nextsent>for these reasons, igtree is also included in the experiments.
</nextsent>
<nextsent>3.2 experimental settings.
</nextsent>
<nextsent>the probabilities used in the language models of the generic classifiers are computed by looking at occurrences of n-grams.
</nextsent>
<nextsent>these occurrences are extracted from corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE483">
<title id=" W09-1007.xml">language models for contextual error detection and correction </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the reuters corpus contains about 810,000 categorized newswire stories as published by reuters in 1996 and 1997.
</prevsent>
<prevsent>this corpus contains around 130 million tokens.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for testing purposes, we used the wall street journal part of the penn treebank corpus (marcuset al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>this well-known corpus contains articles from the wall street journal in 1987 to 1989.
</nextsent>
<nextsent>we extract our test-instances from this corpus in the same way as we extract our training data from the reuters corpus.
</nextsent>
<nextsent>there are minor tokenization differences between the corpora.
</nextsent>
<nextsent>the data iscor rected for these differences.both corpora are in the domain of english language news texts, so we expect them to have similar properties.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE485">
<title id=" W09-0804.xml">a hybrid approach for building arabic diacritizer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is also problematic for arabic processing applications, such as text to-speech, speech-to-text, and text analysis, where the lack of diacritics adds another layer of ambiguity when processing the input data.
</prevsent>
<prevsent>as an example, full vocal ization of arabic text is required for text-to-speech applications, where the mapping from graphemes to phonemes is complicated compared to languages such as english and french; where there is, in most cases, simple one-to-one relationship.
</prevsent>
</prevsection>
<citsent citstr=" P06-1073 ">
nevertheless, using arabic text with diacritics has proven an improvement in the accuracy of speech-recognition applications (zitouni et al, 2006).<papid> P06-1073 </papid></citsent>
<aftsection>
<nextsent>the problem of automatic restoration (i.e., deri vation) of the dia critic signs of arabic text can be solved by two approaches.
</nextsent>
<nextsent>the first is rule based approach that involves complex integration of the arabic morphological, syntactic, and semantic tools with significant efforts to acquire respective linguistic rules.
</nextsent>
<nextsent>a morphological analyzer gets the breakdowns of the undiacritized word according to known patterns or templates and recognizes its prefixes and suffixes.
</nextsent>
<nextsent>a syntax analyzer applies specific syntactic rules to determine the case-ending diacritics, usually, by techniques such as finite-state automata.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE486">
<title id=" W09-0804.xml">a hybrid approach for building arabic diacritizer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the case-ending diacritization is treated as post-process of the internal diacritization task using the same machine learning approach that was trained on base phrase (bp)-chunk as well as pos features of individual tokens with correct case-ending tags.
</prevsent>
<prevsent>a utility has been designed to extract correct case-ending tags from the ldcs arabic tree bank (atb).
</prevsent>
</prevsection>
<citsent citstr=" N07-2014 ">
this paper presents new simple but efficient approach that gets results comparable with the best performing systems, to our knowledge, (habash and rambow, 2007).<papid> N07-2014 </papid></citsent>
<aftsection>
<nextsent>the achieved results are: 11.795% word error rate (wer) and about 3.245% diacritics error rate (der).
</nextsent>
<nextsent>the paper is structured as follows.
</nextsent>
<nextsent>section 2 reviews closely related work.
</nextsent>
<nextsent>section 3 introduces the proposed diacritization approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE490">
<title id=" W09-0804.xml">a hybrid approach for building arabic diacritizer </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the remaining files are used for training.
</prevsent>
<prevsent>for arabic tokenizer, pos tagger, bp-chunk, and statistical case-ending, we used standard svm with polynomial kernel of degree 2 and c=1.0.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
evaluation of the system was done by calculating the performance using the standard evaluation measures: accuracy, precision, recall, and the f-measure4.we used yamcha (kudo and matsumoto, 2003) <papid> P03-1004 </papid>implementation of svms.</citsent>
<aftsection>
<nextsent>diacritization evaluation of our experiments is reported in terms of word error rate (wer), and diacritization error rate (der)5.
</nextsent>
<nextsent>we conducted experiments to: 1.
</nextsent>
<nextsent>evaluate the impact of tokenization, part-of-.
</nextsent>
<nextsent>speech, chunking, and case-ending parameters on the training models, see section 5.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE491">
<title id=" W09-0804.xml">a hybrid approach for building arabic diacritizer </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>pos tagger with the arabicsvmtools tagger using different parameters and fea ture(s), see section 5.2.
</prevsent>
<prevsent>5.1 results of tokenization, part-of-speech,.
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
bp-chunking, and case-ending the results obtained for tokenization (tok), part-of-speech (pos), and chunking (bp-chunk) tasks are comparable with the results presented in the most notable literature (diab et al 2007; diab et al 2004).<papid> N04-4038 </papid></citsent>
<aftsection>
<nextsent>we did some modifications of the feature list to compromise between the speed and accuracy.
</nextsent>
<nextsent>the case ending task is novel, and did not get enough handling in other research.
</nextsent>
<nextsent>it achieved acceptable results.
</nextsent>
<nextsent>evaluation of the impact of the tokenization parameter on the training process two tokenization tasks was performed on window sizes of -2 /+2 and -4/+4, for illustration see tok1 and tok2 tasks in figure 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE497">
<title id=" W08-0909.xml">an analysis of statistical models and features for reading difficulty prediction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are no grammatical features.
</prevsent>
<prevsent>natural language processing techniques enable more sophisticated grammatical analysis for reading difficulty measures.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
rather than using sentence length as proxy, measures can employ tools for automatic analysis of the syntactic structure of texts (e.g., (charniak, 2000)).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>a measure by schwarm and ostendorf (2005) <papid> P05-1065 </papid>incorporates syntactic analyses, among variety of other types of features.</nextsent>
<nextsent>it includes four grammatical features derived from syntactic parses of text: the mean parse tree height, the mean number of noun phrases, mean number of verb phrases, and mean number of sbars.?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE498">
<title id=" W08-0909.xml">an analysis of statistical models and features for reading difficulty prediction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language processing techniques enable more sophisticated grammatical analysis for reading difficulty measures.
</prevsent>
<prevsent>rather than using sentence length as proxy, measures can employ tools for automatic analysis of the syntactic structure of texts (e.g., (charniak, 2000)).<papid> A00-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
a measure by schwarm and ostendorf (2005) <papid> P05-1065 </papid>incorporates syntactic analyses, among variety of other types of features.</citsent>
<aftsection>
<nextsent>it includes four grammatical features derived from syntactic parses of text: the mean parse tree height, the mean number of noun phrases, mean number of verb phrases, and mean number of sbars.?
</nextsent>
<nextsent>sbarsare non-terminal nodes that are associated with subordinate clauses.
</nextsent>
<nextsent>their system led to better predictions than the flesch-kincaid and lexile measures, but the predictive value of the grammatical features is not entirely clear.
</nextsent>
<nextsent>in initial experiments using such course-grain grammatical features alone, rather than in conjunction with language modeling and other features as in schwarm and ostendorfssystem, we found relatively poor prediction performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE499">
<title id=" W08-0909.xml">an analysis of statistical models and features for reading difficulty prediction </title>
<section> types of features.  </section>
<citcontext>
<prevsection>
<prevsent>features of deeper levels occur less frequently in general, and deeper levels were avoided due to data sparseness.
</prevsent>
<prevsent>a depth first search algorithm extracts candidate grammatical features from the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
first, context-free grammar parser (klein and manning, 2003) <papid> P03-1054 </papid>derives parse trees for all texts in the training corpus.</citsent>
<aftsection>
<nextsent>the algorithm traverses these parses, at each node counting all subtree features up to the given depth that are rooted at that node.
</nextsent>
<nextsent>the subtree features are sorted by their overall counts in the corpus.
</nextsent>
<nextsent>in our experiments, frequencies of the most common 1000 subtrees were chosen as the final features.
</nextsent>
<nextsent>these included 64 level 0 features corresponding to nonterminal symbols, 334 level 1 features, 461 level 2 features, and 141 level 3 features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE501">
<title id=" W09-0613.xml">simple nlg a realisation engine for practical applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes simple nlg, realisation engine for english which aims to provide simple and robust interfaces to generate syntactic structures and linearisethem.
</prevsent>
<prevsent>the library is also flexible in allowing the use of mixed (canned and non canned) representations.
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
over the past several years, significant consensus has emerged over the definition of the realisation task, through the development of realisers such asrealpro (lavoie and rambow, 1997), <papid> A97-1039 </papid>aleth gen (coch, 1996), kpml (bateman, 1997),fuf/surge (elhadad and robin, 1996), <papid> W96-0501 </papid>halogen (langkilde, 2000), <papid> A00-2023 </papid>yag (mcroy et al, 2000), <papid> W00-1437 </papid>and openccg (white, 2006).<papid> W06-1403 </papid>realisation involves two logically distinguish able tasks.</citsent>
<aftsection>
<nextsent>tactical generation involves making appropriate linguistic choices given the semantic input.
</nextsent>
<nextsent>however, once tactical decisions have been taken, building syntactic representation, applying the right morphological operations, and lin ear ising the sentence as string are comparatively mechanical tasks.
</nextsent>
<nextsent>with the possible exception of template-based realisers, such as yag, existing wide-coverage realisers usually carry out both tasks.
</nextsent>
<nextsent>by contrast, realisation engine focuses onthe second of the two tasks, making no commitments as to how semantic inputs are mapped to syntactic outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE502">
<title id=" W09-0613.xml">simple nlg a realisation engine for practical applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes simple nlg, realisation engine for english which aims to provide simple and robust interfaces to generate syntactic structures and linearisethem.
</prevsent>
<prevsent>the library is also flexible in allowing the use of mixed (canned and non canned) representations.
</prevsent>
</prevsection>
<citsent citstr=" W96-0501 ">
over the past several years, significant consensus has emerged over the definition of the realisation task, through the development of realisers such asrealpro (lavoie and rambow, 1997), <papid> A97-1039 </papid>aleth gen (coch, 1996), kpml (bateman, 1997),fuf/surge (elhadad and robin, 1996), <papid> W96-0501 </papid>halogen (langkilde, 2000), <papid> A00-2023 </papid>yag (mcroy et al, 2000), <papid> W00-1437 </papid>and openccg (white, 2006).<papid> W06-1403 </papid>realisation involves two logically distinguish able tasks.</citsent>
<aftsection>
<nextsent>tactical generation involves making appropriate linguistic choices given the semantic input.
</nextsent>
<nextsent>however, once tactical decisions have been taken, building syntactic representation, applying the right morphological operations, and lin ear ising the sentence as string are comparatively mechanical tasks.
</nextsent>
<nextsent>with the possible exception of template-based realisers, such as yag, existing wide-coverage realisers usually carry out both tasks.
</nextsent>
<nextsent>by contrast, realisation engine focuses onthe second of the two tasks, making no commitments as to how semantic inputs are mapped to syntactic outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE503">
<title id=" W09-0613.xml">simple nlg a realisation engine for practical applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes simple nlg, realisation engine for english which aims to provide simple and robust interfaces to generate syntactic structures and linearisethem.
</prevsent>
<prevsent>the library is also flexible in allowing the use of mixed (canned and non canned) representations.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
over the past several years, significant consensus has emerged over the definition of the realisation task, through the development of realisers such asrealpro (lavoie and rambow, 1997), <papid> A97-1039 </papid>aleth gen (coch, 1996), kpml (bateman, 1997),fuf/surge (elhadad and robin, 1996), <papid> W96-0501 </papid>halogen (langkilde, 2000), <papid> A00-2023 </papid>yag (mcroy et al, 2000), <papid> W00-1437 </papid>and openccg (white, 2006).<papid> W06-1403 </papid>realisation involves two logically distinguish able tasks.</citsent>
<aftsection>
<nextsent>tactical generation involves making appropriate linguistic choices given the semantic input.
</nextsent>
<nextsent>however, once tactical decisions have been taken, building syntactic representation, applying the right morphological operations, and lin ear ising the sentence as string are comparatively mechanical tasks.
</nextsent>
<nextsent>with the possible exception of template-based realisers, such as yag, existing wide-coverage realisers usually carry out both tasks.
</nextsent>
<nextsent>by contrast, realisation engine focuses onthe second of the two tasks, making no commitments as to how semantic inputs are mapped to syntactic outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE504">
<title id=" W09-0613.xml">simple nlg a realisation engine for practical applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes simple nlg, realisation engine for english which aims to provide simple and robust interfaces to generate syntactic structures and linearisethem.
</prevsent>
<prevsent>the library is also flexible in allowing the use of mixed (canned and non canned) representations.
</prevsent>
</prevsection>
<citsent citstr=" W00-1437 ">
over the past several years, significant consensus has emerged over the definition of the realisation task, through the development of realisers such asrealpro (lavoie and rambow, 1997), <papid> A97-1039 </papid>aleth gen (coch, 1996), kpml (bateman, 1997),fuf/surge (elhadad and robin, 1996), <papid> W96-0501 </papid>halogen (langkilde, 2000), <papid> A00-2023 </papid>yag (mcroy et al, 2000), <papid> W00-1437 </papid>and openccg (white, 2006).<papid> W06-1403 </papid>realisation involves two logically distinguish able tasks.</citsent>
<aftsection>
<nextsent>tactical generation involves making appropriate linguistic choices given the semantic input.
</nextsent>
<nextsent>however, once tactical decisions have been taken, building syntactic representation, applying the right morphological operations, and lin ear ising the sentence as string are comparatively mechanical tasks.
</nextsent>
<nextsent>with the possible exception of template-based realisers, such as yag, existing wide-coverage realisers usually carry out both tasks.
</nextsent>
<nextsent>by contrast, realisation engine focuses onthe second of the two tasks, making no commitments as to how semantic inputs are mapped to syntactic outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE505">
<title id=" W09-0613.xml">simple nlg a realisation engine for practical applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes simple nlg, realisation engine for english which aims to provide simple and robust interfaces to generate syntactic structures and linearisethem.
</prevsent>
<prevsent>the library is also flexible in allowing the use of mixed (canned and non canned) representations.
</prevsent>
</prevsection>
<citsent citstr=" W06-1403 ">
over the past several years, significant consensus has emerged over the definition of the realisation task, through the development of realisers such asrealpro (lavoie and rambow, 1997), <papid> A97-1039 </papid>aleth gen (coch, 1996), kpml (bateman, 1997),fuf/surge (elhadad and robin, 1996), <papid> W96-0501 </papid>halogen (langkilde, 2000), <papid> A00-2023 </papid>yag (mcroy et al, 2000), <papid> W00-1437 </papid>and openccg (white, 2006).<papid> W06-1403 </papid>realisation involves two logically distinguish able tasks.</citsent>
<aftsection>
<nextsent>tactical generation involves making appropriate linguistic choices given the semantic input.
</nextsent>
<nextsent>however, once tactical decisions have been taken, building syntactic representation, applying the right morphological operations, and lin ear ising the sentence as string are comparatively mechanical tasks.
</nextsent>
<nextsent>with the possible exception of template-based realisers, such as yag, existing wide-coverage realisers usually carry out both tasks.
</nextsent>
<nextsent>by contrast, realisation engine focuses onthe second of the two tasks, making no commitments as to how semantic inputs are mapped to syntactic outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE507">
<title id=" W08-2211.xml">from predicting predominant senses to local context for word sense disambiguation </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P04-1036 ">
recent work on automatically predicting the predominant sense of word has proven to be promising (mccarthy et al , 2004).<papid> P04-1036 </papid></citsent>
<aftsection>
<nextsent>it can be applied (as first sense heuristic) to word sense disambiguation (wsd) tasks, without needing expensive hand-annotated datasets.
</nextsent>
<nextsent>due to the big skew in the sense distribution of many words (yarowsky and florian, 2002), the first sense heuristic for wsd is often hard to beat.
</nextsent>
<nextsent>however, the local context of an ambiguous word can give important clues to which of its senses was intended.
</nextsent>
<nextsent>the sense ranking method proposed by mccarthy et al  (2004)<papid> P04-1036 </papid>uses distributional similarity thesaurus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE515">
<title id=" W08-2211.xml">from predicting predominant senses to local context for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(non domain specific) text.
</prevsent>
<prevsent>mccarthy et al method was successfully applied to corpus of modern english text (the bnc (leech, 1992)) and the predicted predominant senses compared well with the gold standard given by semcor.
</prevsent>
</prevsection>
<citsent citstr=" H05-1053 ">
other experiments showed that the method can successfully be adapted to domain specific text (koeling et al , 2005) <papid> H05-1053 </papid>and other languages (for example, japanese (iida et al , 2008)).</citsent>
<aftsection>
<nextsent>even though the first sense heuristic is powerful, it would be preferable to onlyuse it for wsd, when either the sense distribution is so skewed that the most commonly used sense is by far the most dominant, or as back-off when few other clues are available to decide otherwise.
</nextsent>
<nextsent>the use of local context is ultimately necessary tofind evidence for the intended sense of an ambiguous word.
</nextsent>
<nextsent>in this paper we investigate how we can exploit results from intermediate steps taken when calculating the predominant senses to this end.
</nextsent>
<nextsent>the work on automatically finding predominant senses1 was partly inspired by the observation that you can identify word senses by looking at the nearest neighbours of atarget word in distributional thesaurus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE542">
<title id=" W08-2211.xml">from predicting predominant senses to local context for word sense disambiguation </title>
<section> predominant senses and local context.  </section>
<citcontext>
<prevsection>
<prevsent>it can be applied to all parts of speech, but the experiments in this paper all focus on nouns only.
</prevsent>
<prevsent>the method uses thesaurus obtained from the text by parsing, extracting grammatical relations and then listing each word (w) with its top nearest neighbours, where is constant.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
like mccarthy et al  (2004)<papid> P04-1036 </papid>we use = 50 and obtain our thesaurus using the distributional similarity metric described by lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>we use wordnet (wn) as our sense inventory.
</nextsent>
<nextsent>the senses of word are each assigned ranking score which sums over the distributional similarity scores of 2we use the same corpus used for generating the thesaurus as for the reference corpus (in all our experiments).
</nextsent>
<nextsent>132 koeling and mccarthy.
</nextsent>
<nextsent>the neighbours and weights each neighbours score by wn similarity score (pat wardhan and pedersen, 2003) between the sense of and the sense of the neighbour that maximises the wn similarity score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE552">
<title id=" W09-1408.xml">a memory based learning approach to event extraction in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bionlp shared task 2009 takes alinguistically-motivated approach, which is reflected in the properties of the shared task definition:rich semantics, text-bound approach, and decomposition of linguistic phenomena.
</prevsent>
<prevsent>memory-basedalgorithms have been successfully applied in language processing to wide range of linguistic tasks, from phonology to semantic analysis.
</prevsent>
</prevsection>
<citsent citstr=" W09-1105 ">
our goal was to investigate the performance of memory based approach to the event extraction task, using only the information available in the training corpus and modelling the task applying an approach similar to the one that has been applied to tasks like semantic role labeling (morante et al, 2008) or negation scope detection (morante and daelemans, 2009).<papid> W09-1105 </papid></citsent>
<aftsection>
<nextsent>in section 2 we briefly describe the task.
</nextsent>
<nextsent>section 3 reviews some related work.
</nextsent>
<nextsent>section 4 presents the system, and section 5 the results.
</nextsent>
<nextsent>finally, some conclusions are put forward in section 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE553">
<title id=" W09-1408.xml">a memory based learning approach to event extraction in biomedical texts </title>
<section> task description.  </section>
<citcontext>
<prevsection>
<prevsent>task 3: recognition of neg ations and speculations.the task did not include named entity recognition subtask.
</prevsent>
<prevsent>a gold standard set of named entity annotations for proteins was provided by the organisation.
</prevsent>
</prevsection>
<citsent citstr=" E99-1043 ">
a dataset based on the publicly available portion of the genia (collier et al, 1999) <papid> E99-1043 </papid>corpus annotated with events (kim et al, 2008) and of the bio infer (pyysalo et al, 2007) corpus was provided for training, and held-out parts of the same corpora were provided for development and testing.</citsent>
<aftsection>
<nextsent>the inter-annotator agreement reported for the genia event corpus is 56% strict match2, which means that the event type is the same, the clue expressions are overlapping and the themes are thesame.
</nextsent>
<nextsent>this low inter-annotator agreement is an indicator of the complexity of the task.
</nextsent>
<nextsent>similar lowinter-annotator agreement rates (49.00 %) in identification of events have been reported by sasaki et al (2008).<papid> C08-1096 </papid></nextsent>
<nextsent>in recent years, research on text mining in the biomedical domain has experienced substantial progress, as shown in reviews of work done in this field (krallinger and valencia, 2005; ananiadou and mcnaught, 2006; krallinger et al, 2008b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE554">
<title id=" W09-1408.xml">a memory based learning approach to event extraction in biomedical texts </title>
<section> task description.  </section>
<citcontext>
<prevsection>
<prevsent>the inter-annotator agreement reported for the genia event corpus is 56% strict match2, which means that the event type is the same, the clue expressions are overlapping and the themes are thesame.
</prevsent>
<prevsent>this low inter-annotator agreement is an indicator of the complexity of the task.
</prevsent>
</prevsection>
<citsent citstr=" C08-1096 ">
similar lowinter-annotator agreement rates (49.00 %) in identification of events have been reported by sasaki et al (2008).<papid> C08-1096 </papid></citsent>
<aftsection>
<nextsent>in recent years, research on text mining in the biomedical domain has experienced substantial progress, as shown in reviews of work done in this field (krallinger and valencia, 2005; ananiadou and mcnaught, 2006; krallinger et al, 2008b).
</nextsent>
<nextsent>some corpora have been annotated with event level information of different types: propbank-style frames (wattarujeekrit et al, 2004; chou et al, 2006), <papid> W06-0602 </papid>frame independent roles (kim et al, 2008), and specific roles for certain event types (sasaki et al,2008).<papid> C08-1096 </papid></nextsent>
<nextsent>the focus on extraction of event frames using machine learning techniques is relatively new because there were no corpora available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE555">
<title id=" W09-1408.xml">a memory based learning approach to event extraction in biomedical texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similar lowinter-annotator agreement rates (49.00 %) in identification of events have been reported by sasaki et al (2008).<papid> C08-1096 </papid></prevsent>
<prevsent>in recent years, research on text mining in the biomedical domain has experienced substantial progress, as shown in reviews of work done in this field (krallinger and valencia, 2005; ananiadou and mcnaught, 2006; krallinger et al, 2008b).</prevsent>
</prevsection>
<citsent citstr=" W06-0602 ">
some corpora have been annotated with event level information of different types: propbank-style frames (wattarujeekrit et al, 2004; chou et al, 2006), <papid> W06-0602 </papid>frame independent roles (kim et al, 2008), and specific roles for certain event types (sasaki et al,2008).<papid> C08-1096 </papid></citsent>
<aftsection>
<nextsent>the focus on extraction of event frames using machine learning techniques is relatively new because there were no corpora available.
</nextsent>
<nextsent>2we did not find inter-annotator agreement measures in the paper that describes the corpus (kim et al, 2008), but in www-tsujii.is.s.u-tokyo.ac.jp/t-fant/t-fant .files/slides/kim.pdf.most work focuses on extracting biological relations from corpora, which consists of finding associations between entities within text phrase.
</nextsent>
<nextsent>for example, bunds chus et al (2008) develop conditional random fields (crf) system to identify relations between genes and diseases from set of generif (gene reference into function) phrases.
</nextsent>
<nextsent>a shared task was organised in the framework ofthe language learning in logic workshop 2005 devoted to the extraction of relations from biomedical texts (nedellec, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE558">
<title id=" W09-1408.xml">a memory based learning approach to event extraction in biomedical texts </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>in the second phase, event participants and arguments are identified.
</prevsent>
<prevsent>in the third phase, postprocessing heuristics select the best frame for each event.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
parameter isation of the classifiers usedin phases 1 and 2 was performed by experimenting with sets of parameters on the development set.we experimented with manually selected parameters and with parameters selected by genetic algorithm, but the parameters found by the genetic algorithm did not yield better results than the manually selected parameters as first step, we pre process the corpora with the gdep dependency parser (sagae and tsujii, 2007)<papid> D07-1111 </papid>so that we can use part-of-speech tags and syntactic information as features for the machine learner.</citsent>
<aftsection>
<nextsent>gdep is a dependency parser for biomedical text trained on the tsujii labs genia treebank.
</nextsent>
<nextsent>the dependency parser predicts for every word the part of-speech tag, the lemma, the syntactic head, and the dependency relation.
</nextsent>
<nextsent>in addition to these regular dependency tags it also provides information about the iob-style chunks and named entities.
</nextsent>
<nextsent>the classifiers use the output of gdep in addition to some frequency measures as features.we represent the data into columns format, following the standard format of the conll shared task 2006 (buchholz and marsi, 2006), <papid> W06-2920 </papid>in which sentences are separated by blank line and fields are separated by single tab character.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE559">
<title id=" W09-1408.xml">a memory based learning approach to event extraction in biomedical texts </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the dependency parser predicts for every word the part of-speech tag, the lemma, the syntactic head, and the dependency relation.
</prevsent>
<prevsent>in addition to these regular dependency tags it also provides information about the iob-style chunks and named entities.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
the classifiers use the output of gdep in addition to some frequency measures as features.we represent the data into columns format, following the standard format of the conll shared task 2006 (buchholz and marsi, 2006), <papid> W06-2920 </papid>in which sentences are separated by blank line and fields are separated by single tab character.</citsent>
<aftsection>
<nextsent>a sentence consists of tokens, each one starting on new line.
</nextsent>
<nextsent>4.1 phase 1: entity detection.
</nextsent>
<nextsent>in the first phase, memory based classifier predicts for every word in the corpus whether it is an entity or not and the type of entity.
</nextsent>
<nextsent>in this setting, entity refers to what in the shared task definition are events and entities other than proteins.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE561">
<title id=" W09-1403.xml">event extraction from trimmed dependency graphs </title>
<section> event extraction solution.  </section>
<citcontext>
<prevsection>
<prevsent>the dependency edges are also represented as nodes in the new graph such that they are connected to the nodes adjacent in the dependency graph.
</prevsent>
<prevsent>subgraphs which represent, e.g., the linear order of the words in the sentence can be added, if required.
</prevsent>
</prevsection>
<citsent citstr=" W08-0601 ">
the entire graph is represented in terms of an adjacency matrix which is further processed to contain the summed weights of paths connecting two nodes of the graph (see airola et al (2008) <papid> W08-0601 </papid>for details).9we did not account for the binding of more than two proteins as this would have led to combinatory explosion of possible classifications.</citsent>
<aftsection>
<nextsent>10in our experiments, we used full conceptual overlaying (see section 3.2) for the kernel-based representation and partial overlaying for the dependency parse features (only gene/protein annotation was exploited here).
</nextsent>
<nextsent>graph representations allow for many semantic labels to be associated with node.
</nextsent>
<nextsent>11http://mallet.cs.umass.edu/index.php/ main_page figure 3: graph kernel representation for trimmed dependency graph ?
</nextsent>
<nextsent>(1) original representation, (2) representation without graph dependency edge nodes (weights (0.9, 0.3) taken from airola et al (2008)).<papid> W08-0601 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE566">
<title id=" W09-1403.xml">event extraction from trimmed dependency graphs </title>
<section> pipeline.  </section>
<citcontext>
<prevsection>
<prevsent>23
</prevsent>
<prevsent>the event extraction pipeline consists of two major parts, pre-processor and the dedicated event extractor.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
as far as pre-processing is concerned, we imported the sentence splitting, tokenization and gdep parsing results (sagae and tsujii, 2007) <papid> D07-1111 </papid>as prepared by the shared task organizers for all datasets (training, development and test).</citsent>
<aftsection>
<nextsent>we processed this data with the opennlp pos tagger and chun ker, both re-trained on the genia corpus (buyko et al., 2006).
</nextsent>
<nextsent>additionally, we enhanced the original tokenization by one which includes hyphen ization of lexical items such as in pma-dependent?.
</nextsent>
<nextsent>13the data was further processed with the gene normalizer geno(wermter et al, 2009) and number of regex- and dictionary-based entity taggers(covering promoters, binding sites, and transcription factors).
</nextsent>
<nextsent>we also enriched gene name mentions with their respective gene ontology annotations (see section 3.2.2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE567">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, words that occur in object relation with the verb drink have something in common: they are liquid.
</prevsent>
<prevsent>we will refer to words linked by syntactic relation, such as drink -objbeer, as syntactic co-occurrences.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
syntactic co-occurrences have often been used in work on lexical acquisition (lin, 1998<papid> P98-2127 </papid>b; dagan et al, 1999;curran and moens, 2002; <papid> W02-0908 </papid>alfonseca and manandhar, 2002).</citsent>
<aftsection>
<nextsent>distributional methods for automatic acquisition of semantically related words suffer from data sparseness.
</nextsent>
<nextsent>they generally perform less well on low-frequency words (weeds and weir, 2005;<papid> J05-4002 </papid>vander plas, 2008).</nextsent>
<nextsent>this is pity because the available resources for semantically related words usually cover the frequent words rather well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE568">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, words that occur in object relation with the verb drink have something in common: they are liquid.
</prevsent>
<prevsent>we will refer to words linked by syntactic relation, such as drink -objbeer, as syntactic co-occurrences.
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
syntactic co-occurrences have often been used in work on lexical acquisition (lin, 1998<papid> P98-2127 </papid>b; dagan et al, 1999;curran and moens, 2002; <papid> W02-0908 </papid>alfonseca and manandhar, 2002).</citsent>
<aftsection>
<nextsent>distributional methods for automatic acquisition of semantically related words suffer from data sparseness.
</nextsent>
<nextsent>they generally perform less well on low-frequency words (weeds and weir, 2005;<papid> J05-4002 </papid>vander plas, 2008).</nextsent>
<nextsent>this is pity because the available resources for semantically related words usually cover the frequent words rather well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE569">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntactic co-occurrences have often been used in work on lexical acquisition (lin, 1998<papid> P98-2127 </papid>b; dagan et al, 1999;curran and moens, 2002; <papid> W02-0908 </papid>alfonseca and manandhar, 2002).</prevsent>
<prevsent>distributional methods for automatic acquisition of semantically related words suffer from data sparseness.</prevsent>
</prevsection>
<citsent citstr=" J05-4002 ">
they generally perform less well on low-frequency words (weeds and weir, 2005;<papid> J05-4002 </papid>vander plas, 2008).</citsent>
<aftsection>
<nextsent>this is pity because the available resources for semantically related words usually cover the frequent words rather well.
</nextsent>
<nextsent>it is for the low-frequency words that automatic methods would be most welcome.this paper tries to find way to improve the performance on the words that are most wanted: the middle to very-low-frequency words.
</nextsent>
<nextsent>at the basis ofthe proposed technique lies the intuition that semantic similarity between concepts is transitive: if is like and is like ? is like c. as explained in the second paragraph of this section, the fact that both milk and water are found in object relation with the verb to drink tells us that they might be similar.
</nextsent>
<nextsent>however, even if we had never seen lemonade in thesame syntactic contexts as water, we could still infer that lemonade and water are similar because we have found evidence that both water and lemonade are similar to milk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE570">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we will compare second order technique with third-order technique, technique that computes third-order affinities.
</prevsent>
<prevsent>in addition we use combined technique that combines both second-order and third-order techniques.
</prevsent>
</prevsection>
<citsent citstr=" P97-1067 ">
in edmonds (1997) <papid> P97-1067 </papid>the term third-order is used to refer to different concept.</citsent>
<aftsection>
<nextsent>firstly, we have to mention that the author is working in proximity based framework, that is, he is concerned with cooccurrences of words in text, not relations between words in syntactic dependencies.
</nextsent>
<nextsent>secondly, the notion of higher-order co-occurrences refers to connectivity paths in networks, i.e. the network of relations between words co-occurring is augmented by connecting words that are connected by path of length 2 (second-order co-occurrences) and paths 1grefenstette (1994) uses the term third-order affinities for different concept, i.e. for the sub groupings that can be found in list of second-order nearest neighbours.
</nextsent>
<nextsent>of length 3 (third-order co-occurrences) and so on.
</nextsent>
<nextsent>in the above example water and lemonade would be connected by second-order relation implied bythe network in which water and lemonade both cooccur with for example to pour.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE571">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 syntax-based distributional similarity.
</prevsent>
<prevsent>in this section we will describe the syntactic contexts selected, the data we used, and the measures and weights applied to retrieve nearest neighbours.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
4.1.1 syntactic context most research has been done using limited number of syntactic relations (lee, 1999; <papid> P99-1004 </papid>weeds, 2003).we use several syntactic relations: subject, object, adjective, coordination, apposition, and prepositional complement.</citsent>
<aftsection>
<nextsent>in figure 1 examples are given for these types of syntactic relations.2 subj: de kat eet.
</nextsent>
<nextsent>the cat eats.?
</nextsent>
<nextsent>obj: ik voer de kat.
</nextsent>
<nextsent>i feed the cat.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE572">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>intuitively, the fact that two nouns both occur as subject of hebben tells us less about their semantic similarity than the fact that two nouns both occur as the direct object of feed.
</prevsent>
<prevsent>the results of vector-based methods can be improved if we take into account the fact that not all combinations ofa word and syntactic relation have the same information value.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
we have used pointwise mutual information (pmi, church and hanks (1989)) <papid> P89-1010 </papid>to account for the differences in information value between the several headwords and attributes.</citsent>
<aftsection>
<nextsent>the more similar the co-occurrence vectors of any two headwords are, the more distributionally similar the headwords are.
</nextsent>
<nextsent>in order to compare the vectors of any two headwords, we need similarity measure.
</nextsent>
<nextsent>in these experiments we have used variant of dice: dice?, proposed by curran and moens (2002).<papid> W02-0908 </papid></nextsent>
<nextsent>it is defined as: dice?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE577">
<title id=" W09-1706.xml">combining syntactic cooccurrences and nearest neighbours in distributional methods to remedy data sparseness </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>especially for dutch there are not many resources to evaluate semantically related words available.for each word we collected its nearest neighbours according to the system.
</prevsent>
<prevsent>for each pair ofwords4 (target word plus one of the nearest neighbours) we calculated the semantic similarity according to ewn.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
we used the wu and palmer measure (wu and palmer, 1994) <papid> P94-1019 </papid>applied to dutch ewn for computing the semantic similarity between two words.5 the ewn similarity of set of word pairs is defined as the average of the similarity between the pairs.</citsent>
<aftsection>
<nextsent>the wu and palmer measure for computing the semantic similarity between two words (w1 and w2) in wordnet, whose most specific common subsumer (lowest super-ordinate) is w3, is defined as follows: sim(w1,w2) = 2(d3)d1 + d2 + 2(d3) we computed, d1 (d2) as the distance from w1 (w2) to the lowest common ancestor of w1 and w2, w3.
</nextsent>
<nextsent>d3 is the distance of that ancestor to the root node.some words returned by the system as nearest neighbours cannot be found in ewn.
</nextsent>
<nextsent>because counting the words not found in ewn as errors would be too harsh6 we select the next nearest neighbour that is found in ewn, when encountering not found word.
</nextsent>
<nextsent>the wu and palmer measure gives an indication of the degree of semantic similarity among there 4if word is ambiguous according to ewn, i.e. is member of several synsets, the highest similarity score is used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE581">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>1.1 approaches to asgre.
</prevsent>
<prevsent>since early work on asgre, which focused on pragmatic motivations behind different types of reference (appelt, 1985; appelt and kronfeld, 1987), the focus has increasingly been on definite description sand identification, where the set of attributes selected should uniquely distinguish the intended referent from other entities (its distractors?).
</prevsent>
</prevsection>
<citsent citstr=" P89-1009 ">
unique reference in this sense is dominant criterion for selecting attribute sets in classic asgre algorithms.following dale (1989), <papid> P89-1009 </papid>and especially dale andre iter (1995), several contributions have extended the remit of asgre algorithms to handle relations (dale and haddock, 1991; <papid> E91-1028 </papid>kelleher and kruijff, 2006) <papid> P06-1131 </papid>and grad able attributes (van deemter, 2006); and also to guarantee logical completeness of algorithms (van deemter, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2004; gatt and van deemter, 2007).<papid> D07-1011 </papid>much of this work has incorporated the principle of brevity.</citsent>
<aftsection>
<nextsent>based on the gricean quantity maxim (grice, 1975), and originally discussed by appelt (1985), and further by dale (1989), <papid> P89-1009 </papid>reiter (1990) <papid> P90-1013 </papid>and gardent (2002), <papid> P02-1013 </papid>this principle holds that descriptions should contain no more information than is necessary to distinguish an intended referent.</nextsent>
<nextsent>in asgre, this has been translated into criterion which determines the adequacy of an attribute set, implemented in its most straightforward form infull brevity algorithms which select the smallest attribute set that uniquely refers to the intended referent (dale, 1989).<papid> P89-1009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE585">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>1.1 approaches to asgre.
</prevsent>
<prevsent>since early work on asgre, which focused on pragmatic motivations behind different types of reference (appelt, 1985; appelt and kronfeld, 1987), the focus has increasingly been on definite description sand identification, where the set of attributes selected should uniquely distinguish the intended referent from other entities (its distractors?).
</prevsent>
</prevsection>
<citsent citstr=" E91-1028 ">
unique reference in this sense is dominant criterion for selecting attribute sets in classic asgre algorithms.following dale (1989), <papid> P89-1009 </papid>and especially dale andre iter (1995), several contributions have extended the remit of asgre algorithms to handle relations (dale and haddock, 1991; <papid> E91-1028 </papid>kelleher and kruijff, 2006) <papid> P06-1131 </papid>and grad able attributes (van deemter, 2006); and also to guarantee logical completeness of algorithms (van deemter, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2004; gatt and van deemter, 2007).<papid> D07-1011 </papid>much of this work has incorporated the principle of brevity.</citsent>
<aftsection>
<nextsent>based on the gricean quantity maxim (grice, 1975), and originally discussed by appelt (1985), and further by dale (1989), <papid> P89-1009 </papid>reiter (1990) <papid> P90-1013 </papid>and gardent (2002), <papid> P02-1013 </papid>this principle holds that descriptions should contain no more information than is necessary to distinguish an intended referent.</nextsent>
<nextsent>in asgre, this has been translated into criterion which determines the adequacy of an attribute set, implemented in its most straightforward form infull brevity algorithms which select the smallest attribute set that uniquely refers to the intended referent (dale, 1989).<papid> P89-1009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE586">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>1.1 approaches to asgre.
</prevsent>
<prevsent>since early work on asgre, which focused on pragmatic motivations behind different types of reference (appelt, 1985; appelt and kronfeld, 1987), the focus has increasingly been on definite description sand identification, where the set of attributes selected should uniquely distinguish the intended referent from other entities (its distractors?).
</prevsent>
</prevsection>
<citsent citstr=" P06-1131 ">
unique reference in this sense is dominant criterion for selecting attribute sets in classic asgre algorithms.following dale (1989), <papid> P89-1009 </papid>and especially dale andre iter (1995), several contributions have extended the remit of asgre algorithms to handle relations (dale and haddock, 1991; <papid> E91-1028 </papid>kelleher and kruijff, 2006) <papid> P06-1131 </papid>and grad able attributes (van deemter, 2006); and also to guarantee logical completeness of algorithms (van deemter, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2004; gatt and van deemter, 2007).<papid> D07-1011 </papid>much of this work has incorporated the principle of brevity.</citsent>
<aftsection>
<nextsent>based on the gricean quantity maxim (grice, 1975), and originally discussed by appelt (1985), and further by dale (1989), <papid> P89-1009 </papid>reiter (1990) <papid> P90-1013 </papid>and gardent (2002), <papid> P02-1013 </papid>this principle holds that descriptions should contain no more information than is necessary to distinguish an intended referent.</nextsent>
<nextsent>in asgre, this has been translated into criterion which determines the adequacy of an attribute set, implemented in its most straightforward form infull brevity algorithms which select the smallest attribute set that uniquely refers to the intended referent (dale, 1989).<papid> P89-1009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE587">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>1.1 approaches to asgre.
</prevsent>
<prevsent>since early work on asgre, which focused on pragmatic motivations behind different types of reference (appelt, 1985; appelt and kronfeld, 1987), the focus has increasingly been on definite description sand identification, where the set of attributes selected should uniquely distinguish the intended referent from other entities (its distractors?).
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
unique reference in this sense is dominant criterion for selecting attribute sets in classic asgre algorithms.following dale (1989), <papid> P89-1009 </papid>and especially dale andre iter (1995), several contributions have extended the remit of asgre algorithms to handle relations (dale and haddock, 1991; <papid> E91-1028 </papid>kelleher and kruijff, 2006) <papid> P06-1131 </papid>and grad able attributes (van deemter, 2006); and also to guarantee logical completeness of algorithms (van deemter, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2004; gatt and van deemter, 2007).<papid> D07-1011 </papid>much of this work has incorporated the principle of brevity.</citsent>
<aftsection>
<nextsent>based on the gricean quantity maxim (grice, 1975), and originally discussed by appelt (1985), and further by dale (1989), <papid> P89-1009 </papid>reiter (1990) <papid> P90-1013 </papid>and gardent (2002), <papid> P02-1013 </papid>this principle holds that descriptions should contain no more information than is necessary to distinguish an intended referent.</nextsent>
<nextsent>in asgre, this has been translated into criterion which determines the adequacy of an attribute set, implemented in its most straightforward form infull brevity algorithms which select the smallest attribute set that uniquely refers to the intended referent (dale, 1989).<papid> P89-1009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE588">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>1.1 approaches to asgre.
</prevsent>
<prevsent>since early work on asgre, which focused on pragmatic motivations behind different types of reference (appelt, 1985; appelt and kronfeld, 1987), the focus has increasingly been on definite description sand identification, where the set of attributes selected should uniquely distinguish the intended referent from other entities (its distractors?).
</prevsent>
</prevsection>
<citsent citstr=" D07-1011 ">
unique reference in this sense is dominant criterion for selecting attribute sets in classic asgre algorithms.following dale (1989), <papid> P89-1009 </papid>and especially dale andre iter (1995), several contributions have extended the remit of asgre algorithms to handle relations (dale and haddock, 1991; <papid> E91-1028 </papid>kelleher and kruijff, 2006) <papid> P06-1131 </papid>and grad able attributes (van deemter, 2006); and also to guarantee logical completeness of algorithms (van deemter, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2004; gatt and van deemter, 2007).<papid> D07-1011 </papid>much of this work has incorporated the principle of brevity.</citsent>
<aftsection>
<nextsent>based on the gricean quantity maxim (grice, 1975), and originally discussed by appelt (1985), and further by dale (1989), <papid> P89-1009 </papid>reiter (1990) <papid> P90-1013 </papid>and gardent (2002), <papid> P02-1013 </papid>this principle holds that descriptions should contain no more information than is necessary to distinguish an intended referent.</nextsent>
<nextsent>in asgre, this has been translated into criterion which determines the adequacy of an attribute set, implemented in its most straightforward form infull brevity algorithms which select the smallest attribute set that uniquely refers to the intended referent (dale, 1989).<papid> P89-1009 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE593">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>since early work on asgre, which focused on pragmatic motivations behind different types of reference (appelt, 1985; appelt and kronfeld, 1987), the focus has increasingly been on definite description sand identification, where the set of attributes selected should uniquely distinguish the intended referent from other entities (its distractors?).
</prevsent>
<prevsent>unique reference in this sense is dominant criterion for selecting attribute sets in classic asgre algorithms.following dale (1989), <papid> P89-1009 </papid>and especially dale andre iter (1995), several contributions have extended the remit of asgre algorithms to handle relations (dale and haddock, 1991; <papid> E91-1028 </papid>kelleher and kruijff, 2006) <papid> P06-1131 </papid>and grad able attributes (van deemter, 2006); and also to guarantee logical completeness of algorithms (van deemter, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2004; gatt and van deemter, 2007).<papid> D07-1011 </papid>much of this work has incorporated the principle of brevity.</prevsent>
</prevsection>
<citsent citstr=" P90-1013 ">
based on the gricean quantity maxim (grice, 1975), and originally discussed by appelt (1985), and further by dale (1989), <papid> P89-1009 </papid>reiter (1990) <papid> P90-1013 </papid>and gardent (2002), <papid> P02-1013 </papid>this principle holds that descriptions should contain no more information than is necessary to distinguish an intended referent.</citsent>
<aftsection>
<nextsent>in asgre, this has been translated into criterion which determines the adequacy of an attribute set, implemented in its most straightforward form infull brevity algorithms which select the smallest attribute set that uniquely refers to the intended referent (dale, 1989).<papid> P89-1009 </papid></nextsent>
<nextsent>another frequent property of asgre algorithms is incrementality which involves selection of attributes one at time (rather than exhaustive search for distinguishing set), and was initially motivated byalgorithmic complexity considerations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE606">
<title id=" W08-1108.xml">attribute selection for referring expression generation new algorithms and evaluation methods </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the very strong correlation (0.97) between dice and masi is to be expected, given the similarity in the way they are defined.
</prevsent>
<prevsent>another unambiguous result emerges: none of the similarity-based metrics covary significantly with any of the task-performance measures.
</prevsent>
</prevsection>
<citsent citstr=" P08-2050 ">
an extended analysis involving larger range of intrinsic metrics confirmed this lack of significant covariationfor string-based similarity metrics as well as set similarity metrics across two task-performance experiments (belz and gatt, 2008).<papid> P08-2050 </papid></citsent>
<aftsection>
<nextsent>this indicates that at least for some areas of hlt, task-performance evaluation is vital: without the external reality check provided by extrinsic evaluations, intrinsic evaluations may end up being too self-contained and disconnected from notions of usefulness to provide meaningful assessment of systems?
</nextsent>
<nextsent>quality.
</nextsent>
<nextsent>comparative evaluation can be of great benefit, especially in an area as mature and diverse as gre.
</nextsent>
<nextsent>a shared-task evaluation like the asgre challenge can help identify the strengths and weaknesses of alternative approaches and techniques, as measured by different evaluation criteria.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE607">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most wsi systems are based on the vector-space model that represents each context of target wordas vector of features (e.g. frequency of cooccurring words).
</prevsent>
<prevsent>vectors are clustered and the resulting clusters are taken to represent the induced senses.
</prevsent>
</prevsection>
<citsent citstr=" E03-1020 ">
recently, graph-based methods have been employed to wsi (dorow and widdows, 2003; <papid> E03-1020 </papid>veronis, 2004; agirre and soroa, 2007<papid> W07-2075 </papid>b).</citsent>
<aftsection>
<nextsent>typically, graph-based approaches represent each word co-occurring with the target word, within pre-specified window, as vertex.
</nextsent>
<nextsent>two vertices are connected via an edge if they co-occur in oneor more contexts of the target word.
</nextsent>
<nextsent>this cooccurrence graph is then clustered employing different graph clustering algorithms to induce the senses.each cluster (induced sense) consists of words expected to be topically related to the particular sense.
</nextsent>
<nextsent>as result, graph-based approaches assume that each context word is related to one and only one sense of the target one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE608">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most wsi systems are based on the vector-space model that represents each context of target wordas vector of features (e.g. frequency of cooccurring words).
</prevsent>
<prevsent>vectors are clustered and the resulting clusters are taken to represent the induced senses.
</prevsent>
</prevsection>
<citsent citstr=" W07-2075 ">
recently, graph-based methods have been employed to wsi (dorow and widdows, 2003; <papid> E03-1020 </papid>veronis, 2004; agirre and soroa, 2007<papid> W07-2075 </papid>b).</citsent>
<aftsection>
<nextsent>typically, graph-based approaches represent each word co-occurring with the target word, within pre-specified window, as vertex.
</nextsent>
<nextsent>two vertices are connected via an edge if they co-occur in oneor more contexts of the target word.
</nextsent>
<nextsent>this cooccurrence graph is then clustered employing different graph clustering algorithms to induce the senses.each cluster (induced sense) consists of words expected to be topically related to the particular sense.
</nextsent>
<nextsent>as result, graph-based approaches assume that each context word is related to one and only one sense of the target one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE616">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as result, they pro 36 posed the use of graph-based model for wsi, in which each vertex of the graph corresponds to acollocation (word-pair) that co-occurs with the target word, while edges are drawn based on the cooccurrence frequency of their associated collocations.
</prevsent>
<prevsent>clustering of this collocational graph would produce clusters, which consist of set of collocations.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the intuition is that the produced clusters will be less sense-conflating than those produced by other graph-based approaches, since collocations provide strong and consistent clues to the senses of target word (yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>the collocational graph-based approach as wellas the majority of state-of-the-art wsi systems estimate their parameters either empirically or by employing supervised techniques.
</nextsent>
<nextsent>the semeval-2007 wsi task (swsi) participating systems uoy and ubc-as used labeled data for parameter estimation (agirre and soroa, 2007<papid> W07-2075 </papid>a), while the authors of i2r,upv si and umnd2 have empirically chosen values for their parameters.</nextsent>
<nextsent>this issue imposes limits on the unsupervised nature of these algorithms, as well as on their performance on different datasets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE625">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the semeval-2007 wsi task (swsi) participating systems uoy and ubc-as used labeled data for parameter estimation (agirre and soroa, 2007<papid> W07-2075 </papid>a), while the authors of i2r,upv si and umnd2 have empirically chosen values for their parameters.</prevsent>
<prevsent>this issue imposes limits on the unsupervised nature of these algorithms, as well as on their performance on different datasets.</prevsent>
</prevsection>
<citsent citstr=" N07-1032 ">
more specifically, when applying an unsupervised wsi system on different datasets, one cannot be sure that the same set of parameters is appropriate for all datasets (karakos et al, 2007).<papid> N07-1032 </papid></citsent>
<aftsection>
<nextsent>in most cases, new parameter tuning might be necessary.
</nextsent>
<nextsent>unsupervised estimation of free parameters may enhance the unsupervised nature of systems, making them applicable to any dataset, even if there are no tagged data available.
</nextsent>
<nextsent>in this paper, we focus on estimating the free parameters of the collocational graph-based wsi method (klapaftis and manandhar, 2008) using eight graph connectivity measures (gcm).
</nextsent>
<nextsent>given aparameter setting and the associated induced clustering solution, each induced cluster corresponds to subgraph of the original un clustered graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE626">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> collocational graphs for wsi.  </section>
<citcontext>
<prevsection>
<prevsent>initially, tw is removed from bc and both bc and rc are pos-tagged.in the next step, only nouns are kept in the paragraphs of bc, since they are characterised by higher discriminative ability than verbs, adverbs or adjectives which may appear in variety of different contexts.
</prevsent>
<prevsent>at the end of this pre-processing step, each paragraph of bc and rc is list of lemmatized nouns (klapaftis and manandhar, 2008).in the next step, the paragraphs of bc are filtered by removing common nouns which are noisy;contextually not related to tw.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
given contextual word cw that occurs in the paragraphs of bc, log-likelihood ratio (g2) test is employed (dunning, 1993), <papid> J93-1003 </papid>which checks if the distribution of cw in bc is similar to the distribution of cw in rc; p(cw|bc) = p(cw|rc) (null hypothesis).</citsent>
<aftsection>
<nextsent>if this is true, g2 has small value.
</nextsent>
<nextsent>if this value is less than pre-specified threshold (parameter p1) the noun is removed from bc.1the british national corpus (bnc) (2001, version 2).
</nextsent>
<nextsent>distributed by oxford university computing services.
</nextsent>
<nextsent>37 target: cnn nbc target: nbc news nbc tv nbc tv cnn tv soap opera cnn radio nbc show news newscast news newscast radio television nbc news hour cnn headline cnn headline nbc politics radio tv breaking news breaking news table 1: collocations connected to cnn nbc and nbc news this process identifies nouns that are more indicative in bc than in rc and vice versa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE627">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> collocational graphs for wsi.  </section>
<citcontext>
<prevsection>
<prevsent>p(j|i) is defined similarly.
</prevsent>
<prevsent>inducing senses and tagging in this final stage, the collocational graph is clustered to produced the senses (clusters) of the target word.
</prevsent>
</prevsection>
<citsent citstr=" W06-3812 ">
the clustering method employed is chinese whispers (cw) (bie mann, 2006).<papid> W06-3812 </papid></citsent>
<aftsection>
<nextsent>cw is linear to the number of graph edges, while it offers the advantage that it does not require any input parameters, producing the clusters of graph automatically.
</nextsent>
<nextsent>38 figure 1: an example undirected weighted graph.
</nextsent>
<nextsent>initially, cw assigns all vertices to different classes.
</nextsent>
<nextsent>each vertex is processed for number of iterations and inherits the strongest class in its local neighbourhood (ln) in an update step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE629">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> unsupervised parameter tuning.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we investigate unsupervised ways to address the issue of choosing parameter values.
</prevsent>
<prevsent>tothis end, we employ variety of gcm, which measure the relative importance of each vertex and assess the overall connectivity of the corresponding graph.
</prevsent>
</prevsection>
<citsent citstr=" W07-0201 ">
these measures are average degree, cluster coefficient, graph entropy and edge density (navigli and lapata, 2007; zesch and gurevych, 2007).<papid> W07-0201 </papid></citsent>
<aftsection>
<nextsent>gcm quantify the degree of connectivity of the produced clusters (subgraphs), which represent the senses (uses) of the target word forgiven clustering solution (parameter setting).
</nextsent>
<nextsent>higher values ofgcm indicate subgraphs (clusters) of higher connectivity.
</nextsent>
<nextsent>given parameter setting, the induced clustering solution and graph connectivity measuregcmi, each induced cluster is assigned the resulting score of applying gcmi on the corresponding subgraph of the initial un clustered graph.
</nextsent>
<nextsent>each clustering solution is assigned the average of the scores of its clusters (table 6), and the highest scoring one is selected.for each measure, we have developed two versions, i.e. one which considers the edge weights in the subgraph, and second which does not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE638">
<title id=" W09-1705.xml">graph connectivity measures for unsupervised parameter tuning of graph based sense induction systems </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 experimental setting.
</prevsent>
<prevsent>the collocational wsi approach was evaluated under the framework and corpus of semeval-2007 wsi task (agirre and soroa, 2007<papid> W07-2075 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
the corpus consists of text of the wall street journal corpus, and is hand-tagged with ontonotes senses (hovy et al., 2006).<papid> N06-2015 </papid></citsent>
<aftsection>
<nextsent>the evaluation focuses on all 35 nouns of swsi.
</nextsent>
<nextsent>swsi task employs two evaluation schemes.
</nextsent>
<nextsent>in unsupervised evaluation, the results are treated as clusters of contexts and gold standard (gs) sen sesas classes.
</nextsent>
<nextsent>in perfect clustering solution, each induced cluster contains the same contexts as one of the classes (homogeneity), and each class contains the same contexts as one of the clusters (complete ness).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE647">
<title id=" W08-0911.xml">real time web text classification and analysis of reading difficulty </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>reaps information retrieval system (collins-thompson and callan, 2004) contains material from about 5 million pages gathered with web crawling methods.
</prevsent>
<prevsent>thedata have been annotated and indexed off-line.
</prevsent>
</prevsection>
<citsent citstr=" N07-1058 ">
annotations include readability level computed with an earlier version of the method developed by (heilmanet al, 2007), (<papid> N07-1058 </papid>heilman et al, 2006) described below, rough topic categorizations (e.g., fiction, non fiction) and some elements of grammatical structure (e.g., part-of-speech tagging).</citsent>
<aftsection>
<nextsent>(heilman et al, 2007) <papid> N07-1058 </papid>experiment with system for evaluation of reading difficulty which employs both grammatical features and vocabulary.</nextsent>
<nextsent>the grammatical features built in the model were identified from grammar books used in three esl levels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE652">
<title id=" W08-0911.xml">real time web text classification and analysis of reading difficulty </title>
<section> description of toreador.  </section>
<citcontext>
<prevsection>
<prevsent>example (1) is harder to read than example (2) although the latter is longer sentence.
</prevsent>
<prevsent>(1) she told me little white lie will come back to haunt me.
</prevsent>
</prevsection>
<citsent citstr=" N04-1024 ">
(2) she told me that little white lie will come back to haunt me. secondly, it is well known that there are aspects of textual coherence such as topic continuity and rhetorical structure which are not captured in counts of words and sentences (e.g., (higgins et al, 2004), (<papid> N04-1024 </papid>miltsakaki and kukich, 2004))thirdly, readability formulas do not take into account the profile of the reader.</citsent>
<aftsection>
<nextsent>for example, reader who has read lot of literary texts will have less difficulty reading new literary text than reader, with similar educational background, who has never read 93 figure 1: search results and analysis of readability any literature.
</nextsent>
<nextsent>in this section, we discuss the first step we have taken towards making more reliable predictions on text readability given the profile of the reader.
</nextsent>
<nextsent>readers who are familiar with specific thematic areas, are more likely to know vocabulary that is recurring in these areas.
</nextsent>
<nextsent>so, if we have vocabulary frequency counts per thematic area, we are in better position to predict difficult words for specific readers given their reading profiles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE653">
<title id=" W09-1606.xml">investigation in statistical language independent approaches for opinion detection in english chinese and japanese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>both sentences contain the clue word said?
</prevsent>
<prevsent>but only the first one contains an opinion on the target product.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
turney (2002) <papid> P02-1053 </papid>suggested comparing the frequency of phrase co-occurrences with words predetermined by the sentiment lexicon.</citsent>
<aftsection>
<nextsent>specific to the opinion detection in chinese language ku et al.
</nextsent>
<nextsent>(2006) propose dictionary-based approach for extraction and summarization.
</nextsent>
<nextsent>for the japanese language in the last ntcir-6 and ntcir-7 workshops the opinion finding methods included the use of supervised machine learning approaches with specific selection of certain parts-of-speech (pos) and sentence parts in the form of n-gram features to improve performance.
</nextsent>
<nextsent>there has been trend in applying language models for opinion detection task (lavrenko, croft, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE654">
<title id=" W09-1606.xml">investigation in statistical language independent approaches for opinion detection in english chinese and japanese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for the japanese language in the last ntcir-6 and ntcir-7 workshops the opinion finding methods included the use of supervised machine learning approaches with specific selection of certain parts-of-speech (pos) and sentence parts in the form of n-gram features to improve performance.
</prevsent>
<prevsent>there has been trend in applying language models for opinion detection task (lavrenko, croft, 2001).
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
pang &amp; lee (2004) <papid> P04-1035 </papid>propose the use of language models for sentiment analysis task and subjectivity extraction.</citsent>
<aftsection>
<nextsent>usually, language models are trained on the labeled data and as an output they give probabilities of classified tokens belonging to the class.
</nextsent>
<nextsent>eguchi &amp; lavrenko (2006) <papid> W06-1641 </papid>propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevancy.</nextsent>
<nextsent>as an alternative other teams during the last trec and ntcir evaluation campaigns have suggested variations of nave bayes classifier, language models and svm, along with the use of such heuristics as word order, punctuation, sentence length, etc. we might also mention opinion finder (wilson et al, 2005), <papid> H05-2018 </papid>more complex system that performs subjectivity analyses to identify opinions as well as sentiments and other private states (speculations, dreams, etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE655">
<title id=" W09-1606.xml">investigation in statistical language independent approaches for opinion detection in english chinese and japanese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pang &amp; lee (2004) <papid> P04-1035 </papid>propose the use of language models for sentiment analysis task and subjectivity extraction.</prevsent>
<prevsent>usually, language models are trained on the labeled data and as an output they give probabilities of classified tokens belonging to the class.</prevsent>
</prevsection>
<citsent citstr=" W06-1641 ">
eguchi &amp; lavrenko (2006) <papid> W06-1641 </papid>propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevancy.</citsent>
<aftsection>
<nextsent>as an alternative other teams during the last trec and ntcir evaluation campaigns have suggested variations of nave bayes classifier, language models and svm, along with the use of such heuristics as word order, punctuation, sentence length, etc. we might also mention opinion finder (wilson et al, 2005), <papid> H05-2018 </papid>more complex system that performs subjectivity analyses to identify opinions as well as sentiments and other private states (speculations, dreams, etc.).</nextsent>
<nextsent>this system is based on various classical computational linguistics components (tokenization, part-of-speech (pos) tagging (toutano va &amp; manning, 2000) <papid> W00-1308 </papid>as well as classification tools.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE656">
<title id=" W09-1606.xml">investigation in statistical language independent approaches for opinion detection in english chinese and japanese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>usually, language models are trained on the labeled data and as an output they give probabilities of classified tokens belonging to the class.
</prevsent>
<prevsent>eguchi &amp; lavrenko (2006) <papid> W06-1641 </papid>propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevancy.</prevsent>
</prevsection>
<citsent citstr=" H05-2018 ">
as an alternative other teams during the last trec and ntcir evaluation campaigns have suggested variations of nave bayes classifier, language models and svm, along with the use of such heuristics as word order, punctuation, sentence length, etc. we might also mention opinion finder (wilson et al, 2005), <papid> H05-2018 </papid>more complex system that performs subjectivity analyses to identify opinions as well as sentiments and other private states (speculations, dreams, etc.).</citsent>
<aftsection>
<nextsent>this system is based on various classical computational linguistics components (tokenization, part-of-speech (pos) tagging (toutano va &amp; manning, 2000) <papid> W00-1308 </papid>as well as classification tools.</nextsent>
<nextsent>for example, nave bayes classifier (wit ten &amp; frank, 2005) is used to distinguish between subjective and objective sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE657">
<title id=" W09-1606.xml">investigation in statistical language independent approaches for opinion detection in english chinese and japanese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>eguchi &amp; lavrenko (2006) <papid> W06-1641 </papid>propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevancy.</prevsent>
<prevsent>as an alternative other teams during the last trec and ntcir evaluation campaigns have suggested variations of nave bayes classifier, language models and svm, along with the use of such heuristics as word order, punctuation, sentence length, etc. we might also mention opinion finder (wilson et al, 2005), <papid> H05-2018 </papid>more complex system that performs subjectivity analyses to identify opinions as well as sentiments and other private states (speculations, dreams, etc.).</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
this system is based on various classical computational linguistics components (tokenization, part-of-speech (pos) tagging (toutano va &amp; manning, 2000) <papid> W00-1308 </papid>as well as classification tools.</citsent>
<aftsection>
<nextsent>for example, nave bayes classifier (wit ten &amp; frank, 2005) is used to distinguish between subjective and objective sentences.
</nextsent>
<nextsent>a rule-based system is included to identify both speech events (said,?
</nextsent>
<nextsent>according to?)
</nextsent>
<nextsent>and direct subjective expressions (is happy,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE659">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>machine translation (mt) from chinese to english has been difficult problem: structural differences between chinese and english, such asthe different orderings of head nouns and relative clauses, cause bleu scores to be consistently lower than for other difficult language pairs like arabic-english.
</prevsent>
<prevsent>many of these structural differences are related to the ubiquitous chinese {(de) construction, used for wide range of noun modification constructions (both single word and clausal) and other uses.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
part of the solution to dealing with these ordering issues is hierarchical decoding, such as the hiero system (chiang, 2005), <papid> P05-1033 </papid>method motivated by {(de) examples like the one in figure 1.</citsent>
<aftsection>
<nextsent>in this case, the translation goal is to rotate the noun head and the preceding relative clause around{(de), so that we can translate to ?[one of few countries]{ [have diplomatic relations with north korea]?.
</nextsent>
<nextsent>hiero can learn this kind of lexicalized synchronous grammar rule.
</nextsent>
<nextsent>but use of hierarchical decoders has not solved the deconstruction translation problem.
</nextsent>
<nextsent>we analyzed the errors of three state-of-the-art systems (the 3 darpa gale phase 2 teams?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE660">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>around the{.
</prevsent>
<prevsent>we argue that this is because it is not sufficient to have formalism which supports phrasal reordering, but itis also necessary to have sufficient linguistic modeling that the system knows when and how much to rearrange.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
an alternative way of dealing with structural differences is to reorder source language sentences to minimize structural divergence with the target language, (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007).<papid> D07-1077 </papid></citsent>
<aftsection>
<nextsent>for example wang et al.
</nextsent>
<nextsent>(2007) introduced set of rules to decide if a{(de) construction should be reordered or not before translating to english: ? for dnps (consisting ofxp+deg?): ? reorder if xp is pp or lcp; ? reorder if xp is non-pronominal np ? for cps (typically formed by ip+dec?): ? reorder to align with the that+clause?
</nextsent>
<nextsent>structure of english.
</nextsent>
<nextsent>although this and previous reordering work hasled to significant improvements, errors still remain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE661">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>around the{.
</prevsent>
<prevsent>we argue that this is because it is not sufficient to have formalism which supports phrasal reordering, but itis also necessary to have sufficient linguistic modeling that the system knows when and how much to rearrange.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
an alternative way of dealing with structural differences is to reorder source language sentences to minimize structural divergence with the target language, (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007).<papid> D07-1077 </papid></citsent>
<aftsection>
<nextsent>for example wang et al.
</nextsent>
<nextsent>(2007) introduced set of rules to decide if a{(de) construction should be reordered or not before translating to english: ? for dnps (consisting ofxp+deg?): ? reorder if xp is pp or lcp; ? reorder if xp is non-pronominal np ? for cps (typically formed by ip+dec?): ? reorder to align with the that+clause?
</nextsent>
<nextsent>structure of english.
</nextsent>
<nextsent>although this and previous reordering work hasled to significant improvements, errors still remain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE662">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>around the{.
</prevsent>
<prevsent>we argue that this is because it is not sufficient to have formalism which supports phrasal reordering, but itis also necessary to have sufficient linguistic modeling that the system knows when and how much to rearrange.
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
an alternative way of dealing with structural differences is to reorder source language sentences to minimize structural divergence with the target language, (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007).<papid> D07-1077 </papid></citsent>
<aftsection>
<nextsent>for example wang et al.
</nextsent>
<nextsent>(2007) introduced set of rules to decide if a{(de) construction should be reordered or not before translating to english: ? for dnps (consisting ofxp+deg?): ? reorder if xp is pp or lcp; ? reorder if xp is non-pronominal np ? for cps (typically formed by ip+dec?): ? reorder to align with the that+clause?
</nextsent>
<nextsent>structure of english.
</nextsent>
<nextsent>although this and previous reordering work hasled to significant improvements, errors still remain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE692">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>lexical: lexical features in addition to part-of-speech features, we also tried to use features from the words themselves.
</prevsent>
<prevsent>but since using full word identity resulted in sparsity issue,5 we take the one-character suffix of each word and extract suffix unigram and bigram features from them.
</prevsent>
</prevsection>
<citsent citstr=" I05-3005 ">
the argument for using suffixes is that it often captures the larger category of the word (tseng et al, 2005).<papid> I05-3005 </papid></citsent>
<aftsection>
<nextsent>for example, ? ) (china) and8) (korea) share the same suffix ), which means country?.
</nextsent>
<nextsent>these suffix ngram features will result in these features for the np in figure 2: ? suffix unigrams: ?)?, ?!?, l?, ?{?, ???, ?)?
</nextsent>
<nextsent>suffix bigrams: b-)?, ?)-!?, ?!-l?, l-{?, ?{-??, ??-)?, ?)-b?
</nextsent>
<nextsent>other than the suffix ngram, we also add three other lexical features: first, if the word before deis noun, we add feature that is the conjunction of pos and suffix unigram.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE696">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>4 machine translation experiments.
</prevsent>
<prevsent>4.1 experimental setting.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
for our mt experiments, we used re implementation of moses (koehn et al, 2003), <papid> N03-1017 </papid>astate-of-the-art phrase-based system.</citsent>
<aftsection>
<nextsent>the alignment is done by the berkeley word aligner (liang et al, 2006) <papid> N06-1014 </papid>and then we symmetrized the word alignment using the grow-diag heuristic.</nextsent>
<nextsent>for features, we incorporate moses?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE697">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>4.1 experimental setting.
</prevsent>
<prevsent>for our mt experiments, we used re implementation of moses (koehn et al, 2003), <papid> N03-1017 </papid>astate-of-the-art phrase-based system.</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
the alignment is done by the berkeley word aligner (liang et al, 2006) <papid> N06-1014 </papid>and then we symmetrized the word alignment using the grow-diag heuristic.</citsent>
<aftsection>
<nextsent>for features, we incorporate moses?
</nextsent>
<nextsent>standard eight features as well as the lexicalized reordering model.
</nextsent>
<nextsent>parameter tuning is done with minimum error rate training (mert) (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the tuning set for mert is the nist mt06 dataset, which includes 1664 sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE698">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>for features, we incorporate moses?
</prevsent>
<prevsent>standard eight features as well as the lexicalized reordering model.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
parameter tuning is done with minimum error rate training (mert) (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the tuning set for mert is the nist mt06 dataset, which includes 1664 sentences.
</nextsent>
<nextsent>we evaluate the result with mt02 (878 sentences), mt03 (919 sentences), and mt05 (1082 sentences).our mt training corpus contains 1,560,071 sentence pairs from various parallel corpora from ldc.9 there are 12,259,997 words on the english side.
</nextsent>
<nextsent>chinese word segmentation is done by the stanford chinese segmenter (chang et al, 2008).<papid> W08-0336 </papid></nextsent>
<nextsent>after segmentation, there are 11,061,792 words on the chinese side.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE699">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>the tuning set for mert is the nist mt06 dataset, which includes 1664 sentences.
</prevsent>
<prevsent>we evaluate the result with mt02 (878 sentences), mt03 (919 sentences), and mt05 (1082 sentences).our mt training corpus contains 1,560,071 sentence pairs from various parallel corpora from ldc.9 there are 12,259,997 words on the english side.
</prevsent>
</prevsection>
<citsent citstr=" W08-0336 ">
chinese word segmentation is done by the stanford chinese segmenter (chang et al, 2008).<papid> W08-0336 </papid></citsent>
<aftsection>
<nextsent>after segmentation, there are 11,061,792 words on the chinese side.
</nextsent>
<nextsent>we use 5-gram language model trained on the xinhua and afp sections of the gigaword corpus (ldc2007t40) and also the english side of all the ldc parallel data permissible under the nist08 rules.
</nextsent>
<nextsent>documents of gigaword released during the epochs of mt02, mt03, mt05, and mt06 were removed.
</nextsent>
<nextsent>to run the de classifier, we also need to parse the chinese texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE700">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>documents of gigaword released during the epochs of mt02, mt03, mt05, and mt06 were removed.
</prevsent>
<prevsent>to run the de classifier, we also need to parse the chinese texts.
</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
we use the stanford chinese parser (levy and manning, 2003) <papid> P03-1056 </papid>to parse the chinese side of the mt training data and the tuning and test sets.</citsent>
<aftsection>
<nextsent>9ldc2003e07, ldc2003e14, ldc2005e83, ldc2005t06, ldc2006e26, ldc2006e85, ldc2006e85, ldc2005t34, and ldc2005t34 4.2 baseline experiments.
</nextsent>
<nextsent>we have two different settings as baseline experiments.
</nextsent>
<nextsent>the first is without reordering or de annotation on the chinese side; we simply align the parallel texts, extract phrases and tune parameters.
</nextsent>
<nextsent>this experiment is referred to as baseline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE705">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>220 bleu mt06(tune) mt02 mt03 mt05 baseline 32.39 32.51 32.75 31.42 wang-np 32.75(+0.36) 32.66(+0.15) 33.15(+0.40) 31.68(+0.26) de-annotated 33.39(+1.00) 33.75(+1.24) 33.63(+0.88) 32.91(+1.49) baseline+hier 32.96 33.10 32.93 32.23 de-annotated+hier 33.96(+1.00) 34.33(+1.23) 33.88(+0.95) 33.01(+0.77) translation error rate (ter) mt06(tune) mt02 mt03 mt05 baseline 61.10 63.11 62.09 64.06 wang-np 59.78(1.32) 62.58(0.53) 61.36(0.73) 62.35(1.71) de-annotated 58.21(2.89) 61.17(1.94) 60.27(1.82) 60.78(3.28) table 5: mt experiments of different settings on various nist mt evaluation datasets.
</prevsent>
<prevsent>we used both the bleu and ter metrics for evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
all differences between de-annotated and baseline are significant at the level of 0.05 with the approximate randomization test in (riezler and maxwell, 2005)<papid> W05-0908 </papid>conduct additional experiments with hierarchical phrase reordering model introduced by galley and manning (2008).<papid> D08-1089 </papid></citsent>
<aftsection>
<nextsent>the hierarchical phrase reordering model can handle the key examples often used to motivated syntax-based systems; therefore we think it is valuable to see if the de annotation can still improve on top of that.
</nextsent>
<nextsent>in table 5, baseline+hier gives consistent bleu improvement over baseline.
</nextsent>
<nextsent>using de annotation on top of the hierarchical phrase reordering models (de-annotated+hier) provides extra gain over baseline+hier.
</nextsent>
<nextsent>this shows the de annotation canhelp hierarchical system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE706">
<title id=" W09-0436.xml">disambiguating de for chinese english machine translation </title>
<section> a ends with va: </section>
<citcontext>
<prevsection>
<prevsent>220 bleu mt06(tune) mt02 mt03 mt05 baseline 32.39 32.51 32.75 31.42 wang-np 32.75(+0.36) 32.66(+0.15) 33.15(+0.40) 31.68(+0.26) de-annotated 33.39(+1.00) 33.75(+1.24) 33.63(+0.88) 32.91(+1.49) baseline+hier 32.96 33.10 32.93 32.23 de-annotated+hier 33.96(+1.00) 34.33(+1.23) 33.88(+0.95) 33.01(+0.77) translation error rate (ter) mt06(tune) mt02 mt03 mt05 baseline 61.10 63.11 62.09 64.06 wang-np 59.78(1.32) 62.58(0.53) 61.36(0.73) 62.35(1.71) de-annotated 58.21(2.89) 61.17(1.94) 60.27(1.82) 60.78(3.28) table 5: mt experiments of different settings on various nist mt evaluation datasets.
</prevsent>
<prevsent>we used both the bleu and ter metrics for evaluation.
</prevsent>
</prevsection>
<citsent citstr=" D08-1089 ">
all differences between de-annotated and baseline are significant at the level of 0.05 with the approximate randomization test in (riezler and maxwell, 2005)<papid> W05-0908 </papid>conduct additional experiments with hierarchical phrase reordering model introduced by galley and manning (2008).<papid> D08-1089 </papid></citsent>
<aftsection>
<nextsent>the hierarchical phrase reordering model can handle the key examples often used to motivated syntax-based systems; therefore we think it is valuable to see if the de annotation can still improve on top of that.
</nextsent>
<nextsent>in table 5, baseline+hier gives consistent bleu improvement over baseline.
</nextsent>
<nextsent>using de annotation on top of the hierarchical phrase reordering models (de-annotated+hier) provides extra gain over baseline+hier.
</nextsent>
<nextsent>this shows the de annotation canhelp hierarchical system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE710">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fred and cheng (1999) point out that this is often the case in biomedical documents, in this domain ubiquitous abbreviations (such as dna and mrna) often appear without an expansion.it has been reported that misinterpretation of abbreviations in biomedical documents has lead to medical practitioners making fatal errors (fred and cheng, 1999).
</prevsent>
<prevsent>however, identifying the correct expansion is not straightforward task since an abbreviation may have several possible expansions.
</prevsent>
</prevsection>
<citsent citstr=" W02-0312 ">
chang et al (2002) reported that abbreviations in biomedical journal articles consisting of six characters or less have an average of 4.61 possible meanings and pustejovsky et al (2002) <papid> W02-0312 </papid>mention that the simple abbreviation ac?</citsent>
<aftsection>
<nextsent>is associated with at least10 strings in different biomedical documents including atrioventricular connection?, anterior colpor rhaphy procedure?, auditory cortex?
</nextsent>
<nextsent>and atypical carcinoid?.
</nextsent>
<nextsent>the problem of identifying the correct expansion of an ambiguous abbreviation can be viewed as word sense disambiguation (wsd) task where the various expansions are the senses?
</nextsent>
<nextsent>of the abbreviation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE712">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they extracted corpus containing examples of 60 abbreviations from set of biomedical journal articles which was split so that abstracts in which the abbreviations were defined were used as training data and those in which no definition is found as test data.abbreviations in the test portion were manually dis ambiguated.
</prevsent>
<prevsent>they report 79% coverage and 80%precision using naive bayes classifier.
</prevsent>
</prevsection>
<citsent citstr=" P02-1021 ">
pakhomov (2002) <papid> P02-1021 </papid>applied maximum entropy model to identify the meanings of ambiguous abbreviations in10,000 rheumatology notes with around 89% accu racy.</citsent>
<aftsection>
<nextsent>joshi et al (2006) disambiguated abbreviation sin clinical notes using three supervised learning algorithms (naive bayes, decision trees and support vector machines).
</nextsent>
<nextsent>they used range of features and found that the best performance was obtained when these were combined.
</nextsent>
<nextsent>unfortunately direct comparison of these methods is made difficult by the fact that various researchers have evaluated their approaches on different datasets.
</nextsent>
<nextsent>a variety of approaches have also been proposed for the problem of disambiguating local abbreviations in biomedical documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE713">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem is relatively straightforward for abbreviations which are created by selecting the first character from each word in the expansion, such as angiotensin converting enzyme (ace)?, but is more difficult when this convention is not followed, for example acetylchlinesterase(ace)?, antisocial personality (asp)?
</prevsent>
<prevsent>and catalase (cat)?.
</prevsent>
</prevsection>
<citsent citstr=" C08-1083 ">
okazaki et al (2008) <papid> C08-1083 </papid>recently proposed an approach to this problem based on discriminative alignment that has been shown to perform well.</citsent>
<aftsection>
<nextsent>however, the most common solutions are based on heuristic approaches, for example adar (2004) and zhou et al (2006).
</nextsent>
<nextsent>pustejovsky et al (2002) <papid> W02-0312 </papid>used hand-built regular expressions.</nextsent>
<nextsent>schwartz and hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE716">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> abbreviation disambiguation system.  </section>
<citcontext>
<prevsection>
<prevsent>the most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order.
</prevsent>
<prevsent>our abbreviation disambiguation system is based on state-of-the-art wsd system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" W04-0813 ">
the system on which our approach is based (agirre and martnez, 2004) <papid> W04-0813 </papid>participated in the senseval-3 challenge (mihalcea et al, 2004) <papid> W04-0807 </papid>with performance close to the best system for the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (stevenson etal., 2008) on standard test set consisting of ambiguous terms (weeber et al, 2001).this system is based on supervised learning approach with features derived from text around the ambiguous word that are domain independent.</citsent>
<aftsection>
<nextsent>we refer to these as general features.
</nextsent>
<nextsent>this feature sethas been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain-specific features: cuis (asused by mcinnes et al (2007)) and medical subject heading (mesh) terms.
</nextsent>
<nextsent>this set of features is more diverse than have been explored by previous approaches to abbreviation disambiguation.
</nextsent>
<nextsent>3.1 features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE717">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> abbreviation disambiguation system.  </section>
<citcontext>
<prevsection>
<prevsent>the most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order.
</prevsent>
<prevsent>our abbreviation disambiguation system is based on state-of-the-art wsd system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
the system on which our approach is based (agirre and martnez, 2004) <papid> W04-0813 </papid>participated in the senseval-3 challenge (mihalcea et al, 2004) <papid> W04-0807 </papid>with performance close to the best system for the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (stevenson etal., 2008) on standard test set consisting of ambiguous terms (weeber et al, 2001).this system is based on supervised learning approach with features derived from text around the ambiguous word that are domain independent.</citsent>
<aftsection>
<nextsent>we refer to these as general features.
</nextsent>
<nextsent>this feature sethas been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain-specific features: cuis (asused by mcinnes et al (2007)) and medical subject heading (mesh) terms.
</nextsent>
<nextsent>this set of features is more diverse than have been explored by previous approaches to abbreviation disambiguation.
</nextsent>
<nextsent>3.1 features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE718">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> abbreviation disambiguation system.  </section>
<citcontext>
<prevsection>
<prevsent>lean bsa was obtained from height and lean body weight ...?
</prevsent>
<prevsent>the features would include the following:left-content-word-lemma lean bsa?, right function-word-lemma bsa be?, left-pos jjnnp?, right-pos nnp vbd?, left-contentword-form lean bsa?, right-function-word form bsa was?, etc.?
</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
salient bigrams: salient bigrams within the abstract with high log-likelihood scores, as described by pedersen (2001).<papid> N01-1011 </papid></citsent>
<aftsection>
<nextsent>unigrams: lemmas of all content words in the abstract and words within 4-word window around the target word, excluding those in list of stopwords.
</nextsent>
<nextsent>in addition, the lemmas of any unigrams appearing at least twice in the entire corpus and which are found in the abstract are also included as features.
</nextsent>
<nextsent>concept unique identifiers (cuis): we follow the approach presented by mcinnes et al (2007) to generate features based on umls concept unique identifiers (cuis).
</nextsent>
<nextsent>the metamap program (aron son, 2001) identifies all words and terms in text which could be mapped onto umls cui.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE720">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> evaluation corpus.  </section>
<citcontext>
<prevsection>
<prevsent>we used our own implementation of the vector space model and weka implementations (witten and frank, 2005) of the other two algorithms.
</prevsent>
<prevsent>the most common method for generating corpor ato train and test wsd systems is to manually annotate instances of ambiguous terms found in text with the appropriate meaning.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
however, this process is both time-consuming and difficult (artstein and poesio, 2008).<papid> J08-4004 </papid></citsent>
<aftsection>
<nextsent>an alternative to manual tagging is to find way of automatically creating sense tagged corpora.
</nextsent>
<nextsent>for the translation of ambiguous english words ng et al (2003) <papid> P03-1058 </papid>made use of the fact that the various senses are often translated differently.</nextsent>
<nextsent>for example when bank?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE721">
<title id=" W09-1309.xml">disambiguation of biomedical abbreviations </title>
<section> evaluation corpus.  </section>
<citcontext>
<prevsection>
<prevsent>however, this process is both time-consuming and difficult (artstein and poesio, 2008).<papid> J08-4004 </papid></prevsent>
<prevsent>an alternative to manual tagging is to find way of automatically creating sense tagged corpora.</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
for the translation of ambiguous english words ng et al (2003) <papid> P03-1058 </papid>made use of the fact that the various senses are often translated differently.</citsent>
<aftsection>
<nextsent>for example when bank?
</nextsent>
<nextsent>is used in the financial insti tution?
</nextsent>
<nextsent>sense it is translated to french as banque?
</nextsent>
<nextsent>and bord?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE724">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> lexeme-based morphology.  </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
<prevsent>some rights reserved.the morpheme-based / lexeme-based distinction shows up on the computational level.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
inthe morpheme-based conception, the morphological analysis of word aims at segmenting it intoa sequence of morphemes (djean, 1998; goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>bernhard,2006).</citsent>
<aftsection>
<nextsent>in lexeme-based approach, it is to discover the relations between the word and the other lexical items.
</nextsent>
<nextsent>these relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved.
</nextsent>
<nextsent>for instance, the analysis of the french word drivation may be considered as satisfactory if it connects drivation with enough members of its family (driver derivate?, drivationnel derivational?, drivable, drive drift?, driveur sailing dinghy?, etc.) and of its derivationalseries (formation education?, sduction, variation, mission, etc.).
</nextsent>
<nextsent>each of these relations is integrated into large collection of analogies that characterizes it semantically and formally.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE725">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> lexeme-based morphology.  </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
<prevsent>some rights reserved.the morpheme-based / lexeme-based distinction shows up on the computational level.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
inthe morpheme-based conception, the morphological analysis of word aims at segmenting it intoa sequence of morphemes (djean, 1998; goldsmith, 2001; <papid> J01-2001 </papid>creutz and lagus, 2002; <papid> W02-0603 </papid>bernhard,2006).</citsent>
<aftsection>
<nextsent>in lexeme-based approach, it is to discover the relations between the word and the other lexical items.
</nextsent>
<nextsent>these relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved.
</nextsent>
<nextsent>for instance, the analysis of the french word drivation may be considered as satisfactory if it connects drivation with enough members of its family (driver derivate?, drivationnel derivational?, drivable, drive drift?, driveur sailing dinghy?, etc.) and of its derivationalseries (formation education?, sduction, variation, mission, etc.).
</nextsent>
<nextsent>each of these relations is integrated into large collection of analogies that characterizes it semantically and formally.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE726">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> computational modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the second technique, formal analogy, is then used to perform fine-grained filtering.
</prevsent>
<prevsent>technically, our model joins: 1.
</prevsent>
</prevsection>
<citsent citstr=" W06-3811 ">
the representation of the lexicon as graph and its exploration through random walks, along the line of (gaume et al, 2002; gaume et al, 2005; muller et al, 2006), <papid> W06-3811 </papid>and 2.</citsent>
<aftsection>
<nextsent>formal analogies on words (lepage, 1998; <papid> P98-1121 </papid>stroppa and yvon, 2005).</nextsent>
<nextsent>this approach doesdo not make use of morphemes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE727">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> computational modeling.  </section>
<citcontext>
<prevsection>
<prevsent>technically, our model joins: 1.
</prevsent>
<prevsent>the representation of the lexicon as graph and its exploration through random walks, along the line of (gaume et al, 2002; gaume et al, 2005; muller et al, 2006), <papid> W06-3811 </papid>and 2.</prevsent>
</prevsection>
<citsent citstr=" P98-1121 ">
formal analogies on words (lepage, 1998; <papid> P98-1121 </papid>stroppa and yvon, 2005).</citsent>
<aftsection>
<nextsent>this approach doesdo not make use of morphemes.
</nextsent>
<nextsent>correspondence between words is calculated directly on their graphemic representations.
</nextsent>
<nextsent>more generally, our approach is original in that: 1.
</nextsent>
<nextsent>our computational model is pure lexeme-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE729">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many works in the field of computational morphology aim at the discovery of relations between lexical units.
</prevsent>
<prevsent>all of them rely primarily on finding similarities between the word graphemicforms.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
these relations are mainly prefixal or suffixal with two exceptions, (yarowsky and wicentowski, 2000) <papid> P00-1027 </papid>and (baroni et al, 2002), <papid> W02-0606 </papid>who use string edit distances to estimate formal similarity.</citsent>
<aftsection>
<nextsent>as far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (neuvel and fulop, 2002).<papid> W02-0604 </papid></nextsent>
<nextsent>our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE730">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many works in the field of computational morphology aim at the discovery of relations between lexical units.
</prevsent>
<prevsent>all of them rely primarily on finding similarities between the word graphemicforms.
</prevsent>
</prevsection>
<citsent citstr=" W02-0606 ">
these relations are mainly prefixal or suffixal with two exceptions, (yarowsky and wicentowski, 2000) <papid> P00-1027 </papid>and (baroni et al, 2002), <papid> W02-0606 </papid>who use string edit distances to estimate formal similarity.</citsent>
<aftsection>
<nextsent>as far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (neuvel and fulop, 2002).<papid> W02-0604 </papid></nextsent>
<nextsent>our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE731">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>all of them rely primarily on finding similarities between the word graphemicforms.
</prevsent>
<prevsent>these relations are mainly prefixal or suffixal with two exceptions, (yarowsky and wicentowski, 2000) <papid> P00-1027 </papid>and (baroni et al, 2002), <papid> W02-0606 </papid>who use string edit distances to estimate formal similarity.</prevsent>
</prevsection>
<citsent citstr=" W02-0604 ">
as far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (neuvel and fulop, 2002).<papid> W02-0604 </papid></citsent>
<aftsection>
<nextsent>our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features.
</nextsent>
<nextsent>it is the main contribution of this paper.
</nextsent>
<nextsent>our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words.
</nextsent>
<nextsent>usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (schone and jurafsky, 2000), <papid> W00-0712 </papid>mutual information (baroni et al, 2002) <papid> W02-0606 </papid>or co-occurrence inan n-word window (xu and croft, 1998; zweigenbaum and grabar, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE732">
<title id=" W08-2001.xml">acquis tion of the morphological structure of the lexicon based on lexical similarity and formal analogy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it is the main contribution of this paper.
</prevsent>
<prevsent>our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words.
</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (schone and jurafsky, 2000), <papid> W00-0712 </papid>mutual information (baroni et al, 2002) <papid> W02-0606 </papid>or co-occurrence inan n-word window (xu and croft, 1998; zweigenbaum and grabar, 2003).</citsent>
<aftsection>
<nextsent>in the experiment we present here, semantic informations are extracted from machine readable dictionary and semantic similarity is calculated through random walks in lexical graph.
</nextsent>
<nextsent>our approach can also be compared with (hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from wordnet.
</nextsent>
<nextsent>in our model, the lexical units and their properties are represented in bipartite graph with the vertices representing the lexemes in one sub-set and the vertices representing the formal and semantic features in the other.
</nextsent>
<nextsent>lexeme vertices are identified by the lemma and the grammatical category.in the experiment reported in the paper, the formal properties are the n-grams of letters that occur in the lexemes lemma.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE738">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, the amount of readily available texts is huge, while on the other hand the labeling and creation of corpora based on such texts is tedious, error prone and expensive.
</prevsent>
<prevsent>active learning (al) is one way of approaching the challenge of classifier creation and data annotation.
</prevsent>
</prevsection>
<citsent citstr=" P04-1075 ">
examples of al used in language engineering include named entity recognition (shen et al, 2004; <papid> P04-1075 </papid>tomanek et al, 2007), <papid> D07-1051 </papid>text categorization (lewis and gale, 1994; hoi et al, 2006), part-of-speechtagging (ringger et al, 2007), <papid> W07-1516 </papid>and parsing (thomp sonet al, 1999; becker and osborne, 2005).</citsent>
<aftsection>
<nextsent>al is supervised machine learning technique in which the learner is in control of the data used for learning ? the control is used to query an oracle, typically human, for the correct label of the unlabeled training instances for which the classifier learned so far makes unreliable predictions.the al process takes as input set of labeled instances and larger set of unlabeled instances, and produces classifier and relatively small set of newly labeled data.
</nextsent>
<nextsent>the overall goal is to obtain as good classifier as possible, without having tomark-up and supply the learner with more than necessary data.
</nextsent>
<nextsent>the learning process aims at keeping the human annotation effort to minimum, only asking for advice where the training utility of the result of such query is high.
</nextsent>
<nextsent>the approaches taken to al in this paper are based on committees of classifiers with access to pools of data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE739">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, the amount of readily available texts is huge, while on the other hand the labeling and creation of corpora based on such texts is tedious, error prone and expensive.
</prevsent>
<prevsent>active learning (al) is one way of approaching the challenge of classifier creation and data annotation.
</prevsent>
</prevsection>
<citsent citstr=" D07-1051 ">
examples of al used in language engineering include named entity recognition (shen et al, 2004; <papid> P04-1075 </papid>tomanek et al, 2007), <papid> D07-1051 </papid>text categorization (lewis and gale, 1994; hoi et al, 2006), part-of-speechtagging (ringger et al, 2007), <papid> W07-1516 </papid>and parsing (thomp sonet al, 1999; becker and osborne, 2005).</citsent>
<aftsection>
<nextsent>al is supervised machine learning technique in which the learner is in control of the data used for learning ? the control is used to query an oracle, typically human, for the correct label of the unlabeled training instances for which the classifier learned so far makes unreliable predictions.the al process takes as input set of labeled instances and larger set of unlabeled instances, and produces classifier and relatively small set of newly labeled data.
</nextsent>
<nextsent>the overall goal is to obtain as good classifier as possible, without having tomark-up and supply the learner with more than necessary data.
</nextsent>
<nextsent>the learning process aims at keeping the human annotation effort to minimum, only asking for advice where the training utility of the result of such query is high.
</nextsent>
<nextsent>the approaches taken to al in this paper are based on committees of classifiers with access to pools of data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE741">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, the amount of readily available texts is huge, while on the other hand the labeling and creation of corpora based on such texts is tedious, error prone and expensive.
</prevsent>
<prevsent>active learning (al) is one way of approaching the challenge of classifier creation and data annotation.
</prevsent>
</prevsection>
<citsent citstr=" W07-1516 ">
examples of al used in language engineering include named entity recognition (shen et al, 2004; <papid> P04-1075 </papid>tomanek et al, 2007), <papid> D07-1051 </papid>text categorization (lewis and gale, 1994; hoi et al, 2006), part-of-speechtagging (ringger et al, 2007), <papid> W07-1516 </papid>and parsing (thomp sonet al, 1999; becker and osborne, 2005).</citsent>
<aftsection>
<nextsent>al is supervised machine learning technique in which the learner is in control of the data used for learning ? the control is used to query an oracle, typically human, for the correct label of the unlabeled training instances for which the classifier learned so far makes unreliable predictions.the al process takes as input set of labeled instances and larger set of unlabeled instances, and produces classifier and relatively small set of newly labeled data.
</nextsent>
<nextsent>the overall goal is to obtain as good classifier as possible, without having tomark-up and supply the learner with more than necessary data.
</nextsent>
<nextsent>the learning process aims at keeping the human annotation effort to minimum, only asking for advice where the training utility of the result of such query is high.
</nextsent>
<nextsent>the approaches taken to al in this paper are based on committees of classifiers with access to pools of data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE744">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the intrinsic stopping criterion (isc) we propose here focuses on the latter aspect of the ideal stopping point described above ? exhaustive ness of the al pool.
</prevsent>
<prevsent>we suggest to stop the annotation process of the data from given pool when the base learner cannot learn (much) more from it.
</prevsent>
</prevsection>
<citsent citstr=" L08-1208 ">
the definition of our intrinsic stopping criterion for committee-based al builds on the notions of selection agreement(tomanek et al, 2007), <papid> D07-1051 </papid>and validation set agreement (tomanek and hahn, 2008).<papid> L08-1208 </papid></citsent>
<aftsection>
<nextsent>the selection agreement (sa) is the agreement among the members of decision committee regarding the classification of the most informative instance selected from the pool of unlabeled data in each al round.
</nextsent>
<nextsent>the intuition underlying the sa isthat the committee will agree more on the hard instances selected from the remaining set of unlabeled data as the al process proceeds.
</nextsent>
<nextsent>when the members of the committee are in complete agreement, al should be aborted since it no longer contributes to the overall learning process ? in this case, al isbut computationally expensive counterpart of random sampling.
</nextsent>
<nextsent>however, as pointed out by tomanek et al (2007), <papid> D07-1051 </papid>the sa hardly ever signals complete agreement and can thus not be used as the sole indicator of al having reached the point at which it should be aborted.the validation set agreement (vsa) is the agree 139ment among the members of the decision committee concerning the classification of held-out, unannotated dataset (the validation set).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE751">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea is to stop learning whenthe confidence of the classifier, on an external, possibly unannotated test set, remains at the same levelor drops for number of consecutive iterations during the al process.
</prevsent>
<prevsent>vlachos shows that the criterion indeed is applicable to the tasks he investigates.
</prevsent>
</prevsection>
<citsent citstr=" D07-1082 ">
zhu and colleagues (zhu and hovy, 2007; <papid> D07-1082 </papid>zhu et al, 2008<papid> I08-1048 </papid>a; zhu et al, 2008<papid> I08-1048 </papid>b) introducemax-confidence, min-error, minimum expected error strategy, overall-uncertainty, and classification change as means to terminate al. they primarily use single-classifier approach to word sense disambiguation and text classification in their ex periments.</citsent>
<aftsection>
<nextsent>max-confidence seeks to terminate alonce the classifier is most confident in its predictions.
</nextsent>
<nextsent>in the min-error strategy, the learning is halted when there is no difference between the classifiers predictions and those labels provided by human annotator.
</nextsent>
<nextsent>the minimum expected error strategy involves estimating the classification error on future unlabeled instances and stop the learning whenthe expected error is as low as possible.
</nextsent>
<nextsent>overall uncertainty is similar to max-confidence, but unlike the latter, overall-uncertainty takes into account alldata remaining in the unlabeled pool when estimating the uncertainty of the classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE752">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea is to stop learning whenthe confidence of the classifier, on an external, possibly unannotated test set, remains at the same levelor drops for number of consecutive iterations during the al process.
</prevsent>
<prevsent>vlachos shows that the criterion indeed is applicable to the tasks he investigates.
</prevsent>
</prevsection>
<citsent citstr=" I08-1048 ">
zhu and colleagues (zhu and hovy, 2007; <papid> D07-1082 </papid>zhu et al, 2008<papid> I08-1048 </papid>a; zhu et al, 2008<papid> I08-1048 </papid>b) introducemax-confidence, min-error, minimum expected error strategy, overall-uncertainty, and classification change as means to terminate al. they primarily use single-classifier approach to word sense disambiguation and text classification in their ex periments.</citsent>
<aftsection>
<nextsent>max-confidence seeks to terminate alonce the classifier is most confident in its predictions.
</nextsent>
<nextsent>in the min-error strategy, the learning is halted when there is no difference between the classifiers predictions and those labels provided by human annotator.
</nextsent>
<nextsent>the minimum expected error strategy involves estimating the classification error on future unlabeled instances and stop the learning whenthe expected error is as low as possible.
</nextsent>
<nextsent>overall uncertainty is similar to max-confidence, but unlike the latter, overall-uncertainty takes into account alldata remaining in the unlabeled pool when estimating the uncertainty of the classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE764">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to challenge the definition of the isc, we conducted two types of experiments concerning named entity recognition.
</prevsent>
<prevsent>the primary focus of the first typeof experiment is on creating classifiers (classifier centric), while the second type is concerned with the creation of annotated documents (data-centric).
</prevsent>
</prevsection>
<citsent citstr=" P96-1042 ">
in all experiments, the agreement among the decision committee members is quantified by the vote entropy measure (engelson and dagan, 1996): <papid> P96-1042 </papid>e(e) = ? 1log ? v (l, e) log (l, e) (1) where is the number of members in the committee,and (l, e) is the number of members assigning label to instance e. if an instance obtains low vote entropy value, it means that the committee members are in high agreement concerning its classification, and thus also that it is less informative one.</citsent>
<aftsection>
<nextsent>4.1 classifier-centric experimental settings.
</nextsent>
<nextsent>in common al scenarios, the main goal of using al is to create good classifier with minimal label complexity.
</nextsent>
<nextsent>to follow this idea, we select sentences that are assumed to be useful for classifier training.
</nextsent>
<nextsent>we decided to select complete sentences ? instead of, e.g., single tokens ? as in practice annotators must see the context of words to decide on their entity labels.our experimental setting is based on the al approach described by tomanek et al (2007): <papid> D07-1051 </papid>the committee consists of = 3 maximum entropy (me) classifiers (berger et al, 1996).<papid> J96-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE766">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in common al scenarios, the main goal of using al is to create good classifier with minimal label complexity.
</prevsent>
<prevsent>to follow this idea, we select sentences that are assumed to be useful for classifier training.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we decided to select complete sentences ? instead of, e.g., single tokens ? as in practice annotators must see the context of words to decide on their entity labels.our experimental setting is based on the al approach described by tomanek et al (2007): <papid> D07-1051 </papid>the committee consists of = 3 maximum entropy (me) classifiers (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>in each al iteration, each classifier is trained on randomly drawn (sampling without replacement) subset l?
</nextsent>
<nextsent>l with |l?| = 23l, being the set of all instances labeled so far (cf.
</nextsent>
<nextsent>ensemblegenerationmethod in figure 1).
</nextsent>
<nextsent>usefulness of sentence is estimated as the average token vote entropy (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE768">
<title id=" W09-1118.xml">an intrinsic stopping criterion for committee based active learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the texts used are part of the muc-7 corpus (linguistic data consortium, 2001) and consists of 100 documents,3,480 sentences, and 90,790 tokens.
</prevsent>
<prevsent>the task is approached using the iob tagging scheme proposed by, e.g., ramshaw and marcus (1995), turning the original 7-class task into 15-class task.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
each token is represented using fairly standard menagerie of features, including such stemming from the surface appearance of the token (e.g., contains dollar length in characters), calculated based on linguistic pre-processing made with the english functional dependency grammar (tapanainen and jarvinen,1997) (<papid> A97-1011 </papid>e.g., case, part-of-speech), fetched from pre compiled lists of information (e.g., is first name?), and features based on predictions concerning the context of the token (e.g, class of previous token).</citsent>
<aftsection>
<nextsent>the decision committee is made up from 10 boosted decision trees using multiboostab (webb, 2000) (cf.
</nextsent>
<nextsent>ensemblegenerationmethod in figure 1).
</nextsent>
<nextsent>each classifier is created by the reptree decision tree learner described by witten and frank (2005).
</nextsent>
<nextsent>the informative ness of document is calculated bymeans of average token vote entropy (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE770">
<title id=" W09-0201.xml">one distributional memory many semantic spaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>task-specific semantic spaces are then built on demand from the repository.
</prevsent>
<prevsent>a straightforward implementation of our proposal achieves state-of-the-art performance on number of unrelated tasks.
</prevsent>
</prevsection>
<citsent citstr=" J06-3003 ">
corpus-derived distributional semantic spaces have proved valuable in tackling variety of tasks,ranging from concept categorization to relation extraction to many others (sahlgren, 2006; turney,2006; <papid> J06-3003 </papid>pado?</citsent>
<aftsection>
<nextsent>and lapata, 2007).
</nextsent>
<nextsent>the typical approach in the field has been local?
</nextsent>
<nextsent>one, in which each semantic task (or set of closely related tasks) is treated as separate problem, that requires its own corpus-derived model and algorithms.
</nextsent>
<nextsent>its successes notwithstanding, the one task ? one model?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE771">
<title id=" W09-0201.xml">one distributional memory many semantic spaces </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>given graph like the one in figure 1 below, adaptation to all these tasks (and many others) can be reduced to two basic operations: 1) building semantic spaces, as cooccurrence matrices defined by choosing different units of the graph as row and column elements;2) measuring similarity in the resulting matrix either between specific rows or between row and an average of rows whose elements share certain property.after reviewing some of the most closely related work (section 2), we introduce our approach (section 3) and, in section 4, we proceed to test it in various tasks, showing that its performance is always comparable to that of task-specific methods.
</prevsent>
<prevsent>section 5 draws the current conclusions and discusses future directions.
</prevsent>
</prevsection>
<citsent citstr=" C08-1114 ">
turney (2008) <papid> C08-1114 </papid>recently advocated the need for uniform approach to corpus-based semantic tasks.</citsent>
<aftsection>
<nextsent>turney recasts number of semantic challenges in terms of relational or ana logical similarity.
</nextsent>
<nextsent>thus, if an algorithm is able to tackle the latter, it can 1 also be used to address the former.
</nextsent>
<nextsent>turney tests his system in variety of tasks, obtaining good results across the board.
</nextsent>
<nextsent>his approach amounts to picking task (analogy recognition) and reinterpreting other tasks as its particular instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE775">
<title id=" W09-0201.xml">one distributional memory many semantic spaces </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such tasks will require an extension of the current framework ofturney (2008) <papid> C08-1114 </papid>beyond evidence from the direct cooccurrence of target word pairs.</prevsent>
<prevsent>while our unified framework is, as far as we know, novel, the specific ways in which we tackle the different tasks are standard.</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information (lin, 1998; <papid> P98-2127 </papid>curran and moens, 2002).<papid> W02-0908 </papid></citsent>
<aftsection>
<nextsent>our approach to selectional preference is nearly identical to the one of pado?
</nextsent>
<nextsent>et al (2007).
</nextsent>
<nextsent>we solve sat analogies with simplified version of the method of turney (2006).<papid> J06-3003 </papid></nextsent>
<nextsent>detecting whether pair expresses target relation by looking at shared connector patterns with model pairs is common strategy in relation extraction (pantel and pennacchiotti, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE776">
<title id=" W09-0201.xml">one distributional memory many semantic spaces </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such tasks will require an extension of the current framework ofturney (2008) <papid> C08-1114 </papid>beyond evidence from the direct cooccurrence of target word pairs.</prevsent>
<prevsent>while our unified framework is, as far as we know, novel, the specific ways in which we tackle the different tasks are standard.</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information (lin, 1998; <papid> P98-2127 </papid>curran and moens, 2002).<papid> W02-0908 </papid></citsent>
<aftsection>
<nextsent>our approach to selectional preference is nearly identical to the one of pado?
</nextsent>
<nextsent>et al (2007).
</nextsent>
<nextsent>we solve sat analogies with simplified version of the method of turney (2006).<papid> J06-3003 </papid></nextsent>
<nextsent>detecting whether pair expresses target relation by looking at shared connector patterns with model pairs is common strategy in relation extraction (pantel and pennacchiotti, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE783">
<title id=" W08-2227.xml">deep semantic analysis of text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>343 344 allen, swift, and de beaumont
</prevsent>
<prevsent>as building rich semantic representations of text becomes more feasible, it is important to develop standard representations of logical form that can be used to share data and compare approaches.
</prevsent>
</prevsection>
<citsent citstr=" W07-1207 ">
in this paper, we describe some general characteristics that such logical form language should have, then present graphical representation derived from the lf used in the trips system (allen et al, 2007).<papid> W07-1207 </papid></citsent>
<aftsection>
<nextsent>the logical form is representation that serves as the interface between structural analysis of text (i.e., parsing) and the subsequent use of the information to produce knowledge, whether it be for learning by reading, question answering, or dialogue based interactive systems.
</nextsent>
<nextsent>its important to distinguish two separable problems, namely the ontology used and the structure of the logical form language (lfl).
</nextsent>
<nextsent>the ontology determines the set of word senses and semantic relations that can be used.
</nextsent>
<nextsent>the lfl determines how these elements can be structured to capture the meaning of sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE784">
<title id=" W08-2227.xml">deep semantic analysis of text </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>rather than eliminating the interpretations that do not match, the parser simply assigns more weight to interpretations consistent with the tags.
</prevsent>
<prevsent>this allows the parser to override bad pos assignments in some cases.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
using on-line resources we have built system called word finder that draws on wordnet (miller, 1995) andcomlex (grishman et al, 1994) <papid> C94-1042 </papid>to construct (underspecified) lexical representations using mapping rules from high-level wordnet classes into our lf ontology.</citsent>
<aftsection>
<nextsent>we deliberately stay at fairly abstract level as we would rather have few semantically abstract lexical entries rather than the many highly-specific senses found in wordnet, which we have not found useful for parsing.
</nextsent>
<nextsent>using preferences during parsing preferences (either syntactic or semantic) can be given to the parser based on statistical or other analyses.
</nextsent>
<nextsent>we have used the collins parser as pre processor to extract hypotheses for the three constituents (np, vp, and advp) which in pre tests had precision greater than 60% (swift et al, 2004).<papid> C04-1055 </papid></nextsent>
<nextsent>for instance, for the sentence thenew york times is newspaper, the collins pre processor would produce the following preferences: (np 1 5) (np 6 8) (vp 5 8) (s 1 8) with simple sentences, this information has little effect.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE785">
<title id=" W08-2227.xml">deep semantic analysis of text </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>we deliberately stay at fairly abstract level as we would rather have few semantically abstract lexical entries rather than the many highly-specific senses found in wordnet, which we have not found useful for parsing.
</prevsent>
<prevsent>using preferences during parsing preferences (either syntactic or semantic) can be given to the parser based on statistical or other analyses.
</prevsent>
</prevsection>
<citsent citstr=" C04-1055 ">
we have used the collins parser as pre processor to extract hypotheses for the three constituents (np, vp, and advp) which in pre tests had precision greater than 60% (swift et al, 2004).<papid> C04-1055 </papid></citsent>
<aftsection>
<nextsent>for instance, for the sentence thenew york times is newspaper, the collins pre processor would produce the following preferences: (np 1 5) (np 6 8) (vp 5 8) (s 1 8) with simple sentences, this information has little effect.
</nextsent>
<nextsent>but on longer complex sentences, we found that the preferences allow us to produce more accurate interpretations in faster time.
</nextsent>
<nextsent>note again that the parser is not required to follow this advice ? all this information does is add preference for such interpretations.
</nextsent>
<nextsent>another mechanism we use is logical form preference patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE786">
<title id=" W09-0417.xml">limsis statistical translation systems for wmt09 </title>
<section> system architecture and resources.  </section>
<citcontext>
<prevsection>
<prevsent>for french, using small lm trained on the  wmt  data only resulted in perplexity of 301on the devtest corpus and 299 on the test set.
</prevsent>
<prevsent>using all additional data yielded large decrease in perplexity (106 on the devtest and 108 on the test); again the same trend was observed for english.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
2.4 moses baseline our baseline system was vanilla phrase-basedsystem built with moses (koehn et al, 2007) <papid> P07-2045 </papid>using default settings.</citsent>
<aftsection>
<nextsent>phrases were extracted using the grow-diag-final-and?
</nextsent>
<nextsent>heuristics, using maximum phrase length of 7; non-contextual phrase scores contain the 4 translation model scores, plusa fixed phrase penalty; 6 additional scores param eterize the lexicalized reordering model.
</nextsent>
<nextsent>default decoding options were used (20 alternatives per phrase, maximum distortion distance of 7, etc.) 2.5 n-code baseline n-code implements the n-gram-based approach to statistical machine translation (mario et al,2006).
</nextsent>
<nextsent>in nutshell, the translation model is implemented as stochastic finite-state transducer trained using n-gram model of (source,target) pairs (casacuberta and vidal, 2004).<papid> J04-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE787">
<title id=" W09-0417.xml">limsis statistical translation systems for wmt09 </title>
<section> system architecture and resources.  </section>
<citcontext>
<prevsection>
<prevsent>heuristics, using maximum phrase length of 7; non-contextual phrase scores contain the 4 translation model scores, plusa fixed phrase penalty; 6 additional scores param eterize the lexicalized reordering model.
</prevsent>
<prevsent>default decoding options were used (20 alternatives per phrase, maximum distortion distance of 7, etc.) 2.5 n-code baseline n-code implements the n-gram-based approach to statistical machine translation (mario et al,2006).
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
in nutshell, the translation model is implemented as stochastic finite-state transducer trained using n-gram model of (source,target) pairs (casacuberta and vidal, 2004).<papid> J04-2004 </papid></citsent>
<aftsection>
<nextsent>training such model requires to reorder source sentences so as to match the target word order.
</nextsent>
<nextsent>this is also performed via stochastic finite-state reordering model, which uses part-of-speech information to generalise reordering patterns beyond lexical regularities.
</nextsent>
<nextsent>the reordering model is trained on version of the parallel corpora where the source sentences have been reordered via the unfold heuristics (crego and mario, 2007).
</nextsent>
<nextsent>a conventional ngram language model of the target language provides the third component of the system.in all our experiments, we used 4-gram reordering models and bilingual tuple models built using kneser-ney backoff (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE788">
<title id=" W09-0417.xml">limsis statistical translation systems for wmt09 </title>
<section> system architecture and resources.  </section>
<citcontext>
<prevsection>
<prevsent>this is also performed via stochastic finite-state reordering model, which uses part-of-speech information to generalise reordering patterns beyond lexical regularities.
</prevsent>
<prevsent>the reordering model is trained on version of the parallel corpora where the source sentences have been reordered via the unfold heuristics (crego and mario, 2007).
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
a conventional ngram language model of the target language provides the third component of the system.in all our experiments, we used 4-gram reordering models and bilingual tuple models built using kneser-ney backoff (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>the maximum tuple size was also set to 7.
</nextsent>
<nextsent>2.6 tuning procedure.
</nextsent>
<nextsent>the moses-based systems were tuned using the implementation of minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>distributed with the moses decoder, using the development corpus(dev2009a).</nextsent>
<nextsent>for the context-less systems, tuning concerned the 14 usual weights; tuning the 101 22 weights of the context-aware systems (see 3.1) proved to be much more challenging, and the weights used in our submissions are probably far from optimal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE789">
<title id=" W09-0417.xml">limsis statistical translation systems for wmt09 </title>
<section> system architecture and resources.  </section>
<citcontext>
<prevsection>
<prevsent>the maximum tuple size was also set to 7.
</prevsent>
<prevsent>2.6 tuning procedure.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the moses-based systems were tuned using the implementation of minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>distributed with the moses decoder, using the development corpus(dev2009a).</citsent>
<aftsection>
<nextsent>for the context-less systems, tuning concerned the 14 usual weights; tuning the 101 22 weights of the context-aware systems (see 3.1) proved to be much more challenging, and the weights used in our submissions are probably far from optimal.
</nextsent>
<nextsent>the n-code systems only rely on9 weights, since they dispense with the lexical reordering model; these weights were tuned on the same dataset, using an in-house implementation of the simplex algorithm.
</nextsent>
<nextsent>3.1 context-aware system in phrase-based translation, source phrases are translated irrespective of their (source) context.
</nextsent>
<nextsent>this is often not perceived as limitation as (i) typical text domains usually contain only few senses for polysemous words, thus limiting the use of word sense disambiguation (wsd); and (ii) using long-span target language models (4-gramsand more) often capture sufficient context to select the more appropriate translation for source phrase based on the target context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE790">
<title id=" W09-0417.xml">limsis statistical translation systems for wmt09 </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 context-aware system in phrase-based translation, source phrases are translated irrespective of their (source) context.
</prevsent>
<prevsent>this is often not perceived as limitation as (i) typical text domains usually contain only few senses for polysemous words, thus limiting the use of word sense disambiguation (wsd); and (ii) using long-span target language models (4-gramsand more) often capture sufficient context to select the more appropriate translation for source phrase based on the target context.
</prevsent>
</prevsection>
<citsent citstr=" W08-0302 ">
in fact, attempts at using source contexts in phrase-based smt have to date failed to show important gains on standard evaluation test sets (carpuat and wu, 2007; stroppa et al, 2007; gimpel and smith,2008; <papid> W08-0302 </papid>max et al, 2008).</citsent>
<aftsection>
<nextsent>importantly, in all conditions where gains have been obtained, the target language was the morphologically-poor?
</nextsent>
<nextsent>en glish.nonetheless, there seems to be clear consensus on the importance of better exploiting source contexts in smt, so as to improve phrase disambiguation.
</nextsent>
<nextsent>the following sentence extract from the devtest corpus is typical example where the lack of context in our phrase-based system yields an incorrect translation: source: the long weekend comes with price . . .
</nextsent>
<nextsent>target: le long week-end vient avec un prix . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE793">
<title id=" W09-0307.xml">applying nlp technologies to the collection and enrichment of language data on the web to aid linguistic research </title>
<section> building odin.  </section>
<citcontext>
<prevsection>
<prevsent>35: mary be.beautiful(a) 36: mary is beautiful (a).?
</prevsent>
<prevsent>table 1: linguistic document that contains igt: words in boldface are language names(2) igt detection: extracting igts from there trieved documents (3) language id: identifying the language code of the extracted igts.
</prevsent>
</prevsection>
<citsent citstr=" I08-1069 ">
the identified igts are then extracted and stored in database (the odin database), which can be easily searched with gui interface.4 in this section, we briefly describe the procedure, and more detail about the procedure can be found in (xia and lewis, 2008) <papid> I08-1069 </papid>and (xia et al, 2009).</citsent>
<aftsection>
<nextsent>3.1 crawling.
</nextsent>
<nextsent>in the first step, linguistic documents that may contain instances of igt are harvested from the web using metacrawls.
</nextsent>
<nextsent>meta crawling involves throwing queries against an existing search engine, such as google and live search, and crawling only the pages returned by those queries.
</nextsent>
<nextsent>we found that the most successful queries were those that used strings contained within igt itself (e.g.grams such as 3sg).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE795">
<title id=" W09-0307.xml">applying nlp technologies to the collection and enrichment of language data on the web to aid linguistic research </title>
<section> analyzing igt data and creating.  </section>
<citcontext>
<prevsection>
<prevsent>(2) language: haitian cf citation: (lefebvre 1998:165) l: jan pale ak li coindx: (jan, i), (li, i/j) g: john speak with he t1: john speaks with him?
</prevsent>
<prevsent>t2: john speaks with himself?
</prevsent>
</prevsection>
<citsent citstr=" P05-1046 ">
there has been much work on extracting database records from text or semi-structured sources, and the common approach is breaking the text into multiple segments and labeling each segment with field name (e.g., (wellner et al, 2004; grenager et al, 2005; <papid> P05-1046 </papid>poon and domingos, 8cf here stands for french-lexified creole.</citsent>
<aftsection>
<nextsent>2007)).
</nextsent>
<nextsent>our task here is slightly different from their tasks (e.g., extracting author/title/journalfrom citations) in that the fields in igt could over lap9 and corrupted lines need to be re-constructed and re-stored in particular way (e.g., pasting the second and third lines in ex (1) back together).due to the differences, we did not create annotated data by segmenting igt into separate fields and labeling each field.
</nextsent>
<nextsent>instead, we used refined tagset to indicate what information is available at each line of igt instances.
</nextsent>
<nextsent>the tagset includes six main tags (l, g, t, etc.) and nine secondary tags (e.g., -cr for corruption and -sy for syntactic information).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE796">
<title id=" W09-0307.xml">applying nlp technologies to the collection and enrichment of language data on the web to aid linguistic research </title>
<section> analyzing igt data and creating.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, given the igt example in ex (4), the enrichment algorithm would produce the word alignment in figure 1 and the phrase structures in figure 2.
</prevsent>
<prevsent>the algorithm was tested on 538 igts from seven languages and the word alignment accuracy was 94.1% and projection accuracy (i.e., the percentage of correct links in the projected dependency structures) was 81.5%.
</prevsent>
</prevsection>
<citsent citstr=" N07-1057 ">
details of the algorithm and the experiments are discussed in (xia and lewis, 2007).<papid> N07-1057 </papid></citsent>
<aftsection>
<nextsent>(4) rhoddodd yr athro lyfr ir bachgen ddoe gave-3sg the teacher book to-the boy yesterday the teacher gave book to the boy yesterday??
</nextsent>
<nextsent>(bailyn, 2001) the eache gave book o he boy yes terday rhoddodd r th ro y r ? bachgen ddoe loss i ne : r n l t o : a g t i e : a e - 3 g h t a h r o k o - h b y e t r a yfigure 1: aligning the language line and the english translation with the help of the gloss line n 1 p n e c e v d a e p 2 t n 4p n t e n p 3 e t r a n d b o n b y t o n n v d p pp n i + t n nd r o d d ( a e ) r ( he ) th ro ( e c e ) ly r ( o k ) r ( o - he ) a h g n (boy ) d e ( e t r a ) h figure 2: projecting phrase structure from the translation line to the language line 4.3 identifying and mapping grams.
</nextsent>
<nextsent>the third step of stage 2 identifies grams on the gloss line of an igt and mapping them to some common semantic so that they can reliably be searched.
</nextsent>
<nextsent>the gloss line of igt has two types ofglosses: those representing grammatical information (grams) such as nom, 3sg, perf, and standard glosses such as book or give.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE797">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the statistical transfer framework operates in two stages.
</prevsent>
<prevsent>first, the lexicon and grammar are applied to synchronously parse and translate an input sentence; all reordering is applied during this stage, driven by the syntactic grammar.second, monotonic decoder runs over the lattice of scored translation pieces produced during parsing and assembles the highest-scoring overall translation according to log-linear feature model.
</prevsent>
</prevsection>
<citsent citstr=" W08-0324 ">
since our submission to last years workshop on machine translation shared translation task (hanneman et al, 2008), <papid> W08-0324 </papid>we have made numerous improvements and extensions to our resource extraction and processing methods, resulting in significantly improved translation scores.</citsent>
<aftsection>
<nextsent>in section 2 of this paper, we trace our current methods fordata resource management for the stat-xfer submission to the 2009 wmt shared frenchenglishtranslation task.
</nextsent>
<nextsent>section 3 explains our tuning procedure, and section 4 gives our experimental results on various development sets and offers some preliminary analysis.
</nextsent>
<nextsent>because of the additional data resources provided for the 2009 french english task, our system this year is trained on nearly eight times as much data as last years. we used three officially provided datasets to make up parallel corpus for system training: version 4 of the europarl corpus (1.43 million sentence pairs), the news commentary corpus (0.06 million sentence pairs), andthe pre-release version of the new giga-fren corpus (8.60 million sentence pairs)1.
</nextsent>
<nextsent>the combined corpus of 10.09 million sentence pairs was preprocessed to remove blank lines, sentences of 80words or more, and sentence pairs where the ratio between the number of english and french words was larger than 5 to 1 in either direction.these steps removed approximately 3% of the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE798">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>140 2.1 parsing and word alignment.
</prevsent>
<prevsent>we parsed both sides of our parallel corpus with independent automatic constituency parsers.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
we used the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>for both english and french, although we obtained better results for french by tokenizing the data with our own script as preprocessing step and not allowing the parser to change it.</citsent>
<aftsection>
<nextsent>there were approximately 220,000 english sentences that did not return parse, which further reduced the size of our training corpus by 2%.
</nextsent>
<nextsent>after parsing, we re-extracted the leaf nodes of the parse trees and statistically word-alignedthe corpus using multi-threaded implementation (gao and vogel, 2008) <papid> W08-0509 </papid>of the giza++ program (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>unidirectional alignments were symmetrized with the grow-diag final?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE799">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>we used the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>for both english and french, although we obtained better results for french by tokenizing the data with our own script as preprocessing step and not allowing the parser to change it.</prevsent>
<prevsent>there were approximately 220,000 english sentences that did not return parse, which further reduced the size of our training corpus by 2%.</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
after parsing, we re-extracted the leaf nodes of the parse trees and statistically word-alignedthe corpus using multi-threaded implementation (gao and vogel, 2008) <papid> W08-0509 </papid>of the giza++ program (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>unidirectional alignments were symmetrized with the grow-diag final?
</nextsent>
<nextsent>heuristic (koehn et al, 2005).
</nextsent>
<nextsent>2.2 phrase extraction and combination.
</nextsent>
<nextsent>phrase extraction for last years statistical transfer system used automatically generated parse trees on both sides of the corpus as absolute constraints: syntactic phrase pair was extracted from given sentence only when contiguous sequence of english words exactly made up syntactic constituent in the english parse tree and could also be traced though symmetric word alignments to constituent in the french parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE800">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>we used the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>for both english and french, although we obtained better results for french by tokenizing the data with our own script as preprocessing step and not allowing the parser to change it.</prevsent>
<prevsent>there were approximately 220,000 english sentences that did not return parse, which further reduced the size of our training corpus by 2%.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
after parsing, we re-extracted the leaf nodes of the parse trees and statistically word-alignedthe corpus using multi-threaded implementation (gao and vogel, 2008) <papid> W08-0509 </papid>of the giza++ program (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>unidirectional alignments were symmetrized with the grow-diag final?
</nextsent>
<nextsent>heuristic (koehn et al, 2005).
</nextsent>
<nextsent>2.2 phrase extraction and combination.
</nextsent>
<nextsent>phrase extraction for last years statistical transfer system used automatically generated parse trees on both sides of the corpus as absolute constraints: syntactic phrase pair was extracted from given sentence only when contiguous sequence of english words exactly made up syntactic constituent in the english parse tree and could also be traced though symmetric word alignments to constituent in the french parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE801">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>this method can result in 50% increase in the number of extracted syntactic phrase pairs.each extracted phrase pair retains syntactic category label; in our current system, the node label in the english parse tree is used as the category for both sides of the bilingual phrase pair, although we subsequently map the full set of labels used by the berkeley parser down to more general set of 19 syntactic categories.
</prevsent>
<prevsent>we also ran standard?
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
phrase extraction on thesame corpus using steps 4 and 5 of the moses statistical machine translation training script (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the two types of phrases were then merged in syntax-prioritized combination that removes all moses-extracted phrase pairs that have source sides already covered by the tree-to-treestring syntactic phrase extraction.
</nextsent>
<nextsent>the syntax prioritization has the advantage of still including selection of non-syntactic phrases while producing amuch smaller phrase table than direct combination of all phrase pairs of both types.
</nextsent>
<nextsent>previous experiments we conducted indicated that this comes with only minor drop in automatic metric scores.in our current submission, we modify the procedure slightly by removing singleton phrase pairs from the syntactic table before the combination with moses phrases.
</nextsent>
<nextsent>the coverage of the combined table is not affected ? our syntactic phrase extraction algorithm produces subset of the non syntactic phrase pairs extracted from moses, up to phrase length constraints ? but the removal allows moses-extracted versions of some phrases to survive syntax prioritization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE802">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic phrase extraction specifies node-to node alignment across parallel parse trees.
</prevsent>
<prevsent>if these aligned nodes are used as decomposition points,a set of synchronous context-free rules that produced the trees can be collected.
</prevsent>
</prevsection>
<citsent citstr=" W08-0411 ">
this is our process of syntactic grammar extraction (lavie et al,2008).<papid> W08-0411 </papid></citsent>
<aftsection>
<nextsent>for our 2009 wmt submission, we extracted 11.0 million unique grammar rules, 9.1million of which were singletons, from our parallel parsed corpus.
</nextsent>
<nextsent>these rules operate on our syntactically extracted phrase pairs, which have category labels, but they may also be partially lexicalized with explicit source or target word strings.
</nextsent>
<nextsent>each extracted grammar rule is scored according to equations 1 and 2, where now the right-hand sides of the rule are used as ws and wt.
</nextsent>
<nextsent>as yet, we have made only minimal use of thestat-xfer frameworks grammar capabilities, especially for large-scale mt systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE803">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> evaluation and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>first, we report final (tuned) performance on our two tuning sets ? the last 425 sentences of news-dev2009a for the primary system, and the first 600 sentences of the same set for the contrastive.
</prevsent>
<prevsent>we also include our development test (news-dev2009b) and, for additional comparison, the nc-test2007?
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
news commentary test set from the 2007 wmt shared task.for each, we give case-insensitive scores on version 0.6 of meteor (lavie and agarwal, 2007)<papid> W07-0734 </papid>with all modules enabled, version 1.04 of ibm style bleu (papineni et al, 2002), <papid> P02-1040 </papid>and version 5 of ter (snover et al, 2006).from these results, we highlight two interesting areas of analysis.</citsent>
<aftsection>
<nextsent>first, the low tuning and development test set scores bring up questions about system coverage, given that the news do main was not strongly represented in our systems 2due to data processing error, the choice of the primary submission was based on incorrectly computed scores.
</nextsent>
<nextsent>infact, the contrastive system has better performance on our development test set.
</nextsent>
<nextsent>training data.
</nextsent>
<nextsent>we indeed find significantly larger proportion of out-of-vocabulary (oov) words innews-domain sets: the news-dev2009b set is translated by our primary submission with 402 of 6263 word types (6.42%) or 601 of 27,821 word tokens (2.16%) unknown.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE804">
<title id=" W09-0425.xml">an improved statistical transfer system for french english machine translation </title>
<section> evaluation and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>first, we report final (tuned) performance on our two tuning sets ? the last 425 sentences of news-dev2009a for the primary system, and the first 600 sentences of the same set for the contrastive.
</prevsent>
<prevsent>we also include our development test (news-dev2009b) and, for additional comparison, the nc-test2007?
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
news commentary test set from the 2007 wmt shared task.for each, we give case-insensitive scores on version 0.6 of meteor (lavie and agarwal, 2007)<papid> W07-0734 </papid>with all modules enabled, version 1.04 of ibm style bleu (papineni et al, 2002), <papid> P02-1040 </papid>and version 5 of ter (snover et al, 2006).from these results, we highlight two interesting areas of analysis.</citsent>
<aftsection>
<nextsent>first, the low tuning and development test set scores bring up questions about system coverage, given that the news do main was not strongly represented in our systems 2due to data processing error, the choice of the primary submission was based on incorrectly computed scores.
</nextsent>
<nextsent>infact, the contrastive system has better performance on our development test set.
</nextsent>
<nextsent>training data.
</nextsent>
<nextsent>we indeed find significantly larger proportion of out-of-vocabulary (oov) words innews-domain sets: the news-dev2009b set is translated by our primary submission with 402 of 6263 word types (6.42%) or 601 of 27,821 word tokens (2.16%) unknown.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE805">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this can be used to power trucks or cars?, knowledge that ethanol is the kind of thing that can be subject of power?, whereas crop?
</prevsent>
<prevsent>is not, is required to successfully resolve the reference of this?.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
when considering division into semantic categories ones immediate thought would be to take advantage of existing semantic resources (such as wordnet (miller, 1995)) or framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>for example, clark and weir (2002) <papid> J02-2003 </papid>calculate the probability of noun sense appearing as particular argument by using wordnet to generalise over the noun sense.</nextsent>
<nextsent>however, even though wordnet has been extremely useful in numerous applications, many researchers have found that the fact that it is largely developed via the intuitions of lexicographers, rather than being empirically based, means that the semantic information often is poorly matched with word usage in particular domain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE806">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is not, is required to successfully resolve the reference of this?.
</prevsent>
<prevsent>when considering division into semantic categories ones immediate thought would be to take advantage of existing semantic resources (such as wordnet (miller, 1995)) or framenet (baker et al, 1998).<papid> P98-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" J02-2003 ">
for example, clark and weir (2002) <papid> J02-2003 </papid>calculate the probability of noun sense appearing as particular argument by using wordnet to generalise over the noun sense.</citsent>
<aftsection>
<nextsent>however, even though wordnet has been extremely useful in numerous applications, many researchers have found that the fact that it is largely developed via the intuitions of lexicographers, rather than being empirically based, means that the semantic information often is poorly matched with word usage in particular domain.
</nextsent>
<nextsent>pantel and lin (2002) and phillips and riloff (2002) <papid> W02-1017 </papid>have pointed out that wordnet often includes many rare senses while missing out domain specific senses and terminology.</nextsent>
<nextsent>some authors, kilgariff (1997) and hanks and pustejovsky (2004), among others, reject the basic idea shared by wordnet and framenet (as well as traditional dictionaries) that there is fixed list of senses for many verbs, arguing that individual senses will often be domain specific and should be discovered empirically by examining the syntactic and semantic contexts they occur in.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE807">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, clark and weir (2002) <papid> J02-2003 </papid>calculate the probability of noun sense appearing as particular argument by using wordnet to generalise over the noun sense.</prevsent>
<prevsent>however, even though wordnet has been extremely useful in numerous applications, many researchers have found that the fact that it is largely developed via the intuitions of lexicographers, rather than being empirically based, means that the semantic information often is poorly matched with word usage in particular domain.</prevsent>
</prevsection>
<citsent citstr=" W02-1017 ">
pantel and lin (2002) and phillips and riloff (2002) <papid> W02-1017 </papid>have pointed out that wordnet often includes many rare senses while missing out domain specific senses and terminology.</citsent>
<aftsection>
<nextsent>some authors, kilgariff (1997) and hanks and pustejovsky (2004), among others, reject the basic idea shared by wordnet and framenet (as well as traditional dictionaries) that there is fixed list of senses for many verbs, arguing that individual senses will often be domain specific and should be discovered empirically by examining the syntactic and semantic contexts they occur in.
</nextsent>
<nextsent>we are highly sympathetic to this view and in this work we assume, as hanks and pustejovsky do, that rather than relying on the intuitions of lexicographer, it is better to try to induce verb senses and semantic types automatically from data drawn from the domain of interest.
</nextsent>
<nextsent>in this paper we report on some experiments in learning semantic classes.
</nextsent>
<nextsent>we carry out prior syntactic and semantic analysis of relevant corpus so that verb+argumentpairs can be identified.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE809">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>are also considered subjects of the verb clobber?, which belongs to the same synset as hit?
</prevsent>
<prevsent>but is underrepresented in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" P03-1007 ">
this is making use of the knowledge that semantically similar verbs are similar in terms of subcategorisation (korhonen and preiss, 2003)<papid> P03-1007 </papid>and is in agreement with the approach in briscoe and carroll (1997) where the subcategorisation frames (scfs) of representative verbs are merged together to form scfs of the rest of the verbs belonging to the same semantic class.</citsent>
<aftsection>
<nextsent>we understand that the above process may be indirectly adding false positives to the verb senses.
</nextsent>
<nextsent>it would be interesting in the future to examine the trade-off between boosting the counts of infrequent verbs and the addition of false positives.a second pre-processing stage was applied to the arguments of the 2,798 verb predicates.
</nextsent>
<nextsent>the idea underlying this process was to create version of the predicates where obvious semantic grouping would have already taken place.
</nextsent>
<nextsent>this involved merging together the instances of named entity?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE810">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the patterns were stored in mysql database.
</prevsent>
<prevsent>they are partly modelled on the corpus pattern analysis?
</prevsent>
</prevsection>
<citsent citstr=" C04-1133 ">
model described in pustejovsky et al (2004).<papid> C04-1133 </papid></citsent>
<aftsection>
<nextsent>these are syntagmatic patterns representing selection context for the predicate they include,which determines the sense of the latter although cpa patterns as defined by pustejovsky et al (2004) <papid> C04-1133 </papid>and rumshisky and pustejovsky (2006) are in fact rather more detailed than our patterns.</nextsent>
<nextsent>to evaluate the semantic types assigned by the automatically derived classes as well as the transferability of the derived cpa-like patterns to unseen instances, we performed pilot study where we applied the patterns to two randomly selected articles from the on-line versions of the wsj and theft from march 2008.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE812">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the literature on acquiring semantic classes of words is very extensive.
</prevsent>
<prevsent>it is mostly motivated by wsd and wsi where the aim is to discover or be able to differentiate between different senses of target word.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
pereira et al (1993) <papid> P93-1024 </papid>describes method for clustering words according to their distributions in particular syntactic contexts.</citsent>
<aftsection>
<nextsent>nouns for instance are classified according to their distribution as direct objects of verbs, where it is assumed that the classification of verbs and nouns co-varies.
</nextsent>
<nextsent>in our approach we also make this assumption and nouns are clustered indirectly by first grouping together the verb argument slots they fill.
</nextsent>
<nextsent>clustering in both cases is probabilistic with the assumptions that members of the same cluster follow similar distributions or in our case joint distribution.phillips and riloff (2002) <papid> W02-1017 </papid>and pantel and lin (2002) also describe work on clustering nouns to derive semantic classes.</nextsent>
<nextsent>work more directly comparable to ours includes schulte im walde (2003), schulte im walde (2006) who presents method for clustering german verbs by linguistically motivated feature selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE815">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation against manually annotated gold standard showed that syntactic subcategorisation features were most informative whereas selectional preferences added noise to the clustering.
</prevsent>
<prevsent>however, the author concludes that there is no perfect choice of verb features and that some verbs can be distinguished on coarse feature level while others require fine-grained information.
</prevsent>
</prevsection>
<citsent citstr=" P06-1044 ">
korhonen et al (2006) <papid> P06-1044 </papid>also use syntactically motivated features to cluster together verbs from the biomedical domain and in more recent work (sun et al, 2008) showed that rich syntactic information about both arguments and adjuncts of verbs constitute the best performing feature set for verb clustering.</citsent>
<aftsection>
<nextsent>gamallo et al (2007) follow similar approach to pantel and lin (2002) where an initial set of specific clusters, containing manually chosen terms representative of the domain as well as their lexico syntactic contexts, are aggregated to form intermediate clusters to which hierarchical clustering is applied for further generalisation.
</nextsent>
<nextsent>a very interesting aspect of this work is that concept-clusters have dual nature, consisting both of words-terms (extension) and their lexico-syntactic contexts (intension).
</nextsent>
<nextsent>as is the case in our approach, cluster formation is twofold, by grouping together words according to the contexts they appear in but also by clustering contexts based on the words they share though this is mentioned as future work in gamallo et al (2007).however, in earlier work gamallo et al (2005) <papid> J05-1005 </papid>cluster together similar syntactic positions in portuguese derived automatically and each cluster represents semantic condition.</nextsent>
<nextsent>words-fillers of the common position are used to extension ally define the particular condition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE816">
<title id=" W08-2212.xml">automatic fine grained semantic classification for domain adaptation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gamallo et al (2007) follow similar approach to pantel and lin (2002) where an initial set of specific clusters, containing manually chosen terms representative of the domain as well as their lexico syntactic contexts, are aggregated to form intermediate clusters to which hierarchical clustering is applied for further generalisation.
</prevsent>
<prevsent>a very interesting aspect of this work is that concept-clusters have dual nature, consisting both of words-terms (extension) and their lexico-syntactic contexts (intension).
</prevsent>
</prevsection>
<citsent citstr=" J05-1005 ">
as is the case in our approach, cluster formation is twofold, by grouping together words according to the contexts they appear in but also by clustering contexts based on the words they share though this is mentioned as future work in gamallo et al (2007).however, in earlier work gamallo et al (2005) <papid> J05-1005 </papid>cluster together similar syntactic positions in portuguese derived automatically and each cluster represents semantic condition.</citsent>
<aftsection>
<nextsent>words-fillers of the common position are used to extension ally define the particular condition.
</nextsent>
<nextsent>clusters are formed in two stages, where first the similarity between any two positions is calculated in terms of their common word fillers, the 20 most similar ones for each position are aggreggated and the intersection of common words kept as features.
</nextsent>
<nextsent>next, basic clusters are agglomerated according to the amount automatic fine-grained semantic classification for domain adaptation 151of shared features.
</nextsent>
<nextsent>the result is lexicon of words with syntactico-semantic requirements applied successfully to pp-attachment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE819">
<title id=" W09-1105.xml">a meta learning approach to processing the scope of negation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the system was developed and tested on biomedical text, the same approach can also be used for text from other domains.finding the scope of negation signal means determining at sentence level the sequence of words in the sentence that is affected by the negation.
</prevsent>
<prevsent>this task is different from determining whether word is negated or not.
</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
for sentence like the one in example (1) taken from the bio scope corpus (szarvas et al ., 2008), <papid> W08-0606 </papid>the system detects that lack, neither, and nor are negation signals; that lack has as its scope lack of cd5 expression, and that the discontinuous negation signal neither ... nor has as its scope neither to segregation of human auto some 11, on which the cd5 gene has been mapped, nor to deletion of the cd5 structural gene.</citsent>
<aftsection>
<nextsent>(1)  sentence id=s334.5? analysis at the phenotype and genetic level showed that  xcope idx334.5.3?  cue type=negation?
</nextsent>
<nextsent>ref=x334.5.3? lack /cue  of cd5 expression /xcope  was due  xcope id=x334.5.1?   cue type=negation?
</nextsent>
<nextsent>ref=x334.5.1? neither /cue  to segregation of human auto some 11, on which the cd5 gene has been mapped,  cue type=negation?
</nextsent>
<nextsent>ref=x334.5.1? nor /cue  to deletion of the cd5 structural gene /xcope . /sentence  predicting the scope of negation is relevant for text mining and information extraction purposes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE822">
<title id=" W09-1105.xml">a meta learning approach to processing the scope of negation </title>
<section> negation in the bio scope corpus.  </section>
<citcontext>
<prevsection>
<prevsent>length scopes 4.84 7.61 8.06 to the right av.
</prevsent>
<prevsent>length scopes 6.33 5.69 8.55 to the left % scopes to the right 97.64 81.77 85.70 % scopes to the left 2.35 18.22 14.29 table 1: statistics about the sub corpora in the bioscopecorpus and the negation scopes (av?.
</prevsent>
</prevsection>
<citsent citstr=" E99-1043 ">
stands for aver age).the bio scope corpus consists of three parts: clinical free-texts (radiology reports), biological full papers and biological paper abstracts from the genia corpus (collier et al , 1999).<papid> E99-1043 </papid></citsent>
<aftsection>
<nextsent>table 1 shows statistics about the corpora.
</nextsent>
<nextsent>negation signals are represented by one or more tokens.
</nextsent>
<nextsent>only one negation signal (exclude) that occurs in the papers sub corpus does not occur in the abstractssubcorpus, and six negation signals (absence of, exclude, favor, favor over, may, rule out that appear in the clinical sub corpus do not appear in the abstractssubcorpus.
</nextsent>
<nextsent>the negation signal no (determiner) accounts for 11.74 % of the negation signals in the abstracts sub corpus, 12.88 % in the papers subcorpus,and 76.65 % in the clinical subcorpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE823">
<title id=" W09-1105.xml">a meta learning approach to processing the scope of negation </title>
<section> negation in the bio scope corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the negation signal no (determiner) accounts for 11.74 % of the negation signals in the abstracts sub corpus, 12.88 % in the papers subcorpus,and 76.65 % in the clinical subcorpus.
</prevsent>
<prevsent>the negation signal not (adverb) accounts for 58.89 % of the negation signals in the abstracts sub corpus, 53.22 % in the papers sub corpus, and 6.72 % in the clinical subcorpus.
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
the texts have been processed with the genia tagger (tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>tsuruoka et al ,2005), bidirectional inference based tagger that analyzes english sentences and outputs the base forms, part-of-speech tags, chunk tags, and named entity tags in tab-separated format.</citsent>
<aftsection>
<nextsent>additionally, we converted the annotation about scope of negation into atoken-per-token representation, following the standard format of the 2006 conll shared task (buchholz and marsi, 2006), <papid> W06-2920 </papid>where sentences are separated by blank line and fields are separated by asingle tab character.</nextsent>
<nextsent>a sentence consists of sequence of tokens, each one starting on new line.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE824">
<title id=" W09-1105.xml">a meta learning approach to processing the scope of negation </title>
<section> negation in the bio scope corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the negation signal not (adverb) accounts for 58.89 % of the negation signals in the abstracts sub corpus, 53.22 % in the papers sub corpus, and 6.72 % in the clinical subcorpus.
</prevsent>
<prevsent>the texts have been processed with the genia tagger (tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>tsuruoka et al ,2005), bidirectional inference based tagger that analyzes english sentences and outputs the base forms, part-of-speech tags, chunk tags, and named entity tags in tab-separated format.</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
additionally, we converted the annotation about scope of negation into atoken-per-token representation, following the standard format of the 2006 conll shared task (buchholz and marsi, 2006), <papid> W06-2920 </papid>where sentences are separated by blank line and fields are separated by asingle tab character.</citsent>
<aftsection>
<nextsent>a sentence consists of sequence of tokens, each one starting on new line.
</nextsent>
<nextsent>we model the scope finding task as two consecutive classification tasks: first one that consists of classifying the tokens of sentence as being at the beginning of negation signal, inside or outside.
</nextsent>
<nextsent>this allows the system to find multiword negation signals.the second classification task consists of classifying the tokens of sentence as being the first element of the scope, the last, or neither.
</nextsent>
<nextsent>this happens as many times as there are negation signals in the sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE825">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic text summarization dates back to the1950s and 1960s (luhn, 1958; baxendale, 1958; edmundson, 1969).
</prevsent>
<prevsent>today, the proliferation of digital information makes research on summarization technologies more important than ever before.
</prevsent>
</prevsection>
<citsent citstr=" W02-0401 ">
in the last two decades, machine learning techniques have been employed in extractive summarization of single documents (kupiec et al, 1995; aone et al, 1999; osborne, 2002) <papid> W02-0401 </papid>and multiple documents (radev and mckeown, 1998; <papid> J98-3005 </papid>carbonell and goldstein, 1998; radev et al, 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>most of this work aims onlyto extract relevant sentences from the original documents and present them as the summary; this simplification of the problem yields scalable solutions.
</nextsent>
<nextsent>some attention has been devoted by the nlp community to the related problem of sentence compression (knight and marcu, 2000): given long sentence, how to maximally compress it into grammatical sentence that still preserves all the relevant information?
</nextsent>
<nextsent>while sentence compression isa promising framework with applications, for example, in headline generation (dorr et al, 2003; <papid> W03-0501 </papid>jin, 2003), little work has been done to include it as module in document summarization systems.</nextsent>
<nextsent>most existing approaches (with some exceptions, like the vine-growth model of daume?, 2006) use two-stagearchitecture, either by first extracting certain number of salient sentences and then feeding them into sentence compressor, or by first compressing all sentences and extracting later.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE826">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic text summarization dates back to the1950s and 1960s (luhn, 1958; baxendale, 1958; edmundson, 1969).
</prevsent>
<prevsent>today, the proliferation of digital information makes research on summarization technologies more important than ever before.
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
in the last two decades, machine learning techniques have been employed in extractive summarization of single documents (kupiec et al, 1995; aone et al, 1999; osborne, 2002) <papid> W02-0401 </papid>and multiple documents (radev and mckeown, 1998; <papid> J98-3005 </papid>carbonell and goldstein, 1998; radev et al, 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>most of this work aims onlyto extract relevant sentences from the original documents and present them as the summary; this simplification of the problem yields scalable solutions.
</nextsent>
<nextsent>some attention has been devoted by the nlp community to the related problem of sentence compression (knight and marcu, 2000): given long sentence, how to maximally compress it into grammatical sentence that still preserves all the relevant information?
</nextsent>
<nextsent>while sentence compression isa promising framework with applications, for example, in headline generation (dorr et al, 2003; <papid> W03-0501 </papid>jin, 2003), little work has been done to include it as module in document summarization systems.</nextsent>
<nextsent>most existing approaches (with some exceptions, like the vine-growth model of daume?, 2006) use two-stagearchitecture, either by first extracting certain number of salient sentences and then feeding them into sentence compressor, or by first compressing all sentences and extracting later.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE827">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic text summarization dates back to the1950s and 1960s (luhn, 1958; baxendale, 1958; edmundson, 1969).
</prevsent>
<prevsent>today, the proliferation of digital information makes research on summarization technologies more important than ever before.
</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
in the last two decades, machine learning techniques have been employed in extractive summarization of single documents (kupiec et al, 1995; aone et al, 1999; osborne, 2002) <papid> W02-0401 </papid>and multiple documents (radev and mckeown, 1998; <papid> J98-3005 </papid>carbonell and goldstein, 1998; radev et al, 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>most of this work aims onlyto extract relevant sentences from the original documents and present them as the summary; this simplification of the problem yields scalable solutions.
</nextsent>
<nextsent>some attention has been devoted by the nlp community to the related problem of sentence compression (knight and marcu, 2000): given long sentence, how to maximally compress it into grammatical sentence that still preserves all the relevant information?
</nextsent>
<nextsent>while sentence compression isa promising framework with applications, for example, in headline generation (dorr et al, 2003; <papid> W03-0501 </papid>jin, 2003), little work has been done to include it as module in document summarization systems.</nextsent>
<nextsent>most existing approaches (with some exceptions, like the vine-growth model of daume?, 2006) use two-stagearchitecture, either by first extracting certain number of salient sentences and then feeding them into sentence compressor, or by first compressing all sentences and extracting later.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE828">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of this work aims onlyto extract relevant sentences from the original documents and present them as the summary; this simplification of the problem yields scalable solutions.
</prevsent>
<prevsent>some attention has been devoted by the nlp community to the related problem of sentence compression (knight and marcu, 2000): given long sentence, how to maximally compress it into grammatical sentence that still preserves all the relevant information?
</prevsent>
</prevsection>
<citsent citstr=" W03-0501 ">
while sentence compression isa promising framework with applications, for example, in headline generation (dorr et al, 2003; <papid> W03-0501 </papid>jin, 2003), little work has been done to include it as module in document summarization systems.</citsent>
<aftsection>
<nextsent>most existing approaches (with some exceptions, like the vine-growth model of daume?, 2006) use two-stagearchitecture, either by first extracting certain number of salient sentences and then feeding them into sentence compressor, or by first compressing all sentences and extracting later.
</nextsent>
<nextsent>however, regardless of which operation is performed first compression or extractiontwo-step pipeline?
</nextsent>
<nextsent>approaches mayfail to find overall-optimal solutions; often the summaries are not better that the ones produced by extractive summarization.
</nextsent>
<nextsent>on the other hand, pilot study carried out by lin (2003) <papid> W03-1101 </papid>suggests that summarization systems that perform sentence compression have the potential to beat pure extractive systems if they model cross-sentence effects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE830">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, regardless of which operation is performed first compression or extractiontwo-step pipeline?
</prevsent>
<prevsent>approaches mayfail to find overall-optimal solutions; often the summaries are not better that the ones produced by extractive summarization.
</prevsent>
</prevsection>
<citsent citstr=" W03-1101 ">
on the other hand, pilot study carried out by lin (2003) <papid> W03-1101 </papid>suggests that summarization systems that perform sentence compression have the potential to beat pure extractive systems if they model cross-sentence effects.</citsent>
<aftsection>
<nextsent>in this work, we address this issue by merging the tasks of sentence extraction and sentence compression into global optimization problem.
</nextsent>
<nextsent>a careful design of the objective function encourages sparse solutions,?
</nextsent>
<nextsent>i.e., solutions that involve only small number of sentences whose compress ions are to be included in the summary.
</nextsent>
<nextsent>our contributions are: ? we cast joint sentence extraction and compression as an integer linear program (ilp);?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE833">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> sentence compression.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 related work.
</prevsent>
<prevsent>past approaches to sentence compression include noisy channel formulation (knight and marcu, 2000; daume?
</prevsent>
</prevsection>
<citsent citstr=" E06-1038 ">
and marcu, 2002), heuristic methods that parse the sentence and then trim constituents according to linguistic criteria (dorr et al, 2003; <papid> W03-0501 </papid>zajicet al, 2006), pure discriminative model (mcdonald, 2006), <papid> E06-1038 </papid>and an ilp formulation (clarke and la pata, 2008).</citsent>
<aftsection>
<nextsent>we next give an overview of the two latter approaches.
</nextsent>
<nextsent>mcdonald (2006) <papid> E06-1038 </papid>uses the outputs of two parsers(a phrase-based and dependency parser) as features in discriminative model that decomposes over pairs of consecutive words.</nextsent>
<nextsent>formally, given asentence = w1, . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE838">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> sentence compression.  </section>
<citcontext>
<prevsection>
<prevsent>let be the binary vector de figure 1: projective dependency graph.
</prevsent>
<prevsent>figure 2: non-projective dependency graph.those that assume each dependency decision is independent modulo the global structural constraint that dependency graphs must be trees.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
such models are commonly referred to as edge-factored since their parameters factor relative to individual edges of the graph (paskin, 2001; mcdonald et al,2005<papid> H05-1066 </papid>a).</citsent>
<aftsection>
<nextsent>edge-factored models have many computational benefits, most notably that inference for non projective dependency graphs can be achieved inpolynomial time (mcdonald et al, 2005<papid> H05-1066 </papid>b).</nextsent>
<nextsent>the primary problem in treating each dependency as independent is that it is not realistic assumption.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE871">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the compression ratio associated with the reference compressed sentences in this dataset is 69.06%.
</prevsent>
<prevsent>in the rightmost column, the statistically indistinguishable best results are emboldened, based on paired t-test applied to the sequence of f1 measures (p   0.01).
</prevsent>
</prevsection>
<citsent citstr=" W02-0406 ">
sentences, calculated on unigrams.7 to evaluate the full system, we used rouge-n(lin and hovy, 2002), <papid> W02-0406 </papid>popular n-gram recall based automatic evaluation measure.</citsent>
<aftsection>
<nextsent>this score compares the summary produced by system with one or more valid reference summaries.
</nextsent>
<nextsent>all our experiments were conducted on pc with intel dual-core processor with 2.66 ghz and 2 gbram memory.
</nextsent>
<nextsent>we used ilog cplex, commercial integer programming solver.
</nextsent>
<nextsent>the interface with cplex was coded in java.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE888">
<title id=" W09-1801.xml">summarization with a joint model for sentence extraction and compression </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we also intend to model discourse, which, asshown by daume?
</prevsent>
<prevsent>and marcu (2002), plays an important role in document summarization.
</prevsent>
</prevsection>
<citsent citstr=" C08-1018 ">
another future direction is to extend our ilp formulations to more sophisticated models that go beyond word deletion, like the ones proposed by cohn and lapata (2008).<papid> C08-1018 </papid></citsent>
<aftsection>
<nextsent>acknowledgments the authors thank the anonymous reviewers for helpful comments, yiming yang for interesting discussions, and dipanjan das and sourish chaudhuri for providing their code.
</nextsent>
<nextsent>this research was supported by grant from fctthrough the cmu-portugal program and the information and communications technologies institute (icti) at cmu, and also by priberam informatica.
</nextsent>
<nextsent>8
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE889">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conceptually, the 2008 shared task can be divided into three subtasks: (i) parsing of syntactic dependencies, (ii) identification and disambiguation of semantic predicates, and (iii) identification of arguments and assignment of semantic roles for each predicate.
</prevsent>
<prevsent>several objectives were addressed in this shared task: ? srl is performed and evaluated using dependency-based representation for both syntactic and semantic dependencies.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
while srl on top of dependency treebank has been addressed before (hacioglu, 2004), <papid> C04-1186 </papid>our approach has several novelties: (i) ourconstituent-to-dependency conversion strategy transforms all annotated semantic arguments in propbank and nombank not just subset; (ii) we address propositions centered around both verbal (propbank) and nominal (nombank) predicates.</citsent>
<aftsection>
<nextsent>based on the observation that richer setof syntactic dependencies improves semantic processing (johansson and nugues, 2007), the syntactic dependencies modeled are more complex than the ones used in the previous conll shared tasks.
</nextsent>
<nextsent>for example, we now include apposition links, dependencies derived from named entity (ne) structures, and better modeling of long-distance grammatical relations.
</nextsent>
<nextsent>a practical framework is provided for the joint learning of syntactic and semantic dependencies.
</nextsent>
<nextsent>159 given the complexity of this shared task, we limited the evaluation to monolingual, english only setting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE890">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>padding characters (?
</prevsent>
<prevsent>are used in columns 25 to ensure the same number of rows for all columns corresponding to one sentence.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
all syntactic and semantic dependencies are annotated relative to the split word forms (columns 68).table 2 shows the columns available to the systems participating in the open challenge: named entity labels as in the conll-2003 shared task (tjong kim san and de meulder, 2003) and from the bbn wall street journal entity corpus, 2wordnet super sense tags, and the output of an off the-shelf dependency parser (nivre et al, 2007<papid> D07-1096 </papid>b).</citsent>
<aftsection>
<nextsent>columns 13 were predicted using the tagger of ciaramita and altun (2006).<papid> W06-1670 </papid></nextsent>
<nextsent>because the bbn corpus shares lexical content with the penn tree bank, we generated the bbn tags using 2-fold cross-validation procedure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE891">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>are used in columns 25 to ensure the same number of rows for all columns corresponding to one sentence.
</prevsent>
<prevsent>all syntactic and semantic dependencies are annotated relative to the split word forms (columns 68).table 2 shows the columns available to the systems participating in the open challenge: named entity labels as in the conll-2003 shared task (tjong kim san and de meulder, 2003) and from the bbn wall street journal entity corpus, 2wordnet super sense tags, and the output of an off the-shelf dependency parser (nivre et al, 2007<papid> D07-1096 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
columns 13 were predicted using the tagger of ciaramita and altun (2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>because the bbn corpus shares lexical content with the penn tree bank, we generated the bbn tags using 2-fold cross-validation procedure.
</nextsent>
<nextsent>2.2 evaluation measures.
</nextsent>
<nextsent>we separate the evaluation measures into two groups: (i) official measures, which were used forthe ranking of participating systems, and (ii) additional unofficial measures, which provide further insight into the performance of the participating systems.
</nextsent>
<nextsent>2.2.1 official evaluation measures the official evaluation measures consist of three different scores: (i) syntactic dependencies are scored using the labeled attachment score (las), (ii) semantic dependencies are evaluated using labeled 1 score, and (iii) the overall task is scored with macro average of the two previous scores.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE892">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> lemma predicted lemma of form..  </section>
<citcontext>
<prevsection>
<prevsent>all annotations are currently being distributed by the linguistic data consortium, with the exception of nombank, which is freely downloadable.
</prevsent>
<prevsent>6 6 http://nlp.cs.nyu.edu/meyers/nombank.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
html 162 3.1.1 penn treebank 3 the penn treebank 3 corpus (marcus et al, 1993) <papid> J93-2004 </papid>consists of hand-coded parses of the wall street journal (test, development and training) anda small subset of the brown corpus (w. n. francis and h. kucera, 1964) (test only).</citsent>
<aftsection>
<nextsent>these hand parses are notated in-line and sometimes involve changing the strings of the input data.
</nextsent>
<nextsent>forex ample, in file wsj 0309, the token fear last in the text corresponds to the two tokens fear and last in the annotated data.
</nextsent>
<nextsent>in similar way, cannot is regularly split to can and not.
</nextsent>
<nextsent>it is significant that the other annotations assume the tokenization of the penn treebank, as this makes it easier for us to merge the annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE893">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> lemma predicted lemma of form..  </section>
<citcontext>
<prevsection>
<prevsent>subcategories are included as well.
</prevsent>
<prevsent>note however that from this corpus we only use ne boundaries to derive name dependencies between ne tokens, e.g., we create name dependency from mary to smith given the ne mention mary smith.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
3.1.3 proposition bank (propbank) the propbank annotation (palmer et al, 2005) <papid> J05-1004 </papid>classifies the arguments of all the main verbs in the penn treebank corpus, other than be.</citsent>
<aftsection>
<nextsent>arguments are numbered (arg0, arg1, . . .)
</nextsent>
<nextsent>based on lexical entries or frame files.
</nextsent>
<nextsent>different sets of arguments are assumed for different rolesets.
</nextsent>
<nextsent>dependent constituents that fall into categories independent of the lexical entries are classified as various types 7 http://projects.ldc.upenn.edu/ace/ of argm (tmp, adv, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE896">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>in the table) or graph-based (graph?)
</prevsent>
<prevsent>models.
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
by and large, transition-based models use greedy inference strategy, whereas graph-based models used different maximum spanning tree (mst) algorithms: carreras (2007) ? <papid> D07-1101 </papid>mst c, eisner (2000) ? mst e, or chu-liu/edmonds (mc donald et al, 2005; <papid> H05-1066 </papid>chu and liu, 1965; edmonds, 1967) ? mst cl/e . more interestingly, most of.</citsent>
<aftsection>
<nextsent>the best systems used some strategy to mitigate parsing errors.
</nextsent>
<nextsent>in the top three systems in the closed challenge, two (che and ciaramita) used parser combination through voting and/or stacking of different models (see the comb.
</nextsent>
<nextsent>column).samuelsson et al (2008) perform mst inference with the bag of all dependencies output by the individual malt parser variants.
</nextsent>
<nextsent>johansson and nugues (2008) use single parsing model, but this model is extended with second-order features.the pa arch.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE897">
<title id=" W08-2121.xml">the conll 2008 shared task on joint parsing of syntactic and semantic dependencies </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>in the table) or graph-based (graph?)
</prevsent>
<prevsent>models.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
by and large, transition-based models use greedy inference strategy, whereas graph-based models used different maximum spanning tree (mst) algorithms: carreras (2007) ? <papid> D07-1101 </papid>mst c, eisner (2000) ? mst e, or chu-liu/edmonds (mc donald et al, 2005; <papid> H05-1066 </papid>chu and liu, 1965; edmonds, 1967) ? mst cl/e . more interestingly, most of.</citsent>
<aftsection>
<nextsent>the best systems used some strategy to mitigate parsing errors.
</nextsent>
<nextsent>in the top three systems in the closed challenge, two (che and ciaramita) used parser combination through voting and/or stacking of different models (see the comb.
</nextsent>
<nextsent>column).samuelsson et al (2008) perform mst inference with the bag of all dependencies output by the individual malt parser variants.
</nextsent>
<nextsent>johansson and nugues (2008) use single parsing model, but this model is extended with second-order features.the pa arch.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE898">
<title id=" W09-1325.xml">semantic annotation of papers interface x26 enrichment tool sapient </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as part of the system,we developed an xml-aware sentence splitter (sssplit) which preserves xml markup and identifies sentences through the addition of in-line markup.
</prevsent>
<prevsent>sapient has been used in systematic study for the annotation of scientific papers with concepts representing the core information about scientific papers(cisp) to create corpus of 225 annotated papers.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
given the rapid growth in the quantity of scientific literature, particularly in the biosciences, there is an increasing need to work with full papers rather than abstracts, both to identify their key contributions and to provide some automated assistance to researchers (karamanis et al, 2008; medlock and briscoe, 2007).<papid> P07-1125 </papid></citsent>
<aftsection>
<nextsent>initiatives like otmi1, which aim to make full papers available to researchers for text mining purposes is further evidence that relying solely on abstracts presents important limitations for such tasks.
</nextsent>
<nextsent>a recent study on whether information retrieval from full text is more effective than searching abstracts alone (lin jimmy, 2009) showed that 1http://opentextmining.org/wiki/main pagethe former is indeed the case.
</nextsent>
<nextsent>their experimental results suggested that span-level analysis is promising strategy for taking advantage of the full papers,where spans are defined as paragraphs of text assessed by humans and deemed to be relevant to one of 36 pre-defined topics.
</nextsent>
<nextsent>therefore, when working with full papers, it is important to be able to identify and annotate spans of text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE899">
<title id=" W09-1325.xml">semantic annotation of papers interface x26 enrichment tool sapient </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, when working with full papers, it is important to be able to identify and annotate spans of text.
</prevsent>
<prevsent>in previous research, sentence based annotation has been used to identify text regions with scientific content of interest to the user (wilbur et al, 2006; shatkay et al, 2008) or zones of different rhetorical status (az) (teufel and moens, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N06-4006 ">
sentences are the structural units of paragraphs and can be more flexible than paragraphs for text mining purposes other than information re trieval.current general purpose systems for linguistic annotation such as callisto2 allow the creation of simple annotation schema that is tag set augmented with simple (e.g. string) attributes for each tag.knowtator (ogren, 2006) <papid> N06-4006 </papid>is plug-in of the knowledge representation tool protege3, which works as general purpose text annotation tool and has the advantage that it can work with complex ontology derived schemas.</citsent>
<aftsection>
<nextsent>however, these systems are not particularly suited to sentence by sentence annotation of full papers, as one would need to highlight entire sentences manually.
</nextsent>
<nextsent>also these systems work mainly with plain text, so they do not necessarily interpret the structural information already available in the paper, which can be crucial to annotation decisions for the type of high level annotation mentioned 2http://callisto.mitre.org/manual/use.html 3http://protege.stanford.edu/ 193 above.
</nextsent>
<nextsent>the oscar3 (corbett et al, 2007) <papid> W07-1008 </papid>tool for the recognition and annotation of chemical named entities fully displays underlying paper information in xml but is not suited to sentence by sentence an notation.to address the above issues, we present system (sapient) for sentence by sentence annotation of scientific papers which supports ontology motivated concepts representing the core information about scientific papers (cisp) (soldatova and liakata, 2007).</nextsent>
<nextsent>an important aspect of the system isthat although annotation is sentence based, the system caters for identifiers, which link together sentences pertaining to the same concept.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE900">
<title id=" W09-1325.xml">semantic annotation of papers interface x26 enrichment tool sapient </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these systems are not particularly suited to sentence by sentence annotation of full papers, as one would need to highlight entire sentences manually.
</prevsent>
<prevsent>also these systems work mainly with plain text, so they do not necessarily interpret the structural information already available in the paper, which can be crucial to annotation decisions for the type of high level annotation mentioned 2http://callisto.mitre.org/manual/use.html 3http://protege.stanford.edu/ 193 above.
</prevsent>
</prevsection>
<citsent citstr=" W07-1008 ">
the oscar3 (corbett et al, 2007) <papid> W07-1008 </papid>tool for the recognition and annotation of chemical named entities fully displays underlying paper information in xml but is not suited to sentence by sentence an notation.to address the above issues, we present system (sapient) for sentence by sentence annotation of scientific papers which supports ontology motivated concepts representing the core information about scientific papers (cisp) (soldatova and liakata, 2007).</citsent>
<aftsection>
<nextsent>an important aspect of the system isthat although annotation is sentence based, the system caters for identifiers, which link together sentences pertaining to the same concept.
</nextsent>
<nextsent>this way spans of interest or key regions are formed.
</nextsent>
<nextsent>sapi ent also incorporates oscar3 capability for the automatic recognition of chemical named entities and runs within browser, which makes it platformindependent.
</nextsent>
<nextsent>sapient takes as input full scientific papers in xml, splits them into individual sentences, displays them and allows the user to annotate each sentence with one of 11 cisp concepts aswell as link the sentence to other sentences refer ring to the same instance of the concept selected.the system is especially suitable for so called multidimensional annotation (shatkay et al, 2008) orontology-motivated annotation, where label originates from class with properties.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE903">
<title id=" W09-1325.xml">semantic annotation of papers interface x26 enrichment tool sapient </title>
<section> sssplit: sapient sentence splitting.  </section>
<citcontext>
<prevsection>
<prevsent>xml markup (e.g.  abstract , ref , equation )needs to be combined carefully with tags designating sentence boundaries (  /s ), so that the resulting document is in well formed xml.
</prevsent>
<prevsent>current sentence splitters ignore xml markup, which means that any document formatting/information would have to be removed in order to use them.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
rasp (briscoe et al, 2006), <papid> P06-4020 </papid>the sentence splitter used in the sciborg project4 at the university of cambridge, can deal with xml but has to be compiled for different operating systems, which would result in compromising the platform independence of sapient.</citsent>
<aftsection>
<nextsent>a recent mphil thesis (owusu, 2008) has also developed an xml-aware sentence splitter but the code is in microsoft c#.net and therefore not platform independent.we have written the xml-aware sentence splitter sssplit in the platform-independent java language (version 1.6), based on and extending open source perl code5 for handling plain text.
</nextsent>
<nextsent>in or 4http://www.cl.cam.ac.uk/research/nl/sciborg/www/ 5http://search.cpan.org/ tgrose/html-summary-0.017/ 196 figure 3: example of sapient annotation through selection from drop-down menu.
</nextsent>
<nextsent>figure 4: behind the scenes: example xml fragment of paper annotated using sapient.
</nextsent>
<nextsent>figure 5: incorporation of oscar3 annotations in sapient, after selecting the link auto annotate?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE905">
<title id=" W09-1414.xml">from protein protein interaction to molecular event extraction </title>
<section> material and methods.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 event clue-word tagging.
</prevsent>
<prevsent>event clue-word detection was performed by machine learning (ml) sequence labeling program.
</prevsent>
</prevsection>
<citsent citstr=" W07-1033 ">
this named-entity tagger program is based on first order maximum entropy markov model (memm) and is described in yoshida and tsujii (2007).<papid> W07-1033 </papid></citsent>
<aftsection>
<nextsent>the clue-word annotation of the shared-task training set was converted into bio format, and used to train the 2http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 3http://www.cs.cmu.edu/sagae/parser/gdep/ memm model.
</nextsent>
<nextsent>the features used in the memm model was extracted from surface strings and pos information of the words corresponding to (or adjacent to) the target bio tags.
</nextsent>
<nextsent>the clue-word tagger was applied to the development and test sets to obtain the marginal probability that each word is clue-word of certain category.
</nextsent>
<nextsent>the probabilities were obtained by marginalizing the n-best output of the memm tagger.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE906">
<title id=" W09-0427.xml">toward using morphology in french english phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe the system used in our submission to the wmt-2009 french-englishtranslation task.
</prevsent>
<prevsent>we use the moses phrase based statistical machine translation system with two simple mod ications of the decoding input and word-alignment strategy based on morphology, and analyze their impact on translation quality.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
in this first participation to the french-english translation task at wmt, our goal was to build astandard phrase-based statistical machine translation system and study the impact of french morphological variations at different stages of training and decoding.many strategies have been proposed to integrate morphology information in smt, including factored translation models (koehn and hoang, 2007), <papid> D07-1091 </papid>adding translation dictionary containing inflected forms to the training data (schwenk et al., 2008), <papid> W08-0313 </papid>entirely replacing surface forms by representations built on lemmas and pos tags (popovic?</citsent>
<aftsection>
<nextsent>and ney, 2004), morphemes learned in an unsupervised manner (virpojia et al, 2007), and using porter stems and even 4-letter prefixes for word alignment (watanabe et al, 2006).<papid> W06-3115 </papid></nextsent>
<nextsent>in non-european languages, such as arabic, heavy effort has been put in identifying appropriate in put representations to improve smt quality (e.g., sadat and habash (2006))as first step toward using morphology information in our french-english smt system, this submission focused on studying the impact ofthe author was partially funded by gale darpa contract no.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE907">
<title id=" W09-0427.xml">toward using morphology in french english phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe the system used in our submission to the wmt-2009 french-englishtranslation task.
</prevsent>
<prevsent>we use the moses phrase based statistical machine translation system with two simple mod ications of the decoding input and word-alignment strategy based on morphology, and analyze their impact on translation quality.
</prevsent>
</prevsection>
<citsent citstr=" W08-0313 ">
in this first participation to the french-english translation task at wmt, our goal was to build astandard phrase-based statistical machine translation system and study the impact of french morphological variations at different stages of training and decoding.many strategies have been proposed to integrate morphology information in smt, including factored translation models (koehn and hoang, 2007), <papid> D07-1091 </papid>adding translation dictionary containing inflected forms to the training data (schwenk et al., 2008), <papid> W08-0313 </papid>entirely replacing surface forms by representations built on lemmas and pos tags (popovic?</citsent>
<aftsection>
<nextsent>and ney, 2004), morphemes learned in an unsupervised manner (virpojia et al, 2007), and using porter stems and even 4-letter prefixes for word alignment (watanabe et al, 2006).<papid> W06-3115 </papid></nextsent>
<nextsent>in non-european languages, such as arabic, heavy effort has been put in identifying appropriate in put representations to improve smt quality (e.g., sadat and habash (2006))as first step toward using morphology information in our french-english smt system, this submission focused on studying the impact ofthe author was partially funded by gale darpa contract no.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE908">
<title id=" W09-0427.xml">toward using morphology in french english phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we use the moses phrase based statistical machine translation system with two simple mod ications of the decoding input and word-alignment strategy based on morphology, and analyze their impact on translation quality.
</prevsent>
<prevsent>in this first participation to the french-english translation task at wmt, our goal was to build astandard phrase-based statistical machine translation system and study the impact of french morphological variations at different stages of training and decoding.many strategies have been proposed to integrate morphology information in smt, including factored translation models (koehn and hoang, 2007), <papid> D07-1091 </papid>adding translation dictionary containing inflected forms to the training data (schwenk et al., 2008), <papid> W08-0313 </papid>entirely replacing surface forms by representations built on lemmas and pos tags (popovic?</prevsent>
</prevsection>
<citsent citstr=" W06-3115 ">
and ney, 2004), morphemes learned in an unsupervised manner (virpojia et al, 2007), and using porter stems and even 4-letter prefixes for word alignment (watanabe et al, 2006).<papid> W06-3115 </papid></citsent>
<aftsection>
<nextsent>in non-european languages, such as arabic, heavy effort has been put in identifying appropriate in put representations to improve smt quality (e.g., sadat and habash (2006))as first step toward using morphology information in our french-english smt system, this submission focused on studying the impact ofthe author was partially funded by gale darpa contract no.
</nextsent>
<nextsent>hr0011-06-c-0023.
</nextsent>
<nextsent>any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the defense advanced research projects agency.
</nextsent>
<nextsent>different input representations for french based on the pos and lemmatization provided by the tree tagger tool (schmid, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE909">
<title id=" W09-0427.xml">toward using morphology in french english phrase based smt </title>
<section> translation system.  </section>
<citcontext>
<prevsection>
<prevsent>third, sentence-initial capitalized words are normalized to their most frequent form as reported by zollmann et al (2006).
</prevsent>
<prevsent>2.3 core system.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we use the moses phrase-based statistical machine translation system (koehn et al, 2007) <papid> P07-2045 </papid>and follow standard training, tuning and decoding strategies.the translation model consists of standard moses phrase-table with lexicalized reorder ing.</citsent>
<aftsection>
<nextsent>bidirectional word alignments obtained with giza++ are intersected using the grow-diag-final heuristic.
</nextsent>
<nextsent>translations of phrases of up to 7 words long are collected and scored with translation pro bil ities and lexical weighting.
</nextsent>
<nextsent>the english language model is 4-gram model with kneser-ney smoothing, built with the sri language modeling toolkit (stolcke, 2002).
</nextsent>
<nextsent>the loglinear model feature weights were learned using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>with bleu score (papineni et al, 2002) <papid> P02-1040 </papid>as the objective function.other decoding parameters were selected manually on an earlier version of the system trained and evaluated on the single-domain europarl data.while the configuration achieved competitive results on the previous, it is not be optimal for this domain adaptation task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE910">
<title id=" W09-0427.xml">toward using morphology in french english phrase based smt </title>
<section> translation system.  </section>
<citcontext>
<prevsection>
<prevsent>translations of phrases of up to 7 words long are collected and scored with translation pro bil ities and lexical weighting.
</prevsent>
<prevsent>the english language model is 4-gram model with kneser-ney smoothing, built with the sri language modeling toolkit (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the loglinear model feature weights were learned using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>with bleu score (papineni et al, 2002) <papid> P02-1040 </papid>as the objective function.other decoding parameters were selected manually on an earlier version of the system trained and evaluated on the single-domain europarl data.while the configuration achieved competitive results on the previous, it is not be optimal for this domain adaptation task.</citsent>
<aftsection>
<nextsent>we will first conduct an analysis of this coresmt system, and experiment with two modifications of input representation for decoding and alignment respectively.
</nextsent>
<nextsent>1www.ims.uni-stuttgart.de/projekte/corplex/treetagger/ oov verbs w/ surface form in training corpus w/ lemma+ pos in training corpus dev2009a 21 (28%) 48 (63%) dev2009b 16 (24%) 33 (49%) table 1: unknown verbs statistics
</nextsent>
<nextsent>seen in training our baseline system is set up to copy unknown words to the output.
</nextsent>
<nextsent>this is helpful strategy to translate unknown names and cognates, but is far from optimal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE911">
<title id=" W09-0427.xml">toward using morphology in french english phrase based smt </title>
<section> translation system.  </section>
<citcontext>
<prevsection>
<prevsent>translations of phrases of up to 7 words long are collected and scored with translation pro bil ities and lexical weighting.
</prevsent>
<prevsent>the english language model is 4-gram model with kneser-ney smoothing, built with the sri language modeling toolkit (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the loglinear model feature weights were learned using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>with bleu score (papineni et al, 2002) <papid> P02-1040 </papid>as the objective function.other decoding parameters were selected manually on an earlier version of the system trained and evaluated on the single-domain europarl data.while the configuration achieved competitive results on the previous, it is not be optimal for this domain adaptation task.</citsent>
<aftsection>
<nextsent>we will first conduct an analysis of this coresmt system, and experiment with two modifications of input representation for decoding and alignment respectively.
</nextsent>
<nextsent>1www.ims.uni-stuttgart.de/projekte/corplex/treetagger/ oov verbs w/ surface form in training corpus w/ lemma+ pos in training corpus dev2009a 21 (28%) 48 (63%) dev2009b 16 (24%) 33 (49%) table 1: unknown verbs statistics
</nextsent>
<nextsent>seen in training our baseline system is set up to copy unknown words to the output.
</nextsent>
<nextsent>this is helpful strategy to translate unknown names and cognates, but is far from optimal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE915">
<title id=" W09-0634.xml">a probabilistic model of referring expressions for complex objects </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the basic orientation of this research was pursuing an algorithm that generates minimal description which uniquely identifies target object from distractors.
</prevsent>
<prevsent>thusthe research was oriented and limited by two con straints: minimality and uniqueness.
</prevsent>
</prevsection>
<citsent citstr=" C08-2029 ">
the constraint on minimality has, however, been relaxed due to the computational complexity of generation, the perceived naturalness of redundant expressions, and the easiness of understanding them (e.g., (dale and reiter, 1995; spanger et al., 2008)).<papid> C08-2029 </papid></citsent>
<aftsection>
<nextsent>on the other hand, the other constraint of uniqueness has not been paid much attention to.
</nextsent>
<nextsent>one major aim of our research is to relax this constraint on uniqueness because of the reason explained below.
</nextsent>
<nextsent>the fundamental goal of our research is to deal with multi partite objects, which have constituents with different attribute values.
</nextsent>
<nextsent>typical domain settings in previous literature use uniform objects like the table shown in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE916">
<title id=" W09-0634.xml">a probabilistic model of referring expressions for complex objects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as first step in our research, we validate the model with the tuna corpus to show that it includes conventional domain modeling.
</prevsent>
<prevsent>figure 1: an example scene 191
</prevsent>
</prevsection>
<citsent citstr=" W05-1606 ">
horacek (2005) <papid> W05-1606 </papid>proposes to introduce probabilities to overcome uncertainties due to discrepancies in knowledge and cognition between subjects.while our model shares the same awareness of issues with horaceks work, our focus is on rather different issues (i.e., handling multi partite objects and relaxing the constraint on uniqueness).</citsent>
<aftsection>
<nextsent>in addition, horaceks work is concerned only with generation while our model is available both for generation and understanding.
</nextsent>
<nextsent>roy (2002) also proposes probabilistic model for generation but presupposes uniform objects.horacek (2006) <papid> W06-1408 </papid>deals with references for structured objects such as documents.</nextsent>
<nextsent>although it considers parts of objects, the motivation and focus of the work are on quite different aspects from ours.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE918">
<title id=" W09-0634.xml">a probabilistic model of referring expressions for complex objects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>horacek (2005) <papid> W05-1606 </papid>proposes to introduce probabilities to overcome uncertainties due to discrepancies in knowledge and cognition between subjects.while our model shares the same awareness of issues with horaceks work, our focus is on rather different issues (i.e., handling multi partite objects and relaxing the constraint on uniqueness).</prevsent>
<prevsent>in addition, horaceks work is concerned only with generation while our model is available both for generation and understanding.</prevsent>
</prevsection>
<citsent citstr=" W06-1408 ">
roy (2002) also proposes probabilistic model for generation but presupposes uniform objects.horacek (2006) <papid> W06-1408 </papid>deals with references for structured objects such as documents.</citsent>
<aftsection>
<nextsent>although it considers parts of objects, the motivation and focus of the work are on quite different aspects from ours.
</nextsent>
<nextsent>we conducted two psycho linguistic experiments using the visual stimulus shown in figure 1.in the first experiment, thirteen japanese subjects were presented with an expression kado no akai tukue (the table with red corners)?
</nextsent>
<nextsent>and asked to choose table from the three in the figure.
</nextsent>
<nextsent>twelve out of the thirteen chose table b. seven out of the twelve subjects answered that the given expression was not ambiguous.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE922">
<title id=" W08-1001.xml">lexicalised parsing of german v2 </title>
<section> partial vp fronting.  </section>
<citcontext>
<prevsection>
<prevsent>the design of the parser employed here can be called constrained free word order parsing.
</prevsent>
<prevsent>first, it allows for completely free word order at default.
</prevsent>
</prevsection>
<citsent citstr=" P85-1015 ">
the core algorithm for the parse engine is whatreape (1991) presents as generalised permutation complete parser, which in turn is based on the preceding proposal of johnson (1985).<papid> P85-1015 </papid></citsent>
<aftsection>
<nextsent>details apart,while using context-free production rules (no multiple left-hand side non-terminal symbols), this algorithm only checks for the presence of all the right hand side constituents, wherever in the string they occur, potentially discontinuously,1 effectively licensing all the permutations of the given terminal symbols (e.g. 3!
</nextsent>
<nextsent>= 6 permutations for the string consisting of ring, up and john including upjohn ring etc.).
</nextsent>
<nextsent>this directionless?
</nextsent>
<nextsent>parsing is rendered possible by johnsons bitvector?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE923">
<title id=" W09-0506.xml">predicting concept types in user corrections in dialog </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when dialog system requests confirmation, the users subsequent corrections and topic change utterances are particularly likely to be misrecog nized.
</prevsent>
<prevsent>considerable research has now been done on the automatic detection of spoken corrections.linguistic cues to corrections include the number of words in the post-confirmation utterance and the use of marked word order (krahmer et al., 2001).
</prevsent>
</prevsection>
<citsent citstr=" J06-3004 ">
prosodic cues include f0 max, rms max, rms mean, duration, speech tempo, and percentage of silent frames(litman et al, 2006; <papid> J06-3004 </papid>hirschberg et al, 2004; levow, 1998).<papid> P98-1122 </papid></citsent>
<aftsection>
<nextsent>discourse cues include the removal, repetition, addition or modification of concept, the systems dialog acttype, and information about error rates in the dialog so far (krahmer et al, 2001; et al, 2002; litman et al, 2006; <papid> J06-3004 </papid>walker et al, 2000).</nextsent>
<nextsent>in our experiments, we use most of these features as well as additional lexical features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE925">
<title id=" W09-0506.xml">predicting concept types in user corrections in dialog </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when dialog system requests confirmation, the users subsequent corrections and topic change utterances are particularly likely to be misrecog nized.
</prevsent>
<prevsent>considerable research has now been done on the automatic detection of spoken corrections.linguistic cues to corrections include the number of words in the post-confirmation utterance and the use of marked word order (krahmer et al., 2001).
</prevsent>
</prevsection>
<citsent citstr=" P98-1122 ">
prosodic cues include f0 max, rms max, rms mean, duration, speech tempo, and percentage of silent frames(litman et al, 2006; <papid> J06-3004 </papid>hirschberg et al, 2004; levow, 1998).<papid> P98-1122 </papid></citsent>
<aftsection>
<nextsent>discourse cues include the removal, repetition, addition or modification of concept, the systems dialog acttype, and information about error rates in the dialog so far (krahmer et al, 2001; et al, 2002; litman et al, 2006; <papid> J06-3004 </papid>walker et al, 2000).</nextsent>
<nextsent>in our experiments, we use most of these features as well as additional lexical features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE929">
<title id=" W09-1411.xml">molecular event extraction from link grammar parse trees </title>
<section> fns: query misses one argument.  </section>
<citcontext>
<prevsection>
<prevsent>after some manual sentence simplification to increase parsing efficiency, their system assumed an interaction whenever two proteins were connected via link path; an adjustable threshold allowed tocut-off too long paths.
</prevsent>
<prevsent>as they used the original version of link grammar, ding et al argue that adaptations to the biomedical domain would enhance theperformance.
</prevsent>
</prevsection>
<citsent citstr=" W04-1203 ">
pyysalo et al (2004) <papid> W04-1203 </papid>extracted interaction subgraphs, spanning all predicates and arguments at the same time, from the link grammar linkage of known examples.</citsent>
<aftsection>
<nextsent>failure analysis revealed that 34% of the errors were due to unknown grammatical structures, 26% due to dictionary issues and further 17% due to unknown words.
</nextsent>
<nextsent>an adaption of link grammar that handles some of the failure cases is biolg (pyysalo et al, 2006).
</nextsent>
<nextsent>biolg includes additional morpho-guessing rules, 92 lexicon expansion, and disambiguation using pos tagger.
</nextsent>
<nextsent>adding morpho-guessing rules and using adomain-specific pos tagger for disambiguation resulted in an increase from 74.2 to 76.8% in re call; it also increased parsing efficiency by 45%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE930">
<title id=" W08-1307.xml">constructing a parser evaluation scheme </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, in the sentence mary likes apples and pears, the coordination structure apples and pears serves as direct object of likes, and it must be determined which word(s) are used to represent the coordination in the direct object relation.
</prevsent>
<prevsent>we will illustrate some of the consequences ofthe decisions described here with detailed examples of three construction types.
</prevsent>
</prevsection>
<citsent citstr=" P06-2006 ">
we focus on passive, coordination, and relative clause constructions, as analysed in the parc (king et al, 2003), gr (briscoe and carroll, 2006), <papid> P06-2006 </papid>and stanford (de marneffe et al, 2006) evaluation schemes, using sentences from the shared task of the coling 2008 parser evaluation workshop.</citsent>
<aftsection>
<nextsent>1these three constructions were chosen because we believe they provide particularly good illustrations of the various decisions and their consequences for scoring.furthermore, they are constructions whose representation differs across at least two of the three grammatical relation schemes under dicsussion, which makes them more interesting as examples.
</nextsent>
<nextsent>we believe that the principles involved, however, 1 the shared task includes number of additional formats besides the three grammatical relation schemes that we consider here, but the representations are sufficiently different that we dont consider comparison fruitful for the present discussion.
</nextsent>
<nextsent>45 apply to any linguistic construction.
</nextsent>
<nextsent>we also wish to point out that at this stage we are not recommending any particular scheme or any answers to the questions we raise, but only suggesting ways to clarify the decision points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE932">
<title id=" W09-0622.xml">a situated context model for resolution and generation of referring expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>is supposed to direct the hearers attention to the rack and its contents.
</prevsent>
<prevsent>in the following we propose an approach for context determination and extension that allows amobile robot to produce and interpret res to entities outside the current visual context.
</prevsent>
</prevsection>
<citsent citstr=" P97-1027 ">
most gre approaches are applied to very limited, visual scenes ? so-called small-scale space.the domain of such systems is usually small visual scene, e.g. number of objects, such as cups and tables, located in the same room), or other closed-context scenarios (dale and reiter, 1995;horacek, 1997; <papid> P97-1027 </papid>krahmer and theune, 2002).</citsent>
<aftsection>
<nextsent>recently, kelleher and kruijff (2006) <papid> P06-1131 </papid>have presented an incremental gre algorithm for situated dialogue with robot about table-top setting, i.e. also about small-scale space.</nextsent>
<nextsent>in all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocu tors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE933">
<title id=" W09-0622.xml">a situated context model for resolution and generation of referring expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in the following we propose an approach for context determination and extension that allows amobile robot to produce and interpret res to entities outside the current visual context.
</prevsent>
<prevsent>most gre approaches are applied to very limited, visual scenes ? so-called small-scale space.the domain of such systems is usually small visual scene, e.g. number of objects, such as cups and tables, located in the same room), or other closed-context scenarios (dale and reiter, 1995;horacek, 1997; <papid> P97-1027 </papid>krahmer and theune, 2002).</prevsent>
</prevsection>
<citsent citstr=" P06-1131 ">
recently, kelleher and kruijff (2006) <papid> P06-1131 </papid>have presented an incremental gre algorithm for situated dialogue with robot about table-top setting, i.e. also about small-scale space.</citsent>
<aftsection>
<nextsent>in all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocutors.
</nextsent>
<nextsent>the intended referent is thus already in the hearers focus of attention.
</nextsent>
<nextsent>in contrast, robots typically act in large-scalespace, i.e. space larger than what can be perceived at once?
</nextsent>
<nextsent>(kuipers, 1977).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE934">
<title id=" W09-0622.xml">a situated context model for resolution and generation of referring expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they need the ability to understand and produce references to things that are beyond the current visual and spatial context.
</prevsent>
<prevsent>in any situated dialogue that involves entities beyond the current focus of attention, the task of extending the context becomes key.
</prevsent>
</prevsection>
<citsent citstr=" J07-2004 ">
paraboni et al  (2007) <papid> J07-2004 </papid>present an algorithm for context determination in hierarchically ordered domains, e.g. university campus or document structure.</citsent>
<aftsection>
<nextsent>their approach is mainly targeted at producing textual references to entities in written documents (e.g. figures, tables in book chapters).
</nextsent>
<nextsent>consequently they do not address the challenges that arise in physically and perceptually situateddialogues.
</nextsent>
<nextsent>still, the approach presents number of good contributions towards gre for situated dialogue in large-scale space.
</nextsent>
<nextsent>an appropriate context, as subset of the full domain, is determined through ancestral search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE937">
<title id=" W09-0622.xml">a situated context model for resolution and generation of referring expressions </title>
<section> situated dialogue in large-scale space.  </section>
<citcontext>
<prevsection>
<prevsent>taa1 is formulated to be neutral to the kind of gre algorithm that it is used for.
</prevsent>
<prevsent>it can be used with the original incremental algorithm (dale and reiter, 1995), augmented by recursive call if arelation to another entity is selected as discriminatory feature.
</prevsent>
</prevsection>
<citsent citstr=" E91-1028 ">
it could in principle also be used with the standard approach to gre involving relations (dale and haddock, 1991), <papid> E91-1028 </papid>but we agree with paraboni et al  (2007) <papid> J07-2004 </papid>that the mutually qualified references that it can produce2 are not easily resolvable if they pertain to circumstances wherea confirmatory search is costly (such as in largescale space).</citsent>
<aftsection>
<nextsent>more recent approaches to avoiding infinite loops when using relations in gremake use of graph-based knowledge representation (krahmer et al , 2003; <papid> J03-1003 </papid>croitoru and van deemter, 2007).</nextsent>
<nextsent>taa1 is compatible with these approaches, as well as with the salience based approach of (krahmer and theune, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE940">
<title id=" W09-0622.xml">a situated context model for resolution and generation of referring expressions </title>
<section> situated dialogue in large-scale space.  </section>
<citcontext>
<prevsection>
<prevsent>it can be used with the original incremental algorithm (dale and reiter, 1995), augmented by recursive call if arelation to another entity is selected as discriminatory feature.
</prevsent>
<prevsent>it could in principle also be used with the standard approach to gre involving relations (dale and haddock, 1991), <papid> E91-1028 </papid>but we agree with paraboni et al  (2007) <papid> J07-2004 </papid>that the mutually qualified references that it can produce2 are not easily resolvable if they pertain to circumstances wherea confirmatory search is costly (such as in largescale space).</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
more recent approaches to avoiding infinite loops when using relations in gremake use of graph-based knowledge representation (krahmer et al , 2003; <papid> J03-1003 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>taa1 is compatible with these approaches, as well as with the salience based approach of (krahmer and theune, 2002).
</nextsent>
<nextsent>2an example for such phenomenon is the expression the ball on the table?
</nextsent>
<nextsent>in context with several tables and several balls, but of which only one is on table.
</nextsent>
<nextsent>humans find such res natural and easy to resolve in visual scenes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE941">
<title id=" W08-1904.xml">proposel a human oriented prosody and pos english lexicon for machine learning and nlp </title>
<section> proposel: domain knowledge for.  </section>
<citcontext>
<prevsection>
<prevsent>- has proved to be very effective attribute in both deterministic and probabilistic models (liberman and church, 1992; busser et al  2001) and therefore, default content-word/function-word tag is assigned to each entry in proposel in field (10).
</prevsent>
<prevsent>it is anticipated that further research will suggest modifications to this default status when the cfp attribute interacts with other text-based features.
</prevsent>
</prevsection>
<citsent citstr=" C02-1094 ">
syllable counts - field (7) in proposel - have already been used successfully in phrase break models for english (atterer and klein, 2002).<papid> C02-1094 </papid></citsent>
<aftsection>
<nextsent>however, they assume uniformity in terms of duration of syllables whereas we know that in connected speech, an indefinite number of unstressed syllables are packed into the gap between one stress pulse (mortimer, 1985) and an other, english being stress-timed language.
</nextsent>
<nextsent>a lexical stress pattern, where syllables are weighted 0, 1 or 2, has therefore been included in fields (8) and (14) for entries in proposel be cause of its potential as classificatory feature in the machine learning task of phrase break prediction.
</nextsent>
<nextsent>the thematic programme for pascal 3 in 2008 focuses on approaches to supplementing raw training data (e.g. the speech corpus) with priori knowledge (e.g. the lexicon) to improve performance in machine learning.
</nextsent>
<nextsent>the prosody syntax interface is notoriously complex.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE942">
<title id=" W08-2126.xml">hybrid learning of dependency structures from heterogeneous linguistic resources </title>
<section> syntactic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, the second part can be further divided into four stages: predicate identification (pi), argument identification (ai), argument classification (ac), and predicate classification (pc).
</prevsent>
<prevsent>maximum entropy-based machine learning techniques are used in both components which we will see in detail in the following sections.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
for obtaining syntactic dependencies, we have combined the results of two state-of-the-art dependency parsers: the mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>and the malt parser (nivre et al, 2007).</citsent>
<aftsection>
<nextsent>the mst parser formalizes dependency parsing as searching for maximum spanning trees (msts) in directed graphs.
</nextsent>
<nextsent>a major advantage of their framework is the ability to naturally and efficiently model both projective and non-projective parses.to learn these structures they used online large margin learning that empirically provides state-of the-art performance.
</nextsent>
<nextsent>the malt parser is transition-based incremental dependency parser, which is language-independentand data-driven.
</nextsent>
<nextsent>it contains deterministic algorithm, which can be viewed as variant of the basic shift-reduce algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE943">
<title id=" W08-2126.xml">hybrid learning of dependency structures from heterogeneous linguistic resources </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>it should be noted that the prediction of nominal predicates are generally much more difficult (based on conll 2008 shared task annotation).
</prevsent>
<prevsent>the pi model achieved 96.32 f-score on wsj with verbal predicates, but only 84.74 on nominal ones.argument identification after pi, the arguments to the predicted predicates are identified with the ai component.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
similar to the approach taken in hacioglu (2004)<papid> C04-1186 </papid>we use statistical classifier to select from set of candidate nodes in dependency tree.</citsent>
<aftsection>
<nextsent>however, instead of selecting from set of neighboring nodes from the predicate word 2 , we define the concept of argument path as chain of dependency relations from the predicate to the argument in the dependency tree.
</nextsent>
<nextsent>for instance, an argument path [???
</nextsent>
<nextsent>indicates that if the predicate is syntactically depending as ???
</nextsent>
<nextsent>on node which has ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE948">
<title id=" W08-0901.xml">developing online icall resources for russian </title>
<section> linguistic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the fsa analyzer will provide list of possible analyses (i.e., augmented pos tags) for each input item (ranked, ifneed be).
</prevsent>
<prevsent>we can explore using third-party tagger to narrow down this output list to analyses that make sense in context.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we are considering both the hidden markov model tagger tnt (brants, 2000) <papid> A00-1031 </papid>and the decision tree tagger (schmid, 1997), with parameter files from sharoff et al (2008).</citsent>
<aftsection>
<nextsent>both of these taggers use local context, but, as they provide potentially different types of information, the final system may use both in parallel, weighing the out put of each to the degree which each proves useful in trial runs to make its decision.since pos tagging does not capture every syntactic property that we might need access to, we are not sure how accurate error detection can be.
</nextsent>
<nextsent>thus, to supplement its contextual information, we intend to use shallow syntactic processing methods, perhaps based on small set of constraint grammar rules(cf, e.g., bick, 2004).
</nextsent>
<nextsent>this shallow syntactic recognizer can operate over the string of now-annotated tags to resolve any remaining ambiguities and point out any mismatches between the items (for example, noun-adjective pair where the gender does notmatch), thereby more accurately determining there lations between words.
</nextsent>
<nextsent>we have outlined system for russian icall exercises, the first of its kind for slavic language, and we have specifically delineated the types of errors to which need to be analyzed for such morphologically-rich language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE949">
<title id=" W08-2137.xml">dependency tree based srl with proper pruning and extensive feature engineering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although conll 2008 shared task mainly evaluates joint learning of syntactic and semantic parsing, we focus on dependency tree-based semantic role labeling (srl).
</prevsent>
<prevsent>srl refers to label the semantic roles of predicates (either verbs or nouns) in sentence.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
most of previous srl systems (gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>punyakanok et al , 2005; pradhan ? 2008.</citsent>
<aftsection>
<nextsent>licensed under the creative commons attribution noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>et al , 2004, 2005) work on constituent structure trees and has shown to achieve remarkable results.
</nextsent>
<nextsent>for example, punyakanok et al  (2005) achieved the best performance in the conll 2005 shared task with 79.44 in f-measure on the wsj test set and 77.92 on the combined test set (wsj +brown).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE950">
<title id=" W08-2137.xml">dependency tree based srl with proper pruning and extensive feature engineering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although conll 2008 shared task mainly evaluates joint learning of syntactic and semantic parsing, we focus on dependency tree-based semantic role labeling (srl).
</prevsent>
<prevsent>srl refers to label the semantic roles of predicates (either verbs or nouns) in sentence.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
most of previous srl systems (gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>punyakanok et al , 2005; pradhan ? 2008.</citsent>
<aftsection>
<nextsent>licensed under the creative commons attribution noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>et al , 2004, 2005) work on constituent structure trees and has shown to achieve remarkable results.
</nextsent>
<nextsent>for example, punyakanok et al  (2005) achieved the best performance in the conll 2005 shared task with 79.44 in f-measure on the wsj test set and 77.92 on the combined test set (wsj +brown).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE951">
<title id=" W08-2137.xml">dependency tree based srl with proper pruning and extensive feature engineering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, punyakanok et al  (2005) achieved the best performance in the conll 2005 shared task with 79.44 in f-measure on the wsj test set and 77.92 on the combined test set (wsj +brown).
</prevsent>
<prevsent>with rapid development of dependency parsing in the last few years, more and more researchers turn to dependency tree-based srl with hope to advance srl from viewpoint of dependency parsing.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
hacioglu (2004) <papid> C04-1186 </papid>pioneered this work by formulating srl as classification problem of mapping various dependency relations into semantic roles.</citsent>
<aftsection>
<nextsent>compared with previous researches on constituent structure tree-based srl which adopts constituents as labeling units, dependency tree-based srl adopts dependency relations as labeling units.
</nextsent>
<nextsent>due to the difference between constituent structure trees and dependency trees, their feature spaces are expected to be somewhat different.
</nextsent>
<nextsent>in the conll 2008 shared task, we extend the framework by hacioglu (2004) <papid> C04-1186 </papid>with maximum entropy as our classifier.</nextsent>
<nextsent>for evaluation, we will mainly report our official srl performance using malt parser (nivre and nilsson, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE961">
<title id=" W08-2137.xml">dependency tree based srl with proper pruning and extensive feature engineering </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>this suggests that specific pruning algorithm is necessary for noun predicates to include more ancestor nodes.
</prevsent>
<prevsent>2.3 features.
</prevsent>
</prevsection>
<citsent citstr=" P05-1072 ">
some of the features are borrowed from hacioglu (2004) <papid> C04-1186 </papid>with some additional features motivated by constituent structure tree-based srl (pradhan et al 2005; <papid> P05-1072 </papid>xue and palmer, 2004).</citsent>
<aftsection>
<nextsent>in the following, we explain these features and give examples with regard to the dependency tree as shown in figure 1.
</nextsent>
<nextsent>we take the word evidence in figure 1 as the predicate and the node on?
</nextsent>
<nextsent>as the node on focus.
</nextsent>
<nextsent>the following eight basic features are motivated from constituent structure tree-based srl: 1) predicate: predicate lemma.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE963">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it uses parallel and distributed computing techniques for scala bility.
</prevsent>
<prevsent>we demonstrate that the toolkit achieves state of the art translation performance on the wmt09 french-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
large scale parsing-based statistical machine translation (e.g., chiang (2007), <papid> J07-2003 </papid>quirk et al (2005), <papid> P05-1034 </papid>galley et al (2006), <papid> P06-1121 </papid>and liu et al (2006)) <papid> P06-1077 </papid>has made remarkable progress in the last few years.</citsent>
<aftsection>
<nextsent>however, most of the systems mentioned above employ tailor-made, dedicated software thatis not open source.
</nextsent>
<nextsent>this results in high barrier to entry for other researchers, and makes experiments difficult to duplicate and compare.
</nextsent>
<nextsent>in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</nextsent>
<nextsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE964">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it uses parallel and distributed computing techniques for scala bility.
</prevsent>
<prevsent>we demonstrate that the toolkit achieves state of the art translation performance on the wmt09 french-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
large scale parsing-based statistical machine translation (e.g., chiang (2007), <papid> J07-2003 </papid>quirk et al (2005), <papid> P05-1034 </papid>galley et al (2006), <papid> P06-1121 </papid>and liu et al (2006)) <papid> P06-1077 </papid>has made remarkable progress in the last few years.</citsent>
<aftsection>
<nextsent>however, most of the systems mentioned above employ tailor-made, dedicated software thatis not open source.
</nextsent>
<nextsent>this results in high barrier to entry for other researchers, and makes experiments difficult to duplicate and compare.
</nextsent>
<nextsent>in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</nextsent>
<nextsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE965">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it uses parallel and distributed computing techniques for scala bility.
</prevsent>
<prevsent>we demonstrate that the toolkit achieves state of the art translation performance on the wmt09 french-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
large scale parsing-based statistical machine translation (e.g., chiang (2007), <papid> J07-2003 </papid>quirk et al (2005), <papid> P05-1034 </papid>galley et al (2006), <papid> P06-1121 </papid>and liu et al (2006)) <papid> P06-1077 </papid>has made remarkable progress in the last few years.</citsent>
<aftsection>
<nextsent>however, most of the systems mentioned above employ tailor-made, dedicated software thatis not open source.
</nextsent>
<nextsent>this results in high barrier to entry for other researchers, and makes experiments difficult to duplicate and compare.
</nextsent>
<nextsent>in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</nextsent>
<nextsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE966">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it uses parallel and distributed computing techniques for scala bility.
</prevsent>
<prevsent>we demonstrate that the toolkit achieves state of the art translation performance on the wmt09 french-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
large scale parsing-based statistical machine translation (e.g., chiang (2007), <papid> J07-2003 </papid>quirk et al (2005), <papid> P05-1034 </papid>galley et al (2006), <papid> P06-1121 </papid>and liu et al (2006)) <papid> P06-1077 </papid>has made remarkable progress in the last few years.</citsent>
<aftsection>
<nextsent>however, most of the systems mentioned above employ tailor-made, dedicated software thatis not open source.
</nextsent>
<nextsent>this results in high barrier to entry for other researchers, and makes experiments difficult to duplicate and compare.
</nextsent>
<nextsent>in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</nextsent>
<nextsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE967">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, most of the systems mentioned above employ tailor-made, dedicated software thatis not open source.
</prevsent>
<prevsent>this results in high barrier to entry for other researchers, and makes experiments difficult to duplicate and compare.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</citsent>
<aftsection>
<nextsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</nextsent>
<nextsent>the toolkit also implements suffix-array grammar extraction (lopez, 2007) <papid> D07-1104 </papid>and minimum error rate training (och, 2003)<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE969">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</prevsent>
<prevsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
the toolkit also implements suffix-array grammar extraction (lopez, 2007) <papid> D07-1104 </papid>and minimum error rate training (och, 2003)<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>additionally, parallel and distributed computing techniques are exploited to make it scalable (li and khudanpur, 2008<papid> W08-0402 </papid>b).</nextsent>
<nextsent>we have also made great effort to ensure that our toolkit is easy to use and to extend.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE971">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe joshua, general-purpose open source toolkit for parsing-based machine translation, serving the same role as moses (koehnet al, 2007) <papid> P07-2045 </papid>does for regular phrase-based machine translation.</prevsent>
<prevsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the toolkit also implements suffix-array grammar extraction (lopez, 2007) <papid> D07-1104 </papid>and minimum error rate training (och, 2003)<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>additionally, parallel and distributed computing techniques are exploited to make it scalable (li and khudanpur, 2008<papid> W08-0402 </papid>b).</nextsent>
<nextsent>we have also made great effort to ensure that our toolkit is easy to use and to extend.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE973">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our toolkit is written in java and implements all the essential algorithms described in chiang(2007): <papid> J07-2003 </papid>chart-parsing, n-gram language model integration, beam- and cube-pruning, and k-best ex traction.</prevsent>
<prevsent>the toolkit also implements suffix-array grammar extraction (lopez, 2007) <papid> D07-1104 </papid>and minimum error rate training (och, 2003)<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-0402 ">
additionally, parallel and distributed computing techniques are exploited to make it scalable (li and khudanpur, 2008<papid> W08-0402 </papid>b).</citsent>
<aftsection>
<nextsent>we have also made great effort to ensure that our toolkit is easy to use and to extend.
</nextsent>
<nextsent>the toolkit has been used to translate roughlya million sentences in parallel corpus for large scale discriminative training experiments (li and khudanpur, 2008<papid> W08-0402 </papid>a).</nextsent>
<nextsent>we hope the release of the toolkit will greatly contribute the progress of the syntax-based machine translation research.1</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE977">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> joshua toolkit.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 suffix-array grammar extraction.
</prevsent>
<prevsent>hierarchical phrase-based translation requires atranslation grammar extracted from parallel corpus, where grammar rules include associated feature values.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in real translation tasks, the grammars extracted from large training corpora are often far too large to fit into available memory.in such tasks, feature calculation is also very expensive in terms of time required; huge sets of extracted rules must be sorted in two directions for relative frequency calculation of such features as the translation probability p(f |e) and reverse translation probability p(e|f) (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>since the extraction steps must be re-run if any change is made to the input training data, the time required can be major hindrance to researchers,especially those investigating the effects of tokenization or word segmentation.to alleviate these issues, we extract only subset of all available rules.
</nextsent>
<nextsent>specifically, we follow callison-burch et al (2005; lopez (2007) <papid> D07-1104 </papid>and use source language suffix array to extract only those rules which will actually be used in translating particular set of test sentences.</nextsent>
<nextsent>this results in avastly smaller rule set than techniques which extract all rules from the training set.the current code requires suffix array rule extraction to be run as pre-processing step to extract the rules needed to translate particular testset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE981">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> joshua toolkit.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 decoding algorithms2.
</prevsent>
<prevsent>grammar formalism: our decoder assumes probabilistic synchronous context-free grammar (scfg).
</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
currently, it only handles scfgs of thekind extracted by heiro (chiang, 2007), <papid> J07-2003 </papid>but is easily extensible to more general scfgs (e.g., (gal ley et al, 2006)) <papid> P06-1121 </papid>and closely related formalisms like synchronous tree substitution grammars (eis ner, 2003).<papid> P03-2041 </papid>chart parsing: given source sentence to decode, the decoder generates one-best or k-best translations using cky algorithm.</citsent>
<aftsection>
<nextsent>specifically, the decoding algorithm maintains chart, which contains an array of cells.
</nextsent>
<nextsent>each cell in turn maintains list of proven items.
</nextsent>
<nextsent>the parsing process starts with the axioms, and proceeds by applying the inference rules repeatedly to prove new items until proving goal item.
</nextsent>
<nextsent>whenever the parser proves new item, it adds the item to the appropriate chart cell.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE983">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> joshua toolkit.  </section>
<citcontext>
<prevsection>
<prevsent>pruning: severe pruning is needed in order to make the decoding computationally feasible for scfgs with large target-language vocabularies.in our decoder, we incorporate two pruning tech niques: beam and cube pruning (chiang, 2007).<papid> J07-2003 </papid></prevsent>
<prevsent>hypergraphs and k-best extraction: for eachsource-language sentence, the chart-parsing algorithm produces hypergraph, which represents an exponential set of likely derivation hypotheses.</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
using the k-best extraction algorithm (huang and chiang, 2005), <papid> W05-1506 </papid>we extract the most likely derivations from the hypergraph.</citsent>
<aftsection>
<nextsent>parallel and distributed decoding: we also implement parallel decoding and distributed language model by exploiting multi-core andmulti-processor architectures and distributed computing techniques.
</nextsent>
<nextsent>more details on these two features are provided by li and khudanpur (2008<papid> W08-0402 </papid>b).</nextsent>
<nextsent>2.4 language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE986">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> joshua toolkit.  </section>
<citcontext>
<prevsection>
<prevsent>this java implementation is able to read the standard arpa backoff n-gram models, and thus the decoder can be used independently from the srilm toolkit.3 we also provide native code bridge that allows the decoder to use the srilm toolkit to read and score n-grams.
</prevsent>
<prevsent>this native implementation is more scalable than the basic java lm implementation.
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
we have also implemented bloom filter lm in joshua, following talbot and osborne (2007).<papid> P07-1065 </papid></citsent>
<aftsection>
<nextsent>2.5 minimum error rate training.
</nextsent>
<nextsent>johsuas mert module optimizes parameter weights so as to maximize performance on development set as measuered by an automatic evaluation metric, such as bleu.
</nextsent>
<nextsent>the optimization consists of series of line-optimizations along the dimensions corresponding to the parameters.
</nextsent>
<nextsent>the search across dimension uses the efficient method of och (2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE988">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> wmt-09 translation task results.  </section>
<citcontext>
<prevsection>
<prevsent>this is in-domain data that was gathered from the same news sources as the wmt09 test set.
</prevsent>
<prevsent>3.2 translation scores.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the translation scores for four different systems are reported in table 1.5 baseline: in this system, we use the giza++toolkit (och and ney, 2003), <papid> J03-1002 </papid>suffix-array architecture (lopez, 2007), <papid> D07-1104 </papid>the srilm toolkit (stol cke, 2002), and minimum error rate training (och, 2003)<papid> P03-1021 </papid>to obtain word-alignments, translation model, language models, and the optimal weights for combining these models, respectively.minimum bayes risk rescoring: in this system, we re-ranked the n-best output of our base line system using minimum bayes risk (kumarand byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>we re-score the top 300 translations to minimize expected loss under the bleu metric.deterministic annealing: in this system, instead of using the regular mert (och, 2003)<papid> P03-1021 </papid>whose training objective is to minimize the one best error, we use the deterministic annealing training procedure described in smith and eisner(2006), <papid> P06-2101 </papid>whose objective is to minimize the expected error (together with the entropy regularization technique).</nextsent>
<nextsent>variational decoding: statistical models in machine translation exhibit spurious ambiguity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE992">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> wmt-09 translation task results.  </section>
<citcontext>
<prevsection>
<prevsent>this is in-domain data that was gathered from the same news sources as the wmt09 test set.
</prevsent>
<prevsent>3.2 translation scores.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
the translation scores for four different systems are reported in table 1.5 baseline: in this system, we use the giza++toolkit (och and ney, 2003), <papid> J03-1002 </papid>suffix-array architecture (lopez, 2007), <papid> D07-1104 </papid>the srilm toolkit (stol cke, 2002), and minimum error rate training (och, 2003)<papid> P03-1021 </papid>to obtain word-alignments, translation model, language models, and the optimal weights for combining these models, respectively.minimum bayes risk rescoring: in this system, we re-ranked the n-best output of our base line system using minimum bayes risk (kumarand byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>we re-score the top 300 translations to minimize expected loss under the bleu metric.deterministic annealing: in this system, instead of using the regular mert (och, 2003)<papid> P03-1021 </papid>whose training objective is to minimize the one best error, we use the deterministic annealing training procedure described in smith and eisner(2006), <papid> P06-2101 </papid>whose objective is to minimize the expected error (together with the entropy regularization technique).</nextsent>
<nextsent>variational decoding: statistical models in machine translation exhibit spurious ambiguity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE994">
<title id=" W09-0424.xml">joshua an open source toolkit for parsing based machine translation </title>
<section> wmt-09 translation task results.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 translation scores.
</prevsent>
<prevsent>the translation scores for four different systems are reported in table 1.5 baseline: in this system, we use the giza++toolkit (och and ney, 2003), <papid> J03-1002 </papid>suffix-array architecture (lopez, 2007), <papid> D07-1104 </papid>the srilm toolkit (stol cke, 2002), and minimum error rate training (och, 2003)<papid> P03-1021 </papid>to obtain word-alignments, translation model, language models, and the optimal weights for combining these models, respectively.minimum bayes risk rescoring: in this system, we re-ranked the n-best output of our base line system using minimum bayes risk (kumarand byrne, 2004).<papid> N04-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
we re-score the top 300 translations to minimize expected loss under the bleu metric.deterministic annealing: in this system, instead of using the regular mert (och, 2003)<papid> P03-1021 </papid>whose training objective is to minimize the one best error, we use the deterministic annealing training procedure described in smith and eisner(2006), <papid> P06-2101 </papid>whose objective is to minimize the expected error (together with the entropy regularization technique).</citsent>
<aftsection>
<nextsent>variational decoding: statistical models in machine translation exhibit spurious ambiguity.
</nextsent>
<nextsent>that is, the probability of an output string is split among many distinct derivations (e.g., trees or segmentations).
</nextsent>
<nextsent>in principle, the goodness of string is measured by the total probability of its many derivations.
</nextsent>
<nextsent>however, finding the best string(e.g., during decoding) is then computationally intractable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1002">
<title id=" W08-2231.xml">a resource poor approach for linking ontology classes to wikipedia articles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one method towards sense disambiguation that has been studied is to use different kinds of text overlap: ruiz-casado et al (2005) calculate vector similarity between wikipedia article and wordnet glosses based on term frequencies.
</prevsent>
<prevsent>obviously, such glosses are not available for all languages, domains and applications.
</prevsent>
</prevsection>
<citsent citstr=" D07-1074 ">
wu and weld (2007) and cucerzan (2007) <papid> D07-1074 </papid>calculate the overlap between contexts of named entities and candidate articles from wikipedia, using overlap ratios or similarity scores in vector space model, respectively.</citsent>
<aftsection>
<nextsent>both approaches disambiguate named entities using textual context.
</nextsent>
<nextsent>since our aim is to acquire concept-related text sources, these methods are not applicable.
</nextsent>
<nextsent>a general corpus-based approach has been proposed by reiter and buitelaar (2008): using domain corpus and domain-independent reference corpus, they select the article with the highest domain relevance score among multiple candidates.
</nextsent>
<nextsent>this approach works reasonably well but relies on the availability of domain-specific corpora and fails at selecting the appropriate among multiple in-domain senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1003">
<title id=" W08-2231.xml">a resource poor approach for linking ontology classes to wikipedia articles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this approach works reasonably well but relies on the availability of domain-specific corpora and fails at selecting the appropriate among multiple in-domain senses.
</prevsent>
<prevsent>in contrast, our resource-poor approach does not relyon additional textual resources, as ontologies usually do not contain contexts for classes.
</prevsent>
</prevsection>
<citsent citstr=" N07-1025 ">
1mihalcea (2007) <papid> N07-1025 </papid>shows that wikipedia can indeed be used as sense inventory for sense disambiguation.</citsent>
<aftsection>
<nextsent>a resource-poor approach for linking ontology classes to wikipedia 383
</nextsent>
<nextsent>this section briefly reviews relevant information about wikipedia and describes our method for linking ontology classes to wikipedia articles.
</nextsent>
<nextsent>our algorithm consists of two steps: (i) extracting candidate articles from wikipedia and (ii) selecting the most appropriate one.
</nextsent>
<nextsent>the algorithm is independent of the choice of specific ontology.2 3.1 wikipedia.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1004">
<title id=" W09-0104.xml">computational linguistics and generative linguistics the triumph of hope over experience </title>
<section> hope for the future.  </section>
<citcontext>
<prevsection>
<prevsent>among them are both traditional general linguists like huddleston and people with serious cl experience like abeille?
</prevsent>
<prevsent>and huang.but there is more.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
i have made preliminary analysis of the inventory of syntactic categories used in the tagging for labelling trees in the 18 penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>comparing them to the categories used in cgel.</citsent>
<aftsection>
<nextsent>i would describe the fit as not perfect, but within negotiating range.
</nextsent>
<nextsent>in some ways the fit is remarkable, given the complete independence of the two projects (the treebank under mitch marcus in philadelphia was largely complete by 1992, when the cgel project under the direction of rodney huddleston in australia was only just getting up to speed, but huddleston and marcus did not know about each others work).
</nextsent>
<nextsent>the biggest discrepancy in categorization is in the problematic area of prepositions, adverbs, and subordinating conjunctions, where the treebank has remained much too close to the confused older tradition (where many prepositions are claimed to have second lives as adverbs and quite few arealso included on the list of subordinating conjunctions, so that word like since has one meaning but three grammatical categories).
</nextsent>
<nextsent>the heartof the problem is that the sage counsel of jespersen (1924), of jespersen (8790) and the cogent arguments of emonds (1972) were not taken under consideration by the devi sers of the treebanks tagging categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1005">
<title id=" W09-0104.xml">computational linguistics and generative linguistics the triumph of hope over experience </title>
<section> hope for the future.  </section>
<citcontext>
<prevsection>
<prevsent>here will be brief, and things will get slightly technical.
</prevsent>
<prevsent>the question naturally arises of how one might formalize cgel to get it in form where it was explicit enough foruse as database that natural language processing systems could in principle make use of.
</prevsent>
</prevsection>
<citsent citstr=" E93-1004 ">
james rogers and have recently considered that question (pullum and rogers, 2008) within the context of model-theoretic syntax, line of work that first began to receive sophisticated formulations here at the eacl in various papers of the early 1990s (e.g. blackburn et al (1993), <papid> E93-1004 </papid>kracht (1993), <papid> E93-1029 </papid>blackburn &amp; gardent (1995); <papid> E95-1006 </papid>see pullum (2007) for brief historical survey, and pullum &amp; scholz(2001) for deeper treatment of relevant theoretical issues).one thing that might appear to be stumbling block to formalizing cgel, and an obstacle to the relationship with treebanks as well, is that strictly speaking cgels assumed syntactic representations are not (or not all) trees.</citsent>
<aftsection>
<nextsent>they are graphs that depart from being ordinary constituent-structure trees in at least two respects.first, they are annotated not just with categories labelling the nodes, but also with syntactic functions (grammatical relations like subject-of, determiner-of, head-of, complement-of, etc.) that are perhaps best conceptualized as labelling the edges of the graph (the lines between the nodes in the diagrams).second, and perhaps more seriously, there is occasional downward convergence of branches: it is permitted forgiven constituent, under certain conditions, to bear two different grammatical relations to two different super ordinate nodes.
</nextsent>
<nextsent>(a determinative like some, for example, may be both the determiner of an np and the head of the nominal that is the phrasal head of that np.)
</nextsent>
<nextsent>often (as in hpsg work) the introduction of re-entrancy had dramatic consequences for key properties like decidability of satisfiability for descriptions, oreven for model-checking.
</nextsent>
<nextsent>(i take it that the formal issues around hpsg are very well known to the eacl community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1006">
<title id=" W09-0104.xml">computational linguistics and generative linguistics the triumph of hope over experience </title>
<section> hope for the future.  </section>
<citcontext>
<prevsection>
<prevsent>here will be brief, and things will get slightly technical.
</prevsent>
<prevsent>the question naturally arises of how one might formalize cgel to get it in form where it was explicit enough foruse as database that natural language processing systems could in principle make use of.
</prevsent>
</prevsection>
<citsent citstr=" E93-1029 ">
james rogers and have recently considered that question (pullum and rogers, 2008) within the context of model-theoretic syntax, line of work that first began to receive sophisticated formulations here at the eacl in various papers of the early 1990s (e.g. blackburn et al (1993), <papid> E93-1004 </papid>kracht (1993), <papid> E93-1029 </papid>blackburn &amp; gardent (1995); <papid> E95-1006 </papid>see pullum (2007) for brief historical survey, and pullum &amp; scholz(2001) for deeper treatment of relevant theoretical issues).one thing that might appear to be stumbling block to formalizing cgel, and an obstacle to the relationship with treebanks as well, is that strictly speaking cgels assumed syntactic representations are not (or not all) trees.</citsent>
<aftsection>
<nextsent>they are graphs that depart from being ordinary constituent-structure trees in at least two respects.first, they are annotated not just with categories labelling the nodes, but also with syntactic functions (grammatical relations like subject-of, determiner-of, head-of, complement-of, etc.) that are perhaps best conceptualized as labelling the edges of the graph (the lines between the nodes in the diagrams).second, and perhaps more seriously, there is occasional downward convergence of branches: it is permitted forgiven constituent, under certain conditions, to bear two different grammatical relations to two different super ordinate nodes.
</nextsent>
<nextsent>(a determinative like some, for example, may be both the determiner of an np and the head of the nominal that is the phrasal head of that np.)
</nextsent>
<nextsent>often (as in hpsg work) the introduction of re-entrancy had dramatic consequences for key properties like decidability of satisfiability for descriptions, oreven for model-checking.
</nextsent>
<nextsent>(i take it that the formal issues around hpsg are very well known to the eacl community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1007">
<title id=" W09-0104.xml">computational linguistics and generative linguistics the triumph of hope over experience </title>
<section> hope for the future.  </section>
<citcontext>
<prevsection>
<prevsent>here will be brief, and things will get slightly technical.
</prevsent>
<prevsent>the question naturally arises of how one might formalize cgel to get it in form where it was explicit enough foruse as database that natural language processing systems could in principle make use of.
</prevsent>
</prevsection>
<citsent citstr=" E95-1006 ">
james rogers and have recently considered that question (pullum and rogers, 2008) within the context of model-theoretic syntax, line of work that first began to receive sophisticated formulations here at the eacl in various papers of the early 1990s (e.g. blackburn et al (1993), <papid> E93-1004 </papid>kracht (1993), <papid> E93-1029 </papid>blackburn &amp; gardent (1995); <papid> E95-1006 </papid>see pullum (2007) for brief historical survey, and pullum &amp; scholz(2001) for deeper treatment of relevant theoretical issues).one thing that might appear to be stumbling block to formalizing cgel, and an obstacle to the relationship with treebanks as well, is that strictly speaking cgels assumed syntactic representations are not (or not all) trees.</citsent>
<aftsection>
<nextsent>they are graphs that depart from being ordinary constituent-structure trees in at least two respects.first, they are annotated not just with categories labelling the nodes, but also with syntactic functions (grammatical relations like subject-of, determiner-of, head-of, complement-of, etc.) that are perhaps best conceptualized as labelling the edges of the graph (the lines between the nodes in the diagrams).second, and perhaps more seriously, there is occasional downward convergence of branches: it is permitted forgiven constituent, under certain conditions, to bear two different grammatical relations to two different super ordinate nodes.
</nextsent>
<nextsent>(a determinative like some, for example, may be both the determiner of an np and the head of the nominal that is the phrasal head of that np.)
</nextsent>
<nextsent>often (as in hpsg work) the introduction of re-entrancy had dramatic consequences for key properties like decidability of satisfiability for descriptions, oreven for model-checking.
</nextsent>
<nextsent>(i take it that the formal issues around hpsg are very well known to the eacl community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1008">
<title id=" W09-0502.xml">on the segmentation of requests in spoken language </title>
<section> towards definition of requests?.  </section>
<citcontext>
<prevsection>
<prevsent>2000) probabilistic approaches, on the other hand, give an increasingly accurate surface description of empirical dialogues as succes sions of normalized moves?
</prevsent>
<prevsent>or dialogue acts?
</prevsent>
</prevsection>
<citsent citstr=" J97-1002 ">
(carletta et al, 1997; <papid> J97-1002 </papid>stolcke et al, 2000); but the normalization of sequences as distinct utterances?</citsent>
<aftsection>
<nextsent>also encourages an atomistic, one segment, one act?
</nextsent>
<nextsent>vision.6yet, as far as semantic-pragmatic representation is concerned, it is artificial and problematic to imagine that request corresponds to block?
</nextsent>
<nextsent>of signifier (2.1) and to block?
</nextsent>
<nextsent>of meaning (2.2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1012">
<title id=" W08-2226.xml">the textcap semantic interpreter </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of applications depend on explicitly represented knowledge to perform basic tasks or add customization to existing tasks.
</prevsent>
<prevsent>improving the quantity and quality of the knowledge contained in knowledge bases could lead to the improved performance of many applications that depend on knowledge and inference such as:?
</prevsent>
</prevsection>
<citsent citstr=" J97-1004 ">
generating scientific or educational explanations of natural or mechanical systems and phenomena (lester and porter, 1997), ? <papid> J97-1004 </papid>question answering systems (clark et al, 2001) that use reasoning to solve problems rather than looking up answers, ? multimodal information presentation systems that depend on specific real world knowledge in order to describe or refer to it for audiences (callaway et al, 2005; stock et al, 2007).</citsent>
<aftsection>
<nextsent>these systems have typically relied on hand-built and domain specific knowledge bases requiring years of effort to produce.
</nextsent>
<nextsent>the need to speed up this process as well as make the resulting representations more consistent are well-known problems that have yielded number of potential solutions (blythe et al, 2001; reiter et al, 2003; carenini et al, 2005; barker et al, 2007), but large scale, domain independent, and fully automatic knowledge acquisition on unrestricted text is still in its infancy.
</nextsent>
<nextsent>over the last decade research in applied computational linguistics has extended the various components necessary for semantic parsing, but have tended to focus on increasing the measurable performance of individual subtask in isolation (e.g., parsing, anaphora resolution, semantic role labelling, and word sense disambiguation) rather than on an entire end-to-end system.
</nextsent>
<nextsent>meanwhile, theoretical cl research has examined issues such as under specification, scoping and reference resolution in discourse contexts, but has set aside issues such as large-scale robustness, ontology integration and evaluation which are vital for applied uses of semantic parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1013">
<title id=" W08-2226.xml">the textcap semantic interpreter </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>textcap parses document into penn treebank form and then traverses each syntactic parse tree performing series of step-by-step tasks such as discourse parsing, clause separation, word sense disambiguation, anaphora resolution and semantic role labelling.
</prevsent>
<prevsent>ad hoc rules then create set of triples from the resulting semantically-enhanced parse tree.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
textcap first uses the domain-independent charniak parser (charniak, 2000) <papid> A00-2018 </papid>to convert sentences in the source document into sequence of syntactic parses.</citsent>
<aftsection>
<nextsent>it then applies syntax-based discourse parsing rules (such as soricut and marcu (2003)) <papid> N03-1030 </papid>to reduce coordinate, subordinate, and relative clauses into co indexed, simpler sentence parses headed by single verbal relations.</nextsent>
<nextsent>it then marks for grammatical roles (subject, object, etc.) and syntactic features (e.g., passivity) before using simple anaphora resolution algorithm based on those features and word sense disambiguation algorithm grounded in wordnet (fellbaum, 1998) senses that helps determine additional features such as animacy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1014">
<title id=" W08-2226.xml">the textcap semantic interpreter </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>ad hoc rules then create set of triples from the resulting semantically-enhanced parse tree.
</prevsent>
<prevsent>textcap first uses the domain-independent charniak parser (charniak, 2000) <papid> A00-2018 </papid>to convert sentences in the source document into sequence of syntactic parses.</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
it then applies syntax-based discourse parsing rules (such as soricut and marcu (2003)) <papid> N03-1030 </papid>to reduce coordinate, subordinate, and relative clauses into co indexed, simpler sentence parses headed by single verbal relations.</citsent>
<aftsection>
<nextsent>it then marks for grammatical roles (subject, object, etc.) and syntactic features (e.g., passivity) before using simple anaphora resolution algorithm based on those features and word sense disambiguation algorithm grounded in wordnet (fellbaum, 1998) senses that helps determine additional features such as animacy.
</nextsent>
<nextsent>a two-passmethod is applied where first monosemous words are assigned senses, and then remaining senses are selected together with verb types (textcap uses ad hoc rules rather than current verb taxonomies like framenet).
</nextsent>
<nextsent>selectional restrictions from the verb type then allows for labelling of peripheral grammatical roles as semantic roles.
</nextsent>
<nextsent>finally, entities representing specific objects are marked with onto logical relations and discourse relations are realized between individual verbal relations.the end product of textcap is thus list of co indexed semantic triples representing the explicitly recoverable semantic content of the input text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1016">
<title id=" W08-2226.xml">the textcap semantic interpreter </title>
<section> text processing components.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, the introduction of large-scale lexical and syntactic resources like the penn treebank (marcus et al, 1993) have led to highly accurate, domain independent parsers (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></prevsent>
<prevsent>wide-coverage anaphora resolution systems process references across multiple sentences, and recent work on anaphora resolution by poesio and kabadjov (2004) describes itself as the first such system which can be used off-the-shelf.</prevsent>
</prevsection>
<citsent citstr=" P05-1050 ">
word sense disambiguation (gliozzo et al, 2005), <papid> P05-1050 </papid>often based on term frequency analyses of large annotated corpora, can help localize search in particular area of knowledge base to find the most related concepts and instances.</citsent>
<aftsection>
<nextsent>semantic role label ers (gildea and jurafsky, 2002; <papid> J02-3001 </papid>yeh et al, 2006) annotate what role each entity has in relation to its local man verb, and can provide additional clues for disambiguating words and locating them in an onto logical space.</nextsent>
<nextsent>in addition to lexical and semantic tasks, multi-sentence linguistic analysis such as discourse segmentation and parsing is needed to semantically label the roles of verb phrases in relation to one other.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1017">
<title id=" W08-2226.xml">the textcap semantic interpreter </title>
<section> text processing components.  </section>
<citcontext>
<prevsection>
<prevsent>wide-coverage anaphora resolution systems process references across multiple sentences, and recent work on anaphora resolution by poesio and kabadjov (2004) describes itself as the first such system which can be used off-the-shelf.
</prevsent>
<prevsent>word sense disambiguation (gliozzo et al, 2005), <papid> P05-1050 </papid>often based on term frequency analyses of large annotated corpora, can help localize search in particular area of knowledge base to find the most related concepts and instances.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
semantic role label ers (gildea and jurafsky, 2002; <papid> J02-3001 </papid>yeh et al, 2006) annotate what role each entity has in relation to its local man verb, and can provide additional clues for disambiguating words and locating them in an onto logical space.</citsent>
<aftsection>
<nextsent>in addition to lexical and semantic tasks, multi-sentence linguistic analysis such as discourse segmentation and parsing is needed to semantically label the roles of verb phrases in relation to one other.
</nextsent>
<nextsent>soricut and marcu (2003) <papid> N03-1030 </papid>presented statistical system that automatically produces an analysis of the rhetorical structure that holds between sets of sentences or clauses at the paragraph level.</nextsent>
<nextsent>330 callaway.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1020">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>within the field of text-to-text generation, the sentence compression task can be defined as follows: given sentence s, consisting of words w1w2...wn, what is subset of the words of s, such that it is grammatical and preserves essential information from s?
</prevsent>
<prevsent>there are many applications which would benefit from robust compression system, such as subtitle generation, compression for mobile devices with limited screen size, or news digests.
</prevsent>
</prevsection>
<citsent citstr=" P05-1036 ">
given that to date most text and speech summarization systems are extractive, sentence compression techniques are common way to deal with redundancy in their output.in recent years, number of approaches to sentence compression have been developed (jing, 2001; knight &amp; marcu, 2002; gagnon &amp; da sylva, 2005; turner &amp; charniak, 2005; <papid> P05-1036 </papid>clarke &amp; lapata, 2008, inter alia).</citsent>
<aftsection>
<nextsent>many explicitly relyon language model, usually trigram model, to produce grammatical output (knight &amp; marcu, 2002; hori &amp; furui, 2004; turner &amp; charniak, 2005; <papid> P05-1036 </papid>galley &amp; mckeown, 2007).<papid> N07-1023 </papid></nextsent>
<nextsent>testing the grammaticality of the output with language model is justified when working with language with rigid word order like english, and all but one approach mentioned have been applied to english data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1026">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are many applications which would benefit from robust compression system, such as subtitle generation, compression for mobile devices with limited screen size, or news digests.
</prevsent>
<prevsent>given that to date most text and speech summarization systems are extractive, sentence compression techniques are common way to deal with redundancy in their output.in recent years, number of approaches to sentence compression have been developed (jing, 2001; knight &amp; marcu, 2002; gagnon &amp; da sylva, 2005; turner &amp; charniak, 2005; <papid> P05-1036 </papid>clarke &amp; lapata, 2008, inter alia).</prevsent>
</prevsection>
<citsent citstr=" N07-1023 ">
many explicitly relyon language model, usually trigram model, to produce grammatical output (knight &amp; marcu, 2002; hori &amp; furui, 2004; turner &amp; charniak, 2005; <papid> P05-1036 </papid>galley &amp; mckeown, 2007).<papid> N07-1023 </papid></citsent>
<aftsection>
<nextsent>testing the grammaticality of the output with language model is justified when working with language with rigid word order like english, and all but one approach mentioned have been applied to english data.
</nextsent>
<nextsent>however, compressing sentences in languages with less rigid word order needs deeper analysis to test grammaticality.
</nextsent>
<nextsent>and even for languages with rigid word order the trigram model ignores the structure of the sentence and therefore may significantly distort the meaning of the source sentence.
</nextsent>
<nextsent>approaches going beyond the word level either require comprehensive lexicon (jing, 2001), or manually devised rules (gagnon&amp; da sylva, 2005; clarke &amp; lapata, 2008) to determine prunable constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1031">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gagnon &da; sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions.
</prevsent>
<prevsent>apparently, this does not guarantee grammaticality in all cases.
</prevsent>
</prevsection>
<citsent citstr=" N03-1026 ">
it may also eliminate important information from the tree.most approaches are supervised and require training data to learn which words or constituents can be dropped from sentence (riezler et al, 2003; <papid> N03-1026 </papid>mcdonald, 2006).<papid> E06-1038 </papid></citsent>
<aftsection>
<nextsent>however, it is difficult to obtain training data.
</nextsent>
<nextsent>still, there are few unsupervised methods.
</nextsent>
<nextsent>for example, hori &amp; furui (2004) introducea scoring function which relies on such information sources as word significance score and language model.
</nextsent>
<nextsent>a compression of given length which maximizes the scoring function is then found with dynamic programming.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1032">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gagnon &da; sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions.
</prevsent>
<prevsent>apparently, this does not guarantee grammaticality in all cases.
</prevsent>
</prevsection>
<citsent citstr=" E06-1038 ">
it may also eliminate important information from the tree.most approaches are supervised and require training data to learn which words or constituents can be dropped from sentence (riezler et al, 2003; <papid> N03-1026 </papid>mcdonald, 2006).<papid> E06-1038 </papid></citsent>
<aftsection>
<nextsent>however, it is difficult to obtain training data.
</nextsent>
<nextsent>still, there are few unsupervised methods.
</nextsent>
<nextsent>for example, hori &amp; furui (2004) introducea scoring function which relies on such information sources as word significance score and language model.
</nextsent>
<nextsent>a compression of given length which maximizes the scoring function is then found with dynamic programming.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1033">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> dependency based compression.  </section>
<citcontext>
<prevsection>
<prevsent>one of the rules of german grammar states that in the main clause the inflected part of the verb occupies the second position, the first position being occupied by exactly one constituent.
</prevsent>
<prevsent>therefore, if the sentence initial position in source sentence is occupied by constituent which got pruned off as result of compression, the verb becomes the first element of the sentence which results in an undesirable output.
</prevsent>
</prevsection>
<citsent citstr=" C04-1097 ">
there are linearization methods developed for german which find an optimal word order for sentence (ringger et al, 2004; <papid> C04-1097 </papid>filippova &amp; strube, 2007).<papid> P07-1041 </papid></citsent>
<aftsection>
<nextsent>we use our recent method to linearize compressed trees.
</nextsent>
<nextsent>we apply our method to sentences from two corpora in english and german.
</nextsent>
<nextsent>these are presented below.
</nextsent>
<nextsent>english compression corpus: the english datawe use is document-based compression corpus from the british national corpus and american news text corpus which consists of 82 news stories3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1034">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> dependency based compression.  </section>
<citcontext>
<prevsection>
<prevsent>one of the rules of german grammar states that in the main clause the inflected part of the verb occupies the second position, the first position being occupied by exactly one constituent.
</prevsent>
<prevsent>therefore, if the sentence initial position in source sentence is occupied by constituent which got pruned off as result of compression, the verb becomes the first element of the sentence which results in an undesirable output.
</prevsent>
</prevsection>
<citsent citstr=" P07-1041 ">
there are linearization methods developed for german which find an optimal word order for sentence (ringger et al, 2004; <papid> C04-1097 </papid>filippova &amp; strube, 2007).<papid> P07-1041 </papid></citsent>
<aftsection>
<nextsent>we use our recent method to linearize compressed trees.
</nextsent>
<nextsent>we apply our method to sentences from two corpora in english and german.
</nextsent>
<nextsent>these are presented below.
</nextsent>
<nextsent>english compression corpus: the english datawe use is document-based compression corpus from the british national corpus and american news text corpus which consists of 82 news stories3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1035">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> corpora and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>these are presented below.
</prevsent>
<prevsent>english compression corpus: the english datawe use is document-based compression corpus from the british national corpus and american news text corpus which consists of 82 news stories3.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
we parsed the corpus withrasp (briscoe et al, 2006) <papid> P06-4020 </papid>and with the stanford pcfg parser (klein &amp; manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>the output of the former is set of dependency relations whereas the latter provides an option for converting the output into dependency format (de marneffe et al, 2006) which we use.tuba-d/z: the german corpus we use is collection of 1,000 newspaper articles (telljohannet al, 2003)4.
</nextsent>
<nextsent>sentence boundaries, morphology, dependency structure and anaphoric relations are manually annotated in this corpus.
</nextsent>
<nextsent>rasp has been used by clarke &amp; lapata (2008) whose state of the art results we compare with ours.
</nextsent>
<nextsent>we use not only rasp but also the stanford parser for several reasons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1036">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> corpora and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>these are presented below.
</prevsent>
<prevsent>english compression corpus: the english datawe use is document-based compression corpus from the british national corpus and american news text corpus which consists of 82 news stories3.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we parsed the corpus withrasp (briscoe et al, 2006) <papid> P06-4020 </papid>and with the stanford pcfg parser (klein &amp; manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>the output of the former is set of dependency relations whereas the latter provides an option for converting the output into dependency format (de marneffe et al, 2006) which we use.tuba-d/z: the german corpus we use is collection of 1,000 newspaper articles (telljohannet al, 2003)4.
</nextsent>
<nextsent>sentence boundaries, morphology, dependency structure and anaphoric relations are manually annotated in this corpus.
</nextsent>
<nextsent>rasp has been used by clarke &amp; lapata (2008) whose state of the art results we compare with ours.
</nextsent>
<nextsent>we use not only rasp but also the stanford parser for several reasons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1037">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> corpora and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>the latter number is comparable to the size of the dataset we use to compute the probabilities for german.
</prevsent>
<prevsent>there, we use corpus of about 4,000 articles from the german wikipedia to calculate conditional probabilities and significance scores.
</prevsent>
</prevsection>
<citsent citstr=" P06-1041 ">
the corpus is parsed with the highly accurate cdg parser (foth &amp; menzel, 2006) <papid> P06-1041 </papid>and has the same dependency format as tuba-d/z (versley, 2005).although all corpora are annotated with dependency relations, there are considerable differences between the annotation of the english and german data sets.</citsent>
<aftsection>
<nextsent>the phrase to dependency structure conversion done by the stanford parser makes these mantic head of the constituent its syntactic head.
</nextsent>
<nextsent>for example, in the sentence he is right it is the adjective right which is the root of the tree.
</nextsent>
<nextsent>unlike that, sentences from the german corpora always have verb as the root.
</nextsent>
<nextsent>to unify the formats, we write set of rules to make the verb the root of the tree in all cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1039">
<title id=" W08-1105.xml">dependency tree based sentence compression </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to assess the performance of the method on the english data, we calculate the fmeasure on grammatical relations.
</prevsent>
<prevsent>following riezler et al (2003), <papid> N03-1026 </papid>we calculate average precision and recall as the amount of grammatical relations shared between the output of our system and the gold stan 29dard variant divided over the total number of relations in the output and in the human-generated compression respectively.</prevsent>
</prevsection>
<citsent citstr=" P06-1048 ">
according to clarke &amp; lapata (2006), <papid> P06-1048 </papid>this measure reliably correlates with human judgements.</citsent>
<aftsection>
<nextsent>the results of our evaluation as well asthe state of the art results reported by clarke &amp; lap ata (2008) (lm+sig+constr), whose system uses language model scoring (lm), word significance score (sig), and linguistic constraints (constr), are presented in table 3.
</nextsent>
<nextsent>the f-measure reported by clarke &amp; lapata (2008) is calculated with rasp which their system builds upon.
</nextsent>
<nextsent>for our system we present the results obtained on the data parsed with rasp as well as with the stanford parser (sp).
</nextsent>
<nextsent>inboth cases the f-measure is found with rasp in order to allow for fair comparison between the three systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1040">
<title id=" W09-1217.xml">a joint syntactic and semantic dependency parsing system based on maximum entropy models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for semantic parsing and predicate classifying, wefocus on finding optimized features on multiple languages.
</prevsent>
<prevsent>the average macro f1 score of our system is 73.97 for joint task in closed challenge.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
the task for conll-2009 is an extension of theconll-2008 shared task to multiple languages: english (surdeanu et al, 2008), <papid> W08-2121 </papid>catalan plus spanish (mariona taule?</citsent>
<aftsection>
<nextsent>et al, 2008), chinese (martha palmer et al, 2009), czech (jan hajic?
</nextsent>
<nextsent>et al, 2006), german (aljoscha burchardt et al, 2006) and japanese (daisuke kawahara et al, 2002).
</nextsent>
<nextsent>compared to the conll-2008 shared task, the predicates are given for us in semantic dependencies task.
</nextsent>
<nextsent>therefore, we have only need to label the semantic roles of nouns and verbs, and the frames of predi cates.in this paper, joint syntactic and semantic dependency parsing system submitted to the conll2009 shared task is presented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1041">
<title id=" W09-1217.xml">a joint syntactic and semantic dependency parsing system based on maximum entropy models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>features of different types are extracted for each predicate, and an optimized combination of them is adopted in our final system.
</prevsent>
<prevsent>table 1 lists all features.
</prevsent>
</prevsection>
<citsent citstr=" W08-2130 ">
1-20 are the features used in lis system (lu li et al, 2008), <papid> W08-2130 </papid>no features no features 1 w0 20 lemma 2 p0 21 deprel 3 p1 22 chd pos 4 p1 23 chd pos 5 p1p0 24 chd rel 6 p0p1 25 chd rel 7 p2p0 26 sib rel 8 p0p2 27 sib rel 9 p3p0 28 sib pos 10 p0p3 29 sib pos 11 p1p0p1 30 verb 12 w0p0 31 4+11 13 w0p1p0 32 in degree 14 w0p0p1 33 out degree 15 w0p2p0 34 degree 16 w0p0p2 35 arg in 17 w0p3p0 36 arg out 18 w0p0p3 37 arg degree 19 w0p1p0p1 38 span table 1: features for predicate classification.and 21-31 are part of the optimized features presented inches system (wanxiang che et al, 2008)in table 1, w? denotes the word and p? denotes pos of the words.</citsent>
<aftsection>
<nextsent>features in the form ofpart1 part2 denote the part2 of the part1, while features in the form of part1+part2 denote the combination of the part1 and part2.
</nextsent>
<nextsent>chd?
</nextsent>
<nextsent>and sib?
</nextsent>
<nextsent>denote sequence of the child and the sibling words respectively, rel?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1044">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kubler et al.
</prevsent>
<prevsent>(2006) point out three grammatical features that could make parsing of german more difficult: finite verb placement, flexible phrase ordering and discontinuous constituents.
</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
earlier studies by dubey and keller (2003) <papid> P03-1013 </papid>and dubey (2005) <papid> P05-1039 </papid>using the negra treebank (skut et al, 1997) <papid> A97-1014 </papid>reports that lexicalization of pcfgs decrease the parsing accuracy when parsing negras flat constituent structures.</citsent>
<aftsection>
<nextsent>however, kubler et al (2006) present comparative study that suggests that it is not harder to parse german than for example english.
</nextsent>
<nextsent>by contrast, rehbein andvan genabith (2007) <papid> D07-1066 </papid>study different parser evaluation metrics by simulating parser errors on two german treebanks (with different treebank annotation schemes) and they claim that the question whether german is harder to parse than english is still unde cided.</nextsent>
<nextsent>this paper does not try to answer the question above, but presents new way of parsing constituent structures that can output the whole structure withall grammatical functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1045">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kubler et al.
</prevsent>
<prevsent>(2006) point out three grammatical features that could make parsing of german more difficult: finite verb placement, flexible phrase ordering and discontinuous constituents.
</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
earlier studies by dubey and keller (2003) <papid> P03-1013 </papid>and dubey (2005) <papid> P05-1039 </papid>using the negra treebank (skut et al, 1997) <papid> A97-1014 </papid>reports that lexicalization of pcfgs decrease the parsing accuracy when parsing negras flat constituent structures.</citsent>
<aftsection>
<nextsent>however, kubler et al (2006) present comparative study that suggests that it is not harder to parse german than for example english.
</nextsent>
<nextsent>by contrast, rehbein andvan genabith (2007) <papid> D07-1066 </papid>study different parser evaluation metrics by simulating parser errors on two german treebanks (with different treebank annotation schemes) and they claim that the question whether german is harder to parse than english is still unde cided.</nextsent>
<nextsent>this paper does not try to answer the question above, but presents new way of parsing constituent structures that can output the whole structure withall grammatical functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1046">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>kubler et al.
</prevsent>
<prevsent>(2006) point out three grammatical features that could make parsing of german more difficult: finite verb placement, flexible phrase ordering and discontinuous constituents.
</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
earlier studies by dubey and keller (2003) <papid> P03-1013 </papid>and dubey (2005) <papid> P05-1039 </papid>using the negra treebank (skut et al, 1997) <papid> A97-1014 </papid>reports that lexicalization of pcfgs decrease the parsing accuracy when parsing negras flat constituent structures.</citsent>
<aftsection>
<nextsent>however, kubler et al (2006) present comparative study that suggests that it is not harder to parse german than for example english.
</nextsent>
<nextsent>by contrast, rehbein andvan genabith (2007) <papid> D07-1066 </papid>study different parser evaluation metrics by simulating parser errors on two german treebanks (with different treebank annotation schemes) and they claim that the question whether german is harder to parse than english is still unde cided.</nextsent>
<nextsent>this paper does not try to answer the question above, but presents new way of parsing constituent structures that can output the whole structure withall grammatical functions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1047">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>earlier studies by dubey and keller (2003) <papid> P03-1013 </papid>and dubey (2005) <papid> P05-1039 </papid>using the negra treebank (skut et al, 1997) <papid> A97-1014 </papid>reports that lexicalization of pcfgs decrease the parsing accuracy when parsing negras flat constituent structures.</prevsent>
<prevsent>however, kubler et al (2006) present comparative study that suggests that it is not harder to parse german than for example english.</prevsent>
</prevsection>
<citsent citstr=" D07-1066 ">
by contrast, rehbein andvan genabith (2007) <papid> D07-1066 </papid>study different parser evaluation metrics by simulating parser errors on two german treebanks (with different treebank annotation schemes) and they claim that the question whether german is harder to parse than english is still unde cided.</citsent>
<aftsection>
<nextsent>this paper does not try to answer the question above, but presents new way of parsing constituent structures that can output the whole structure withall grammatical functions.
</nextsent>
<nextsent>the shared task on parsing german was to parse both the constituency version and the dependency version of the two german treebanks: tiger (brants et al, 2002) and tuba-d/z (telljohann et al, 2005).
</nextsent>
<nextsent>we present adependency-driven parser that parses both dependency structures and constituent structures using an extended version of malt parser 1.0.1 the focus of this paper is how malt parser parses the constituent structures with dependency-based algorithm.
</nextsent>
<nextsent>this paper is structured as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1048">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> malt parser.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 presents the experimental evaluation and discusses the results.
</prevsent>
<prevsent>finally section 6 concludes.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
malt parser is transition-based parsing system which was one of the top performing systems on multilingual dependency parsing in the conll 2006 shared task (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2006) <papid> W06-2933 </papid>and the conll shared task 2007 (nivre et al, 2007; <papid> D07-1096 </papid>hallet al, 2007).<papid> D07-1097 </papid></citsent>
<aftsection>
<nextsent>the basic idea of malt parser is to derive dependency graphs using agreedy parsing algorithm that approximates glob 1maltparser is distributed with an open-source license and can be downloaded free of charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ 47ally optimal solution by making sequence of locally optimal choices.
</nextsent>
<nextsent>the system is equipped with several parsing algorithms, but we have chosen to only optimize nivres parsing algorithm for both the dependency track and the constituency track.
</nextsent>
<nextsent>nivres algorithm is deterministic algorithm for building labeled projective dependency structures in linear time (nivre, 2006).
</nextsent>
<nextsent>there are two essential parameters that can be varied for this algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1049">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> malt parser.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 presents the experimental evaluation and discusses the results.
</prevsent>
<prevsent>finally section 6 concludes.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
malt parser is transition-based parsing system which was one of the top performing systems on multilingual dependency parsing in the conll 2006 shared task (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2006) <papid> W06-2933 </papid>and the conll shared task 2007 (nivre et al, 2007; <papid> D07-1096 </papid>hallet al, 2007).<papid> D07-1097 </papid></citsent>
<aftsection>
<nextsent>the basic idea of malt parser is to derive dependency graphs using agreedy parsing algorithm that approximates glob 1maltparser is distributed with an open-source license and can be downloaded free of charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ 47ally optimal solution by making sequence of locally optimal choices.
</nextsent>
<nextsent>the system is equipped with several parsing algorithms, but we have chosen to only optimize nivres parsing algorithm for both the dependency track and the constituency track.
</nextsent>
<nextsent>nivres algorithm is deterministic algorithm for building labeled projective dependency structures in linear time (nivre, 2006).
</nextsent>
<nextsent>there are two essential parameters that can be varied for this algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1050">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> malt parser.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 presents the experimental evaluation and discusses the results.
</prevsent>
<prevsent>finally section 6 concludes.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
malt parser is transition-based parsing system which was one of the top performing systems on multilingual dependency parsing in the conll 2006 shared task (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2006) <papid> W06-2933 </papid>and the conll shared task 2007 (nivre et al, 2007; <papid> D07-1096 </papid>hallet al, 2007).<papid> D07-1097 </papid></citsent>
<aftsection>
<nextsent>the basic idea of malt parser is to derive dependency graphs using agreedy parsing algorithm that approximates glob 1maltparser is distributed with an open-source license and can be downloaded free of charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ 47ally optimal solution by making sequence of locally optimal choices.
</nextsent>
<nextsent>the system is equipped with several parsing algorithms, but we have chosen to only optimize nivres parsing algorithm for both the dependency track and the constituency track.
</nextsent>
<nextsent>nivres algorithm is deterministic algorithm for building labeled projective dependency structures in linear time (nivre, 2006).
</nextsent>
<nextsent>there are two essential parameters that can be varied for this algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1051">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> malt parser.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 presents the experimental evaluation and discusses the results.
</prevsent>
<prevsent>finally section 6 concludes.
</prevsent>
</prevsection>
<citsent citstr=" D07-1097 ">
malt parser is transition-based parsing system which was one of the top performing systems on multilingual dependency parsing in the conll 2006 shared task (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2006) <papid> W06-2933 </papid>and the conll shared task 2007 (nivre et al, 2007; <papid> D07-1096 </papid>hallet al, 2007).<papid> D07-1097 </papid></citsent>
<aftsection>
<nextsent>the basic idea of malt parser is to derive dependency graphs using agreedy parsing algorithm that approximates glob 1maltparser is distributed with an open-source license and can be downloaded free of charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ 47ally optimal solution by making sequence of locally optimal choices.
</nextsent>
<nextsent>the system is equipped with several parsing algorithms, but we have chosen to only optimize nivres parsing algorithm for both the dependency track and the constituency track.
</nextsent>
<nextsent>nivres algorithm is deterministic algorithm for building labeled projective dependency structures in linear time (nivre, 2006).
</nextsent>
<nextsent>there are two essential parameters that can be varied for this algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1053">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>is taken from dependency version of tuba-d/z treebank.contain non-projective structures, such as the dependency graph illustrated in figure 1.
</prevsent>
<prevsent>nivres parsing algorithm only produces projective dependency structures, and therefore we used pseudo-projective parsing for recovering non-projective structures.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
the training data are projectivized and information about these transformations is encoded into the arc labels to enable deprojectivizition of the parser out put (nivre and nilsson, 2005).<papid> P05-1013 </papid></citsent>
<aftsection>
<nextsent>this section explains how transition-based dependency parser can be used for parsing constituent structures.
</nextsent>
<nextsent>the basic idea is to use the common practice of transforming constituent structure into dependency graph and encode the inverse mapping with complex arc labels.
</nextsent>
<nextsent>note that the goal is not to create the best dependency representation of constituent structure.
</nextsent>
<nextsent>instead the main objective is to find general method to transform constituency to dependency so that is easy to do the inverse transformation without losing any information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1058">
<title id=" W08-1007.xml">a dependency driven parser for german dependency and constituency representations </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we can see that the dependency results dependency constituency treebank las lp lr lf tiger 90.80 67.06 63.40 65.18 tuba-d/z 88.64 76.44 74.79 75.60table 1: the results for the extended version of malt parser 1.0 in the shared task on parsing german dependency and constituency representations.
</prevsent>
<prevsent>are close to 90% for both the treebanks, 90.80 for tiger and 88.64 for tuba-d/z, which were the unchallenged best scores in the shared task.
</prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
the highest score on parsing german in the conll-x shared task was obtained by the system of mcdonald et al (2006) <papid> W06-2932 </papid>with las of 87.34 based on the tiger treebank, but we want to stress that these results are not comparable due to different datasets (anda different policy regarding the inclusion of punctu ation).the constituency versions were evaluated according to the labeled recall (lr), labeled precision(lp) and labeled f-score (lf).</citsent>
<aftsection>
<nextsent>labeled in this context means that both the constituent label and the grammatical function should agree with the gold standard, but grammatical functions labeling theedge between constituent and token were not included in the evaluation.
</nextsent>
<nextsent>the labeled f-scores are 75.60 for tuba-d/z and 65.18 for tiger and these results are the second best results in the shared task out of three systems.
</nextsent>
<nextsent>we want to emphasize that the results may not be strictly comparable because of different use of the grammatical functions attached to the parts of speech in the bracketing format.
</nextsent>
<nextsent>we did not use these grammatical functions as input,instead these were assigned by the parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1061">
<title id=" W09-0306.xml">the development of the x201cindex thomisticusx201d treebank valency lexicon </title>
<section> latin treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>the same approach was later on followed by third latin treebank now 2 with tesnire (1959) as common background, there are.
</prevsent>
<prevsent>many different current dg flavours.
</prevsent>
</prevsection>
<citsent citstr=" C86-1046 ">
see for instance the following: dependency unification grammar (hellwig, 1986), <papid> C86-1046 </papid>functional generative description (sgall, hajiov?</citsent>
<aftsection>
<nextsent>and panevov?, 1986), meaning text theory (meluk, 1988), word grammar (hudson, 1990).
</nextsent>
<nextsent>available, which is ongoing at the university of oslo in the context of the proiel project (pragmatic resources in old indo-european languages): the aim of proiel is the syntactic annotation of the oldest extant versions of the new testament in indo-european languages, including greek, latin, gothic, armenian and church slavonic (haug and jhndal, 2008).
</nextsent>
<nextsent>2.1 annotation guidelines.
</nextsent>
<nextsent>since ldt and it-tb were the first projects of their kind for latin, no prior established guidelines were available to relyon for syntactic annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1062">
<title id=" W09-0306.xml">the development of the x201cindex thomisticusx201d treebank valency lexicon </title>
<section> latin treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>et al, 1999) was chosen and adapted to specific or idiosyncratic constructions of latin.
</prevsent>
<prevsent>these constructions (such as the ablative absolute or the passive periphrastic) could be syntactically annotated in several different ways and are common to latin of all eras.
</prevsent>
</prevsection>
<citsent citstr=" L08-1446 ">
rather than have each treebank project decide upon and record each decision for annotating them, ldt and it-tb decided to pool their resources and create single annotation manual that would govern both treebanks (bamman et al., 2007a; bamman et al, 2007b; bamman et al, 2008).<papid> L08-1446 </papid></citsent>
<aftsection>
<nextsent>as we are dealing with latin dialects separated by 13 centuries, sharing single annotation manual is very useful for comparison purposes, such as checking annotation consistency or dia chronically studying specific syntactic constructions.
</nextsent>
<nextsent>in addition, the task of data annotation through these common guidelines allows annotators to base their decisions on variety of examples from wider range of texts and combine the two datasets in order to train probabilistic dependency parsers.
</nextsent>
<nextsent>although the proiel annotation guidelines are grounded on the same grammar framework as the ldt and it-tb, they differ in number of details, some of which are described in passarotti (forthcoming).
</nextsent>
<nextsent>2.2 the index thomisticus treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1063">
<title id=" W09-0306.xml">the development of the x201cindex thomisticusx201d treebank valency lexicon </title>
<section> valency lexicons.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, lexicons like propbank (kings bury and palmer, 2002), framenet (ruppenhofer et al, 2006) and pdt-vallex (haji?
</prevsent>
<prevsent>et al, 2003) have been created in an intuition-based fashion and then checked and improved with examples from corpora.
</prevsent>
</prevsection>
<citsent citstr=" L08-1210 ">
on the other side, research in lexical acquisition has recently made available number of valency lexicons automatically acquired from annotated corpora, such as valex (korhonen, et al, 2006) and lexshem (messiant et al, 2008).<papid> L08-1210 </papid></citsent>
<aftsection>
<nextsent>unlike the fully intuition-based ones, these lexicons aim at systematically reflecting the evidence provided by data, with very little human intervention.
</nextsent>
<nextsent>the role of intuition is therefore left to the annotation phase (where the annotator interprets the corpus data), and not extended to the development of the lexicon itself.
</nextsent>
<nextsent>corpus-based lexicons show several advantages if compared with traditional human developed dictionaries.
</nextsent>
<nextsent>firstly, they systematically reflect the evidence of the corpus they were extracted from, while acquiring information specific to the domain of the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1064">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we confirm the intuition that srl at indexing stage improves the performance of qa and propose simplified technique named the question prediction language model (qplm), which provides similar information with much lower cost.
</prevsent>
<prevsent>the methods were tested on four different qa systems and the results suggest that qplmcan be used as good compromise between speed and accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
semantic role labeling (srl) has been implemented or suggested as means to aid several natural language processing (nlp) tasks such as information extraction (kogan et al , 2005), multi document summarization (barzilay et al , 1999) <papid> P99-1071 </papid>and machine translation (quantz and schmitz, 1994).</citsent>
<aftsection>
<nextsent>question answering (qa) is one task that takes advantage of srl, and in fact much of the research about the application of srl to nlp is related to qa.
</nextsent>
<nextsent>thus, narayanan and harabagiu (2004) <papid> C04-1100 </papid>apply the argument-predicate relationship from propbank (palmer et al , 2005) <papid> J05-1004 </papid>together with the semantic frames from framenet (baker et al , 1998) <papid> P98-1013 </papid>to create an inference mechanism to improve qa.</nextsent>
<nextsent>kaisser and webber (2007) <papid> W07-1206 </papid>apply semantic ? 2008.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1065">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic role labeling (srl) has been implemented or suggested as means to aid several natural language processing (nlp) tasks such as information extraction (kogan et al , 2005), multi document summarization (barzilay et al , 1999) <papid> P99-1071 </papid>and machine translation (quantz and schmitz, 1994).</prevsent>
<prevsent>question answering (qa) is one task that takes advantage of srl, and in fact much of the research about the application of srl to nlp is related to qa.</prevsent>
</prevsection>
<citsent citstr=" C04-1100 ">
thus, narayanan and harabagiu (2004) <papid> C04-1100 </papid>apply the argument-predicate relationship from propbank (palmer et al , 2005) <papid> J05-1004 </papid>together with the semantic frames from framenet (baker et al , 1998) <papid> P98-1013 </papid>to create an inference mechanism to improve qa.</citsent>
<aftsection>
<nextsent>kaisser and webber (2007) <papid> W07-1206 </papid>apply semantic ? 2008.</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1066">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic role labeling (srl) has been implemented or suggested as means to aid several natural language processing (nlp) tasks such as information extraction (kogan et al , 2005), multi document summarization (barzilay et al , 1999) <papid> P99-1071 </papid>and machine translation (quantz and schmitz, 1994).</prevsent>
<prevsent>question answering (qa) is one task that takes advantage of srl, and in fact much of the research about the application of srl to nlp is related to qa.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
thus, narayanan and harabagiu (2004) <papid> C04-1100 </papid>apply the argument-predicate relationship from propbank (palmer et al , 2005) <papid> J05-1004 </papid>together with the semantic frames from framenet (baker et al , 1998) <papid> P98-1013 </papid>to create an inference mechanism to improve qa.</citsent>
<aftsection>
<nextsent>kaisser and webber (2007) <papid> W07-1206 </papid>apply semantic ? 2008.</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1067">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic role labeling (srl) has been implemented or suggested as means to aid several natural language processing (nlp) tasks such as information extraction (kogan et al , 2005), multi document summarization (barzilay et al , 1999) <papid> P99-1071 </papid>and machine translation (quantz and schmitz, 1994).</prevsent>
<prevsent>question answering (qa) is one task that takes advantage of srl, and in fact much of the research about the application of srl to nlp is related to qa.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
thus, narayanan and harabagiu (2004) <papid> C04-1100 </papid>apply the argument-predicate relationship from propbank (palmer et al , 2005) <papid> J05-1004 </papid>together with the semantic frames from framenet (baker et al , 1998) <papid> P98-1013 </papid>to create an inference mechanism to improve qa.</citsent>
<aftsection>
<nextsent>kaisser and webber (2007) <papid> W07-1206 </papid>apply semantic ? 2008.</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1068">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>question answering (qa) is one task that takes advantage of srl, and in fact much of the research about the application of srl to nlp is related to qa.
</prevsent>
<prevsent>thus, narayanan and harabagiu (2004) <papid> C04-1100 </papid>apply the argument-predicate relationship from propbank (palmer et al , 2005) <papid> J05-1004 </papid>together with the semantic frames from framenet (baker et al , 1998) <papid> P98-1013 </papid>to create an inference mechanism to improve qa.</prevsent>
</prevsection>
<citsent citstr=" W07-1206 ">
kaisser and webber (2007) <papid> W07-1206 </papid>apply semantic ? 2008.</citsent>
<aftsection>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.relational information in order to transform questions into information retrieval queries and further analyze the results to find the answers for natural language questions.
</nextsent>
<nextsent>sun et al  (2005) use shallow semantic parser to create semantic roles in order to match questions and answers.
</nextsent>
<nextsent>shen and lapata (2007) <papid> D07-1002 </papid>developed an answer extraction module that incorporates framenet style semantic roleinformation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1069">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.relational information in order to transform questions into information retrieval queries and further analyze the results to find the answers for natural language questions.
</prevsent>
<prevsent>sun et al  (2005) use shallow semantic parser to create semantic roles in order to match questions and answers.
</prevsent>
</prevsection>
<citsent citstr=" D07-1002 ">
shen and lapata (2007) <papid> D07-1002 </papid>developed an answer extraction module that incorporates framenet style semantic roleinformation.</citsent>
<aftsection>
<nextsent>they deal with the semantic role assignment as optimization problem in bipartitegraph and the answer extraction as graph matching over the semantic relations.most of the studies that use srl or similar techniques to qa apply semantic relation tools on the input or output of the information retrieval phase of their system.
</nextsent>
<nextsent>our paper investigates the use of semantic information for indexing documents.
</nextsent>
<nextsent>our hypothesis is that allowing semantic role information at the indexing stage the question analyzer and subsequent stages of the qa system can obtain higher accuracy by providing an implicit query analyzer as well as more precise retrieval.
</nextsent>
<nextsent>theoretically, the inclusion of this information at indexing time can also speed up the overall qa process since syntactic rephrasing or re-ranking of documents based on semantic roles would not be necessary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1070">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>theoretically, the inclusion of this information at indexing time can also speed up the overall qa process since syntactic rephrasing or re-ranking of documents based on semantic roles would not be necessary.
</prevsent>
<prevsent>however, srl techniques are still highly complex and they demand computational power that is not yet available to most research groups when working with large corpora.
</prevsent>
</prevsection>
<citsent citstr=" W05-0635 ">
in our experience the annotation of 3gb corpus, such as the aquaint (graff, 2002), using semantic role labeler, for instance swirl from surdeanu and turmo (2005) <papid> W05-0635 </papid>can take more than one year using standard pc configuration1 .in order to efficiently process corpus with se 1intel(r) pentium(r) 4 ht 2.80ghz with 2.0 gb ram 74mantic relations, we have developed an alternative annotation strategy based on word-to-word relations instead of noun phrase-to-predicate relations.</citsent>
<aftsection>
<nextsent>we define semantic triples based on syntactic clues; this approach was also studied by litkowski (1999) but some major differences with our work are that we use automatically learned rules to generate the semantic relations, and thatwe use different semantic labels than those defined by litkowski, some more specific and some more general.
</nextsent>
<nextsent>our annotation scheme is named the question prediction language model (qplm) and represents relations between pairs of words using labels such as who and when, according to how one word complements the other.
</nextsent>
<nextsent>in the following section we provide an overview of the proposed semantic annotation module.
</nextsent>
<nextsent>then in section 3 we detail the information retrieval framework used that allows the indexing and retrieval of semantic information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1072">
<title id=" W08-1810.xml">indexing on semantic roles for question answering </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>this is an undesirable but expected problem that occurred not only because of the modifications carried on the qa systems but mainly because of the reduced number of documents used for this evaluation.
</prevsent>
<prevsent>we are looking into more efficient alternatives for performing the srl annotation of the aquaint corpus.
</prevsent>
</prevsection>
<citsent citstr=" W05-0625 ">
only recently we have been able to test koomen et al  (2005) <papid> W05-0625 </papid>srl tool.</citsent>
<aftsection>
<nextsent>this srl tool is the top ranking srl tool at the conll-2005 shared task evaluation and it seems to be much faster than swirl.
</nextsent>
<nextsent>preliminary tests suggest that it is able to perform the annotation of aquaint in almost one full year using single computer; however, this tool, like swirl, is not very stable, crashing several times during the experiments.
</nextsent>
<nextsent>as further work, we plan to employ several computers and attempt to parse the whole aquaint corpus with this tool.
</nextsent>
<nextsent>it is important to point out that although the tool of koomen et al  seems much faster than swirl, qplm still outperforms both of them on speed by large.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1073">
<title id=" W08-0903.xml">king alfred a translation environment for learners of anglo saxon english </title>
<section> automatically scoring translation.  </section>
<citcontext>
<prevsection>
<prevsent>we now believe, however, that king alfreds greatest benefit to the student may be in providing accurate, automatic feedback to translation that takes the variety of possible translation results into account.
</prevsent>
<prevsent>recent work on machine translation evaluation has uncovered methodologies for automatic evaluation that we believe we can adapt to our purposes.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
techniques that analyze n-gram precision such asbleu score (papineni et al, 2002) <papid> P02-1040 </papid>have been developed with the goal of comparing candidate translations against references provided by human expert sin order to determine accuracy; although in our application the candidate translator is student and not machine, the principle is the same, and we wish to adapt their technique to our context.our approach will differ from the n-gram precision of bleu score in several key ways.</citsent>
<aftsection>
<nextsent>most importantly, bleu score only captures potential correct translations but equally penalizes errors without regard to how serious these errors are.
</nextsent>
<nextsent>this is not acceptable in pedagogical context; take, for example, the following source sentence4: (1) sum mann feoll on ise.
</nextsent>
<nextsent>the instructors translation is given as: (2) one man fell on the ice.
</nextsent>
<nextsent>possible student translations might include: (3) one man fell on ice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1077">
<title id=" W08-2116.xml">easy as abc facilitating pictorial communication via semantically enhanced layout </title>
<section> prior pictorial communication work.  </section>
<citcontext>
<prevsection>
<prevsent>at one extreme, there has been significant prior work on text-to-scene?
</prevsent>
<prevsent>type systems, which were often intended to aid graphic designers in placing objects in 3d environment.
</prevsent>
</prevsection>
<citsent citstr=" C92-4207 ">
example systems include nalig (adorni et al, 1983), sprint (ya mada et al, 1992), <papid> C92-4207 </papid>put (clay and wilhelms, 1996), and others (brown and chandrasekaran, 1981).</citsent>
<aftsection>
<nextsent>perhaps the best known system of this type, words eye (coyne and sproat, 2001), uses large manually tagged collection of 3d polyhedral models to create photo-realistic scenes.
</nextsent>
<nextsent>similarly, car sim (johansson et al, 2005) can create animated scenes, but operates exclusively in the limited do main of reconstructing road accidents from traffic reports.
</nextsent>
<nextsent>these systems cater to detailed descriptive text with visual and spatial elements.
</nextsent>
<nextsent>they are not intended as assistive tools to communicate general text, which is our goal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1078">
<title id=" W09-0508.xml">an integrated approach to robust processing of situated spoken dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this problem is particularly acute for robots operating in real world noisy environments and deal with utterances pertaining to complex, open-ended domains.
</prevsent>
<prevsent>the paper presents new approach to address these two difficult issues.
</prevsent>
</prevsection>
<citsent citstr=" D07-1071 ">
our starting point is the work done by zettlemoyer and collinson parsing using relaxed ccg grammars (zettlemoyer and collins, 2007) (<papid> D07-1071 </papid>zc07).</citsent>
<aftsection>
<nextsent>in order to account for natural spoken language phenomena (more flexible word order, missing words, etc.), they augment their grammar framework with small set of non-standard combinatory rules, leading to arelaxation of the grammatical constraints.
</nextsent>
<nextsent>a discriminative model over the parses is coupled with the parser, and is responsible for selecting the most likely interpretation(s) among the possible ones.
</nextsent>
<nextsent>in this paper, we extend their approach in two important ways.
</nextsent>
<nextsent>first, zc07 focused on the treatment of ill-formed input, and ignored the speech recognition issues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1079">
<title id=" W09-0508.xml">an integrated approach to robust processing of situated spoken dialogue </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>a grammatical analysis constructs both syntactic analysis of the utterance, and representation of its meaning.
</prevsent>
<prevsent>the analysis is based on an incremental chart parser1 for combinatory categorial grammar (steedmanand baldridge, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P02-1041 ">
these meaning representations are onto logically richly sorted, relational 1built on top of the openccg nlp library: http://openccg.sf.netstructures, formulated in (propositional) description logic, more precisely in the hlds formalism (baldridge and kruijff, 2002).<papid> P02-1041 </papid></citsent>
<aftsection>
<nextsent>the parser compacts all meaning representations into single packed logical form (carroll and oepen, 2005;<papid> I05-1015 </papid>kruijff et al , 2007).</nextsent>
<nextsent>a packed lf represents content similar across the different analyses as single graph, using over- and under specification of how different nodes can be connected to capture lexical and syntactic forms of ambiguity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1080">
<title id=" W09-0508.xml">an integrated approach to robust processing of situated spoken dialogue </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the analysis is based on an incremental chart parser1 for combinatory categorial grammar (steedmanand baldridge, 2009).
</prevsent>
<prevsent>these meaning representations are onto logically richly sorted, relational 1built on top of the openccg nlp library: http://openccg.sf.netstructures, formulated in (propositional) description logic, more precisely in the hlds formalism (baldridge and kruijff, 2002).<papid> P02-1041 </papid></prevsent>
</prevsection>
<citsent citstr=" I05-1015 ">
the parser compacts all meaning representations into single packed logical form (carroll and oepen, 2005;<papid> I05-1015 </papid>kruijff et al , 2007).</citsent>
<aftsection>
<nextsent>a packed lf represents content similar across the different analyses as single graph, using over- and under specification of how different nodes can be connected to capture lexical and syntactic forms of ambiguity.
</nextsent>
<nextsent>at the level of dialogue interpretation, packed logical form is resolved against sdrs-like dialogue model (asher and lascarides, 2003) to establish contextual co-reference and dialogue moves.linguistic interpretations must finally be associated with extra-linguistic knowledge about the environment ? dialogue comprehension hence needs to connect with other sub architectures like vision, spatial reasoning or planning.
</nextsent>
<nextsent>we realise this information binding between different modalities via specific module, called the binder?, which is responsible for the ontology-based mediation ac cross modalities (jacobsson et al , 2008).
</nextsent>
<nextsent>2.1 context-sensitivity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1083">
<title id=" W09-0508.xml">an integrated approach to robust processing of situated spoken dialogue </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>3.3.2 perceptron learning the algorithm we use to estimate the parametersw using the training data is perceptron.
</prevsent>
<prevsent>the algorithm is fully online - it visits each example in turn and updates if necessary.
</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
albeit simple, the algorithm has proven to be very efficient and accurate for the task of parse selection (collins and roark, 2004; <papid> P04-1015 </papid>collins, 2004; zettlemoyer and collins, 2005; zettlemoyer and collins, 2007).<papid> D07-1071 </papid>the pseudo-code for the online learning algorithm is detailed in [algorithm 1].</citsent>
<aftsection>
<nextsent>it works as follows: the parameters are first initial ised to some arbitrary values.
</nextsent>
<nextsent>then, for each pair (xi, zi) in the training set, the algorithmsearchs for the parse y?
</nextsent>
<nextsent>with the highest score according to the current model.
</nextsent>
<nextsent>if this parse happens to match the best parse which generates zi (which we shall denote y?), we move to the next example.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1087">
<title id=" W09-1707.xml">using dedicom for completely unsupervised partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rule based approach relies on two elements: dictionary to assign possible parts of speech to each word, and list of hand-written rules ? which must be painstakingly developed for each new language or domain ? to disambiguate tokens in context.
</prevsent>
<prevsent>stochastic taggers, on the other hand, avoid the need for hand-written rules by tabulating probabilities of types and part-of-speech tags (which must be gathered from tagged training corpus), and applying special case of bayesian inference (usually, hidden markov models [hmms]) to disambiguate tokens in context.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
the latter approach was pioneered by stolz et al (1965) and bahl and mercer (1976), and became widely known through the work of e.g. church (1988) <papid> A88-1019 </papid>and derose (1988).<papid> J88-1003 </papid></citsent>
<aftsection>
<nextsent>a third and more recent approach, known as distributional tagging?
</nextsent>
<nextsent>and exemplified by schtze (1993), exemplified by schtze (1995) and biemann (2006), <papid> P06-3002 </papid>aims to eliminate the need for both hand-written rules and tagged training corpus, since the latter may not be available for every language or domain.</nextsent>
<nextsent>distributional tagging is fully-unsupervised, unlike the two traditional approaches described above.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1088">
<title id=" W09-1707.xml">using dedicom for completely unsupervised partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rule based approach relies on two elements: dictionary to assign possible parts of speech to each word, and list of hand-written rules ? which must be painstakingly developed for each new language or domain ? to disambiguate tokens in context.
</prevsent>
<prevsent>stochastic taggers, on the other hand, avoid the need for hand-written rules by tabulating probabilities of types and part-of-speech tags (which must be gathered from tagged training corpus), and applying special case of bayesian inference (usually, hidden markov models [hmms]) to disambiguate tokens in context.
</prevsent>
</prevsection>
<citsent citstr=" J88-1003 ">
the latter approach was pioneered by stolz et al (1965) and bahl and mercer (1976), and became widely known through the work of e.g. church (1988) <papid> A88-1019 </papid>and derose (1988).<papid> J88-1003 </papid></citsent>
<aftsection>
<nextsent>a third and more recent approach, known as distributional tagging?
</nextsent>
<nextsent>and exemplified by schtze (1993), exemplified by schtze (1995) and biemann (2006), <papid> P06-3002 </papid>aims to eliminate the need for both hand-written rules and tagged training corpus, since the latter may not be available for every language or domain.</nextsent>
<nextsent>distributional tagging is fully-unsupervised, unlike the two traditional approaches described above.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1089">
<title id=" W09-1707.xml">using dedicom for completely unsupervised partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the latter approach was pioneered by stolz et al (1965) and bahl and mercer (1976), and became widely known through the work of e.g. church (1988) <papid> A88-1019 </papid>and derose (1988).<papid> J88-1003 </papid></prevsent>
<prevsent>a third and more recent approach, known as distributional tagging?</prevsent>
</prevsection>
<citsent citstr=" P06-3002 ">
and exemplified by schtze (1993), exemplified by schtze (1995) and biemann (2006), <papid> P06-3002 </papid>aims to eliminate the need for both hand-written rules and tagged training corpus, since the latter may not be available for every language or domain.</citsent>
<aftsection>
<nextsent>distributional tagging is fully-unsupervised, unlike the two traditional approaches described above.
</nextsent>
<nextsent>schtze suggests analyzing the distributional patterns of words by forming term adjacency matrix, then subjecting that matrix to singular value decomposition (svd) to reveal latent dimensions.
</nextsent>
<nextsent>he shows that in the reduced-dimensional space implied by svd, tokens do indeed cluster intuitively by part-of-speech; and that if context is taken into account, something akin to part-of-speech tagging 54can be achieved.
</nextsent>
<nextsent>whereas the performance of stochastic taggers is generally sub-optimal when the domain of the training data differs from that of the test data, distributional tagging sidesteps this problem, since each corpus can be considered in its own right.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1091">
<title id=" W09-1707.xml">using dedicom for completely unsupervised partofspeech tagging </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>each token is associated with part-of-speech tag and chunk tag, although we did not use the chunk tags 57in the work described here.
</prevsent>
<prevsent>the tags are from 44 item tagset.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
the conll 2000 tags against which we measure our own results are in fact assigned by the brill tagger (brill 1992), <papid> A92-1021 </papid>and while these may not correlate perfectly with those that would have been assigned by human linguist, we believe that the correlation is likely to be good enough to allow for an informative evaluation of our method.</citsent>
<aftsection>
<nextsent>before discussing the evaluation of unsupervised dedicom, let us briefly reconsider the similarities of dedicom to the supervised hmm model in the light of actual data in the conll corpus.
</nextsent>
<nextsent>we stated in (5) that  a*dar*daa*t. for the conll 2000 tagged data, a* is 19,440 ? 44 matrix and r* is 44 ? 44 matrix.
</nextsent>
<nextsent>using a*da and r*da as emission- and transition probability matrices within standard hmm (where the entire conll 2000 corpus is treated as both training and test data), we obtained tagging accuracy of 95.6%.
</nextsent>
<nextsent>by multiplying a*dar*daa*t, we expect to obtain matrix approximating x, the table of bigram frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1092">
<title id=" W09-1503.xml">using paraphrases of deep semantic represent ions to support regression testing in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper discusses the methodology we have developed to address regression testing issues within the regulus framework.
</prevsent>
<prevsent>regulus (rayner et al, 2006) is an open source toolkit for builting medium 14vocabulary spoken dialogue and translation applications, and has been used to build number ofnon-trivial spoken dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" P05-3008 ">
prominent examples include nasas clarissa procedure navigator (rayner et al, 2005), <papid> P05-3008 </papid>geneva universitys multi-modal mobile-platform calendar application(tsourakis et al, 2008), <papid> L08-1493 </papid>sds, prototype in-car system developed by uc santacruz in collaboration with ford motors research which was voted first in fords 2007 internal technology fair, and taxi, speech-enabled game in which the user interacts with simulated cabdriver to navigate around map of manhattan.</citsent>
<aftsection>
<nextsent>it has also been used to build themedslt medical speech translation system (bouil lon et al, 2008).the regulus platform includes tools for developing feature grammars, and compiling them in various ways.
</nextsent>
<nextsent>in particular, it is possible to compile grammars into generators, and use them to support paraphrasing from the internal semantic representations created during dialogue processing.
</nextsent>
<nextsent>this capability is key to the newest part of our regression testing approach, and is discussed in detail in section 3.
</nextsent>
<nextsent>first, though, section 2 gives an overview ofregulus and the architecture of regulus-based sys tems; we discuss features that complicate regression testing, and how to address these problems within this type of architecture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1093">
<title id=" W09-1503.xml">using paraphrases of deep semantic represent ions to support regression testing in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper discusses the methodology we have developed to address regression testing issues within the regulus framework.
</prevsent>
<prevsent>regulus (rayner et al, 2006) is an open source toolkit for builting medium 14vocabulary spoken dialogue and translation applications, and has been used to build number ofnon-trivial spoken dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" L08-1493 ">
prominent examples include nasas clarissa procedure navigator (rayner et al, 2005), <papid> P05-3008 </papid>geneva universitys multi-modal mobile-platform calendar application(tsourakis et al, 2008), <papid> L08-1493 </papid>sds, prototype in-car system developed by uc santacruz in collaboration with ford motors research which was voted first in fords 2007 internal technology fair, and taxi, speech-enabled game in which the user interacts with simulated cabdriver to navigate around map of manhattan.</citsent>
<aftsection>
<nextsent>it has also been used to build themedslt medical speech translation system (bouil lon et al, 2008).the regulus platform includes tools for developing feature grammars, and compiling them in various ways.
</nextsent>
<nextsent>in particular, it is possible to compile grammars into generators, and use them to support paraphrasing from the internal semantic representations created during dialogue processing.
</nextsent>
<nextsent>this capability is key to the newest part of our regression testing approach, and is discussed in detail in section 3.
</nextsent>
<nextsent>first, though, section 2 gives an overview ofregulus and the architecture of regulus-based sys tems; we discuss features that complicate regression testing, and how to address these problems within this type of architecture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1094">
<title id=" W09-1503.xml">using paraphrases of deep semantic represent ions to support regression testing in spoken dialogue systems </title>
<section> context, regression testing and.  </section>
<citcontext>
<prevsection>
<prevsent>paraphrasing the three main components of the spoken dialogue system ? the im, dm and om ? all transform one or more inputs into one or more outputs.with the current focus on machine learning techniques, natural thought is to learn the relevant tran formations from examples.
</prevsent>
<prevsent>implemented mainly through partially observable markov decision processes (pomdps), this idea is attractive theoretically, but has been challenging to scale up.
</prevsent>
</prevsection>
<citsent citstr=" P00-1013 ">
systems have been restricted to very simple domains (roy et al, 2000; <papid> P00-1013 </papid>zhang et al, 2001) and only recently have techniques been developed that show promise for use in real-world systems (williams and young,2007; gasic?</citsent>
<aftsection>
<nextsent>et al, 2008).
</nextsent>
<nextsent>the representations required in many systems are more complex than those employed even in the more recent pomdp based work, and there is also the usual problem that it is noteasy to obtain training data.
</nextsent>
<nextsent>in practice, most people are forced to construct the transformation rules by hand; the regulus framework assumes this will be the case.
</nextsent>
<nextsent>hand-coding of dialogue processing components involves the usual software engineering problems that arise when building and maintaining substantial rule-sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1095">
<title id=" W08-1802.xml">exact phrases in information retrieval for question answering </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>phrases are identified automatically using the nltk toolkit (bird et al , 2008).
</prevsent>
<prevsent>we extract noun phrases, verb phrases and prepositional phrases.
</prevsent>
</prevsection>
<citsent citstr=" P06-1063 ">
the rules for identifying phrases are mined from dataset of manually annotated parse trees (judge et al , 2006) <papid> P06-1063 </papid>4.</citsent>
<aftsection>
<nextsent>converted qphrases are heuristic ally created phrases that paraphrase the question in declarative form using small set of rules.
</nextsent>
<nextsent>the rules match question to pattern and transform the question using linguistic information.
</nextsent>
<nextsent>for example, one rule matches who is|was noun|pronoun vbd and converts it to noun|pronoun is|was vbd.
</nextsent>
<nextsent>5 3the trec dataset al provides target topic for each questions, and we include it in the query.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1096">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the english to german system used an additional translation step which recreated compound words and generated morphological inflection.
</prevsent>
<prevsent>the institute for natural language processing (ifnlp), stuttgart, participated in the wmt-2009 shared tasks for german to english and english to german translation with constrained systems which employed morphological and syntactic processing techniques.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the systems were based on the open source moses docoder (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we combined ifnlp tools for syntactic and morphological analysis (which are publicly available and widely used) with preprocessing techniques that were successfully used by other groups in wmt-2008, and extended these.
</nextsent>
<nextsent>for english to german translation, we additionally performed astep which recreated compound words and generated morphological inflection.
</nextsent>
<nextsent>1.1 baseline.
</nextsent>
<nextsent>the baseline is the standard system supplied for the shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1097">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>115 2.3 reordering german.
</prevsent>
<prevsent>german word order differs from english substantially.
</prevsent>
</prevsection>
<citsent citstr=" J04-2003 ">
preprocessing approaches involving the use of syntactic parse of the source sentence to change the word order to more closely match theword order of the target language have been studied by niessen and ney (2004), <papid> J04-2003 </papid>xia and mccord (2004), <papid> C04-1073 </papid>drabek and yarowsky (2004), <papid> P04-3014 </papid>collins et al.</citsent>
<aftsection>
<nextsent>(2005), popovic?
</nextsent>
<nextsent>and ney (2006), wang et al (2007) <papid> D07-1077 </papid>and many others.</nextsent>
<nextsent>to obtain parse of each german sentence in the training, dev and test corpora, we employed the ifnlp bitpar probabilistic parser (schmid, 2004), <papid> C04-1024 </papid>using models learned from the tiger treebank for german.dealing with morphological productivity is important in the syntactic parsing of german.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1098">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>115 2.3 reordering german.
</prevsent>
<prevsent>german word order differs from english substantially.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
preprocessing approaches involving the use of syntactic parse of the source sentence to change the word order to more closely match theword order of the target language have been studied by niessen and ney (2004), <papid> J04-2003 </papid>xia and mccord (2004), <papid> C04-1073 </papid>drabek and yarowsky (2004), <papid> P04-3014 </papid>collins et al.</citsent>
<aftsection>
<nextsent>(2005), popovic?
</nextsent>
<nextsent>and ney (2006), wang et al (2007) <papid> D07-1077 </papid>and many others.</nextsent>
<nextsent>to obtain parse of each german sentence in the training, dev and test corpora, we employed the ifnlp bitpar probabilistic parser (schmid, 2004), <papid> C04-1024 </papid>using models learned from the tiger treebank for german.dealing with morphological productivity is important in the syntactic parsing of german.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1099">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>115 2.3 reordering german.
</prevsent>
<prevsent>german word order differs from english substantially.
</prevsent>
</prevsection>
<citsent citstr=" P04-3014 ">
preprocessing approaches involving the use of syntactic parse of the source sentence to change the word order to more closely match theword order of the target language have been studied by niessen and ney (2004), <papid> J04-2003 </papid>xia and mccord (2004), <papid> C04-1073 </papid>drabek and yarowsky (2004), <papid> P04-3014 </papid>collins et al.</citsent>
<aftsection>
<nextsent>(2005), popovic?
</nextsent>
<nextsent>and ney (2006), wang et al (2007) <papid> D07-1077 </papid>and many others.</nextsent>
<nextsent>to obtain parse of each german sentence in the training, dev and test corpora, we employed the ifnlp bitpar probabilistic parser (schmid, 2004), <papid> C04-1024 </papid>using models learned from the tiger treebank for german.dealing with morphological productivity is important in the syntactic parsing of german.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1100">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>preprocessing approaches involving the use of syntactic parse of the source sentence to change the word order to more closely match theword order of the target language have been studied by niessen and ney (2004), <papid> J04-2003 </papid>xia and mccord (2004), <papid> C04-1073 </papid>drabek and yarowsky (2004), <papid> P04-3014 </papid>collins et al.</prevsent>
<prevsent>(2005), popovic?</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
and ney (2006), wang et al (2007) <papid> D07-1077 </papid>and many others.</citsent>
<aftsection>
<nextsent>to obtain parse of each german sentence in the training, dev and test corpora, we employed the ifnlp bitpar probabilistic parser (schmid, 2004), <papid> C04-1024 </papid>using models learned from the tiger treebank for german.dealing with morphological productivity is important in the syntactic parsing of german.</nextsent>
<nextsent>bit par has been designed with this in mind.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1101">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>(2005), popovic?
</prevsent>
<prevsent>and ney (2006), wang et al (2007) <papid> D07-1077 </papid>and many others.</prevsent>
</prevsection>
<citsent citstr=" C04-1024 ">
to obtain parse of each german sentence in the training, dev and test corpora, we employed the ifnlp bitpar probabilistic parser (schmid, 2004), <papid> C04-1024 </papid>using models learned from the tiger treebank for german.dealing with morphological productivity is important in the syntactic parsing of german.</citsent>
<aftsection>
<nextsent>bit par has been designed with this in mind.
</nextsent>
<nextsent>ifnlpssmor analyzer is used for morphological analysis (schmid et al, 2004).
</nextsent>
<nextsent>smor is run over list of types in each german sentence, and outputs alist of analyses for each type, each of which corresponds to pos tag.
</nextsent>
<nextsent>bitpar is limited to choosing one of these pos tags for this type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1102">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>bitpar is limited to choosing one of these pos tags for this type.
</prevsent>
<prevsent>words which smor fails to analyze are allowed to occur with any pos tag.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
we reimplemented the syntactic preprocessing approach of collins et al (2005), <papid> P05-1066 </papid>with modi fica tions.</citsent>
<aftsection>
<nextsent>reordering rules are applied to german parse tree (generated by bitpar), and focus on reordering the words in the german clause structure to more closely resemble english clause structure.
</nextsent>
<nextsent>the rules are applied to both the training data for the smt system, and the input (the dev and test sets).
</nextsent>
<nextsent>we previously performed an error analysis of this approach and for the work described here we addressed some of the shortcomings identified through the analysis.
</nextsent>
<nextsent>the analysis was performed on the europarl dev2006 set.the first error that we noticed occurring frequently was that some large clausal units which were labeled as subjects were being moved forward in the sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1103">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>using the original rules, the verb 2nd rule fails to fire, incorrectly leaving haben (gloss: have) at the end of the clause.
</prevsent>
<prevsent>2.4 morphological decomposition.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
we implemented the frequency-based word splitting approach of koehn and knight (2003), <papid> E03-1076 </papid>and made modifications, including some similar to those described by stymne et al (2008).<papid> W08-0317 </papid></citsent>
<aftsection>
<nextsent>this well-known technique splits compound words.
</nextsent>
<nextsent>in addition, we performed simple suffix elimination, aimed at removing inflection marking features such as gender and case that are not necessary for translation to english.
</nextsent>
<nextsent>we took the stem combination with the highest geometric mean of the frequencies of the stems, but following stymne et al (2008), <papid> W08-0317 </papid>we restricted stems to minimum length 4, and we allowed an extended list of infixes: s, n, en, nen, es, er and ien.</nextsent>
<nextsent>for suffixes, we allowed: e, en, n, es, s, em and er, which is more aggressive 116 input mir ist bewusst , dass der balkan kein gebiet ist , das anlass zu optimism us gibt . gloss me is clear , that the balkans not area is , that opportunity for optimism gives . before mir dass der balkan ist kein gebiet ist bewusst , , das anlass zu optimism us gibt . gloss me that the balkans is not area is clear , that opportunity for optimism gives . after mir ist bewusst , dass der balkan ist kein gebiet , das anlass zu optimism us gibt . gloss me is clear , that the balkans is not area , that opportunity for optimism gives . ref am aware that the balkans are not the most promising area for optimism .input am 23.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1104">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> improvements.  </section>
<citcontext>
<prevsection>
<prevsent>using the original rules, the verb 2nd rule fails to fire, incorrectly leaving haben (gloss: have) at the end of the clause.
</prevsent>
<prevsent>2.4 morphological decomposition.
</prevsent>
</prevsection>
<citsent citstr=" W08-0317 ">
we implemented the frequency-based word splitting approach of koehn and knight (2003), <papid> E03-1076 </papid>and made modifications, including some similar to those described by stymne et al (2008).<papid> W08-0317 </papid></citsent>
<aftsection>
<nextsent>this well-known technique splits compound words.
</nextsent>
<nextsent>in addition, we performed simple suffix elimination, aimed at removing inflection marking features such as gender and case that are not necessary for translation to english.
</nextsent>
<nextsent>we took the stem combination with the highest geometric mean of the frequencies of the stems, but following stymne et al (2008), <papid> W08-0317 </papid>we restricted stems to minimum length 4, and we allowed an extended list of infixes: s, n, en, nen, es, er and ien.</nextsent>
<nextsent>for suffixes, we allowed: e, en, n, es, s, em and er, which is more aggressive 116 input mir ist bewusst , dass der balkan kein gebiet ist , das anlass zu optimism us gibt . gloss me is clear , that the balkans not area is , that opportunity for optimism gives . before mir dass der balkan ist kein gebiet ist bewusst , , das anlass zu optimism us gibt . gloss me that the balkans is not area is clear , that opportunity for optimism gives . after mir ist bewusst , dass der balkan ist kein gebiet , das anlass zu optimism us gibt . gloss me is clear , that the balkans is not area , that opportunity for optimism gives . ref am aware that the balkans are not the most promising area for optimism .input am 23.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1107">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>after this the splitting and stemming process was applied.
</prevsent>
<prevsent>finally, we lower cased the data.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
word alignments were generated using model 4 (brown et al, 1993) <papid> J93-2003 </papid>using the multi-threaded implementation of giza++ (och and ney, 2003; <papid> J03-1002 </papid>gao and vogel, 2008).<papid> W08-0509 </papid></citsent>
<aftsection>
<nextsent>we first trained model 4 with english as the source language, and then with german as the source language, resulting in twoviterbi alignments3.
</nextsent>
<nextsent>the resulting viterbi alignments were combined using the grow diag final and symmetrization heuristic (koehn et al, 2003).we estimated standard moses system using default settings.
</nextsent>
<nextsent>mert was run until convergence using dev-2009a (separately for each experiment).
</nextsent>
<nextsent>one limitation of our german to english system is that we were unable to scale to the full language modeling data using srilm (stolcke, 2002), 5grams and modified kneser-ney with no singleton deletion4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1108">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>after this the splitting and stemming process was applied.
</prevsent>
<prevsent>finally, we lower cased the data.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignments were generated using model 4 (brown et al, 1993) <papid> J93-2003 </papid>using the multi-threaded implementation of giza++ (och and ney, 2003; <papid> J03-1002 </papid>gao and vogel, 2008).<papid> W08-0509 </papid></citsent>
<aftsection>
<nextsent>we first trained model 4 with english as the source language, and then with german as the source language, resulting in twoviterbi alignments3.
</nextsent>
<nextsent>the resulting viterbi alignments were combined using the grow diag final and symmetrization heuristic (koehn et al, 2003).we estimated standard moses system using default settings.
</nextsent>
<nextsent>mert was run until convergence using dev-2009a (separately for each experiment).
</nextsent>
<nextsent>one limitation of our german to english system is that we were unable to scale to the full language modeling data using srilm (stolcke, 2002), 5grams and modified kneser-ney with no singleton deletion4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1109">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>after this the splitting and stemming process was applied.
</prevsent>
<prevsent>finally, we lower cased the data.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
word alignments were generated using model 4 (brown et al, 1993) <papid> J93-2003 </papid>using the multi-threaded implementation of giza++ (och and ney, 2003; <papid> J03-1002 </papid>gao and vogel, 2008).<papid> W08-0509 </papid></citsent>
<aftsection>
<nextsent>we first trained model 4 with english as the source language, and then with german as the source language, resulting in twoviterbi alignments3.
</nextsent>
<nextsent>the resulting viterbi alignments were combined using the grow diag final and symmetrization heuristic (koehn et al, 2003).we estimated standard moses system using default settings.
</nextsent>
<nextsent>mert was run until convergence using dev-2009a (separately for each experiment).
</nextsent>
<nextsent>one limitation of our german to english system is that we were unable to scale to the full language modeling data using srilm (stolcke, 2002), 5grams and modified kneser-ney with no singleton deletion4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1110">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>one limitation of our german to english system is that we were unable to scale to the full language modeling data using srilm (stolcke, 2002), 5grams and modified kneser-ney with no singleton deletion4.
</prevsent>
<prevsent>the language model in our submitted system is based on all of the available english data, but news-train08 is truncated to the first 10193376 lines, meaning that we did not train on the remaining 11038787 lines, so we used little less than half of the data.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
we converted the lan 3we used 5 iterations of model 1, 4 iterations of hmm (vogel et al, 1996) <papid> C96-2141 </papid>and 4 iterations of model 4.</citsent>
<aftsection>
<nextsent>4srilm failed when trained on the full data, even when machine with 32 gb ram and 48 gb swap was used.
</nextsent>
<nextsent>117 guage model trained using srilm to the binary format using irstlm.
</nextsent>
<nextsent>experiments are presented in table 1, using bleu (papineni et al, 2001) and meteor5 (banerjee and lavie, 2005), <papid> W05-0909 </papid>and we also show the length ratio (ratio of hypothesized tokens to reference tokens).</nextsent>
<nextsent>for translation into english meteor had superior correlation with human rankings to bleu at wmt 2008 (callison-burch et al, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1111">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>4srilm failed when trained on the full data, even when machine with 32 gb ram and 48 gb swap was used.
</prevsent>
<prevsent>117 guage model trained using srilm to the binary format using irstlm.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
experiments are presented in table 1, using bleu (papineni et al, 2001) and meteor5 (banerjee and lavie, 2005), <papid> W05-0909 </papid>and we also show the length ratio (ratio of hypothesized tokens to reference tokens).</citsent>
<aftsection>
<nextsent>for translation into english meteor had superior correlation with human rankings to bleu at wmt 2008 (callison-burch et al, 2008).
</nextsent>
<nextsent>our submitted system had bug where the environment variable lc all was setto en us when creating the binarized filtered lexicalized reordering table for the test set (and for the blind test set, but not for the dev set used for mert).
</nextsent>
<nextsent>this caused minor degradation, see the system marked (*) for the system with the bug cor rected.each system increases in both bleu and meteor as improvements are added.
</nextsent>
<nextsent>an exception is that splitting/stemming decreases bleu some what.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1112">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also compared using different language model instead of the srilm model (the bottom half of table 1).
</prevsent>
<prevsent>these used either the reduced english language modeling data or the full data (21.2 segments, marked 21.2 in the results).
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>performs well and scaled to the full data with improvement (resulting in our best overall system).</citsent>
<aftsection>
<nextsent>irstlm (federico and cettolo, 2007) <papid> W07-0712 </papid>also performs well, but the quant ized model on the 21.2 data did not improve over the smaller quant ized model6.</nextsent>
<nextsent>irstlm uses an approximation of witten-bellsmoothing, our results support that this is compet itive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1113">
<title id=" W09-0420.xml">experiments in morphosyntactic processing for translating to and from german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>these used either the reduced english language modeling data or the full data (21.2 segments, marked 21.2 in the results).
</prevsent>
<prevsent>randlm (talbot and osborne, 2007) <papid> P07-1065 </papid>performs well and scaled to the full data with improvement (resulting in our best overall system).</prevsent>
</prevsection>
<citsent citstr=" W07-0712 ">
irstlm (federico and cettolo, 2007) <papid> W07-0712 </papid>also performs well, but the quant ized model on the 21.2 data did not improve over the smaller quant ized model6.</citsent>
<aftsection>
<nextsent>irstlm uses an approximation of witten-bellsmoothing, our results support that this is competitive.
</nextsent>
<nextsent>3.2 english to german.
</nextsent>
<nextsent>we trained our english to german system on the constrained parallel data.
</nextsent>
<nextsent>the first smt system translates from lower cased english to lower cased simplified german, which is then recased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1115">
<title id=" W08-2217.xml">refining the meaning of sense labels in pdtb concession </title>
<section> toward formal definition of concession?.  </section>
<citcontext>
<prevsection>
<prevsent>refining the meaning of sense labels in pdtb: concession?
</prevsent>
<prevsent>213 be treated simply as eventualities that can be the content of thoughts.
</prevsent>
</prevsection>
<citsent citstr=" P83-1009 ">
to this end, the logical framework includes the notion of typical element (from hobbs (1983, <papid> P83-1009 </papid>1995, 1998)).</citsent>
<aftsection>
<nextsent>the typical element of set is the reification of the universally quantified variable ranging over the elements of the set (cf.
</nextsent>
<nextsent>mccarthy (1977)).
</nextsent>
<nextsent>typical elements are first-order individuals.
</nextsent>
<nextsent>the introduction of typical elements arises from the need to move from the standard set-theoretic notation = {x | p(x) } or its logical equivalent, (forall (x) (iff (member s) (p x))) to simple statement that is true of typical element?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1116">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its top 10 accuracy for noun translation is higher than that of statistical translation model trained on spanish-english parallel corpus containing 100,000 sentence pairs.
</prevsent>
<prevsent>we generalize the evaluation toother word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equiva lencies during translation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>however,large parallel corpora exist for only small fraction of the worlds languages, leading to bottleneck for building translation systems in low-density languages such as swahili, uzbek or punjabi.
</nextsent>
<nextsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</nextsent>
<nextsent>the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</nextsent>
<nextsent>languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1117">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its top 10 accuracy for noun translation is higher than that of statistical translation model trained on spanish-english parallel corpus containing 100,000 sentence pairs.
</prevsent>
<prevsent>we generalize the evaluation toother word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equiva lencies during translation.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (koehn et al, 2003; <papid> N03-1017 </papid>chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>however,large parallel corpora exist for only small fraction of the worlds languages, leading to bottleneck for building translation systems in low-density languages such as swahili, uzbek or punjabi.
</nextsent>
<nextsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</nextsent>
<nextsent>the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</nextsent>
<nextsent>languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1118">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however,large parallel corpora exist for only small fraction of the worlds languages, leading to bottleneck for building translation systems in low-density languages such as swahili, uzbek or punjabi.
</prevsent>
<prevsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</citsent>
<aftsection>
<nextsent>languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
<nextsent>this paper investigates new ways of learning translations from monolingual corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1122">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however,large parallel corpora exist for only small fraction of the worlds languages, leading to bottleneck for building translation systems in low-density languages such as swahili, uzbek or punjabi.
</prevsent>
<prevsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</citsent>
<aftsection>
<nextsent>languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
<nextsent>this paper investigates new ways of learning translations from monolingual corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1127">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however,large parallel corpora exist for only small fraction of the worlds languages, leading to bottleneck for building translation systems in low-density languages such as swahili, uzbek or punjabi.
</prevsent>
<prevsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</prevsent>
</prevsection>
<citsent citstr=" W02-2026 ">
the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</citsent>
<aftsection>
<nextsent>languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
<nextsent>this paper investigates new ways of learning translations from monolingual corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1129">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however,large parallel corpora exist for only small fraction of the worlds languages, leading to bottleneck for building translation systems in low-density languages such as swahili, uzbek or punjabi.
</prevsent>
<prevsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</prevsent>
</prevsection>
<citsent citstr=" P08-1088 ">
the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</citsent>
<aftsection>
<nextsent>languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></nextsent>
<nextsent>this paper investigates new ways of learning translations from monolingual corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1130">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data.
</prevsent>
<prevsent>the marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (rapp, 1999; <papid> P99-1067 </papid>koehn and knight, 2002; <papid> W02-0902 </papid>schafer and yarowsky, 2002;<papid> W02-2026 </papid>haghighi et al, 2008) <papid> P08-1088 </papid>or by exploiting the cross-language evidence of closely related bridge?</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
languages that have more resources (mann and yarowsky, 2001).<papid> N01-1020 </papid></citsent>
<aftsection>
<nextsent>this paper investigates new ways of learning translations from monolingual corpora.
</nextsent>
<nextsent>we extend the rapp (1999) <papid> P99-1067 </papid>model of context vector projection using seed lexicon.</nextsent>
<nextsent>it is based on the intuition that translations will have similar lexical context, even in unrelated corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1172">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>haghighi et al, (2008) <papid> P08-1088 </papid>made use of contextual and orthographic clues for learning generative model from monolingual corpora and seed lexicon.</prevsent>
<prevsent>all of the aforementioned work defines context similarity in terms of the adjacent words over window of some arbitary size (usually 2 to 4 words), as initially proposed by rapp (1999).<papid> P99-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we show that the model for surrounding context can be improved byusing dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (lin and pantel, 2002; pado andlapata, 2007) and the recent developments in multilingual dependency parsing literature (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>we further differentiate ourselves from previous work by conducting second evaluation which examines the accuracy of translating all word types,rather than just nouns.
</nextsent>
<nextsent>while the straightforward application of context-based model gives lower overall accuracy than nouns alone, we show how learning mapping of part-of-speech tagsets between the source and target language can result incomparable performance to that of noun translation.
</nextsent>
<nextsent>projection this section details how translations are discovered from monolingual corpora through context vector projection.
</nextsent>
<nextsent>section 3.1 defines alternative ways of modeling context vectors, and including baseline models and our dependency-based model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1173">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>haghighi et al, (2008) <papid> P08-1088 </papid>made use of contextual and orthographic clues for learning generative model from monolingual corpora and seed lexicon.</prevsent>
<prevsent>all of the aforementioned work defines context similarity in terms of the adjacent words over window of some arbitary size (usually 2 to 4 words), as initially proposed by rapp (1999).<papid> P99-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
we show that the model for surrounding context can be improved byusing dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (lin and pantel, 2002; pado andlapata, 2007) and the recent developments in multilingual dependency parsing literature (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>we further differentiate ourselves from previous work by conducting second evaluation which examines the accuracy of translating all word types,rather than just nouns.
</nextsent>
<nextsent>while the straightforward application of context-based model gives lower overall accuracy than nouns alone, we show how learning mapping of part-of-speech tagsets between the source and target language can result incomparable performance to that of noun translation.
</nextsent>
<nextsent>projection this section details how translations are discovered from monolingual corpora through context vector projection.
</nextsent>
<nextsent>section 3.1 defines alternative ways of modeling context vectors, and including baseline models and our dependency-based model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1192">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>depposn + rev ? the above depposn model applied in both directions (spanish-to-english and english-to-spanish) using their sum as the final translation score.
</prevsent>
<prevsent>we contrasted the accuracy of the above methods, which use monolingual corpora, with statistical 132model trained on bilingual parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we refer to that model as mosesen-es-100k, because it was trained using the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>4.1 training data.
</nextsent>
<nextsent>all context models were trained on spanish corpus containing 100,000 sentences with 2.13 million words and an english corpus containing 100,000sentences with 2.07 million words.
</nextsent>
<nextsent>the spanish corpus was parsed using the mst dependency parser (mcdonald et al, 2005) <papid> H05-1066 </papid>trained using dependency trees generated from the the english penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and spanish conll-x data (buchholz and marsi, 2006).<papid> W06-2920 </papid>so that we could directly compare against statistical translation models, our spanish and english monolingual corpora were drawn from the europarl parallel corpus (koehn, 2005).</nextsent>
<nextsent>the fact that our two monolingual corpora are taken from parallel corpus ensures that the assumption that similar contexts are good indicator of translation holds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1193">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 training data.
</prevsent>
<prevsent>all context models were trained on spanish corpus containing 100,000 sentences with 2.13 million words and an english corpus containing 100,000sentences with 2.07 million words.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
the spanish corpus was parsed using the mst dependency parser (mcdonald et al, 2005) <papid> H05-1066 </papid>trained using dependency trees generated from the the english penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and spanish conll-x data (buchholz and marsi, 2006).<papid> W06-2920 </papid>so that we could directly compare against statistical translation models, our spanish and english monolingual corpora were drawn from the europarl parallel corpus (koehn, 2005).</citsent>
<aftsection>
<nextsent>the fact that our two monolingual corpora are taken from parallel corpus ensures that the assumption that similar contexts are good indicator of translation holds.
</nextsent>
<nextsent>this assumption underlies in all work of translation lexicon induction from comparable monolingual corpora, and here we strongly bias toward that assumption.
</nextsent>
<nextsent>despite the bias, the comparison of different context models holds, since all models are trained on the same data.
</nextsent>
<nextsent>4.2 evaluation criterion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1194">
<title id=" W09-1117.xml">improving translation lexicon induction from monolingual corpora via dependency contexts and partofspeech equivalences </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 training data.
</prevsent>
<prevsent>all context models were trained on spanish corpus containing 100,000 sentences with 2.13 million words and an english corpus containing 100,000sentences with 2.07 million words.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the spanish corpus was parsed using the mst dependency parser (mcdonald et al, 2005) <papid> H05-1066 </papid>trained using dependency trees generated from the the english penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and spanish conll-x data (buchholz and marsi, 2006).<papid> W06-2920 </papid>so that we could directly compare against statistical translation models, our spanish and english monolingual corpora were drawn from the europarl parallel corpus (koehn, 2005).</citsent>
<aftsection>
<nextsent>the fact that our two monolingual corpora are taken from parallel corpus ensures that the assumption that similar contexts are good indicator of translation holds.
</nextsent>
<nextsent>this assumption underlies in all work of translation lexicon induction from comparable monolingual corpora, and here we strongly bias toward that assumption.
</nextsent>
<nextsent>despite the bias, the comparison of different context models holds, since all models are trained on the same data.
</nextsent>
<nextsent>4.2 evaluation criterion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1217">
<title id=" W08-1702.xml">making speech look like text in the regulus development environment </title>
<section> the regulus platform.  </section>
<citcontext>
<prevsection>
<prevsent>the regulus platform is comprehensive toolkit for developing grammar-based speech-enabledsystems that can be run on the commercially available nuance recognition environment.
</prevsent>
<prevsent>the platform has been developed by an open source consortium, the main partners of which have been nasa ames research center and geneva university, and is freely available for download from the source forge website1.
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
in terms of ideas (thoughnot code), regulus is descend ent of sri internationals cle and gemini platforms (alshawi, 1992; dowding et al, 1993); <papid> P93-1008 </papid>other related systems are lkb (copestake, 2002), xle (crouch et al, 2008) and uniance (bos, 2002).<papid> C02-1095 </papid>regulus has already been used to build several large applications.</citsent>
<aftsection>
<nextsent>prominent examples are geneva universitys medslt medical speech translator (bouillon et al, 2005), nasas clarissa procedure browser (rayner et al, 2005) <papid> P05-3008 </papid>and ford researchs experimental sds in-car spoken dialogue system, which was awarded first prize atthe 2007 ford internal demo fair.</nextsent>
<nextsent>regulus is described at length in (rayner et al, 2006), the first half of which consists of an extended tutorial in troduction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1218">
<title id=" W08-1702.xml">making speech look like text in the regulus development environment </title>
<section> the regulus platform.  </section>
<citcontext>
<prevsection>
<prevsent>the regulus platform is comprehensive toolkit for developing grammar-based speech-enabledsystems that can be run on the commercially available nuance recognition environment.
</prevsent>
<prevsent>the platform has been developed by an open source consortium, the main partners of which have been nasa ames research center and geneva university, and is freely available for download from the source forge website1.
</prevsent>
</prevsection>
<citsent citstr=" C02-1095 ">
in terms of ideas (thoughnot code), regulus is descend ent of sri internationals cle and gemini platforms (alshawi, 1992; dowding et al, 1993); <papid> P93-1008 </papid>other related systems are lkb (copestake, 2002), xle (crouch et al, 2008) and uniance (bos, 2002).<papid> C02-1095 </papid>regulus has already been used to build several large applications.</citsent>
<aftsection>
<nextsent>prominent examples are geneva universitys medslt medical speech translator (bouillon et al, 2005), nasas clarissa procedure browser (rayner et al, 2005) <papid> P05-3008 </papid>and ford researchs experimental sds in-car spoken dialogue system, which was awarded first prize atthe 2007 ford internal demo fair.</nextsent>
<nextsent>regulus is described at length in (rayner et al, 2006), the first half of which consists of an extended tutorial in troduction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1219">
<title id=" W08-1702.xml">making speech look like text in the regulus development environment </title>
<section> the regulus platform.  </section>
<citcontext>
<prevsection>
<prevsent>the platform has been developed by an open source consortium, the main partners of which have been nasa ames research center and geneva university, and is freely available for download from the source forge website1.
</prevsent>
<prevsent>in terms of ideas (thoughnot code), regulus is descend ent of sri internationals cle and gemini platforms (alshawi, 1992; dowding et al, 1993); <papid> P93-1008 </papid>other related systems are lkb (copestake, 2002), xle (crouch et al, 2008) and uniance (bos, 2002).<papid> C02-1095 </papid>regulus has already been used to build several large applications.</prevsent>
</prevsection>
<citsent citstr=" P05-3008 ">
prominent examples are geneva universitys medslt medical speech translator (bouillon et al, 2005), nasas clarissa procedure browser (rayner et al, 2005) <papid> P05-3008 </papid>and ford researchs experimental sds in-car spoken dialogue system, which was awarded first prize atthe 2007 ford internal demo fair.</citsent>
<aftsection>
<nextsent>regulus is described at length in (rayner et al, 2006), the first half of which consists of an extended tutorial introduction.
</nextsent>
<nextsent>the release includes command-linedevelopment environment, extensive online documentation, and several example applications.
</nextsent>
<nextsent>the core functionality offered by regulus is compilation of typed unification grammars into parsers, generators, and nuance-formatted cfg language models, and hence also into nuance recognition packages.
</nextsent>
<nextsent>these recognition packages produced by regulus can be invoked through theregulus speech server (regserver?), which provides an interface to the underlying nuance recognition engine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1220">
<title id=" W08-1702.xml">making speech look like text in the regulus development environment </title>
<section> the regulus development cycle.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, once the commands for the text view have been mastered, there is certain temptation to consider that these are enough, since the text and speech views can reasonably be perceived as fairly similar.in the next two sections, we describe an enhanced development environment for regulus, which addresses the key problems we have just sketched.
</prevsent>
<prevsent>from the point of view of the linguist rule-writer, we want speech-based development to feel more like text-based development.
</prevsent>
</prevsection>
<citsent citstr=" W07-1807 ">
development environment the regulus gui (kron et al, 2007) <papid> W07-1807 </papid>is intend edas complete redesign of the development environment, which simultaneously attacks all of the central issues.</citsent>
<aftsection>
<nextsent>commands are organised in structured set of functionality-based windows, each of which has an appropriate set of drop-down menus.
</nextsent>
<nextsent>following normal gui design practice (dix et al, 1998, chapters 3 and 4); (jacko and sears, 2003, chapter 13), only currently meaningful commands are executable in each menu, with the others shown greyed out.
</nextsent>
<nextsent>both compile-time and run-time speech-related functionality can be invoked directly from the command menus, with no need for external scripts, make files or glue code.
</nextsent>
<nextsent>focussing for the moment on the specific case of developing speech translation application, the rule-writer will initially write and debug her rules in text mode.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1223">
<title id=" W08-1702.xml">making speech look like text in the regulus development environment </title>
<section> the regulus development cycle.  </section>
<citcontext>
<prevsection>
<prevsent>the application is defined by config file which combines japanese recogniser and analysis grammar, japanese to interlingua and interlingua to arabic translation rules, an arabic generation grammar, and recorded arabic wavfiles used to construct spoken result.
</prevsent>
<prevsent>and miller, 2007) will also receive asynchronous inputs from the robot control and monitoring pro cess; once again, all inputs have to be processed in the appropriate temporal order.
</prevsent>
</prevsection>
<citsent citstr=" W07-1806 ">
a third example is contextual bidirectional speech translation (bouil lon et al, 2007).<papid> W07-1806 </papid></citsent>
<aftsection>
<nextsent>here, the problem is slightly different ? we have only speech inputs, but they are for two different languages.
</nextsent>
<nextsent>the basic issue, however, remains the same, since inputs have to be processed in the right order to maintain the correct context at each point.
</nextsent>
<nextsent>with examples like these in mind, we have also effected complete redesign of the regulus environments regression testing facilities.
</nextsent>
<nextsent>a test suite is now allowed to consist of list of items of any type ? text, wavfile, or non-speech input ? in any order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1224">
<title id=" W08-1702.xml">making speech look like text in the regulus development environment </title>
<section> the regulus development cycle.  </section>
<citcontext>
<prevsection>
<prevsent>at risk of stating the obvious, it is also worth pointing out that many users, particularly younger ones who have grown up using windows and mac environments, expect as matter of course that development platforms will be gui-based rather thancommand-line.
</prevsent>
<prevsent>addressing this issue, and simplifying the transition between text- and speech based, views has the pleasant consequence of improving regulus as vehicle for introducing linguistics students to speech technology.
</prevsent>
</prevsection>
<citsent citstr=" W08-0210 ">
an initial regulus-based course at the university of santacruz, focussing on spoken dialogue systems, is described in (hockey and christian, 2008); <papid> W08-0210 </papid>similar one, but oriented towards speech translation and using the new top-level described here, is currently under way at the university of geneva.</citsent>
<aftsection>
<nextsent>we expect to present this in detail in later paper.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1225">
<title id=" W09-0806.xml">automatic treebank based acquisition of arabic lfg dependency structures </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" L08-1246 ">
a number of papers have reported on methods for the automatic acquisition of large-scale, probabilistic lfg-based grammatical resources from treebanks for english (cahill and al., 2002), (cahill and al., 2004), german (cahill and al., 2003), chinese (burke, 2004), (guo and al., 2007), spanish (odonovan, 2004), (chrupala and van genabith, 2006) and french (schluter and van genabith, 2008).<papid> L08-1246 </papid></citsent>
<aftsection>
<nextsent>here, we extend the lfg grammar acquisition approach to arabic and the penn arabic treebank (atb) (maamouri andbies, 2004), <papid> W04-1602 </papid>adapting and extending the methodology of (cahill and al., 2004) originally developed for english.</nextsent>
<nextsent>arabic is challenging because of its morphological richness and syntactic complexity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1227">
<title id=" W09-0806.xml">automatic treebank based acquisition of arabic lfg dependency structures </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>a number of papers have reported on methods for the automatic acquisition of large-scale, probabilistic lfg-based grammatical resources from treebanks for english (cahill and al., 2002), (cahill and al., 2004), german (cahill and al., 2003), chinese (burke, 2004), (guo and al., 2007), spanish (odonovan, 2004), (chrupala and van genabith, 2006) and french (schluter and van genabith, 2008).<papid> L08-1246 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-1602 ">
here, we extend the lfg grammar acquisition approach to arabic and the penn arabic treebank (atb) (maamouri andbies, 2004), <papid> W04-1602 </papid>adapting and extending the methodology of (cahill and al., 2004) originally developed for english.</citsent>
<aftsection>
<nextsent>arabic is challenging because of its morphological richness and syntactic complexity.
</nextsent>
<nextsent>currently 98% of atb trees (without frag and x) produce covering and connected f-structure.we conduct qualitative evaluation of our annotation against gold standard and achieve an f-score of 95%.
</nextsent>
<nextsent>treebank-based statistical parsers tend to achieve greater coverage and robustness compared to approaches using handcrafted grammars.
</nextsent>
<nextsent>however, they are criticised for being too shallow to mark important syntactic and semantic dependencies needed for meaning-sensitive applications (ka plan, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1228">
<title id=" W09-0806.xml">automatic treebank based acquisition of arabic lfg dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to treat this deficiency, number of researchers have concentrated on enriching shallow parsers with deep dependency information.
</prevsent>
<prevsent>(cahill and al., 2002), (cahill and al., 2004) outlined an approach which exploits information encoded in the penn-ii treebank (ptb) trees to automatically annotate each node in each tree with lfg f-structure equations representing deep predicate-argument structure relations.
</prevsent>
</prevsection>
<citsent citstr=" P06-1130 ">
from this lfg annotated treebank, large-scale unification grammar resources were automatically extracted and used in parsing (cahill and al., 2008) and generation (cahill and van genabith, 2006).<papid> P06-1130 </papid></citsent>
<aftsection>
<nextsent>this approach was subsequently extended to other languages including german (cahill and al., 2003), chinese (burke, 2004), (guo and al., 2007), spanish (odonovan, 2004), (chrupala and van genabith, 2006) and french (schluter and van genabith, 2008).<papid> L08-1246 </papid></nextsent>
<nextsent>arabic is semitic language and is well-known for its morphological richness and syntactic complexity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1236">
<title id=" W08-0913.xml">diagnosing meaning errors in short answers to reading comprehension questions </title>
<section> multiple incorrect concepts..  </section>
<citcontext>
<prevsection>
<prevsent>thus, response generally contains multiple concepts.
</prevsent>
<prevsent>3note the incorrect pre supposition in the cue provided by the instructor.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
109 machine translation evaluation (e.g., banerjee andlavie, 2005; <papid> W05-0909 </papid>lin and och, 2004), <papid> P04-1077 </papid>paraphrase recognition (e.g., brockett and dolan, 2005; <papid> I05-5001 </papid>hatzivassiloglou et al, 1999), <papid> W99-0625 </papid>and automatic grading (e.g., leacock, 2004; marn, 2004).to illustrate the general idea, consider the example from our corpus in figure 2.</citsent>
<aftsection>
<nextsent>figure 2: basic matching example we find one string identical match between the token was occurring in the target and the learner response.
</nextsent>
<nextsent>at the noun chunk level we can match home with his house.
</nextsent>
<nextsent>and finally, after pronoun resolution it is possible to match bob hope with he.the overall architecture of cam is shown in figure 3.
</nextsent>
<nextsent>generally speaking, cam compares the learner response to stored target response and decides whether the two responses are possibly different realizations of the same semantic content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1237">
<title id=" W08-0913.xml">diagnosing meaning errors in short answers to reading comprehension questions </title>
<section> multiple incorrect concepts..  </section>
<citcontext>
<prevsection>
<prevsent>thus, response generally contains multiple concepts.
</prevsent>
<prevsent>3note the incorrect pre supposition in the cue provided by the instructor.
</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
109 machine translation evaluation (e.g., banerjee andlavie, 2005; <papid> W05-0909 </papid>lin and och, 2004), <papid> P04-1077 </papid>paraphrase recognition (e.g., brockett and dolan, 2005; <papid> I05-5001 </papid>hatzivassiloglou et al, 1999), <papid> W99-0625 </papid>and automatic grading (e.g., leacock, 2004; marn, 2004).to illustrate the general idea, consider the example from our corpus in figure 2.</citsent>
<aftsection>
<nextsent>figure 2: basic matching example we find one string identical match between the token was occurring in the target and the learner response.
</nextsent>
<nextsent>at the noun chunk level we can match home with his house.
</nextsent>
<nextsent>and finally, after pronoun resolution it is possible to match bob hope with he.the overall architecture of cam is shown in figure 3.
</nextsent>
<nextsent>generally speaking, cam compares the learner response to stored target response and decides whether the two responses are possibly different realizations of the same semantic content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1238">
<title id=" W08-0913.xml">diagnosing meaning errors in short answers to reading comprehension questions </title>
<section> multiple incorrect concepts..  </section>
<citcontext>
<prevsection>
<prevsent>thus, response generally contains multiple concepts.
</prevsent>
<prevsent>3note the incorrect pre supposition in the cue provided by the instructor.
</prevsent>
</prevsection>
<citsent citstr=" I05-5001 ">
109 machine translation evaluation (e.g., banerjee andlavie, 2005; <papid> W05-0909 </papid>lin and och, 2004), <papid> P04-1077 </papid>paraphrase recognition (e.g., brockett and dolan, 2005; <papid> I05-5001 </papid>hatzivassiloglou et al, 1999), <papid> W99-0625 </papid>and automatic grading (e.g., leacock, 2004; marn, 2004).to illustrate the general idea, consider the example from our corpus in figure 2.</citsent>
<aftsection>
<nextsent>figure 2: basic matching example we find one string identical match between the token was occurring in the target and the learner response.
</nextsent>
<nextsent>at the noun chunk level we can match home with his house.
</nextsent>
<nextsent>and finally, after pronoun resolution it is possible to match bob hope with he.the overall architecture of cam is shown in figure 3.
</nextsent>
<nextsent>generally speaking, cam compares the learner response to stored target response and decides whether the two responses are possibly different realizations of the same semantic content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1239">
<title id=" W08-0913.xml">diagnosing meaning errors in short answers to reading comprehension questions </title>
<section> multiple incorrect concepts..  </section>
<citcontext>
<prevsection>
<prevsent>thus, response generally contains multiple concepts.
</prevsent>
<prevsent>3note the incorrect pre supposition in the cue provided by the instructor.
</prevsent>
</prevsection>
<citsent citstr=" W99-0625 ">
109 machine translation evaluation (e.g., banerjee andlavie, 2005; <papid> W05-0909 </papid>lin and och, 2004), <papid> P04-1077 </papid>paraphrase recognition (e.g., brockett and dolan, 2005; <papid> I05-5001 </papid>hatzivassiloglou et al, 1999), <papid> W99-0625 </papid>and automatic grading (e.g., leacock, 2004; marn, 2004).to illustrate the general idea, consider the example from our corpus in figure 2.</citsent>
<aftsection>
<nextsent>figure 2: basic matching example we find one string identical match between the token was occurring in the target and the learner response.
</nextsent>
<nextsent>at the noun chunk level we can match home with his house.
</nextsent>
<nextsent>and finally, after pronoun resolution it is possible to match bob hope with he.the overall architecture of cam is shown in figure 3.
</nextsent>
<nextsent>generally speaking, cam compares the learner response to stored target response and decides whether the two responses are possibly different realizations of the same semantic content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1240">
<title id=" W08-0913.xml">diagnosing meaning errors in short answers to reading comprehension questions </title>
<section> multiple incorrect concepts..  </section>
<citcontext>
<prevsection>
<prevsent>table 1 contains an overview of the annotations and the resources, tools or algorithms used.
</prevsent>
<prevsent>the choice of the particular algorithm or implementation was primarily based on availability and performance on our development corpus ? other implementations could generally be substituted without changing the overall approach.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
annotation task language processing tool sentence detection, monty lingua (liu, 2004) tokenization, lemmatization lemmatization pc-kimmo (antworth, 1993) spell checking edit distance (levenshtein, 1966), scowl word list (atkinson, 2004) part-of-speech tagging tree tagger (schmid, 1994) noun phrase chunking cass (abney, 1997) lexical relations wordnet (miller, 1995) similarity scores pmi-ir (turney, 2001; mihalcea et al, 2006) dependency relations stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>table 1: nlp tools used in cam after the annotation phase, alignment maps new (i.e., not given) concepts in the learner response to concepts in the target response using the annotated information.</citsent>
<aftsection>
<nextsent>the final diagnosis phase analyzes the alignment to determine whether the learner re 110 annotation alignment diagnosis punctuation input learner response target response(s) question output source text activity model settings sentence detection tokenization lemmatization pos tagging chunking dependency parsing spelling correction similarity scoring pronoun resolution type recognition analysis filter givenness pre-alignment filters token-level alignment chunk-level alignment relation-level alignment error reporting detection classification diagnosis classification figure 3: architecture of the content assessment module (cam)sponse contains content errors.
</nextsent>
<nextsent>if multiple target responses are supplied, then each is compared to the learner response and the target response with themost matches is selected as the model used in diagnosis.
</nextsent>
<nextsent>the output is diagnosis of the input pair, which might be used in number of ways to provide feedback to the learner.
</nextsent>
<nextsent>3.1 combining the evidence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1242">
<title id=" W08-0913.xml">diagnosing meaning errors in short answers to reading comprehension questions </title>
<section> l-chunk percent of aligned learner chunks </section>
<citcontext>
<prevsection>
<prevsent>icall system designs that do incorporate more sophisticated content assessment include free text (lhaire and faltin, 2003), the military language tutor (milt) program (kaplan et al, 1998), and herr kommissar (desmedt, 1995).
</prevsent>
<prevsent>these systems restrict both the exercise types and domains to make content assessment feasible using deeper semantic processing strategies.
</prevsent>
</prevsection>
<citsent citstr=" W99-0411 ">
beyond the icall domain, work in automatic grading of short answers and essays has addressed whether the students answers convey the correct meaning, but these systems focus on largely scoring rather than diagnosis (e.g., e-rater, burstein and chodorow, 1999), <papid> W99-0411 </papid>do not specifically address language learning contexts and/or are designed towork specifically with longer texts (e.g., autotu tor, wiemer-hastings et al, 1999).</citsent>
<aftsection>
<nextsent>thus, the extent to which icall systems can diagnose meaning errors in language learner responses has been far from clear.
</nextsent>
<nextsent>as far as we are aware, no directly comparable systems performing content-assessment on related language learner data exist.
</nextsent>
<nextsent>the closest related system that does similar kind of detection is the rater system (leacock, 2004).
</nextsent>
<nextsent>that system obtains85% accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1243">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P89-1009 ">
many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context.a solution to this problem has been initially proposed by dale (1989) <papid> P89-1009 </papid>in termsof distinguishing descriptions and distinguishable entities.</citsent>
<aftsection>
<nextsent>in this paper, we givea formal definition of the terms distinguishable entity?
</nextsent>
<nextsent>in non trivial cases and we show that its properties lead us to the definition of distance between entities.
</nextsent>
<nextsent>then, we give polynomial algorithm to compute distinguishing descriptions.
</nextsent>
<nextsent>many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context (dale, 1989; <papid> P89-1009 </papid>dale and haddock, 1991; <papid> E91-1028 </papid>dale and reiter, 1995; van deemter,2002; krahmer et al, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2003), <papid> E03-1017 </papid>and more recently (viethen and dale, 2006; <papid> W06-1410 </papid>gatt and van deemter, 2006; <papid> P06-2033 </papid>croitoru and van deemter, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1245">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in non trivial cases and we show that its properties lead us to the definition of distance between entities.
</prevsent>
<prevsent>then, we give polynomial algorithm to compute distinguishing descriptions.
</prevsent>
</prevsection>
<citsent citstr=" E91-1028 ">
many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context (dale, 1989; <papid> P89-1009 </papid>dale and haddock, 1991; <papid> E91-1028 </papid>dale and reiter, 1995; van deemter,2002; krahmer et al, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2003), <papid> E03-1017 </papid>and more recently (viethen and dale, 2006; <papid> W06-1410 </papid>gatt and van deemter, 2006; <papid> P06-2033 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>following dale (1989),<papid> P89-1009 </papid>these definite descriptions are named distinguishing descriptions?.</nextsent>
<nextsent>informally, distinguishing description is definite description which designates one and only one entity among others in contextset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1246">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in non trivial cases and we show that its properties lead us to the definition of distance between entities.
</prevsent>
<prevsent>then, we give polynomial algorithm to compute distinguishing descriptions.
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context (dale, 1989; <papid> P89-1009 </papid>dale and haddock, 1991; <papid> E91-1028 </papid>dale and reiter, 1995; van deemter,2002; krahmer et al, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2003), <papid> E03-1017 </papid>and more recently (viethen and dale, 2006; <papid> W06-1410 </papid>gatt and van deemter, 2006; <papid> P06-2033 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>following dale (1989),<papid> P89-1009 </papid>these definite descriptions are named distinguishing descriptions?.</nextsent>
<nextsent>informally, distinguishing description is definite description which designates one and only one entity among others in contextset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1247">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in non trivial cases and we show that its properties lead us to the definition of distance between entities.
</prevsent>
<prevsent>then, we give polynomial algorithm to compute distinguishing descriptions.
</prevsent>
</prevsection>
<citsent citstr=" E03-1017 ">
many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context (dale, 1989; <papid> P89-1009 </papid>dale and haddock, 1991; <papid> E91-1028 </papid>dale and reiter, 1995; van deemter,2002; krahmer et al, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2003), <papid> E03-1017 </papid>and more recently (viethen and dale, 2006; <papid> W06-1410 </papid>gatt and van deemter, 2006; <papid> P06-2033 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>following dale (1989),<papid> P89-1009 </papid>these definite descriptions are named distinguishing descriptions?.</nextsent>
<nextsent>informally, distinguishing description is definite description which designates one and only one entity among others in contextset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1248">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in non trivial cases and we show that its properties lead us to the definition of distance between entities.
</prevsent>
<prevsent>then, we give polynomial algorithm to compute distinguishing descriptions.
</prevsent>
</prevsection>
<citsent citstr=" W06-1410 ">
many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context (dale, 1989; <papid> P89-1009 </papid>dale and haddock, 1991; <papid> E91-1028 </papid>dale and reiter, 1995; van deemter,2002; krahmer et al, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2003), <papid> E03-1017 </papid>and more recently (viethen and dale, 2006; <papid> W06-1410 </papid>gatt and van deemter, 2006; <papid> P06-2033 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>following dale (1989),<papid> P89-1009 </papid>these definite descriptions are named distinguishing descriptions?.</nextsent>
<nextsent>informally, distinguishing description is definite description which designates one and only one entity among others in contextset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1249">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in non trivial cases and we show that its properties lead us to the definition of distance between entities.
</prevsent>
<prevsent>then, we give polynomial algorithm to compute distinguishing descriptions.
</prevsent>
</prevsection>
<citsent citstr=" P06-2033 ">
many studies in natural language processing are concerned with how to generate definite descriptions that evoke discourse entity already introduced in the context (dale, 1989; <papid> P89-1009 </papid>dale and haddock, 1991; <papid> E91-1028 </papid>dale and reiter, 1995; van deemter,2002; krahmer et al, 2002; gardent, 2002; <papid> P02-1013 </papid>horacek, 2003), <papid> E03-1017 </papid>and more recently (viethen and dale, 2006; <papid> W06-1410 </papid>gatt and van deemter, 2006; <papid> P06-2033 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>following dale (1989),<papid> P89-1009 </papid>these definite descriptions are named distinguishing descriptions?.</nextsent>
<nextsent>informally, distinguishing description is definite description which designates one and only one entity among others in contextset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1253">
<title id=" W09-0606.xml">distinguishable entities definitions and properties </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so, even if the formula on(-, t1) is formally different from the formula on(-, t2) and b1 satisfies the first one and not the second one, that does not imply that b1 is distinguishable from b2.so, the fact is that to determine if b1 is distinguishable from b2, knowing that the set of properties of b1 is true for b1 and not for b2 is not sufficient: we have to determine if t1 is distinguishable from t2.
</prevsent>
<prevsent>that clearly leads to non-trivial recursive definition and non-trivial recursive processes.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
two recent works describe algorithms that deal with this problem (krahmer et al, 2003; <papid> J03-1003 </papid>croitoru and van deemter, 2007).</citsent>
<aftsection>
<nextsent>their works are both based on graph theory and their algorithms deal well with the non-unary case, but their computations need exponential time.in this paper, our main goal is to give definition of distinguishable entity which corresponds to the intuitive sense and which works well even in non-trivial cases.
</nextsent>
<nextsent>then we study its properties, which leads us to an interesting notion of distance between entities.
</nextsent>
<nextsent>finally, we give polynomial algorithm able to produce distinguishing description whenever it is possible and which is based on this definition.
</nextsent>
<nextsent>intuitively, an entity e1 is distinguishable from an entity e2 in two cases: ? e1 involves properties that are not involved by e2 (we will say that e1 is 0-distinguishable from e2) ? otherwise, e1 and e2 are in relations (we will precisely see how below) with at least two distinguishable entities e1 and e2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1254">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (eck et al, 2004) adaptation is limited to the target language model (lm).
</prevsent>
<prevsent>the background lm is combined with one estimated on documents retrieved from the web by using the input sentence as query and applying cross language information retrieval techniques.
</prevsent>
</prevsection>
<citsent citstr=" C04-1059 ">
refinements of this approach are described in (zhao et al., 2004).<papid> C04-1059 </papid></citsent>
<aftsection>
<nextsent>in (hildebrand et al, 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences.
</nextsent>
<nextsent>both the language and the translation models are retrained on the extracted data.
</nextsent>
<nextsent>in (foster and kuhn, 2007) <papid> W07-0717 </papid>two basic settings are investigated: cross-domain adaptation, in whicha small sample of parallel in-domain text is assumed, and dynamic adaptation, in which onlythe current input source text is considered.</nextsent>
<nextsent>adaptation relies on mixture models estimated on the training data through some unsupervised clustering method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1255">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (hildebrand et al, 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences.
</prevsent>
<prevsent>both the language and the translation models are retrained on the extracted data.
</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
in (foster and kuhn, 2007) <papid> W07-0717 </papid>two basic settings are investigated: cross-domain adaptation, in whicha small sample of parallel in-domain text is assumed, and dynamic adaptation, in which onlythe current input source text is considered.</citsent>
<aftsection>
<nextsent>adaptation relies on mixture models estimated on the training data through some unsupervised clustering method.
</nextsent>
<nextsent>given available adaptation data, mixture weights are re-estimated ad-hoc.
</nextsent>
<nextsent>a variation of this approach was also recently proposed in (finch and sumita, 2008).<papid> W08-0334 </papid></nextsent>
<nextsent>in (civera and juan, 2007) <papid> W07-0722 </papid>mixture models are instead employed toadapt word alignment model to in-domain parallel data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1256">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>adaptation relies on mixture models estimated on the training data through some unsupervised clustering method.
</prevsent>
<prevsent>given available adaptation data, mixture weights are re-estimated ad-hoc.
</prevsent>
</prevsection>
<citsent citstr=" W08-0334 ">
a variation of this approach was also recently proposed in (finch and sumita, 2008).<papid> W08-0334 </papid></citsent>
<aftsection>
<nextsent>in (civera and juan, 2007) <papid> W07-0722 </papid>mixture models are instead employed toadapt word alignment model to in-domain parallel data.</nextsent>
<nextsent>in (koehn and schroeder, 2007) <papid> W07-0733 </papid>cross-domainadaptation techniques were applied on phrase based smt trained on the europarl task, in order to translate news commentaries, from french to english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1257">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>given available adaptation data, mixture weights are re-estimated ad-hoc.
</prevsent>
<prevsent>a variation of this approach was also recently proposed in (finch and sumita, 2008).<papid> W08-0334 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0722 ">
in (civera and juan, 2007) <papid> W07-0722 </papid>mixture models are instead employed toadapt word alignment model to in-domain parallel data.</citsent>
<aftsection>
<nextsent>in (koehn and schroeder, 2007) <papid> W07-0733 </papid>cross-domainadaptation techniques were applied on phrase based smt trained on the europarl task, in order to translate news commentaries, from french to english.</nextsent>
<nextsent>in particular, small portion of in domain bilingual data was exploited to adapt the europarl language model and translation models by means of linear interpolation techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1258">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>a variation of this approach was also recently proposed in (finch and sumita, 2008).<papid> W08-0334 </papid></prevsent>
<prevsent>in (civera and juan, 2007) <papid> W07-0722 </papid>mixture models are instead employed toadapt word alignment model to in-domain parallel data.</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
in (koehn and schroeder, 2007) <papid> W07-0733 </papid>cross-domainadaptation techniques were applied on phrase based smt trained on the europarl task, in order to translate news commentaries, from french to english.</citsent>
<aftsection>
<nextsent>in particular, small portion of in domain bilingual data was exploited to adapt the europarl language model and translation models by means of linear interpolation techniques.
</nextsent>
<nextsent>ueffing et al (2007) proposed several elaborate adaptation methods relying on additional bilingual data synthesized from the development or test set.
</nextsent>
<nextsent>our work is mostly related to (koehn and schroeder, 2007) <papid> W07-0733 </papid>but explores different assumptions about available adaptation data: i.e. only monolingual in-domain texts are available.</nextsent>
<nextsent>the adaptation of the translation and re-ordering models is performed by generating synthetic bilingual data from monolingual texts, similarly to what proposed in (schwenk, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1261">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>is it convenient to combine models learned from adaptation data with models learned from training data??
</prevsent>
<prevsent>how can interpolation of models be effectively learned from small amounts of in domain parallel data?
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the investigation presented in this paper was carried out with the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>state-of-the-art open-source phrase-basedsmt system.</citsent>
<aftsection>
<nextsent>we trained moses in standard configuration, including 4-feature translation model, 7-feature lexicalized re-ordering model, one lm, word and phrase penalties.the translation and the re-ordering model relied on grow-diag-final?
</nextsent>
<nextsent>symmetrized word-to word alignments built using giza++ (och and ney, 2003) <papid> J03-1002 </papid>and the training script of moses.</nextsent>
<nextsent>a5-gram language model was trained on the target side of the training parallel corpus using the irstlm toolkit (federico et al, 2008), exploiting modified kneser-ney smoothing, and quantizing both probabilities and backoff weights.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1262">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the investigation presented in this paper was carried out with the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>state-of-the-art open-source phrase-basedsmt system.</prevsent>
<prevsent>we trained moses in standard configuration, including 4-feature translation model, 7-feature lexicalized re-ordering model, one lm, word and phrase penalties.the translation and the re-ordering model relied on grow-diag-final?</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
symmetrized word-to word alignments built using giza++ (och and ney, 2003) <papid> J03-1002 </papid>and the training script of moses.</citsent>
<aftsection>
<nextsent>a5-gram language model was trained on the target side of the training parallel corpus using the irstlm toolkit (federico et al, 2008), exploiting modified kneser-ney smoothing, and quantizing both probabilities and backoff weights.
</nextsent>
<nextsent>decoding was performed applying cube-pruning with pop limit of 6000 hypotheses.
</nextsent>
<nextsent>log-linear interpol ations of feature functions were estimated with the parallel version of minimum error rate training procedure distributed with moses.
</nextsent>
<nextsent>4.1 fast training from synthetic data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1265">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>in these undefined situations, moses provides default value of0, which is the highest available score, as the feature values come from probabilistic distributions and are expressed as logarithms.
</prevsent>
<prevsent>henceforth, aphrase pair belonging to all original sets is penalized with respect to phrase pairs belonging to few of them only.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
to address this drawback, we proposed new method3 to compute more reliable and smoothed score in the undefined case, based on the ibm model 1 (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>if (f? = f1, . . .
</nextsent>
<nextsent>, fl, e?
</nextsent>
<nextsent>= e1, . . .
</nextsent>
<nextsent>, el) ? su \ sj for any the 3authors are not aware of any work addressing this issue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1266">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in this way, we created two synthetic versions of the ep corpus, named se?-ep and se ep, respectively.
</prevsent>
<prevsent>all presented translation systems were optimized on the dev2006 set with respect to4distributed by the linguistic data consortium, catalogue # ldc94t4a.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
5http://www.statmt.org/wmt08 185 the bleu score (papineni et al, 2002), <papid> P02-1040 </papid>and tested on test2008.</citsent>
<aftsection>
<nextsent>(notice that one reference translation is available for both sets.)
</nextsent>
<nextsent>table 1 reports statistics of original and synthetic parallel corpora, as well of the employed development and evaluation datasets.
</nextsent>
<nextsent>all the texts were just tokenized and mixed case was kept.
</nextsent>
<nextsent>hence, all systems were developed to produce case-sensitive translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1269">
<title id=" W09-0432.xml">domain adaptation for statistical machine translation with monolingual resources </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>notice that decoding time is not included in this plot, as moses allows to perform this step in parallel on computer cluster.
</prevsent>
<prevsent>hence, to our viewthe real bottleneck of the tuning process is actually related to the strictly serial part of the mert implementation of moses.
</prevsent>
</prevsection>
<citsent citstr=" D08-1076 ">
as already observed in previous literature(macherey et al, 2008), <papid> D08-1076 </papid>first iterations of the tuning process produces very bad weights (even closeto 0); this exceptional performance drop is attributed to an over-fitting on the candidate reposi tory.configurations exploiting the small development set (c,d) show slower and more unstable convergence; however, their final performance intable 3 result only slightly lower than that obtained with the standard dev sets (a, b).</citsent>
<aftsection>
<nextsent>due to the larger number of iterations they needed, both configurations are indeed more time consuming than the intermediate configuration (b), which seems the best one.
</nextsent>
<nextsent>in conclusion, we found that the size of the n-best list has essentially no effect on thequality of the final weights, but it impacts significantly on the computational time.
</nextsent>
<nextsent>moreover, using the regular development set with few translation alternatives ends up to be the most efficient 187configuration in terms of computational effort, robustness, and performance.our analysis suggests that it is important to dispose of sufficiently large development set although reasonably good weights can be obtained even if such data are very few.
</nextsent>
<nextsent>5.4 lm adaptation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1270">
<title id=" W08-2104.xml">linguistic features in data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this article investigates the effect of setof linguistically motivated features on argument disambiguation in data-driven dependency parsing of swedish.
</prevsent>
<prevsent>we present results from experiments with gold standard features, such as animacy, definite ness and finite ness, as well as corresponding experiments where these features have been acquired automatically and show significant improvements both in overall parse results and in the analysis of specific argument relations, such as subjects, objects and predicatives.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
data-driven dependency parsing has recently received extensive attention in the parsing community and impressive results have been obtained for range of languages (nivre et al , 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>even with high overall parsing accuracy, however, data driven parsers often make errors in the assignment of argument relations such as subject and object and the exact influence of data-derived features on the parsing accuracy for specific linguistic constructions is still relatively poorly understood.
</nextsent>
<nextsent>there are number of studies that investigate the influence of different features or representational choices on overall parsing accuracy, (bod, 1998; klein and manning, 2003).<papid> P03-1054 </papid></nextsent>
<nextsent>there are also attempt sat more fine-grained analysis of accuracy, targeting specific linguistic constructions or grammatical functions (carroll and briscoe, 2002; <papid> C02-1013 </papid>kubler and prokic?, 2006; mcdonald and nivre, 2007).<papid> D07-1013 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1271">
<title id=" W08-2104.xml">linguistic features in data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data-driven dependency parsing has recently received extensive attention in the parsing community and impressive results have been obtained for range of languages (nivre et al , 2007).<papid> D07-1096 </papid></prevsent>
<prevsent>even with high overall parsing accuracy, however, data driven parsers often make errors in the assignment of argument relations such as subject and object and the exact influence of data-derived features on the parsing accuracy for specific linguistic constructions is still relatively poorly understood.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
there are number of studies that investigate the influence of different features or representational choices on overall parsing accuracy, (bod, 1998; klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>there are also attempt sat more fine-grained analysis of accuracy, targeting specific linguistic constructions or grammatical functions (carroll and briscoe, 2002; <papid> C02-1013 </papid>kubler and prokic?, 2006; mcdonald and nivre, 2007).<papid> D07-1013 </papid></nextsent>
<nextsent>c ? 2008.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1272">
<title id=" W08-2104.xml">linguistic features in data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even with high overall parsing accuracy, however, data driven parsers often make errors in the assignment of argument relations such as subject and object and the exact influence of data-derived features on the parsing accuracy for specific linguistic constructions is still relatively poorly understood.
</prevsent>
<prevsent>there are number of studies that investigate the influence of different features or representational choices on overall parsing accuracy, (bod, 1998; klein and manning, 2003).<papid> P03-1054 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1013 ">
there are also attempt sat more fine-grained analysis of accuracy, targeting specific linguistic constructions or grammatical functions (carroll and briscoe, 2002; <papid> C02-1013 </papid>kubler and prokic?, 2006; mcdonald and nivre, 2007).<papid> D07-1013 </papid></citsent>
<aftsection>
<nextsent>c ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.but there are few studies that combine the two perspectives and try to tease apart the influence of different features on the analysis of specific constructions, let al ne motivated by thorough linguistic analysis.
</nextsent>
<nextsent>in this paper, we investigate the influence of aset of linguistically motivated features on parse results for swedish, and in particular on the analysis of argument relations such as subjects, objects and subject predicatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1273">
<title id=" W08-2104.xml">linguistic features in data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even with high overall parsing accuracy, however, data driven parsers often make errors in the assignment of argument relations such as subject and object and the exact influence of data-derived features on the parsing accuracy for specific linguistic constructions is still relatively poorly understood.
</prevsent>
<prevsent>there are number of studies that investigate the influence of different features or representational choices on overall parsing accuracy, (bod, 1998; klein and manning, 2003).<papid> P03-1054 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1013 ">
there are also attempt sat more fine-grained analysis of accuracy, targeting specific linguistic constructions or grammatical functions (carroll and briscoe, 2002; <papid> C02-1013 </papid>kubler and prokic?, 2006; mcdonald and nivre, 2007).<papid> D07-1013 </papid></citsent>
<aftsection>
<nextsent>c ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.but there are few studies that combine the two perspectives and try to tease apart the influence of different features on the analysis of specific constructions, let al ne motivated by thorough linguistic analysis.
</nextsent>
<nextsent>in this paper, we investigate the influence of aset of linguistically motivated features on parse results for swedish, and in particular on the analysis of argument relations such as subjects, objects and subject predicatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1274">
<title id=" W08-2104.xml">linguistic features in data driven dependency parsing </title>
<section> parsing swedish.  </section>
<citcontext>
<prevsection>
<prevsent>personal pronouns distinguish nominative and accusative case, but demonstratives and quantifying pronouns are case ambiguous (like nouns).
</prevsent>
<prevsent>2.1 treebank: talbanken05.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
talbanken05 is swedish treebank converted to dependency format, containing both written and spoken language (nivre et al , 2006<papid> W06-2933 </papid>a).1 for each token, talbanken05 contains information on word form, part of speech, head and dependency relation, as well as various morphosyntactic and/orlexical semantic features.</citsent>
<aftsection>
<nextsent>the nature of this additional information varies depending on part of speech: noun: definite ness, animacy, case (?/gen) pro: animacy, case (?/acc) verb: tense, voice (?/pa) 2.2 parser: maltparser.
</nextsent>
<nextsent>we use the freely available maltparser,2 which is language-independent system for data-driven dependency parsing.
</nextsent>
<nextsent>malt parser is based on deterministic parsing strategy, first proposed by nivre (2003), in combination with treebank induced classifiers for predicting the next parsingaction.
</nextsent>
<nextsent>classifiers can be trained using any machine learning approach, but the best results have so far been obtained with support vector machines,using libsvm (chang and lin, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1276">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the objective of our work is to correctly assign gender to english noun tokens, in context; to determine which class of pronoun will refer to given noun.
</prevsent>
<prevsent>one successful approach to this problem is tobuild statistical gender model from nouns association with pronouns in text.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
for example, ge et al(1998) <papid> W98-1119 </papid>learn ford has 94% chance of being neutral, based on its frequent co-occurrence with neutral pronouns in text.</citsent>
<aftsection>
<nextsent>such estimates are noisy but useful.
</nextsent>
<nextsent>both ge et al (1998) <papid> W98-1119 </papid>and bergsma and lin(2006) <papid> P06-1005 </papid>show that learned gender is the most important feature in their pronoun resolution systems.</nextsent>
<nextsent>english differs from other languages like french and german in that gender is not an inherent grammatical property of an english noun, but rather property of real-world entity that is being referredto.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1279">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, ge et al(1998) <papid> W98-1119 </papid>learn ford has 94% chance of being neutral, based on its frequent co-occurrence with neutral pronouns in text.</prevsent>
<prevsent>such estimates are noisy but useful.</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
both ge et al (1998) <papid> W98-1119 </papid>and bergsma and lin(2006) <papid> P06-1005 </papid>show that learned gender is the most important feature in their pronoun resolution systems.</citsent>
<aftsection>
<nextsent>english differs from other languages like french and german in that gender is not an inherent grammatical property of an english noun, but rather property of real-world entity that is being referredto.
</nextsent>
<nextsent>a common noun like lawyer can be (semanti cally) masculine in one document and feminine in another.
</nextsent>
<nextsent>while previous statistical gender models learn gender for noun types only, we use document context to correctly determine the current gender class of noun tokens, making dynamic decisions on common nouns like lawyer and ambiguous names like ford.
</nextsent>
<nextsent>furthermore, if noun type has not yet 120been observed (an unknown word), previous approaches cannot estimate the gender.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1280">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> testing:.  </section>
<citcontext>
<prevsection>
<prevsent>all previous statistical approaches relyon similar observation: if noun like glen is often referred to by masculine pronouns, like he or his, then glen is likely masculine noun.
</prevsent>
<prevsent>but for most nouns we have no annotated data recording their coreference with pronouns, and thus no data from which we can extract the co-occurrence statistics.
</prevsent>
</prevsection>
<citsent citstr=" W05-0612 ">
thus previous approaches relyon either hand-crafted coreference indicating patterns (bergsma, 2005), or iterativelyguess and improve gender models through expectation maximization of pronoun resolution (cherry and bergsma, 2005; <papid> W05-0612 </papid>charniak and elsner, 2009).</citsent>
<aftsection>
<nextsent>in statistical approaches, the more frequent the noun, the more accurate the assignment of gender.
</nextsent>
<nextsent>we use the approach of bergsma and lin (2006), <papid> P06-1005 </papid>both because it achieves state-of-the-art gender classification performance, and because database of the obtained noun genders is available online.1 bergsma and lin (2006) <papid> P06-1005 </papid>use an unsupervised algorithm to identify syntactic paths along which noun and pronoun are highly likely to corefer.</nextsent>
<nextsent>to extract gender information, they processed large corpus of news text, and obtained co-occurrence counts for nouns and pronouns connected with these paths in the corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1286">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> discriminative learning of gender.  </section>
<citcontext>
<prevsection>
<prevsent>attest time, all nouns in the test documents are converted to this format for further processing.we group nouns because there is strong tendency for nouns to have only one sense (and hence gender) per discourse.
</prevsent>
<prevsent>we extract contexts because nearby words provide good clues about which gender is being used.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the notion that nouns have onlyone sense per discourse/collocation was also exploited by yarowsky (1995) <papid> P95-1026 </papid>in his seminal work on bootstrapping for word sense disambiguation.</citsent>
<aftsection>
<nextsent>3.2 feature vectors.
</nextsent>
<nextsent>once the training instances are extracted, they are converted to labeled feature vectors for supervisedlearning.
</nextsent>
<nextsent>the automatically-determined gender provides the class label (e.g., masculine for the group in figure 2).
</nextsent>
<nextsent>the features identify properties of the noun and its context that potentially correlate with particular gender category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1287">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> discriminative learning of gender.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we have features that indicate if the nounor parts of the noun occur on various lists.
</prevsent>
<prevsent>indicator features specify if any token occurs on in-house lists of given names, family names, cities, provinces, countries, corporations, languages, etc. feature also indicates if token is corporate designation (like inc. or ltd.) or human one (like mr. or sheik).
</prevsent>
</prevsection>
<citsent citstr=" P03-1001 ">
we also made use of the person-name/instance pairs automatically extracted by fleischman et al (2003).<papid> P03-1001 </papid>4 this data provides counts for pairs such as (zhang qiyue, spokeswoman) and (thorvaldstoltenberg, mediator).</citsent>
<aftsection>
<nextsent>we have features for all concepts (like spokeswoman and mediator) and therefore learn their association with each gender.
</nextsent>
<nextsent>3.3 supervised learning and classification.
</nextsent>
<nextsent>once all the feature vectors have been extracted,they are passed to supervised machine learn 4available at http://www.mit.edu/mbf/instances.txt.gz 123 ing algorithm.
</nextsent>
<nextsent>we train and classify using multi-class linear-kernel support vector machine (svm) (crammer and singer, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1288">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>we back off to counts for the first name (e.g. kathleen .*) if the full name is unobserved.
</prevsent>
<prevsent>this enhancement improved the path gender and pathgender+ systems to 93.3% and 94.3%, respectively, while raising the accuracy of our full-semi system to 96.7%.
</prevsent>
</prevsection>
<citsent citstr=" P04-1056 ">
this demonstrates that the surname-matching post-processor is simple but worthwhile extension to gender predictor.8the remaining errors represent number of challenging cases: united states, group, and public labeled as plural but classified as neutral ; spectator classified as neutral , etc. some of these may yieldto more sophisticated joint classification of coreference and gender, perhaps along the lines of work in named-entity classification (bunescu and mooney, 2004) <papid> P04-1056 </papid>or anaphoricity (denis and baldridge, 2007).<papid> N07-1030 </papid>while gender has been shown to be the key feature for statistical pronoun resolution (ge et al, 1998; <papid> W98-1119 </papid>bergsma and lin, 2006), <papid> P06-1005 </papid>it remains to be seen whether the exceptional accuracy obtained here will translate into improvements in resolution per formance.</citsent>
<aftsection>
<nextsent>however, given the clear utility of gender in coreference, substantial error reductions in gender 8one might wonder, why not provide special features so thatthe system can learn how to handle ambiguous nouns that occurred as sub-phrases in earlier names?
</nextsent>
<nextsent>the nature of our training data precludes this approach.
</nextsent>
<nextsent>we only include unambiguous examples as pseudo-seeds in the learning process.
</nextsent>
<nextsent>without providing ambiguous (but labeled) surnames in some way, the learner will not take advantage of features to help classify them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1289">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>we back off to counts for the first name (e.g. kathleen .*) if the full name is unobserved.
</prevsent>
<prevsent>this enhancement improved the path gender and pathgender+ systems to 93.3% and 94.3%, respectively, while raising the accuracy of our full-semi system to 96.7%.
</prevsent>
</prevsection>
<citsent citstr=" N07-1030 ">
this demonstrates that the surname-matching post-processor is simple but worthwhile extension to gender predictor.8the remaining errors represent number of challenging cases: united states, group, and public labeled as plural but classified as neutral ; spectator classified as neutral , etc. some of these may yieldto more sophisticated joint classification of coreference and gender, perhaps along the lines of work in named-entity classification (bunescu and mooney, 2004) <papid> P04-1056 </papid>or anaphoricity (denis and baldridge, 2007).<papid> N07-1030 </papid>while gender has been shown to be the key feature for statistical pronoun resolution (ge et al, 1998; <papid> W98-1119 </papid>bergsma and lin, 2006), <papid> P06-1005 </papid>it remains to be seen whether the exceptional accuracy obtained here will translate into improvements in resolution per formance.</citsent>
<aftsection>
<nextsent>however, given the clear utility of gender in coreference, substantial error reductions in gender 8one might wonder, why not provide special features so thatthe system can learn how to handle ambiguous nouns that occurred as sub-phrases in earlier names?
</nextsent>
<nextsent>the nature of our training data precludes this approach.
</nextsent>
<nextsent>we only include unambiguous examples as pseudo-seeds in the learning process.
</nextsent>
<nextsent>without providing ambiguous (but labeled) surnames in some way, the learner will not take advantage of features to help classify them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1292">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>6 related work.
</prevsent>
<prevsent>most coreference and pronoun resolution papers mention that they use gender information, but few explain how it is acquired.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
kennedy and boguraev(1996) <papid> C96-1021 </papid>use gender information produced by their enhanced part-of-speech tagger.</citsent>
<aftsection>
<nextsent>gender mistakes account for 35% of their systems errors.
</nextsent>
<nextsent>gender is less crucial in some genres, like computer manuals; most nouns are either neutral or plural and gender can be determined accurately based solely on morphological information (lappin and leass, 1994).<papid> J94-4002 </papid></nextsent>
<nextsent>a number of researchers (evans and orasan, 2000; soon et al, 2001; <papid> J01-4004 </papid>harabagiu et al, 2001) <papid> N01-1008 </papid>use wordnet classes to infer gender knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1293">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>kennedy and boguraev(1996) <papid> C96-1021 </papid>use gender information produced by their enhanced part-of-speech tagger.</prevsent>
<prevsent>gender mistakes account for 35% of their systems errors.</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
gender is less crucial in some genres, like computer manuals; most nouns are either neutral or plural and gender can be determined accurately based solely on morphological information (lappin and leass, 1994).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>a number of researchers (evans and orasan, 2000; soon et al, 2001; <papid> J01-4004 </papid>harabagiu et al, 2001) <papid> N01-1008 </papid>use wordnet classes to infer gender knowledge.</nextsent>
<nextsent>unfortunately, manually-constructed databases like wordnet suffer from both low coverage and rare senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1294">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>gender mistakes account for 35% of their systems errors.
</prevsent>
<prevsent>gender is less crucial in some genres, like computer manuals; most nouns are either neutral or plural and gender can be determined accurately based solely on morphological information (lappin and leass, 1994).<papid> J94-4002 </papid></prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
a number of researchers (evans and orasan, 2000; soon et al, 2001; <papid> J01-4004 </papid>harabagiu et al, 2001) <papid> N01-1008 </papid>use wordnet classes to infer gender knowledge.</citsent>
<aftsection>
<nextsent>unfortunately, manually-constructed databases like wordnet suffer from both low coverage and rare senses.
</nextsent>
<nextsent>pantel and ravichandran (2004) <papid> N04-1041 </papid>note that the nouns computer and company both have wordnet sense that is hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she.</nextsent>
<nextsent>in addition to using wordnet classes, soonet al (2001) <papid> J01-4004 </papid>assign gender if the noun has gen dered designator (like mr. or mrs.) or if the first token is present on list of common human first names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1295">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>gender mistakes account for 35% of their systems errors.
</prevsent>
<prevsent>gender is less crucial in some genres, like computer manuals; most nouns are either neutral or plural and gender can be determined accurately based solely on morphological information (lappin and leass, 1994).<papid> J94-4002 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
a number of researchers (evans and orasan, 2000; soon et al, 2001; <papid> J01-4004 </papid>harabagiu et al, 2001) <papid> N01-1008 </papid>use wordnet classes to infer gender knowledge.</citsent>
<aftsection>
<nextsent>unfortunately, manually-constructed databases like wordnet suffer from both low coverage and rare senses.
</nextsent>
<nextsent>pantel and ravichandran (2004) <papid> N04-1041 </papid>note that the nouns computer and company both have wordnet sense that is hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she.</nextsent>
<nextsent>in addition to using wordnet classes, soonet al (2001) <papid> J01-4004 </papid>assign gender if the noun has gen dered designator (like mr. or mrs.) or if the first token is present on list of common human first names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1296">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>a number of researchers (evans and orasan, 2000; soon et al, 2001; <papid> J01-4004 </papid>harabagiu et al, 2001) <papid> N01-1008 </papid>use wordnet classes to infer gender knowledge.</prevsent>
<prevsent>unfortunately, manually-constructed databases like wordnet suffer from both low coverage and rare senses.</prevsent>
</prevsection>
<citsent citstr=" N04-1041 ">
pantel and ravichandran (2004) <papid> N04-1041 </papid>note that the nouns computer and company both have wordnet sense that is hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she.</citsent>
<aftsection>
<nextsent>in addition to using wordnet classes, soonet al (2001) <papid> J01-4004 </papid>assign gender if the noun has gen dered designator (like mr. or mrs.) or if the first token is present on list of common human first names.</nextsent>
<nextsent>note that we incorporate such contextual and categorical information (among many other information sources) automatically in our discriminative classifier, while they manually specify few high-precision rules for particular gender cues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1300">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>gender and plentiful gold standard data, gender can be tagged along with other word properties using standard supervised tagging techniques (hajic?
</prevsent>
<prevsent>and hladka?, 1997).
</prevsent>
</prevsection>
<citsent citstr=" N03-1006 ">
while our approach is the first to exploit dualor orthogonal representation of english noun gender, bootstrapping approach has been applied to determining grammatical gender in other languages by cucerzan and yarowsky (2003).<papid> N03-1006 </papid></citsent>
<aftsection>
<nextsent>in their work, the two orthogonal views are: 1) the context of the noun, and 2) the nouns morphological properties.
</nextsent>
<nextsent>bootstrapping with these views is possible in other languages where context is highly predictive of gender class, since contextual words like adjectives and determiners inflect to agree with the grammatical noun gender.
</nextsent>
<nextsent>we initially attempted similar system for english noun gender but found context alone to be insufficiently predictive.
</nextsent>
<nextsent>bootstrapping is also used in general informationextraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1301">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>bootstrapping is also used in general informationextraction.
</prevsent>
<prevsent>brin (1998) shows how to alternate between extracting instances of class and inducing new instance-extracting patterns.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
collins and singer (1999) <papid> W99-0613 </papid>and cucerzan and yarowsky (1999) <papid> W99-0612 </papid>apply bootstrapping to the related task of named-entity recognition.</citsent>
<aftsection>
<nextsent>our approach was directly influenced by the hypernym-extractor of snow et al (2005) and we provided an analogous summary in section 1.while their approach uses wordnet to label hypernyms in raw text, our initial labels are generated automatically.
</nextsent>
<nextsent>etzioni et al (2005) also require no labeled data or hand-labeled seeds for their named entity extractor, but by comparison their classifier only uses very small number of both features and automatically-generated training examples.
</nextsent>
<nextsent>7 conclusion.
</nextsent>
<nextsent>we have shown how noun-pronoun co-occurrence counts can be used to automatically annotate the gender of millions of nouns in unlabeled text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1302">
<title id=" W09-1116.xml">glen glenda or glendale unsupervised and semi supervised learning of english noun gender </title>
<section> full-semi:.  </section>
<citcontext>
<prevsection>
<prevsent>bootstrapping is also used in general informationextraction.
</prevsent>
<prevsent>brin (1998) shows how to alternate between extracting instances of class and inducing new instance-extracting patterns.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
collins and singer (1999) <papid> W99-0613 </papid>and cucerzan and yarowsky (1999) <papid> W99-0612 </papid>apply bootstrapping to the related task of named-entity recognition.</citsent>
<aftsection>
<nextsent>our approach was directly influenced by the hypernym-extractor of snow et al (2005) and we provided an analogous summary in section 1.while their approach uses wordnet to label hypernyms in raw text, our initial labels are generated automatically.
</nextsent>
<nextsent>etzioni et al (2005) also require no labeled data or hand-labeled seeds for their named entity extractor, but by comparison their classifier only uses very small number of both features and automatically-generated training examples.
</nextsent>
<nextsent>7 conclusion.
</nextsent>
<nextsent>we have shown how noun-pronoun co-occurrence counts can be used to automatically annotate the gender of millions of nouns in unlabeled text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1303">
<title id=" W09-0422.xml">english czech mt in 2008 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe two systems for english-to czech machine translation that took part in the wmt09 translation task.
</prevsent>
<prevsent>one of the systems is tuned phrase-based system and the other one is based on linguistically motivated analysis-transfer-synthesis approach.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we participated in wmt09 with two very different systems: (1) phrase-based mt based on moses (koehn et al, 2007) <papid> P07-2045 </papid>and tuned for english czech translation, and (2) complex system in the tectomt platform ( zabokrtsky?</citsent>
<aftsection>
<nextsent>et al., 2008).
</nextsent>
<nextsent>2.1 monolingual data.
</nextsent>
<nextsent>our czech monolingual data consist of (1) the czech national corpus (cnc, versions syn200[056], 72.6%, kocek et al (2000)), (2) collection of web pages downloaded by pavelpecina (web, 17.1%), and (3) the czech monolingual data provided by wmt09 organizers (10.3%).
</nextsent>
<nextsent>table 1 lists sentence and token counts(see section 2.3 for the explanation of a- and layer).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1304">
<title id=" W09-0422.xml">english czech mt in 2008 </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>the work on this project was supported by the grants msm0021620838, 1et201120505, 1et101120503, gauk 52408/2008, msmt cr lc536 and fp6-ist-5-034291-stp (euromatrix).
</prevsent>
<prevsent>2.2 parallel data.
</prevsent>
</prevsection>
<citsent citstr=" W08-0319 ">
as the source of parallel data we use an internal release of czech-english parallel corpus czeng (bojar et al, 2008) <papid> W08-0319 </papid>extended with some additional texts.</citsent>
<aftsection>
<nextsent>one of the added sections was gathered from two major web sites containing czech subtitles to movies and tv series1.
</nextsent>
<nextsent>the matching ofthe czech and english movies is rather straightforward thanks to the naming conventions.
</nextsent>
<nextsent>however, we were unable to reliably determine these ries number and the episode number from the filenames.
</nextsent>
<nextsent>we employed two-step procedure to automatically pair the tv series subtitle files.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1306">
<title id=" W09-0422.xml">english czech mt in 2008 </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>et al, 2008).
</prevsent>
<prevsent>tectomt is highly modular software framework aimed at creating mt systems (focused, but by far not limited to translation using tectogrammatical transfer) and other nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
numerous existing nlp tools such as taggers, parsers, and named entityrecognizers are already integrated in tectomt, especially for (but again, not limited to) english and czech.during the analysis of the large czech monolingual data, we used jan hajics czech tagger shipped with pdt 2.0, maximum spanning tree parser (mcdonald et al, 2005) <papid> H05-1066 </papid>with optimized set of features as described in novak and zabokrtsky?(2007), and tool for assigning functors (seman tic roles) from klimes?</citsent>
<aftsection>
<nextsent>(2006), and numerous other components of our own (e.g. for conversion of analytical trees into tectogrammatical ones).
</nextsent>
<nextsent>in the parallel data, we analyzed the czech side using more or less the same scenario as used forthe monolingual data.
</nextsent>
<nextsent>english sentences were analyzed using (among other tools) morce tagger spoustova?
</nextsent>
<nextsent>et al (2007) and maximum spanning tree parser.2 the resulting deep syntactic (tectogrammatical)czech and english trees are then aligned using talignera feature based greedy algorithm implemented for this purpose (marecek et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1308">
<title id=" W09-0422.xml">english czech mt in 2008 </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>it 2in some previous experiments (e.g. zabokrtsky?
</prevsent>
<prevsent>et al (2008)), we used phrase-structure parser collins (1999) with subsequent constituency-dependency conversion.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
also uses word alignment generated from surface shapes of sentences by giza++ tool, och and ney (2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>we use acquired aligned tectogrammatical trees for training some models for the transfer.as analysis of such amounts of data is obviously computationally very demanding, we run it in parallel using sun grid engine3 cluster of 404-cpu computers.
</nextsent>
<nextsent>for this purpose, we implemented rather generic tool that submits any tec tomt pipeline to the cluster.
</nextsent>
<nextsent>we essentially repeat our experiments from last year (bojar and hajic?, 2008): giza++ alignments4 on a-layer lemmas (a-layer nodes correspond 1-1 to surface tokens), symmetrized using grow-diag-final (no -and) heuristic5 . probably due to the domain difference (the test set is news), including subtitles in the parallel data and web in the monolingual data did not bring any improvement that would justify the additional performance costs.
</nextsent>
<nextsent>for most of the phrase-based experiments, we thus used only 2.2m parallel sentences (27m czech and 32m english tokens) and 43m czech sentences (694 tokens).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1311">
<title id=" W09-0422.xml">english czech mt in 2008 </title>
<section> translation setup based on.  </section>
<citcontext>
<prevsection>
<prevsent>6we used the full development set of 2k sentences for moses t?
</prevsent>
<prevsent>and subset of 1k sentences for the other two setups due to time constraints.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
one of the steps in the analysis of english is named entity recognition using stanford named entity recognizer (finkel et al, 2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>the nodes in the english t-layer are grouped according to the detected named entities and they are assigned the type of entity (location, person, or organization).
</nextsent>
<nextsent>this information is preserved in the transfer of thedeep english trees to the deep czech trees to allow for the appropriate capitalization of the czech translation.
</nextsent>
<nextsent>4.2 transfer.
</nextsent>
<nextsent>the transfer phase consists of the following steps:?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1312">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, fixing erroneous words, generating complex morphology, andre ranking translation results in post-processing phases may utilize syntactic information of both source and target languages.
</prevsent>
<prevsent>a syntax-based smt system encodes the syntactic information in its translation model of the decoding step.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
a number of researchers have proposed syntactic reordering as preprocessing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007).</citsent>
<aftsection>
<nextsent>in these syntactic reordering approaches, source sentences are first parsed and series of reordering rules are applied to the parsed trees to reorder the source sentences into target language like word orders.
</nextsent>
<nextsent>such an approach is an effective method for phrase-based smt system that employs relatively simple distortion model in the decoding phase.
</nextsent>
<nextsent>this paper concentrates upon reordering source sentences in the preprocessing step of chinese-to-korean phrase-based smt system using syntactic information.
</nextsent>
<nextsent>chinese-to-korean smt has more difficulties than the language pairs studied in previous research (french english, german-english, and chinese-english).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1313">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, fixing erroneous words, generating complex morphology, andre ranking translation results in post-processing phases may utilize syntactic information of both source and target languages.
</prevsent>
<prevsent>a syntax-based smt system encodes the syntactic information in its translation model of the decoding step.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
a number of researchers have proposed syntactic reordering as preprocessing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007).</citsent>
<aftsection>
<nextsent>in these syntactic reordering approaches, source sentences are first parsed and series of reordering rules are applied to the parsed trees to reorder the source sentences into target language like word orders.
</nextsent>
<nextsent>such an approach is an effective method for phrase-based smt system that employs relatively simple distortion model in the decoding phase.
</nextsent>
<nextsent>this paper concentrates upon reordering source sentences in the preprocessing step of chinese-to-korean phrase-based smt system using syntactic information.
</nextsent>
<nextsent>chinese-to-korean smt has more difficulties than the language pairs studied in previous research (french english, german-english, and chinese-english).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1314">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> chinese syntactic reordering rules.  </section>
<citcontext>
<prevsection>
<prevsent>first is the correct position of verbal phrases, and the second is the generation of verb affixes which convey modality information.
</prevsent>
<prevsent>in this section, we describe set of manually constructed chinese syntactic reordering rules.
</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
chinese sentences are first parsed by stanford pcfg parser which uses penn chinese treebank as the training corpus (levy and manning, 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>penn chinese treebank adopts 23 tags for phrases (appendix a).
</nextsent>
<nextsent>we identified three categories in chinese that need to be reordered: verb phrases (vps), preposition phrases (pps), and modali ty-bearing words.
</nextsent>
<nextsent>3.1 verb phrases.
</nextsent>
<nextsent>korean is verb-final language, and verb phrase modifiers and complements occur in the pre verbal positions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1316">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> chinese syntactic reordering rules.  </section>
<citcontext>
<prevsection>
<prevsent>the corresponding modality information is implicitly or explicitly expressed in chinese.
</prevsent>
<prevsent>it is important to figure out what features are used to represent modality information.
</prevsent>
</prevsection>
<citsent citstr=" L08-1057 ">
li et al (2008) <papid> L08-1057 </papid>describes in detail the features in chinese that express modality information.</citsent>
<aftsection>
<nextsent>however, since only lexical features can be reordered, we consider explicit modality features only.
</nextsent>
<nextsent>modality-bearing words are scattered over an entire sentence.
</nextsent>
<nextsent>we move them near their verbal heads because their correspondences in korean sentences are always placed right after their verbs.
</nextsent>
<nextsent>when constructing reordering rules, we consider temporal adverbs, auxiliary verbs, negation particles, and aspect particles only.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1317">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>generally speaking, chinese does not have grammatical forms for voice.
</prevsent>
<prevsent>although, voice is also grammatical category expressing modality information, we have left it out of the current phase of our experiment since voice detection is another research issue and reordering rules for voice are unavoidably complicated.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our baseline system is popular phrase-based smt system, moses (koehn et al, 2007), <papid> P07-2045 </papid>with 5-gram srilm language model (stolcke, 2002), tuned with minimum error training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we adopt nist (nist, 2002) and bleu (papi neni et al, 2001) as our evaluation metrics.
</nextsent>
<nextsent>chinese sentences in training and test corpora are first parsed and are applied series of syntactic reordering rules.
</nextsent>
<nextsent>to evaluate the contribution of the three categories of syntactic reordering rules, we perform the experiments applying each category independently.
</nextsent>
<nextsent>experiments of various combinations are also carried out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1318">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>generally speaking, chinese does not have grammatical forms for voice.
</prevsent>
<prevsent>although, voice is also grammatical category expressing modality information, we have left it out of the current phase of our experiment since voice detection is another research issue and reordering rules for voice are unavoidably complicated.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
our baseline system is popular phrase-based smt system, moses (koehn et al, 2007), <papid> P07-2045 </papid>with 5-gram srilm language model (stolcke, 2002), tuned with minimum error training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we adopt nist (nist, 2002) and bleu (papi neni et al, 2001) as our evaluation metrics.
</nextsent>
<nextsent>chinese sentences in training and test corpora are first parsed and are applied series of syntactic reordering rules.
</nextsent>
<nextsent>to evaluate the contribution of the three categories of syntactic reordering rules, we perform the experiments applying each category independently.
</nextsent>
<nextsent>experiments of various combinations are also carried out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1319">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>the other corpus is provided by msra (microsoft research asia).
</prevsent>
<prevsent>it is chinese korean-english trilingual corpus of technical manuals and literally translated corpus.
</prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
chinese sentences are segmented by stanford chinese word segmenter (tseng et al, 2005), <papid> I05-3027 </papid>and parsed by stanford chinese parser (levy and manning, 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>korean sentences are segmented into morphemes by an in-house morphological analyzer.
</nextsent>
<nextsent>the detailed corpus profiles are displayed in table 1 and 2.
</nextsent>
<nextsent>the dong-a newspaper corpus is much longer than the msra technical manual corpus.
</nextsent>
<nextsent>in korean, we report the length of content and function words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1322">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>in the future, we may improve our system by extracting implicit modality features.
</prevsent>
<prevsent>in addition to generating verbal phrases, there is the more general issue of generating complex morphology in smt systems targeting korean, such as generating korean case markers.
</prevsent>
</prevsection>
<citsent citstr=" P07-1017 ">
there are several previous studies on this topic (min kov et al, 2007; <papid> P07-1017 </papid>toutanova et al, 2008).<papid> P08-1059 </papid></citsent>
<aftsection>
<nextsent>this issue will also be the focus of our future work in both the phrase- and syntax-based smt frameworks.
</nextsent>
<nextsent>acknowledgments this work was supported in part by mke &amp; ii ta through the it leading r&d; support project and also in part by the bk 21 project in 2009.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1323">
<title id=" W09-0433.xml">chinese syntactic reordering for adequate generation of korean verbal phrases in chinesetokorean smt </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>in the future, we may improve our system by extracting implicit modality features.
</prevsent>
<prevsent>in addition to generating verbal phrases, there is the more general issue of generating complex morphology in smt systems targeting korean, such as generating korean case markers.
</prevsent>
</prevsection>
<citsent citstr=" P08-1059 ">
there are several previous studies on this topic (min kov et al, 2007; <papid> P07-1017 </papid>toutanova et al, 2008).<papid> P08-1059 </papid></citsent>
<aftsection>
<nextsent>this issue will also be the focus of our future work in both the phrase- and syntax-based smt frameworks.
</nextsent>
<nextsent>acknowledgments this work was supported in part by mke &amp; ii ta through the it leading r&d; support project and also in part by the bk 21 project in 2009.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1324">
<title id=" W08-2135.xml">the integration of dependency relation classification and semantic role labeling using bilayer maximum entropy markov models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 syntactic dependency relation.
</prevsent>
<prevsent>classification and semantic dependency relation identification we integrate dependency parsing and semantic role labeling to some extent in this stage.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
some dependency parsing systems prefer two-stage architecture: unlabeled parsing and dependency classification (nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>previous semantic role labeling approaches also prefer two-stage ar chitecture: argument identification and argument classification.
</nextsent>
<nextsent>our system does syntactic relations classification and semantic relations identification at the same time.
</nextsent>
<nextsent>specially, using pruning algorithm, we collect set of argument candidates;then we classify dependency relations between argument candidates and the predicates and predict whether candidate is an argument.
</nextsent>
<nextsent>a directed graphical model is used to represent the relations between syntactic and semantic relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1325">
<title id=" W09-1419.xml">analyzing text in search of biomolecular events a high precision machine learning framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to detect negation and speculation in text,we describe custom-made rule-based system which is simple in design, but effective in performance.
</prevsent>
<prevsent>bionlp recently emerged from the combined expertise of molecular biology and computational linguistics.
</prevsent>
</prevsection>
<citsent citstr=" E06-1051 ">
at first, the community was mainly focused on named entity recognition (ner) and simple relation extraction, such as protein-protein interactions (plake et al, 2005; giuliano et al, 2006; <papid> E06-1051 </papid>fundel et al., 2007; saetre et al, 2008).</citsent>
<aftsection>
<nextsent>however, the future of bionlp lies in the ability to extract more complex events from text, in order to fully capture all available information (altman et al, 2008).two recent community-wide challenges, biocre ative (hirschman et al, 2005) and ii (krallinger etal., 2008) have shown their merits by providing common benchmarking data and meaningful comparison of various techniques.
</nextsent>
<nextsent>in contrast to the monolithic bio creative tasks, the bionlp09 shared task has more modular nature (kim et al, 2009).
</nextsent>
<nextsent>it is not concerned with named entity recognition or normalization, but focuses on the task of event extraction itself.this article is organized as follows: we first describe the shared task in little more detail.
</nextsent>
<nextsent>next,we present the methods used in our machine learning framework, carefully discussing our choices in design and their influence on performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1326">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sometimes the system makes the inclusion of schema element conditional on the context of the text, for instance, deciding to include or exclude content based on the type of user that the message is being generated for (dimarco et al 1997).
</prevsent>
<prevsent>for other types of text, the application of sche mas is less appropriate.
</prevsent>
</prevsection>
<citsent citstr=" P88-1020 ">
some text planners take as their goal the delivery of single fact, or set of facts, but take into account that other information may need to be given first for each message to be understood, other information may need to be given after to counter misconceptions, and examples may be given to aide assimilation (for instance, the rst text planners, such as hovy 1988).<papid> P88-1020 </papid></citsent>
<aftsection>
<nextsent>the system thus composes text which delivers the facts required of it, and any other facts which will facilitate the uptake of these facts.
</nextsent>
<nextsent>in another text genre, the goal is not to deliver specific facts, but rather to describe an entity, for instance, museum artefacts (e.g., ilex: odonnell et al 2001), or animals (peba: milosavljevic 1999).
</nextsent>
<nextsent>a basic strategy to generate reasonable text of this kind is to list the different attributes of the target entity, possibly sorted into relevant topics.
</nextsent>
<nextsent>good systems are aware of which information is already known to the intended audience, what should be interesting, etc. in ilex, the system followed various strategies to generate better texts, such as allowing digressions (describing secondary entities), generalisations, defeating misconceptions, aggregation, etc. systems have increasingly tried to address larger sets of the issues needed to produce good quality text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1327">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> what texts can be produced?.  </section>
<citcontext>
<prevsection>
<prevsent>the constraint satisfaction algorithm then derives the ordering of facts which maximises the constraints.
</prevsent>
<prevsent>marcu elsewhere provides an algorithm to build text tree on top of given ordering of facts, again using adjacency and order propensities.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
mellish et al (1998) <papid> W98-1411 </papid>made the point that even this restricted approach would soon become intractable with more than small set of facts when one allows weak rst relations such as joint and elaboration into the model.</citsent>
<aftsection>
<nextsent>an alternative approach, which havent seen implemented (although mellish mentions the possibility), would be to apply hill climbing techniques to the problem of finding text which optimally satisfies set of locally and globally stated text constraints.
</nextsent>
<nextsent>the idea would be to start with single text structure, generated in simple manner.
</nextsent>
<nextsent>the system then tries each possible single mutation on this text structure, (e.g., adding fact in each location in the tree this is possible; deleting each subtree in the tree; grafting subtree from one location to another, etc.).
</nextsent>
<nextsent>each of the resulting text structures is then evaluated, and the one which scores higher is taken as the text structure for the next cycle.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1331">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> what texts can be produced?.  </section>
<citcontext>
<prevsection>
<prevsent>another approach to the problem of satisfying global constraints in text planning has been the generate and revise?
</prevsent>
<prevsent>approach, where text is generated with only partial regard to the global constraints, and the resulting text is then revised to fit the global constraints (e.g., robin and mckeown, 1996).
</prevsent>
</prevsection>
<citsent citstr=" J00-2005 ">
in the stop system (reiter 2000), <papid> J00-2005 </papid>texts are constrained to fit certain length.</citsent>
<aftsection>
<nextsent>the system generates texts of approximately the right length, and then prunes the text until the size requirement is met.
</nextsent>
<nextsent>piwek and van deemter (2007) expand this approach to handle more than single global constraint, exemplifying using both global length and communicative effectiveness as (some times) contradictory goals.
</nextsent>
<nextsent>their approach is to generate single starting text, and then apply revision operations to work towards an optimal text.
</nextsent>
<nextsent>if one sees revision operation as similar to the text mutations applied above, then it seems there vision approach is not so different to the genetic algorithm approach above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1335">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> what texts can be produced?.  </section>
<citcontext>
<prevsection>
<prevsent>while it is clear each of these criteria is contributory to good text, the numbers used were 125 made up.
</prevsent>
<prevsent>basing these numbers on corpus study of good texts may be useful for future work.
</prevsent>
</prevsection>
<citsent citstr=" W00-1425 ">
following on from mellish et al, some work took place focusing on improving the evaluation function, for instance cheng and mellish (2000) <papid> W00-1425 </papid>expanded on the criteria for evaluating focus movement (there called discourse topic move ment?), and also allowed for embedding of facts in others, providing criteria for evaluating how good an embedding is. karamanis also examined focus movement (or as he calls it, entity coherence) in text evaluation (karamanis and manurung 2002; karamanis 2003; karamanis et al 2004; karamanis and mellish 2005).</citsent>
<aftsection>
<nextsent>he proposes dropping the use of rhetorical structure, and taking the goal of text planning as sequencing facts so as to achieve smooth focus movement.
</nextsent>
<nextsent>mutations thus change the ordering of facts in given sequence (as in the mellish work), but evaluation is applied directly to the fact sequence, penalising discontinuous focus movements.
</nextsent>
<nextsent>in summary of this section, the movement to search-based text planning allowed the researcher to move away from issues regarding how to program system to generate texts, focusing instead on the problems of deciding how to evaluate the quality of text.
</nextsent>
<nextsent>4 how good is this text?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1336">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> what texts can be produced?.  </section>
<citcontext>
<prevsection>
<prevsent>the problem here is that ml techniques can only function on the range of features that they have access to.
</prevsent>
<prevsent>in the worst case, only the surface text is provided to the system.
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
some approaches work simply with the n-gram sequences of words, for instance, to select between alternative sentences generated to express some content (e.g., langkilde and knight 1998).<papid> W98-1426 </papid></citsent>
<aftsection>
<nextsent>n-grams have even been used to assess the global quality of texts, not for text planning, but to assess student exam questions (prez et al 2004).
</nextsent>
<nextsent>however, the sequence of words within sentence cannot tell us anything about the quality of the text structure.
</nextsent>
<nextsent>in recent years, there has been substantial work that assumes that the quality of text can be judged in relation to the degree to which the sequence of sentences in the generated text corresponds to golden standard?
</nextsent>
<nextsent>(lapata 2003; <papid> P03-1069 </papid>dimitromanolaki and androutsopoulos 2003; karamanis et al 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1337">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> what texts can be produced?.  </section>
<citcontext>
<prevsection>
<prevsent>however, the sequence of words within sentence cannot tell us anything about the quality of the text structure.
</prevsent>
<prevsent>in recent years, there has been substantial work that assumes that the quality of text can be judged in relation to the degree to which the sequence of sentences in the generated text corresponds to golden standard?
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
(lapata 2003; <papid> P03-1069 </papid>dimitromanolaki and androutsopoulos 2003; karamanis et al 2004).</citsent>
<aftsection>
<nextsent>this work, referred to as input ordering?, assumes that content selection is done as separate task, and the role of text planning can be seen as simply ordering the facts output from content planning.
</nextsent>
<nextsent>a corpus of human written texts, (in most approaches tagged by propositional content), is provided.
</nextsent>
<nextsent>these represent golden standard?.
</nextsent>
<nextsent>text plans generated by the computer are evaluated in terms of the degree to which the terminals of the text structures occur in the same order as the golden standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1338">
<title id=" W08-1116.xml">evolving questions in text planning </title>
<section> what texts can be produced?.  </section>
<citcontext>
<prevsection>
<prevsent>focusing on input order just because it is easy is something like looking for your watch under the street-light, even though you lost it in the dark alley.
</prevsent>
<prevsent>the looking might be easier, but if the answers are in the dark, then that is where we should be looking.
</prevsent>
</prevsection>
<citsent citstr=" J00-3005 ">
126rather than explore surface features of language which are easier to recognise, believe we should be either: ? building discourse-level tree-banks of real texts, to provide real information to inform the automatic derivation of evaluation functions, or, ? building tools to automatically recognise discourse structure of text, (rst, focus movement, etc.) daniel marcu has been leader in both directions, working both on building an rst-tagged corpus, and also exploring the automatic recognition of rhetorical structure (marcu 2000).<papid> J00-3005 </papid></citsent>
<aftsection>
<nextsent>in regards to the latter, unfortunately, the results have not so far been useful for real applications.
</nextsent>
<nextsent>if one wants to rhetorically annotate corpus, one needs to do it by hand, which involves substantial investment of time.
</nextsent>
<nextsent>the case is similar for annotation of other discourse structures, such as focus movement.
</nextsent>
<nextsent>within the context of nlg, another approach is possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1342">
<title id=" W09-1511.xml">modular resource development and diagnostic evaluation framework for fast nlp system improvement </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in the future, we should study the interest to give the ability to our framework to integrate uima-ready modules.
</prevsent>
<prevsent>71 close to our benchmarking tool, some projects aim at building frameworks for text analysis, annotation and evaluation, which projects encourage people to use common architecture, as opennlpor gate.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
those may also be used for benchmarking and evaluation tasks (cunningham et al, 2002)<papid> P02-1022 </papid>as part of their process.</citsent>
<aftsection>
<nextsent>but, while these framework often provide evaluation and regression testing tools, they are rarely well-suited for only implementing specific diagnostic tasks.
</nextsent>
<nextsent>we would appreciate that such frameworks focusing on evaluating,benchmarking and diagnosing, as generic as possible across ir tasks, become more widely available.if our benchmarking tool appears to be appropriate for other systems evaluations, we will consider making it available for their community.
</nextsent>
<nextsent>from our first use of the framework, we are convinced of the importance of diagnostic for accelerating the improvement of our analyzer, by making linguistic resources accessible and by ite rating tests and comparing results obtained over time.
</nextsent>
<nextsent>we also concluded that this generic framework would be useful in other tasks, such as information retrieval.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1343">
<title id=" W09-1511.xml">modular resource development and diagnostic evaluation framework for fast nlp system improvement </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we also intend to focus on visualization of results for better identification and interpretation of errors, in order to access directly erroneous analysis and involved resources.
</prevsent>
<prevsent>a second development iteration will include the development of more user friendly resources editors.
</prevsent>
</prevsection>
<citsent citstr=" L08-1238 ">
we also plan to work on automatic syntactic rules inference, based on previous work in our laboratory(embarek and ferret, 2008).<papid> L08-1238 </papid></citsent>
<aftsection>
<nextsent>for this goal, continuous benchmarking will be even more important as the system will relyon experts tuning parameters for learning rules, the syntactic rules themselves being not necessarily edited nor viewable for the expert.
</nextsent>
<nextsent>acknowledgments this work was partly funded by the french national research agency (anr), mdca program 2006.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1344">
<title id=" W09-0415.xml">deep linguistic multilingual translation and bilingual dictionaries </title>
<section> multilingual lexical database.  </section>
<citcontext>
<prevsection>
<prevsent>c, we can obtain a!
</prevsent>
<prevsent>c. we will see below how the correspondences are validated.the idea of using pivot language for deriving bilingual lexicons from existing ones is not new.
</prevsent>
</prevsection>
<citsent citstr=" W06-2006 ">
the reader can find related approaches in (paik &amp; al. 2004, ahn &amp; frampton 2006, <papid> W06-2006 </papid>zhang &amp; al. 2007) . the specificity of our approach is that the initial resources are manually made, i.e. non noisy, lexicons.</citsent>
<aftsection>
<nextsent>the derivation process goes as follows: 1.
</nextsent>
<nextsent>take two bilingual tables for language pairs.
</nextsent>
<nextsent>(a, b) and (b, c) and perform relational equi-join.
</nextsent>
<nextsent>perform filtering based on the preference attribute to avoid combinatory explosion of the number of generated correspondences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1345">
<title id=" W08-2136.xml">mixing and blending syntactic and semantic dependencies </title>
<section> pipe lined srls.  </section>
<citcontext>
<prevsection>
<prevsent>to further advance the syntactic accuracy, we added the syntactic structure predicted by joint system for syntactic and semantic dependencies (see section 3.4) in the blending process.
</prevsent>
<prevsent>2.1 parsers.
</prevsent>
</prevsection>
<citsent citstr=" W04-0308 ">
the malt parser is dependency parser generator, with three parsing algorithms: nivres arc standard, nivres arc eager (see nivre (2004)<papid> W04-0308 </papid>for comparison between the two nivre algo rithms), and covingtons (covington, 2001).</citsent>
<aftsection>
<nextsent>both of nivres algorithms assume projectivity, but the malt parser supports pseudo-projective parsing(nilsson et al, 2007), <papid> P07-1122 </papid>for projectivization and de projectivization.</nextsent>
<nextsent>248 wsj brown best single parse 85.22% 78.37% las weights 87.00% 80.60% learned weights 87.36% 80.77% table 1: labelled attachment score on the two test sets of the best single parse, blended with weights set to pos labelled attachment score (las) and blended with learned weights.four parsing algorithms (the two nivre algorithms, and covingtons projective and non projective version) were used, creating eight parsers by varying the parsing direction, left-to right and right-to-left.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1346">
<title id=" W08-2136.xml">mixing and blending syntactic and semantic dependencies </title>
<section> pipe lined srls.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 parsers.
</prevsent>
<prevsent>the malt parser is dependency parser generator, with three parsing algorithms: nivres arc standard, nivres arc eager (see nivre (2004)<papid> W04-0308 </papid>for comparison between the two nivre algo rithms), and covingtons (covington, 2001).</prevsent>
</prevsection>
<citsent citstr=" P07-1122 ">
both of nivres algorithms assume projectivity, but the malt parser supports pseudo-projective parsing(nilsson et al, 2007), <papid> P07-1122 </papid>for projectivization and de projectivization.</citsent>
<aftsection>
<nextsent>248 wsj brown best single parse 85.22% 78.37% las weights 87.00% 80.60% learned weights 87.36% 80.77% table 1: labelled attachment score on the two test sets of the best single parse, blended with weights set to pos labelled attachment score (las) and blended with learned weights.four parsing algorithms (the two nivre algorithms, and covingtons projective and non projective version) were used, creating eight parsers by varying the parsing direction, left-to right and right-to-left.
</nextsent>
<nextsent>the latter was achieved by reversing the word order in pre-processing stepand then restoring it in post-processing.
</nextsent>
<nextsent>for the final system, feature models and training parameters were adapted from hallet al (2007).<papid> D07-1097 </papid></nextsent>
<nextsent>2.2 blender.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1347">
<title id=" W08-2136.xml">mixing and blending syntactic and semantic dependencies </title>
<section> pipe lined srls.  </section>
<citcontext>
<prevsection>
<prevsent>248 wsj brown best single parse 85.22% 78.37% las weights 87.00% 80.60% learned weights 87.36% 80.77% table 1: labelled attachment score on the two test sets of the best single parse, blended with weights set to pos labelled attachment score (las) and blended with learned weights.four parsing algorithms (the two nivre algorithms, and covingtons projective and non projective version) were used, creating eight parsers by varying the parsing direction, left-to right and right-to-left.
</prevsent>
<prevsent>the latter was achieved by reversing the word order in pre-processing stepand then restoring it in post-processing.
</prevsent>
</prevsection>
<citsent citstr=" D07-1097 ">
for the final system, feature models and training parameters were adapted from hallet al (2007).<papid> D07-1097 </papid></citsent>
<aftsection>
<nextsent>2.2 blender.
</nextsent>
<nextsent>the single parses were blended following the procedure of hallet al (2007).<papid> D07-1097 </papid></nextsent>
<nextsent>the parses of each sentence were combined into weighted directed graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1351">
<title id=" W08-2136.xml">mixing and blending syntactic and semantic dependencies </title>
<section> semantic role labelling.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 features.
</prevsent>
<prevsent>we implemented large number of features (over 50) 1 for the srl system.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
many of them can be found in the literature, starting from gildea and jurafsky (2002) <papid> J02-3001 </papid>and onward.</citsent>
<aftsection>
<nextsent>all features, exceptbag-of-words, take nominal values, which are bi narized for the vectors used as input to the svm classifier.
</nextsent>
<nextsent>low-frequency feature values (exceptfor voice, initial letter, number of words, relative position, and the distance features), below threshold of 20 occurrences, were given default value.
</nextsent>
<nextsent>we distinguish between single node and node pair features.
</nextsent>
<nextsent>the following single node features were used for all three learning tasks and for both the predicate and argument node: 2 ? lemma, pos, and dependency relation (deprel) for the node itself, the parent, and the left and right sibling ? initial letter (upper-case/lower-case), number of words, and voice (based on simple heuristics, only for the predicate node during argument classification) ? pos sequence and pos bag-of-words (bow) for thenode itself with children and for the parent with children ? lemma and pos for the first and last child of the node ? sequence and bow of lemma and pos for content words ? sequence and bow of pos for the immediate childrens content words ? sequence and bow of pos for the parents content words and for the parents immediate children ? sequence and bow of deprels for the node itself, for the immediate children, and for the parents immediate children all extractors of node pair features, where the pair consists of the predicate and the argument node, can be used both for argument identification and argument classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1353">
<title id=" W08-2136.xml">mixing and blending syntactic and semantic dependencies </title>
<section> semantic role labelling.  </section>
<citcontext>
<prevsection>
<prevsent>the likelihood of the chosen labelling was also used as confidence measure for the syntactic blender.
</prevsent>
<prevsent>3.5 blending and post-processing.
</prevsent>
</prevsection>
<citsent citstr=" W05-0625 ">
combining the output from several different systems has been shown to be beneficial (koomenet al, 2005).<papid> W05-0625 </papid></citsent>
<aftsection>
<nextsent>for the final submission, we combined the output of two variants of the pipe lined srl system, each using different data splits, with 3 the version of the joint system used in the submission was based on an early predicate prediction.
</nextsent>
<nextsent>more accurate predicates would give major improvement for the results.
</nextsent>
<nextsent>250 test set pred pos labelled 1 un labelled 1 wsj all 82.90 90.90 nn* 81.12 86.39 vb* 85.52 96.49 brown all 67.48 85.49 nn* 58.34 75.35 vb* 73.24 91.97 table 2: semantic predicate results on the test sets.the srl output of the joint system.
</nextsent>
<nextsent>a simple uniform weight majority vote heuristic was used, withno combinatorial constraints on the selected arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1354">
<title id=" W08-1506.xml">the 2008 medslt system </title>
<section> a bidirectional version </section>
<citcontext>
<prevsection>
<prevsent>= semantic error rate for source language recogniser, on in-coverage material.
</prevsent>
<prevsent>tient will respond non-verbally.
</prevsent>
</prevsection>
<citsent citstr=" W07-1806 ">
our second demo, an early version of which is described in (bouillon et al, 2007), <papid> W07-1806 </papid>supports bidirectional translation for the sore throat domain, in the english ? spanish pair.</citsent>
<aftsection>
<nextsent>here, the english-speaking doctor typically asks wh-questions, and the spanish-speaking patient responds with elliptical utterances, which are translated as full sentence responses.
</nextsent>
<nextsent>a short example dialogue is shown in table 3.
</nextsent>
<nextsent>doctor: where is the pain?
</nextsent>
<nextsent>donde le duele?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1355">
<title id=" W08-1506.xml">the 2008 medslt system </title>
<section> a mobile platform version </section>
<citcontext>
<prevsection>
<prevsent>do you have history of sinus disease?
</prevsent>
<prevsent>table 1: examples of english medslt coverage the tablet, showing the user interface, is presented in figure 1.
</prevsent>
</prevsection>
<citsent citstr=" W06-3702 ">
the sentences appearing under theback-translation at the top are produced by an on line help component, and are intended to guide the user into the grammars coverage (chatzichrisafis et al, 2006).<papid> W06-3702 </papid></citsent>
<aftsection>
<nextsent>the architecture is described further in(tsourakis et al, 2008), which also gives performance results for another regulus applications.these strongly suggest that recognition performance in the client/server environment is no worse than on laptop, as long as comparable microphone is used.
</nextsent>
<nextsent>our final demo highlights the new regulus development environment (kron et al, 2007), <papid> W07-1807 </papid>which has over the last few months acquired large amount of new functionality designed to facilitate rapid prototyping of spoken language applications3 . the developer initially constructs and debugs her components (grammar, translation rules etc) in text view.</nextsent>
<nextsent>as soon as they are consistent, she is able to compile the source-language grammar into arecogniser, and combine this with other components to run complete speech translation system within the development environment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1356">
<title id=" W08-1506.xml">the 2008 medslt system </title>
<section> the development environment.  </section>
<citcontext>
<prevsection>
<prevsent>the sentences appearing under theback-translation at the top are produced by an on line help component, and are intended to guide the user into the grammars coverage (chatzichrisafis et al, 2006).<papid> W06-3702 </papid></prevsent>
<prevsent>the architecture is described further in(tsourakis et al, 2008), which also gives performance results for another regulus applications.these strongly suggest that recognition performance in the client/server environment is no worse than on laptop, as long as comparable microphone is used.</prevsent>
</prevsection>
<citsent citstr=" W07-1807 ">
our final demo highlights the new regulus development environment (kron et al, 2007), <papid> W07-1807 </papid>which has over the last few months acquired large amount of new functionality designed to facilitate rapid prototyping of spoken language applications3 . the developer initially constructs and debugs her components (grammar, translation rules etc) in text view.</citsent>
<aftsection>
<nextsent>as soon as they are consistent, she is able to compile the source-language grammar into arecogniser, and combine this with other components to run complete speech translation system within the development environment.
</nextsent>
<nextsent>connections between components are defined by simple con fig file.
</nextsent>
<nextsent>figure 2 shows an example.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1357">
<title id=" W08-2123.xml">dependency based syntacticx2013semantic analysis with propbank and nombank </title>
<section> syntactic sub model.  </section>
<citcontext>
<prevsection>
<prevsent>t )) returnwaverage we used c value of 0.01, and the number of iterations was 6.
</prevsent>
<prevsent>2.1 features and search.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
the feature function ? is second-order edge factored representation (mcdonald and pereira,2006; <papid> E06-1011 </papid>carreras, 2007).<papid> D07-1101 </papid></citsent>
<aftsection>
<nextsent>the second-order representation allows us to express features not only ofheaddependent links, but also of siblings and children of the dependent.
</nextsent>
<nextsent>this feature set forces usto adopt the expensive search procedure by carreras (2007), <papid> D07-1101 </papid>which extends eisners span-based dynamic programming algorithm (1996) to allow second-order feature dependencies.</nextsent>
<nextsent>since the cost function ? is based on the cost of single links, this procedure can also be used to find the maximizer of (x , ij )+?(y , ij), which is needed at training time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1358">
<title id=" W08-2123.xml">dependency based syntacticx2013semantic analysis with propbank and nombank </title>
<section> syntactic sub model.  </section>
<citcontext>
<prevsection>
<prevsent>t )) returnwaverage we used c value of 0.01, and the number of iterations was 6.
</prevsent>
<prevsent>2.1 features and search.
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
the feature function ? is second-order edge factored representation (mcdonald and pereira,2006; <papid> E06-1011 </papid>carreras, 2007).<papid> D07-1101 </papid></citsent>
<aftsection>
<nextsent>the second-order representation allows us to express features not only ofheaddependent links, but also of siblings and children of the dependent.
</nextsent>
<nextsent>this feature set forces usto adopt the expensive search procedure by carreras (2007), <papid> D07-1101 </papid>which extends eisners span-based dynamic programming algorithm (1996) to allow second-order feature dependencies.</nextsent>
<nextsent>since the cost function ? is based on the cost of single links, this procedure can also be used to find the maximizer of (x , ij )+?(y , ij), which is needed at training time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1362">
<title id=" W08-2123.xml">dependency based syntacticx2013semantic analysis with propbank and nombank </title>
<section> syntactic sub model.  </section>
<citcontext>
<prevsection>
<prevsent>for parsers that consider features of single links only,the chu-liu/edmonds algorithm can be used instead.
</prevsent>
<prevsent>however, this algorithm cannot be generalized to the second-order setting ? mcdonald and pereira (2006) <papid> E06-1011 </papid>proved that this problem is np hard, and described an approximate greedy search algorithm.</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
to simplify implementation, we instead opted for the pseudo-projective approach (nivre and nilsson, 2005), <papid> P05-1013 </papid>in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time.</citsent>
<aftsection>
<nextsent>the useof trace labels in the pseudo-projective transformation leads to proliferation of edge label types: from 69 to 234 in the training set, many of which occur only once.
</nextsent>
<nextsent>since the running time of our parser depends on the number of labels, we used only the 20 most frequent trace labels.
</nextsent>
<nextsent>our semantic model consists of three parts: ? srl classifier pipeline that generates list of candidate predicate argument structures.
</nextsent>
<nextsent>a constraint system that filters the candidate list to enforce linguistic restrictions on the global configuration of arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1365">
<title id=" W08-2108.xml">fast mapping in word learning what probabilities tell us </title>
<section> overview of the computational model.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the overall behaviour of our model confirms that the probabilistic bootstrapping approach to word learning naturally leads to the onset of fast mapping in the course of lexical development, with out hard-coding any specialized learning mechanism into the model to account for this phenomenon.
</prevsent>
<prevsent>this section summarizes the model presented in fa zly et al (2008).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
our word learning algorithm is an adaptation of the ibm translation model proposed bybrown et al (1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>however, our model is incremental, and does not require batch process over the entire data.
</nextsent>
<nextsent>2.1 utterance and meaning representations.
</nextsent>
<nextsent>the input to our word learning model consists of set of utterance scene pairs that link an observed scene(what the child perceives) to the utterance that describes it (what the child hears).
</nextsent>
<nextsent>we represent each utterance as sequence of words, and the corresponding scene as set of meaning symbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1366">
<title id=" W08-0910.xml">retrieval of reading materials for vocabulary and reading practice </title>
<section> learner and teacher support.  </section>
<citcontext>
<prevsection>
<prevsent>other types of exercises are certainly possible.
</prevsent>
<prevsent>for extra review, students also complete exercises for target words from previous readings.students receive immediate feedback on the practice and review exercises.
</prevsent>
</prevsection>
<citsent citstr=" H05-1103 ">
currently, sets of the exercises are manually authored for each target wordand stored in database, but we are exploring automated question generation techniques (brown et al,2005; <papid> H05-1103 </papid>liu et al, 2005).<papid> W05-0201 </papid></citsent>
<aftsection>
<nextsent>at runtime, the system selects practice and review exercises from this repository.
</nextsent>
<nextsent>a number of recent projects have taken similar approaches to providing authentic texts for languagelearners.
</nextsent>
<nextsent>werti (amaral et al, 2006) is an intelligent automatic workbook that uses texts fromthe web to increase knowledge of english grammatical forms and functions.
</nextsent>
<nextsent>read-x (miltsakakiand troutt, 2007) is tool for finding texts at specified reading levels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1367">
<title id=" W08-0910.xml">retrieval of reading materials for vocabulary and reading practice </title>
<section> learner and teacher support.  </section>
<citcontext>
<prevsection>
<prevsent>other types of exercises are certainly possible.
</prevsent>
<prevsent>for extra review, students also complete exercises for target words from previous readings.students receive immediate feedback on the practice and review exercises.
</prevsent>
</prevsection>
<citsent citstr=" W05-0201 ">
currently, sets of the exercises are manually authored for each target wordand stored in database, but we are exploring automated question generation techniques (brown et al,2005; <papid> H05-1103 </papid>liu et al, 2005).<papid> W05-0201 </papid></citsent>
<aftsection>
<nextsent>at runtime, the system selects practice and review exercises from this repository.
</nextsent>
<nextsent>a number of recent projects have taken similar approaches to providing authentic texts for languagelearners.
</nextsent>
<nextsent>werti (amaral et al, 2006) is an intelligent automatic workbook that uses texts fromthe web to increase knowledge of english grammatical forms and functions.
</nextsent>
<nextsent>read-x (miltsakakiand troutt, 2007) is tool for finding texts at specified reading levels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1368">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>over the best single system.
</prevsent>
<prevsent>the rwth approach to mt system combination is refined version of the rover approach in asr (fiscus, 1997), with additional steps to cope with reordering between different hypotheses, andto use true casing information from the input hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the basic concept of the approach has been described by matusov et al (2006).<papid> E06-1005 </papid></citsent>
<aftsection>
<nextsent>several improvements have been added later (matusov et al., 2008).
</nextsent>
<nextsent>this approach includes an enhanced alignment and reordering framework.
</nextsent>
<nextsent>in contrast to existing approaches (jayaraman and lavie, 2005; <papid> P05-3026 </papid>rosti et al, 2007), <papid> P07-1040 </papid>the context of the whole corpus rather than single sentence is considered in this iterative, unsupervised procedure, yielding more reliable alignment.</nextsent>
<nextsent>majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as special n-gram language model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1369">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several improvements have been added later (matusov et al., 2008).
</prevsent>
<prevsent>this approach includes an enhanced alignment and reordering framework.
</prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
in contrast to existing approaches (jayaraman and lavie, 2005; <papid> P05-3026 </papid>rosti et al, 2007), <papid> P07-1040 </papid>the context of the whole corpus rather than single sentence is considered in this iterative, unsupervised procedure, yielding more reliable alignment.</citsent>
<aftsection>
<nextsent>majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as special n-gram language model.
</nextsent>
<nextsent>in this section we present the details of our system combination method.
</nextsent>
<nextsent>figure 1 gives an overview of the system combination architecture described in this section.
</nextsent>
<nextsent>after preprocessing the mt hypotheses, pairwise alignments between the hypotheses are calculated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1370">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several improvements have been added later (matusov et al., 2008).
</prevsent>
<prevsent>this approach includes an enhanced alignment and reordering framework.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
in contrast to existing approaches (jayaraman and lavie, 2005; <papid> P05-3026 </papid>rosti et al, 2007), <papid> P07-1040 </papid>the context of the whole corpus rather than single sentence is considered in this iterative, unsupervised procedure, yielding more reliable alignment.</citsent>
<aftsection>
<nextsent>majority voting on the generated lattice is performed using the prior probabilities for each system as well as other statistical models such as special n-gram language model.
</nextsent>
<nextsent>in this section we present the details of our system combination method.
</nextsent>
<nextsent>figure 1 gives an overview of the system combination architecture described in this section.
</nextsent>
<nextsent>after preprocessing the mt hypotheses, pairwise alignments between the hypotheses are calculated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1371">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>since it is not clear which hypothesis should be primary, i. e. has the best?
</prevsent>
<prevsent>word order, we let every hypothesis play the role of the primary translation, and align all pairs of hypotheses (en, em); 6= m. the word alignment is trained in analogy to the alignment training procedure in statistical mt. the difference is that the two sentences that have to be aligned are in the same language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use theibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>and the hidden markov model (hmm, (vogel et al, 1996)) <papid> C96-2141 </papid>to estimate the alignment model.</citsent>
<aftsection>
<nextsent>the alignment training corpus is created from atest corpus1 of effectively ?
</nextsent>
<nextsent>(m ? 1) ? sentences translated by the involved mt engines.
</nextsent>
<nextsent>the single-word based lexicon probabilities p(e|e?) areinitialized from normalized lexicon counts collected over the sentence pairs (em, en) on this corpus.
</nextsent>
<nextsent>since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some and j. in addition, we add fraction of count for words with identical prefixes.1a test corpus can be used directly because the alignment training is unsupervised and only automatically produced translations are considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1372">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>since it is not clear which hypothesis should be primary, i. e. has the best?
</prevsent>
<prevsent>word order, we let every hypothesis play the role of the primary translation, and align all pairs of hypotheses (en, em); 6= m. the word alignment is trained in analogy to the alignment training procedure in statistical mt. the difference is that the two sentences that have to be aligned are in the same language.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
we use theibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>and the hidden markov model (hmm, (vogel et al, 1996)) <papid> C96-2141 </papid>to estimate the alignment model.</citsent>
<aftsection>
<nextsent>the alignment training corpus is created from atest corpus1 of effectively ?
</nextsent>
<nextsent>(m ? 1) ? sentences translated by the involved mt engines.
</nextsent>
<nextsent>the single-word based lexicon probabilities p(e|e?) areinitialized from normalized lexicon counts collected over the sentence pairs (em, en) on this corpus.
</nextsent>
<nextsent>since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some and j. in addition, we add fraction of count for words with identical prefixes.1a test corpus can be used directly because the alignment training is unsupervised and only automatically produced translations are considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1373">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the single-word based lexicon probabilities p(e|e?) areinitialized from normalized lexicon counts collected over the sentence pairs (em, en) on this corpus.
</prevsent>
<prevsent>since all of the hypotheses are in the same language, we count co-occurring identical words, i. e. whether em,j is the same word as en,i for some and j. in addition, we add fraction of count for words with identical prefixes.1a test corpus can be used directly because the alignment training is unsupervised and only automatically produced translations are considered.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
51the model parameters are trained iteratively using the giza++ toolkit (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the training is performed in the directions em ? en and en ? em.
</nextsent>
<nextsent>after each iteration, the updated lexicon tables from the two directions are interpolated.
</nextsent>
<nextsent>the final alignments are determined using cost matrix for each sentence pair (em, en).
</nextsent>
<nextsent>elements of this matrix are the local costs c(j, i) of aligning word em,j from em to word en,i from en.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1374">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the final alignments are determined using cost matrix for each sentence pair (em, en).
</prevsent>
<prevsent>elements of this matrix are the local costs c(j, i) of aligning word em,j from em to word en,i from en.
</prevsent>
</prevsection>
<citsent citstr=" C04-1032 ">
following matusov et al (2004), <papid> C04-1032 </papid>we compute these local costs by interpol ating the negated logarithms of the state occupation probabilities from the source-to-target?</citsent>
<aftsection>
<nextsent>and target-tosource?
</nextsent>
<nextsent>training of the hmm model.
</nextsent>
<nextsent>two different alignments are computed using the cost matrixc: the alignment a?
</nextsent>
<nextsent>used for reordering each secondary translation em, and the alignment a?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1375">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> system combination algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>used for reordering each secondary translation em, and the alignment a?
</prevsent>
<prevsent>used to build the confusion network.
</prevsent>
</prevsection>
<citsent citstr=" D08-1011 ">
in addition to the giza++ alignments, we have also conducted preliminary experiments following he et al (2008) <papid> D08-1011 </papid>to exploit character-based similarity, as well as estimating p(e|e?) :=?</citsent>
<aftsection>
<nextsent>f p(e|f)p(f |e?) directly from bilingual lexicon.
</nextsent>
<nextsent>but we were not able to find improvements over the giza++ alignments so far.
</nextsent>
<nextsent>2.2 word reordering and confusion.
</nextsent>
<nextsent>network generation after reordering each secondary hypothesis em and the rows of the corresponding alignment cost matrix according to a?, we determine m1 monotone one-to-one alignments between en as the primary translation and em,m = 1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1377">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> tuning system weights.  </section>
<citcontext>
<prevsection>
<prevsent>systems written in oblique were also used in the cross lingual task (rbmt3 for fren).deen google, liu, rbmt3, rwth, stuttgart, systran, uedin, uka, umd esen google, nict, rbmt4, rwth, talp-upc, uedinfren dcu, google, jhu, limsi, lium systran, rbmt4, rwth, uedin, uka publicly available condor optimization toolkit (berghen and bersini, 2005).
</prevsent>
<prevsent>for the wmt 2009 workshop, we selected linear combina-.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
tion of bleu (papineni et al, 2002) <papid> P02-1040 </papid>and ter (snover et al, 2006) as optimization criterion, ??</citsent>
<aftsection>
<nextsent>:= argmax?
</nextsent>
<nextsent>{(2 ? bleu)?
</nextsent>
<nextsent>ter}, based on previous experience (mauser et al, 2008).<papid> L08-1403 </papid></nextsent>
<nextsent>we used the whole dev set as tuning set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1378">
<title id=" W09-0407.xml">the rwth system combination system for wmt 2009 </title>
<section> tuning system weights.  </section>
<citcontext>
<prevsection>
<prevsent>:= argmax?
</prevsent>
<prevsent>{(2 ? bleu)?
</prevsent>
</prevsection>
<citsent citstr=" L08-1403 ">
ter}, based on previous experience (mauser et al, 2008).<papid> L08-1403 </papid></citsent>
<aftsection>
<nextsent>we used the whole dev set as tuning set.
</nextsent>
<nextsent>for more stable results, we used the case-insensitive variants for both measures, despite the explicit use of case information in our approach.
</nextsent>
<nextsent>due to the large number of submissions (71 in total for the language pairs deen, esen, fren), we had to select reasonable number of systems to be able to tune the parameters in reliable way.
</nextsent>
<nextsent>based on previous experience, we manually selected the systems with the best bleu/ter score, and tried different variations of this selection, e.g. by removing systems which had low weights after optimization, or by adding promising systems, like rule based systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1379">
<title id=" W09-1214.xml">the crotal srl system  a generic tool based on tree structured crf </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>crf are powerful machine learning technique that has been successfully applied to large number of natural language tasks, mainly to tag sequences.
</prevsent>
<prevsent>compared to classification techniques, crf can easily take into account dependencies among annotations: it is therefore possible to represent tree-like structures in the input of the algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P08-1109 ">
recently, crf using tree structures were used in (finkel et al, 2008) <papid> P08-1109 </papid>in the case of parsing.before participating to this shared task, our prototype had only been used to annotate function tags in french treebank: these data were drastically this work has been funded by the french national project anr-07-mdco-03 crotal?.</citsent>
<aftsection>
<nextsent>1we have participated in the srl-only category.
</nextsent>
<nextsent>smaller, and the task was simpler.
</nextsent>
<nextsent>therefore conll 2009 st is the first time the crotal system is run.
</nextsent>
<nextsent>for quite complex task, with so many data as input, and seven different languages (catalan, spanish (taule?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1380">
<title id=" W09-1214.xml">the crotal srl system  a generic tool based on tree structured crf </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for quite complex task, with so many data as input, and seven different languages (catalan, spanish (taule?
</prevsent>
<prevsent>et al, 2008), chinese (palmer and xue, 2009), czech (hajic?
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
et al, 2006), english (surdeanu et al, 2008), <papid> W08-2121 </papid>german (burchardt et al, 2006) and japanese (kawahara et al, 2002)).</citsent>
<aftsection>
<nextsent>in this context, the performance we obtained seems reasonable: our average f1-measure is 66.49% (evaluation dataset).
</nextsent>
<nextsent>one of the advantages we want to emphasise about our system is its genericity: the system does not need lot of information as input (we mainly use pos and deprel columns, and the frame sets havenot been used), and it was able to achieve satisfying results for the seven different languages using nearly the same parameters (differences were essentially due to the volume of data, since it was sometimes necessary to reduce the processing time).
</nextsent>
<nextsent>of course, we hope to improve this prototype thanks to this experience: it may become necessary to lose in genericity in order to gain in performance, but ourgoal is to maintain as much as possible this advantage.
</nextsent>
<nextsent>in section 2 we explain the general architecture for crotal, then we explain how features are selected in our system in section 3, and finally we detail and discuss the results in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1381">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern statistical machine translation (smt) systems are typically trained on sentence-aligned parallel texts (bi-texts) from particular domain.
</prevsent>
<prevsent>when tested on text from that domain, they demonstrate state-of-the art performance, but on out-of-domain test data the results can deteriorate significantly.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
for example, on the wmt06 shared translation task, the scores for french-to-english translation dropped from about 30 to about 20 bleu points for nearly all systems when tested on news commentary instead of the europarl1 text, which was used for training (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>1see (koehn, 2005) for details about the europarl corpus.
</nextsent>
<nextsent>subsequently, in 2007 and 2008, the wmt shared translation task organizers provided limited amount of bilingual news commentary training data (1-1.3m words) in addition to the large amount of europarl data (30-32m words),and set up separate evaluations on news commentary and on europarl data, thus inviting interest in domain adaptation experiments for the news do main (callison-burch et al, 2007; callison-burch et al, 2008).
</nextsent>
<nextsent>this year, the evaluation is on news commentary only, which makes domain adaptation the central focus of the shared translation task.the team of the national university of singapore (nus) participated in the wmt09 shared translation task with an english-to-spanish system.2 our approach is based on domain adaptation, combining the small in-domain news commentary bi-text (1.8m words) and the large out of-domain one from the europarl corpus (40m words), from which we built and combined two separate phrase tables.
</nextsent>
<nextsent>we further used two language models (in-domain and out-of-domain), cognates, improved tokenization, and additional smart re casing as post-processing step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1382">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>in our baseline experiments, we used the following general setup: first, we tokenized the par2the task organizers invited submissions translating forward and/or backward between english and five other european languages (french, spanish, german, czech and hun garian), but we only participated in english spanish, due to time limitations.
</prevsent>
<prevsent>75allel bi-text, converted it to lowercase, and filtered out the overly-long training sentences, which complicate word alignments (we tried maximum length limits of 40 and 100).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we then built separate english-to-spanish and spanish-to-english directed word alignments using ibm model 4(brown et al, 1993), <papid> J93-2003 </papid>combined them using the in tersect+grow heuristic (och and ney, 2003), <papid> J03-1002 </papid>and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>we thus obtained phrase table where each phrase translation pairis associated with the following five standard pa rameters: forward and reverse phrase translation probabilities, forward and reverse lexical translation probabilities, and phrase penalty.
</nextsent>
<nextsent>we then trained log-linear model using the standard feature functions: language model probability, word penalty, distortion costs (we tried distance based and lexicalized reordering models), and the parameters from the phrase table.
</nextsent>
<nextsent>weset al feature weights by optimizing bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>directly using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the tuning part of the development set (dev-test2009a).</nextsent>
<nextsent>we used these weights in beam search decoder (koehn et al, 2007) <papid> P07-2045 </papid>to translate the test sentences (the english part of dev-test2009b, tokenized and lowercased).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1383">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>in our baseline experiments, we used the following general setup: first, we tokenized the par2the task organizers invited submissions translating forward and/or backward between english and five other european languages (french, spanish, german, czech and hun garian), but we only participated in english spanish, due to time limitations.
</prevsent>
<prevsent>75allel bi-text, converted it to lowercase, and filtered out the overly-long training sentences, which complicate word alignments (we tried maximum length limits of 40 and 100).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we then built separate english-to-spanish and spanish-to-english directed word alignments using ibm model 4(brown et al, 1993), <papid> J93-2003 </papid>combined them using the in tersect+grow heuristic (och and ney, 2003), <papid> J03-1002 </papid>and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>we thus obtained phrase table where each phrase translation pairis associated with the following five standard pa rameters: forward and reverse phrase translation probabilities, forward and reverse lexical translation probabilities, and phrase penalty.
</nextsent>
<nextsent>we then trained log-linear model using the standard feature functions: language model probability, word penalty, distortion costs (we tried distance based and lexicalized reordering models), and the parameters from the phrase table.
</nextsent>
<nextsent>weset al feature weights by optimizing bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>directly using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the tuning part of the development set (dev-test2009a).</nextsent>
<nextsent>we used these weights in beam search decoder (koehn et al, 2007) <papid> P07-2045 </papid>to translate the test sentences (the english part of dev-test2009b, tokenized and lowercased).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1384">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>in our baseline experiments, we used the following general setup: first, we tokenized the par2the task organizers invited submissions translating forward and/or backward between english and five other european languages (french, spanish, german, czech and hun garian), but we only participated in english spanish, due to time limitations.
</prevsent>
<prevsent>75allel bi-text, converted it to lowercase, and filtered out the overly-long training sentences, which complicate word alignments (we tried maximum length limits of 40 and 100).
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
we then built separate english-to-spanish and spanish-to-english directed word alignments using ibm model 4(brown et al, 1993), <papid> J93-2003 </papid>combined them using the in tersect+grow heuristic (och and ney, 2003), <papid> J03-1002 </papid>and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>we thus obtained phrase table where each phrase translation pairis associated with the following five standard pa rameters: forward and reverse phrase translation probabilities, forward and reverse lexical translation probabilities, and phrase penalty.
</nextsent>
<nextsent>we then trained log-linear model using the standard feature functions: language model probability, word penalty, distortion costs (we tried distance based and lexicalized reordering models), and the parameters from the phrase table.
</nextsent>
<nextsent>weset al feature weights by optimizing bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>directly using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the tuning part of the development set (dev-test2009a).</nextsent>
<nextsent>we used these weights in beam search decoder (koehn et al, 2007) <papid> P07-2045 </papid>to translate the test sentences (the english part of dev-test2009b, tokenized and lowercased).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1385">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>we thus obtained phrase table where each phrase translation pairis associated with the following five standard pa rameters: forward and reverse phrase translation probabilities, forward and reverse lexical translation probabilities, and phrase penalty.
</prevsent>
<prevsent>we then trained log-linear model using the standard feature functions: language model probability, word penalty, distortion costs (we tried distance based and lexicalized reordering models), and the parameters from the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
weset al feature weights by optimizing bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>directly using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the tuning part of the development set (dev-test2009a).</citsent>
<aftsection>
<nextsent>we used these weights in beam search decoder (koehn et al, 2007) <papid> P07-2045 </papid>to translate the test sentences (the english part of dev-test2009b, tokenized and lowercased).</nextsent>
<nextsent>we then recased the output using monotone model that translates from lowercase to upper case spanish, we post-cased it using simple heuristic, de-tokenized the result, and compared it to the gold standard (the spanish part of dev-test2009b) using bleu and nist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1386">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>we thus obtained phrase table where each phrase translation pairis associated with the following five standard pa rameters: forward and reverse phrase translation probabilities, forward and reverse lexical translation probabilities, and phrase penalty.
</prevsent>
<prevsent>we then trained log-linear model using the standard feature functions: language model probability, word penalty, distortion costs (we tried distance based and lexicalized reordering models), and the parameters from the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
weset al feature weights by optimizing bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>directly using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the tuning part of the development set (dev-test2009a).</citsent>
<aftsection>
<nextsent>we used these weights in beam search decoder (koehn et al, 2007) <papid> P07-2045 </papid>to translate the test sentences (the english part of dev-test2009b, tokenized and lowercased).</nextsent>
<nextsent>we then recased the output using monotone model that translates from lowercase to upper case spanish, we post-cased it using simple heuristic, de-tokenized the result, and compared it to the gold standard (the spanish part of dev-test2009b) using bleu and nist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1387">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>we then trained log-linear model using the standard feature functions: language model probability, word penalty, distortion costs (we tried distance based and lexicalized reordering models), and the parameters from the phrase table.
</prevsent>
<prevsent>weset al feature weights by optimizing bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>directly using minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the tuning part of the development set (dev-test2009a).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used these weights in beam search decoder (koehn et al, 2007) <papid> P07-2045 </papid>to translate the test sentences (the english part of dev-test2009b, tokenized and lowercased).</citsent>
<aftsection>
<nextsent>we then recased the output using monotone model that translates from lowercase to upper case spanish, we post-cased it using simple heuristic, de-tokenized the result, and compared it to the gold standard (the spanish part of dev-test2009b) using bleu and nist.
</nextsent>
<nextsent>2.2 nonstandard settings.
</nextsent>
<nextsent>the nonstandard features of our system can be summarized as follows: two language models.
</nextsent>
<nextsent>following nakovand hearst (2007), <papid> W07-0730 </papid>we used two language models (lm) ? an in-domain one (trained on concatenation of the provided monolingual spanish news commentary data and the spanish side of the training news commentary bi-text) and an out-of domain one (trained on the provided monolingual spanish europarl data).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1388">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 nonstandard settings.
</prevsent>
<prevsent>the nonstandard features of our system can be summarized as follows: two language models.
</prevsent>
</prevsection>
<citsent citstr=" W07-0730 ">
following nakovand hearst (2007), <papid> W07-0730 </papid>we used two language models (lm) ? an in-domain one (trained on concatenation of the provided monolingual spanish news commentary data and the spanish side of the training news commentary bi-text) and an out-of domain one (trained on the provided monolingual spanish europarl data).</citsent>
<aftsection>
<nextsent>for both lms, we used 5-gram models with kneser-ney smoothing.
</nextsent>
<nextsent>merging two phrase tables.
</nextsent>
<nextsent>followingnakov (2008), <papid> W08-0320 </papid>we trained and merged two phrase based smt systems: small in-domain one using the news commentary bi-text, and large out-of domain one using the europarl bi-text.</nextsent>
<nextsent>as result, we obtained two phrase tables, tnews and teuro, and two lexicalized reordering models, rnews and reuro.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1389">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>for both lms, we used 5-gram models with kneser-ney smoothing.
</prevsent>
<prevsent>merging two phrase tables.
</prevsent>
</prevsection>
<citsent citstr=" W08-0320 ">
followingnakov (2008), <papid> W08-0320 </papid>we trained and merged two phrase based smt systems: small in-domain one using the news commentary bi-text, and large out-of domain one using the europarl bi-text.</citsent>
<aftsection>
<nextsent>as result, we obtained two phrase tables, tnews and teuro, and two lexicalized reordering models, rnews and reuro.
</nextsent>
<nextsent>we merged the phrase table as follows.
</nextsent>
<nextsent>first, we kept all phrase pairs from tnews.
</nextsent>
<nextsent>then we added those phrase pairs from teuro which were not present in tnews.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1390">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>when building the two phrase tables, we also built two lexicalized reordering tables (koehn et al., 2005) for them, rnews and reuro, which we merged as follows: we first kept all phrases from rnews, then we added those from reuro which were not present in rnews.
</prevsent>
<prevsent>this resulting lexicalized reordering table was used together with the above-described merged phrase table.cognates.
</prevsent>
</prevsection>
<citsent citstr=" N03-2016 ">
previous research has shown that using cognates can yield better word alignments (al onaizan et al, 1999; kondrak et al, 2003), <papid> N03-2016 </papid>which in turn often means higher-quality phrase pairs and better smt systems.</citsent>
<aftsection>
<nextsent>linguists define cognates as words derived from common root (bickford and tuggy, 2002).
</nextsent>
<nextsent>following previous researcher sin computational linguistics (bergsma and kondrak, 2007; <papid> P07-1083 </papid>mann and yarowsky, 2001; <papid> N01-1020 </papid>melamed, 1999), <papid> J99-1003 </papid>however, we adopted simplified definition which ignores origin, defining cognates as words in different languages that are mutual translations and have similar orthography.</nextsent>
<nextsent>we extracted and used such potential cognates in order tobias the training of the ibm word alignment models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1391">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>previous research has shown that using cognates can yield better word alignments (al onaizan et al, 1999; kondrak et al, 2003), <papid> N03-2016 </papid>which in turn often means higher-quality phrase pairs and better smt systems.</prevsent>
<prevsent>linguists define cognates as words derived from common root (bickford and tuggy, 2002).</prevsent>
</prevsection>
<citsent citstr=" P07-1083 ">
following previous researcher sin computational linguistics (bergsma and kondrak, 2007; <papid> P07-1083 </papid>mann and yarowsky, 2001; <papid> N01-1020 </papid>melamed, 1999), <papid> J99-1003 </papid>however, we adopted simplified definition which ignores origin, defining cognates as words in different languages that are mutual translations and have similar orthography.</citsent>
<aftsection>
<nextsent>we extracted and used such potential cognates in order tobias the training of the ibm word alignment models.
</nextsent>
<nextsent>following melamed (1995), <papid> W95-0115 </papid>we measured the orthographic similarity using longest common subse quence ratio (lcsr), which is defined as follows: lcsr(s1, s2) = |lcs(s1,s2)|max(|s1|,|s2|)where lcs(s1, s2) is the longest common subse quence of s1 and s2, and |s| is the length of s. following nakov et al (2007), we combined the lcsr similarity measure with competitive linking(melamed, 2000) <papid> J00-2004 </papid>in order to extract potential cog 76nates from the training bi-text.</nextsent>
<nextsent>competitive linking assumes that, given source english sentence and its spanish translation, source word is either translated with single target word or is not translated at all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1392">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>previous research has shown that using cognates can yield better word alignments (al onaizan et al, 1999; kondrak et al, 2003), <papid> N03-2016 </papid>which in turn often means higher-quality phrase pairs and better smt systems.</prevsent>
<prevsent>linguists define cognates as words derived from common root (bickford and tuggy, 2002).</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
following previous researcher sin computational linguistics (bergsma and kondrak, 2007; <papid> P07-1083 </papid>mann and yarowsky, 2001; <papid> N01-1020 </papid>melamed, 1999), <papid> J99-1003 </papid>however, we adopted simplified definition which ignores origin, defining cognates as words in different languages that are mutual translations and have similar orthography.</citsent>
<aftsection>
<nextsent>we extracted and used such potential cognates in order tobias the training of the ibm word alignment models.
</nextsent>
<nextsent>following melamed (1995), <papid> W95-0115 </papid>we measured the orthographic similarity using longest common subse quence ratio (lcsr), which is defined as follows: lcsr(s1, s2) = |lcs(s1,s2)|max(|s1|,|s2|)where lcs(s1, s2) is the longest common subse quence of s1 and s2, and |s| is the length of s. following nakov et al (2007), we combined the lcsr similarity measure with competitive linking(melamed, 2000) <papid> J00-2004 </papid>in order to extract potential cog 76nates from the training bi-text.</nextsent>
<nextsent>competitive linking assumes that, given source english sentence and its spanish translation, source word is either translated with single target word or is not translated at all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1393">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>previous research has shown that using cognates can yield better word alignments (al onaizan et al, 1999; kondrak et al, 2003), <papid> N03-2016 </papid>which in turn often means higher-quality phrase pairs and better smt systems.</prevsent>
<prevsent>linguists define cognates as words derived from common root (bickford and tuggy, 2002).</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
following previous researcher sin computational linguistics (bergsma and kondrak, 2007; <papid> P07-1083 </papid>mann and yarowsky, 2001; <papid> N01-1020 </papid>melamed, 1999), <papid> J99-1003 </papid>however, we adopted simplified definition which ignores origin, defining cognates as words in different languages that are mutual translations and have similar orthography.</citsent>
<aftsection>
<nextsent>we extracted and used such potential cognates in order tobias the training of the ibm word alignment models.
</nextsent>
<nextsent>following melamed (1995), <papid> W95-0115 </papid>we measured the orthographic similarity using longest common subse quence ratio (lcsr), which is defined as follows: lcsr(s1, s2) = |lcs(s1,s2)|max(|s1|,|s2|)where lcs(s1, s2) is the longest common subse quence of s1 and s2, and |s| is the length of s. following nakov et al (2007), we combined the lcsr similarity measure with competitive linking(melamed, 2000) <papid> J00-2004 </papid>in order to extract potential cog 76nates from the training bi-text.</nextsent>
<nextsent>competitive linking assumes that, given source english sentence and its spanish translation, source word is either translated with single target word or is not translated at all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1394">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>following previous researcher sin computational linguistics (bergsma and kondrak, 2007; <papid> P07-1083 </papid>mann and yarowsky, 2001; <papid> N01-1020 </papid>melamed, 1999), <papid> J99-1003 </papid>however, we adopted simplified definition which ignores origin, defining cognates as words in different languages that are mutual translations and have similar orthography.</prevsent>
<prevsent>we extracted and used such potential cognates in order tobias the training of the ibm word alignment models.</prevsent>
</prevsection>
<citsent citstr=" W95-0115 ">
following melamed (1995), <papid> W95-0115 </papid>we measured the orthographic similarity using longest common subse quence ratio (lcsr), which is defined as follows: lcsr(s1, s2) = |lcs(s1,s2)|max(|s1|,|s2|)where lcs(s1, s2) is the longest common subse quence of s1 and s2, and |s| is the length of s. following nakov et al (2007), we combined the lcsr similarity measure with competitive linking(melamed, 2000) <papid> J00-2004 </papid>in order to extract potential cog 76nates from the training bi-text.</citsent>
<aftsection>
<nextsent>competitive linking assumes that, given source english sentence and its spanish translation, source word is either translated with single target word or is not translated at all.
</nextsent>
<nextsent>given an english-spanish sentence pair, we calculated lcsr for all cross-lingual word pairs (excluding stop words and words of length 3 or less), which induced fully-connected weighted bipartite graph.
</nextsent>
<nextsent>then, we performed greedy approximation to the maximum weightedbipartite matching in that graph (competitive linking) as follows: first, we aligned the most similar pair of unaligned words and we discarded these words from further consideration.
</nextsent>
<nextsent>then, we aligned the next most similar pair of unaligned words, and so forth.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1395">
<title id=" W09-0412.xml">nus at wmt09 domain adaptation experiments for english spanish machine translation of news commentary text </title>
<section> the nus system.  </section>
<citcontext>
<prevsection>
<prevsent>following previous researcher sin computational linguistics (bergsma and kondrak, 2007; <papid> P07-1083 </papid>mann and yarowsky, 2001; <papid> N01-1020 </papid>melamed, 1999), <papid> J99-1003 </papid>however, we adopted simplified definition which ignores origin, defining cognates as words in different languages that are mutual translations and have similar orthography.</prevsent>
<prevsent>we extracted and used such potential cognates in order tobias the training of the ibm word alignment models.</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
following melamed (1995), <papid> W95-0115 </papid>we measured the orthographic similarity using longest common subse quence ratio (lcsr), which is defined as follows: lcsr(s1, s2) = |lcs(s1,s2)|max(|s1|,|s2|)where lcs(s1, s2) is the longest common subse quence of s1 and s2, and |s| is the length of s. following nakov et al (2007), we combined the lcsr similarity measure with competitive linking(melamed, 2000) <papid> J00-2004 </papid>in order to extract potential cog 76nates from the training bi-text.</citsent>
<aftsection>
<nextsent>competitive linking assumes that, given source english sentence and its spanish translation, source word is either translated with single target word or is not translated at all.
</nextsent>
<nextsent>given an english-spanish sentence pair, we calculated lcsr for all cross-lingual word pairs (excluding stop words and words of length 3 or less), which induced fully-connected weighted bipartite graph.
</nextsent>
<nextsent>then, we performed greedy approximation to the maximum weightedbipartite matching in that graph (competitive linking) as follows: first, we aligned the most similar pair of unaligned words and we discarded these words from further consideration.
</nextsent>
<nextsent>then, we aligned the next most similar pair of unaligned words, and so forth.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1398">
<title id=" W08-2205.xml">augmenting wordnet for deep understanding of text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our work we are developing several augmentations to wordnet to improve its utility further, and we report here on our experiences to date.
</prevsent>
<prevsent>although we are performing experiments with recognizing textual entailment (rte)(determining whether hypothesis sentence follows from some text t), it is important to note that rte is not our end-goal.
</prevsent>
</prevsection>
<citsent citstr=" W07-1420 ">
many existing rte systems, e.g., (adamset al , 2007; <papid> W07-1420 </papid>chambers et al , 2007) <papid> W07-1427 </papid>largely work by statistically scoring the match between and h, but this to an extent sidesteps deep?</citsent>
<aftsection>
<nextsent>language understanding, namely building coherent, internal representation of the overall scenario the input text was intended to convey.
</nextsent>
<nextsent>rte is one way of measuring success in this endeavor, but it is also possible to do moderately well in rte without the system even attempting to understand?
</nextsent>
<nextsent>the scenario the text is describing.
</nextsent>
<nextsent>it is yet to be seen whether very high performance in rte can be obtained without some kind of deep language understanding of the entire scene that text conveys.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1399">
<title id=" W08-2205.xml">augmenting wordnet for deep understanding of text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our work we are developing several augmentations to wordnet to improve its utility further, and we report here on our experiences to date.
</prevsent>
<prevsent>although we are performing experiments with recognizing textual entailment (rte)(determining whether hypothesis sentence follows from some text t), it is important to note that rte is not our end-goal.
</prevsent>
</prevsection>
<citsent citstr=" W07-1427 ">
many existing rte systems, e.g., (adamset al , 2007; <papid> W07-1420 </papid>chambers et al , 2007) <papid> W07-1427 </papid>largely work by statistically scoring the match between and h, but this to an extent sidesteps deep?</citsent>
<aftsection>
<nextsent>language understanding, namely building coherent, internal representation of the overall scenario the input text was intended to convey.
</nextsent>
<nextsent>rte is one way of measuring success in this endeavor, but it is also possible to do moderately well in rte without the system even attempting to understand?
</nextsent>
<nextsent>the scenario the text is describing.
</nextsent>
<nextsent>it is yet to be seen whether very high performance in rte can be obtained without some kind of deep language understanding of the entire scene that text conveys.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1400">
<title id=" W08-2205.xml">augmenting wordnet for deep understanding of text </title>
<section> exploiting lexical &amp; world knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>second, two new app roches for amassing knowledge are available today that were not available previously, namely automated learning from corpora, and use of web volunteers (e.g., (chklovski, 2005)), and may be applicable to script acquisition (script work in the 70s typically worked with tiny databases of scripts).
</prevsent>
<prevsent>finally, techniques for language processing have substantially improved, making core tasks (e.g., parsing) less problematic, and opening the possibility to easy authoring of scripts in english, followed by machine interpretation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
framenet (baker et al , 1998) <papid> P98-1013 </papid>already provides few small scripts, but does not currently encode the complex scenarios that we would like; vastly expanded resource would be highly useful.</citsent>
<aftsection>
<nextsent>we are in the early stages of exploring this avenue, encoding scripts as list of simple english sentences, which are then automatically translated to wordnet-sense tagged logic using our software.
</nextsent>
<nextsent>for example, bombing?
</nextsent>
<nextsent>script looks: building is bombed by an attacker.
</nextsent>
<nextsent>the attacker plants the bomb in the building.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1401">
<title id=" W08-1304.xml">toward a cross framework parser annotation standard </title>
<section> predicate-argument structures, not.  </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>labelled bracketings competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult andin the limit uninteresting.
</prevsent>
</prevsection>
<citsent citstr=" W03-1013 ">
the syntactic structures of combinatory categorial grammar (ccg: steedman (2000), hockenmaier (2003), clark and curran (2003)), <papid> W03-1013 </papid>for example, contrast sharply with those of the penn treebank marcus et al (1993), <papid> J93-2004 </papid>and the ptb structures differ in many less dramatic though equally important details from those assigned in lexical functional grammar (lfg: bresnan and kaplan (1982)) or head-driven phrase structure grammar (hpsg: pollard andsag (1994)).</citsent>
<aftsection>
<nextsent>we even find variation in the assignments of part-of-speech tags for individual tokens,for example with words like missionary?
</nextsent>
<nextsent>or classical?
</nextsent>
<nextsent>treated as adjectives in some of the annotations and as nouns in others.
</nextsent>
<nextsent>furthermore, simple labelled bracketing of surface tokens obscures the fact that single syntactic constituent can fill multiple roles in the logical structure expressed by sentence, as with controlled subjects, relative clauses, appositives, coordination, etc. more detailed discussions of the obstacles to directly comparing syntactic structures include preiss (2003), <papid> E03-1025 </papid>clark and curran (2007), <papid> P07-1032 </papid>and most recently sagae et al (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1402">
<title id=" W08-1304.xml">toward a cross framework parser annotation standard </title>
<section> predicate-argument structures, not.  </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>labelled bracketings competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult andin the limit uninteresting.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the syntactic structures of combinatory categorial grammar (ccg: steedman (2000), hockenmaier (2003), clark and curran (2003)), <papid> W03-1013 </papid>for example, contrast sharply with those of the penn treebank marcus et al (1993), <papid> J93-2004 </papid>and the ptb structures differ in many less dramatic though equally important details from those assigned in lexical functional grammar (lfg: bresnan and kaplan (1982)) or head-driven phrase structure grammar (hpsg: pollard andsag (1994)).</citsent>
<aftsection>
<nextsent>we even find variation in the assignments of part-of-speech tags for individual tokens,for example with words like missionary?
</nextsent>
<nextsent>or classical?
</nextsent>
<nextsent>treated as adjectives in some of the annotations and as nouns in others.
</nextsent>
<nextsent>furthermore, simple labelled bracketing of surface tokens obscures the fact that single syntactic constituent can fill multiple roles in the logical structure expressed by sentence, as with controlled subjects, relative clauses, appositives, coordination, etc. more detailed discussions of the obstacles to directly comparing syntactic structures include preiss (2003), <papid> E03-1025 </papid>clark and curran (2007), <papid> P07-1032 </papid>and most recently sagae et al (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1403">
<title id=" W08-1304.xml">toward a cross framework parser annotation standard </title>
<section> predicate-argument structures, not.  </section>
<citcontext>
<prevsection>
<prevsent>or classical?
</prevsent>
<prevsent>treated as adjectives in some of the annotations and as nouns in others.
</prevsent>
</prevsection>
<citsent citstr=" E03-1025 ">
furthermore, simple labelled bracketing of surface tokens obscures the fact that single syntactic constituent can fill multiple roles in the logical structure expressed by sentence, as with controlled subjects, relative clauses, appositives, coordination, etc. more detailed discussions of the obstacles to directly comparing syntactic structures include preiss (2003), <papid> E03-1025 </papid>clark and curran (2007), <papid> P07-1032 </papid>and most recently sagae et al (2008).</citsent>
<aftsection>
<nextsent>since it is this underlying logical content thatwe seek when parsing sentence, the target annotation for cross-framework comparison should not include marking of syntactic constituents, but focus instead on the predicate argument structures determined by the syntactic analysis, as proposed ten years ago by carroll et al (1998).
</nextsent>
<nextsent>several of 24 the annotations provided in the shared task already do this, providing good set of starting points for negotiating common target.
</nextsent>
<nextsent>some of the issues in need of negotiation are quite general in nature, while many others involve specific phenomena.
</nextsent>
<nextsent>first, the general ones: 3.1 unique identifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1404">
<title id=" W08-1304.xml">toward a cross framework parser annotation standard </title>
<section> predicate-argument structures, not.  </section>
<citcontext>
<prevsection>
<prevsent>or classical?
</prevsent>
<prevsent>treated as adjectives in some of the annotations and as nouns in others.
</prevsent>
</prevsection>
<citsent citstr=" P07-1032 ">
furthermore, simple labelled bracketing of surface tokens obscures the fact that single syntactic constituent can fill multiple roles in the logical structure expressed by sentence, as with controlled subjects, relative clauses, appositives, coordination, etc. more detailed discussions of the obstacles to directly comparing syntactic structures include preiss (2003), <papid> E03-1025 </papid>clark and curran (2007), <papid> P07-1032 </papid>and most recently sagae et al (2008).</citsent>
<aftsection>
<nextsent>since it is this underlying logical content thatwe seek when parsing sentence, the target annotation for cross-framework comparison should not include marking of syntactic constituents, but focus instead on the predicate argument structures determined by the syntactic analysis, as proposed ten years ago by carroll et al (1998).
</nextsent>
<nextsent>several of 24 the annotations provided in the shared task already do this, providing good set of starting points for negotiating common target.
</nextsent>
<nextsent>some of the issues in need of negotiation are quite general in nature, while many others involve specific phenomena.
</nextsent>
<nextsent>first, the general ones: 3.1 unique identifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1405">
<title id=" W09-1311.xml">exploring graph structure for detection of reliability zones within synonym resources experiment with the gene ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but the situation is not as successful at the semantic level: little synonym resources can be found.
</prevsent>
<prevsent>if wordnet (fellbaum, 1998) proposes general language synonym relations for english, the corresponding resources for other languages are not freely available.
</prevsent>
</prevsection>
<citsent citstr=" C04-1054 ">
moreover, the initiative for fitting wordnet to the biomedical area (smith and fellbaum, 2004) <papid> C04-1054 </papid>seems to have been abandoned, although there is huge need for this kind of resources.in our previous work, we proposed to use the existing biomedical terminologies (i.e., gene ontology (gene ontology consortium, 2001), snomed (cote?</citsent>
<aftsection>
<nextsent>et al, 1997), umls (nlm, 2007)), wich provide complex terms, and to acquire from them lexical resources of synonyms.
</nextsent>
<nextsent>indeed, the use of complex biomedical terms seems to be less suitable and generalizable as compared to lexical resources (popratet al, 2008).
</nextsent>
<nextsent>within the biological area, we proposed to exploit the gene ontology (go), and more specifically to exploit compositional structure of its terms (hamon and grabar, 2008).
</nextsent>
<nextsent>however, withthe acquisition of synonymy we faced two prob lems: (1) contextual character of these relations(cruse, 1986), i.e., two terms or words are considered as synonyms if they can occur within the 89 same context, which makes this relation more or less broad depending on the usage; (2) ability of automatic tools to detect and characterize these relations, i.e., two terms or words taken out of their context can convey different relations than the one expected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1406">
<title id=" W08-1119.xml">the importance of narrative and other lessons from an evaluation of an nlg system that summarises clinical data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these systems have generated short (paragraph-length or smaller) summaries of relatively small datasets (less than 1kb).
</prevsent>
<prevsent>some research has been on systems that summarise larger datasets (yu et al, 2007; turner et al, 2008), but these systems have also generated paragraph-lengthsummaries; we are not aware of any previous research on generating multi-paragraph summaries in data-to-text system.
</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
data-to-texts systems have been evaluated in number of ways, including human ratings (the most common technique) (reiter et al, 2005), bleu-like scores against human texts (belz and reiter, 2006),<papid> E06-1040 </papid>post-edit analyses (sripada et al, 2005), <papid> W05-1615 </papid>and persuasive effectiveness (carenini and moore, 2006).however, again to the best of our knowledge no previous data-to-text system has been evaluated by asking users to make decisions based on the generated texts, and measuring the quality of these decisions.</citsent>
<aftsection>
<nextsent>law et al (2005) showed that human-written textual summaries were effective decision-support aids innicu, but of course it is not practical to expect medical professionals to routinely write such summaries, especially considering that the summaries used by law et al in some cases took several hours to write.
</nextsent>
<nextsent>the goal of the baby talk research project is touse nlg and data-to-text technology to automatically generate textual summaries of nicu data, for variety of audiences and purposes.
</nextsent>
<nextsent>the first system developed in baby talk, and the subject of this paper, is bt-45 (portet et al, 2007), which generates summaries of 30-60 minute chunks of clinical data, for the purpose of helping nurses and doctors make appropriate treatment decisions.
</nextsent>
<nextsent>an example of baby talk input data is shown in figures 1 (sensor data) and 2 (selected event data).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1407">
<title id=" W08-1119.xml">the importance of narrative and other lessons from an evaluation of an nlg system that summarises clinical data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these systems have generated short (paragraph-length or smaller) summaries of relatively small datasets (less than 1kb).
</prevsent>
<prevsent>some research has been on systems that summarise larger datasets (yu et al, 2007; turner et al, 2008), but these systems have also generated paragraph-lengthsummaries; we are not aware of any previous research on generating multi-paragraph summaries in data-to-text system.
</prevsent>
</prevsection>
<citsent citstr=" W05-1615 ">
data-to-texts systems have been evaluated in number of ways, including human ratings (the most common technique) (reiter et al, 2005), bleu-like scores against human texts (belz and reiter, 2006),<papid> E06-1040 </papid>post-edit analyses (sripada et al, 2005), <papid> W05-1615 </papid>and persuasive effectiveness (carenini and moore, 2006).however, again to the best of our knowledge no previous data-to-text system has been evaluated by asking users to make decisions based on the generated texts, and measuring the quality of these decisions.</citsent>
<aftsection>
<nextsent>law et al (2005) showed that human-written textual summaries were effective decision-support aids innicu, but of course it is not practical to expect medical professionals to routinely write such summaries, especially considering that the summaries used by law et al in some cases took several hours to write.
</nextsent>
<nextsent>the goal of the baby talk research project is touse nlg and data-to-text technology to automatically generate textual summaries of nicu data, for variety of audiences and purposes.
</nextsent>
<nextsent>the first system developed in baby talk, and the subject of this paper, is bt-45 (portet et al, 2007), which generates summaries of 30-60 minute chunks of clinical data, for the purpose of helping nurses and doctors make appropriate treatment decisions.
</nextsent>
<nextsent>an example of baby talk input data is shown in figures 1 (sensor data) and 2 (selected event data).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1408">
<title id=" W08-1119.xml">the importance of narrative and other lessons from an evaluation of an nlg system that summarises clinical data </title>
<section> qualitative analysis of problems in.  </section>
<citcontext>
<prevsection>
<prevsent>two aspects of bt-45 were repeatedly criticised in these comments.
</prevsent>
<prevsent>5.1.1 layout and bullet lists subjects wanted better layout and formatting, in the human texts as well as the bt-45 texts (bt-45 texts do not currently include any visual formatting).in particular, they wanted bullet lists to be used, especially for lab results.
</prevsent>
</prevsection>
<citsent citstr=" J03-2003 ">
such issues have been extensively discussed by other researchers (e.g., (power et al., 2003)), <papid> J03-2003 </papid>we will not further discuss them here.</citsent>
<aftsection>
<nextsent>5.1.2 continuity bt-45 sometimes described changes in signals (or other events) which didnt make sense because they omitted intermediate events.
</nextsent>
<nextsent>for example, consider the last paragraph in the bt-45 text shown in figure 4 (with italics added):there were 3 failed attempts to insert peripheral venous line at 13:53.
</nextsent>
<nextsent>tcpo2 suddenly decreased to 8.1.
</nextsent>
<nextsent>sao2 suddenly increased to 92.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1409">
<title id=" W08-1119.xml">the importance of narrative and other lessons from an evaluation of an nlg system that summarises clinical data </title>
<section> qualitative analysis of problems in.  </section>
<citcontext>
<prevsection>
<prevsent>now, if the final insertion attempt at 14.08 had been successful,the bt-45 data abstraction module would have instead produced the abstract event line-insertionprocess-succeeded, with similar times, and bt 45 would have produced the text after three attempts, at 13.53 peripheral venous line was inserted successfully.
</prevsent>
<prevsent>in other words, the time given would still be the time that the abstract event started; but this is misleading, because readers of the above text expect thatthe stated time is the time of the successful insertion (14.08), not the time at which the sequence of insert/remove events started.we need much better model of how to communicate time, and how this communication depends on the semantics and linguistic expression of the events being described.
</prevsent>
</prevsection>
<citsent citstr=" J88-2003 ">
an obvious first step, which we are currently working on, is to include linguistically motivated temporal ontology (moens and steedman,1988), <papid> J88-2003 </papid>which will be separate from the existing do main ontology.</citsent>
<aftsection>
<nextsent>we also need better techniques for communicating the temporal relationships between events in cases where they are not listed in chronological order (oberlander and lascarides, 1992).<papid> C92-2108 </papid></nextsent>
<nextsent>two discourse analysts from edinburgh university, dr. andy mckinlay and dr chris mcvittie, kindly examined and compared some of the human and bt45 texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1410">
<title id=" W08-1119.xml">the importance of narrative and other lessons from an evaluation of an nlg system that summarises clinical data </title>
<section> qualitative analysis of problems in.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, the time given would still be the time that the abstract event started; but this is misleading, because readers of the above text expect thatthe stated time is the time of the successful insertion (14.08), not the time at which the sequence of insert/remove events started.we need much better model of how to communicate time, and how this communication depends on the semantics and linguistic expression of the events being described.
</prevsent>
<prevsent>an obvious first step, which we are currently working on, is to include linguistically motivated temporal ontology (moens and steedman,1988), <papid> J88-2003 </papid>which will be separate from the existing do main ontology.</prevsent>
</prevsection>
<citsent citstr=" C92-2108 ">
we also need better techniques for communicating the temporal relationships between events in cases where they are not listed in chronological order (oberlander and lascarides, 1992).<papid> C92-2108 </papid></citsent>
<aftsection>
<nextsent>two discourse analysts from edinburgh university, dr. andy mckinlay and dr chris mcvittie, kindly examined and compared some of the human and bt45 texts.
</nextsent>
<nextsent>their top-level comment was that the human texts had much better narrative structures than the bt-45 texts.
</nextsent>
<nextsent>they use the term narrative?
</nextsent>
<nextsent>in 153the sense of labov (1972, chapter 9); that is story like structures which describe real experiences, and which go beyond just describing the events and include information that helps listeners make sense ofwhat happened, such as abstracts, evaluatives, cor relatives, and explicatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1411">
<title id=" W09-1304.xml">learning the scope of hedge cues in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>vincze et al (2008) report that 17.70%of the sentences in the abstracts section of the bio scope corpus and 19.44% of the sentences in the full papers section contain hedge cues.
</prevsent>
<prevsent>light et al (2004) estimate that 11% of sentences in medline abstracts contain speculative fragments.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
szarvas(2008) reports that 32.41% of gene names mentioned in the hedge classification dataset described in medlock and briscoe (2007)<papid> P07-1125 </papid>appears in speculative sentence.in this paper we present machine learning system that finds the scope of hedge cues in biomedicaltexts.</citsent>
<aftsection>
<nextsent>finding the scope of hedge cue means determining at sentence level which words in the sentence are affected by the hedge cue.
</nextsent>
<nextsent>the system combines several classifiers and works in two phases: in the first phase hedge cues (i.e., words indicating speculative language) are identified, and in the second phase the full scope of these hedge cues is found.this means that for sentence like the one in example (1) taken from the bio scope corpus (szarvas et al, 2008), <papid> W08-0606 </papid>the system performs two actions: first,it detects that suggest, might, and or are hedge sig nals; second, it detects that suggest has as its scope expression of c-jun, jun and jun genes might be involved in terminal granulocyte differentiation or in regulating granulocyte functionality, that might hasas its scope be involved in terminal granulocyte differentiation or in regulating granulocyte functionality, and that or has as its scope in regulating granu locyte functionality.</nextsent>
<nextsent>(1) these results  xcope id=x7.5.3?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1414">
<title id=" W09-1304.xml">learning the scope of hedge cues in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>szarvas(2008) reports that 32.41% of gene names mentioned in the hedge classification dataset described in medlock and briscoe (2007)<papid> P07-1125 </papid>appears in speculative sentence.in this paper we present machine learning system that finds the scope of hedge cues in biomedicaltexts.</prevsent>
<prevsent>finding the scope of hedge cue means determining at sentence level which words in the sentence are affected by the hedge cue.</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
the system combines several classifiers and works in two phases: in the first phase hedge cues (i.e., words indicating speculative language) are identified, and in the second phase the full scope of these hedge cues is found.this means that for sentence like the one in example (1) taken from the bio scope corpus (szarvas et al, 2008), <papid> W08-0606 </papid>the system performs two actions: first,it detects that suggest, might, and or are hedge sig nals; second, it detects that suggest has as its scope expression of c-jun, jun and jun genes might be involved in terminal granulocyte differentiation or in regulating granulocyte functionality, that might hasas its scope be involved in terminal granulocyte differentiation or in regulating granulocyte functionality, and that or has as its scope in regulating granu locyte functionality.</citsent>
<aftsection>
<nextsent>(1) these results  xcope id=x7.5.3?
</nextsent>
<nextsent>  cue type= spec ulation?
</nextsent>
<nextsent>ref=x7.5.3?  suggest  /cue  that  xcope id= x7.5.2? expression of c-jun, jun and jun genes  cue type= speculation?
</nextsent>
<nextsent>ref= x7.5.2?  might  /cue  be involved  xcope id=x7.5.1? in terminal granulocyte differentiation  cue type= speculation?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1422">
<title id=" W09-1304.xml">learning the scope of hedge cues in biomedical texts </title>
<section> hedge cues in the bio scope corpus.  </section>
<citcontext>
<prevsection>
<prevsent>in the corpus, every sentence is annotated with information about negation and speculation.
</prevsent>
<prevsent>the annotation indicates the boundaries of the scope and the keywords, as shown in (1) above.
</prevsent>
</prevsection>
<citsent citstr=" E99-1043 ">
in the annotation, scopes are extended to the biggest syntactic unit possible, so that scopes have the maximal length, and the speculation cue is always included in the scope.the bio scope corpus consists of three parts: clinical free-texts (radiology reports), biological full papers and biological paper abstracts from the genia corpus (collier et al, 1999).<papid> E99-1043 </papid></citsent>
<aftsection>
<nextsent>table 1 shows statistics about the corpora.
</nextsent>
<nextsent>hedge cues are represented by one or more tokens, as (2) shows, where the hedge cues that appear in the three corpora are listed.
</nextsent>
<nextsent>the complete list of all hedge cues comprises 176 cues.
</nextsent>
<nextsent>2web page: www.inf.u-szeged.hu/rgai/bioscope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1423">
<title id=" W09-1304.xml">learning the scope of hedge cues in biomedical texts </title>
<section> hedge cues in the bio scope corpus.  </section>
<citcontext>
<prevsection>
<prevsent>length scopes 2.46 5.94 5.60 to the left % scopes to the right 73.28 76.55 82.45 % scopes to the left 26.71 23.44 17.54 table 1: statistics about the sub corpora in the bio scope corpus and the hedge scopes (av?.
</prevsent>
<prevsent>stands for average).
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
the texts have been processed with the genia tagger (tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>tsuruoka et al,2005), bidirectional inference based tagger that analyzes english sentences and outputs the base forms, part-of-speech tags, chunk tags, and named entity tags in tab-separated format.</citsent>
<aftsection>
<nextsent>additionally, we converted the annotation about scope of negation into atoken-per-token representation, following the standard format of the 2006 conll shared task (buchholz and marsi, 2006), <papid> W06-2920 </papid>where sentences are separated by blank line and fields are separated by asingle tab character.</nextsent>
<nextsent>a sentence consists of sequence of tokens, each one starting on new line.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1424">
<title id=" W09-1304.xml">learning the scope of hedge cues in biomedical texts </title>
<section> hedge cues in the bio scope corpus.  </section>
<citcontext>
<prevsection>
<prevsent>stands for average).
</prevsent>
<prevsent>the texts have been processed with the genia tagger (tsuruoka and tsujii, 2005; <papid> H05-1059 </papid>tsuruoka et al,2005), bidirectional inference based tagger that analyzes english sentences and outputs the base forms, part-of-speech tags, chunk tags, and named entity tags in tab-separated format.</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
additionally, we converted the annotation about scope of negation into atoken-per-token representation, following the standard format of the 2006 conll shared task (buchholz and marsi, 2006), <papid> W06-2920 </papid>where sentences are separated by blank line and fields are separated by asingle tab character.</citsent>
<aftsection>
<nextsent>a sentence consists of sequence of tokens, each one starting on new line.
</nextsent>
<nextsent>30we model this task in the same way that we modelled the task for finding the scope of negation(morante and daelemans, 2009), i.e., as two consecutive classification tasks: first one that consists of classifying the tokens of sentence as being at the beginning of hedge signal, inside or outside.
</nextsent>
<nextsent>this allows the system to find multiword hedge cues.
</nextsent>
<nextsent>the second classification task consists of classifying the tokens of sentence as being the first element of the scope, the last, or neither.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1425">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these constraints establish links between language expressions and the entities they refer to in the real world.
</prevsent>
<prevsent>we present relational learning algorithm that learns these grammars froma small representative set of annotated examples, and show how this grammar induction framework and the ontology-basedsemantic representation allow us to directly map text to graph-based meaning representations.
</prevsent>
</prevsection>
<citsent citstr=" P07-1121 ">
recent work (wong and mooney, 2007; <papid> P07-1121 </papid>zettlemoyer and collins, 2005; he and young, 2006) has developed learning algorithms for the problem of mapping sentences to their underlying semantic representations.</citsent>
<aftsection>
<nextsent>these semantic representations vary from ?-expressions (bos et al , 2004; <papid> C04-1180 </papid>zettlemoyer and collins, 2005; wong and mooney, 2007) <papid> P07-1121 </papid>to db query languages and command-like languages (robocup coach language, clang) (ge and mooney, 2005).<papid> W05-0602 </papid></nextsent>
<nextsent>in this paper we focus on an ontology-basedsemantic representation which allows us to encode the meaning of text as direct acyclic graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1426">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present relational learning algorithm that learns these grammars froma small representative set of annotated examples, and show how this grammar induction framework and the ontology-basedsemantic representation allow us to directly map text to graph-based meaning representations.
</prevsent>
<prevsent>recent work (wong and mooney, 2007; <papid> P07-1121 </papid>zettlemoyer and collins, 2005; he and young, 2006) has developed learning algorithms for the problem of mapping sentences to their underlying semantic representations.</prevsent>
</prevsection>
<citsent citstr=" C04-1180 ">
these semantic representations vary from ?-expressions (bos et al , 2004; <papid> C04-1180 </papid>zettlemoyer and collins, 2005; wong and mooney, 2007) <papid> P07-1121 </papid>to db query languages and command-like languages (robocup coach language, clang) (ge and mooney, 2005).<papid> W05-0602 </papid></citsent>
<aftsection>
<nextsent>in this paper we focus on an ontology-basedsemantic representation which allows us to encode the meaning of text as direct acyclic graph.
</nextsent>
<nextsent>recently, there is growing interest on ontology-based nlp, starting from efforts in defining ontology-based semantic representations ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.(nirenburg and raskin, 2004), to using onto logical resources in nlp applications, such as question answering (basili et al , 2004; <papid> W04-2510 </papid>beale et al , 2004), <papid> W04-0906 </papid>and building annotated corpora, such as the ontonotes project (hovy et al , 2006).<papid> N06-2015 </papid>there are three novel properties to ontology based semantics that we propose in this paper: ? there is direct link between the ontology and the grammar through constraints at the grammar rule level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1428">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present relational learning algorithm that learns these grammars froma small representative set of annotated examples, and show how this grammar induction framework and the ontology-basedsemantic representation allow us to directly map text to graph-based meaning representations.
</prevsent>
<prevsent>recent work (wong and mooney, 2007; <papid> P07-1121 </papid>zettlemoyer and collins, 2005; he and young, 2006) has developed learning algorithms for the problem of mapping sentences to their underlying semantic representations.</prevsent>
</prevsection>
<citsent citstr=" W05-0602 ">
these semantic representations vary from ?-expressions (bos et al , 2004; <papid> C04-1180 </papid>zettlemoyer and collins, 2005; wong and mooney, 2007) <papid> P07-1121 </papid>to db query languages and command-like languages (robocup coach language, clang) (ge and mooney, 2005).<papid> W05-0602 </papid></citsent>
<aftsection>
<nextsent>in this paper we focus on an ontology-basedsemantic representation which allows us to encode the meaning of text as direct acyclic graph.
</nextsent>
<nextsent>recently, there is growing interest on ontology-based nlp, starting from efforts in defining ontology-based semantic representations ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.(nirenburg and raskin, 2004), to using onto logical resources in nlp applications, such as question answering (basili et al , 2004; <papid> W04-2510 </papid>beale et al , 2004), <papid> W04-0906 </papid>and building annotated corpora, such as the ontonotes project (hovy et al , 2006).<papid> N06-2015 </papid>there are three novel properties to ontology based semantics that we propose in this paper: ? there is direct link between the ontology and the grammar through constraints at the grammar rule level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1429">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, there is growing interest on ontology-based nlp, starting from efforts in defining ontology-based semantic representations ? 2008.
</prevsent>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
</prevsection>
<citsent citstr=" W04-2510 ">
some rights reserved.(nirenburg and raskin, 2004), to using onto logical resources in nlp applications, such as question answering (basili et al , 2004; <papid> W04-2510 </papid>beale et al , 2004), <papid> W04-0906 </papid>and building annotated corpora, such as the ontonotes project (hovy et al , 2006).<papid> N06-2015 </papid>there are three novel properties to ontology based semantics that we propose in this paper: ? there is direct link between the ontology and the grammar through constraints at the grammar rule level.</citsent>
<aftsection>
<nextsent>these ontology constraints enable access to meaning during language processing (parsing and generation).
</nextsent>
<nextsent>our ontology-based semantic representation is expressive enough to capture various phenomena of natural language, yet restrictive enough to facilitate grammar learning.
</nextsent>
<nextsent>the representation encodes both ontologicalmeaning (concepts and relations among con cepts) and extra-ontological meaning, such as voice, tense, aspect, modality.
</nextsent>
<nextsent>our representation and grammar learning framework allow direct mapping of text to its meaning, encoded as direct acyclic graph (dag).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1430">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, there is growing interest on ontology-based nlp, starting from efforts in defining ontology-based semantic representations ? 2008.
</prevsent>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
</prevsection>
<citsent citstr=" W04-0906 ">
some rights reserved.(nirenburg and raskin, 2004), to using onto logical resources in nlp applications, such as question answering (basili et al , 2004; <papid> W04-2510 </papid>beale et al , 2004), <papid> W04-0906 </papid>and building annotated corpora, such as the ontonotes project (hovy et al , 2006).<papid> N06-2015 </papid>there are three novel properties to ontology based semantics that we propose in this paper: ? there is direct link between the ontology and the grammar through constraints at the grammar rule level.</citsent>
<aftsection>
<nextsent>these ontology constraints enable access to meaning during language processing (parsing and generation).
</nextsent>
<nextsent>our ontology-based semantic representation is expressive enough to capture various phenomena of natural language, yet restrictive enough to facilitate grammar learning.
</nextsent>
<nextsent>the representation encodes both ontologicalmeaning (concepts and relations among con cepts) and extra-ontological meaning, such as voice, tense, aspect, modality.
</nextsent>
<nextsent>our representation and grammar learning framework allow direct mapping of text to its meaning, encoded as direct acyclic graph (dag).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1431">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, there is growing interest on ontology-based nlp, starting from efforts in defining ontology-based semantic representations ? 2008.
</prevsent>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
some rights reserved.(nirenburg and raskin, 2004), to using onto logical resources in nlp applications, such as question answering (basili et al , 2004; <papid> W04-2510 </papid>beale et al , 2004), <papid> W04-0906 </papid>and building annotated corpora, such as the ontonotes project (hovy et al , 2006).<papid> N06-2015 </papid>there are three novel properties to ontology based semantics that we propose in this paper: ? there is direct link between the ontology and the grammar through constraints at the grammar rule level.</citsent>
<aftsection>
<nextsent>these ontology constraints enable access to meaning during language processing (parsing and generation).
</nextsent>
<nextsent>our ontology-based semantic representation is expressive enough to capture various phenomena of natural language, yet restrictive enough to facilitate grammar learning.
</nextsent>
<nextsent>the representation encodes both ontologicalmeaning (concepts and relations among con cepts) and extra-ontological meaning, such as voice, tense, aspect, modality.
</nextsent>
<nextsent>our representation and grammar learning framework allow direct mapping of text to its meaning, encoded as direct acyclic graph (dag).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1432">
<title id=" W08-2002.xml">learning to map text to graph based meaning representations via grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we consider that understanding?
</prevsent>
<prevsent>a text is the ability to correctly answer, at the conceptual level, all the questions asked w.r.t to that text, and thus meaning = text + all questions/answers w.r.t that text.
</prevsent>
</prevsection>
<citsent citstr=" P07-1105 ">
under this assumption, obtaining the meaning of text is reduced to question answering process, which in our framework is dag matching problem.first, we review our grammar formalism introduced in (muresan, 2006; muresan and rambow,2007), <papid> P07-1105 </papid>called lexicalized well-founded grammars.</citsent>
<aftsection>
<nextsent>second, we present relational learning algorithm for inducing these grammars from representative sample of strings annotated with their semantics, along with minimal assumptions about 9 i. semantic molecules a.
</nextsent>
<nextsent>(major/adj)?= 0 b b b @ 1 2 6 4 cat adj head 1 mod 2 3 7 5 1 x 1 .isa = major, 2 .y=x 1 1 c c c a b.
</nextsent>
<nextsent>(damage/noun)?= 0 b b b @ 2 2 6 4 cat noun nr sg head 3 3 7 5 2 x 3 .isa = damagee 1 c c c a c.
</nextsent>
<nextsent>(major damage)?= 0 b b b @ 2 6 4 cat nr sg head 3 7 5 d 1 .isa = major, x.y=x 1 , x.isa=damagee 1 c c c ii.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1438">
<title id=" W08-2106.xml">using lda to detect semantically incoherent documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>among these, the latter two are easy to detect using simple statistical models of natural texts, but the former is more challenging, it being made up of actual sentences: recognizing these texts as forged requires either to resort to plagiarism detection techniques, or to automatically identify their lack of semantic consistency.
</prevsent>
<prevsent>detecting the consistency of texts or of text chunks has many applications in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
so far, it has been used mainly in the context of automatic text segmentation, where change in vocabulary is often the mark of topic change (hearst, 1997), <papid> J97-1003 </papid>and, to lesser extent, in discourse studies (see, e.g., (foltz et al , 1998)).</citsent>
<aftsection>
<nextsent>it could also serve to devise automatic metrics for text summarization or machine translation tasks.
</nextsent>
<nextsent>this paper is an attempt to address the issueof differentiating between true?
</nextsent>
<nextsent>and false?
</nextsent>
<nextsent>documents on the basis of their consistency through topic modeling approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1439">
<title id=" W08-2106.xml">using lda to detect semantically incoherent documents </title>
<section> latent dirichlet allocation.  </section>
<citcontext>
<prevsection>
<prevsent>in (griffiths and steyvers, 2004), the authors used lda for identifying hottopics?
</prevsent>
<prevsent>by analyzing the temporal dynamics of topics over period of time.
</prevsent>
</prevsection>
<citsent citstr=" W06-1644 ">
more recently lda has also been used for unsupervised language model (lm) adaptation in the context of automatic speech recognition (asr) (hsu and glass, 2006; <papid> W06-1644 </papid>tam and schultz, 2007; heidel et al , 2007).</citsent>
<aftsection>
<nextsent>several extensions of the lda model, such as hierarchical lda (blei et al , 2004), hmm-lda (grif fiths et al , 2005), correlated topic models (bleiand lafferty, 2005) and hidden topic markov models (gruber et al , 2007), have been proposed, that introduce more complex dependency patterns in the model.
</nextsent>
<nextsent>like most of the text mining techniques, lda assumes that documents are made up of words and the ordering of the words within document is unimportant (bag-of-words?
</nextsent>
<nextsent>assumption).
</nextsent>
<nextsent>contrary to the simpler multinomial mixture model (see, e.g., (nigam et al , 2000) and section 2.4), lda assumes that every document is represented by topic distribution and that each topic defines an underlying distribution on words.the generative history of document (a bag of-words) collection is the following: assuming fixed and known number of topics t , for each topic t, distribution ? tover the indexing vocabulary (w = 1 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1440">
<title id=" W09-1502.xml">context dependent regression testing for natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>contest allows the authors of individual system components to control what information to record for regression testing.
</prevsent>
<prevsent>test dialogues are 5saved and replayed through the system, and individual components are tested by comparing only their specific regression output, ignoring the outputs generated by other components.
</prevsent>
</prevsection>
<citsent citstr=" W08-1707 ">
the components are isolated by maintaining minimal set of inputs that are guaranteed to be processed correctly.to deal with issues of output complexity we extend the approach of de paiva and king (2008) <papid> W08-1707 </papid>for testing deep parser.</citsent>
<aftsection>
<nextsent>they created test sets at different levels of granularity, some including detailed representations, but some just saving very simple output of textual entailment component.
</nextsent>
<nextsent>they showed that, given carefully selected test set, testing on the final system output can be fast and effective way to discover problems in the interpretation pipeline.
</nextsent>
<nextsent>we show how the same idea can be used to test other dialogue system components as well.
</nextsent>
<nextsent>we describe the design of three different test sets that effectively isolate the interpretation, tutorial planning and generation components of our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1442">
<title id=" W09-1502.xml">context dependent regression testing for natural language processing </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>however, oaa is not essential for the system design ? any communication architecture which supports adding extra agents into system would work equally well.beetle aims to get students to support their reasoning using natural language, since explanations and content ful talk are associated with learning gain(purandare and litman, 2008).
</prevsent>
<prevsent>this requires detailed analyses of student answers in terms of correct, incorrect and missing parts (dzikovska et al, 2008; nielsen et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W07-1207 ">
thus, we use the trips parser (allen et al, 2007), <papid> W07-1207 </papid>deep parser which produces detailed analyses of student input.</citsent>
<aftsection>
<nextsent>the lexical interpreter extracts list of objects and relationships mentioned, which are checked against the expected answer.
</nextsent>
<nextsent>these lists are fairly long ? many expected answers have ten or more relations in them.
</nextsent>
<nextsent>the 2all our components are rule-based, but we expect the same approach would work for components of statistical nature.
</nextsent>
<nextsent>6diagnoser categorises each of the objects and relationships as correct, contradictory or irrelevant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1443">
<title id=" W09-1502.xml">context dependent regression testing for natural language processing </title>
<section> test cases.  </section>
<citcontext>
<prevsection>
<prevsent>if interpretation fails, the student act will be set to uninterpretable, and the code will correspond to the reason for failed interpretation: unknown input if the parse failed, unknown mapping or restriction failure if lexical interpretation failed, and unresolvable if reference resolution failed.
</prevsent>
<prevsent>if interpretation worked, but took incorrect scoping or attachment decisions, the resulting proposition is likely to be inconsistent with the 4sometimes students are unable to interpret diagrams, or are lacking essential background knowledge, and therefore say things that contradict the information in the domain model.
</prevsent>
</prevsection>
<citsent citstr=" W06-1803 ">
the system detects and re mediates such cases differently from general errors in explanations (dzikovska et al, 2006).<papid> W06-1803 </papid></citsent>
<aftsection>
<nextsent>current knowledge base, and an inconsistency code will be reported.
</nextsent>
<nextsent>in addition, verifying the matched answer id provides some information in case only partial interpretation was produced.
</nextsent>
<nextsent>sometimes different answer ids correspond to answers that are very complete versus answers that are acceptable because they address the key point of the question, but miss some small details.
</nextsent>
<nextsent>thus if different answer id has matched, it indicates that some information was probably lost in interpretation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1446">
<title id=" W08-1109.xml">the use of spatial relations in referring expression generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe an experiemtthat attempts to test this assumption; we determine that, even in simple scenes where the use of relations is not strictly required in order to identify an entity, relations are in fact often used.
</prevsent>
<prevsent>we draw some conclusions as to what this means for the development of algorithms for the generation of referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" P06-2033 ">
in recent years, researchers working on referring expression generation have increasingly moved towards collecting their own data on the human production of referring expressions (res) (krahmer and theune, 2002; vander sluis and krahmer, 2004; gatt and van deemter, 2006; <papid> P06-2033 </papid>belz and varges, 2007); and the recent attribute selection in the generation of referring expressions (asgre) challenge used the tuna corpus (gatt et al, 2007), which is the most extensive collection of referring expressions to date.</citsent>
<aftsection>
<nextsent>while there is substantial body of experimental work in psycho linguistics that looks at the human production of referring expressions (see, amongst more recent work, (clark and wilkes-gibbs, 1986; stevenson, 2002; haywood et al., 2003; jordan and walker, 2005)) the large range of factors that play role in language production mean that it is often the case that the specific question that one is interested in has not been studied before.
</nextsent>
<nextsent>so, nlg researchers have tended towards data gathering exercises that explore some specific aspect of referring expression generation, focussing on hypotheses relevant to algorithm development.
</nextsent>
<nextsent>this paper is in the same mold.
</nextsent>
<nextsent>we are particuarlyinterested in how people use spatial relations in referring expressions, and so in this paper we describe an experiment that explores the generation of relational referring expressions in simple scene.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1447">
<title id=" W08-1109.xml">the use of spatial relations in referring expression generation </title>
<section> spatial relations in referring.  </section>
<citcontext>
<prevsection>
<prevsent>does not appear to hold; relations are often used, even in simple scenes, when they are not strictly required, and it is likely that they would be more heavily used in more complex real-world scenes.
</prevsent>
<prevsent>we conclude in section 4 with some observations as to how the results presented here might impact on the development of algorithms for referring expression generation, and outline some future work.
</prevsent>
</prevsection>
<citsent citstr=" P89-1009 ">
expression generation the bulk of the existing literature on referring expression generation (see, for example, dale (1989),<papid> P89-1009 </papid>dale and reiter (1995), van deemter (2006), horacek (2004), gatt and van deemter (2006)) <papid> P06-2033 </papid>generally focuses on the use of non-relational properties, which can either be absolute (for example, colour) or relative (for example, size).</citsent>
<aftsection>
<nextsent>we are interested in the 59 use of relational expressions, and in particular the use of spatial relations; the contexts of use we are interested in are task-specific, where, for example, we might want an omniscient domestic agent to tell us where we have placed lost object (you left your keys under the folder on the desk . . .
</nextsent>
<nextsent>), or to identifya hearer-new object in cluttered scene (the magazine at the bottom of the pile of papers next to the lampshade in the corner).
</nextsent>
<nextsent>to develop agents with these kinds of referential capabilities, we want to acquire data that will inform the development of algorithms, either by automatically checking their ability to replicate the corpus, or as baseline for assessing the performance of humans in an identification task based on the output of these algorithms.
</nextsent>
<nextsent>in this paper, we describe an experiment that looks at how and when people use spatial relation sin simple scene.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1449">
<title id=" W08-1109.xml">the use of spatial relations in referring expression generation </title>
<section> spatial relations in referring.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe an experiment that looks at how and when people use spatial relation sin simple scene.
</prevsent>
<prevsent>more specifically, we aim to explore the hypothesis that relations are always dis preferred over non-relational properties.
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
this hypothesis appears to underly most approaches to referring expression generation that handle relations:gardent (2002) <papid> P02-1013 </papid>adopts constraint based approach to deal with relations specifically geared at generating referring expressions that are as short aspossible.</citsent>
<aftsection>
<nextsent>as including relation in referring expression always entails the additional mention ofat least head noun for the related object, this approach inherently prefers properties over relations.krahmer and theune (2002) extend the incremental algorithm (ia; dale and reiter (1995)) to handle relations.
</nextsent>
<nextsent>this requires preference list over all properties and relations to be specified in advance.
</nextsent>
<nextsent>they explicitly choose to put spatial relations right at the end of that preference list, on the basis that it seems an acceptable assumption that people prefer to describe an object in terms of simple properties, and only shift to relations when properties do not suffice [.
</nextsent>
<nextsent>] it takes less effort to consider and describe only one object?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1450">
<title id=" W08-1109.xml">the use of spatial relations in referring expression generation </title>
<section> spatial relations in referring.  </section>
<citcontext>
<prevsection>
<prevsent>2005 domain are all points on map distinguishable only by their spatial relations to other objects, he has no choice but to use relations.
</prevsent>
<prevsent>however, he also adopts brevity as main criterion for choosing which spatial relations to use.
</prevsent>
</prevsection>
<citsent citstr=" P06-1131 ">
kelleher and kruijff (2005), kelleher and kruijff (2006) <papid> P06-1131 </papid>cite clark andwilkes-gibbs?</citsent>
<aftsection>
<nextsent>(1986) principle of minimal cooperative effort and dale and reiters (1995) principle of sensitivity, as well as vander sluis and krahmers (2004) production study, to motivate the ordering over the types of properties that can be usedby their system; accordingly, their system only includes spatial (and hence relational) information in referring expression if it is not possible to construct description from non-relational properties.these approaches would appear to favour the production of referring expressions containing long sequences of non-relational properties when single relational property might do the job.
</nextsent>
<nextsent>we are interested, then, in whether it really is the case that relational expressions are dis preferred, and in determining when they might in fact be preferred.
</nextsent>
<nextsent>to date, we are not aware of any substantial datasets that would allow this question to be explored.
</nextsent>
<nextsent>both the tuna corpus (gatt et al, 2007) and the macquarie drawer data (viethen and dale, 2006) contain too few relational descriptions to allow us to draw conclusions about any kind of patterns; thegrec corpus (belz and varges, 2007) is not concerned with content selection at all, but rather studies the form of referring expressions used over whole text; i.e. the choice between fully descriptive nps, reduced nps, one-anaphora and pronouns.there are number of corpora resulting from experiments involving human participants which contain referring expressions, such as brennan and clarks (1996) collection of tangram descriptions, the hcrc map task corpus (thompson et al, 1993), <papid> H93-1005 </papid>the coconut corpus (jordan and walker, 2005), and byron and fosler-lussiers (2006) osu quake corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1451">
<title id=" W08-1109.xml">the use of spatial relations in referring expression generation </title>
<section> spatial relations in referring.  </section>
<citcontext>
<prevsection>
<prevsent>we are interested, then, in whether it really is the case that relational expressions are dis preferred, and in determining when they might in fact be preferred.
</prevsent>
<prevsent>to date, we are not aware of any substantial datasets that would allow this question to be explored.
</prevsent>
</prevsection>
<citsent citstr=" H93-1005 ">
both the tuna corpus (gatt et al, 2007) and the macquarie drawer data (viethen and dale, 2006) contain too few relational descriptions to allow us to draw conclusions about any kind of patterns; thegrec corpus (belz and varges, 2007) is not concerned with content selection at all, but rather studies the form of referring expressions used over whole text; i.e. the choice between fully descriptive nps, reduced nps, one-anaphora and pronouns.there are number of corpora resulting from experiments involving human participants which contain referring expressions, such as brennan and clarks (1996) collection of tangram descriptions, the hcrc map task corpus (thompson et al, 1993), <papid> H93-1005 </papid>the coconut corpus (jordan and walker, 2005), and byron and fosler-lussiers (2006) osu quake corpus.</citsent>
<aftsection>
<nextsent>however, these contain whole conversations between communicative partners cooperating on task, making it difficult to factor out the impact of prior discourse context on the referring expressions used.
</nextsent>
<nextsent>3.1 general overview.
</nextsent>
<nextsent>we conducted web-based production experiment to elicit referring expressions describing singular objects in very simple scenes.
</nextsent>
<nextsent>the study was aimed at shedding light on the question of whether spatial relations are indeed as dis preferred as suggested by the literature in those situations where non-relational descriptions are possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1453">
<title id=" W08-1503.xml">an integrated dialog simulation technique for evaluating spoken dialog systems </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>one of the purposes is to support the refinement of dialog strategies.
</prevsent>
<prevsent>some techniques use large amounts of simulated data for systematic exploration of the dialog state spacein the framework of reinforcement learning (schatz mann et al, 2005; schatzmann et al, 2007a).
</prevsent>
</prevsection>
<citsent citstr=" P04-1009 ">
other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristic ally or automatically (chung, 2004;<papid> P04-1009 </papid>rieser and lemon, 2006; torres et al, 2008).</citsent>
<aftsection>
<nextsent>a second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively.
</nextsent>
<nextsent>eckert et al, (1997) and lopez-cozar et., (2003),  (2006) used dialog simulation to evaluate whole dialog systems.
</nextsent>
<nextsent>dialog simulation techniques can also be classified according to the layers of the simulation.
</nextsent>
<nextsent>typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1457">
<title id=" W08-1503.xml">an integrated dialog simulation technique for evaluating spoken dialog systems </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we conducted case study for the navigation domain korean spoken dialog system to test our simulation method and examine the dialog behaviors using the simulator.
</prevsent>
<prevsent>we used 100 dialog examples from real user and dialog system to train user intention and utterance simulator.
</prevsent>
</prevsection>
<citsent citstr=" W08-0120 ">
we usedthe slu method of (jeong and lee, 2006), and dialog management method of (kim et al, 2008) <papid> W08-0120 </papid>to build the dialog system.</citsent>
<aftsection>
<nextsent>after trained user simulator, we perform simulation to collect 5000 dialog samples for each wer settings (wer = 0 ? 40 %).to verify the user intention and utterance simulation quality, we let two human judges to evaluate 200 randomly chosen dialogs and 1031 utterances from the simulated dialog examples (wer=0%).
</nextsent>
<nextsent>at first, they evaluate dialog with three scale (1: unnatural, 2: possible, 3: natural), then evaluate the utterances of dialog with three scale (1: unclear, 2: understandable, 3: natural).
</nextsent>
<nextsent>the inter evaluator agreement (kappa) is 0.45 and 0.58 for dialog and utterance evaluation respectively, which show the moderate agreement (fig.
</nextsent>
<nextsent>8).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1458">
<title id=" W09-0611.xml">learning lexical alignment policies for generating referring expressions for spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the learned policies are consistently between 2 and 8 turns shorter than range of different hand-coded but adaptive baseline lexical alignment policies.
</prevsent>
<prevsent>in current troubleshooting?
</prevsent>
</prevsection>
<citsent citstr=" W07-0301 ">
spoken dialogue systems (sds)(williams, 2007), <papid> W07-0301 </papid>the major part of the conversation is directed by the system, while the user follows the systems instructions.</citsent>
<aftsection>
<nextsent>once the system decides what instruction to give the user(at the dialogue management level), it faces several decisions to be made at the natural language generation (nlg) level.
</nextsent>
<nextsent>these include, deciding which concepts to include in the utterance, deciding the referring expressions (re) to use in the utterance and so on.
</nextsent>
<nextsent>a little-studied problem is to what extent system could automatically align to the users lexical knowledge by adapting its re choices, in particular based on his domain expertise, and how this can be modelled and optimised computationally.(issacs and clark, 1987) show how two interlocutors adapt their language in conversation by assessing each others domain expertise during dialogue, by observing how they react toeach others re choices.
</nextsent>
<nextsent>this is called alignment through audience design (clark, 1996; bell, 1984).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1459">
<title id=" W09-0611.xml">learning lexical alignment policies for generating referring expressions for spoken dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we then evaluate the user simulation (section 6), testing whether simulation that is sensitive to systems re choices can be used to learn good lexical alignment policies.
</prevsent>
<prevsent>finally, we compare policies learned in interaction with the user simulation with hand-coded policies, and present the results in section 7.
</prevsent>
</prevsection>
<citsent citstr=" N07-2038 ">
several statistical user simulation models that model users behaviour in conversation have been proposed (georgila et al, 2005; schatzmann et al, 2006; schatzmann et al, 2007).<papid> N07-2038 </papid></citsent>
<aftsection>
<nextsent>these models issue task specific dialogue acts like informing their search constraints, confirming values, rejecting mis recognised values, etc. however, theydo not model user population with varying do main expertise.
</nextsent>
<nextsent>also, none of these models seek clarification at conceptual or lexical levels that occur naturally in conversations between real users.(komatani et al, 2003) <papid> P03-1033 </papid>proposed using user models with features like skills, domain knowledge and hastiness as part of the dialogue manager to produce adaptive responses.</nextsent>
<nextsent>(janarthanam and lemon, 2008) presented user simulation model that simulates variety of users with different do main knowledge profiles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1460">
<title id=" W09-0611.xml">learning lexical alignment policies for generating referring expressions for spoken dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several statistical user simulation models that model users behaviour in conversation have been proposed (georgila et al, 2005; schatzmann et al, 2006; schatzmann et al, 2007).<papid> N07-2038 </papid></prevsent>
<prevsent>these models issue task specific dialogue acts like informing their search constraints, confirming values, rejecting mis recognised values, etc. however, theydo not model user population with varying do main expertise.</prevsent>
</prevsection>
<citsent citstr=" P03-1033 ">
also, none of these models seek clarification at conceptual or lexical levels that occur naturally in conversations between real users.(komatani et al, 2003) <papid> P03-1033 </papid>proposed using user models with features like skills, domain knowledge and hastiness as part of the dialogue manager to produce adaptive responses.</citsent>
<aftsection>
<nextsent>(janarthanam and lemon, 2008) presented user simulation model that simulates variety of users with different do main knowledge profiles.
</nextsent>
<nextsent>although this model incorporated clarification acts at the conceptual level, these users ignore the issues concerning the users understanding of theres used by the system.
</nextsent>
<nextsent>in this work, in contrast to the above, we present user simulation model which explicitly encodes the users lexical knowledge of the domain, understands descriptive expressions, and issues clarification requests at the lexical level.
</nextsent>
<nextsent>our user simulation module simulates dialogue behaviour of different users, and interacts with the dialogue system by exchanging both dialogue actsand res.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1461">
<title id=" W09-0611.xml">learning lexical alignment policies for generating referring expressions for spoken dialogue systems </title>
<section> user simulation.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: bayes net for user lexical knowledge using this bayesian model, we instantiate different knowledge profiles for different users.
</prevsent>
<prevsent>the current conditional probabilities were set by hand based on intuition.
</prevsent>
</prevsection>
<citsent citstr=" W09-0614 ">
in future work, these value swill be populated based on simple knowledge surveys performed on real users (janarthanam and lemon, 2009).<papid> W09-0614 </papid></citsent>
<aftsection>
<nextsent>this method creates spectrum ofusers from ones who have no knowledge of technical terms to ones who know all the technical jargon, though every profile will have different frequency of occurrence.
</nextsent>
<nextsent>this difference in frequency reflects that expert users are less common than novice users.the users domain knowledge can be dynamically updated.
</nextsent>
<nextsent>the new res, both technical and descriptive, presented by the system through clarification moves are stored in the users short term memory.
</nextsent>
<nextsent>exactly how long (in terms of dialogue turns) to retain the newly acquired knowledge is given by retention index riu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1463">
<title id=" W09-0611.xml">learning lexical alignment policies for generating referring expressions for spoken dialogue systems </title>
<section> user simulation.  </section>
<citcontext>
<prevsection>
<prevsent>request disambiguation is issued when the user faces an underspecified and ambiguous descriptive expression, e.g.user: have two black boxes here - one with lights and one without.
</prevsent>
<prevsent>which one is it??.
</prevsent>
</prevsection>
<citsent citstr=" W04-2325 ">
these clarification strategies have been modeled based on (schlangen, 2004).<papid> W04-2325 </papid></citsent>
<aftsection>
<nextsent>the user simulation also issues request location and request procedure dialogue acts, when it does notknow the location of domain objects or how to manipulate them, respectively.
</nextsent>
<nextsent>3.3 environment simulation.
</nextsent>
<nextsent>the environment simulation includes both physical objects, such as the computer, modem, adsl filter, etc and virtual objects, such as the browser,control panel, etc in the users environment.
</nextsent>
<nextsent>physical and virtual connections between these objects 76 report problem provide info(dobj, info) acknowledge request verification(x, y) request description(x) request disambiguation(x, [y1,y2]) request location(dobj) request procedure(daction) thank system table 2: user dialogue acts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1466">
<title id=" W09-0629.xml">the tunareg challenge 2009 overview and evaluation results </title>
<section> evaluation methods and results.  </section>
<citcontext>
<prevsection>
<prevsent>otherwise the value depends on the length of the two strings (the maximum value is the sum of the lengths).
</prevsent>
<prevsent>as an aggregate measure, we compute the mean of pairwise se scores.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu-x is an n-gram based string comparison measure, originally proposed by papineni et al(2001), papineni et al(2002) <papid> P02-1040 </papid>for evaluation of machine translation systems.</citsent>
<aftsection>
<nextsent>it computes the proportion of wordn-grams of length and less that system out put shares with several reference outputs.
</nextsent>
<nextsent>setting = 4 (i.e. considering all n-grams of length ? 4)is standard, but because many of the tuna descriptions are shorter than 4 tokens, we compute bleu-3 instead.
</nextsent>
<nextsent>bleu ranges from 0 to 1.
</nextsent>
<nextsent>nist is version of bleu, but where bleu gives equal weight to all n-grams, nist gives more importance to less frequent n-grams, which are taken to be more informative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1467">
<title id=" W09-0629.xml">the tunareg challenge 2009 overview and evaluation results </title>
<section> evaluation methods and results.  </section>
<citcontext>
<prevsection>
<prevsent>se bleu nist fluency 1 0.68 0.50 -0.89* .85* -0.57 0.66 0.30 adequacy 0.68 1 0.95** -0.65 .83* -0.29 0.60 0.48 identification accuracy 0.50 0.95** 1 -0.39 0.68 -0.01 0.49 0.60 identification speed 0.89* -0.65 -0.39 1 -0.79 0.68 -0.51 0.06 accuracy 0.85* 0.83* 0.68 -0.79 1.00 -0.68 .859* 0.49 se -0.57 -0.29 -0.01 0.68 -0.68 1 -0.75 -0.07 bleu 0.66 0.60 0.49 -0.51 .86* -0.75 1 0.71 nist 0.30 0.48 0.60 0.06 0.49 -0.07 0.71 1 table 10: correlations (pearsons r) between all evaluation measures.
</prevsent>
<prevsent>(significant at ? .05; significant at ? .01) fluency and identification speed, implying that more fluent descriptions led to faster identification.
</prevsent>
</prevsection>
<citsent citstr=" P08-2050 ">
while these results differ from previous findings (belz and gatt, 2008), <papid> P08-2050 </papid>in which no significant correlations were found between extrinsic measures and automatic intrinsic metrics, it is worth noting that significance in the results reported herewas only observed between human-assessed intrinsic measures and the extrinsic ones.</citsent>
<aftsection>
<nextsent>the three editions of the tuna stec have attracted substantial amount of interest.
</nextsent>
<nextsent>in addition to sizeable body of new work on referring expression generation, as another tangible out come of these stecs we now have wide range of different sets of system outputs for the same set of inputs.
</nextsent>
<nextsent>a particularly valuable resource is the pairing of these outputs from the submitted systems in each edition with evaluation data.
</nextsent>
<nextsent>as this was the last time we are running stec with the tuna data, we will now make all datasets, documentation and evaluation software from all tuna stecs available to researchers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1468">
<title id=" W09-0509.xml">rubisc  a robust unification based incremental semantic chunker </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>real-time nlp applications such as dialogue systems can profit considerably from incremental processing of language.
</prevsent>
<prevsent>when syntactic and semantic structure is built on-line while the speech recognition (asr) is still working on the speech stream, unnatural silences can be avoided andthe system can react in faster and more user friendly way.
</prevsent>
</prevsection>
<citsent citstr=" W04-0304 ">
as (aist et al, 2007) and (skantzeand schlangen, 2009) show, such incremental systems are typically preferred by users over non incremental systems.to achieve incrementality, most dialogue systems employ an incremental chart parser (cf.(stoness et al, 2004; <papid> W04-0304 </papid>seginer, 2007) <papid> P07-1049 </papid>etc.).</citsent>
<aftsection>
<nextsent>how ever, most existing dialogue systems operate invery limited domains, e.g. moving objects, people, trains etc. from one place to another (cf.
</nextsent>
<nextsent>(aist et al, 2007), (skantze, 2007), (traum et al,1996)).
</nextsent>
<nextsent>the complexity of the semantic representations needed is thus limited.
</nextsent>
<nextsent>moreover, user behaviour (ungrammatical sentences, hesitations,false starts) and error-prone asr require the parsing process to be robust.1 we argue that obtaining relatively flat semantics in limited domain while needing exigent robustness calls for investigating shallower incremental chunking approaches as alternatives to cfg or dependency parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1469">
<title id=" W09-0509.xml">rubisc  a robust unification based incremental semantic chunker </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>real-time nlp applications such as dialogue systems can profit considerably from incremental processing of language.
</prevsent>
<prevsent>when syntactic and semantic structure is built on-line while the speech recognition (asr) is still working on the speech stream, unnatural silences can be avoided andthe system can react in faster and more user friendly way.
</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
as (aist et al, 2007) and (skantzeand schlangen, 2009) show, such incremental systems are typically preferred by users over non incremental systems.to achieve incrementality, most dialogue systems employ an incremental chart parser (cf.(stoness et al, 2004; <papid> W04-0304 </papid>seginer, 2007) <papid> P07-1049 </papid>etc.).</citsent>
<aftsection>
<nextsent>how ever, most existing dialogue systems operate invery limited domains, e.g. moving objects, people, trains etc. from one place to another (cf.
</nextsent>
<nextsent>(aist et al, 2007), (skantze, 2007), (traum et al,1996)).
</nextsent>
<nextsent>the complexity of the semantic representations needed is thus limited.
</nextsent>
<nextsent>moreover, user behaviour (ungrammatical sentences, hesitations,false starts) and error-prone asr require the parsing process to be robust.1 we argue that obtaining relatively flat semantics in limited domain while needing exigent robustness calls for investigating shallower incremental chunking approaches as alternatives to cfg or dependency parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1470">
<title id=" W09-0509.xml">rubisc  a robust unification based incremental semantic chunker </title>
<section> incremental chunking.  </section>
<citcontext>
<prevsection>
<prevsent>xpos:figure 1: incremental robust sense unit construction by rubisc.figure 2: puzzle-task of the corpus used for grammar building and testing.
</prevsent>
<prevsent>whether the utterance is complete is made, so that the chunker can be restarted for the next utterance if necessary.
</prevsent>
</prevsection>
<citsent citstr=" W08-0113 ">
2.1 regular grammar for semantics the grammar we are using for the experiments in this paper was developed using small corpus of german dialogue (siebert and schlangen, 2008), (<papid> W08-0113 </papid>siebert, 2007).</citsent>
<aftsection>
<nextsent>figure 2 shows picture of the task that the subjects completed for this corpus.2 number of pentomino pieces were presented.
</nextsent>
<nextsent>the pieces had to be moved into an animal-shaped figure.
</nextsent>
<nextsent>the subjects were shown partly completed puzzles and had to give concise and detailed verbal instructions of the next move that had to be done.
</nextsent>
<nextsent>the locations inside this figure were usually referred to in terms of body parts (move the into2for the corpus used here the difference was that the button labels were german and that the pentomino pieces were not ordered in two rows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1471">
<title id=" W09-0509.xml">rubisc  a robust unification based incremental semantic chunker </title>
<section> incremental chunking.  </section>
<citcontext>
<prevsection>
<prevsent>one of the main features of rubisc is its incre mentality.
</prevsent>
<prevsent>it can receive one word at time and extract semantic structure from it.
</prevsent>
</prevsection>
<citsent citstr=" W04-0308 ">
incrementalityis not strict here in the sense of (nivre, 2004), <papid> W04-0308 </papid>be cause sometimes more than one word is needed before parts of the frame are constructed and out put: into the right, for instance, needs to wait for word like leg that completes the chunk.</citsent>
<aftsection>
<nextsent>we dont necessarily consider this disadvantage, though, as our chunks closely correlate to the minimal bits of information that can usefully be reacted to.
</nextsent>
<nextsent>in our corpus the first slot gets on average filled after 3.5 words (disregarding examples where no slots are filled).
</nextsent>
<nextsent>the average utterance is 12.4 words long.
</nextsent>
<nextsent>2.5 end-of-sentence detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1472">
<title id=" W09-0509.xml">rubisc  a robust unification based incremental semantic chunker </title>
<section> incremental chunking.  </section>
<citcontext>
<prevsection>
<prevsent>2.5 end-of-sentence detection.
</prevsent>
<prevsent>an incremental parser in dialogue system needs to know when to stop processing sentence and when to start the next one.
</prevsent>
</prevsection>
<citsent citstr=" C08-2003 ">
this can be done by using prosodic and syntactic information (atterer et al, 2008) <papid> C08-2003 </papid>or by checking whether syntactic s-node is complete.</citsent>
<aftsection>
<nextsent>since rubisc builds sense units, the completeness of an utterance can be defined as semantic-pragmatic completeness, i.e. by certain number of slots that must be filled.
</nextsent>
<nextsent>in our domain, for instance, it makes sense to restart the chunker when the action and end slot and either the name slot or the two position slots are filled.
</nextsent>
<nextsent>2.6 history.
</nextsent>
<nextsent>the chunker keeps history of the states of the frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1473">
<title id=" W09-0509.xml">rubisc  a robust unification based incremental semantic chunker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our unification is carried out on filled slots and in an incremental fashion.
</prevsent>
<prevsent>it is not directly specified in our grammar formalism.
</prevsent>
</prevsection>
<citsent citstr=" P00-1018 ">
the chunker rather checks whether slot entries suggested by various independent grammar rules are unifiable.even though not incremental either, the approach by (milward, 2000) <papid> P00-1018 </papid>is similar in that it canpick information from various parts of an utter ance; for example, it can extract the arrival time from sentences like id like to arrive at york nowlets see yes at 3pm.</citsent>
<aftsection>
<nextsent>it builds semantic chart using categorial grammar.
</nextsent>
<nextsent>the entries of this chart are then mapped into slots.
</nextsent>
<nextsent>a number of settings are compared and evaluated using recall and precision measures.
</nextsent>
<nextsent>the setting with the highest recall (52%) achieves precision of 79%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1474">
<title id=" W08-1405.xml">multi sum query based multi document summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>mary.
</prevsent>
</prevsection>
<citsent citstr=" N04-3001 ">
uses of mds systems vary widely, from summarisation of closed-domain documents, suchas news documents (evans et al, 2004), <papid> N04-3001 </papid>to aggregation of information from several sources in an open domain.</citsent>
<aftsection>
<nextsent>mds techniques can be used in various tools that may help addressing the problems described in section 1.
</nextsent>
<nextsent>on the other hand, brief study of the relevant literature indicates that the majority of the work done in this area concerns closed-domains such as news summarisation, which is perhaps the reason why such tools have not yet become more popular.
</nextsent>
<nextsent>the objectives of this study are thus twofold.?
</nextsent>
<nextsent>the primary objective is that of designing, implementing and evaluating an open domain, query-based mds system which is capable of compiling an acceptably-coherent report from the most relevant online sources of information, whilst making it easy for the reader to access the full source of information in its original context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1475">
<title id=" W08-1405.xml">multi sum query based multi document summarization </title>
<section> make clusters disjoint.  </section>
<citcontext>
<prevsection>
<prevsent>however, in order to make it more applicable to our problem domain and increase the output quality, we introduced some improvements.
</prevsent>
<prevsent>sentence ordering model we introduced aprobabilistic sentence ordering model which enables the algorithm to choose the sentence that 29maximises the probability given the previous sentence.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
the sentence ordering model, based on method of probabilistic text structuring introduced by lapata (2003), <papid> P03-1069 </papid>is trained upon the whole document collection.</citsent>
<aftsection>
<nextsent>we used minipar (lin, 1993), <papid> P93-1016 </papid>dependency-based parser, in order to identify verbs, nouns, verb dependencies and noun dependencies.</nextsent>
<nextsent>using counts of these features and simple good-turing smoothing (gale and sampson, 1995), we were able to construct probabilistic sentence ordering model such that, during summary generation, given the previous sentence, we are able to identify the sentence which is the most likely to occur from the pool of sentences appearing at the beginning of the remaining paragraphs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1476">
<title id=" W08-1405.xml">multi sum query based multi document summarization </title>
<section> make clusters disjoint.  </section>
<citcontext>
<prevsection>
<prevsent>sentence ordering model we introduced aprobabilistic sentence ordering model which enables the algorithm to choose the sentence that 29maximises the probability given the previous sentence.
</prevsent>
<prevsent>the sentence ordering model, based on method of probabilistic text structuring introduced by lapata (2003), <papid> P03-1069 </papid>is trained upon the whole document collection.</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
we used minipar (lin, 1993), <papid> P93-1016 </papid>dependency-based parser, in order to identify verbs, nouns, verb dependencies and noun dependencies.</citsent>
<aftsection>
<nextsent>using counts of these features and simple good-turing smoothing (gale and sampson, 1995), we were able to construct probabilistic sentence ordering model such that, during summary generation, given the previous sentence, we are able to identify the sentence which is the most likely to occur from the pool of sentences appearing at the beginning of the remaining paragraphs.
</nextsent>
<nextsent>sentence filtering we also introduced at this stage method to filter out sentences that decrease the coherency and fluency of the resultant summary.
</nextsent>
<nextsent>this is based on two criteria: 1.
</nextsent>
<nextsent>very low probability of occurrence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1477">
<title id=" W08-1405.xml">multi sum query based multi document summarization </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 automatic evaluation.
</prevsent>
<prevsent>5.1.1 coherence evaluation in order to evaluate the local coherence of the reports generated by the system, we employed an au 4context switch refers to scenarios where candidate sentence comes from different document than that of the last sentence in the summary.
</prevsent>
</prevsection>
<citsent citstr=" P05-1018 ">
tomatic coherence evaluation method introduced by barzilay and lapata (2005) <papid> P05-1018 </papid>5 . the main objec-.</citsent>
<aftsection>
<nextsent>tive of this part of the evaluation phase was to determine the effect on output quality when parameters are varied, namely the minimum cluster support parameter for the clustering algorithm, and the key phrase popularity.from this evaluation, we empirically determined that the optimum minimum cluster support threshold for this application is 50, whilst the quality of the output is directly proportional to the key word popularity.
</nextsent>
<nextsent>5.1.2 keyword density evaluation here we focused on determining whether the secondary objective was achieved (cf.
</nextsent>
<nextsent>section 2).
</nextsent>
<nextsent>we measured the frequency of occurrence of the keyword phrase within the output, or more specifically, the keyword density.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1478">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>grammars extracted from the wall street journal(wsj) section of the penn treebank have been successfully applied to natural language parsing, and more recently, to natural language generation.
</prevsent>
<prevsent>it is clear that high-quality grammars can be extracted for the wsj domain but it is not so clear how these grammars scale to other text genres.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
gildea (2001), <papid> W01-0521 </papid>for example, has shown that wsj-trained parsers suffer drop in performance when applied to the more varied sentences of the brown cor pus.</citsent>
<aftsection>
<nextsent>we investigate the effect of domain variation in treebank-grammar-based generation by applying wsj-trained generator to sentences from the british national corpus (bnc).as with probabilistic parsing, probabilistic generation aims to produce the most likely output(s) given the input.
</nextsent>
<nextsent>we can distinguish three types of probabilistic generators, based on the type of probability model used to select the most likely sentence.
</nextsent>
<nextsent>the first type uses an n-gram language model, e.g.(langkilde, 2000), <papid> A00-2023 </papid>the second type uses probability model defined over trees or feature-structure annotated trees, e.g.</nextsent>
<nextsent>(cahill and van genabith, 2006), <papid> P06-1130 </papid>and the third type is mixture of the fir stand second type, employing n-gram and grammar based features, e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1479">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigate the effect of domain variation in treebank-grammar-based generation by applying wsj-trained generator to sentences from the british national corpus (bnc).as with probabilistic parsing, probabilistic generation aims to produce the most likely output(s) given the input.
</prevsent>
<prevsent>we can distinguish three types of probabilistic generators, based on the type of probability model used to select the most likely sentence.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
the first type uses an n-gram language model, e.g.(langkilde, 2000), <papid> A00-2023 </papid>the second type uses probability model defined over trees or feature-structure annotated trees, e.g.</citsent>
<aftsection>
<nextsent>(cahill and van genabith, 2006), <papid> P06-1130 </papid>and the third type is mixture of the fir stand second type, employing n-gram and grammar based features, e.g.</nextsent>
<nextsent>(velldal and oepen, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1480">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we can distinguish three types of probabilistic generators, based on the type of probability model used to select the most likely sentence.
</prevsent>
<prevsent>the first type uses an n-gram language model, e.g.(langkilde, 2000), <papid> A00-2023 </papid>the second type uses probability model defined over trees or feature-structure annotated trees, e.g.</prevsent>
</prevsection>
<citsent citstr=" P06-1130 ">
(cahill and van genabith, 2006), <papid> P06-1130 </papid>and the third type is mixture of the fir stand second type, employing n-gram and grammar based features, e.g.</citsent>
<aftsection>
<nextsent>(velldal and oepen, 2005).
</nextsent>
<nextsent>the generator used in our experiments is an instance of the second type, using probability model defined over lexical functional grammar c-structure and f-structure annotations (cahill and van genabith, 2006; <papid> P06-1130 </papid>hogan et al, 2007).<papid> D07-1028 </papid></nextsent>
<nextsent>in an initial evaluation, we apply our probabilistic wsj-trained generator to bnc material, and show that the generator suffers substantial performance degradation, with drop in bleu score from 0.66 to 0.54.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1482">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(cahill and van genabith, 2006), <papid> P06-1130 </papid>and the third type is mixture of the fir stand second type, employing n-gram and grammar based features, e.g.</prevsent>
<prevsent>(velldal and oepen, 2005).</prevsent>
</prevsection>
<citsent citstr=" D07-1028 ">
the generator used in our experiments is an instance of the second type, using probability model defined over lexical functional grammar c-structure and f-structure annotations (cahill and van genabith, 2006; <papid> P06-1130 </papid>hogan et al, 2007).<papid> D07-1028 </papid></citsent>
<aftsection>
<nextsent>in an initial evaluation, we apply our probabilistic wsj-trained generator to bnc material, and show that the generator suffers substantial performance degradation, with drop in bleu score from 0.66 to 0.54.
</nextsent>
<nextsent>we then turn our attention to the problem of adapting the generator so that it can more accurately generate the 1,000 sentences in our bnc test set.
</nextsent>
<nextsent>the problem of adapting any nlp system to domain different from the domain upon which it hasbeen trained and for which no gold standard training material is available is very real one, and one which has been the focus of much recent research in parsing.
</nextsent>
<nextsent>some success has been achieved by training parser, not on gold standard hand-corrected trees, but on parser output trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1483">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of adapting any nlp system to domain different from the domain upon which it hasbeen trained and for which no gold standard training material is available is very real one, and one which has been the focus of much recent research in parsing.
</prevsent>
<prevsent>some success has been achieved by training parser, not on gold standard hand-corrected trees, but on parser output trees.
</prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
these parser output trees can by produced by second parser in co-training scenario (steedman et al, 2003), <papid> E03-1008 </papid>or by the same parser with reranking component in type of self training scenario (mcclosky et al, 2006).<papid> N06-1020 </papid></citsent>
<aftsection>
<nextsent>we tackle 165 the problem of domain adaptation in generation in similar way, by training the generator on domain specific parser output trees instead of manually corrected gold standard trees.
</nextsent>
<nextsent>this experiment achieves promising results, with an increase in bleu score from 0.54 to 0.61.
</nextsent>
<nextsent>the method is generic and can be applied to other probabilistic generators (for which suitable training material can be automatically pro duced).
</nextsent>
<nextsent>the natural language generator used in our experiments is the wsj-trained system described in cahill and van genabith (2006) <papid> P06-1130 </papid>and hogan et al (2007).<papid> D07-1028 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1484">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of adapting any nlp system to domain different from the domain upon which it hasbeen trained and for which no gold standard training material is available is very real one, and one which has been the focus of much recent research in parsing.
</prevsent>
<prevsent>some success has been achieved by training parser, not on gold standard hand-corrected trees, but on parser output trees.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
these parser output trees can by produced by second parser in co-training scenario (steedman et al, 2003), <papid> E03-1008 </papid>or by the same parser with reranking component in type of self training scenario (mcclosky et al, 2006).<papid> N06-1020 </papid></citsent>
<aftsection>
<nextsent>we tackle 165 the problem of domain adaptation in generation in similar way, by training the generator on domain specific parser output trees instead of manually corrected gold standard trees.
</nextsent>
<nextsent>this experiment achieves promising results, with an increase in bleu score from 0.54 to 0.61.
</nextsent>
<nextsent>the method is generic and can be applied to other probabilistic generators (for which suitable training material can be automatically pro duced).
</nextsent>
<nextsent>the natural language generator used in our experiments is the wsj-trained system described in cahill and van genabith (2006) <papid> P06-1130 </papid>and hogan et al (2007).<papid> D07-1028 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1488">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the natural language generator used in our experiments is the wsj-trained system described in cahill and van genabith (2006) <papid> P06-1130 </papid>and hogan et al (2007).<papid> D07-1028 </papid></prevsent>
<prevsent>sentences are generated from lexical functional grammar (lfg) f-structures (kaplan and bresnan, 1982).</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
the f-structures are created automatically by annotating nodes in the gold standard wsj trees with lfg functional equations and then passing these equations through constraint solver (cahillet al, 2004).<papid> P04-1041 </papid></citsent>
<aftsection>
<nextsent>the generation algorithm is chart based one which works by finding the most probable tree associated with the input f-structure.
</nextsent>
<nextsent>the yield of the most probable tree is the output sentence.
</nextsent>
<nextsent>an annotated pcfg, in which the nonterminal symbols are decorated with functional information, is used to generate the most probable tree from an f-structure.
</nextsent>
<nextsent>cahill and van genabith (2006) <papid> P06-1130 </papid>attain 98.2% coverage and bleu score of 0.6652 on the standard wsj test set (section 23).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1492">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>instead of conditioning the right hand sideof rule on the left hand non-terminal and its associated functional information alone, the new model includes non-local conditioning information in theform of functional information associated with ancestor nodes of the left hand side category.
</prevsent>
<prevsent>this system achieves bleu score of 0.6724 and 99.9% coverage.
</prevsent>
</prevsection>
<citsent citstr=" W05-1510 ">
other wsj-trained generation systems include nakanishi et al (2005) <papid> W05-1510 </papid>and white et al (2007).</citsent>
<aftsection>
<nextsent>nakanishi et al (2005) <papid> W05-1510 </papid>describe generator trained on hpsg grammar derived from the wsj section of the penn treebank.</nextsent>
<nextsent>on sentences of ? 20 words in length, their system attains coverage of 90.75% and bleu score of 0.7733.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1496">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in further experiment, we attempt to adapt the generator to bnc data by using bnc trees as training material.
</prevsent>
<prevsent>because we lack gold standard bnc trees (apart from those in our test set), wetry instead to use parse trees produced by an accurate parser.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
we choose the charniak and johnson reranking parser because it is freely available and achieves state-of-the-art accuracy (a parseval f-scoreof 91.3%) on the wsj domain (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>it is, however, affected by domain variation ? foster et al (2007) <papid> W07-2204 </papid>report that its f-score drops by approximately 8 percentage points when applied to the bnc domain.</nextsent>
<nextsent>our training size is 500,000 sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1497">
<title id=" W08-1122.xml">parser based retraining for domain adaptation of probabilistic generators </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>because we lack gold standard bnc trees (apart from those in our test set), wetry instead to use parse trees produced by an accurate parser.
</prevsent>
<prevsent>we choose the charniak and johnson reranking parser because it is freely available and achieves state-of-the-art accuracy (a parseval f-scoreof 91.3%) on the wsj domain (charniak and johnson, 2005).<papid> P05-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-2204 ">
it is, however, affected by domain variation ? foster et al (2007) <papid> W07-2204 </papid>report that its f-score drops by approximately 8 percentage points when applied to the bnc domain.</citsent>
<aftsection>
<nextsent>our training size is 500,000 sentences.
</nextsent>
<nextsent>we conduct two experiments: the first, in which 500,000 sentences are extracted randomly from the bnc (minus the test set sentences), and the second in which only shorter sentences, of length ? 20 words, are chosen as trainingmaterial.
</nextsent>
<nextsent>the rationale behind the second experiment is that shorter sentences are less likely to contain parser errors.we use the bleu evaluation metric for our experiments.
</nextsent>
<nextsent>we measure both coverage and full coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1503">
<title id=" W09-1321.xml">bridging the gap between domain oriented and linguistically oriented semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an important step in nlp-based tm is obtaining the domain oriented semantics of sentences, as shown at the bottom of figure 1.
</prevsent>
<prevsent>the bio infer (pyysalo et al, 2007)and the genia event corpus (kim et al, 2008) provide annotations of such semantic structures on collections of bio-medical articles.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
domain-oriented semantic structures are valuable assets because their representation suits information needs in the do main; however, the extraction of such structures is difficult due to the large gap between the text and these structures.on the other hand, the extraction of linguistically oriented semantics from text has long been studied in computational linguistics, and has recently been formalized as semantic role labeling (gildea and jurafsky, 2002), <papid> J02-3001 </papid>and semantic structure extraction(baker et al, 2007)(<papid> W07-2018 </papid>surdeanu et al, 2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>semantic structures in such tasks are exemplified in the middle of figure 1.
</nextsent>
<nextsent>the linguistically-oriented semantic structures are easier to extract, although the information is not practical to the domain.
</nextsent>
<nextsent>we aim at relating linguistically-oriented frames of semantics with domain-oriented classes, thus making step forward in utilizing the computational linguistic resources for the bio-medical tm.of all the differences in the two type of semantics, we focused on the fact that the former frames are more sensitive to the perspective imposed bythe sentence writer.
</nextsent>
<nextsent>in the right hand-side example of figure 1, the linguistically-oriented structure treats pbmc, cell entity, as an agent; however the bio-medical structure reflects the scientific view that there are no agents, objects acting with intention, in bio-molecular phenomena.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1504">
<title id=" W09-1321.xml">bridging the gap between domain oriented and linguistically oriented semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an important step in nlp-based tm is obtaining the domain oriented semantics of sentences, as shown at the bottom of figure 1.
</prevsent>
<prevsent>the bio infer (pyysalo et al, 2007)and the genia event corpus (kim et al, 2008) provide annotations of such semantic structures on collections of bio-medical articles.
</prevsent>
</prevsection>
<citsent citstr=" W07-2018 ">
domain-oriented semantic structures are valuable assets because their representation suits information needs in the do main; however, the extraction of such structures is difficult due to the large gap between the text and these structures.on the other hand, the extraction of linguistically oriented semantics from text has long been studied in computational linguistics, and has recently been formalized as semantic role labeling (gildea and jurafsky, 2002), <papid> J02-3001 </papid>and semantic structure extraction(baker et al, 2007)(<papid> W07-2018 </papid>surdeanu et al, 2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>semantic structures in such tasks are exemplified in the middle of figure 1.
</nextsent>
<nextsent>the linguistically-oriented semantic structures are easier to extract, although the information is not practical to the domain.
</nextsent>
<nextsent>we aim at relating linguistically-oriented frames of semantics with domain-oriented classes, thus making step forward in utilizing the computational linguistic resources for the bio-medical tm.of all the differences in the two type of semantics, we focused on the fact that the former frames are more sensitive to the perspective imposed bythe sentence writer.
</nextsent>
<nextsent>in the right hand-side example of figure 1, the linguistically-oriented structure treats pbmc, cell entity, as an agent; however the bio-medical structure reflects the scientific view that there are no agents, objects acting with intention, in bio-molecular phenomena.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1505">
<title id=" W09-1321.xml">bridging the gap between domain oriented and linguistically oriented semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an important step in nlp-based tm is obtaining the domain oriented semantics of sentences, as shown at the bottom of figure 1.
</prevsent>
<prevsent>the bio infer (pyysalo et al, 2007)and the genia event corpus (kim et al, 2008) provide annotations of such semantic structures on collections of bio-medical articles.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
domain-oriented semantic structures are valuable assets because their representation suits information needs in the do main; however, the extraction of such structures is difficult due to the large gap between the text and these structures.on the other hand, the extraction of linguistically oriented semantics from text has long been studied in computational linguistics, and has recently been formalized as semantic role labeling (gildea and jurafsky, 2002), <papid> J02-3001 </papid>and semantic structure extraction(baker et al, 2007)(<papid> W07-2018 </papid>surdeanu et al, 2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>semantic structures in such tasks are exemplified in the middle of figure 1.
</nextsent>
<nextsent>the linguistically-oriented semantic structures are easier to extract, although the information is not practical to the domain.
</nextsent>
<nextsent>we aim at relating linguistically-oriented frames of semantics with domain-oriented classes, thus making step forward in utilizing the computational linguistic resources for the bio-medical tm.of all the differences in the two type of semantics, we focused on the fact that the former frames are more sensitive to the perspective imposed bythe sentence writer.
</nextsent>
<nextsent>in the right hand-side example of figure 1, the linguistically-oriented structure treats pbmc, cell entity, as an agent; however the bio-medical structure reflects the scientific view that there are no agents, objects acting with intention, in bio-molecular phenomena.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1506">
<title id=" W09-1321.xml">bridging the gap between domain oriented and linguistically oriented semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>geniaexpression?(biologicallyorientedsemans) class:localizantheme:nfkappabfromloc:cytosoltoloc:nucleus?
</prevsent>
<prevsent>theme:il6fromloc:?(insideof)pmbctoloc:??????(outsideof)pmbcfigure 1: comparison of the linguistically-oriented and biologically oriented structure of semantics event corpus.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
expressions mentioning the four classes were examined and manually classified into linguistically-oriented frames, represented by those defined in framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>fn frames associated to bio-molecular event class constitute alist of possible perspectives in mentioning phenomena of the class.the rest of this paper is structured in the following way: section 2 reviews the existing work on semantic structures and expression varieties inthe bio-medical domain, and provides comparison to our work.
</nextsent>
<nextsent>in section 3, we describe the genia event corpus, and the framenet frames used as linguistically-oriented classes in our investigation.
</nextsent>
<nextsent>sections 4 and 5 explain the methods and results ofthe corpus investigation; in particular the sections investigate how the linguistic frames were associated to the domain-oriented classes of semantics.
</nextsent>
<nextsent>finally, we provide discussion and conclusion in section 6 and 7.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1507">
<title id=" W09-1321.xml">bridging the gap between domain oriented and linguistically oriented semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing work on semantics approached domain oriented semantic structures from linguistically oriented semantics.
</prevsent>
<prevsent>in contrast, our approach usesdomain-oriented semantics to find the linguistic semantics that represent them.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
we believe that the two different approaches could complement each other.the pasbio(wattarujeekrit et al, 2004) proposes predicate argument structures (pass), type of linguistically-oriented semantic structures, fordomain-specific lexical items, based on pass defined in propbank(wattarujeekrit et al, 2004) andnombank(meyers et al, 2004).<papid> W04-2705 </papid></citsent>
<aftsection>
<nextsent>the pass are defined per lexical item, and is therefore distinct from abiologically-oriented representation of events.
</nextsent>
<nextsent>(co hen et al, 2008) investigated syntactic alternations of verbs and their nominal ized forms which occurred in the pennbioie corpus(kulick et al, 2004), <papid> W04-3111 </papid>whilst keeping pass of the pasbio in their minds.the bioframenet(dolbey et al, 2006) is an attempt to extend the framenet with specific frames to the bio-medical domain, and to apply the frames to corpus annotation.</nextsent>
<nextsent>our attempts were similar, in that both were: 1) utilizing the fn frames or their extensions to classify mentions of biological events,and 2) relating the frames and the fes (roles of par ticipants) with classes in domain ontologies; e.g. the gene ontology(ashburner et al, 2000).as far as the authors know, it is the first attempt to explicitly address the problem of linking linguistically-oriented and domain-oriented frames of semantics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1508">
<title id=" W09-1321.xml">bridging the gap between domain oriented and linguistically oriented semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we believe that the two different approaches could complement each other.the pasbio(wattarujeekrit et al, 2004) proposes predicate argument structures (pass), type of linguistically-oriented semantic structures, fordomain-specific lexical items, based on pass defined in propbank(wattarujeekrit et al, 2004) andnombank(meyers et al, 2004).<papid> W04-2705 </papid></prevsent>
<prevsent>the pass are defined per lexical item, and is therefore distinct from abiologically-oriented representation of events.</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
(co hen et al, 2008) investigated syntactic alternations of verbs and their nominal ized forms which occurred in the pennbioie corpus(kulick et al, 2004), <papid> W04-3111 </papid>whilst keeping pass of the pasbio in their minds.the bioframenet(dolbey et al, 2006) is an attempt to extend the framenet with specific frames to the bio-medical domain, and to apply the frames to corpus annotation.</citsent>
<aftsection>
<nextsent>our attempts were similar, in that both were: 1) utilizing the fn frames or their extensions to classify mentions of biological events,and 2) relating the frames and the fes (roles of par ticipants) with classes in domain ontologies; e.g. the gene ontology(ashburner et al, 2000).as far as the authors know, it is the first attempt to explicitly address the problem of linking linguistically-oriented and domain-oriented frames of semantics.
</nextsent>
<nextsent>however, it has been indirectly studied through works on tm or relation extraction using linguistically-oriented semantic structures as features, such as in the case with (harabagiu et al, 2005).
</nextsent>
<nextsent>we used domain-oriented annotations of the genia event corpus and linguistically-oriented frames defined in framenet (fn), to link domain-oriented and linguistically-oriented frames of semantics.
</nextsent>
<nextsent>we briefly describe these resources next.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1509">
<title id=" W08-1701.xml">tulipa towards a multi formalism parsing environment for grammar engineering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is used for the development of tree-based grammar for german.
</prevsent>
<prevsent>grammars and lexicons represent important linguistic resources for many nlp applications,among which one may cite dialog systems, automatic summarization or machine translation.
</prevsent>
</prevsection>
<citsent citstr=" A92-1039 ">
developing such resources is known to be complex task that needs useful tools such as parsers and generators (erbach, 1992).<papid> A92-1039 </papid>furthermore, there is lack of common framework allowing for multi-formalism grammar engineering.</citsent>
<aftsection>
<nextsent>thus, many formalisms have been proposed to model natural language, each coming with specific implementations.
</nextsent>
<nextsent>having common framework would facilitate the comparison ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.between formalisms (e.g., in terms of parsing complexity in practice), and would allow for better sharing of resources (e.g., having common lexicon, from which different features would be extracted depending on the target formalism).in this context, we present parsing environment relying on general architecture that can be used for parsing with mildly context-sensitive(mcs) formalisms1 (joshi, 1987).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1510">
<title id=" W08-1701.xml">tulipa towards a multi formalism parsing environment for grammar engineering </title>
<section> range concatenation grammar as a.  </section>
<citcontext>
<prevsection>
<prevsent>in turns, this makes tulipa more easily extensible, either in terms of functional ities, or in terms of formalisms.
</prevsent>
<prevsent>2.1 adding functional ities to the parsing.
</prevsent>
</prevsection>
<citsent citstr=" E03-1030 ">
environment as an illustration of tulipas extensibility, one may consider two extensions applied to the system recently.first, semantic calculus using the syntax/semantics interface for tag proposed by gardent and kallmeyer (2003) <papid> E03-1030 </papid>has been added.</citsent>
<aftsection>
<nextsent>this interface associates each tree with flat semantic formulas.
</nextsent>
<nextsent>the arguments of these formulas are unification variables, which are co-indexed with features labelling the nodes of the syntactic tree.during classical tag derivation, trees are combined, triggering unifications of the feature structures labelling nodes.
</nextsent>
<nextsent>as result of these unifica tions, the arguments of the semantic formulas are unified (see fig.
</nextsent>
<nextsent>1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1511">
<title id=" W08-1701.xml">tulipa towards a multi formalism parsing environment for grammar engineering </title>
<section> range concatenation grammar as a.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, this sub grammar may contain many trees that either do not lead to parse or for which we know priori that they cannot be combined within the same derivation (so we should not predict derivation from oneof these trees to another during parsing).
</prevsent>
<prevsent>as result, the parser could have poor performance be cause of the many derivation paths that have to be explored.
</prevsent>
</prevsection>
<citsent citstr=" C04-1044 ">
bonfante et al (2004) <papid> C04-1044 </papid>proposed to polarize the structures of the grammar, and to apply an automaton-based filtering of the compatible structures.</citsent>
<aftsection>
<nextsent>the idea is the following.
</nextsent>
<nextsent>one compute polarities representing the needs/resources brought by given tree (or tree tuple for tt-mctag).a substitution or foot node with category np reflects need for an np (written np-).
</nextsent>
<nextsent>in the same way, an np root node reflects resource of type np (written np+).
</nextsent>
<nextsent>then you build an automaton whose edges correspond to trees, and states to polarities brought by trees along the path.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1514">
<title id=" W08-1701.xml">tulipa towards a multi formalism parsing environment for grammar engineering </title>
<section> towards complete grammar.  </section>
<citcontext>
<prevsection>
<prevsent>the german grammar, called gertt (forgerman tree tuples), is released under lgpl license for linguistic resources11 and is presentedin (kallmeyer et al, 2008).
</prevsent>
<prevsent>the test-suite currently used to check the grammar is hand-crafted.
</prevsent>
</prevsection>
<citsent citstr=" C96-2120 ">
a more systematic evaluation of the grammar is in preparation, using the test suite for natural language processing (lehmann et al, 1996).<papid> C96-2120 </papid></citsent>
<aftsection>
<nextsent>9see http://sourcesup.cru.fr/tulipa.
</nextsent>
<nextsent>10see http://www.gecode.org/gecodej.
</nextsent>
<nextsent>11see http://infolingu.univ-mlv.
</nextsent>
<nextsent>fr/donneeslinguistiques/ lexiques-grammaires/lgpllr.html 5
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1516">
<title id=" W08-1701.xml">tulipa towards a multi formalism parsing environment for grammar engineering </title>
<section> comparison with existing approaches.  </section>
<citcontext>
<prevsection>
<prevsent>dyalogsmain quality lies in its efficiency in terms of parsing time and its capacity to handle very large resources.
</prevsent>
<prevsent>unlike tulipa, it does not compute semantic representations.
</prevsent>
</prevsection>
<citsent citstr=" P07-2004 ">
the closest approach to tulipa corresponds to the semtag system13, which extends tag parsers compiled with dyalog with semantic calculus module (gardent and parmentier, 2007).<papid> P07-2004 </papid></citsent>
<aftsection>
<nextsent>unlike tulipa, this system only supports tag, and does not provide any graphical output allowing to easily check the result of parsing.note that, for grammar designers mainly interested in tag, semtag and tulipa can be seen as complementary tools.
</nextsent>
<nextsent>indeed, one may usetulipa to develop the grammar and check specific syntactic structures thanks to its intuitive parsing environment.
</nextsent>
<nextsent>once the grammar is stable, one may use semtag in batch processing to parse corp uses and build semantic representations using large grammars.
</nextsent>
<nextsent>this combination of these 2 systems is made easier by the fact that both use the same input formats (a meta grammar in the xmg language and text-based lexicon).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1517">
<title id=" W08-1701.xml">tulipa towards a multi formalism parsing environment for grammar engineering </title>
<section> comparison with existing approaches.  </section>
<citcontext>
<prevsection>
<prevsent>this combination of these 2 systems is made easier by the fact that both use the same input formats (a meta grammar in the xmg language and text-based lexicon).
</prevsent>
<prevsent>this approach is the one being adopted for the development of french tag equipped with semantics.
</prevsent>
</prevsection>
<citsent citstr=" C00-2087 ">
for interaction grammar (perrier, 2000), <papid> C00-2087 </papid>there exists an engineering environment gathering the xmg meta grammar compiler and an eletrostaticparser (leopar).14 this environment is being used to develop an interaction grammar for french.</citsent>
<aftsection>
<nextsent>tulipas lexical disambiguation module 12see http://dyalog.gforge.inria.fr 13see http://trac.loria.fr/semconst 14see http://www.loria.fr/equipes/ calligramme/leopar/ reuses techniques introduced by leopar.
</nextsent>
<nextsent>unliketulipa, leopar does not currently support semantic information.
</nextsent>
<nextsent>4.2 engineering environments for other.
</nextsent>
<nextsent>grammar formalisms for other formalisms, there exist state-of-the-art grammar engineering environments that have been used for many years to design large deep grammars for several languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1520">
<title id=" W09-0504.xml">semantic representation of non sentential utterances in dialog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(eh so ... you kinda like you know hmm drinking) in nlp, such disfluencies can be removed before any syntactic or semantic processing since they cause confusion without adding any semantic information.
</prevsent>
<prevsent>in machine-learning tasks, dis fluency is sought to be automatically removed by learning from disfluency-marked corpora or corpora of text edits (haji?
</prevsent>
</prevsection>
<citsent citstr=" L08-1530 ">
et al, 2008; fitzgerald and jelinek, 2008) <papid> L08-1530 </papid>to smooth the input text into written-language standard before parsing.</citsent>
<aftsection>
<nextsent>on the other hand, there is another sort of dis fluencies, which do not disturb the course of the dialog, namely contextual ellipsis: even though most people remember being taught at school to answer questions with complete sentence, not even educated speakers performing sophisticated dialog always do so, and yet they do not sound incorrect.
</nextsent>
<nextsent>clearly, an extensive use of ellipsis is an inherent feature of verbal interaction between speakers, which is usually smoothly perceived by the listener and thus all right in its place.
</nextsent>
<nextsent>such fragmentary utterances that do not have the form of full sentence according to most traditional grammars, but that nevertheless convey complete clausal meaning?
</nextsent>
<nextsent>are called non sentential utterances (nsus)1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1521">
<title id=" W09-1009.xml">upper bounds for unsupervised parsing with unambiguous non terminally separated grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show way to translate this score into an upper bound for the f1.
</prevsent>
<prevsent>in particular, we show that the f1 parsing score of any unts grammar can not be beyond 82.2%when the gold treebank is the wsj10 corpus.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
unsupervised learning of natural language has received lot of attention in the last years, e.g., klein and manning (2004), <papid> P04-1061 </papid>bod (2006<papid> W06-2912 </papid>a) and seginer(2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>most of them use sentences from tree bank for training and trees from the same treebank for evaluation.
</nextsent>
<nextsent>as such, the best model for unsupervised parsing is the one that reports the best performance.
</nextsent>
<nextsent>unambiguous non-terminally separated (unts) grammars have properties that make them attractive for grammatical inference.
</nextsent>
<nextsent>these grammars have been shown to be pac-learnable in polynomial time (clark, 2006), meaning that under certain circumstances, the underlying grammar can be learned from sample of the underlying language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1522">
<title id=" W09-1009.xml">upper bounds for unsupervised parsing with unambiguous non terminally separated grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show way to translate this score into an upper bound for the f1.
</prevsent>
<prevsent>in particular, we show that the f1 parsing score of any unts grammar can not be beyond 82.2%when the gold treebank is the wsj10 corpus.
</prevsent>
</prevsection>
<citsent citstr=" W06-2912 ">
unsupervised learning of natural language has received lot of attention in the last years, e.g., klein and manning (2004), <papid> P04-1061 </papid>bod (2006<papid> W06-2912 </papid>a) and seginer(2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>most of them use sentences from tree bank for training and trees from the same treebank for evaluation.
</nextsent>
<nextsent>as such, the best model for unsupervised parsing is the one that reports the best performance.
</nextsent>
<nextsent>unambiguous non-terminally separated (unts) grammars have properties that make them attractive for grammatical inference.
</nextsent>
<nextsent>these grammars have been shown to be pac-learnable in polynomial time (clark, 2006), meaning that under certain circumstances, the underlying grammar can be learned from sample of the underlying language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1526">
<title id=" W09-1009.xml">upper bounds for unsupervised parsing with unambiguous non terminally separated grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show way to translate this score into an upper bound for the f1.
</prevsent>
<prevsent>in particular, we show that the f1 parsing score of any unts grammar can not be beyond 82.2%when the gold treebank is the wsj10 corpus.
</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
unsupervised learning of natural language has received lot of attention in the last years, e.g., klein and manning (2004), <papid> P04-1061 </papid>bod (2006<papid> W06-2912 </papid>a) and seginer(2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>most of them use sentences from tree bank for training and trees from the same treebank for evaluation.
</nextsent>
<nextsent>as such, the best model for unsupervised parsing is the one that reports the best performance.
</nextsent>
<nextsent>unambiguous non-terminally separated (unts) grammars have properties that make them attractive for grammatical inference.
</nextsent>
<nextsent>these grammars have been shown to be pac-learnable in polynomial time (clark, 2006), meaning that under certain circumstances, the underlying grammar can be learned from sample of the underlying language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1543">
<title id=" W09-1305.xml">how feasible and robust is the automatic extraction of gene regulation events a cross method evaluation under lab and real life conditions </title>
<section> extraction of gene regulation events.  </section>
<citcontext>
<prevsection>
<prevsent>the system further recognizes multi-gene object names (e.g., acrab?), divides them into individual gene names (e.g., acra?, acrb?)
</prevsent>
<prevsent>and associates the gene names with the multi-gene object names.relation identification.
</prevsent>
</prevsection>
<citsent citstr=" P07-1079 ">
the system then identifies syntactic structures of sentences in an in put corpus by utilizing the enju parser (sagae etal., 2007).<papid> P07-1079 </papid></citsent>
<aftsection>
<nextsent>the enju parser generates predicate argument structures, and the system converts them into dependency structures.
</nextsent>
<nextsent>the system then analyzes the semantics of the sentences by matching syntactic-semantic patterns to the dependency structures.
</nextsent>
<nextsent>we constructed 1,123patterns for the event extraction according to the following workflow.
</nextsent>
<nextsent>we first collected keywords related to gene regulation, from gene ontology, inter pro, wordnet, and several papers about information extraction from biomedical literature (hatzivassiloglou and weng, 2002; kim and park,2004; huang et al, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1544">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an mwe is compositional if the meaning of an mwe as unit can be predicted from the meaning of its component words such as in make decision meaning to decide.
</prevsent>
<prevsent>if we conceive ofidiomaticity as being continuum, the more idiomatic an expression, the less transparent and the more non-compositional it is.mwes are pervasive in natural language, especially in web based texts and speech genres.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
identifying mwes and understanding their meaning is essential to language understanding, hence theyare of crucial importance for any natural language processing (nlp) applications that aim at handling robust language meaning and use.to date, most research has addressed the problem of mwe type classification for vnc expressions in english (melamed, 1997; <papid> W97-0311 </papid>lin, 1999; <papid> P99-1041 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>na villada moiron and tiedemann, 2006; fazly and stevenson, 2007;<papid> W07-1102 </papid>van de cruys and villada moiron, 2007; mccarthy et al, 2007), <papid> D07-1039 </papid>not token classification.</citsent>
<aftsection>
<nextsent>for example: he spilt the beans over the kitchen counter is most likely literal usage.
</nextsent>
<nextsent>this is given away by the use of the prepositional phrase over the kitchen counter, since it is pla usable that beans could have literally been spilt on location such as kitchen counter.
</nextsent>
<nextsent>most previous research would classify spilt the beans as idiomatic irrespective of usage.
</nextsent>
<nextsent>a recent study by (cook et al, 2008) of 60 idiom mwe types concluded that almost half of them had clear literal meaning and over 40% of their usages in text were actually literal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1545">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an mwe is compositional if the meaning of an mwe as unit can be predicted from the meaning of its component words such as in make decision meaning to decide.
</prevsent>
<prevsent>if we conceive ofidiomaticity as being continuum, the more idiomatic an expression, the less transparent and the more non-compositional it is.mwes are pervasive in natural language, especially in web based texts and speech genres.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
identifying mwes and understanding their meaning is essential to language understanding, hence theyare of crucial importance for any natural language processing (nlp) applications that aim at handling robust language meaning and use.to date, most research has addressed the problem of mwe type classification for vnc expressions in english (melamed, 1997; <papid> W97-0311 </papid>lin, 1999; <papid> P99-1041 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>na villada moiron and tiedemann, 2006; fazly and stevenson, 2007;<papid> W07-1102 </papid>van de cruys and villada moiron, 2007; mccarthy et al, 2007), <papid> D07-1039 </papid>not token classification.</citsent>
<aftsection>
<nextsent>for example: he spilt the beans over the kitchen counter is most likely literal usage.
</nextsent>
<nextsent>this is given away by the use of the prepositional phrase over the kitchen counter, since it is pla usable that beans could have literally been spilt on location such as kitchen counter.
</nextsent>
<nextsent>most previous research would classify spilt the beans as idiomatic irrespective of usage.
</nextsent>
<nextsent>a recent study by (cook et al, 2008) of 60 idiom mwe types concluded that almost half of them had clear literal meaning and over 40% of their usages in text were actually literal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1546">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an mwe is compositional if the meaning of an mwe as unit can be predicted from the meaning of its component words such as in make decision meaning to decide.
</prevsent>
<prevsent>if we conceive ofidiomaticity as being continuum, the more idiomatic an expression, the less transparent and the more non-compositional it is.mwes are pervasive in natural language, especially in web based texts and speech genres.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
identifying mwes and understanding their meaning is essential to language understanding, hence theyare of crucial importance for any natural language processing (nlp) applications that aim at handling robust language meaning and use.to date, most research has addressed the problem of mwe type classification for vnc expressions in english (melamed, 1997; <papid> W97-0311 </papid>lin, 1999; <papid> P99-1041 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>na villada moiron and tiedemann, 2006; fazly and stevenson, 2007;<papid> W07-1102 </papid>van de cruys and villada moiron, 2007; mccarthy et al, 2007), <papid> D07-1039 </papid>not token classification.</citsent>
<aftsection>
<nextsent>for example: he spilt the beans over the kitchen counter is most likely literal usage.
</nextsent>
<nextsent>this is given away by the use of the prepositional phrase over the kitchen counter, since it is pla usable that beans could have literally been spilt on location such as kitchen counter.
</nextsent>
<nextsent>most previous research would classify spilt the beans as idiomatic irrespective of usage.
</nextsent>
<nextsent>a recent study by (cook et al, 2008) of 60 idiom mwe types concluded that almost half of them had clear literal meaning and over 40% of their usages in text were actually literal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1548">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an mwe is compositional if the meaning of an mwe as unit can be predicted from the meaning of its component words such as in make decision meaning to decide.
</prevsent>
<prevsent>if we conceive ofidiomaticity as being continuum, the more idiomatic an expression, the less transparent and the more non-compositional it is.mwes are pervasive in natural language, especially in web based texts and speech genres.
</prevsent>
</prevsection>
<citsent citstr=" W07-1102 ">
identifying mwes and understanding their meaning is essential to language understanding, hence theyare of crucial importance for any natural language processing (nlp) applications that aim at handling robust language meaning and use.to date, most research has addressed the problem of mwe type classification for vnc expressions in english (melamed, 1997; <papid> W97-0311 </papid>lin, 1999; <papid> P99-1041 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>na villada moiron and tiedemann, 2006; fazly and stevenson, 2007;<papid> W07-1102 </papid>van de cruys and villada moiron, 2007; mccarthy et al, 2007), <papid> D07-1039 </papid>not token classification.</citsent>
<aftsection>
<nextsent>for example: he spilt the beans over the kitchen counter is most likely literal usage.
</nextsent>
<nextsent>this is given away by the use of the prepositional phrase over the kitchen counter, since it is pla usable that beans could have literally been spilt on location such as kitchen counter.
</nextsent>
<nextsent>most previous research would classify spilt the beans as idiomatic irrespective of usage.
</nextsent>
<nextsent>a recent study by (cook et al, 2008) of 60 idiom mwe types concluded that almost half of them had clear literal meaning and over 40% of their usages in text were actually literal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1549">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an mwe is compositional if the meaning of an mwe as unit can be predicted from the meaning of its component words such as in make decision meaning to decide.
</prevsent>
<prevsent>if we conceive ofidiomaticity as being continuum, the more idiomatic an expression, the less transparent and the more non-compositional it is.mwes are pervasive in natural language, especially in web based texts and speech genres.
</prevsent>
</prevsection>
<citsent citstr=" D07-1039 ">
identifying mwes and understanding their meaning is essential to language understanding, hence theyare of crucial importance for any natural language processing (nlp) applications that aim at handling robust language meaning and use.to date, most research has addressed the problem of mwe type classification for vnc expressions in english (melamed, 1997; <papid> W97-0311 </papid>lin, 1999; <papid> P99-1041 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>na villada moiron and tiedemann, 2006; fazly and stevenson, 2007;<papid> W07-1102 </papid>van de cruys and villada moiron, 2007; mccarthy et al, 2007), <papid> D07-1039 </papid>not token classification.</citsent>
<aftsection>
<nextsent>for example: he spilt the beans over the kitchen counter is most likely literal usage.
</nextsent>
<nextsent>this is given away by the use of the prepositional phrase over the kitchen counter, since it is pla usable that beans could have literally been spilt on location such as kitchen counter.
</nextsent>
<nextsent>most previous research would classify spilt the beans as idiomatic irrespective of usage.
</nextsent>
<nextsent>a recent study by (cook et al, 2008) of 60 idiom mwe types concluded that almost half of them had clear literal meaning and over 40% of their usages in text were actually literal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1550">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an idm expression is certainly an mwe, however, the converse is not necessarily true.
</prevsent>
<prevsent>we handle the problem of sparsity for mwe classification by exploring different vector space features: various vector similarity metrics, andmore linguistically oriented feature sets.
</prevsent>
</prevsection>
<citsent citstr=" W07-1106 ">
we evaluate our results against standard dataset from the study by (cook et al, 2007).<papid> W07-1106 </papid></citsent>
<aftsection>
<nextsent>we achieve state of the art performance in classifying vnc tokens as either literal (f-measure: f1=0.64) or idiomatic (f1=0.82), corresponding to an overall accuracy of 75.54%.
</nextsent>
<nextsent>this paper is organized as follows: in section 96 2 we describe our understanding of the various classes of mwes in general.
</nextsent>
<nextsent>section 3 is summary of previous related research.
</nextsent>
<nextsent>section 4 describes our approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1553">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> previous related work.  </section>
<citcontext>
<prevsection>
<prevsent>this category consists of light verb constructions (lvc) such as make living and verb particle constructions (vpc) such as write-up, call-up.
</prevsent>
<prevsent>non-idiomatic: this category includes expressions that are semantically compositional such as prime minister, proper nouns such as new york yankees.
</prevsent>
</prevsection>
<citsent citstr=" W06-1203 ">
several researchers have addressed the problem of mwe classification (baldwin et al, 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006; <papid> W06-1203 </papid>schone and juraksfy, 2001; hashimoto et al, 2006; <papid> P06-2046 </papid>hashimoto and kawahara, 2008).<papid> D08-1104 </papid></citsent>
<aftsection>
<nextsent>the majority of the proposed research hasbeen using unsupervised approaches and have addressed the problem of mwe type classification irrespective of usage in context.
</nextsent>
<nextsent>only, the work by hashimoto et al (2006) <papid> P06-2046 </papid>and hashimoto and kawahara (2008) <papid> D08-1104 </papid>addressed token classification in japanese using supervised learning.the most comparable work to ours is there search by (cook et al, 2007) <papid> W07-1106 </papid>and (fazly and stevenson, 2007).<papid> W07-1102 </papid></nextsent>
<nextsent>on the other hand, (cook et al., 2007) <papid> W07-1106 </papid>develop an unsupervised technique that classifies vnc expression as idiomatic or literal.they examine if the similarity between the context vector of the mwe, in this case the vnc, and that of its idiomatic usage is higher than the similarity between its context vector and that ofits literal usage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1555">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> previous related work.  </section>
<citcontext>
<prevsection>
<prevsent>this category consists of light verb constructions (lvc) such as make living and verb particle constructions (vpc) such as write-up, call-up.
</prevsent>
<prevsent>non-idiomatic: this category includes expressions that are semantically compositional such as prime minister, proper nouns such as new york yankees.
</prevsent>
</prevsection>
<citsent citstr=" P06-2046 ">
several researchers have addressed the problem of mwe classification (baldwin et al, 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006; <papid> W06-1203 </papid>schone and juraksfy, 2001; hashimoto et al, 2006; <papid> P06-2046 </papid>hashimoto and kawahara, 2008).<papid> D08-1104 </papid></citsent>
<aftsection>
<nextsent>the majority of the proposed research hasbeen using unsupervised approaches and have addressed the problem of mwe type classification irrespective of usage in context.
</nextsent>
<nextsent>only, the work by hashimoto et al (2006) <papid> P06-2046 </papid>and hashimoto and kawahara (2008) <papid> D08-1104 </papid>addressed token classification in japanese using supervised learning.the most comparable work to ours is there search by (cook et al, 2007) <papid> W07-1106 </papid>and (fazly and stevenson, 2007).<papid> W07-1102 </papid></nextsent>
<nextsent>on the other hand, (cook et al., 2007) <papid> W07-1106 </papid>develop an unsupervised technique that classifies vnc expression as idiomatic or literal.they examine if the similarity between the context vector of the mwe, in this case the vnc, and that of its idiomatic usage is higher than the similarity between its context vector and that ofits literal usage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1556">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> previous related work.  </section>
<citcontext>
<prevsection>
<prevsent>this category consists of light verb constructions (lvc) such as make living and verb particle constructions (vpc) such as write-up, call-up.
</prevsent>
<prevsent>non-idiomatic: this category includes expressions that are semantically compositional such as prime minister, proper nouns such as new york yankees.
</prevsent>
</prevsection>
<citsent citstr=" D08-1104 ">
several researchers have addressed the problem of mwe classification (baldwin et al, 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006; <papid> W06-1203 </papid>schone and juraksfy, 2001; hashimoto et al, 2006; <papid> P06-2046 </papid>hashimoto and kawahara, 2008).<papid> D08-1104 </papid></citsent>
<aftsection>
<nextsent>the majority of the proposed research hasbeen using unsupervised approaches and have addressed the problem of mwe type classification irrespective of usage in context.
</nextsent>
<nextsent>only, the work by hashimoto et al (2006) <papid> P06-2046 </papid>and hashimoto and kawahara (2008) <papid> D08-1104 </papid>addressed token classification in japanese using supervised learning.the most comparable work to ours is there search by (cook et al, 2007) <papid> W07-1106 </papid>and (fazly and stevenson, 2007).<papid> W07-1102 </papid></nextsent>
<nextsent>on the other hand, (cook et al., 2007) <papid> W07-1106 </papid>develop an unsupervised technique that classifies vnc expression as idiomatic or literal.they examine if the similarity between the context vector of the mwe, in this case the vnc, and that of its idiomatic usage is higher than the similarity between its context vector and that ofits literal usage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1571">
<title id=" W09-0213.xml">handling sparsity for verb noun mwe token classification </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>after combining the word types in the vector dimensions, weneed to handle their co-occurrence frequency values.
</prevsent>
<prevsent>hence we have two methods: addition where we simply add the frequencies in the cases of the shared dimensions which amounts to union where the co-occurrence frequencies are added;or multiplication which amounts to an intersection of the vector dimensions where the cooccurrence frequencies are multiplied, hence giving more weight to the shared dimensions than inthe addition case.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
in study by (mitchell and lapata, 2008) <papid> P08-1028 </papid>on sentence similarity task, multiplicative combination model performs better than the additive one.similarity measures we experiment with several standard similarity measures: cosine similarity, overlap similarity, dice coefficient and jac card index as defined in (manning and schutze, 1999).</citsent>
<aftsection>
<nextsent>a context vector is converted to set by using the dimensions of the vector as members of the set.
</nextsent>
<nextsent>5.1 data.
</nextsent>
<nextsent>we use the british national corpus (bnc),3 which contains 100m words, because it draws itstext from wide variety of domains and the existing gold standard datasets are derived from it.the bnc contains multiple genres including written text and transcribed speech.
</nextsent>
<nextsent>we only experiment with the written-text portion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1573">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the aim is to detect implications between sentences like: 1 ? 1 1 wanadoo bought kstones?
</prevsent>
<prevsent>h 1 wanadoo owns kstones?
</prevsent>
</prevsection>
<citsent citstr=" W05-1203 ">
where 1 and 1stand for text and hypothesis, re spectively.several models, ranging from the simple lexical similarity between and to advanced logic form representations, have been proposed (cor ley and mihalcea, 2005; <papid> W05-1203 </papid>glickman and dagan,2004; de salvo braz et al, 2005; bos and markert, 2005).<papid> H05-1079 </papid></citsent>
<aftsection>
<nextsent>however, since linguistic theory able to analytically show how to computationally solve the rte problem has not been developed yet, to ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>design accurate systems, we should rely upon the application of machine learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1574">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the aim is to detect implications between sentences like: 1 ? 1 1 wanadoo bought kstones?
</prevsent>
<prevsent>h 1 wanadoo owns kstones?
</prevsent>
</prevsection>
<citsent citstr=" H05-1079 ">
where 1 and 1stand for text and hypothesis, re spectively.several models, ranging from the simple lexical similarity between and to advanced logic form representations, have been proposed (cor ley and mihalcea, 2005; <papid> W05-1203 </papid>glickman and dagan,2004; de salvo braz et al, 2005; bos and markert, 2005).<papid> H05-1079 </papid></citsent>
<aftsection>
<nextsent>however, since linguistic theory able to analytically show how to computationally solve the rte problem has not been developed yet, to ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>design accurate systems, we should rely upon the application of machine learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1575">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the use of syntactic trees poses the problem of representing structures in learning algorithms.
</prevsent>
<prevsent>1 ? is larger than the actual space, which is the one of all possible sub sequences with gaps, i.e. it only contains all possible concatenations of words respecting their order.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
25for this purpose, kernel methods, and in particular tree kernels allow for representing trees in terms of all possible subtrees (collins and duffy,2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>unfortunately, the representation in entailment recognition problems requires the definition of kernels over graphs constituted by tree pairs, which are in general different from kernels applied to single trees.
</nextsent>
<nextsent>in (zanzotto and moschitti, 2006), this has been addressed by introducing semantic links (placeholders) between text and hypothesis parse trees and evaluating two distinct tree kernels for the trees of texts and for those of hypotheses.
</nextsent>
<nextsent>in order to make such disjoint kernel combination effective, all possible assignments between the place holders of the first and the second entailment pair were generated causing remarkable slowdown.
</nextsent>
<nextsent>in this paper, we describe the feature space of all possible tree fragment pairs and we show that it can be evaluated with much simpler kernel than the one used in previous work, both in terms of design and computational complexity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1580">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> kernels over semantic tree pair-based.  </section>
<citcontext>
<prevsection>
<prevsent>since the considered graphs are composed by only two trees, we can carried out simplified computation of graph kernel based on tree kernel pairs.
</prevsent>
<prevsent>3.1 tree kernels.
</prevsent>
</prevsection>
<citsent citstr=" P06-1117 ">
tree kernels (e.g. see nlp applications in (giu glea and moschitti, 2006; <papid> P06-1117 </papid>zanzotto and moschitti, 2006; moschitti et al, 2007; <papid> P07-1098 </papid>moschitti et al, 2006; <papid> W06-2909 </papid>moschitti and bejan, 2004)) <papid> W04-2403 </papid>represent trees in terms of their substructures (fragments) which are mapped into feature vector spaces, e.g. n.the kernel function measures the similarity between two trees by counting the number of their common fragments.</citsent>
<aftsection>
<nextsent>for example, figure 1 shows some substructures for the parse tree of the sentence  book flight .
</nextsent>
<nextsent>the main advantage of tree kernels is that, to compute the substructures shared by two trees ? 1 and ? 2 , the whole fragment space is not used.
</nextsent>
<nextsent>in the following, we report the formal definition presented in (collins and duffy, 2002).<papid> P02-1034 </papid></nextsent>
<nextsent>given the set of fragments {f 1 , 2 , ..}</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1581">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> kernels over semantic tree pair-based.  </section>
<citcontext>
<prevsection>
<prevsent>since the considered graphs are composed by only two trees, we can carried out simplified computation of graph kernel based on tree kernel pairs.
</prevsent>
<prevsent>3.1 tree kernels.
</prevsent>
</prevsection>
<citsent citstr=" P07-1098 ">
tree kernels (e.g. see nlp applications in (giu glea and moschitti, 2006; <papid> P06-1117 </papid>zanzotto and moschitti, 2006; moschitti et al, 2007; <papid> P07-1098 </papid>moschitti et al, 2006; <papid> W06-2909 </papid>moschitti and bejan, 2004)) <papid> W04-2403 </papid>represent trees in terms of their substructures (fragments) which are mapped into feature vector spaces, e.g. n.the kernel function measures the similarity between two trees by counting the number of their common fragments.</citsent>
<aftsection>
<nextsent>for example, figure 1 shows some substructures for the parse tree of the sentence  book flight .
</nextsent>
<nextsent>the main advantage of tree kernels is that, to compute the substructures shared by two trees ? 1 and ? 2 , the whole fragment space is not used.
</nextsent>
<nextsent>in the following, we report the formal definition presented in (collins and duffy, 2002).<papid> P02-1034 </papid></nextsent>
<nextsent>given the set of fragments {f 1 , 2 , ..}</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1582">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> kernels over semantic tree pair-based.  </section>
<citcontext>
<prevsection>
<prevsent>since the considered graphs are composed by only two trees, we can carried out simplified computation of graph kernel based on tree kernel pairs.
</prevsent>
<prevsent>3.1 tree kernels.
</prevsent>
</prevsection>
<citsent citstr=" W06-2909 ">
tree kernels (e.g. see nlp applications in (giu glea and moschitti, 2006; <papid> P06-1117 </papid>zanzotto and moschitti, 2006; moschitti et al, 2007; <papid> P07-1098 </papid>moschitti et al, 2006; <papid> W06-2909 </papid>moschitti and bejan, 2004)) <papid> W04-2403 </papid>represent trees in terms of their substructures (fragments) which are mapped into feature vector spaces, e.g. n.the kernel function measures the similarity between two trees by counting the number of their common fragments.</citsent>
<aftsection>
<nextsent>for example, figure 1 shows some substructures for the parse tree of the sentence  book flight .
</nextsent>
<nextsent>the main advantage of tree kernels is that, to compute the substructures shared by two trees ? 1 and ? 2 , the whole fragment space is not used.
</nextsent>
<nextsent>in the following, we report the formal definition presented in (collins and duffy, 2002).<papid> P02-1034 </papid></nextsent>
<nextsent>given the set of fragments {f 1 , 2 , ..}</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1583">
<title id=" W08-2004.xml">encoding tree pair based graphs in learning algorithms the textual entailment recognition case </title>
<section> kernels over semantic tree pair-based.  </section>
<citcontext>
<prevsection>
<prevsent>since the considered graphs are composed by only two trees, we can carried out simplified computation of graph kernel based on tree kernel pairs.
</prevsent>
<prevsent>3.1 tree kernels.
</prevsent>
</prevsection>
<citsent citstr=" W04-2403 ">
tree kernels (e.g. see nlp applications in (giu glea and moschitti, 2006; <papid> P06-1117 </papid>zanzotto and moschitti, 2006; moschitti et al, 2007; <papid> P07-1098 </papid>moschitti et al, 2006; <papid> W06-2909 </papid>moschitti and bejan, 2004)) <papid> W04-2403 </papid>represent trees in terms of their substructures (fragments) which are mapped into feature vector spaces, e.g. n.the kernel function measures the similarity between two trees by counting the number of their common fragments.</citsent>
<aftsection>
<nextsent>for example, figure 1 shows some substructures for the parse tree of the sentence  book flight .
</nextsent>
<nextsent>the main advantage of tree kernels is that, to compute the substructures shared by two trees ? 1 and ? 2 , the whole fragment space is not used.
</nextsent>
<nextsent>in the following, we report the formal definition presented in (collins and duffy, 2002).<papid> P02-1034 </papid></nextsent>
<nextsent>given the set of fragments {f 1 , 2 , ..}</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1587">
<title id=" W08-0912.xml">towards automatic scoring of a test of spoken language with heterogeneous task types </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe the speech recognizer used for this system and its acoustic model and language model adaptation; the speech features computed based on the recognition output; and finally the scoring models based on multiple regression and classification trees.
</prevsent>
<prevsent>for both tasks, agreement measures between machine and human scores (correlation, kappa) are close to or reach inter-human agreements.
</prevsent>
</prevsection>
<citsent citstr=" N06-1028 ">
as demand for spoken language testing and cost of human scoring have increased in recent years, there is growing interest in building both research and industrial systems for automatically scoring non-native speech (bernstein, 1999, zechner and bejar, 2006, <papid> N06-1028 </papid>zechner et al 2007).</citsent>
<aftsection>
<nextsent>however, past approaches have focused typically only on one type of spoken language, or on range of types similar in linguistic entropy.
</nextsent>
<nextsent>entropy in this context can be seen as measure for how predictable the language in the expected spoken response is: some tests, such as set-10 (bern stein 1999), are focused mostly on the lower entropy aspects of language, using tasks such as reading?
</nextsent>
<nextsent>or repetition?, where the expected sequence of words is highly predictable.
</nextsent>
<nextsent>other assessments, such as the toefl?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1591">
<title id=" W09-0621.xml">clustering and matching headlines for automatic paraphrase acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in wordnet), this kind of information is much harder to get by at the phrase level.
</prevsent>
<prevsent>therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
paraphrase generation has already proven to be valuable for question answering (lin and pantel, 2001; riezler et al, 2007), machine translation (callison-burch et al, 2006) and the evaluation thereof (russo-lassner et al, 2006; kauchak and barzilay, 2006; <papid> N06-1058 </papid>zhou etal., 2006), but also for text simplification and ex planation.</citsent>
<aftsection>
<nextsent>in the study described in this paper, we make an effort to collect dutch paraphrases from news article headlines in an unsupervised way to beused in future paraphrase generation.
</nextsent>
<nextsent>news article headlines are abundant on the web, and are already grouped by news aggregators such as google news.
</nextsent>
<nextsent>these services collect multiple articles covering the same event.
</nextsent>
<nextsent>crawling such newsaggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of paraphrases (dolan et al, 2004; <papid> C04-1051 </papid>nelken and shieber, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1592">
<title id=" W09-0621.xml">clustering and matching headlines for automatic paraphrase acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>news article headlines are abundant on the web, and are already grouped by news aggregators such as google news.
</prevsent>
<prevsent>these services collect multiple articles covering the same event.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
crawling such newsaggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of paraphrases (dolan et al, 2004; <papid> C04-1051 </papid>nelken and shieber, 2006).</citsent>
<aftsection>
<nextsent>we use this method to collect large amount of aligned paraphrases in an automatic fashion.
</nextsent>
<nextsent>we aim to build high-quality paraphrase corpus.considering the fact that this corpus will be the basic resource of paraphrase generation system, we need it to be as free of errors as possible, because errors will propagate throughout the system.
</nextsent>
<nextsent>this implies that we focus on obtaining high precision in the paraphrases collection process.
</nextsent>
<nextsent>where previous work has focused on aligning news-items atthe paragraph and sentence level (barzilay andel hadad, 2003), we choose to focus on aligning the headlines of news articles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1593">
<title id=" W09-0413.xml">the universitaumlt karlsruhe translation system for the eaclwmt 2009 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the core of our system is the sttk decoder (vo gel, 2003), phrase-based smt decoder with alocal reordering window of 2 words.
</prevsent>
<prevsent>the decoder generates translation for the input text or word lattice by searching translation mod eland language model for the hypothesis that maximizes phrase translation probabilities and target language probabilities.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the translation model, i.e. the smt phrase table is created during the training phase by modified version of the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>applying giza++ for word alignment.</citsent>
<aftsection>
<nextsent>language models are built using thesrilm toolkit.
</nextsent>
<nextsent>the pos-tags for the reordering models were generated with the tree tagger (schmid, 1994) for all languages.
</nextsent>
<nextsent>2.1 training, development and test data.
</nextsent>
<nextsent>we submitted translations for the english german, german-english, english-french and french-english tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1594">
<title id=" W09-0413.xml">the universitaumlt karlsruhe translation system for the eaclwmt 2009 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we submitted translations for the english german, german-english, english-french and french-english tasks.
</prevsent>
<prevsent>all systems were trained on the europarl and news commentary corpora using the moses toolkit and apply 4-gram language models created from the respective monolingual news corpora.
</prevsent>
</prevsection>
<citsent citstr=" W05-0836 ">
all feature weights are automatically determined and optimized with respect to bleu via mert (venugopal et al, 2005).<papid> W05-0836 </papid>for development and testing we used data provided by the wmt09, news-dev2009a and news dev2009b, consisting of 1026 sentences each.</citsent>
<aftsection>
<nextsent>one part of our system that differs from the base line system is the reordering model.
</nextsent>
<nextsent>to account for the different word orders in the languages, we used the pos-based reordering model presented in rottmann and vogel (2007).
</nextsent>
<nextsent>this model learns rules from parallel text to reorder the source side.
</nextsent>
<nextsent>the aim is to generate reordered source side that can be translated in more monotone way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1595">
<title id=" W09-0413.xml">the universitaumlt karlsruhe translation system for the eaclwmt 2009 </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 word alignment.
</prevsent>
<prevsent>the baseline method for creating the word alignment is to create the giza++ alignments in both directions and then to combine both alignments using heuristic, e.g. grow-diag-final-and heuristic, as provided by the moses toolkit.
</prevsent>
</prevsection>
<citsent citstr=" W08-0303 ">
in someof the submitted systems we used discriminative word alignment model (dwa) to generate the alignments as described in niehues and vogel (2008) <papid> W08-0303 </papid>instead.</citsent>
<aftsection>
<nextsent>this model is trained on small amount of hand-aligned data and uses the lexical probability as well as the fertilities generated by the giza++ toolkit and pos information.
</nextsent>
<nextsent>weused all local features, the giza and indicator fertility features as well as first order features for 6 directions.
</nextsent>
<nextsent>the model was trained in three steps, first using the maximum likelihood optimization and afterwards it was optimized towards the alignment error rate.
</nextsent>
<nextsent>for more details see niehues and vogel (2008).<papid> W08-0303 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1597">
<title id=" W09-0413.xml">the universitaumlt karlsruhe translation system for the eaclwmt 2009 </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 phrase table smoothing.
</prevsent>
<prevsent>the relative frequencies of the phrase pairs are very important feature of the translation model, but they often overestimate rare phrase pairs.
</prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
therefore, the raw relative frequency estimates found in the phrase translation tables are smoothed by applying modified kneser-ney discounting as described in foster et al (2006).<papid> W06-1607 </papid></citsent>
<aftsection>
<nextsent>4.3 lattice phrase extraction.
</nextsent>
<nextsent>for the test sentences the pos-based reordering allows us to change the word order in the source sentence, so that the sentence can be translated more easily.
</nextsent>
<nextsent>but this approach does not reorder the training sentences.
</nextsent>
<nextsent>this may cause problems for phrase extraction, especially for long-range reorderings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1598">
<title id=" W09-0413.xml">the universitaumlt karlsruhe translation system for the eaclwmt 2009 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>wa 14.45 15.61 + long-range reordering 14.58 15.70 5.2 german-english.
</prevsent>
<prevsent>the german-english system was trained on the same data as the english-german except that we perform compound splitting as an additional preprocessing step.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the compound splitting was done with the frequency-based method described in koehn et al (2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>for this language direction, the initial system already uses phrase table smoothing, adaptation and discriminative word alignment, in addition to the techniques of the english-german baseline system.
</nextsent>
<nextsent>the results are shown in table 2.
</nextsent>
<nextsent>for this language pair, we could improve the translation quality, first, by adding the long-range reordering model.
</nextsent>
<nextsent>further improvements could be achieved by using lattice phrase extraction as described before.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1599">
<title id=" W08-1131.xml">the tuna challenge 2008 overview and evaluation results </title>
<section> evaluation methods.  </section>
<citcontext>
<prevsection>
<prevsent>the cost for insertions and deletions was set to 1, that for substitutions to 2.
</prevsent>
<prevsent>edit distance is an integer bounded by the length of the longest description in the pair being compared.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu (tuna-r, tuna-reg): this is an n-grambased string comparison measure, originally proposed by papineni et al (2002) <papid> P02-1040 </papid>for evaluation of machine translation systems.</citsent>
<aftsection>
<nextsent>it evaluates system based on the proportion of word n-grams (consid ering all n-grams of length ? 4 is standard) that it shares with several reference translations.
</nextsent>
<nextsent>unlike dice, masi and string-edit, bleu is by definition an aggregate measure (i.e. single bleu score is obtained for system based on the entire set of items to be compared, and this is generally not equal to the average of bleu scores for individual items).
</nextsent>
<nextsent>bleu ranges between 0 and 1.
</nextsent>
<nextsent>nist (tuna-r, tuna-reg): this is version of bleu, which gives more importance to less frequent (hence more informative) n-grams.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1600">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state of the art statistical parsers require large amounts of manually annotated data to achieve good performance.
</prevsent>
<prevsent>creating such data imposes heavy cognitive load on the human annotator and is thus costly and error prone.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
statistical parsers are major components in nlp applications such as qa (kwok et al, 2001), mt (marcu et al, 2006) <papid> W06-1606 </papid>andsrl (toutanova et al, 2005).<papid> P05-1073 </papid></citsent>
<aftsection>
<nextsent>these often operate over the highly variable web, which consists of texts written in many languages and genres.
</nextsent>
<nextsent>since the performance of parsers markedly degrades when training and test data come from different domains(lease and charniak, 2005), <papid> I05-1006 </papid>large amounts of training data from each domain are required for using them effectively.</nextsent>
<nextsent>thus, decreasing the human efforts involved in creating training data for parsers without harming their performance is of high importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1601">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state of the art statistical parsers require large amounts of manually annotated data to achieve good performance.
</prevsent>
<prevsent>creating such data imposes heavy cognitive load on the human annotator and is thus costly and error prone.
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
statistical parsers are major components in nlp applications such as qa (kwok et al, 2001), mt (marcu et al, 2006) <papid> W06-1606 </papid>andsrl (toutanova et al, 2005).<papid> P05-1073 </papid></citsent>
<aftsection>
<nextsent>these often operate over the highly variable web, which consists of texts written in many languages and genres.
</nextsent>
<nextsent>since the performance of parsers markedly degrades when training and test data come from different domains(lease and charniak, 2005), <papid> I05-1006 </papid>large amounts of training data from each domain are required for using them effectively.</nextsent>
<nextsent>thus, decreasing the human efforts involved in creating training data for parsers without harming their performance is of high importance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1602">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical parsers are major components in nlp applications such as qa (kwok et al, 2001), mt (marcu et al, 2006) <papid> W06-1606 </papid>andsrl (toutanova et al, 2005).<papid> P05-1073 </papid></prevsent>
<prevsent>these often operate over the highly variable web, which consists of texts written in many languages and genres.</prevsent>
</prevsection>
<citsent citstr=" I05-1006 ">
since the performance of parsers markedly degrades when training and test data come from different domains(lease and charniak, 2005), <papid> I05-1006 </papid>large amounts of training data from each domain are required for using them effectively.</citsent>
<aftsection>
<nextsent>thus, decreasing the human efforts involved in creating training data for parsers without harming their performance is of high importance.
</nextsent>
<nextsent>in this paper we address this problem through sample selection: given parsing algorithm and alarge pool of unannotated sentences s, select subset s1 ? for human annotation such that the human efforts in annotating s1 are minimized while the parser performance when trained with this sample is maximized.
</nextsent>
<nextsent>previous works addressing training sample size vs. parser performance for constituency parsers (section 2) evaluated training sample size using the total number of constituents (tc).
</nextsent>
<nextsent>sentences differ in length and therefore in annotation efforts, and ithas been argued (see, e.g, (hwa, 2004)) <papid> J04-3001 </papid>that tc reflects the number of decisions the human annotator makes when syntactically annotating the sample, assuming uniform cost for each decision.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1603">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we address this problem through sample selection: given parsing algorithm and alarge pool of unannotated sentences s, select subset s1 ? for human annotation such that the human efforts in annotating s1 are minimized while the parser performance when trained with this sample is maximized.
</prevsent>
<prevsent>previous works addressing training sample size vs. parser performance for constituency parsers (section 2) evaluated training sample size using the total number of constituents (tc).
</prevsent>
</prevsection>
<citsent citstr=" J04-3001 ">
sentences differ in length and therefore in annotation efforts, and ithas been argued (see, e.g, (hwa, 2004)) <papid> J04-3001 </papid>that tc reflects the number of decisions the human annotator makes when syntactically annotating the sample, assuming uniform cost for each decision.</citsent>
<aftsection>
<nextsent>in this paper we posit that important aspects of the efforts involved in annotating sample are not reflected by the tc measure.
</nextsent>
<nextsent>since annotators analyze sentences rather than bag of constituents, sentence structure has major impact on their cognitive efforts.
</nextsent>
<nextsent>sizeable psycho linguistic literature points to the connection between nested structures in the syntactic structure of sentence and its annotationefforts.
</nextsent>
<nextsent>this has motivated us to introduce (section 3) three sample size measures, the total and av 3 erage number of nested structures of degree in the sample, and the average number of constituents per sentence in the sample.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1609">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>their uncertainty sampling protocol combined bagging with the te function, achieving 32% tc reduction for reaching parser f-score level of 85.5%.
</prevsent>
<prevsent>the target sample size set contained much smaller number of sentences(5k) than ours.
</prevsent>
</prevsection>
<citsent citstr=" W04-3202 ">
baldridge and osborne (2004) <papid> W04-3202 </papid>addressed hpsg parse selection using feature basedlog-linear parser, the redwoods corpus and committee based active learning, obtaining 80% reduction in annotation cost.</citsent>
<aftsection>
<nextsent>their annotation cost measure was related to the number of possible parses of the sentence.
</nextsent>
<nextsent>tang et al (2002) <papid> P02-1016 </papid>addressed shallow parser trained on semantically annotated corpus.</nextsent>
<nextsent>1hwa explored several functions in the experimental setup used in the present work, and te gave the best results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1610">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>baldridge and osborne (2004) <papid> W04-3202 </papid>addressed hpsg parse selection using feature basedlog-linear parser, the redwoods corpus and committee based active learning, obtaining 80% reduction in annotation cost.</prevsent>
<prevsent>their annotation cost measure was related to the number of possible parses of the sentence.</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
tang et al (2002) <papid> P02-1016 </papid>addressed shallow parser trained on semantically annotated corpus.</citsent>
<aftsection>
<nextsent>1hwa explored several functions in the experimental setup used in the present work, and te gave the best results.
</nextsent>
<nextsent>4 they used an uncertainty sampling protocol, where in each iteration the sentences of the un labelled pool are clustered using distance measure defined on parse trees to predefined number of clusters.
</nextsent>
<nextsent>themost uncertain sentences are selected from the clusters, the training taking into account the densities of the clusters.
</nextsent>
<nextsent>they reduced the number of training sentences required for their parser to achieve its best performance from 1300 to 400.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1611">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they reduced the number of training sentences required for their parser to achieve its best performance from 1300 to 400.
</prevsent>
<prevsent>the importance of cognitively driven measures of sentences?
</prevsent>
</prevsection>
<citsent citstr=" W07-1001 ">
syntactic complexity has been recognized by roark et al (2007) <papid> W07-1001 </papid>who demonstrated their utility for mild cognitive impairment diagnosis.</citsent>
<aftsection>
<nextsent>zhu et al (2008) <papid> C08-1143 </papid>used clustering algorithm for sampling the initial labeled set in an al algorithm for word sense disambiguation and text classification.</nextsent>
<nextsent>in contrast toour cbs method, they proceeded with iterative uncertainty al selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1612">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the importance of cognitively driven measures of sentences?
</prevsent>
<prevsent>syntactic complexity has been recognized by roark et al (2007) <papid> W07-1001 </papid>who demonstrated their utility for mild cognitive impairment diagnosis.</prevsent>
</prevsection>
<citsent citstr=" C08-1143 ">
zhu et al (2008) <papid> C08-1143 </papid>used clustering algorithm for sampling the initial labeled set in an al algorithm for word sense disambiguation and text classification.</citsent>
<aftsection>
<nextsent>in contrast toour cbs method, they proceeded with iterative uncertainty al selection.
</nextsent>
<nextsent>melville et al (2005) used parameter-based sample selection for classifier ina classic active learning setting, for task very different from ours.
</nextsent>
<nextsent>sample selection has been applied to many nlp applications.
</nextsent>
<nextsent>examples include base noun phrase chunking (ngai, 2000), named entity recognition (tomanek et al, 2007) <papid> D07-1051 </papid>and multi task annotation (reichart et al, 2008).<papid> P08-1098 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1613">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>melville et al (2005) used parameter-based sample selection for classifier ina classic active learning setting, for task very different from ours.
</prevsent>
<prevsent>sample selection has been applied to many nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" D07-1051 ">
examples include base noun phrase chunking (ngai, 2000), named entity recognition (tomanek et al, 2007) <papid> D07-1051 </papid>and multi task annotation (reichart et al, 2008).<papid> P08-1098 </papid></citsent>
<aftsection>
<nextsent>while the resources, capabilities and constraints of the human parser have been the subject of extensive research, different theories predict different aspects of its observed performance.
</nextsent>
<nextsent>we focus on structures that are widely agreed to impose high cognitive load on the human annotator and on theories considering the cognitive resources required in parsing complete sentence.
</nextsent>
<nextsent>based on these, we derive measures for the cognitive load on the human parser when syntactically annotating set of sentences.
</nextsent>
<nextsent>nested structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1614">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>melville et al (2005) used parameter-based sample selection for classifier ina classic active learning setting, for task very different from ours.
</prevsent>
<prevsent>sample selection has been applied to many nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" P08-1098 ">
examples include base noun phrase chunking (ngai, 2000), named entity recognition (tomanek et al, 2007) <papid> D07-1051 </papid>and multi task annotation (reichart et al, 2008).<papid> P08-1098 </papid></citsent>
<aftsection>
<nextsent>while the resources, capabilities and constraints of the human parser have been the subject of extensive research, different theories predict different aspects of its observed performance.
</nextsent>
<nextsent>we focus on structures that are widely agreed to impose high cognitive load on the human annotator and on theories considering the cognitive resources required in parsing complete sentence.
</nextsent>
<nextsent>based on these, we derive measures for the cognitive load on the human parser when syntactically annotating set of sentences.
</nextsent>
<nextsent>nested structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1615">
<title id=" W09-1103.xml">sample selection for statistical parsers cognitively driven algorithms and evaluation measures </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>experimental setup.
</prevsent>
<prevsent>we used bikels reimplemen tation of collins?
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
parsing model 2 (bikel, 2004).<papid> J04-4004 </papid></citsent>
<aftsection>
<nextsent>sections 02-21 and 23 of the wsj were stripped from their annotation.
</nextsent>
<nextsent>sections 2-21 (39832 sentences, about 800k constituents) were used for training, section 23 (2416 sentences) for testing.
</nextsent>
<nextsent>no development set was used.
</nextsent>
<nextsent>we used the gold standard pos tags in two cases: in the test section (23) in all experiments, and in sections 02-21 in the cbs method when these sections are to be parsed in the process of vector creation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1619">
<title id=" W09-1211.xml">exploring multilingual semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inspite of these difficulties and resource limitations, we are proud to be among the 21 teams who successfully submitted the results1.
</prevsent>
<prevsent>as new participant, our goals in attending the conll-2009 srlonly shared task were to gain more thorough knowledge of this line of research and its state-of-the-art, and to explore how well system quickly assembled with existing packages can fare at this hard semantic analysis problem.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
following the successful approaches taken by the participants of the conll-2008 shared task (surdeanu et al, 2008) <papid> W08-2121 </papid>on monolingual syntactic and semantic dependency analysis, we designed and implemented our conll-2009 srlonly system with pipeline architecture.</citsent>
<aftsection>
<nextsent>two main components are cascaded in this system: one is for disambiguating predicate word sense 2 , and the other for identifying and classifying arguments for 1 according to our correspondence with dr. jan haji?, totally 31 teams among 60 registered ones signed and got the evaluation data.
</nextsent>
<nextsent>2 as predicate words are marked in the conll-2009 datasets, we dont need to identify predicate words.
</nextsent>
<nextsent>73 predicate words.
</nextsent>
<nextsent>different supervised learning techniques are utilized in these two components.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1620">
<title id=" W09-1211.xml">exploring multilingual semantic role labeling </title>
<section> predicate word sense disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>and removing the invalid attribute of ?*?; c. [lemma | pos] bi-grams of predicate word and its [previous | following] one word; d. [lemma | pos] tri-grams of predicate word and its [previous | following] two words; e. [lemma | (lemma with pos)] of its most [left | right] child; f. [(lemma+dependency_relation+lemma) | (pos +dependency_relation+pos)] of predicate word and its most [left | right] child; 3 we referred to those conll-2008 participants?
</prevsent>
<prevsent>reports, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W08-2138 ">
(ciaramita et al, 2008), <papid> W08-2138 </papid>when we designed the feature sets for the two components.</citsent>
<aftsection>
<nextsent>75g.
</nextsent>
<nextsent>[lemma | (lemma with pos)] of the head of the predicate word; h. [(lemma+dependency_relation+lemma) | (pos+d ependency_relation+pos)] of predicate word and its head; i. [lemma | (lemma with pos)] of its [previous | fol lowing] two brothers; j. [lemma | pos | (dependency relation)] bi-gram of predicate word and its [previous | following] one brother; k. [lemma | pos | (dependency relation)] tri-gram of predicate word and its [previous | following] two brothers.
</nextsent>
<nextsent>tion the second component of our system is used to detect and classify arguments with respect to predicate word.
</nextsent>
<nextsent>we take joint solution rather than solve the problem in two consecutive steps: argument identification and argument classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1622">
<title id=" W09-0714.xml">exploiting cross linguistic similarities in zulu and xhosa computational morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the few bantu languages for which computational morphological analysers have been fully developed so far is swahili (hur skainen, 1992; de pauw and de schryver, 2008).
</prevsent>
<prevsent>a computational morphological analyser prototype for zulu (zulmorph) is in an advanced stage of development, the results of which have already been used in other applications.
</prevsent>
</prevsection>
<citsent citstr=" L08-1537 ">
preliminary experiments and results towards obtaining morphological analysers for xhosa, swati and ndebele by bootstrapping zulmorph were particularly encouraging (bosch et al, 2008).<papid> L08-1537 </papid></citsent>
<aftsection>
<nextsent>this bootstrapping process may be briefly summarised as sequence of steps in which the baseline analyser, zulmorph, is applied to the new language (in this case xhosa) and then systematically extended to include the morphology of the other language.
</nextsent>
<nextsent>the extensions concern the word root lexicon, followed by the grammatical morpheme lexicons and finally by the appropriate morpho phonological rules.
</nextsent>
<nextsent>the guiding principle in this process is as follows: use the zulu morphological structure wherever applicable and only extend the analyser to accommodate differences between the source language (zulu) and the target language (in this case xhosa).
</nextsent>
<nextsent>so far the question as to whether the boot strapped analyser, extended to include xhosa morphology, could also improve the coverage of the zulu analyser was not specifically addressed in bosch et al.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1623">
<title id=" W09-0308.xml">instance driven discovery of onto logical relation labels </title>
<section> data preparation.  </section>
<citcontext>
<prevsection>
<prevsent>relation discovery between terms (instantiations of different onto logical classes) that have page in wikipedia is best performed after establishing if sufficiently strong relation between the two terms under consideration actually exists.
</prevsent>
<prevsent>to do this, the semantic relatedness of those two termsor concepts needs to be computed first.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
semantic relatedness can denote every possible relation between two concepts, unlike semantic similarity, which typically denotes only certain hierarchical relations (like hypernymy and synonymy) and is often computed using hierarchical networks like wordnet (budanitsky and hirst, 2006).<papid> J06-1003 </papid>a simple and effective way of computing semantic relatedness between two concepts c1 and c2 is measuring their distance in semantic network.</citsent>
<aftsection>
<nextsent>this results in semantic distance metric, which can be in versed to yield semantic relatedness metric.
</nextsent>
<nextsent>computing the path-length between terms c1 and c2 can be done using formula 1 where is the set of paths connecting c1 to c2 and np is the number of nodes in path p. 1the double brackets indicate wikilinks 63 relpath(c1, c2) = argmaxpp 1 np (1)we search for shortest paths in semantic network that is constructed by mapping the concepts in wikipedia to nodes, and the links between the concepts to edges.
</nextsent>
<nextsent>this generates very large network (millions of nodes and tens of millions of edges), but due to the fact that wikipedia isscale-free (barabasi and albert, 1999) (its connectedness degree distribution follows power law), paths stay relatively short.
</nextsent>
<nextsent>by indexing both incoming and outgoing links, bidirectional breadth-first search can be used to find shortest paths between concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1624">
<title id=" W09-0308.xml">instance driven discovery of onto logical relation labels </title>
<section> extracting relations from wikipedia.  </section>
<citcontext>
<prevsection>
<prevsent>genus?
</prevsent>
<prevsent>and genus?
</prevsent>
</prevsection>
<citsent citstr=" W99-0707 ">
country?.subsequently, the selected sentences are pos tagged and parsed using the memory based shallow parser (daelemans et al, 1999).<papid> W99-0707 </papid></citsent>
<aftsection>
<nextsent>this parser provides token isation, pos-tagging, chunking,and grammatical relations such as subject and direct object between verbs and phrases, and isbased on memory-based classification as implemented in timbl (daelemans et al, 2004).
</nextsent>
<nextsent>the five most frequently recurring phrases that occur 64 between the column pairs, where the subject of the sentence is value from one of the two columns, are presented to the human annotators.
</nextsent>
<nextsent>the cut-off of five was chosen to prevent the annotators from having to evaluate too many relations and to only present those that occur more often, and are hence less likely to be misses.
</nextsent>
<nextsent>misses can for instance be induced by ambiguous person names that also accidentally match location names (e.g., dakota).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1625">
<title id=" W09-1802.xml">a scalable global model for summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, sentence selection represents reasonable trade-off between linguistic quality, guaranteed by longer textual units, and summary content, often improved with shorter units.
</prevsent>
<prevsent>whereas the majority of approaches employ greedy search to find set of sentences that is 1tac is continuation of duc, which ran from 2001-2007.
</prevsent>
</prevsection>
<citsent citstr=" W00-0405 ">
both relevant and non-redundant (goldstein et al,2000; <papid> W00-0405 </papid>nenkova and vanderwende, 2005), some recent work focuses on improved search (mcdonald, 2007; yih et al, 2007).</citsent>
<aftsection>
<nextsent>among them, mcdonald isthe first to consider non-approximated maximization of an objective function through integer linear programming (ilp), which improves on greedy search by 4-12%.
</nextsent>
<nextsent>his formulation assumes that the quality of summary is proportional to the sum ofthe relevance scores of the selected sentences, penalized by the sum of the redundancy scores of all pairs of selected sentences.
</nextsent>
<nextsent>under maximum summary length constraint, this problem can be expressed as quadratic knapsack (gallo et al, 1980) and many methods are available to solve it (pisinger et al, 2005).
</nextsent>
<nextsent>however, mcdonald reports that the method is not scalable above 100 input sentences and discusses more practical approximations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1627">
<title id=" W09-1802.xml">a scalable global model for summarization </title>
<section> performance.  </section>
<citcontext>
<prevsection>
<prevsent>split text into sentences.
</prevsent>
<prevsent>we use the unsuper-.
</prevsent>
</prevsection>
<citsent citstr=" J06-4003 ">
vised punkt system (kiss and strunk, 2006).<papid> J06-4003 </papid></citsent>
<aftsection>
<nextsent>3.
</nextsent>
<nextsent>prune sentences shorter than 5 words..
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>compute parameters needed by the models..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1628">
<title id=" W09-1802.xml">a scalable global model for summarization </title>
<section> performance.  </section>
<citcontext>
<prevsection>
<prevsent>data here averaged over all problems in duc 2007.
</prevsent>
<prevsent>the summaries produced by the two systems have been evaluated automatically with rouge and manually with the pyramid metric.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
in particular, rouge-2 is the recall in bigrams with set of human-written abs tractive summaries (lin, 2004).<papid> W04-1013 </papid></citsent>
<aftsection>
<nextsent>the pyramid score arises from manual alignment of basic facts from the reference summaries, called summary content units (scus), in hypothesis summary (nenkova and passonneau, 2004).
</nextsent>
<nextsent>we used the scus provided by the tac evaluation.table 2 compares these results, alongside baseline that uses the first 100 words of the most recent document.
</nextsent>
<nextsent>all the scores are significantly different, showing that according to both hum anand automatic content evaluation, the concept based model outperforms mcdonalds sentence based model, which in turn outperforms the baseline.
</nextsent>
<nextsent>of course, the relevance and redundancy functions used for mcdonalds formulation in this experiment are rather primitive, and results would likely improve with better relevance features as used in many tac systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1629">
<title id=" W09-1802.xml">a scalable global model for summarization </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>however, since the ilp gives optimal solutions so quickly, we are more interested in discriminative training where we learn weights for features that push the resulting summaries in the right direction, as opposed to the individual concept values.
</prevsent>
<prevsent>third, our rule-based sentence compression ismore of proof of concept, showing that joint compression and optimal selection is feasible.
</prevsent>
</prevsection>
<citsent citstr=" E06-1038 ">
better statistical methods have been developed for producing high quality compression candidates (mcdonald, 2006), <papid> E06-1038 </papid>that maintain linguistic quality, some recent work even uses ilps for exact inference (clarkeand lapata, 2008).</citsent>
<aftsection>
<nextsent>the addition of compressed sentences tends to yield less coherent summaries, making sentence ordering more important.
</nextsent>
<nextsent>we would like to add constraints on sentence ordering to the ilp formulation to address this issue.
</nextsent>
<nextsent>acknowledgments this work is supported by the defense advanced research projects agency (darpa) gale project,under contract no.
</nextsent>
<nextsent>hr0011-06-c-0023.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1630">
<title id=" W09-0703.xml">information structure in african languages corpora and tools </title>
<section> annis ? the linguistic database of.  </section>
<citcontext>
<prevsection>
<prevsent>the types of annotations handled by annis include, among others, flat, layer-based annotations (e.g., for glossing) and hierarchical trees (e.g., syntax).
</prevsent>
<prevsent>source data.
</prevsent>
</prevsection>
<citsent citstr=" W00-1434 ">
as an architecture designed to facilitate diverse and integrative research on is, annis can import formats from broad variety of tools from nlp and manual annotation, the latter including exmaralda (schmidt, 2004), annotate (brants and plaehn, 2000), synpathy (www.lat-mpi.eu/tools/synpathy/), mmax2 (mller and strube, 2006), rsttool (o donnell, 2000), <papid> W00-1434 </papid>palinka (orasan, 2003), toolbox (busemann &amp; busemann, 2008) etc. these tools allow researchers to annotate data for syntax, semantics, morphology, prosody, phone tics, referentiality, lexis and much more, as their research questions require.</citsent>
<aftsection>
<nextsent>all annotated data are merged together via general interchange format paula (dipper 2005, dipper &amp; gtze 2005), highly expressive standoff xml format that specifically allows further annotation levels to be added at later time without disrupting the structure of existing annotations.
</nextsent>
<nextsent>paula, then, is the native format of annis.
</nextsent>
<nextsent>backend.
</nextsent>
<nextsent>the annis server uses relational database that offers many advantages including full unicode support and regular expression searches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1631">
<title id=" W09-0904.xml">another look at indirect negative evidence </title>
<section> probabilistic learning.  </section>
<citcontext>
<prevsection>
<prevsent>these correspond to violation of the identically?
</prevsent>
<prevsent>part of the iid assumption: the distribution will change in time.the question is whether it is legitimate to neglect these issues in order to get some mathematical insight: do these ideal ising assumptions critically affect learnability?
</prevsent>
</prevsection>
<citsent citstr=" C04-1013 ">
all of the computational work that we are aware of makes these assumptions, whether in nativist paradigm, (niyogi and berwick, 2000; sakas and fodor, 2001; yang, 2002) or an empiricist one (clark and thollard, 2004).<papid> C04-1013 </papid></citsent>
<aftsection>
<nextsent>we do need to make some assumptions,otherwise even learning the class of observed natural languages would be too hard.
</nextsent>
<nextsent>the minimal assumptions if we wish to allow any learn ability under stochastic presentation are that the process generating the data is stationary and mixing.
</nextsent>
<nextsent>all we need is for the law of large numbers to hold,and for there to be rapid convergence of the observed frequency to the expectation.
</nextsent>
<nextsent>we can get this easily with the iid assumption, or with bitmore work using ergodic theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1633">
<title id=" W08-2132.xml">a pipeline approach for syntactic and semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the relative preference of the attachment is modeled by one-on-one match in the tournament.
</prevsent>
<prevsent>iwatate et al (iwatate et al, 2008)initially proposed the method for japanese dependency parsing, and we applied it to other languages by relaxing some constraints (section 2.1).
</prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
dependency label classification is performed by linear chain sequential labeling on the dependency siblings like mcdonalds schemata (mcdonald et al,2006).<papid> W06-2932 </papid></citsent>
<aftsection>
<nextsent>we use an online passive-aggressive algorithm (crammer et al, 2006) for linear-chain sequential labeling (section 2.2).
</nextsent>
<nextsent>we also use the other linear-chain sequential labeling method to annotate whether each word is predicate or not (section 2.3).
</nextsent>
<nextsent>if an identified predicate has more than one sense, nearest neighbour classifier disambiguates the word sense candidates (section2.4).
</nextsent>
<nextsent>we use an online passive-aggressive algorithm again for the semantic role labeling (section2.5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1636">
<title id=" W08-2132.xml">a pipeline approach for syntactic and semantic dependency parsing </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>for this reason, we usepropbank/nombank semantic frames for semantic role pruning.
</prevsent>
<prevsent>suppose semantic roles in these mantic frame are i = {a0, a1, a2, a3}.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
since obligatory arguments are {a0...aa}, the remaining arguments {a4, a5, aa} are removed from label candidates.for verb predicates, the features used in our system are based on (hacioglu, 2004).<papid> C04-1186 </papid></citsent>
<aftsection>
<nextsent>we also employed some other features proposed in (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2004<papid> N04-1030 </papid>b).</nextsent>
<nextsent>for noun predicates, the features are primarily based on (pradhan et al, 2004<papid> N04-1030 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1637">
<title id=" W08-2132.xml">a pipeline approach for syntactic and semantic dependency parsing </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>suppose semantic roles in these mantic frame are i = {a0, a1, a2, a3}.
</prevsent>
<prevsent>since obligatory arguments are {a0...aa}, the remaining arguments {a4, a5, aa} are removed from label candidates.for verb predicates, the features used in our system are based on (hacioglu, 2004).<papid> C04-1186 </papid></prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
we also employed some other features proposed in (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2004<papid> N04-1030 </papid>b).</citsent>
<aftsection>
<nextsent>for noun predicates, the features are primarily based on (pradhan et al, 2004<papid> N04-1030 </papid>a).</nextsent>
<nextsent>the features that we defined for semantic role labeling are as follows: word features: split lemma and ppos of the predicate, dependent and dependents head, and its conjunctions.dependency label: the dependency label between the argument candidate and the its head.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1638">
<title id=" W08-2132.xml">a pipeline approach for syntactic and semantic dependency parsing </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>suppose semantic roles in these mantic frame are i = {a0, a1, a2, a3}.
</prevsent>
<prevsent>since obligatory arguments are {a0...aa}, the remaining arguments {a4, a5, aa} are removed from label candidates.for verb predicates, the features used in our system are based on (hacioglu, 2004).<papid> C04-1186 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
we also employed some other features proposed in (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2004<papid> N04-1030 </papid>b).</citsent>
<aftsection>
<nextsent>for noun predicates, the features are primarily based on (pradhan et al, 2004<papid> N04-1030 </papid>a).</nextsent>
<nextsent>the features that we defined for semantic role labeling are as follows: word features: split lemma and ppos of the predicate, dependent and dependents head, and its conjunctions.dependency label: the dependency label between the argument candidate and the its head.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1642">
<title id=" W09-1410.xml">biomedical event annotation with crfs and precision grammars </title>
<section> development experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the substantially poorer performance when using our own annotations for the in put events is discussed in more detail in section 4.2 one area where we could improve is to go after the 30% of sentences for which we do not have as panning parse and resultant rmrs.
</prevsent>
<prevsent>to reuse existing infrastructure, we could produce rmrs out put from an alternative processing component with broader coverage but less precision.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
several methods exist to do this ? e.g. producing rmrs out put from rasp (briscoe et al, 2006) <papid> P06-4020 </papid>is described infrank (2004).<papid> C04-1185 </papid></citsent>
<aftsection>
<nextsent>however there is clearly room for improvement in the remaining 70% of sentences which we can parse ? our results in table 4 are still well below the limit of roughly 70% recall.3 additional lexical resources beyond wordnet, particularly domain-specific ones, are likely to be useful in boosting performance since they will help maximally utilise the training data.
</nextsent>
<nextsent>additionally,we have not yet made use of other event annotations apart from the trigger words ? features basedon characteristics such as the event class or properties of the event arguments could also be useful.
</nextsent>
<nextsent>3we have not performed any analysis to verify whether the number of events per sentence differs between parse able and unparseable sentences.
</nextsent>
<nextsent>82 system rec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1643">
<title id=" W09-1410.xml">biomedical event annotation with crfs and precision grammars </title>
<section> development experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the substantially poorer performance when using our own annotations for the in put events is discussed in more detail in section 4.2 one area where we could improve is to go after the 30% of sentences for which we do not have as panning parse and resultant rmrs.
</prevsent>
<prevsent>to reuse existing infrastructure, we could produce rmrs out put from an alternative processing component with broader coverage but less precision.
</prevsent>
</prevsection>
<citsent citstr=" C04-1185 ">
several methods exist to do this ? e.g. producing rmrs out put from rasp (briscoe et al, 2006) <papid> P06-4020 </papid>is described infrank (2004).<papid> C04-1185 </papid></citsent>
<aftsection>
<nextsent>however there is clearly room for improvement in the remaining 70% of sentences which we can parse ? our results in table 4 are still well below the limit of roughly 70% recall.3 additional lexical resources beyond wordnet, particularly domain-specific ones, are likely to be useful in boosting performance since they will help maximally utilise the training data.
</nextsent>
<nextsent>additionally,we have not yet made use of other event annotations apart from the trigger words ? features basedon characteristics such as the event class or properties of the event arguments could also be useful.
</nextsent>
<nextsent>3we have not performed any analysis to verify whether the number of events per sentence differs between parse able and unparseable sentences.
</nextsent>
<nextsent>82 system rec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1644">
<title id=" W09-0304.xml">evaluating the pairwise string alignment of pronunciations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the focus on the aggregate distance of 100 or so word 26 pairs effectively hides many differences between methods.
</prevsent>
<prevsent>for example, heeringa et al (2006) find no significant differences in the degrees to which several pairwise string distance measures correlate with perceptual distances when examined at an aggregate level.
</prevsent>
</prevsection>
<citsent citstr=" W07-1307 ">
wieling et al (2007) <papid> W07-1307 </papid>and wieling and nerbonne (2007) also report almost no difference between different psa algorithms at the aggregate level.</citsent>
<aftsection>
<nextsent>it is important to be able to evaluate the different techniques more sensitively, which is why this paper examines alignment quality at the segment level.
</nextsent>
<nextsent>kondrak (2003) applies psa algorithm toalign words in different languages in order to detect cognates automatically.
</nextsent>
<nextsent>exceptionally, he does provide an evaluation of the string alignments generated by different algorithms.
</nextsent>
<nextsent>but he restricts his examination to set of only 82 gold standard pairwise alignments and he only distinguishes correct and incorrect alignments and does not look at misaligned phones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1646">
<title id=" W09-0304.xml">evaluating the pairwise string alignment of pronunciations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but he restricts his examination to set of only 82 gold standard pairwise alignments and he only distinguishes correct and incorrect alignments and does not look at misaligned phones.
</prevsent>
<prevsent>in the current study we introduce and evaluate several alignment algorithms more extensively at the alignment level.
</prevsent>
</prevsection>
<citsent citstr=" E95-1009 ">
the algorithms we evaluate include the levenshtein algorithm (with sylla bic ity constraint), which is one of the most popular alignment methods and has successfully been usedin determining pronunciation differences in phonetic strings (kessler, 1995; <papid> E95-1009 </papid>heeringa, 2004).</citsent>
<aftsection>
<nextsent>in addition we look at two adaptations of the lev enshtein algorithm.
</nextsent>
<nextsent>the first adaptation includes the swap-operation (wagner and low rance, 1975),while the second adaptation includes phonetic segment distances, which are generated by applying an iterative pointwise mutual information (pmi) procedure (church and hanks, 1990).<papid> J90-1003 </papid></nextsent>
<nextsent>finally we include alignments generated with the pair hidden markov model (phmm) as introduced to language studies by mackay and kondrak (2005).<papid> W05-0606 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1647">
<title id=" W09-0304.xml">evaluating the pairwise string alignment of pronunciations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithms we evaluate include the levenshtein algorithm (with sylla bic ity constraint), which is one of the most popular alignment methods and has successfully been usedin determining pronunciation differences in phonetic strings (kessler, 1995; <papid> E95-1009 </papid>heeringa, 2004).</prevsent>
<prevsent>in addition we look at two adaptations of the lev enshtein algorithm.</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
the first adaptation includes the swap-operation (wagner and low rance, 1975),while the second adaptation includes phonetic segment distances, which are generated by applying an iterative pointwise mutual information (pmi) procedure (church and hanks, 1990).<papid> J90-1003 </papid></citsent>
<aftsection>
<nextsent>finally we include alignments generated with the pair hidden markov model (phmm) as introduced to language studies by mackay and kondrak (2005).<papid> W05-0606 </papid></nextsent>
<nextsent>they reported that the pair hidden markov model outperformed aline, the best performing algorithm at the alignment level in the aforementioned study of kondrak (2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1648">
<title id=" W09-0304.xml">evaluating the pairwise string alignment of pronunciations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition we look at two adaptations of the lev enshtein algorithm.
</prevsent>
<prevsent>the first adaptation includes the swap-operation (wagner and low rance, 1975),while the second adaptation includes phonetic segment distances, which are generated by applying an iterative pointwise mutual information (pmi) procedure (church and hanks, 1990).<papid> J90-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0606 ">
finally we include alignments generated with the pair hidden markov model (phmm) as introduced to language studies by mackay and kondrak (2005).<papid> W05-0606 </papid></citsent>
<aftsection>
<nextsent>they reported that the pair hidden markov model outperformed aline, the best performing algorithm at the alignment level in the aforementioned study of kondrak (2003).
</nextsent>
<nextsent>the phmm has also successfully been used in dialectology by wieling et al (2007).<papid> W07-1307 </papid></nextsent>
<nextsent>the dataset used in this study consists of 152 words collected from 197 sites equally distribute dover bulgaria.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1662">
<title id=" W09-1204.xml">hybrid multilingual parsing with hpsg for srl </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>performance.
</prevsent>
<prevsent>this makes the task nice testbed forthe cross-fertilization of various language processing techniques.
</prevsent>
</prevsection>
<citsent citstr=" W08-2126 ">
as an example of such work, zhang et al (2008) <papid> W08-2126 </papid>have shown in the past that deep linguistic parsing outputs can be integrated to help improve the performance of the english semantic role labeling task.</citsent>
<aftsection>
<nextsent>but several questions remain unanswered.
</nextsent>
<nextsent>first, the integration only experimented with the semantic role labeling part of the task.
</nextsent>
<nextsent>it is not clear whether syntactic dependency parsing can also benefit from grammar-based parsing results.
</nextsent>
<nextsent>second, the english grammar used to achieve the improvement is one of the largest and most mature hand-crafted linguisticgrammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1672">
<title id=" W09-1204.xml">hybrid multilingual parsing with hpsg for srl </title>
<section> hpsg parsing for the conll data.  </section>
<citcontext>
<prevsection>
<prevsent>semantics indelph-in is cast in the minimal recur sion semantics framework (mrs; copestake, flickinger, pollard, &amp; sag, 2005), essentially predicate ? argument structures with provision for underspecified scopal relations.
</prevsent>
<prevsent>for the 2009 open?
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
task, we used the delph-in grammars for english (erg; flickinger, 2000), german (gg; crysmann, 2005), japanese (jacy; siegel &amp; bender, 2002), <papid> W02-1210 </papid>and spanish (srg; marimon, bel, &amp; seghezzi, 2007).</citsent>
<aftsection>
<nextsent>the grammars vary in their stage of development: the erg comprises some 15 years of continuous development, whereas work on the srg only started about five years ago, with gg and jacy ranging somewhere inbetween.
</nextsent>
<nextsent>3.1 overall setup.
</nextsent>
<nextsent>we applied the delph-in grammars to the conll data using the pet parser (callmeier, 2002) running 1see http://www.delph-in.net for background.
</nextsent>
<nextsent>it through the [incr tsdb()] environment (oepen &amp; carroll, 2000), for parallel ization and distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1673">
<title id=" W09-1204.xml">hybrid multilingual parsing with hpsg for srl </title>
<section> hpsg parsing for the conll data.  </section>
<citcontext>
<prevsection>
<prevsent>thus, string like dont you!
</prevsent>
<prevsent>in the conll data is tokenized as the four-elementsequence do, nt, you, !?,2 whereas the erg analysis has only two leaf nodes: dont, you!?.
</prevsent>
</prevsection>
<citsent citstr=" L08-1024 ">
fortunately, the delph-in tool chain recently incorporated mechanism called chart mapping (adolphs et al, 2008), <papid> L08-1024 </papid>which allows one to map flexibly from external?</citsent>
<aftsection>
<nextsent>input to grammar-internal assumptions, while keeping track of external token identities and their contributions to the final analysis.
</nextsent>
<nextsent>the february 2009 release of the erg already had this machinery in place (with the goal of supporting extant, ptb-trained pos taggers in pre-processing input to the deep parser), and we found that only tiny number of additional chart mapping rules was required to fix up?
</nextsent>
<nextsent>conll-specific deviations fromthe ptb tradition.
</nextsent>
<nextsent>with the help of the original developers, we created new chart mapping configurations for the german and japanese grammars (with 17 and 16 such accomodation rules, respectively) ina similar spirit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1677">
<title id=" W09-1204.xml">hybrid multilingual parsing with hpsg for srl </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>argument identification, argument classification and predicate classification are the three sub-components in the pipeline.
</prevsent>
<prevsent>all of them are maxent-based classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
for parameter estimation, we use the open source tadm system (malouf, 2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>the active features used in various steps of srlare fine tuned separately for different languages using development datasets.
</nextsent>
<nextsent>the significance of feature types varies across languages and datasets.
</nextsent>
<nextsent>34 ca zh cs en de ja es sy closed 82.67 73.63 75.58 87.90 84.57 91.47 82.69ood - - 71.29 81.50 75.06 - sr closed 67.34 73.20 78.28 77.85 62.95 64.71 67.81ood - - 77.78 67.07 54.87 - open - - - 78.13 (0.28) 64.31 (1.36) 65.95 (1.24) 68.24 (0.43)ood - - - 68.11 (1.04) 58.42 (3.55) - table 2: summary of system performance on multiple language sin the open challenge, two groups of extra features from hpsg parsing outputs, as described in section 3.3, were used on languages for which we have hpsg grammars, that is english, german, japanese, and spanish.
</nextsent>
<nextsent>the evaluation results of the submitted system are summarized in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1683">
<title id=" W09-0429.xml">edinburghs submission to all tracks of the wmt 2009 shared task with reordering and speed improvements to moses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the commitment of the university of edinburgh tothe wmt shared tasks is to provide strong statistical machine translation baseline with our open source tools for all language pairs.
</prevsent>
<prevsent>we are again the only institution that participated in all tracks.the shared task is also an opportunity to incorporate novel contributions and test them against the best machine translation systems for these language pairs.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
in this paper we describe the speed improvements to the moses decoder (koehn et al,2007), <papid> P07-2045 </papid>as well as novel framework to specify reordering constraints with xml markup, which we tested with punctuation-based constraints.</citsent>
<aftsection>
<nextsent>we trained default moses system with the following non-default settings: ? maximum sentence length 80 ? grow-diag-final-and symmetrization of giza++ alignments ? interpolated kneser-ney discounted 5-gram language model ? msd-bidrectional-fe lexicalized reordering language ep nc news intpl.
</nextsent>
<nextsent>english 449 486 216 192 french 264 311 147 131 german 785 821 449 402 spanish 341 392 219 190 czech *:1475 1615 752 690 hungarian hung:2148 815 786 table 1: perplexity (ppl) of the domain-trained (ep= europarl (czeng for czech), nc = news commentary, news = news) and interpolated language models.
</nextsent>
<nextsent>2.1 domain adaptation.
</nextsent>
<nextsent>in contrast to last years task, where news translation was presented as true out-of-domain problem, this year large monolingual news corpora and tuning set (last years test set) were provided.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1684">
<title id=" W09-0429.xml">edinburghs submission to all tracks of the wmt 2009 shared task with reordering and speed improvements to moses </title>
<section> system configuration.  </section>
<citcontext>
<prevsection>
<prevsent>we see significant gains with the addition of news data to the language model (about 2 bleu points) and using true casing (about 0.51.0bleu points), and minor if any gains using minimum bayes risk decoding (mbr), the monotoneat-punctuation reordering constraint (mp, see section 3.2), and bigger beam sizes.
</prevsent>
<prevsent>2.4 germanenglish.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
for german english, we additionally incorpo ratedrule-based reordering ? we parse the input using the collins parser (collins, 1997) <papid> P97-1003 </papid>and apply set of reordering rules to re-arrange the german sentence so that it corresponds more closely english word order (collins et al, 2005).<papid> P05-1066 </papid>compound splitting ? we split german compound words (mostly nouns), based on the frequency of the words in the potential de compositions (koehn and knight, 2003<papid> P03-1040 </papid>a).part-of-speech language model ? we use factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>to also output part-of-speech tags with each word in single phrase mapping and runa second n-gram model over them.</citsent>
<aftsection>
<nextsent>the en german english bleu (ued08: 17.1, best08: 19.7) (uncased) baseline 16.6 + interpolated news lm 20.6 + minimum bayes risk decoding 20.6 + monotone at punctuation 20.9 + true casing 20.9 + rule-based reordering 21.7 + compound splitting 22.0 + part-of-speech lm 22.1 + big beam 22.3table 3: results for german english with the incremental addition of methods beyond baseline trained on the parallel corpus english german bleu (ued08: 12.1, best08: 14.2) (uncased) baseline 13.5 + interpolated news lm 15.2 + minimum bayes risk decoding 15.2 + monotone at punctuation 15.2 + true casing 15.2 + morphological lm 15.2 + big beam 15.7table 4: results for english german with the incremental addition of methods beyiond baseline trained on the parallel corpus glish part-of-speech tags are obtained using mxpost (ratnaparkhi, 1996).
</nextsent>
<nextsent>2.5 english-german.
</nextsent>
<nextsent>for english german, we additionally incorporated morphological language model the same way we incorporated part-of-speech language model in the other translation direction.
</nextsent>
<nextsent>the morphological tags were obtained using lopar (schmidt and schulte im walde, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1685">
<title id=" W09-0429.xml">edinburghs submission to all tracks of the wmt 2009 shared task with reordering and speed improvements to moses </title>
<section> system configuration.  </section>
<citcontext>
<prevsection>
<prevsent>we see significant gains with the addition of news data to the language model (about 2 bleu points) and using true casing (about 0.51.0bleu points), and minor if any gains using minimum bayes risk decoding (mbr), the monotoneat-punctuation reordering constraint (mp, see section 3.2), and bigger beam sizes.
</prevsent>
<prevsent>2.4 germanenglish.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
for german english, we additionally incorpo ratedrule-based reordering ? we parse the input using the collins parser (collins, 1997) <papid> P97-1003 </papid>and apply set of reordering rules to re-arrange the german sentence so that it corresponds more closely english word order (collins et al, 2005).<papid> P05-1066 </papid>compound splitting ? we split german compound words (mostly nouns), based on the frequency of the words in the potential de compositions (koehn and knight, 2003<papid> P03-1040 </papid>a).part-of-speech language model ? we use factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>to also output part-of-speech tags with each word in single phrase mapping and runa second n-gram model over them.</citsent>
<aftsection>
<nextsent>the en german english bleu (ued08: 17.1, best08: 19.7) (uncased) baseline 16.6 + interpolated news lm 20.6 + minimum bayes risk decoding 20.6 + monotone at punctuation 20.9 + true casing 20.9 + rule-based reordering 21.7 + compound splitting 22.0 + part-of-speech lm 22.1 + big beam 22.3table 3: results for german english with the incremental addition of methods beyond baseline trained on the parallel corpus english german bleu (ued08: 12.1, best08: 14.2) (uncased) baseline 13.5 + interpolated news lm 15.2 + minimum bayes risk decoding 15.2 + monotone at punctuation 15.2 + true casing 15.2 + morphological lm 15.2 + big beam 15.7table 4: results for english german with the incremental addition of methods beyiond baseline trained on the parallel corpus glish part-of-speech tags are obtained using mxpost (ratnaparkhi, 1996).
</nextsent>
<nextsent>2.5 english-german.
</nextsent>
<nextsent>for english german, we additionally incorporated morphological language model the same way we incorporated part-of-speech language model in the other translation direction.
</nextsent>
<nextsent>the morphological tags were obtained using lopar (schmidt and schulte im walde, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1686">
<title id=" W09-0429.xml">edinburghs submission to all tracks of the wmt 2009 shared task with reordering and speed improvements to moses </title>
<section> system configuration.  </section>
<citcontext>
<prevsection>
<prevsent>we see significant gains with the addition of news data to the language model (about 2 bleu points) and using true casing (about 0.51.0bleu points), and minor if any gains using minimum bayes risk decoding (mbr), the monotoneat-punctuation reordering constraint (mp, see section 3.2), and bigger beam sizes.
</prevsent>
<prevsent>2.4 germanenglish.
</prevsent>
</prevsection>
<citsent citstr=" P03-1040 ">
for german english, we additionally incorpo ratedrule-based reordering ? we parse the input using the collins parser (collins, 1997) <papid> P97-1003 </papid>and apply set of reordering rules to re-arrange the german sentence so that it corresponds more closely english word order (collins et al, 2005).<papid> P05-1066 </papid>compound splitting ? we split german compound words (mostly nouns), based on the frequency of the words in the potential de compositions (koehn and knight, 2003<papid> P03-1040 </papid>a).part-of-speech language model ? we use factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>to also output part-of-speech tags with each word in single phrase mapping and runa second n-gram model over them.</citsent>
<aftsection>
<nextsent>the en german english bleu (ued08: 17.1, best08: 19.7) (uncased) baseline 16.6 + interpolated news lm 20.6 + minimum bayes risk decoding 20.6 + monotone at punctuation 20.9 + true casing 20.9 + rule-based reordering 21.7 + compound splitting 22.0 + part-of-speech lm 22.1 + big beam 22.3table 3: results for german english with the incremental addition of methods beyond baseline trained on the parallel corpus english german bleu (ued08: 12.1, best08: 14.2) (uncased) baseline 13.5 + interpolated news lm 15.2 + minimum bayes risk decoding 15.2 + monotone at punctuation 15.2 + true casing 15.2 + morphological lm 15.2 + big beam 15.7table 4: results for english german with the incremental addition of methods beyiond baseline trained on the parallel corpus glish part-of-speech tags are obtained using mxpost (ratnaparkhi, 1996).
</nextsent>
<nextsent>2.5 english-german.
</nextsent>
<nextsent>for english german, we additionally incorporated morphological language model the same way we incorporated part-of-speech language model in the other translation direction.
</nextsent>
<nextsent>the morphological tags were obtained using lopar (schmidt and schulte im walde, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1688">
<title id=" W09-0429.xml">edinburghs submission to all tracks of the wmt 2009 shared task with reordering and speed improvements to moses </title>
<section> system configuration.  </section>
<citcontext>
<prevsection>
<prevsent>we see significant gains with the addition of news data to the language model (about 2 bleu points) and using true casing (about 0.51.0bleu points), and minor if any gains using minimum bayes risk decoding (mbr), the monotoneat-punctuation reordering constraint (mp, see section 3.2), and bigger beam sizes.
</prevsent>
<prevsent>2.4 germanenglish.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
for german english, we additionally incorpo ratedrule-based reordering ? we parse the input using the collins parser (collins, 1997) <papid> P97-1003 </papid>and apply set of reordering rules to re-arrange the german sentence so that it corresponds more closely english word order (collins et al, 2005).<papid> P05-1066 </papid>compound splitting ? we split german compound words (mostly nouns), based on the frequency of the words in the potential de compositions (koehn and knight, 2003<papid> P03-1040 </papid>a).part-of-speech language model ? we use factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>to also output part-of-speech tags with each word in single phrase mapping and runa second n-gram model over them.</citsent>
<aftsection>
<nextsent>the en german english bleu (ued08: 17.1, best08: 19.7) (uncased) baseline 16.6 + interpolated news lm 20.6 + minimum bayes risk decoding 20.6 + monotone at punctuation 20.9 + true casing 20.9 + rule-based reordering 21.7 + compound splitting 22.0 + part-of-speech lm 22.1 + big beam 22.3table 3: results for german english with the incremental addition of methods beyond baseline trained on the parallel corpus english german bleu (ued08: 12.1, best08: 14.2) (uncased) baseline 13.5 + interpolated news lm 15.2 + minimum bayes risk decoding 15.2 + monotone at punctuation 15.2 + true casing 15.2 + morphological lm 15.2 + big beam 15.7table 4: results for english german with the incremental addition of methods beyiond baseline trained on the parallel corpus glish part-of-speech tags are obtained using mxpost (ratnaparkhi, 1996).
</nextsent>
<nextsent>2.5 english-german.
</nextsent>
<nextsent>for english german, we additionally incorporated morphological language model the same way we incorporated part-of-speech language model in the other translation direction.
</nextsent>
<nextsent>the morphological tags were obtained using lopar (schmidt and schulte im walde, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1689">
<title id=" W09-0429.xml">edinburghs submission to all tracks of the wmt 2009 shared task with reordering and speed improvements to moses </title>
<section> recent improvements.  </section>
<citcontext>
<prevsection>
<prevsent>to mention just two data points in the german-english setting: stack size of 500 and early discarding threshold of 1.0 results in faster search (150ms/word) and better quality (73.5% search accuracy) than the default search setting of stack size 200 and no early discarding (252ms/word for 62.5% seach accuracy).
</prevsent>
<prevsent>accuracy is measured against the best translations found under any setting.
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
note that this early discarding is related to ideas behind cube pruning (huang and chiang, 2007),<papid> P07-1019 </papid>which generates the top most promising hypotheses, but in our method the decision not to generate hypotheses is guided by the quality of hypotheses on the result stack.</citsent>
<aftsection>
<nextsent>3.2 framework to specify reordering.
</nextsent>
<nextsent>constraints commonly in statistical machine translation, punctuation tokens are treated just like words.
</nextsent>
<nextsent>for tokens such as commas, many possible translations are collected and they may be translated into any of these choices or reordered if the language model sees gains.
</nextsent>
<nextsent>in fact, since the comma is one 162  &amp; $ % requiring the translation of quoted material as block: he said  zone    yes    /zone  . hard reordering constraint: number 1 :  wall/  the beginning . local hard reordering constraint within zone: new idea  zone  (  wall/  maybe not new  wall/  )  /zone  has come forward . nesting: the  zone    new  zone  ( old )  /zone     /zone  proposal . figure 2: framework to specify reordering constraints with zones and walls.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1692">
<title id=" W08-0907.xml">learner characteristics and feedback in tutorial dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems such as circsim (evens and michael 2006), beetle (zinn et al  2002), the geometry explanation tutor (aleven et al  2003), why2/atlas (vanlehn et al  2002), itspoke (litman et al  2006), scot (pon barry et al  2006), propl (lane and vanlehn 2005) and auto tutor (graesser et al  2003) support research that has begun to the see the emergence of core set of foundational requirements for mixed initiative natural language interaction that occurs in the kind of tutorial dialogue investigated here.
</prevsent>
<prevsent>moreover, recent years have witnessed the appearance of corpus studies empirically investigating speech acts in tutorial dialogue (marineau et al  2000), dialogues?
</prevsent>
</prevsection>
<citsent citstr=" E03-1072 ">
correlation with learning (forbes-riley et al  2005, core et al  2003, <papid> E03-1072 </papid>ros?</citsent>
<aftsection>
<nextsent>et al . 2003, katz et al  2003), student uncertainty in dialogue (liscombe et al  2005, forbes-riley and litman 2005), and comparing text-based and spoken dialogue (litman et al  2006).
</nextsent>
<nextsent>recent years have also seen the emergence of broader view of learning as complex process involving both cognitive and affective states.
</nextsent>
<nextsent>to empirically explore these issues, number of itss such as auto tutor (jackson et al  2007), bettys brain (tan and biswas 2006), itspoke (forbes riley et al  2005), m-ecolab (rebolledo-mendez et al  2006), and more (del soldato and boulay 1995) are being used as platforms to investigate the impact of tutorial interactions on affective and motivational outcomes (e.g., self-efficacy) along with purely cognitive measures (i.e., learning gains).
</nextsent>
<nextsent>a central problem in this line of investigation is iden 53 tifying tutorial strategies (e.g., graesser et al  1995) that can appropriately balance the tradeoffs between cognitive and affective student outcomes (lepper et al  1993).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1693">
<title id=" W08-0907.xml">learner characteristics and feedback in tutorial dialogue </title>
<section> corpus study.  </section>
<citcontext>
<prevsection>
<prevsent>while no single standardized dialogue act tag set has been identified for tutorial dialogue, the tags applied here were drawn from several schemes in the tutorial dialogue and broader dialogue literature.
</prevsent>
<prevsent>a coding scheme for tutorial dialogue in the domain of qualitative physics influenced the creation of the tag set (forbes-riley et al  2005), as did the four category scheme (marineau et al  2000).
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
a more expansive general dialogue act tag set al contributed commonly occurring acts (stolcke et al  2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>the motivational tags were drawn from work by lepper (1993) on motivational strategies of human tutors.
</nextsent>
<nextsent>table 1 displays the cognitive subset of this dialogue act tag set, while table 2 displays the mo tivational/affective tags.
</nextsent>
<nextsent>it should be noted that cognitive tag was required for each utterance, while motivational/affective tag was applied only to the subset of utterances that communicated in that channel.
</nextsent>
<nextsent>if an utterance constituted strictly motivational/affective act, its cognitive channel was tagged with ex (extra-domain) indicating there was no relevant cognitive content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1694">
<title id=" W09-1407.xml">high precision biological event extraction with a concept recognizer </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>freely mixing text liter als, semantically typed basal syntactic constituents, and semantically defined classes of entities.
</prevsent>
<prevsent>our approach is to take advantage of the high 50quality ontologies available in the biomedical domain to formally define entities, events, and constraints on slots within events and to develop patterns for how concepts can be expressed in text that take advantage of both semantic and linguistic characteristics of the text.
</prevsent>
</prevsection>
<citsent citstr=" W04-3101 ">
we manually built patterns for each event type by examining the training data and by using native speaker intuitions about likely ways of expressing relationships, similar to the technique described in (cohen et al, 2004).<papid> W04-3101 </papid></citsent>
<aftsection>
<nextsent>the patterns characterize the linguistic expression of that event and identify the arguments (participants) of the events according to (a) occurrence in relevant linguistic context and (b) satisfaction of appropriate semantic constraints, as defined by our ontology.
</nextsent>
<nextsent>our solution results in very high precision information extraction, although the current rule set has limited recall.
</nextsent>
<nextsent>3.1 the reference ontology.
</nextsent>
<nextsent>the central organizing structure of an opendmap project is an ontology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1695">
<title id=" W08-1008.xml">the page 2008 shared task on parsing german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, we provide an overview of the test results and first analysis.
</prevsent>
<prevsent>german is one of the very few languages for which more than one syntactically annotated resource exists.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
other languages for which this is the case include english (with the penn treebank (marcus et al., 1993), <papid> J93-2004 </papid>the susanne corpus (sampson, 1993), and the british section of the ice corpus (wallisand nelson, 2006)) and italian (with isst (mon tegmagni et al, 2000) and tut (bosco et al, 2000)).</citsent>
<aftsection>
<nextsent>the three german treebanks are negra (skut et al, 1998), tiger (brants et al, 2002), andtuba-d/z (hinrichs et al, 2004).
</nextsent>
<nextsent>we will concentrate on tiger and tuba-d/z here; negra is annotated with an annotation scheme very similar to tiger but is smaller.
</nextsent>
<nextsent>in contrast to other languages, these two treebanks are similar on many levels: both treebanks are based on newspaper text, bothuse the stts part of speech (pos) tagset (thie len and schiller, 1994), and both use an annotation am very grateful to gerald penn, who suggested this workshop and the shared task, took over the biggest part of the workshop organization and helped with the shared task.
</nextsent>
<nextsent>scheme based on constituent structure augmented with grammatical functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1696">
<title id=" W08-1008.xml">the page 2008 shared task on parsing german </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>part of speech labels were not considered in the evaluation.
</prevsent>
<prevsent>evaluation for the dependency version consisted of labeled and unlabeled attachment scores.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
for this evaluation, we used the scripts provided by the conll shared task 2007 on dependency parsing (nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>the two treebanks used for the shared task were the tiger corpus, (brants et al, 2002) version 2, and the tuba-d/z treebank (hinrichs et al, 2004; telljohann et al, 2006), version 3.
</nextsent>
<nextsent>both treebanks use german newspapers as their data source: the frankfurter rundschau newspaper for tiger and the die tageszeitung?
</nextsent>
<nextsent>(taz) newspaper for tuba-d/z. the average sentence length is very similar: in tiger, sentences have an average length of 17.0, and in tuba-d/z, 17.3.
</nextsent>
<nextsent>this can be regarded as an indication that the complexity of the two texts is comparable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1697">
<title id=" W09-0406.xml">cmu system combination for wmt09 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we combined restricted data track entries in french - english, german - english and hungarian - english using provided data only.
</prevsent>
<prevsent>for the combination of machine translation systems there have been two main approaches described in recent publications.
</prevsent>
</prevsection>
<citsent citstr=" W08-0329 ">
one uses confusion network decoding to combine translation systems as described in (rosti et al, 2008) <papid> W08-0329 </papid>and (karakos etal., 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>the other approach selects whole hypotheses from combined n-best list (hildebrand and vogel, 2008).
</nextsent>
<nextsent>our setup follows the approach described in (hildebrand and vogel, 2008).
</nextsent>
<nextsent>we combine the output from the available translation systems intoone joint n-best list, then calculate set of features consistently for all hypotheses.
</nextsent>
<nextsent>we use mer training on development set to determine feature weights and re-rank the joint n-best list.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1698">
<title id=" W09-0406.xml">cmu system combination for wmt09 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we combined restricted data track entries in french - english, german - english and hungarian - english using provided data only.
</prevsent>
<prevsent>for the combination of machine translation systems there have been two main approaches described in recent publications.
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
one uses confusion network decoding to combine translation systems as described in (rosti et al, 2008) <papid> W08-0329 </papid>and (karakos etal., 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>the other approach selects whole hypotheses from combined n-best list (hildebrand and vogel, 2008).
</nextsent>
<nextsent>our setup follows the approach described in (hildebrand and vogel, 2008).
</nextsent>
<nextsent>we combine the output from the available translation systems intoone joint n-best list, then calculate set of features consistently for all hypotheses.
</nextsent>
<nextsent>we use mer training on development set to determine feature weights and re-rank the joint n-best list.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1699">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many languages, especially on the african continent, are under-resourced in that they have very few computational linguistic tools or corpora (such as lexica, taggers, parsers or tree-banks) available.
</prevsent>
<prevsent>here, we will concentrate on the task of developing part-of-speech taggers for amharic, the official working language of the government of the federal democratic republic of ethiopia: ethiopia is divided into nine regions, each with its own nationality language; however, amharic is the language for country-wide communication.
</prevsent>
</prevsection>
<citsent citstr=" W05-0707 ">
amharic is spoken by about 30 million people as first or second language, making it the second most spoken semitic language in the world (after arabic), probably the second largest language in ethiopia (after oromo), and possibly one of the five largest languages on the african continent.the actual size of the amharic speaking population must be based on estimates: hudson (1999)analysed the ethiopian census from 1994 and indicated that more than 40% of the population then understood amharic, while the current size of the ethiopian population is about 80 million.1 182.5 million according to cia (2009); 76.9 according to ethiopian parliament projections in december 2008 based on the preliminary reports from the census of may 2007.in spite of the relatively large number of speakers, amharic is still language for which very few computational linguistic resources have been developed, and previous efforts to create language processing tools for amharice.g., alemayehu and willett (2002) and fissaha (2005)<papid> W05-0707 </papid>have been severely hampered by the lack of large-scale linguistic resources for the language.</citsent>
<aftsection>
<nextsent>in contrast, the work detailed in the present paper has been able to utilize the first publicly available medium-sized tagged amharic corpus, described in section 5.
</nextsent>
<nextsent>however, first the amharic language as such is introduced (in section 2), and then the task of part of-speech tagging and some previous work in the field is described (section 3).
</nextsent>
<nextsent>section 4 details the tagging strategies used in the experiments, there sults of which can be found in section 6 together with short discussion.
</nextsent>
<nextsent>finally, section 7 sums up the paper and points to ways in which we believe that the results can be improved in the future.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1700">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>most work on tagging has concentrated on english and on using supervised methods, in the sense that the taggers have been trained on an available, tagged corpus.
</prevsent>
<prevsent>both rule-based and statistical / machine-learning based approaches have been thoroughly investigated.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the brill tagger(brill, 1995) <papid> J95-4004 </papid>was fundamental in using combined rule- and learning-based strategy to achieve 96.6% accuracy on tagging the penn treebank version of the wall street journal corpus.</citsent>
<aftsection>
<nextsent>that is, to level which is just about what humans normally achieve when hand-tagging corpus, in terms of inter annotator agreement even though voutilainen (1999) <papid> E99-1027 </papid>has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases.</nextsent>
<nextsent>later taggers have managed to improve brills figures little bit, to just above 97% on the wall street journal corpus using hidden markov models, hmm and conditional random fields, crf; e.g., collins (2002) <papid> W02-1001 </papid>and toutanova et al (2003).<papid> N03-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1701">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>both rule-based and statistical / machine-learning based approaches have been thoroughly investigated.
</prevsent>
<prevsent>the brill tagger(brill, 1995) <papid> J95-4004 </papid>was fundamental in using combined rule- and learning-based strategy to achieve 96.6% accuracy on tagging the penn treebank version of the wall street journal corpus.</prevsent>
</prevsection>
<citsent citstr=" E99-1027 ">
that is, to level which is just about what humans normally achieve when hand-tagging corpus, in terms of inter annotator agreement even though voutilainen (1999) <papid> E99-1027 </papid>has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases.</citsent>
<aftsection>
<nextsent>later taggers have managed to improve brills figures little bit, to just above 97% on the wall street journal corpus using hidden markov models, hmm and conditional random fields, crf; e.g., collins (2002) <papid> W02-1001 </papid>and toutanova et al (2003).<papid> N03-1033 </papid></nextsent>
<nextsent>however, most recent work has concentrated on applying tagging strategies to other languages than english, on combining taggers, and/or on using unsupervised methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1702">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the brill tagger(brill, 1995) <papid> J95-4004 </papid>was fundamental in using combined rule- and learning-based strategy to achieve 96.6% accuracy on tagging the penn treebank version of the wall street journal corpus.</prevsent>
<prevsent>that is, to level which is just about what humans normally achieve when hand-tagging corpus, in terms of inter annotator agreement even though voutilainen (1999) <papid> E99-1027 </papid>has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
later taggers have managed to improve brills figures little bit, to just above 97% on the wall street journal corpus using hidden markov models, hmm and conditional random fields, crf; e.g., collins (2002) <papid> W02-1001 </papid>and toutanova et al (2003).<papid> N03-1033 </papid></citsent>
<aftsection>
<nextsent>however, most recent work has concentrated on applying tagging strategies to other languages than english, on combining taggers, and/or on using unsupervised methods.
</nextsent>
<nextsent>in this section we will look at these issues in more detail, in particular with the relation to languages similar to amharic.
</nextsent>
<nextsent>3.1 tagging semitic languages.
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>used support vector machine, svm-based tagger, trained on the arabic penn2other knowledge sources for processing amharic include, e.g., gassers verb stem finder (available from nlp.amharic.org) and word lists as those collected by gebremichael (www.cs.ru.nl/biniam/geez).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1703">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the brill tagger(brill, 1995) <papid> J95-4004 </papid>was fundamental in using combined rule- and learning-based strategy to achieve 96.6% accuracy on tagging the penn treebank version of the wall street journal corpus.</prevsent>
<prevsent>that is, to level which is just about what humans normally achieve when hand-tagging corpus, in terms of inter annotator agreement even though voutilainen (1999) <papid> E99-1027 </papid>has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases.</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
later taggers have managed to improve brills figures little bit, to just above 97% on the wall street journal corpus using hidden markov models, hmm and conditional random fields, crf; e.g., collins (2002) <papid> W02-1001 </papid>and toutanova et al (2003).<papid> N03-1033 </papid></citsent>
<aftsection>
<nextsent>however, most recent work has concentrated on applying tagging strategies to other languages than english, on combining taggers, and/or on using unsupervised methods.
</nextsent>
<nextsent>in this section we will look at these issues in more detail, in particular with the relation to languages similar to amharic.
</nextsent>
<nextsent>3.1 tagging semitic languages.
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>used support vector machine, svm-based tagger, trained on the arabic penn2other knowledge sources for processing amharic include, e.g., gassers verb stem finder (available from nlp.amharic.org) and word lists as those collected by gebremichael (www.cs.ru.nl/biniam/geez).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1704">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we will look at these issues in more detail, in particular with the relation to languages similar to amharic.
</prevsent>
<prevsent>3.1 tagging semitic languages.
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
diab et al (2004) <papid> N04-4038 </papid>used support vector machine, svm-based tagger, trained on the arabic penn2other knowledge sources for processing amharic include, e.g., gassers verb stem finder (available from nlp.amharic.org) and word lists as those collected by gebremichael (www.cs.ru.nl/biniam/geez).</citsent>
<aftsection>
<nextsent>105 treebank 1 to tokenize, pos tag, and annotate arabic base phrases.
</nextsent>
<nextsent>with an accuracy of 95.5%over set of 24 tags, the data-driven tagger performed on par with state-of-the-art results for english when trained on similar-sized data (168k tokens).
</nextsent>
<nextsent>bar-haim et al (2008) developed lexicon based hmm tagger for hebrew.
</nextsent>
<nextsent>they report 89.6% accuracy using 21 tags and training on 36k tokens of news text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1706">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 unsupervised tagging.
</prevsent>
<prevsent>the desire to use unsupervised machine learning approaches to tagging essentially originates from the wish to exploit the vast amounts of un labelled data available when constructing taggers.
</prevsent>
</prevsection>
<citsent citstr=" C04-1080 ">
the area is particularly vivid when it comes to the treatment of languages for which there exist few, if any, computational resources, and for the case of adapting an existing tagger to new language domain.banko and moore (2004) <papid> C04-1080 </papid>compared unsupervised hmm and transformation-based taggers trained on the same portions of the penn treebank, and showed that the quality of the lexicon used for training had high impact on the tagging results.duh and kirchhoff (2005) <papid> W05-0708 </papid>presented minimally supervised approach to tagging for dialectal arabic (colloquial egyptian), based on morphological analyzer for modern standard arabic and unlabeled texts in number of dialects.</citsent>
<aftsection>
<nextsent>using trigram hmm tagger, they first produced baseline system and then gradually improved on that in an unsupervised manner by adding features so as to facilitate the analysis of unknown words, and by constraining and refining the lexicon.
</nextsent>
<nextsent>unsupervised learning is often casted as the problem of finding (hidden) structure in unlabeled data.
</nextsent>
<nextsent>goldwater and griffiths (2007) <papid> P07-1094 </papid>noted that most recent approaches to this problem aim to identify the set of attributes that maximizes some target function (maximum likelihood estimation), and then to select the values of these attributes based on the representation of the model.</nextsent>
<nextsent>they proposed different approach, based on bayesian principles, which tries to directly maximize the probability of the attributes based on observation in the data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1707">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 unsupervised tagging.
</prevsent>
<prevsent>the desire to use unsupervised machine learning approaches to tagging essentially originates from the wish to exploit the vast amounts of un labelled data available when constructing taggers.
</prevsent>
</prevsection>
<citsent citstr=" W05-0708 ">
the area is particularly vivid when it comes to the treatment of languages for which there exist few, if any, computational resources, and for the case of adapting an existing tagger to new language domain.banko and moore (2004) <papid> C04-1080 </papid>compared unsupervised hmm and transformation-based taggers trained on the same portions of the penn treebank, and showed that the quality of the lexicon used for training had high impact on the tagging results.duh and kirchhoff (2005) <papid> W05-0708 </papid>presented minimally supervised approach to tagging for dialectal arabic (colloquial egyptian), based on morphological analyzer for modern standard arabic and unlabeled texts in number of dialects.</citsent>
<aftsection>
<nextsent>using trigram hmm tagger, they first produced baseline system and then gradually improved on that in an unsupervised manner by adding features so as to facilitate the analysis of unknown words, and by constraining and refining the lexicon.
</nextsent>
<nextsent>unsupervised learning is often casted as the problem of finding (hidden) structure in unlabeled data.
</nextsent>
<nextsent>goldwater and griffiths (2007) <papid> P07-1094 </papid>noted that most recent approaches to this problem aim to identify the set of attributes that maximizes some target function (maximum likelihood estimation), and then to select the values of these attributes based on the representation of the model.</nextsent>
<nextsent>they proposed different approach, based on bayesian principles, which tries to directly maximize the probability of the attributes based on observation in the data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1708">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>using trigram hmm tagger, they first produced baseline system and then gradually improved on that in an unsupervised manner by adding features so as to facilitate the analysis of unknown words, and by constraining and refining the lexicon.
</prevsent>
<prevsent>unsupervised learning is often casted as the problem of finding (hidden) structure in unlabeled data.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
goldwater and griffiths (2007) <papid> P07-1094 </papid>noted that most recent approaches to this problem aim to identify the set of attributes that maximizes some target function (maximum likelihood estimation), and then to select the values of these attributes based on the representation of the model.</citsent>
<aftsection>
<nextsent>they proposed different approach, based on bayesian principles, which tries to directly maximize the probability of the attributes based on observation in the data.
</nextsent>
<nextsent>this bayesian approach outperformed maximum likelihood estimation when training trigram hmm tagger for english.toutanova and johnson (2007) report state-of-the art results by extending the work on bayesian modelling for unsupervised learning of taggers both in the way that prior knowledge can be incorporated into the model, and in the way that possible tags forgiven word is explicitly modeled.
</nextsent>
<nextsent>3.3 combining taggers.
</nextsent>
<nextsent>a possible way to improve on pos tagging result sis to combine the output of several different taggers into committee, forming joint decisions regarding the labeling of the input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1709">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the weights of the votes, if any, are usually calculated based on the classifiers performance on some initial dataset.
</prevsent>
<prevsent>stacking, finally, is way of combining the decisions made by individual taggers in which the predicted tags forgiven word are used as input to subsequent tagger which outputs final label for the word.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
committee-based approaches to pos tagging have been in focus the last decade: brill and wu (1998) <papid> P98-1029 </papid>combined four different taggers for english using unweighted voting and by exploring contextual cues (essentially variant of stacking).</citsent>
<aftsection>
<nextsent>aires et al (2000) experimented with 12 different ways of combining the output from taggers for brazilian 106 portuguese, and concluded that some, but not all, combinations yielded better accuracy than the best individual tagger.
</nextsent>
<nextsent>shacham and wintner (2007) <papid> D07-1046 </papid>contrasted what they refer to as being nave wayof combining taggers with more elaborate, hierarchical one for hebrew.</nextsent>
<nextsent>in the end, the elaborated method yielded results inferior to the naveapproach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1710">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> part-of-speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>committee-based approaches to pos tagging have been in focus the last decade: brill and wu (1998) <papid> P98-1029 </papid>combined four different taggers for english using unweighted voting and by exploring contextual cues (essentially variant of stacking).</prevsent>
<prevsent>aires et al (2000) experimented with 12 different ways of combining the output from taggers for brazilian 106 portuguese, and concluded that some, but not all, combinations yielded better accuracy than the best individual tagger.</prevsent>
</prevsection>
<citsent citstr=" D07-1046 ">
shacham and wintner (2007) <papid> D07-1046 </papid>contrasted what they refer to as being nave wayof combining taggers with more elaborate, hierarchical one for hebrew.</citsent>
<aftsection>
<nextsent>in the end, the elaborated method yielded results inferior to the naveapproach.
</nextsent>
<nextsent>de pauw et al (2006) came to similar conclusions when using five different ways of combining four data-driven taggers for swahili.
</nextsent>
<nextsent>the taggers were based on hmm, memory-based learning, svm, and maximum entropy, with the latter proving most accurate.
</nextsent>
<nextsent>only in three of five cases did combination of classifiers perform better than the maximum entropy-based tagger,and simpler combination methods mostly outperformed more elaborate ones.spoustova?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1711">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> the taggers.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 hidden markov models: tnt.
</prevsent>
<prevsent>tnt, trigramsntags?
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
(brants, 2000) <papid> A00-1031 </papid>is very fast and easy-to-use hmm-based tagger which painlessly can be trained on different language sand tagsets, given tagged corpus.4 markov based tagger aims to find tag sequence which maximizes (wordn|tagn) ? (tagn|tag1...n1),where the first factor is the emit (or lexical) prob 3as reported on ufal.mff.cuni.cz/compost/en 4www.coli.uni-saarland.de/thorsten/tnt ability, the likelihood of word given certain tag,and the second factor is the state transition (or con textual) probability, the likelihood of tag given sequence of preceding tags.</citsent>
<aftsection>
<nextsent>tnt uses the viterbi algorithm for finding the optimal tag sequence.
</nextsent>
<nextsent>smoothing is implemented by linear interpolation, the respective weights are determined by deleted interpolation.
</nextsent>
<nextsent>unknown words are handled by suffix trie and successive abstraction.applying tnt to the wall street journal corpus, brants (2000) <papid> A00-1031 </papid>reports 96.7% overall accuracy, with 97.0% on known and 85.5% on unknown words (with 2.9% of the words being unknown).</nextsent>
<nextsent>4.2 support vector machines: svmtool.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1713">
<title id=" W09-0715.xml">methods for amharic partofspeech tagging </title>
<section> the taggers.  </section>
<citcontext>
<prevsection>
<prevsent>training maximum entropy classifier involves fitting the weights of each feature value for particular class to the available training data.
</prevsent>
<prevsent>a good fit of the weight sto the data is obtained by selecting weights to maximize the log-likelihood of the learned classification model.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
using an maximum entropy approach to pos tagging, ratnaparkhi (1996) <papid> W96-0213 </papid>reports tagging accuracy of 96.6% on the wall street journal.the software of choice for the experiments reported here is mallet (mccallum, 2002), freely available java implementation of range of machine learning methods, such as nave bayes, decision trees, crf, and maximum entropy.6 5www.lsi.upc.edu/nlp/svmtool 6mallet.cs.umass.edu 107</citsent>
<aftsection>
<nextsent>the experiments of this paper utilize the first medium-sized corpus for amharic (available at http://nlp.amharic.org).
</nextsent>
<nextsent>the corpus consists of all 1065 news texts (210,000 words) from the ethiopian year 1994 (parts of the gregorian years 20012002) from the walta information center, private news service based in addis ababa.
</nextsent>
<nextsent>it hasbeen morphologically analysed and manually part of-speech tagged by staff at elrc, the ethiopian languages research center at addis ababa university (demeke and getachew, 2006).the corpus is available both infidel and transcribed into roman ized version known as sera,system for ethiopic representation in ascii (ya cob, 1997).
</nextsent>
<nextsent>we worked with the transliterated form (202,671 words), to be compatible with the machine learning tools used in the experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1715">
<title id=" W09-0441.xml">fluency adequacy or hter exploring different human judgments with a tunable mt metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ter-plus was shown to be one of the top metrics in nists metrics matr2008 challenge, having the highest average rankin terms of pearson and spearman correlation.
</prevsent>
<prevsent>optimizing ter-plus to different types of human judgments yields significantly improved correlations and meaningful changes in the weight of different types of edits, demonstrating significant differences between the types of human judgments.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
since the introduction of the bleu metric (pa pineni et al, 2002), <papid> P02-1040 </papid>statistical mt systems have moved away from human evaluation of their performance and towards rapid evaluation using automatic metrics.</citsent>
<aftsection>
<nextsent>these automatic metrics are themselves evaluated by their ability to generate scores for mt output that correlate well with human judgments of translation quality.
</nextsent>
<nextsent>numerous methods of judging mt output by humans have been used, including fluency, adequacy, and, more recently, human-mediated translation edit rate (hter) (snover et al, 2006).
</nextsent>
<nextsent>fluency measures whether translation is fluent, regardless of the correct meaning, while adequacy measures whether the translation conveys the correct meaning, even if the translation is not fully fluent.
</nextsent>
<nextsent>fluency and adequacy are frequently measured together on discrete 5 or 7 point scale, with their average being used as single score of translation quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1716">
<title id=" W09-0441.xml">fluency adequacy or hter exploring different human judgments with a tunable mt metric </title>
<section> ter and terp.  </section>
<citcontext>
<prevsection>
<prevsent>while ter has been shown to correlate well with human judgments of translation quality, it has several flaws, including the use of only single reference translation and the measuring of similarity only by exact word matches between the hypothesis and the reference.
</prevsent>
<prevsent>the handicap of using asingle reference can be addressed by the construction of lattice of reference translations.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
such technique has been used with ter to combine the output of multiple translation systems (rosti et al, 2007).<papid> P07-1040 </papid></citsent>
<aftsection>
<nextsent>terp does not utilize this methodology2and instead focuses on addressing the exact matching flaw of ter.
</nextsent>
<nextsent>a brief description of ter is presented in section 2.1, followed by discussion of how terp differs from ter in section 2.2.
</nextsent>
<nextsent>2.1 ter.
</nextsent>
<nextsent>one of the first automatic metrics used to evaluate automatic machine translation (mt) systems was word error rate (wer) (niessen et al, 2000),which is the standard evaluation metric for automatic speech recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1717">
<title id=" W09-0441.xml">fluency adequacy or hter exploring different human judgments with a tunable mt metric </title>
<section> ter and terp.  </section>
<citcontext>
<prevsection>
<prevsent>ter-plus (terp) is an extension of ter that aligns words in the hypothesis and reference not only when they are exact matches but also whenthe words share stem or are synonyms.
</prevsent>
<prevsent>in addition, it uses probabilistic phrasal substitutions to align phrases in the hypothesis and reference.these phrases are generated by considering possible paraphrases of the reference words.
</prevsent>
</prevsection>
<citsent citstr=" W06-1610 ">
matching using stems and synonyms (banerjee and lavie, 2005) and using paraphrases (zhou et al, 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006) have previously been shown to be beneficial for automatic mt evalu ation.</citsent>
<aftsection>
<nextsent>paraphrases have also been shown to be useful in expanding the number of references usedfor parameter tuning (madnani et al, 2007; madnani et al, 2008) although they are not used directly in this fashion within terp.
</nextsent>
<nextsent>while all edit costs inter are constant, all edit costs in terp are optimized to maximize correlation with human judgments.
</nextsent>
<nextsent>this is because while set of constant weights might prove adequate for the purpose of measuring translation quality as evidenced by correlation with human judgments both for terand hterthey may not be ideal for maximizing correlation.
</nextsent>
<nextsent>terp uses all the edit operations of ter?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1719">
<title id=" W08-1910.xml">the close distant relation of adjectival concepts based on self organizing map </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from the map, we found 8 adjectival clusters in super-ordinate level and some tendencies of similar and dissimilar clusters.
</prevsent>
<prevsent>this paper aims to find diversity range of ad jectival meanings from coordinate map in which  close-distant  relationships between ad jectival classes is reflected.
</prevsent>
</prevsection>
<citsent citstr=" A00-2006 ">
in related research over adjectives, alonge et.al (2000), <papid> A00-2006 </papid>solar (2003), marrafa and mendes (2006) <papid> P06-2072 </papid>suggested that wordnet and euro wordnet lack sufficient adjectival classes and semantic relations, and extended the resources over such relations.</citsent>
<aftsection>
<nextsent>for the sake of identifying the diversity of adjectival meanings, it is necessary to analyze adjectival semantics via  close-distant  relationships extracted from texts.
</nextsent>
<nextsent>in our work on extracting adjective semantics, we consider abstract nouns as semantic proxies of adjectives.
</nextsent>
<nextsent>for the clustering method, we utilized self-organizing ? 2008.
</nextsent>
<nextsent>licensed under the creative commons attri bution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc sa/3.0/).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1720">
<title id=" W08-1910.xml">the close distant relation of adjectival concepts based on self organizing map </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>from the map, we found 8 adjectival clusters in super-ordinate level and some tendencies of similar and dissimilar clusters.
</prevsent>
<prevsent>this paper aims to find diversity range of ad jectival meanings from coordinate map in which  close-distant  relationships between ad jectival classes is reflected.
</prevsent>
</prevsection>
<citsent citstr=" P06-2072 ">
in related research over adjectives, alonge et.al (2000), <papid> A00-2006 </papid>solar (2003), marrafa and mendes (2006) <papid> P06-2072 </papid>suggested that wordnet and euro wordnet lack sufficient adjectival classes and semantic relations, and extended the resources over such relations.</citsent>
<aftsection>
<nextsent>for the sake of identifying the diversity of adjectival meanings, it is necessary to analyze adjectival semantics via  close-distant  relationships extracted from texts.
</nextsent>
<nextsent>in our work on extracting adjective semantics, we consider abstract nouns as semantic proxies of adjectives.
</nextsent>
<nextsent>for the clustering method, we utilized self-organizing ? 2008.
</nextsent>
<nextsent>licensed under the creative commons attri bution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc sa/3.0/).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1721">
<title id=" W08-1910.xml">the close distant relation of adjectival concepts based on self organizing map </title>
<section> a map of adjective semantics   </section>
<citcontext>
<prevsection>
<prevsent>the maximum number of co-occurring adjectives forgiven abstract noun in the corpus was 1,594.
</prevsent>
<prevsent>in the data, each abstract noun was defined by feature vector, in the form of noun cooccurrences represented by pointwise mutual information (manning and schutze, 1999).
</prevsent>
</prevsection>
<citsent citstr=" C02-1144 ">
mutual information (mi) is an information theoric measure and has been used in many nlp tasks, including clustering words (e.g. lin and pantel, 2002).<papid> C02-1144 </papid></citsent>
<aftsection>
<nextsent>3.2 som.
</nextsent>
<nextsent>kohonens self-organizing map (som) is an unsupervised learning method, where input instances are projected onto grid/map of nodes arranged in an n-dimensional space.
</nextsent>
<nextsent>input instances are usually high-dimensional data, while the map is usually two-dimensional (i.e., = 2).
</nextsent>
<nextsent>thus, som essentially reduces the dimensionality of the data, and can be used as an effective tool for data visualization ? projecting complex, high-dimensional data onto low-dimensional map.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1722">
<title id=" W09-1417.xml">biomedical event detection using rules conditional random fields and parse tree distances </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>for each event.
</prevsent>
<prevsent>it was obvious that participants did not have to be the nearest to the trigger on the surface level, so our approach was based on distances within the parse trees associated with the sentences containing candidate events.
</prevsent>
</prevsection>
<citsent citstr=" L08-1383 ">
parse tree distances have been studied previously in clustering and automatic translation tasks (emms 2008), <papid> L08-1383 </papid>so we hypothesised that we could use them to identify the most likely participants.</citsent>
<aftsection>
<nextsent>the training data was analysed for the proximities between the triggers and the (correct) event participants in the parse tree of the sentence.1 figure 1 gives detailed density function of these distances (ignoring non-protein nodes).
</nextsent>
<nextsent>the analysis showed that theme was usually amongst the nearest proteins to the trigger in terms of parse tree distances: for example, in 60% of all single theme events (e.g. localisation, phosphorylation) the correct protein participant was the triggers nearest or second nearest protein in the parse tree.
</nextsent>
<nextsent>a further 1 the parse trees were produced by the gdep parser (sagae and tsujii, 2007) <papid> D07-1111 </papid>and supplied by the challenge organisers.</nextsent>
<nextsent>analysis demonstrated that it was more likely for theme to appear in the sub-tree of the corresponding trigger, with 70% of all single theme events having theme which appeared in the sub-tree of the trigger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1723">
<title id=" W09-1417.xml">biomedical event detection using rules conditional random fields and parse tree distances </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the training data was analysed for the proximities between the triggers and the (correct) event participants in the parse tree of the sentence.1 figure 1 gives detailed density function of these distances (ignoring non-protein nodes).
</prevsent>
<prevsent>the analysis showed that theme was usually amongst the nearest proteins to the trigger in terms of parse tree distances: for example, in 60% of all single theme events (e.g. localisation, phosphorylation) the correct protein participant was the triggers nearest or second nearest protein in the parse tree.
</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
a further 1 the parse trees were produced by the gdep parser (sagae and tsujii, 2007) <papid> D07-1111 </papid>and supplied by the challenge organisers.</citsent>
<aftsection>
<nextsent>analysis demonstrated that it was more likely for theme to appear in the sub-tree of the corresponding trigger, with 70% of all single theme events having theme which appeared in the sub-tree of the trigger.
</nextsent>
<nextsent>furthermore, specific analyses of the parse trees associated to the binding events (which can have more than one theme) suggested linear relationship between the parse tree distance and binding event participant number (participant1 is the nearest, participant2 is the second nearest, etc.).
</nextsent>
<nextsent>figure 1: probability density function of the distance between the trigger and the theme in the parse tree (ignoring the tokens that are not proteins) we used this distributional analysis (derived from the training data) to design rule-based method for the identification of participating themes.
</nextsent>
<nextsent>the rules were manually derived for each of the nine event classes, by defining: ? threshold for the maximum distance to the trigger in the sub-tree for the given event type; ? threshold for the difference between the maximum distance in the whole tree and the given sub-tree for the given event type; ? the number of nearest proteins to be reported for each trigger.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1724">
<title id=" W09-1206.xml">multilingual semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluated our semantic parser on set of seven languages provided by the organizers of the conll 2009 shared task: catalan and spanish (taule?
</prevsent>
<prevsent>et al., 2008), chinese (palmer and xue, 2009), czech (hajic?
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
et al, 2006), english (surdeanu et al, 2008), <papid> W08-2121 </papid>german (burchardt et al, 2006), and japanese (kawahara et al, 2002).</citsent>
<aftsection>
<nextsent>our system achieved an average labeled semantic f1 of 80.31, which corresponded to the second best semantic score over all.
</nextsent>
<nextsent>after the official evaluation was completed, we discovered fault in the training procedure of the reranker for spanish.
</nextsent>
<nextsent>the revised average labeled semantic f1 after correction was 80.80.
</nextsent>
<nextsent>the pipeline of classifiers consists of predicate disambiguation (pd) module, an argument identification module (ai), and an argument classification (ac) module.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1728">
<title id=" W09-1206.xml">multilingual semantic role labeling </title>
<section> srl pipeline.  </section>
<citcontext>
<prevsection>
<prevsent>the revised average labeled semantic f1 after correction was 80.80.
</prevsent>
<prevsent>the pipeline of classifiers consists of predicate disambiguation (pd) module, an argument identification module (ai), and an argument classification (ac) module.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
aside from the lack of predicate identification module, which was not needed,as predicates were given, this architecture is identical to the one adopted by recent systems (surdeanu et al, 2008), <papid> W08-2121 </papid>as well as the general approach within the field (gildea and jurafsky, 2002; <papid> J02-3001 </papid>toutanova et al., 2005).<papid> P05-1073 </papid>we build all the classifiers using the l2regularized linear logistic regression from the liblinear package (fan et al, 2008).</citsent>
<aftsection>
<nextsent>the package implementation makes models very fast to train and 43 candidates candidates reranker local features + proposition features global model linear combination of models local classifier pipeline sense disambiguation greedy search argument identification beam search argument labeling beam search reranked candidates figure 1: system architecture.
</nextsent>
<nextsent>use for classification.
</nextsent>
<nextsent>since models are logistic, they produce an output in the form of probabilities that we use later in the reranker (see sect.
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1729">
<title id=" W09-1206.xml">multilingual semantic role labeling </title>
<section> srl pipeline.  </section>
<citcontext>
<prevsection>
<prevsent>the revised average labeled semantic f1 after correction was 80.80.
</prevsent>
<prevsent>the pipeline of classifiers consists of predicate disambiguation (pd) module, an argument identification module (ai), and an argument classification (ac) module.
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
aside from the lack of predicate identification module, which was not needed,as predicates were given, this architecture is identical to the one adopted by recent systems (surdeanu et al, 2008), <papid> W08-2121 </papid>as well as the general approach within the field (gildea and jurafsky, 2002; <papid> J02-3001 </papid>toutanova et al., 2005).<papid> P05-1073 </papid>we build all the classifiers using the l2regularized linear logistic regression from the liblinear package (fan et al, 2008).</citsent>
<aftsection>
<nextsent>the package implementation makes models very fast to train and 43 candidates candidates reranker local features + proposition features global model linear combination of models local classifier pipeline sense disambiguation greedy search argument identification beam search argument labeling beam search reranked candidates figure 1: system architecture.
</nextsent>
<nextsent>use for classification.
</nextsent>
<nextsent>since models are logistic, they produce an output in the form of probabilities that we use later in the reranker (see sect.
</nextsent>
<nextsent>3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1731">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality, for more than 20 metrics.
</prevsent>
<prevsent>we present new evaluation technique whereby system output is edited and judged for correctness.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
this paper presents the results of the shared tasksof the 2009 eacl workshop on statistical machine translation, which builds on three previous workshops (koehn and monz, 2006; <papid> W06-3114 </papid>callison burch et al, 2007; callison-burch et al, 2008).there were three shared tasks this year: translation task between english and five other european languages, task to combine the output of multiple machine translation systems, and task to predict human judgments of translation quality using automatic evaluation metrics.</citsent>
<aftsection>
<nextsent>the performance on each of these shared task was determined after comprehensive human evaluation.
</nextsent>
<nextsent>there were number of differences between this years workshop and last years workshop: ? larger training sets ? in addition to annual increases in the europarl corpus, we released french-english parallel corpus verging on 1billion words.
</nextsent>
<nextsent>we also provided large monolingual training sets for better language modeling of the news translation task.?
</nextsent>
<nextsent>reduced number of conditions ? previous workshops had many conditions: 10language pairs, both in-domain and out-ofdomain translation, and three types of manual evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1732">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many of the documents gathered in our web crawl were duplicates or near duplicates, and lot of the text is repeated,as with web site navigation.
</prevsent>
<prevsent>we further eliminated sentence pairs that varied from previous sentences by only numbers, which helped eliminate template web pages such as expense reports.
</prevsent>
</prevsection>
<citsent citstr=" D07-1049 ">
we used bloom filter (talbot and osborne, 2007) <papid> D07-1049 </papid>to do de-duplication, so it may have discarded more sentence pairs than strictly necessary.</citsent>
<aftsection>
<nextsent>after deduplication, the parallel corpus contained 28 million sentence pairs with 0.8 billion french words and 0.7 billion english words.
</nextsent>
<nextsent>monolingual news corpora we have crawled the news sources that were the basis of our test sets (and few more additional sources) since august 2007.
</nextsent>
<nextsent>this allowed us to assemble large corpora in the target domain to be mainly used as training data for language modeling.
</nextsent>
<nextsent>we collected texts from the beginning of our data collection period to one month before the test set period, segmented these into sentences and randomized the order of the sentences to obviate copyright concerns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1733">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>last year, nist began running similar metrics for machine translation?
</prevsent>
<prevsent>challenge (metricsmatr), and presented their findings at work shop at amta (przybocki et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in this years shared task we evaluated number of different automatic metrics: ? bleu (papineni et al, 2002)<papid> P02-1040 </papid>bleu remains the de facto standard in machine translation evaluation.</citsent>
<aftsection>
<nextsent>it calculates n-gram precision anda brevity penalty, and can make use of multiple reference translations as way of capturing some of the allowable variation in translation.
</nextsent>
<nextsent>we use single reference translation in our experiments.
</nextsent>
<nextsent>meteor (agarwal and lavie, 2008)<papid> W08-0312 </papid>meteor measures precision and recall for unigrams and applies fragmentation penalty.</nextsent>
<nextsent>it uses flexible word matching based on stemming and wordnet-synonymy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1734">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it calculates n-gram precision anda brevity penalty, and can make use of multiple reference translations as way of capturing some of the allowable variation in translation.
</prevsent>
<prevsent>we use single reference translation in our experiments.
</prevsent>
</prevsection>
<citsent citstr=" W08-0312 ">
meteor (agarwal and lavie, 2008)<papid> W08-0312 </papid>meteor measures precision and recall for unigrams and applies fragmentation penalty.</citsent>
<aftsection>
<nextsent>it uses flexible word matching based on stemming and wordnet-synonymy.
</nextsent>
<nextsent>meteor-ranking is optimized for correlation with ranking judgments.
</nextsent>
<nextsent>translation error rate (snover et al,2006)ter calculates the number of edits required to change hypothesis translation into reference translation.
</nextsent>
<nextsent>the possible edits inter include insertion, deletion, and substitution of single words, and an edit which moves sequences of contiguous words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1735">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the possible edits inter include insertion, deletion, and substitution of single words, and an edit which moves sequences of contiguous words.
</prevsent>
<prevsent>two variants of ter are also included: terp(snover et al, 2009), new version which introduces number of different features, and (bleu ? ter)/2, combination of bleu and translation edit rate.
</prevsent>
</prevsection>
<citsent citstr=" P08-1007 ">
maxsim (chan and ng, 2008)<papid> P08-1007 </papid>maxsim calculates similarity score by comparing items in the translation against the reference.unlike most metrics which do strict matching, maxsim computes similarity score for non-identical items.</citsent>
<aftsection>
<nextsent>to find maximum weight matching that matches each system item to at most one reference item, the items are then modeled as nodes in bipar tite graph.?
</nextsent>
<nextsent>wcd6p4er (leusch and ney, 2008)a measure based on cder with word-based substitution costs.
</nextsent>
<nextsent>leusch and ney (2008) also submitted two contrastive metrics: bleusp4114, modified version of bleu-s (lin and och, 2004), <papid> P04-1077 </papid>with tuned n-gram weights, and bleusp, with constant weights.</nextsent>
<nextsent>wcd6p4er is an error measure and bleusp is quality score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1736">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to find maximum weight matching that matches each system item to at most one reference item, the items are then modeled as nodes in bipar tite graph.?
</prevsent>
<prevsent>wcd6p4er (leusch and ney, 2008)a measure based on cder with word-based substitution costs.
</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
leusch and ney (2008) also submitted two contrastive metrics: bleusp4114, modified version of bleu-s (lin and och, 2004), <papid> P04-1077 </papid>with tuned n-gram weights, and bleusp, with constant weights.</citsent>
<aftsection>
<nextsent>wcd6p4er is an error measure and bleusp is quality score.
</nextsent>
<nextsent>rte (pado et al, 2009)the rte metric follows semantic approach which applies recent work in rich textual entailment to the problem of mt evaluation.
</nextsent>
<nextsent>its predictions are based on regression model over feature set adapted from an entailment systems.
</nextsent>
<nextsent>the features primarily model alignment quality and (mis-)matches of syntactic and semantic structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1737">
<title id=" W09-0401.xml">findings of the 2009 workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thusan automatic evaluation metric with higher absolute value for ? is making predictions that are more similar to the human judgments than an automatic evaluation metric with lower absolute ?.
</prevsent>
<prevsent>5.2 measuring sentence-level consistency.
</prevsent>
</prevsection>
<citsent citstr=" P07-1111 ">
because the sentence-level judgments collected in the manual evaluation are relative judgments rather than absolute judgments, it is not possible for us to measure correlation at the sentence level in the same way that previous work has done (kulesza and shieber, 2004; albrecht and hwa, 2007<papid> P07-1111 </papid>a; albrecht and hwa, 2007<papid> P07-1111 </papid>b).</citsent>
<aftsection>
<nextsent>rather than calculating correlation coefficient at the sentence-level we instead ascertained how consistent the automatic metrics were with the human judgments.
</nextsent>
<nextsent>the way that we calculated consistency was the following: for every pairwise comparison of two systems on single sentence by person, we counted the automatic metric as being consistent if the relative scores were the same (i.e. the metric assigned higher score to the higher ranked system).
</nextsent>
<nextsent>we divided this by the total number of pairwise comparisons to get percentage.because the systems generally assign real numbers as scores, we excluded pairs that the human annotators ranked as ties.
</nextsent>
<nextsent>de -e (2 1 sy st em s) fr -e (2 1 sy st em s) es -e (1 3 sy st em s) cz -e (5 sy st em s) hu -e (6 sy st em s) ve ra ge ulc .78 .92 .86 1 .6 .83 maxsim .76 .91 .98 .7 .66 .8 rte (absolute) .64 .91 .96 .6 .83 .79 meteor-rank .64 .93 .96 .7 .54 .75 rte (pairwise) .76 .59 .78 .8 .83 .75 terp -.72 -.89 -.94 -.7 -.37 -.72 meteor-0.6 .56 .93 .87 .7 .54 .72 meteor-0.7 .55 .93 .86 .7 .26 .66 bleu-ter/2 .38 .88 .78 .9 -.03 .58 nist .41 .87 .75 .9 -.14 .56 wpf .42 .87 .82 1 -.31 .56 ter -.43 -.83 -.84 -.6 -.01 -.54 nist (cased) .42 .83 .75 1 -.31 .54 bleu .41 .88 .79 .6 -.14 .51 bleusp .39 .88 .78 .6 -.09 .51 bleusp4114 .39 .89 .78 .6 -.26 .48 bleu (cased) .4 .86 .8 .6 -.31 .47 wpbleu .43 .86 .8 .7 -.49 .46 wcd6p4er -.41 -.89 -.76 -.6 .43 -.45table 7: the system-level correlation of the automatic evaluation metrics with the human judgments for translation into english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1745">
<title id=" W09-1605.xml">directions for exploiting asymmetries in multilingual wikipedia </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wikipedia entries can have descriptions in several languages independently created for each language.
</prevsent>
<prevsent>thus, wikipedia can be considered comparable corpus.
</prevsent>
</prevsection>
<citsent citstr=" P07-1099 ">
wikipedia is used in qa for answer extraction and verification (ahn et al, 2005; buscaldi and rosso, 2006; ko et al, 2007).<papid> P07-1099 </papid></citsent>
<aftsection>
<nextsent>in summarization,wikipedia articles structure is used to learn the features for summary generation (baidsy et al, 2008).several nlp systems utilize the wikipedia multi linguality property.
</nextsent>
<nextsent>adafre et al (2006) analyze the possibility of constructing an english-dutch parallel corpus by suggesting two ways of looking for similar sentences in wikipedia pages (using matching translations and hyperlinks).
</nextsent>
<nextsent>richman et al (2008) utilize multilingual characteristics of wikipedia to annotate large corpus of text with named entitytags.
</nextsent>
<nextsent>multilingual wikipedia has been used to facilitate cross-language ir (schonhofen et al, 2007) and to perform cross-lingual qa (ferrandez et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1746">
<title id=" W09-1605.xml">directions for exploiting asymmetries in multilingual wikipedia </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we showed that despite the fact that english has descriptions for the most number of wikipedia entries across all languages, english descriptions can not always be considered as the most detailed descriptions.
</prevsent>
<prevsent>we showed that for many wikipedia entries, descriptions in the languages other than english are much longer than the corresponding descriptions in english.our estimation is that even though wikipedia entry descriptions created in different languages arenot identical, they are likely to contain information facts that appear in descriptions in many languages.
</prevsent>
</prevsection>
<citsent citstr=" W04-3254 ">
one research direction that we are interested in pursuing is investigating whether the information repeated in multiple descriptions of particular entry corresponds to the pyramid summarization model (teufel and halteren, 2004; <papid> W04-3254 </papid>nenkova et al., 2007).</citsent>
<aftsection>
<nextsent>in case of the positive answer to this question, multilingual wikipedia can be used as reliable corpus for learning summarization features.
</nextsent>
<nextsent>also, our preliminary analysis shows that wikipedia entry descriptions might contain information that contradicts information presented in the entry descriptions in other languages.
</nextsent>
<nextsent>even the choice of title for wikipedia entry can provide interesting information.
</nextsent>
<nextsent>for example, the title for the wikipedia entry about former yugoslav republic of macedonia in english, german, italian, and many other languages uses the term republic of macedonia or simply macedonia.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1747">
<title id=" W09-1609.xml">ne tagging for urdu based on bootstrap pos learning </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>bbc urdu and jung daily are both encoded with unicode standards and are good sources of data.
</prevsent>
<prevsent>the availability of online resources for urdu is not as extensive as other asian languages like chinese and hindi.
</prevsent>
</prevsection>
<citsent citstr=" I08-7017 ">
however, hussain (2008) <papid> I08-7017 </papid>has done good job in assimilating most of the resources available on the internet.</citsent>
<aftsection>
<nextsent>the lexicon provided as part of the emille (2003) dataset for urdu has about 200,000 words.
</nextsent>
<nextsent>crl5 has released lexicon of 8000 words as part of their urdu data collection.
</nextsent>
<nextsent>they also provide an ne tagged dataset mostly used for morphological analysis.
</nextsent>
<nextsent>the lexicon includes pos information as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1748">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we argue that part of this is due to evaluation issues and estimate that deletion model is in fact compatible with approximately 55% of the observed data.
</prevsent>
<prevsent>we analyse the remaining problems and conclude that in those cases word order changes and paraphrasing are crucial, and argue for more elaborate sentence compression models which build on nlg work.
</prevsent>
</prevsection>
<citsent citstr=" A00-2024 ">
the task of sentence compression (or sentence re duction) can be defined as summarizing single sentence by removing information from it (jing and mckeown, 2000).<papid> A00-2024 </papid></citsent>
<aftsection>
<nextsent>the compressed sentence should retain the most important information and remain grammatical.
</nextsent>
<nextsent>one of the application sis in automatic summarization in order to compress sentences extracted for the summary (lin,2003; <papid> W03-1101 </papid>jing and mckeown, 2000).<papid> A00-2024 </papid></nextsent>
<nextsent>other applications include automatic sub titling (vandeghin ste and tsjong kim sang, 2004; vandeghinste and pan, 2004; <papid> W04-1015 </papid>daelemans et al, 2004) and displaying text on devices with very small screens (corston oliver, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1750">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task of sentence compression (or sentence re duction) can be defined as summarizing single sentence by removing information from it (jing and mckeown, 2000).<papid> A00-2024 </papid></prevsent>
<prevsent>the compressed sentence should retain the most important information and remain grammatical.</prevsent>
</prevsection>
<citsent citstr=" W03-1101 ">
one of the application sis in automatic summarization in order to compress sentences extracted for the summary (lin,2003; <papid> W03-1101 </papid>jing and mckeown, 2000).<papid> A00-2024 </papid></citsent>
<aftsection>
<nextsent>other applications include automatic sub titling (vandeghin ste and tsjong kim sang, 2004; vandeghinste and pan, 2004; <papid> W04-1015 </papid>daelemans et al, 2004) and displaying text on devices with very small screens (corston oliver, 2001).</nextsent>
<nextsent>a more restricted version defines sentence compression as dropping any subset of words from the input sentence while retaining important information and grammaticality (knight andmarcu, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1753">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the compressed sentence should retain the most important information and remain grammatical.
</prevsent>
<prevsent>one of the application sis in automatic summarization in order to compress sentences extracted for the summary (lin,2003; <papid> W03-1101 </papid>jing and mckeown, 2000).<papid> A00-2024 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-1015 ">
other applications include automatic sub titling (vandeghin ste and tsjong kim sang, 2004; vandeghinste and pan, 2004; <papid> W04-1015 </papid>daelemans et al, 2004) and displaying text on devices with very small screens (corston oliver, 2001).</citsent>
<aftsection>
<nextsent>a more restricted version defines sentence compression as dropping any subset of words from the input sentence while retaining important information and grammaticality (knight andmarcu, 2002).
</nextsent>
<nextsent>this formulation of the task provided the basis for the noisy-channel en decision tree based algorithms presented in (knight and marcu, 2002), and for virtually all follow-up work on data-driven sentence compression (le and horiguchi, 2003; vandeghinste and pan, 2004; <papid> W04-1015 </papid>turner and charniak, 2005; <papid> P05-1036 </papid>clarke and lapata, 2006; <papid> P06-1048 </papid>zajic et al, 2007; clarke and lapata, 2008) it makes two important assumptions: (1) only word deletions are allowed ? no substitutions or insertions ? and therefore no paraphrases; (2) theword order is fixed.</nextsent>
<nextsent>in other words, the compressed sentence must be sub sequence of the source sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1757">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other applications include automatic sub titling (vandeghin ste and tsjong kim sang, 2004; vandeghinste and pan, 2004; <papid> W04-1015 </papid>daelemans et al, 2004) and displaying text on devices with very small screens (corston oliver, 2001).</prevsent>
<prevsent>a more restricted version defines sentence compression as dropping any subset of words from the input sentence while retaining important information and grammaticality (knight andmarcu, 2002).</prevsent>
</prevsection>
<citsent citstr=" P05-1036 ">
this formulation of the task provided the basis for the noisy-channel en decision tree based algorithms presented in (knight and marcu, 2002), and for virtually all follow-up work on data-driven sentence compression (le and horiguchi, 2003; vandeghinste and pan, 2004; <papid> W04-1015 </papid>turner and charniak, 2005; <papid> P05-1036 </papid>clarke and lapata, 2006; <papid> P06-1048 </papid>zajic et al, 2007; clarke and lapata, 2008) it makes two important assumptions: (1) only word deletions are allowed ? no substitutions or insertions ? and therefore no paraphrases; (2) theword order is fixed.</citsent>
<aftsection>
<nextsent>in other words, the compressed sentence must be sub sequence of the source sentence.
</nextsent>
<nextsent>we will call this the subsequenceconstraint, and refer to the corresponding compression models as word deletion models.
</nextsent>
<nextsent>another implicit assumption in most work is that the scopeof sentence compression is limited to isolated sentences and that the textual context is irrelevant.
</nextsent>
<nextsent>under this definition, sentence compression is reduced to word deletion task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1758">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other applications include automatic sub titling (vandeghin ste and tsjong kim sang, 2004; vandeghinste and pan, 2004; <papid> W04-1015 </papid>daelemans et al, 2004) and displaying text on devices with very small screens (corston oliver, 2001).</prevsent>
<prevsent>a more restricted version defines sentence compression as dropping any subset of words from the input sentence while retaining important information and grammaticality (knight andmarcu, 2002).</prevsent>
</prevsection>
<citsent citstr=" P06-1048 ">
this formulation of the task provided the basis for the noisy-channel en decision tree based algorithms presented in (knight and marcu, 2002), and for virtually all follow-up work on data-driven sentence compression (le and horiguchi, 2003; vandeghinste and pan, 2004; <papid> W04-1015 </papid>turner and charniak, 2005; <papid> P05-1036 </papid>clarke and lapata, 2006; <papid> P06-1048 </papid>zajic et al, 2007; clarke and lapata, 2008) it makes two important assumptions: (1) only word deletions are allowed ? no substitutions or insertions ? and therefore no paraphrases; (2) theword order is fixed.</citsent>
<aftsection>
<nextsent>in other words, the compressed sentence must be sub sequence of the source sentence.
</nextsent>
<nextsent>we will call this the subsequenceconstraint, and refer to the corresponding compression models as word deletion models.
</nextsent>
<nextsent>another implicit assumption in most work is that the scopeof sentence compression is limited to isolated sentences and that the textual context is irrelevant.
</nextsent>
<nextsent>under this definition, sentence compression is reduced to word deletion task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1760">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>it turns min: max: sum: mean: sd: del 1 34 34728 6.64 4.57 sub 0 6 4116 0.79 0.94 ins 0 17 7768 1.48 1.78 dist 1 46 46612 8.91 5.78 reorder nan nan 1688 0.32 nan table 3: observed word deletions, insertions, substitutions, and edit distances out that only 843 (16.11%) subtitles are subse quence, which is rather low.
</prevsent>
<prevsent>at first sight, this appears to be bad news for any deletion model, as it seems to imply that the model cannot account for close to 84% the observed data.
</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
however, the important thing to keep in mind is that compression of given sentence is problem for which there are usually multiple solutions (belz and reiter, 2006).<papid> E06-1040 </papid></citsent>
<aftsection>
<nextsent>this is exactly what makes it so hard to perform automatic evaluation of nlg systems.
</nextsent>
<nextsent>there may very well exist semantically equivalent alternatives with the same cr which do satisfy the sub sequence constraint.
</nextsent>
<nextsent>for this reason, substantial part of the observednon-subsequences may have sub sequence counterparts which can be accounted for by deletion model.
</nextsent>
<nextsent>the question is: how many?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1761">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> 9 4.50 </section>
<citcontext>
<prevsection>
<prevsent>in the next section, we look at the possibilities of automatic extraction of such paraphrases.
</prevsent>
<prevsent>3.4 perspectives for automatic paraphrase.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
extraction there is growing amount of work on automatic extraction of paraphrases from text corpora (lin and pantel, 2001; barzilay and lee, 2003; <papid> N03-1003 </papid>ibrahim et al, 2003; <papid> W03-1608 </papid>dolan et al, 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>one general prerequisite for learning particular paraphrase pattern is that it must occur in the text corpus with sufficiently high frequency, otherwise the chances of learning the pattern are proportionally small.
</nextsent>
<nextsent>inthis section, we investigate to what extent the paraphrases encountered in our random sample of 200 pairs can be retrieved from reasonably large text corpus.
</nextsent>
<nextsent>in first step, we manually extracted 106paraphrase patterns.
</nextsent>
<nextsent>we filtered these patterns and excluded anaphoric expressions, general verb alternation patterns like active/passive andcontinuous/non-continuous, as well as verbal patterns involving more than two slots.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1762">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> 9 4.50 </section>
<citcontext>
<prevsection>
<prevsent>in the next section, we look at the possibilities of automatic extraction of such paraphrases.
</prevsent>
<prevsent>3.4 perspectives for automatic paraphrase.
</prevsent>
</prevsection>
<citsent citstr=" W03-1608 ">
extraction there is growing amount of work on automatic extraction of paraphrases from text corpora (lin and pantel, 2001; barzilay and lee, 2003; <papid> N03-1003 </papid>ibrahim et al, 2003; <papid> W03-1608 </papid>dolan et al, 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>one general prerequisite for learning particular paraphrase pattern is that it must occur in the text corpus with sufficiently high frequency, otherwise the chances of learning the pattern are proportionally small.
</nextsent>
<nextsent>inthis section, we investigate to what extent the paraphrases encountered in our random sample of 200 pairs can be retrieved from reasonably large text corpus.
</nextsent>
<nextsent>in first step, we manually extracted 106paraphrase patterns.
</nextsent>
<nextsent>we filtered these patterns and excluded anaphoric expressions, general verb alternation patterns like active/passive andcontinuous/non-continuous, as well as verbal patterns involving more than two slots.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1763">
<title id=" W09-0604.xml">is sentence compression an nlg task </title>
<section> 9 4.50 </section>
<citcontext>
<prevsection>
<prevsent>in the next section, we look at the possibilities of automatic extraction of such paraphrases.
</prevsent>
<prevsent>3.4 perspectives for automatic paraphrase.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
extraction there is growing amount of work on automatic extraction of paraphrases from text corpora (lin and pantel, 2001; barzilay and lee, 2003; <papid> N03-1003 </papid>ibrahim et al, 2003; <papid> W03-1608 </papid>dolan et al, 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>one general prerequisite for learning particular paraphrase pattern is that it must occur in the text corpus with sufficiently high frequency, otherwise the chances of learning the pattern are proportionally small.
</nextsent>
<nextsent>inthis section, we investigate to what extent the paraphrases encountered in our random sample of 200 pairs can be retrieved from reasonably large text corpus.
</nextsent>
<nextsent>in first step, we manually extracted 106paraphrase patterns.
</nextsent>
<nextsent>we filtered these patterns and excluded anaphoric expressions, general verb alternation patterns like active/passive andcontinuous/non-continuous, as well as verbal patterns involving more than two slots.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1765">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> design challenges inner.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we introduce the baseline ner system, and raise the fundamental questions underlying robust and efficient design.
</prevsent>
<prevsent>these questions define the outline of this paper.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
ner is typically view edas sequential prediction problem, the typical models include hmm (rabiner, 1989), crf (laffertyet al, 2001), and sequential application of perceptron or winnow (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>that is, let = (x1, . . .
</nextsent>
<nextsent>, xn ) be an input sequence and = (y1, . . .
</nextsent>
<nextsent>, yn ) be the output sequence.
</nextsent>
<nextsent>the sequential prediction problem is to estimate the probabilities (yi|xik . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1766">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> design challenges inner.  </section>
<citcontext>
<prevsection>
<prevsent>xi+l, yim . . .
</prevsent>
<prevsent>yi1), where k, and are small numbers to allow tractable inference and avoid overfitting.
</prevsent>
</prevsection>
<citsent citstr=" W03-0434 ">
this conditional probability distribution is estimated inner using the following baseline set of features (zhang and johnson, 2003): (<papid> W03-0434 </papid>1) previous two predictions yi1 and yi2 (2) current word xi (3) xi word type(all-capitalized, is-capitalized, all-digits, alphanumeric, etc.)</citsent>
<aftsection>
<nextsent>(4) prefixes and suffixes of xi (5) tokens in the window = (xi2, xi1, xi, xi+1, xi+2) (6)capitalization pattern in the window (7) conjunction of and yi1.
</nextsent>
<nextsent>most ner systems use additional features, such as pos tags, shallow parsing information andgazetteers.
</nextsent>
<nextsent>we discuss additional features in the following sections.
</nextsent>
<nextsent>we note that we normalize dates and numbers, that is 12/3/2008 becomes *date*, 1980 becomes *dddd* and 212-325-4751 becomes*ddd*-*ddd*-*dddd*.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1767">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> design challenges inner.  </section>
<citcontext>
<prevsection>
<prevsent>we note that we normalize dates and numbers, that is 12/3/2008 becomes *date*, 1980 becomes *dddd* and 212-325-4751 becomes*ddd*-*ddd*-*dddd*.
</prevsent>
<prevsent>this allows degree of abstraction to years, phone numbers, etc.our baseline ner system uses regularized averaged perceptron (freund and schapire, 1999).
</prevsent>
</prevsection>
<citsent citstr=" D07-1073 ">
systems based on perceptron have been shown to be competitive inner and text chunking (kazama and torisawa, 2007<papid> D07-1073 </papid>b; punyakanok and roth, 2001; carreras et al, 2003) <papid> W03-0422 </papid>we specify the model and the features with the lbj (rizzolo and roth, 2007) modeling language.</citsent>
<aftsection>
<nextsent>we now state the four fundamental design decisions inner system which define the structure of this paper.
</nextsent>
<nextsent>algorithm baseline system final system greedy 83.29 90.57 beam size=10 83.38 90.67 beam size=100 83.38 90.67 viterbi 83.71 n/a table 1: phrase-level f1 performance of different inference methods on conll03 test data.
</nextsent>
<nextsent>viterbi cannot be used in the end system due to non-local features.
</nextsent>
<nextsent>key design decisions in an ner system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1769">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> design challenges inner.  </section>
<citcontext>
<prevsection>
<prevsent>we note that we normalize dates and numbers, that is 12/3/2008 becomes *date*, 1980 becomes *dddd* and 212-325-4751 becomes*ddd*-*ddd*-*dddd*.
</prevsent>
<prevsent>this allows degree of abstraction to years, phone numbers, etc.our baseline ner system uses regularized averaged perceptron (freund and schapire, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W03-0422 ">
systems based on perceptron have been shown to be competitive inner and text chunking (kazama and torisawa, 2007<papid> D07-1073 </papid>b; punyakanok and roth, 2001; carreras et al, 2003) <papid> W03-0422 </papid>we specify the model and the features with the lbj (rizzolo and roth, 2007) modeling language.</citsent>
<aftsection>
<nextsent>we now state the four fundamental design decisions inner system which define the structure of this paper.
</nextsent>
<nextsent>algorithm baseline system final system greedy 83.29 90.57 beam size=10 83.38 90.67 beam size=100 83.38 90.67 viterbi 83.71 n/a table 1: phrase-level f1 performance of different inference methods on conll03 test data.
</nextsent>
<nextsent>viterbi cannot be used in the end system due to non-local features.
</nextsent>
<nextsent>key design decisions in an ner system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1770">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> inference &amp; chunk representation.  </section>
<citcontext>
<prevsection>
<prevsent>however, it has the appealing quality of finding the most likely assignment toa second-order model, and since the baseline features only have second order dependencies, we have tested it on the baseline configuration.
</prevsent>
<prevsent>table 1 compares between the greedy decoding, beam search with varying beam size, and viterbi, both for the system with baseline features and for the end system (to be presented later).
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
surprisingly, the greedy policy performs well, this phenmenon was also observed in the pos tagging task (toutanovaet al, 2003; <papid> N03-1033 </papid>roth and zelenko, 1998).<papid> P98-2186 </papid></citsent>
<aftsection>
<nextsent>the implications are subtle.
</nextsent>
<nextsent>first, due to the second-order of the model, the greedy decoding is over 100 times faster than viterbi.
</nextsent>
<nextsent>the reason is that with the bilou encoding of four ne types, each token can take 21 states (o, b-per, i-per , u-per, etc.).
</nextsent>
<nextsent>totag token, the greedy policy requires 21 comparisons, while the viterbi requires 213, and this analysis carries over to the number of classifier invocations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1771">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> inference &amp; chunk representation.  </section>
<citcontext>
<prevsection>
<prevsent>however, it has the appealing quality of finding the most likely assignment toa second-order model, and since the baseline features only have second order dependencies, we have tested it on the baseline configuration.
</prevsent>
<prevsent>table 1 compares between the greedy decoding, beam search with varying beam size, and viterbi, both for the system with baseline features and for the end system (to be presented later).
</prevsent>
</prevsection>
<citsent citstr=" P98-2186 ">
surprisingly, the greedy policy performs well, this phenmenon was also observed in the pos tagging task (toutanovaet al, 2003; <papid> N03-1033 </papid>roth and zelenko, 1998).<papid> P98-2186 </papid></citsent>
<aftsection>
<nextsent>the implications are subtle.
</nextsent>
<nextsent>first, due to the second-order of the model, the greedy decoding is over 100 times faster than viterbi.
</nextsent>
<nextsent>the reason is that with the bilou encoding of four ne types, each token can take 21 states (o, b-per, i-per , u-per, etc.).
</nextsent>
<nextsent>totag token, the greedy policy requires 21 comparisons, while the viterbi requires 213, and this analysis carries over to the number of classifier invocations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1772">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> non-local features.  </section>
<citcontext>
<prevsection>
<prevsent>we believe that this approach will also make our system more robust in cases when the document boundaries are not given.
</prevsent>
<prevsent>5.1 context aggregation.
</prevsent>
</prevsection>
<citsent citstr=" W03-0423 ">
(chieu and ng, 2003) <papid> W03-0423 </papid>used features that aggregate, for each document, the context tokens appearin.</citsent>
<aftsection>
<nextsent>sample features are: the longest capitilized sequence of words in the document which contains the current token and the token appears before company marker such as ltd. elsewhere in text.in this work, we call this type of features context aggregation features.
</nextsent>
<nextsent>manually designed context aggregation features clearly have low coverage, therefore we used the following approach.
</nextsent>
<nextsent>recall that for each token instance xi, we use as features the tokens in the window of size two around it: ci = (xi2, xi1, xi, xi+1, xi+2).
</nextsent>
<nextsent>when the same token type appears in several locations in the text,say xi1 , xi2 , . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1773">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> non-local features.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 two-stage prediction aggregation.
</prevsent>
<prevsent>context aggregation as done above can lead to excessive number of features.
</prevsent>
</prevsection>
<citsent citstr=" P06-1141 ">
(krishnan and manning,2006) <papid> P06-1141 </papid>used the intuition that some instances of token appear in easily-identifiable contexts.</citsent>
<aftsection>
<nextsent>therefore they apply baseline ner system, and use the resulting predictions as features in second level of inference.
</nextsent>
<nextsent>we call the technique two-stage prediction aggregation.
</nextsent>
<nextsent>we implemented the token-majorityand the entity-majority features discussed in (krishnan and manning, 2006); <papid> P06-1141 </papid>however, instead of document and corpus majority tags, we used relative frequency of the tags in 1000 token window.</nextsent>
<nextsent>5.3 extended prediction history.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1775">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>gazette ers and unlabeled text.
</prevsent>
<prevsent>6.1 unlabeled text.
</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
recent successful semi-supervised systems (ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008)<papid> P08-1076 </papid>have illustrated that unlabeled text can be used to im prove the performance of ner systems.</citsent>
<aftsection>
<nextsent>in this work, we analyze simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (koo et al, 2008), <papid> P08-1068 </papid>chinese word segmentation (liang, 2005) and ner (miller et al, 2004).<papid> N04-1043 </papid>the technique is based on word class models, pioneered by (brown et al, 1992), <papid> J92-4003 </papid>which hierarchically 151 conll03 conll03 muc7 muc7 web component test data dev data dev test pages 1) baseline 83.65 89.25 74.72 71.28 71.41 2) (1) + gazetteer match 87.22 91.61 85.83 80.43 74.46 3) (1) + word class model 86.82 90.85 80.25 79.88 72.26 4) all external knowledge 88.55 92.49 84.50 83.23 74.44 table 4: utility of external knowledge.</nextsent>
<nextsent>the system was trained on conll03 data and tested on connl03, muc7 and webpages.clusters words, producing binary tree as in figure 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1776">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>gazette ers and unlabeled text.
</prevsent>
<prevsent>6.1 unlabeled text.
</prevsent>
</prevsection>
<citsent citstr=" P08-1076 ">
recent successful semi-supervised systems (ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008)<papid> P08-1076 </papid>have illustrated that unlabeled text can be used to im prove the performance of ner systems.</citsent>
<aftsection>
<nextsent>in this work, we analyze simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (koo et al, 2008), <papid> P08-1068 </papid>chinese word segmentation (liang, 2005) and ner (miller et al, 2004).<papid> N04-1043 </papid>the technique is based on word class models, pioneered by (brown et al, 1992), <papid> J92-4003 </papid>which hierarchically 151 conll03 conll03 muc7 muc7 web component test data dev data dev test pages 1) baseline 83.65 89.25 74.72 71.28 71.41 2) (1) + gazetteer match 87.22 91.61 85.83 80.43 74.46 3) (1) + word class model 86.82 90.85 80.25 79.88 72.26 4) all external knowledge 88.55 92.49 84.50 83.23 74.44 table 4: utility of external knowledge.</nextsent>
<nextsent>the system was trained on conll03 data and tested on connl03, muc7 and webpages.clusters words, producing binary tree as in figure 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1778">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 unlabeled text.
</prevsent>
<prevsent>recent successful semi-supervised systems (ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008)<papid> P08-1076 </papid>have illustrated that unlabeled text can be used to im prove the performance of ner systems.</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
in this work, we analyze simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (koo et al, 2008), <papid> P08-1068 </papid>chinese word segmentation (liang, 2005) and ner (miller et al, 2004).<papid> N04-1043 </papid>the technique is based on word class models, pioneered by (brown et al, 1992), <papid> J92-4003 </papid>which hierarchically 151 conll03 conll03 muc7 muc7 web component test data dev data dev test pages 1) baseline 83.65 89.25 74.72 71.28 71.41 2) (1) + gazetteer match 87.22 91.61 85.83 80.43 74.46 3) (1) + word class model 86.82 90.85 80.25 79.88 72.26 4) all external knowledge 88.55 92.49 84.50 83.23 74.44 table 4: utility of external knowledge.</citsent>
<aftsection>
<nextsent>the system was trained on conll03 data and tested on connl03, muc7 and webpages.clusters words, producing binary tree as in figure 2.
</nextsent>
<nextsent>figure 2: an extract from word cluster hierarchy.the approach is related, but not identical, to distributional similarity (for details, see (brown et al, 1992) <papid> J92-4003 </papid>and (liang, 2005)).</nextsent>
<nextsent>for example, since the words friday and tuesday appear in similar contexts, the brown algorithm will assign them to the same cluster.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1779">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 unlabeled text.
</prevsent>
<prevsent>recent successful semi-supervised systems (ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008)<papid> P08-1076 </papid>have illustrated that unlabeled text can be used to im prove the performance of ner systems.</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
in this work, we analyze simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (koo et al, 2008), <papid> P08-1068 </papid>chinese word segmentation (liang, 2005) and ner (miller et al, 2004).<papid> N04-1043 </papid>the technique is based on word class models, pioneered by (brown et al, 1992), <papid> J92-4003 </papid>which hierarchically 151 conll03 conll03 muc7 muc7 web component test data dev data dev test pages 1) baseline 83.65 89.25 74.72 71.28 71.41 2) (1) + gazetteer match 87.22 91.61 85.83 80.43 74.46 3) (1) + word class model 86.82 90.85 80.25 79.88 72.26 4) all external knowledge 88.55 92.49 84.50 83.23 74.44 table 4: utility of external knowledge.</citsent>
<aftsection>
<nextsent>the system was trained on conll03 data and tested on connl03, muc7 and webpages.clusters words, producing binary tree as in figure 2.
</nextsent>
<nextsent>figure 2: an extract from word cluster hierarchy.the approach is related, but not identical, to distributional similarity (for details, see (brown et al, 1992) <papid> J92-4003 </papid>and (liang, 2005)).</nextsent>
<nextsent>for example, since the words friday and tuesday appear in similar contexts, the brown algorithm will assign them to the same cluster.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1780">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 unlabeled text.
</prevsent>
<prevsent>recent successful semi-supervised systems (ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008)<papid> P08-1076 </papid>have illustrated that unlabeled text can be used to im prove the performance of ner systems.</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
in this work, we analyze simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (koo et al, 2008), <papid> P08-1068 </papid>chinese word segmentation (liang, 2005) and ner (miller et al, 2004).<papid> N04-1043 </papid>the technique is based on word class models, pioneered by (brown et al, 1992), <papid> J92-4003 </papid>which hierarchically 151 conll03 conll03 muc7 muc7 web component test data dev data dev test pages 1) baseline 83.65 89.25 74.72 71.28 71.41 2) (1) + gazetteer match 87.22 91.61 85.83 80.43 74.46 3) (1) + word class model 86.82 90.85 80.25 79.88 72.26 4) all external knowledge 88.55 92.49 84.50 83.23 74.44 table 4: utility of external knowledge.</citsent>
<aftsection>
<nextsent>the system was trained on conll03 data and tested on connl03, muc7 and webpages.clusters words, producing binary tree as in figure 2.
</nextsent>
<nextsent>figure 2: an extract from word cluster hierarchy.the approach is related, but not identical, to distributional similarity (for details, see (brown et al, 1992) <papid> J92-4003 </papid>and (liang, 2005)).</nextsent>
<nextsent>for example, since the words friday and tuesday appear in similar contexts, the brown algorithm will assign them to the same cluster.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1782">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 gazetteers.
</prevsent>
<prevsent>an important question at the inception of the ner task was whether machine learning techniques are necessary at all, and whether simple dictionary lookup would be sufficient for good performance.
</prevsent>
</prevsection>
<citsent citstr=" W03-0419 ">
indeed, the baseline for the conll03 shared taskwas essentially dictionary lookup of the entities which appeared in the training data, and it achieves 71.91 f1 score on the test set (tjong andde meulder, 2003).<papid> W03-0419 </papid></citsent>
<aftsection>
<nextsent>it turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (cohen, 2004; kazamaand torisawa, 2007<papid> D07-1073 </papid>a; toral and munoz, 2006; florian et al, 2003).<papid> W03-0425 </papid></nextsent>
<nextsent>given these findings, several approaches have been proposed to automatically extract comprehensive gazette ers from the web and from large collections of unlabeled text (etzioniet al, 2005; riloff and jones, 1999) with limited impact on ner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1785">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> external knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>an important question at the inception of the ner task was whether machine learning techniques are necessary at all, and whether simple dictionary lookup would be sufficient for good performance.
</prevsent>
<prevsent>indeed, the baseline for the conll03 shared taskwas essentially dictionary lookup of the entities which appeared in the training data, and it achieves 71.91 f1 score on the test set (tjong andde meulder, 2003).<papid> W03-0419 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
it turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (cohen, 2004; kazamaand torisawa, 2007<papid> D07-1073 </papid>a; toral and munoz, 2006; florian et al, 2003).<papid> W03-0425 </papid></citsent>
<aftsection>
<nextsent>given these findings, several approaches have been proposed to automatically extract comprehensive gazette ers from the web and from large collections of unlabeled text (etzioniet al, 2005; riloff and jones, 1999) with limited impact on ner.
</nextsent>
<nextsent>recently, (toral and munoz,2006; kazama and torisawa, 2007<papid> D07-1073 </papid>a) have successfully constructed high quality and high coverage gazette ers from wikipedia.in this work, we use collection of 14 high precision, low-recall lists extracted from the web that cover common names, countries, monetary units, temporal expressions, etc. while thesegazetteers have excellent accuracy, they do not provide sufficient coverage.</nextsent>
<nextsent>to further improve the coverage, we have extracted 16 gazette ers from wikipedia, which collectively contain over 1.5m en tities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1802">
<title id=" W09-1119.xml">design challenges and misconceptions in named entity recognition </title>
<section> final system performance analysis.  </section>
<citcontext>
<prevsection>
<prevsent>we have chosen to compare against the stanford tagger because to the best of our knowledge, it is the best publicly available system which is trained on the same data.
</prevsent>
<prevsent>we have downloaded the stanford ner tagger and used the strongest provided model trained on the conll03data with distributional similarity features.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
there sults we obtained on the conll03 test set were consistent with what was reported in (finkel et al, 2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>our goal was to compare the performance ofthe taggers across several datasets.
</nextsent>
<nextsent>for the most realistic comparison, we have presented each system with raw text, and relied on the systems sentence splitter and tokenizer.
</nextsent>
<nextsent>when evaluating the systems, we matched against the gold tokenization ignoring punctuation marks.
</nextsent>
<nextsent>table 6 summarizes the results.note that due to differences in sentence splitting, tokenization and evaluation, these results are not identical to those reported in table 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1823">
<title id=" W08-1406.xml">mixed source multi document speechtotext summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, while text summarization has attained some degree of success (hovy, 2003; mckeown et al, 2005; sparck jones, 2007) due tothe considerable body of work, speech summarization still requires further research, both in speech and text analysis, in order to overcome the specific challenges of the task (mckeown et al, 2005; furui, 2007).
</prevsent>
<prevsent>issues like speech recognition errors,disfluencies, and difficulties inaccurately identifying sentence boundaries must be taken into account when summarizing spoken language.
</prevsent>
</prevsection>
<citsent citstr=" N06-1047 ">
how ever, if on the one hand, recognition errors seemnot to have considerable impact on the summarization task (murray et al, 2006; <papid> N06-1047 </papid>murray et al,2005), on the other hand, spoken language summarization systems often explore ways of minimizing that impact (zechner and waibel, 2000; hori et al, 2003; kikuchi et al, 2003).we argue that by including related solid back ground information from different source less prone to this kind of errors (e.g., textual source) 33in the summarization process, we are able to reduce the influence of recognition errors on the resulting summary.</citsent>
<aftsection>
<nextsent>to support this argument, we developed new approach to speech-to-text summarization that combines information from multiple information sources to produce summary driven by the spoken language document to be summarized.
</nextsent>
<nextsent>the idea mimics the natural human behavior, in which information acquired from different sources is used to build better understanding of given topic (wan et al, 2007).
</nextsent>
<nextsent>furthermore, webuild on the conjecture that this background information is often used by humans to overcome perception difficulties.
</nextsent>
<nextsent>in that sense, one of our goalsis also to understand what is expected in sum mary: comprehensive, shorter, text that addresses the same subject of the input source to be summarized (possibly introducing new information); or text restricted to the information conveyed in the input source.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1828">
<title id=" W08-1406.xml">mixed source multi document speechtotext summarization </title>
<section> working in the phonetic domain.  </section>
<citcontext>
<prevsection>
<prevsent>the phone features used are described in table 1.
</prevsent>
<prevsent>the computation of the similarity between sentence-like units is based on the alignment of the phonetic transcriptions of the given segments.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
the generation of the possible alignments and the selection of the best alignment is done through the use of weighted finite-state transducers (wf sts) (mohri, 1997; <papid> J97-2003 </papid>paulo and oliveira, 2002).</citsent>
<aftsection>
<nextsent>35 4.2 threshold estimation process.
</nextsent>
<nextsent>to estimate the threshold to be used in the sentence selection process, we use the algorithm presented in figure 1.
</nextsent>
<nextsent>the procedure consists of comparing automatic transcriptions and their hand-correctedversions: the output is the average difference between the submitted inputs.
</nextsent>
<nextsent>phonetic transliteration phonetic transliteration sentence segmented asr output manual transcription projection of the sentences of the asr ouput over the manual transcription sentence segmented manual transcriptionsentence-by sentence distance calculation figure 1: threshold estimation process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1829">
<title id=" W08-1406.xml">mixed source multi document speechtotext summarization </title>
<section> a case study using broadcast news </section>
<citcontext>
<prevsection>
<prevsent>since the abs tractive summaries had already been created, summary size was determined by their size (which means creating summaries using compression rate of around 10% of the original size).as mentioned before, the whole summarization process begins with the selection of the back ground information.
</prevsent>
<prevsent>using the threshold estimate das described in section 4.2 and the method described in section 4.1 to compute similarity between sentence-like units, no background information was selected for 11 of the 26 news stories ofthe test corpus.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
for the remaining 15 news stories, summaries were generated using the three automatic summarization strategies described before.in what concerns the evaluation process, although rouge (lin, 2004) <papid> W04-1013 </papid>is the most common evaluation metric for the automatic evaluation of summarization, since our approach might introduce in the summary information that it is not present in the original input source, we found that human evaluation was more adequate to assess the relevance of that additional information.</citsent>
<aftsection>
<nextsent>a perceptual evaluation is also adequate to assess the perceive quality of the summaries and better indicator of the what is expected to be in summary.
</nextsent>
<nextsent>we asked an heterogeneous group of sixteen people to evaluate the summaries created for the 15 news stories for which background information 1 http://www.gnu.org/software/gsl/ 37 0 20 40 60 80 100 120 simple (news only) background only background + news human extractive human abs tractive ns00 ns01 ns02 ns03 ns04 ns05 ns06 ns07 ns08 ns09 ns10 ns11 ns12 ns13 ns14 figure 2: overall results for each summary creation method (nsnn identifies news story).
</nextsent>
<nextsent>was selected.
</nextsent>
<nextsent>each evaluator was given, for each story, the news story itself (without background in formation) and five summaries, corresponding to the five different methods presented before.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1830">
<title id=" W08-1403.xml">automatic construction of domain specific dictionaries on sparse parallel corpora in the nordic languages </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>suite for word alignment that was used in nystrm et al(2006) on medical parallel corpus, containing 174 000 swedish words and 153 000 english words, created 31 000 word pairs with 76 percent precision and 77 percent recall.
</prevsent>
<prevsent>in this work the word alignment was produced interactively.
</prevsent>
</prevsection>
<citsent citstr=" W05-0809 ">
a shared task on languages with sparse resources is described in martinet al(2005).<papid> W05-0809 </papid></citsent>
<aftsection>
<nextsent>the language pairs processed were english-inuktitut, romanian-english and english-hindi, where the english-inuktitut parallel corpus contained around 4 million words for english and 2 millions words for inuktitut.
</nextsent>
<nextsent>english-hindi had less words, 60 000 words and 70 000 words respectively.
</nextsent>
<nextsent>the languages with the largest corpora obtained best word alignment results, for eng lish-inuktitut over 90 percent precision and recall and for english-hindi 77 percent precision and 68 percent recall.
</nextsent>
<nextsent>one conclusion from the shared task was that it is worth using additional resources for languages with very sparse corpora improving results with up to 20 percent but not for the languages with more abundant corpora such as for instance english-inuktitut.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1831">
<title id=" W08-1403.xml">automatic construction of domain specific dictionaries on sparse parallel corpora in the nordic languages </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 word alignment: uplug.
</prevsent>
<prevsent>we have chosen to use the uplug word alignment system since it is non-commercial system which does not need pre-trained model and is easy to use.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
it is also updated continuously and incorporates other alignment models, such as giza++ (och &amp; ney 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>we did not want to evaluate the performance of different systems in the work presented here, but rather evaluate the performance of only one system applied on different language combinations and on sparse corpora.
</nextsent>
<nextsent>evaluating the performance of different systems is an important and interesting research problem, but is left for future work.
</nextsent>
<nextsent>an evaluation of two word alignment systems plug (uplug) and arcade is described in ahrenberg et al (2000).
</nextsent>
<nextsent>the uplug system implements word alignment process that combines different statistical measures for finding word alignment candidates and is fully automatic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1832">
<title id=" W08-1403.xml">automatic construction of domain specific dictionaries on sparse parallel corpora in the nordic languages </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>the corpora were to some extent non-parallel containing some extra non-parallel paragraphs.
</prevsent>
<prevsent>we found that around five percent of the corpora were non-parallel.
</prevsent>
</prevsection>
<citsent citstr=" P06-1011 ">
in order to detect non-parallel sections we have used simpler algorithm than in for instance munteanu &amp; marcu (2006).<papid> P06-1011 </papid></citsent>
<aftsection>
<nextsent>the total number of paragraphs and sentences in each 3 see: http://cst.dk/download/cstlemma/current/doc/.
</nextsent>
<nextsent>parallel text pair were counted.
</nextsent>
<nextsent>if the total number for each language in some language pair differed more than 20 percent these files were deleted.
</nextsent>
<nextsent>the refined corpora have been re-aligned with uplug and evaluated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1833">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the concepts in an ontology are generally arranged in deep class/subclass hierarchies, the problem of populating ontologies is typically solved top-down, firstly identifying and classifying entities in the most general concepts, and then refining the classification process.recent advances have made supervised approaches very successful in entity identification andclassification.
</prevsent>
<prevsent>however, to achieve satisfactory performance, supervised systems must be supplied with sufficiently large amount of training data, usually consisting of hand tagged texts.
</prevsent>
</prevsection>
<citsent citstr=" E06-1003 ">
as domain specific ontologies generally contains hundreds of subcategories, such approaches are not directly applicable for more fine-grained categorization because the number of documents required to find sufficient positive examples for all subclasses becomes too large, making the manual annotation very expensive.consequently, in the literature, supervised approaches are confined to classify entities into broad categories, such as persons, locations, and organizations, while the fine-grained classification has been approached with minimally supervised (e.g., tanev and magnini (2006) <papid> E06-1003 </papid>and giuliano and gliozzo (2008)) <papid> C08-1034 </papid>and unsupervised learning algorithms (e.g., cimiano and volker (2005) and giuliano and gliozzo (2007)).<papid> D07-1026 </papid>following this trend, we present minimally supervised approach to fine-grained categorization ofnamed entities previously recognized into coarse grained categories, e.g., by named-entity recog nizer.</citsent>
<aftsection>
<nextsent>the only training data for our algorithm is few manually annotated entities for each class.
</nextsent>
<nextsent>for example, niels bohr, albert einstein, and enrico fermi might be used as examples for the class physicists.
</nextsent>
<nextsent>in some cases, training entities can be acquired(semi-) automatically from existing ontologies allowing us to automatically derive training entities for use with our machine learning algorithm.
</nextsent>
<nextsent>for instance, we may easily obtain tens of training entities for very specific classes, such as astronomers, materials scientists, nuclear physicists, by querying the yago ontology (suchanek et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1837">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the concepts in an ontology are generally arranged in deep class/subclass hierarchies, the problem of populating ontologies is typically solved top-down, firstly identifying and classifying entities in the most general concepts, and then refining the classification process.recent advances have made supervised approaches very successful in entity identification andclassification.
</prevsent>
<prevsent>however, to achieve satisfactory performance, supervised systems must be supplied with sufficiently large amount of training data, usually consisting of hand tagged texts.
</prevsent>
</prevsection>
<citsent citstr=" C08-1034 ">
as domain specific ontologies generally contains hundreds of subcategories, such approaches are not directly applicable for more fine-grained categorization because the number of documents required to find sufficient positive examples for all subclasses becomes too large, making the manual annotation very expensive.consequently, in the literature, supervised approaches are confined to classify entities into broad categories, such as persons, locations, and organizations, while the fine-grained classification has been approached with minimally supervised (e.g., tanev and magnini (2006) <papid> E06-1003 </papid>and giuliano and gliozzo (2008)) <papid> C08-1034 </papid>and unsupervised learning algorithms (e.g., cimiano and volker (2005) and giuliano and gliozzo (2007)).<papid> D07-1026 </papid>following this trend, we present minimally supervised approach to fine-grained categorization ofnamed entities previously recognized into coarse grained categories, e.g., by named-entity recog nizer.</citsent>
<aftsection>
<nextsent>the only training data for our algorithm is few manually annotated entities for each class.
</nextsent>
<nextsent>for example, niels bohr, albert einstein, and enrico fermi might be used as examples for the class physicists.
</nextsent>
<nextsent>in some cases, training entities can be acquired(semi-) automatically from existing ontologies allowing us to automatically derive training entities for use with our machine learning algorithm.
</nextsent>
<nextsent>for instance, we may easily obtain tens of training entities for very specific classes, such as astronomers, materials scientists, nuclear physicists, by querying the yago ontology (suchanek et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1838">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the concepts in an ontology are generally arranged in deep class/subclass hierarchies, the problem of populating ontologies is typically solved top-down, firstly identifying and classifying entities in the most general concepts, and then refining the classification process.recent advances have made supervised approaches very successful in entity identification andclassification.
</prevsent>
<prevsent>however, to achieve satisfactory performance, supervised systems must be supplied with sufficiently large amount of training data, usually consisting of hand tagged texts.
</prevsent>
</prevsection>
<citsent citstr=" D07-1026 ">
as domain specific ontologies generally contains hundreds of subcategories, such approaches are not directly applicable for more fine-grained categorization because the number of documents required to find sufficient positive examples for all subclasses becomes too large, making the manual annotation very expensive.consequently, in the literature, supervised approaches are confined to classify entities into broad categories, such as persons, locations, and organizations, while the fine-grained classification has been approached with minimally supervised (e.g., tanev and magnini (2006) <papid> E06-1003 </papid>and giuliano and gliozzo (2008)) <papid> C08-1034 </papid>and unsupervised learning algorithms (e.g., cimiano and volker (2005) and giuliano and gliozzo (2007)).<papid> D07-1026 </papid>following this trend, we present minimally supervised approach to fine-grained categorization ofnamed entities previously recognized into coarse grained categories, e.g., by named-entity recog nizer.</citsent>
<aftsection>
<nextsent>the only training data for our algorithm is few manually annotated entities for each class.
</nextsent>
<nextsent>for example, niels bohr, albert einstein, and enrico fermi might be used as examples for the class physicists.
</nextsent>
<nextsent>in some cases, training entities can be acquired(semi-) automatically from existing ontologies allowing us to automatically derive training entities for use with our machine learning algorithm.
</nextsent>
<nextsent>for instance, we may easily obtain tens of training entities for very specific classes, such as astronomers, materials scientists, nuclear physicists, by querying the yago ontology (suchanek et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1845">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach achieves significant improvement over the state of the art for the task of populating the people ontology (giuliano and gliozzo, 2008), <papid> C08-1034 </papid>although requiring considerably less training instances than previous approaches.</prevsent>
<prevsent>the task consists in classifying person names into multi-level taxonomy composed of 21 categories derived from wordnet,making very fine-grained distinctions (e.g., physicists vs. mathematicians).</prevsent>
</prevsection>
<citsent citstr=" C02-1130 ">
it provides more realistic and challenging benchmark than the ones previously available (e.g., tanev and magnini (2006) <papid> E06-1003 </papid>and fleischman and hovy (2002)), <papid> C02-1130 </papid>that consider smaller number of categories arranged in one-level taxonomy.</citsent>
<aftsection>
<nextsent>the goal of our research is to determine the fine grained categories of named entities requiring minimal amount of human supervision.our method is based on the common assumption that named entities co-occurring with the same (domain-specific) terms are highly probable to referto the same categories.
</nextsent>
<nextsent>for example, quantum mechanics, atomic physics, and nobel prize in physics are all terms that bound niels bohr and enrico fermi to the concept of physics.
</nextsent>
<nextsent>to automatically derive features for the training and testing entities we proceed as follows.
</nextsent>
<nextsent>we pair each entity with multi-context mi obtained by querying search engine with the entity i? and merging the first snippets si,j returned (1 6 6m ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1847">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> kernels for fine-grained classification.  </section>
<citcontext>
<prevsection>
<prevsent>to this aim, in the next section, we introduce the class of semantic kernels and showhow to define an effective semantic vsm using (un labeled) external knowledge.
</prevsent>
<prevsent>3.2 semantic kernels.
</prevsent>
</prevsection>
<citsent citstr=" P05-1050 ">
it has been shown that semantic information is fundamental for improving the accuracy and reducing the amount of training data in many natural language tasks, including fine-grained classification of named entities (fleischman and hovy, 2002), <papid> C02-1130 </papid>question classification (li and roth, 2005), text categorization(giozzo and strapparava, 2005), word sense disambiguation (gliozzo et al, 2005).<papid> P05-1050 </papid>in the context of kernel methods, semantic information can be integrated considering linear transformations of the type ??(cj) = ?(cj)s, where is n ? matrix (shawe-taylor and cristianini, 2004).</citsent>
<aftsection>
<nextsent>the matrix can be rewritten as = wp, where is diagonal matrix determining the word weights, while is the word proximity matrix capturing the semantic relations between words.
</nextsent>
<nextsent>the proximity matrix can be defined by setting non zero entries between those words whose semantic relation is inferred from an external source of domain knowledge.
</nextsent>
<nextsent>the semantic kernel takes the general form k?(mi,mj) = ?(mi)ss??(mj)?
</nextsent>
<nextsent>= ??(mi)??(mj)?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1854">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in more realistic scenario, the result of search engine for person name is usually mix of contexts about different entities sharing the same name.
</prevsent>
<prevsent>in this case, our approach have to be combined with system that clusters the search engine result, where each cluster is assumed to contain all (and only those) contexts that refer to the same entity.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
the weps evaluation campaign on disambiguation of person names (artiles et al., 2007; <papid> W07-2012 </papid>artiles et al, 2009) has shown that the best clustering systems achieve precision of about 90% 206 scientist performer creator communicator business health phy mat che bio soc act mus fil pai mus poe dra rep man prof phy 118 24 10 4 2 0 0 0 0 0 0 0 0 7 2 mat 2 33 0 0 1 0 0 0 0 0 1 0 0 3 0 che 13 2 68 9 2 0 0 0 0 0 0 0 0 5 2 bio 3 0 7 52 0 0 0 0 1 0 0 0 1 6 6 soc 0 4 1 1 55 0 0 0 0 0 3 1 1 4 2 act 0 0 0 0 0 98 5 27 0 0 2 14 0 3 0 mus 0 0 0 0 0 17 67 0 0 32 1 0 1 2 1 fil 0 0 0 0 0 13 0 45 0 0 1 4 0 2 0 pai 0 0 0 1 1 2 0 1 100 0 1 0 0 1 0 mus 0 0 0 0 0 4 29 0 0 139 0 1 0 0 0 poe 0 2 0 0 0 0 0 0 7 3 98 26 1 2 3 dra 0 0 0 1 1 9 0 1 0 1 12 61 1 4 1 rep 0 0 0 0 0 1 1 0 2 0 0 0 197 22 0 bus 1 0 1 0 1 0 0 1 0 1 0 0 1 36 0 hea 0 0 0 8 4 0 1 0 0 0 0 1 1 2 31 table 3: confusion matrix of kbow +kw for the more fine-grained categories grouped according to their top-level concepts of the people ontology.</citsent>
<aftsection>
<nextsent>category prec.
</nextsent>
<nextsent>recall f1 scientist 95.1 90.1 92.6 physicist 86.1 70.7 77.6 mathematician 50.8 82.5 62.9 chemist 78.2 67.3 72.3 biologist 68.4 68.4 68.4 social scientist 82.1 76.4 79.1 performer 75.7 69.3 72.3 actor 68.1 65.8 66.9 musician 65.0 55.4 59.8 creator 78.9 82.6 80.7 filmmaker 60.0 69.2 64.3 artist 83.6 85.4 84.5 painter 90.9 93.5 92.2 musician 79.0 80.3 79.7 communicator 91.9 86.7 89.2 representative 96.6 88.3 92.3 writer 86.8 84.2 85.5 poet 82.4 69.0 75.1 dramatist 56.5 66.3 61.0 business man 36.4 85.7 51.1 health professional 64.6 64.6 64.6 micro 80.9 79.6 80.2 macro 75.1 76.3 75.7 table 2: results for each category using kbow +kw .and recall of about 70% and that, in the majority of the cases, the number of contexts per entity is less than 20.
</nextsent>
<nextsent>this shows that latent semantic kernels are an effective tool for fine-grained classification of person names.finally, table 3 shows that misclassification errors are largely distributed among categories belonging to the same super-class (i.e., the blocks on themain diagonal are more densely populated than others).
</nextsent>
<nextsent>as expected, the algorithm is much more accurate for the top-level concepts (i.e., scientist, communicator, etc.), where the category distinctions are clearer, while further fine-grained classification, in some cases, is even difficult for human annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1866">
<title id=" W09-1125.xml">fine grained classification of named entities exploiting latent semantic kernels </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>ganti et al (2008) present method that consider san entitys context across multiple documents containing it, and exploiting word n-grams and existing large list of related entities as features.
</prevsent>
<prevsent>they generated training and test data using wikipedia articles that contain list of instances.
</prevsent>
</prevsection>
<citsent citstr=" D08-1061 ">
they compare their system with single-context classifier, showing that their approach based on aggregate context perform better.finally, talukdar et al (2008) <papid> D08-1061 </papid>propose graph based semi-supervised label propagation algorithm for acquiring open-domain labeled classes and their instances from combination of unstructured and structured text.</citsent>
<aftsection>
<nextsent>we presented an approach to automatic fine-grained categorization of named entities based on kernel methods.
</nextsent>
<nextsent>entities are represented by aggregating all contexts in which they occur.
</nextsent>
<nextsent>we employed latent semantic kernels to extend the bag-of-words representation.
</nextsent>
<nextsent>the latent semantic models were derived from wikipedia and news corpus we evaluated our approach on the people ontology, multi-level ontology of people derived from wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1867">
<title id=" W09-0716.xml">an ontology for accessing transcription systems oats </title>
<section> inter operating over transcription.  </section>
<citcontext>
<prevsection>
<prevsent>however, what first seem to be trivial differences, illustrate one issue of resource discovery on the web ? without methods for interoperability, even slightly divergent resources are more difficult to discover,query and compare.
</prevsent>
<prevsent>how would someone researching comparative analysis of /?/ sounds of languages in northern ghana discover that it is represented as  ky  and  ch  without first locating the extremely sparse grammatical information available on these languages?
</prevsent>
</prevsection>
<citsent citstr=" W06-1709 ">
furthermore,automatic phonetic research is possible on languages with shallow orthographies (zuraw, 2006), <papid> W06-1709 </papid>but cross linguistic versions of such work require inter operation overwriting systems.</citsent>
<aftsection>
<nextsent>3.2 technological challenges.
</nextsent>
<nextsent>the main technological challenges in inter operating over textual electronic resources are: encoding multilingual language text in an interoperable format and resolving ambiguity between mapping relations.
</nextsent>
<nextsent>these are addressed below.hundreds of character encoding sets for writing systems have been developed, e.g. ascii, gb 180306 and unicode.
</nextsent>
<nextsent>historically, different standards were formalized differently and for different purposes by different standards committees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1868">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many research systems offer the option to filter the models at load time or offline, so that only information pertaining to tokens that occur in given in put is kept in memory; all other database entries areskipped.
</prevsent>
<prevsent>language model implementations that offer model filtering at load time include the srilmtoolkit (stolcke, 2002) and the portage lm implementation (badr et al, 2007).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for translation tables, the moses system (koehn et al, 2007) <papid> P07-2045 </papid>as well as portage offer model filtering (moses: offline; portage: offline and/or at load time).</citsent>
<aftsection>
<nextsent>model filtering requires that the input is known when the respective program is started and therefore is not feasible for server implementations.
</nextsent>
<nextsent>4.3 on-demand loading.
</nextsent>
<nextsent>a variant of model filtering that is also viable for server implementations is on-demand loading.
</nextsent>
<nextsent>in the context of smt, zens and ney (2007) <papid> N07-1062 </papid>store the phrase table on disk, represented as trie with relative offsets, so that sections of the trie can be loaded into memory without rebuilding them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1869">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 on-demand loading.
</prevsent>
<prevsent>a variant of model filtering that is also viable for server implementations is on-demand loading.
</prevsent>
</prevsection>
<citsent citstr=" N07-1062 ">
in the context of smt, zens and ney (2007) <papid> N07-1062 </papid>store the phrase table on disk, represented as trie with relative offsets, so that sections of the trie can be loaded into memory without rebuilding them.</citsent>
<aftsection>
<nextsent>during translation, only those sections of the trie that actually match the input are loaded into memory.
</nextsent>
<nextsent>they report that their approach is not slower than the traditional approach?, which has significant load time overhead.
</nextsent>
<nextsent>they do not provide comparison of pure processing speed ignoring the initial table load time overhead of the traditional approach?.
</nextsent>
<nextsent>irstlm (federico and cettolo, 2007) <papid> W07-0712 </papid>offers the option to use custom page manager that relegates part of the structure to disk via memory-mappedfiles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1870">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they report that their approach is not slower than the traditional approach?, which has significant load time overhead.
</prevsent>
<prevsent>they do not provide comparison of pure processing speed ignoring the initial table load time overhead of the traditional approach?.
</prevsent>
</prevsection>
<citsent citstr=" W07-0712 ">
irstlm (federico and cettolo, 2007) <papid> W07-0712 </papid>offers the option to use custom page manager that relegates part of the structure to disk via memory-mappedfiles.</citsent>
<aftsection>
<nextsent>the difference with our use of memory mapping is that irstlm still builds the structure in memory and then swaps part of it out to disk.
</nextsent>
<nextsent>35 4.4 lossy compression and pruning.
</nextsent>
<nextsent>large models can also be reduced in size by lossy compression.
</nextsent>
<nextsent>both srilm and irstlm offer tools for language model pruning (stolcke, 1998): if probability values for long contexts can be approximate dwell by the back-off computation, the respective entries are dropped.another form of lossy compression is the quan tization of probability values and back-off weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1871">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>both srilm and irstlm offer tools for language model pruning (stolcke, 1998): if probability values for long contexts can be approximate dwell by the back-off computation, the respective entries are dropped.another form of lossy compression is the quan tization of probability values and back-off weights.
</prevsent>
<prevsent>whittaker and raj (2001) use pruning, quantizationand difference encoding to store language model parameters in as little as 4 bits per value, reducing language model sizes by to 60% with minimal loss in recognition performance.?
</prevsent>
</prevsection>
<citsent citstr=" W06-3113 ">
federico and bertoldi (2006) <papid> W06-3113 </papid>show that the performance of an smt system does not suffer if lm parameters are quant ized into 256 distinct classes (8 bits per value).</citsent>
<aftsection>
<nextsent>johnson et al (2007) <papid> D07-1103 </papid>use significance tests to eliminate poor candidates from phrase tables for smt.</nextsent>
<nextsent>they are able to eliminate 90% of the phrase table entries without an adverse effect on translation quality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1872">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>whittaker and raj (2001) use pruning, quantizationand difference encoding to store language model parameters in as little as 4 bits per value, reducing language model sizes by to 60% with minimal loss in recognition performance.?
</prevsent>
<prevsent>federico and bertoldi (2006) <papid> W06-3113 </papid>show that the performance of an smt system does not suffer if lm parameters are quant ized into 256 distinct classes (8 bits per value).</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
johnson et al (2007) <papid> D07-1103 </papid>use significance tests to eliminate poor candidates from phrase tables for smt.</citsent>
<aftsection>
<nextsent>they are able to eliminate 90% of the phrase table entries without an adverse effect on translation quality.
</nextsent>
<nextsent>pruning and lossy compression are orthogonal to the approach taken in tpts.
</nextsent>
<nextsent>the two approaches can be combined to achieve even more compact language models and phrase tables.
</nextsent>
<nextsent>4.5 hash functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1873">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with hash-based implementations, the keys are usually not stored at all in the database; hash collisions and therefore lookup errors are the price to be paid for compact storage.
</prevsent>
<prevsent>this risk can be controlled by the design of the hash function.
</prevsent>
</prevsection>
<citsent citstr=" P08-1058 ">
talbot and brants (2008) <papid> P08-1058 </papid>show that bloomier filters (chazelle et al, 2004) can be used to create perfect hash functions for language models.</citsent>
<aftsection>
<nextsent>this guarantees that there are no collisions between existing entries in the database but does not eliminate the risk of false positives for items that are not in the database.
</nextsent>
<nextsent>for situations where space is at premium and speed negotiable (e.g., in interactive context-based spelling correction, where the number of lookups isnot in the range of thousands or millions per second), church et al (2007) <papid> D07-1021 </papid>present compressed trigram model that combines stolcke (1998) pruning with golomb (1966) coding of inter-arrival times in the (sparse) range of hash values computed by the hash function.</nextsent>
<nextsent>one major drawback of their method of storage is that search is linear in the total number of keys in the worst case (usually mediated by auxiliary data structures that cache information).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1874">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>talbot and brants (2008) <papid> P08-1058 </papid>show that bloomier filters (chazelle et al, 2004) can be used to create perfect hash functions for language models.</prevsent>
<prevsent>this guarantees that there are no collisions between existing entries in the database but does not eliminate the risk of false positives for items that are not in the database.</prevsent>
</prevsection>
<citsent citstr=" D07-1021 ">
for situations where space is at premium and speed negotiable (e.g., in interactive context-based spelling correction, where the number of lookups isnot in the range of thousands or millions per second), church et al (2007) <papid> D07-1021 </papid>present compressed trigram model that combines stolcke (1998) pruning with golomb (1966) coding of inter-arrival times in the (sparse) range of hash values computed by the hash function.</citsent>
<aftsection>
<nextsent>one major drawback of their method of storage is that search is linear in the total number of keys in the worst case (usually mediated by auxiliary data structures that cache information).
</nextsent>
<nextsent>since hash-based implementations of token sequence-based nlp databases usually dont store the search keys, it is not possible to iterate through such databases.
</nextsent>
<nextsent>4.6 distributed implementations.
</nextsent>
<nextsent>brants et al (2007) <papid> D07-1090 </papid>present an lm implementation that distributes very large language models over network of language model servers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1875">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>since hash-based implementations of token sequence-based nlp databases usually dont store the search keys, it is not possible to iterate through such databases.
</prevsent>
<prevsent>4.6 distributed implementations.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
brants et al (2007) <papid> D07-1090 </papid>present an lm implementation that distributes very large language models over network of language model servers.</citsent>
<aftsection>
<nextsent>the delay dueto network latency makes it inefficient to issue individual lookup requests to distributed language models.
</nextsent>
<nextsent>as brants et al point out: onboard memory is around 10,000 times faster?
</nextsent>
<nextsent>than access via the network.
</nextsent>
<nextsent>instead, requests are batched and sent to the server in chunks of 1,000 or 10,000 requests.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1877">
<title id=" W09-1505.xml">tightly packed tries how to fit large models into memory and make them load fast too </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>15s 5.0 1.0 154s 5.5 0.12   1s 5.3 5.2 baseline: port ages implementation as pointer structure with load-time filtering.
</prevsent>
<prevsent>tp: tightly packed; pt: phrase table; lm: language model 1 words per second, excluding load time (pure translation time after model loading) 2 words per second, including load time (bottom line translation speed) 5.2 tpts in statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" W05-0822 ">
to test the usefulness of tpts in more realistic setting, we integrated them into the portage smt system (sadat et al, 2005) <papid> W05-0822 </papid>and ran large-scale translations in parallel batch processes on cluster.</citsent>
<aftsection>
<nextsent>both language models and translation tables were encoded as tpts and compared against the native portage implementation.
</nextsent>
<nextsent>the system was trained on ca.
</nextsent>
<nextsent>5.2 million parallel sentences from the canadian hansard (english: 101 million tokens; french: 113 million tokens).
</nextsent>
<nextsent>the language model statistics are given in table 2; the phrase table contained about 60.6 million pairs of phrases up to length 8.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1878">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>from there, we use lexical information to combine contexts in way which preserves the intended category, providing aplatform for grammatical category induction.
</prevsent>
<prevsent>in human category acquisition, the immediate local context of word has proven to be reliable indicator of its grammatical category, or part of speech (e.g., mintz, 2002, 2003; redington et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
likewise, category induction techniques cluster word types together (e.g., clark, 2003; <papid> E03-1009 </papid>schutze, 1995), using similar information, i.e., distributions of local context information.</citsent>
<aftsection>
<nextsent>these methods are successful and useful (e.g. koo et al, 2008), <papid> P08-1068 </papid>but in both cases it is not always clear whether errors in lexical classification are due to aproblem in the induction algorithm or in what contexts count as identifying the same category (cf.</nextsent>
<nextsent>dickinson, 2008).<papid> C08-1026 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1882">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in human category acquisition, the immediate local context of word has proven to be reliable indicator of its grammatical category, or part of speech (e.g., mintz, 2002, 2003; redington et al, 1998).
</prevsent>
<prevsent>likewise, category induction techniques cluster word types together (e.g., clark, 2003; <papid> E03-1009 </papid>schutze, 1995), using similar information, i.e., distributions of local context information.</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
these methods are successful and useful (e.g. koo et al, 2008), <papid> P08-1068 </papid>but in both cases it is not always clear whether errors in lexical classification are due to aproblem in the induction algorithm or in what contexts count as identifying the same category (cf.</citsent>
<aftsection>
<nextsent>dickinson, 2008).<papid> C08-1026 </papid></nextsent>
<nextsent>the question we ask, then, is:what role does the context on its own play in defining grammatical category?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1883">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>likewise, category induction techniques cluster word types together (e.g., clark, 2003; <papid> E03-1009 </papid>schutze, 1995), using similar information, i.e., distributions of local context information.</prevsent>
<prevsent>these methods are successful and useful (e.g. koo et al, 2008), <papid> P08-1068 </papid>but in both cases it is not always clear whether errors in lexical classification are due to aproblem in the induction algorithm or in what contexts count as identifying the same category (cf.</prevsent>
</prevsection>
<citsent citstr=" C08-1026 ">
dickinson, 2008).<papid> C08-1026 </papid></citsent>
<aftsection>
<nextsent>the question we ask, then, is:what role does the context on its own play in defining grammatical category?
</nextsent>
<nextsent>specifically, when do two contexts identify the same category?
</nextsent>
<nextsent>many category induction experiments start by trying to categorize words, and parisien et al (2008) <papid> W08-2112 </papid>categorize word usages, combination of word and its context.</nextsent>
<nextsent>but to isolate the effect the context has on the word, we take the approach of categorizing contexts as first step towards clustering words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1887">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the question we ask, then, is:what role does the context on its own play in defining grammatical category?
</prevsent>
<prevsent>specifically, when do two contexts identify the same category?
</prevsent>
</prevsection>
<citsent citstr=" W08-2112 ">
many category induction experiments start by trying to categorize words, and parisien et al (2008) <papid> W08-2112 </papid>categorize word usages, combination of word and its context.</citsent>
<aftsection>
<nextsent>but to isolate the effect the context has on the word, we take the approach of categorizing contexts as first step towards clustering words.
</nextsent>
<nextsent>by separating out contexts for word clustering, we can begin to speak of better disambiguation models as foundation for induction.
</nextsent>
<nextsent>we aim in this paper to thoroughly investigate what category properties contexts can or can not distinguish by themselves.with this approach, we are able to more thoroughly examine the categories used for evaluation.
</nextsent>
<nextsent>evaluation of induction methods is difficult, due to the variety of corpora and tagsets in existence (seediscussion in clark, 2003) <papid> E03-1009 </papid>and the variety of potential purposes for induced categories (e.g., koo et al, 2008; <papid> P08-1068 </papid>miller et al, 2004).<papid> N04-1043 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1890">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>by separating out contexts for word clustering, we can begin to speak of better disambiguation models as foundation for induction.
</prevsent>
<prevsent>we aim in this paper to thoroughly investigate what category properties contexts can or can not distinguish by themselves.with this approach, we are able to more thoroughly examine the categories used for evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
evaluation of induction methods is difficult, due to the variety of corpora and tagsets in existence (seediscussion in clark, 2003) <papid> E03-1009 </papid>and the variety of potential purposes for induced categories (e.g., koo et al, 2008; <papid> P08-1068 </papid>miller et al, 2004).<papid> N04-1043 </papid></citsent>
<aftsection>
<nextsent>yet improving the evaluation of category induction is vital, as evaluation does not match up well with grammar induction evaluation (headden iii et al, 2008).
</nextsent>
<nextsent>for many evaluations, pos tags have been mapped to smaller tagset (e.g., goldwater and griffiths, 2007; <papid> P07-1094 </papid>toutanova and johnson, 2008), but there have been few criteria for evaluating the quality of these mappings.</nextsent>
<nextsent>by isolating contexts, we can investigate how each mapping affects the accuracy of method and the lexicon.using corpus annotation also allows us to explore the relation between induced categories and computationally or theoretically-relevant categories (e.g., elworthy, 1995).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1891">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>evaluation of induction methods is difficult, due to the variety of corpora and tagsets in existence (seediscussion in clark, 2003) <papid> E03-1009 </papid>and the variety of potential purposes for induced categories (e.g., koo et al, 2008; <papid> P08-1068 </papid>miller et al, 2004).<papid> N04-1043 </papid></prevsent>
<prevsent>yet improving the evaluation of category induction is vital, as evaluation does not match up well with grammar induction evaluation (headden iii et al, 2008).</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
for many evaluations, pos tags have been mapped to smaller tagset (e.g., goldwater and griffiths, 2007; <papid> P07-1094 </papid>toutanova and johnson, 2008), but there have been few criteria for evaluating the quality of these mappings.</citsent>
<aftsection>
<nextsent>by isolating contexts, we can investigate how each mapping affects the accuracy of method and the lexicon.using corpus annotation also allows us to explore the relation between induced categories and computationally or theoretically-relevant categories (e.g., elworthy, 1995).
</nextsent>
<nextsent>while human category acquisition results successfully divide lexicon into categories, these categories are not necessarily ones which are appropriate for many computational purposes or match theoretical syntactic analysis.
</nextsent>
<nextsent>this work can also serve as platform to help drive the design of new tagsets, or refinement of old ones, by outlining which types of categories are or are not applicable for category induction.after discussing some preliminary issues in section 2, in section 3 we examine to what extent contexts by themselves can distinguish different category properties and how this affects evaluation.
</nextsent>
<nextsent>namely, we propose that corpus tagsets should be clear about identifying syntactic/distributional properties and about how tagset mappings for evaluation should outline how much information 34is lost by mapping.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1897">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>indeed, accuracies slightly degrade when moving from standard labeling2 to the more fine-grained expanded la beling,3 from .98 to .91 in token accuracy and from .93 to .91 in type accuracy.
</prevsent>
<prevsent>in scaling the method beyond child-directed speech, it would be beneficial to use annotated data, which allows for ambiguity and distinguishes words category across corpus instances.
</prevsent>
</prevsection>
<citsent citstr=" P03-1009 ">
furthermore, even though many frames identify the same category,1this use of frame is different than that used for subcategorization frames, which are also used to induce word classes (e.g., korhonen et al, 2003).<papid> P03-1009 </papid></citsent>
<aftsection>
<nextsent>2categories = noun, verb, adjective, preposition, adverb, determiner, wh-word, not, conjunction, and interjection.
</nextsent>
<nextsent>3nouns split into nouns and pronouns; verbs split into verbs, auxiliaries, and copulathe method does not thoroughly specify how to relate them.
</nextsent>
<nextsent>it has been recognized for some time that wider contexts result in better induction models (e.g., parisien et al, 2008; <papid> W08-2112 </papid>redington et al, 1998), butmany linguistic distinctions relyon lexical information that cannot be inferred from additional context (dickinson, 2008), <papid> C08-1026 </papid>so focusing on short contexts can provide many insights.</nextsent>
<nextsent>the use of frames allows for frequent recurrent contexts and way to investigate corpus categories, or pos tags (cf., e.g., dickinson and jochim, 2008).<papid> L08-1225 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1900">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>3nouns split into nouns and pronouns; verbs split into verbs, auxiliaries, and copulathe method does not thoroughly specify how to relate them.
</prevsent>
<prevsent>it has been recognized for some time that wider contexts result in better induction models (e.g., parisien et al, 2008; <papid> W08-2112 </papid>redington et al, 1998), butmany linguistic distinctions relyon lexical information that cannot be inferred from additional context (dickinson, 2008), <papid> C08-1026 </papid>so focusing on short contexts can provide many insights.</prevsent>
</prevsection>
<citsent citstr=" L08-1225 ">
the use of frames allows for frequent recurrent contexts and way to investigate corpus categories, or pos tags (cf., e.g., dickinson and jochim, 2008).<papid> L08-1225 </papid></citsent>
<aftsection>
<nextsent>an added benefit of starting with this method is that it can be converted to model of online acquisition (wang and mintz, 2007).
</nextsent>
<nextsent>for this paper, however, we only investigate the type of information input into the model.
</nextsent>
<nextsent>2.2 some definitions.
</nextsent>
<nextsent>frequency the core idea of using frames is that words used in the same context are associated with each other, and the more often these contexts occur, the more confidence we have that the frame indicates category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1911">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> categories in local contexts.  </section>
<citcontext>
<prevsection>
<prevsent>and how fine-grained is the category that the context distinguishes?
</prevsent>
<prevsent>to test whethera frame defines single category in non-child directed speech, we focus on which categorical properties frames define, and for this we use pos-annotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" P08-1085 ">
due to its popularity for unsupervised pos induction research (e.g., goldberg et al, 2008; <papid> P08-1085 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>toutanova and johnson, 2008) and its often-used tagset, for our initial research, we use the wall street journal (wsj) portion of the penn treebank(marcus et al, 1993), <papid> J93-2004 </papid>with 36 tags (plus 9 punctuation tags), and we use sections 00-18, leaving held-out data for future experiments.4 defining frequent frames as those occurring at 4even if we wanted child-directed speech, the childes database (macwhinney, 2000) uses coarse pos tags.</citsent>
<aftsection>
<nextsent>least 200 times, we find 79.5% token precision.
</nextsent>
<nextsent>additionally, we have 99 frames, identifying 14 types of categories as the majority tag (common noun (nn) being the most prevalent (37 frames)).
</nextsent>
<nextsent>for threshold of 2, we have 77.3% precision for 67,721 frames and 35 categories.5 with precision below 80%, we observe that frames are not fully able to disambiguate these corpus categories.
</nextsent>
<nextsent>3.1 frame-defined categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1914">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> categories in local contexts.  </section>
<citcontext>
<prevsection>
<prevsent>and how fine-grained is the category that the context distinguishes?
</prevsent>
<prevsent>to test whethera frame defines single category in non-child directed speech, we focus on which categorical properties frames define, and for this we use pos-annotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
due to its popularity for unsupervised pos induction research (e.g., goldberg et al, 2008; <papid> P08-1085 </papid>goldwater and griffiths, 2007; <papid> P07-1094 </papid>toutanova and johnson, 2008) and its often-used tagset, for our initial research, we use the wall street journal (wsj) portion of the penn treebank(marcus et al, 1993), <papid> J93-2004 </papid>with 36 tags (plus 9 punctuation tags), and we use sections 00-18, leaving held-out data for future experiments.4 defining frequent frames as those occurring at 4even if we wanted child-directed speech, the childes database (macwhinney, 2000) uses coarse pos tags.</citsent>
<aftsection>
<nextsent>least 200 times, we find 79.5% token precision.
</nextsent>
<nextsent>additionally, we have 99 frames, identifying 14 types of categories as the majority tag (common noun (nn) being the most prevalent (37 frames)).
</nextsent>
<nextsent>for threshold of 2, we have 77.3% precision for 67,721 frames and 35 categories.5 with precision below 80%, we observe that frames are not fully able to disambiguate these corpus categories.
</nextsent>
<nextsent>3.1 frame-defined categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1915">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> categories in local contexts.  </section>
<citcontext>
<prevsection>
<prevsent>we start with basic categories, akin to those in mintz (2003).
</prevsent>
<prevsent>despite the differences among tagsets, these basic categories are common, and merging pos tags into basic categories can show that differences inaccuracy have more to do with stricter category labels than language type.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
we merged tags to create basic categories, as in table 1 (adapted from hepple and van genabith (2000); see appendix for descriptions).6 category corpus tags determiner dt, pdt, prp$ adjective jj, jjr, jjs noun nn, nns, prp, nnp, nnps adverb rb, rbr, rbs verb md, vb, vbd, vbg, vbn, vbp, vbz wh-det. wdt, wp$ table 1: tag mappings into basic categories these broader categories result in the accuracies in table 2, and we also record accuracies for the similar ptb-17 tagset used in variety of unsupervised tagging experiments (smith and eisner, 2005), <papid> P05-1044 </papid>which mainly differs by treating vbg and vbn uniquely.</citsent>
<aftsection>
<nextsent>with token precision around 90%,it seems that frame-based disambiguation is generally identifying basic categories, though with less 5ls (list item marker) is not identified; uh (interjection) appears in one repeating frame, and sym (symbol) in two.
</nextsent>
<nextsent>6the 13 other linguistic tags were not merged, i.e., cc, cd, ex, fw, in, ls, pos, rp, sym, to, uh, wp, wrb.
</nextsent>
<nextsent>36 accuracy than in mintz (2003).
</nextsent>
<nextsent>2 ? 200 orig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1928">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> combining contexts.  </section>
<citcontext>
<prevsection>
<prevsent>thus far, we have not utilized frames target words; we turn to these now, in order to better gauge the effectiveness of frames for identifying categories.
</prevsent>
<prevsent>although the work is somewhat preliminary, our goal is to continue to investigate when contexts identify the same category.
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
this merging of contexts is different than clustering words (e.g., clark, 2000; <papid> W00-0717 </papid>brown et al, 1992), <papid> J92-4003 </papid>but is applicable, as word clustering relies on knowing which contexts identify the same cat egory.</citsent>
<aftsection>
<nextsent>4.1 word-based combination.
</nextsent>
<nextsent>on their own, frames at best distinguish only very broad categorical properties.
</nextsent>
<nextsent>this is perhaps unsurprising, as the finer-grained distinctions in corpora seem to be based on lexical properties more than on additional context (see, e.g., dickinson, 2008).<papid> C08-1026 </papid></nextsent>
<nextsent>if we want to combine contexts in way which maps to corpus tagsets, then, we need to examine the target words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1929">
<title id=" W09-0905.xml">categorizing local contexts as a step in grammatical category induction </title>
<section> combining contexts.  </section>
<citcontext>
<prevsection>
<prevsent>thus far, we have not utilized frames target words; we turn to these now, in order to better gauge the effectiveness of frames for identifying categories.
</prevsent>
<prevsent>although the work is somewhat preliminary, our goal is to continue to investigate when contexts identify the same category.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
this merging of contexts is different than clustering words (e.g., clark, 2000; <papid> W00-0717 </papid>brown et al, 1992), <papid> J92-4003 </papid>but is applicable, as word clustering relies on knowing which contexts identify the same cat egory.</citsent>
<aftsection>
<nextsent>4.1 word-based combination.
</nextsent>
<nextsent>on their own, frames at best distinguish only very broad categorical properties.
</nextsent>
<nextsent>this is perhaps unsurprising, as the finer-grained distinctions in corpora seem to be based on lexical properties more than on additional context (see, e.g., dickinson, 2008).<papid> C08-1026 </papid></nextsent>
<nextsent>if we want to combine contexts in way which maps to corpus tagsets, then, we need to examine the target words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1934">
<title id=" W08-0908.xml">automatic identification of discourse moves in scientific article introductions </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>traditionally, automated evaluation has been usedfor essay grading, but its potential could be successfully extrapolated to other genres in both first language (l1) and second language (l2) academic contexts.
</prevsent>
<prevsent>existing scoring systems can assess various constructs such as topical content, grammar, style, mechanics, syntactic complexity, and even deviance or plagiarism (burstein, 2003; elliott, 2003; landauer et al, 2003; mitchell et al, 2002; page, 2003; rudner and liang, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W99-0411 ">
because learner writing is generally highly erroneous, an emerging research trend has focused on automated error detection inl2 output finding novel approaches to develop intelligent ways to assess ill-formed learner responses (burstein and chodorow, 1999; <papid> W99-0411 </papid>chodorow et al, 2007; <papid> W07-1604 </papid>han et al, 2006; leacock and chodorow, 2003).</citsent>
<aftsection>
<nextsent>various nlp and statistical techniques also allow for the evaluation of text organization, which is however limited to recognizing the five-paragraph essay format, thesis, and topic sentences.
</nextsent>
<nextsent>at present,to our knowledge, there is only one automated evaluation system, ant mover (anthony and lashkia,2003), that applies intelligent technological possibilities to the genre of research reportsa major challenge for new non-native speaker (nns) members ofacademia.
</nextsent>
<nextsent>ant mover is able to automatically identify the structure of abstracts in various fields and disciplines.academic writing pedagogues have been struggling to find effective ways to teach academic writing.
</nextsent>
<nextsent>frodesen (1995) argues that the writing instruction for non-native speaker students should help 62initiate writers into their field-specific research com munities?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1935">
<title id=" W08-0908.xml">automatic identification of discourse moves in scientific article introductions </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>traditionally, automated evaluation has been usedfor essay grading, but its potential could be successfully extrapolated to other genres in both first language (l1) and second language (l2) academic contexts.
</prevsent>
<prevsent>existing scoring systems can assess various constructs such as topical content, grammar, style, mechanics, syntactic complexity, and even deviance or plagiarism (burstein, 2003; elliott, 2003; landauer et al, 2003; mitchell et al, 2002; page, 2003; rudner and liang, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W07-1604 ">
because learner writing is generally highly erroneous, an emerging research trend has focused on automated error detection inl2 output finding novel approaches to develop intelligent ways to assess ill-formed learner responses (burstein and chodorow, 1999; <papid> W99-0411 </papid>chodorow et al, 2007; <papid> W07-1604 </papid>han et al, 2006; leacock and chodorow, 2003).</citsent>
<aftsection>
<nextsent>various nlp and statistical techniques also allow for the evaluation of text organization, which is however limited to recognizing the five-paragraph essay format, thesis, and topic sentences.
</nextsent>
<nextsent>at present,to our knowledge, there is only one automated evaluation system, ant mover (anthony and lashkia,2003), that applies intelligent technological possibilities to the genre of research reportsa major challenge for new non-native speaker (nns) members ofacademia.
</nextsent>
<nextsent>ant mover is able to automatically identify the structure of abstracts in various fields and disciplines.academic writing pedagogues have been struggling to find effective ways to teach academic writing.
</nextsent>
<nextsent>frodesen (1995) argues that the writing instruction for non-native speaker students should help 62initiate writers into their field-specific research com munities?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1936">
<title id=" W09-0503.xml">identifying segment topics in medical dicta tions </title>
<section> conclusion and outlook.  </section>
<citcontext>
<prevsection>
<prevsent>in various experiments, linear models using binary feature weights had the best performance.
</prevsent>
<prevsent>a posteriori error correction via classifier stacking additionally improved the results.
</prevsent>
</prevsection>
<citsent citstr=" D08-1001 ">
when comparing our results to the results of jancsary et al (2008), <papid> D08-1001 </papid>who pursue multi-level segmentation aproach using conditional random fields optimizing over the whole report, the locally obtained svm results cannot compete fully.</citsent>
<aftsection>
<nextsent>onlabel chain 2, which is equivalent to segment topics as investigated here, jancsary et al (2008) <papid> D08-1001 </papid>report an estimated accuracy of 81.45 ? 2.14 % on asr output (after some postprocessing), whereas our results, even with posteriori error correction,are at least 4 percent points behind.</nextsent>
<nextsent>this is probably due to the fact that the multi-level annotation employed in jancsary et al (2008) <papid> D08-1001 </papid>contains additional information useful for the learning task, and constraints between the levels improve segmentation behavior at the segment boundaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1941">
<title id=" W08-1004.xml">revisiting the impact of different annotation schemes on pcfg parsing a grammatical dependency evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present the first comparison of negra and tuba-d/z using labeled dependency evaluation based on the grammatical function labels provided in the corpora.
</prevsent>
<prevsent>we show that, in contrast to previous literature, labeled dependency evaluation establishes that pcfg parsers trained on the two corpora give similar parsing performance.
</prevsent>
</prevsection>
<citsent citstr=" P07-1032 ">
the focus on labeled dependencies also provides direct link to recent work on dependency-based evaluation (e.g., clark and curran, 2007) <papid> P07-1032 </papid>and dependency parsing (e.g., conll shared tasks 2006, 2007).</citsent>
<aftsection>
<nextsent>1.1 previous work.
</nextsent>
<nextsent>the question of how to evaluate parser output has naturally already arisen in earlier work on parsing english.
</nextsent>
<nextsent>as discussed by lin (1995) and others, the parseval evaluation typically used to analyze the performance of statistical parsing models has manydrawbacks.
</nextsent>
<nextsent>bracketing evaluation may count single error multiple times and does not differentiate between errors that significantly affect the interpretation of the sentence and those that are less crucial.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1942">
<title id=" W08-1004.xml">revisiting the impact of different annotation schemes on pcfg parsing a grammatical dependency evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition,and most directly relevant for this paper, parseval scores are difficult to compare across syntactic annotation schemes (carroll et al, 2003).
</prevsent>
<prevsent>at the same time, previous research on pcfg parsing using treebank training data present parseval measures in comparing the parsing performance for different languages and annotation schemes, reporting number of striking differences.
</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
for example, levy and manning (2003), <papid> P03-1056 </papid>kubler(2005), and kubler et al (2006) highlight the significant effect of language properties and annotation schemes for german and chinese treebanks.</citsent>
<aftsection>
<nextsent>in related work, parser enhancements that provide significant performance boost for english, such as head lexicalization, are reported not to provide the same kind of improvement, if any, for german (dubey and keller, 2003; <papid> P03-1013 </papid>dubey, 2004; kubler et al, 2006).</nextsent>
<nextsent>previous work has compared the similar negra and tiger corpora of german to the very different tuba-d/z corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1943">
<title id=" W08-1004.xml">revisiting the impact of different annotation schemes on pcfg parsing a grammatical dependency evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at the same time, previous research on pcfg parsing using treebank training data present parseval measures in comparing the parsing performance for different languages and annotation schemes, reporting number of striking differences.
</prevsent>
<prevsent>for example, levy and manning (2003), <papid> P03-1056 </papid>kubler(2005), and kubler et al (2006) highlight the significant effect of language properties and annotation schemes for german and chinese treebanks.</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
in related work, parser enhancements that provide significant performance boost for english, such as head lexicalization, are reported not to provide the same kind of improvement, if any, for german (dubey and keller, 2003; <papid> P03-1013 </papid>dubey, 2004; kubler et al, 2006).</citsent>
<aftsection>
<nextsent>previous work has compared the similar negra and tiger corpora of german to the very different tuba-d/z corpus.
</nextsent>
<nextsent>kubler et al (2006) compares the negra and tuba-d/z corpora of german using parseval evaluation and an evaluation on core grammatical function labels that is included to address concerns about the parseval measure.1 using the stanford parser (klein and manning, 2002), which employs factored pcfg and dependency model, they claim that the model trained on tubad/z consistently outperforms that trained on negra in parseval and grammatical function evaluations.
</nextsent>
<nextsent>dubey (2004) also includes an evaluation on grammatical function for statistical models trained on negra, but obtains very different results from kubler et al (2006).2 in recent related work, rehbein and van genabith (2007<papid> D07-1066 </papid>a) demonstrate using the tiger and tuba-d/z 1the evaluation is based only on the grammatical function; it does not identify the dependency pair that it labels.</nextsent>
<nextsent>2while the focus of kubler et al (2006) is on comparing parsing results across corpora, dubey (2004) focuses on improving parsing for negra, including corpus-specific enhancements leading to better results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1944">
<title id=" W08-1004.xml">revisiting the impact of different annotation schemes on pcfg parsing a grammatical dependency evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work has compared the similar negra and tiger corpora of german to the very different tuba-d/z corpus.
</prevsent>
<prevsent>kubler et al (2006) compares the negra and tuba-d/z corpora of german using parseval evaluation and an evaluation on core grammatical function labels that is included to address concerns about the parseval measure.1 using the stanford parser (klein and manning, 2002), which employs factored pcfg and dependency model, they claim that the model trained on tubad/z consistently outperforms that trained on negra in parseval and grammatical function evaluations.
</prevsent>
</prevsection>
<citsent citstr=" D07-1066 ">
dubey (2004) also includes an evaluation on grammatical function for statistical models trained on negra, but obtains very different results from kubler et al (2006).2 in recent related work, rehbein and van genabith (2007<papid> D07-1066 </papid>a) demonstrate using the tiger and tuba-d/z 1the evaluation is based only on the grammatical function; it does not identify the dependency pair that it labels.</citsent>
<aftsection>
<nextsent>2while the focus of kubler et al (2006) is on comparing parsing results across corpora, dubey (2004) focuses on improving parsing for negra, including corpus-specific enhancements leading to better results.
</nextsent>
<nextsent>this difference in focus and additional differences in experimental setup mean that fine grained comparison of the results is inappropriate ? the relevant point here is that the gap between the results (23% for subjects, 35% for accusative objects) warrants further attention in the context of comparing parsing results across corpora.corpora of german that parseval is inappropriate for comparisons of the output of pcfg parser strained on different treebank annotation schemes be cause parseval scores are affected by the ratioof terminal to non-terminal nodes.
</nextsent>
<nextsent>a dependency based evaluation on triples of the form word-pos head shows better results for the parser trained on tiger even though the much lower parseval scores, if meaningful, would predict that the out put for tiger is of lower quality.
</nextsent>
<nextsent>however, their dependency-based evaluation does not make useof the grammatical function labels, which are provided in the corpora and closely correspond to the representations used in recent work on formalism independent evaluation of parsers (e.g., clark and curran, 2007).<papid> P07-1032 </papid>3 addressing these issues, we resolve the apparent discrepancy between kubler et al (2006) and dubey (2004) and establish firm grammatical function comparison of negra and tuba-d/z. we also extend the evaluation to labeled dependency evaluation based on grammatical relations for both cor pora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1949">
<title id=" W08-1004.xml">revisiting the impact of different annotation schemes on pcfg parsing a grammatical dependency evaluation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>around 30% of sentences in negra contain at least one discontinuity.
</prevsent>
<prevsent>to remove discontinuities, we used the conversion program included with the negra corpus annotation tools (brants and plaehn, 2000), the same tool used in kubler et al (2006),which raises non-head elements to higher tree until there are no more discontinuities.
</prevsent>
</prevsection>
<citsent citstr=" W07-1506 ">
for example, for the discontinuous tree with fronted object we saw in figure 1, the pp containing the fronted np dieser meinung is raised to become daughter of the top node.4 additionally, the edge labels used in both corpora need to be folded into the node labels to become 4an alternate method that avoids certain problems with this raising method is discussed in boyd (2007).<papid> W07-1506 </papid></citsent>
<aftsection>
<nextsent>27 part of context-free grammar rules used by pcfg parser.
</nextsent>
<nextsent>in the penn treebank-style versions of the corpora appropriate for training pcfg parser, each edge label is joined with the phrase or pos label on the phrase or word immediately below it.
</nextsent>
<nextsent>both corpora include edge labels above all phrases and words.
</nextsent>
<nextsent>however the flatter structures in negra result in 39 different edge labels on words while tuba-d/z has only 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1963">
<title id=" W08-2204.xml">high precision analysis of nps with a deep processing grammar </title>
<section> foundations.  </section>
<citcontext>
<prevsection>
<prevsent>as such, they are the preferred grammars interface for applications, that do not need any knowledge of the grammatical properties of portuguese and may not need to look at syntactic analysis.
</prevsent>
<prevsent>the mrs format is also used with several other computational hpsgs, for other languages.
</prevsent>
</prevsection>
<citsent citstr=" W04-1901 ">
several applications (e.g. machine translation) have been used with other hpsgs that communicate with these grammars via the mrss (bond et al, 2004).<papid> W04-1901 </papid></citsent>
<aftsection>
<nextsent>these applications can be easily integrated with grammars for different languages that also use mrs: they are almost completely language independent.
</nextsent>
<nextsent>given the foundational options, lxgram adheres to number of important design features.
</nextsent>
<nextsent>bidirectionality lxgram is bidirectional.
</nextsent>
<nextsent>the formalism employed is completelydeclarative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1964">
<title id=" W09-1324.xml">text2table medical text summarization system based on named entity recognition and modality identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>endo glucose control monitored while on de cadron with ssri coverage . will check hgba1c prior to discharge . giaggressive bowel regimen to continue at home . pt is full code . additional comments: please call dr. xellcaugh with worsening headache or back pain, or any other concern . keep appointment as scheduled with xrt . please check finger stick once day, and record, call md if greater than 200 . 186 figure 1: visualization result (left), magnified (right).
</prevsent>
<prevsent>figure 2: negative triggers and events on dependency structure.
</prevsent>
</prevsection>
<citsent citstr=" W06-0305 ">
table 2: corpora and modalities corpus modality ace asserted, or other timeml must, may, should, would, or could prasad et al, 2006 <papid> W06-0305 </papid>assertion, belief, facts or eventualities saur?</citsent>
<aftsection>
<nextsent>et al, 2007 certain, probable, possible, or other inui et al, 2008 affirm, infer, doubt, hear, intend, ask, recommend, hypothesize, or other this study s/o, necessity, hope, possible, recommend, intend table 3: markup scheme (tags and definitions) tag definition (examples) remedy, medical operation (e.g. radiotherapy) medical test, medical examination (e.g., ct, mri) deasese, symptom (e.g., endometrial cancer, headache) medication, administration of drug (e.g., levofloxacin, flexeril) patient action (e.g., admitted to hospital) other verb (e.g., cancer spread to ...)
</nextsent>
<nextsent>2.1 previous markup schemes.
</nextsent>
<nextsent>in the nlp field, fact identification has not been studied well to date.
</nextsent>
<nextsent>nevertheless, similar analyses can be found in studies of sentence modality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1966">
<title id=" W09-1324.xml">text2table medical text summarization system based on named entity recognition and modality identification </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>the original algorithm is based on list of negation expressions.
</prevsent>
<prevsent>goldin et al (2003) incorporate machine learning techniques (nave bayes and decision trees) into the algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W07-1011 ">
the extended version (context) was also proposed (chapman et al, 2007).<papid> W07-1011 </papid></citsent>
<aftsection>
<nextsent>elkin et al (2005) use list of negation words and list of negation scope-ending words to iden 2 http://projects.ldc.upenn.edu/ace/ 3 http://www.seas.upenn.edu/~pdtb/ 4 http://www.dbmi.pitt.edu/chapman/negex.html 187tify negated statements and their scope.
</nextsent>
<nextsent>their technique was used in the mayo clinic vocabulary server (mcvs)5, which encodes clinical expressions into medical ontology (snomed-ct) and identifies whether the event is positive or negative.
</nextsent>
<nextsent>m t utalik et al (2001) earlier developed neg finder to recognize negated patterns in medical texts.
</nextsent>
<nextsent>their system uses regular expressions to identify words indicating negation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1967">
<title id=" W09-1324.xml">text2table medical text summarization system based on named entity recognition and modality identification </title>
<section> medical text summarization system:.  </section>
<citcontext>
<prevsection>
<prevsent>(1) date time normalization as for date time expressions, relative date expressions are converted into yyyy/mm/dd as follows.
</prevsent>
<prevsent>on dec last year ? 2007/12/xx 10 dec 2008 ? 2008/12/10 these conversions are based on heuristic rules.
</prevsent>
</prevsection>
<citsent citstr=" I08-1007 ">
(2) event normalization medical terms are converted into standard notation (dictionary entry terms) using orthographic disambiguation (aramaki et al, 2008).<papid> I08-1007 </papid></citsent>
<aftsection>
<nextsent>step 3: time event relation identification then, each event is tied with date time.
</nextsent>
<nextsent>the current system relies on simple rule (i.e., an event is tied with the latest date time).
</nextsent>
<nextsent>step 4: negative identification the proposed svm classifier distinguishes negative events from other events.
</nextsent>
<nextsent>the detailed algorithm is described in the next section.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1968">
<title id=" W08-1604.xml">context modelling for iqa the role of tasks and entities </title>
<section> coherence in iqa dialogues.  </section>
<citcontext>
<prevsection>
<prevsent>we claim that in information seeking dialogue?
</prevsent>
<prevsent>this distinction is moot,and the two kinds of foci collapse into one.
</prevsent>
</prevsection>
<citsent citstr=" W04-2504 ">
furthermore, our empirical investigation shows that it suffices to consider rather short history of the dialogue, i.e. the previous user question and previous system answer, when looking for relations between previous dialogue and fu q. salient transitions between two consecutive questions are defined in (chai and jin, 2004) <papid> W04-2504 </papid>under the name of informational transitions?.</citsent>
<aftsection>
<nextsent>the authors aim to describe how the topic within di 1 this definition is in line with how focus has been used in computational linguistics and artificial intelligence (hence, ai focus?), originating in the work of grosz and sidner on discourse entity salience.
</nextsent>
<nextsent>we follow lecuche et al in that focused elements could also be actions/tasks.
</nextsent>
<nextsent>we see the most salient focused element (corresponding to the backward looking center?
</nextsent>
<nextsent>in centering theory) as the topic of the utterance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1970">
<title id=" W08-1604.xml">context modelling for iqa the role of tasks and entities </title>
<section> coherence in iqa dialogues.  </section>
<citcontext>
<prevsection>
<prevsent>a fu can be used to ask (i) similar question as the previous one but with different constraints or different participants (topic extension); (ii) question concerning different aspect of the same topic (topic exploration); (iii) question concerning related activity or related entity (topic shift).
</prevsent>
<prevsent>we take this analysis as our starting point, extend it and propose an algorithm to automatically detect the kind of focus transition user performs when asking fu q, and evaluate our extended theory with real dialogue data.
</prevsent>
</prevsection>
<citsent citstr=" W06-3001 ">
following (bertomeu et al., 2006) <papid> W06-3001 </papid>we consider also the role of the system answer, and we analyze the thematic relations between the current question and previous question,and the current question and previous answer.</citsent>
<aftsection>
<nextsent>unlike (bertomeu et al, 2006), <papid> W06-3001 </papid>we attempt to learn model of naturally occurring thematic relations in relatively unconstrained iqa dialogues.</nextsent>
<nextsent>3.1 what things?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1972">
<title id=" W08-1604.xml">context modelling for iqa the role of tasks and entities </title>
<section> preliminary observations.  </section>
<citcontext>
<prevsection>
<prevsent>our theory of focus structure is related to thetask-based theory of (grosz, 1977).
</prevsent>
<prevsent>tasks correspond to verbs, which are inherently connected to an argument structure defining the verbs semanticroles.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
by consulting lexical resources like propbank (palmer et al, 2005), <papid> J05-1004 </papid>we can use existing knowledge about possible semantic arguments of 26 the tasks we have identified.</citsent>
<aftsection>
<nextsent>we claim that actions/verbs form suitable and robust basis for describing the (informational) meaning of utterances in iqa.
</nextsent>
<nextsent>taking the main verb along with its semantic arguments to represent the core meaning of user questions seems tobe more feasible alternative to deep semantic approaches that still lack the robustness for dealing with unconstrained user input.
</nextsent>
<nextsent>further, we claim that analyzing user questions on the basis of their task/entity structure provides auseful level of abstraction and granularity for empirically studying informational transitions in iqa dialogues.
</nextsent>
<nextsent>we back up this claim in section 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1980">
<title id=" W09-0210.xml">unsupervised and constrained dirichlet process mixture models for verb clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these models have the attractive property that the number of components used to model the data is not fixed in advance but is actually determined by the model and the data.
</prevsent>
<prevsent>this property is particularly interesting for nlp where many tasks are aimed at discovering novel, previously unknown information in corpora.
</prevsent>
</prevsection>
<citsent citstr=" P07-1107 ">
recent work has applied bayesian non-parametric models to anaphora resolution (haghighi and klein, 2007), <papid> P07-1107 </papid>lexical acquisition (goldwater, 2007) and language modeling (teh, 2006) <papid> P06-1124 </papid>with good results.recently, vlachos et al (2008) applied the basic models of this class, dirichlet process mixture models (dpmms) (neal, 2000), to typical learning task in nlp: lexical-semantic verb clus tering.</citsent>
<aftsection>
<nextsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).
</nextsent>
<nextsent>such classes can provide important support for other nlp tasks, such as word sense disambiguation, parsing and semantic role labeling (dang, 2004; swier and stevenson, 2004).<papid> W04-3213 </papid></nextsent>
<nextsent>although some fixed classifications are available (e.g. verbnet (kipper-schuler, 2005)) these are not comprehensive and are inadequate for specific domains (korhonen et al, 2006<papid> P06-1044 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1981">
<title id=" W09-0210.xml">unsupervised and constrained dirichlet process mixture models for verb clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these models have the attractive property that the number of components used to model the data is not fixed in advance but is actually determined by the model and the data.
</prevsent>
<prevsent>this property is particularly interesting for nlp where many tasks are aimed at discovering novel, previously unknown information in corpora.
</prevsent>
</prevsection>
<citsent citstr=" P06-1124 ">
recent work has applied bayesian non-parametric models to anaphora resolution (haghighi and klein, 2007), <papid> P07-1107 </papid>lexical acquisition (goldwater, 2007) and language modeling (teh, 2006) <papid> P06-1124 </papid>with good results.recently, vlachos et al (2008) applied the basic models of this class, dirichlet process mixture models (dpmms) (neal, 2000), to typical learning task in nlp: lexical-semantic verb clus tering.</citsent>
<aftsection>
<nextsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).
</nextsent>
<nextsent>such classes can provide important support for other nlp tasks, such as word sense disambiguation, parsing and semantic role labeling (dang, 2004; swier and stevenson, 2004).<papid> W04-3213 </papid></nextsent>
<nextsent>although some fixed classifications are available (e.g. verbnet (kipper-schuler, 2005)) these are not comprehensive and are inadequate for specific domains (korhonen et al, 2006<papid> P06-1044 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1982">
<title id=" W09-0210.xml">unsupervised and constrained dirichlet process mixture models for verb clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has applied bayesian non-parametric models to anaphora resolution (haghighi and klein, 2007), <papid> P07-1107 </papid>lexical acquisition (goldwater, 2007) and language modeling (teh, 2006) <papid> P06-1124 </papid>with good results.recently, vlachos et al (2008) applied the basic models of this class, dirichlet process mixture models (dpmms) (neal, 2000), to typical learning task in nlp: lexical-semantic verb clus tering.</prevsent>
<prevsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).</prevsent>
</prevsection>
<citsent citstr=" W04-3213 ">
such classes can provide important support for other nlp tasks, such as word sense disambiguation, parsing and semantic role labeling (dang, 2004; swier and stevenson, 2004).<papid> W04-3213 </papid></citsent>
<aftsection>
<nextsent>although some fixed classifications are available (e.g. verbnet (kipper-schuler, 2005)) these are not comprehensive and are inadequate for specific domains (korhonen et al, 2006<papid> P06-1044 </papid>b).</nextsent>
<nextsent>unlike the clustering algorithms applied to this task before, dpmms do not require the number of clusters as input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1983">
<title id=" W09-0210.xml">unsupervised and constrained dirichlet process mixture models for verb clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task involves discovering classes of verbs similar in terms of their syntactic-semantic properties (e.g. motion class for travel, walk, run, etc.).
</prevsent>
<prevsent>such classes can provide important support for other nlp tasks, such as word sense disambiguation, parsing and semantic role labeling (dang, 2004; swier and stevenson, 2004).<papid> W04-3213 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1044 ">
although some fixed classifications are available (e.g. verbnet (kipper-schuler, 2005)) these are not comprehensive and are inadequate for specific domains (korhonen et al, 2006<papid> P06-1044 </papid>b).</citsent>
<aftsection>
<nextsent>unlike the clustering algorithms applied to this task before, dpmms do not require the number of clusters as input.
</nextsent>
<nextsent>this is important because even if the number of classes in particular task was known (e.g. in the context of carefully controlled experiment), particular dataset may not contain instances for all the classes.
</nextsent>
<nextsent>moreover, each classis not necessarily contained in one cluster exclusively, since the target classes are defined manually without taking into account the feature representation used.
</nextsent>
<nextsent>the fact that dpmms do not require the number of target clusters in advance, renders them promising for the many nlp tasks where clustering is used for learning purposes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1985">
<title id=" W09-0210.xml">unsupervised and constrained dirichlet process mixture models for verb clustering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the fact that dpmms do not require the number of target clusters in advance, renders them promising for the many nlp tasks where clustering is used for learning purposes.
</prevsent>
<prevsent>while the results of vlachos et al (2008) are promising, the use of clustering approach which discovers the number of clusters in data presents new challenge to existing evaluation measures.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
in this work, we investigate optimal evaluation for such approaches, using the dataset and the basic method of vlachos et al as starting point.we review the applicability of existing evaluation measures and propose modified version of the newly introduced v-measure (rosenberg and hirschberg, 2007).<papid> D07-1043 </papid></citsent>
<aftsection>
<nextsent>we complement the quantitative evaluation with thorough qualitative assessment, for which we introduce method to summarize samples obtained from clustering algorithm.
</nextsent>
<nextsent>in preliminary work by vlachos et al (2008),a constrained version of dpmms which takes advantage of must-link and cannot-link pairwise constraints was introduced.
</nextsent>
<nextsent>it was demonstrated how such const raines can guide the clustering solution towards some prior intuition or considerations relevant to the specific nlp application in mind.
</nextsent>
<nextsent>we explain the inference algorithm for the constraineddpmm in greater detail and evaluate quant ita 74 tively the contribution of each constraint type of independently, complementing it with qualitative analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1993">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> hidden language dependence.  </section>
<citcontext>
<prevsection>
<prevsent>thus even though n-grams models can be built 26 without any hand-coding of linguistic knowledge, they are not truly language independent.
</prevsent>
<prevsent>rather, their success depends on typo logical properties of the languages they were first developed for.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
a more linguistically-informed (and thus more language independent) approach to n-gram models is the factored language model approach of bilmes and kirchhoff (2003).<papid> N03-2002 </papid></citsent>
<aftsection>
<nextsent>factored language models address the problems of data-sparsity in morphologically complex languages by representing words as bundles of features, thus capturing dependencies between subword parts of adjacent words.a second example of subtle language dependence comes from dasgupta and ng (2007), <papid> N07-1020 </papid>who present an unsupervised morphological segmentation algorithm meant to be language-independent.indeed, this work goes much further towards language independence than is the norm (see section 3).</nextsent>
<nextsent>it is tested against data from english, bengali, finnish and turkish, particularly good selection of languages in that it includes diversity along akey dimension (degree of morphological complex ity), as well as representatives of three language families (indo-european, uralic, and altaic).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1994">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> hidden language dependence.  </section>
<citcontext>
<prevsection>
<prevsent>rather, their success depends on typo logical properties of the languages they were first developed for.
</prevsent>
<prevsent>a more linguistically-informed (and thus more language independent) approach to n-gram models is the factored language model approach of bilmes and kirchhoff (2003).<papid> N03-2002 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1020 ">
factored language models address the problems of data-sparsity in morphologically complex languages by representing words as bundles of features, thus capturing dependencies between subword parts of adjacent words.a second example of subtle language dependence comes from dasgupta and ng (2007), <papid> N07-1020 </papid>who present an unsupervised morphological segmentation algorithm meant to be language-independent.indeed, this work goes much further towards language independence than is the norm (see section 3).</citsent>
<aftsection>
<nextsent>it is tested against data from english, bengali, finnish and turkish, particularly good selection of languages in that it includes diversity along akey dimension (degree of morphological complex ity), as well as representatives of three language families (indo-european, uralic, and altaic).
</nextsent>
<nextsent>furthermore, the algorithm is designed to detect more than one prefix or suffix per word, which is important for analyzing morphologically complex languages.
</nextsent>
<nextsent>however, it seems unrealistic to expect one-size-fits-all approach to be achieve uniformly high performance across varied languages, and, in fact, it doesnt. though the system presented in (dasgupta and ng, 2007) <papid> N07-1020 </papid>outperforms the best systems in the 2006 pascal challenge for turkish and finnish, it still does significantly worse on these languages than english (f-scores of 66.2 and 66.5, compared to 79.4).this seems to be due to an interesting interaction of at least two properties of the language sin question.</nextsent>
<nextsent>first, the initial algorithm for discovering candidate roots and affixes relies on the presence of bare, uninflected roots in the training vocabulary, extracting string as candidate affix (or sequence of affixes) when it appears at the end (or beginning) of another string that also appears independently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1996">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> hidden language dependence.  </section>
<citcontext>
<prevsection>
<prevsent>a clear example of this is english letter-to-phoneme conversion, which, as result of the lack of transparency in english orthog raphy, is harder problem that letter-to-phoneme conversion in other languages.
</prevsent>
<prevsent>not surprisingly, the letter-to-phoneme systems described in e.g.
</prevsent>
</prevsection>
<citsent citstr=" P08-1103 ">
(jiampojamarn et al, 2008) <papid> P08-1103 </papid>and (bartlett et al, 2008) <papid> P08-1065 </papid>do worse on the english test data than they do on german, dutch, or french.</citsent>
<aftsection>
<nextsent>on the other hand, just because one language may present harder problem than the other doesnt mean that system developers can assume that any performance differences can be explained in such way.if one aims to create language-independent system, then one must explore the possibility thatthe system includes assumptions about linguistic structure which do not hold up across all languages.
</nextsent>
<nextsent>the conclusions would like to draw from these examples are as follows: truly language independent system works equally well across languages.
</nextsent>
<nextsent>when system that is meant to be language independent does not in fact work equally well across languages, it is likely because some thing about the system design is making implicit assumptions about language structure.
</nextsent>
<nextsent>these assumptions are typically the result of overfittingto the original development language(s).3 in sec 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1997">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> hidden language dependence.  </section>
<citcontext>
<prevsection>
<prevsent>a clear example of this is english letter-to-phoneme conversion, which, as result of the lack of transparency in english orthog raphy, is harder problem that letter-to-phoneme conversion in other languages.
</prevsent>
<prevsent>not surprisingly, the letter-to-phoneme systems described in e.g.
</prevsent>
</prevsection>
<citsent citstr=" P08-1065 ">
(jiampojamarn et al, 2008) <papid> P08-1103 </papid>and (bartlett et al, 2008) <papid> P08-1065 </papid>do worse on the english test data than they do on german, dutch, or french.</citsent>
<aftsection>
<nextsent>on the other hand, just because one language may present harder problem than the other doesnt mean that system developers can assume that any performance differences can be explained in such way.if one aims to create language-independent system, then one must explore the possibility thatthe system includes assumptions about linguistic structure which do not hold up across all languages.
</nextsent>
<nextsent>the conclusions would like to draw from these examples are as follows: truly language independent system works equally well across languages.
</nextsent>
<nextsent>when system that is meant to be language independent does not in fact work equally well across languages, it is likely because some thing about the system design is making implicit assumptions about language structure.
</nextsent>
<nextsent>these assumptions are typically the result of overfittingto the original development language(s).3 in sec 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1998">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> language independence and language.  </section>
<citcontext>
<prevsection>
<prevsent>the three papers studying zero languages involved abstract, formal proofs regarding,e.g., grammar formalisms.
</prevsent>
<prevsent>95 of the papers studied just one language or language pair.
</prevsent>
</prevsection>
<citsent citstr=" P08-1112 ">
languages or language number of papers pairs considered 0 3 1 95 2 13 3 3 4 2 5 1 12 1 13 1 total 119table 1: number of languages/language pairs considered the two papers looking at the widest variety of languages were (ganchev et al, 2008) <papid> P08-1112 </papid>and (nivre and mcdonald, 2008).<papid> P08-1108 </papid></citsent>
<aftsection>
<nextsent>ganchev et al (2008) <papid> P08-1112 </papid>explore whether better alignments lead to better translations, across 6 language pairs, in each direction (12 mt systems), collecting data from variety of sources.</nextsent>
<nextsent>nivre and mcdonald (2008) <papid> P08-1108 </papid>present an approach to dependency parsing which integrates graph-based and transition-based methods, and evaluate the result against the 13 datasets ing our ideas against particular languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE1999">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> language independence and language.  </section>
<citcontext>
<prevsection>
<prevsent>the three papers studying zero languages involved abstract, formal proofs regarding,e.g., grammar formalisms.
</prevsent>
<prevsent>95 of the papers studied just one language or language pair.
</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
languages or language number of papers pairs considered 0 3 1 95 2 13 3 3 4 2 5 1 12 1 13 1 total 119table 1: number of languages/language pairs considered the two papers looking at the widest variety of languages were (ganchev et al, 2008) <papid> P08-1112 </papid>and (nivre and mcdonald, 2008).<papid> P08-1108 </papid></citsent>
<aftsection>
<nextsent>ganchev et al (2008) <papid> P08-1112 </papid>explore whether better alignments lead to better translations, across 6 language pairs, in each direction (12 mt systems), collecting data from variety of sources.</nextsent>
<nextsent>nivre and mcdonald (2008) <papid> P08-1108 </papid>present an approach to dependency parsing which integrates graph-based and transition-based methods, and evaluate the result against the 13 datasets ing our ideas against particular languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2002">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> language independence and language.  </section>
<citcontext>
<prevsection>
<prevsent>ganchev et al (2008) <papid> P08-1112 </papid>explore whether better alignments lead to better translations, across 6 language pairs, in each direction (12 mt systems), collecting data from variety of sources.</prevsent>
<prevsent>nivre and mcdonald (2008) <papid> P08-1108 </papid>present an approach to dependency parsing which integrates graph-based and transition-based methods, and evaluate the result against the 13 datasets ing our ideas against particular languages.</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
provided in the conll-x shared task (nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>it is encouraging to see such use of multilingual datasets; the field as whole will be in better position to test (and improve) the cross-linguistic applicability of various methods to the extent that more such datasets are produced.
</nextsent>
<nextsent>it is worth noting, however, that the sheer number of languages tested is not the only important factor: because related languages tend to share typo logical properties, it is also important to sample across the known language families.
</nextsent>
<nextsent>tables 2 and 3 list the languages and language pairs studied in the papers in the survey.
</nextsent>
<nextsent>table 2 presents the data on methodologies that involve producing results for one language at time, and groups the languages by genus and family (accord ing to the classification used by the world atlas of language structures online4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2003">
<title id=" W09-0106.xml">linguistically naiumlve  language independent why nlp needs linguistic typology </title>
<section> language independence and language.  </section>
<citcontext>
<prevsection>
<prevsent>ethnologue6 lists 94 language fami lies; acl2008:hlt papers studied six.
</prevsent>
<prevsent>of course, the distribution of languages (and perhaps moreto the point, speakers) is not uniform across lan 4http://wals.info (haspelmath et al, 2008); note that japanese is treated as language isolate and chinese is the name for the genus including (among others) mandarin and cantonese.
</prevsent>
</prevsection>
<citsent citstr=" P08-1084 ">
5the very interesting study by snyder and barzilay (2008) <papid> P08-1084 </papid>on multilingual approaches to morphological segmentation was difficult to classify.</citsent>
<aftsection>
<nextsent>their methodology involved jointly analyzing two languages at time in order to produce morphological segment ers for each.
</nextsent>
<nextsent>since the resulting systems were monolingual, the data from these studies are included in table 2.
</nextsent>
<nextsent>6http://www.ethnologue.com/ethno docs/distribution.asp, accessed on 6 february 2009.
</nextsent>
<nextsent>28 language studies genus studies family studies % % % english 81 63.28 germanic 91 71.09 indo-european 109 85.16 german 5 3.91 dutch 3 2.34 danish 1 0.78 swedish 1 0.78 czech 3 2.34 slavic 8 6.25 russian 2 1.56 bulgarian 1 0.78 slovene 1 0.78 ukranian 1 0.78 portuguese 3 2.34 romance 8 6.25 spanish 3 2.34 french 2 1.56 hindi 2 1.56 indic 2 1.56 arabic 4 3.13 semitic 9 7.03 afro-asiatic 9 7.03 hebrew 4 3.13 aramaic 1 0.78 chinese 5 3.91 chinese 5 3.91 sino-tibetan 5 3.91 japanese 3 2.34 japanese 3 3.24 japanese 3 3.24 turkish 1 0.78 turkic 1 0.78 altaic 1 0.78 wambaya 1 0.78 west barkly 1 0.78 australian 1 0.78 total 128 100.00 128 100.00 128 100.00 table 2: languages studied in acl 2008 papers, by language genus and family source target source target symmetrical pair chinese english 9 english chinese 2 english, chinese 3 arabic english 5 english arabic 2 english, arabic 1 french english 2 english french 2 english, french 1 czech english 1 english czech 2 english, spanish 1 finnish english 1 english finnish 1 german english 1 english german 1 italian english 1 english italian 1 spanish english 1 english spanish 1 english greek 1 english russian 1 table 3: language pairs studied in acl 2008 papers 29 language family living examples % pop.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2005">
<title id=" W09-1402.xml">extracting complex biological events with rich graph based feature sets </title>
<section> the system description.  </section>
<citcontext>
<prevsection>
<prevsent>each example is then classified as theme, cause, or negative denoting the absence of an edge between the two nodes in the given direction.
</prevsent>
<prevsent>it should be noted that even though event nodes often require multiple outgoing edges corresponding to multiple event arguments, all edges are predicted independently and are not affected by positive or negative classifications of other edges.the feature set makes extensive use of syntactic dependencies, in line with many recent studies in biomedical information extraction (see, e.g.
</prevsent>
</prevsection>
<citsent citstr=" C08-1053 ">
(kim et al, 2008b; miwa et al, 2008; airola et al, 2008; van landeghem et al, 2008; katrenko and adriaans, 2008)).<papid> C08-1053 </papid></citsent>
<aftsection>
<nextsent>the central concept in generating features of potential event argument edges is the shortest undirected path of syntactic dependencies in the stanford scheme parse of the sentence whichwe assume to accurately capture the relationship expressed by the edge.
</nextsent>
<nextsent>in figure 3, we show that the distances among event and named entity nodes interms of shortest dependency path length are considerably shorter than in terms of their linear order inthe sentence.
</nextsent>
<nextsent>the endpoints of the path are the syntactic head tokens of the two named entities or eventtriggers.
</nextsent>
<nextsent>the head tokens are identified using simple heuristic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2006">
<title id=" W09-1402.xml">extracting complex biological events with rich graph based feature sets </title>
<section> the system description.  </section>
<citcontext>
<prevsection>
<prevsent>similar assumptions are made in the trigger detection phase, where the classifications of individual tokens are independent.a common way to relax independence assumptions is to use -best re-ranking where most likely candidates are re-ranked using global features that model data dependencies that could not be modelled in the candidate generation step.
</prevsent>
<prevsent>the best candidate with respect to this re-ranked order is then the final prediction of the system.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
n -best re-rankinghas been successfully applied for example in statistical parsing (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>we generated the ten most likely candidate graphs, as determined by the confidence scores of the individual edges given by the multi-class svm.
</nextsent>
<nextsent>a perfect reranking of these ten candidates would lead to 11.5 percentage point improvement in the overall systemf-score on the development set.
</nextsent>
<nextsent>while we were unable to produce re-ranker sufficiently accurate to improve the system performance in the time given, the large potential gain warrants further research.
</nextsent>
<nextsent>in trigger word detection, we experimented with structural svm incorporating hidden markov model type of sequential dependencies (altun et al,2003; tsochantaridis et al, 2004), which allow conditioning classification decisions on decisions madefor previous tokens as well as with conditional random field (crf) sequence classifier (lafferty et al,2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2007">
<title id=" W09-1402.xml">extracting complex biological events with rich graph based feature sets </title>
<section> tools and resources.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 dependency parses.
</prevsent>
<prevsent>both trigger detection and edge prediction rely ona wide array of features derived from full dependency parses of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
we use the mcclosky charniak domain-adapted parser (mcclosky and charniak, 2008) <papid> P08-2026 </papid>which is among the best performing parsers trained on the genia treebank corpus.the native constituency output of the parser is transformed to the collapsed?</citsent>
<aftsection>
<nextsent>form of the stanford dependency scheme (de marneffe and manning, 2008) using the stanford parser tools.4 the parses were provided by the shared task organizers.
</nextsent>
<nextsent>the final evaluation of the system was performed bythe shared task organizers using test set whose an 4http://nlp.stanford.edu/software/notation was at no point available to the task participants.
</nextsent>
<nextsent>by the main criterion of task 1, approximate span matching with approximate recursive matching, our system achieved an f-score of 51.95%.
</nextsent>
<nextsent>figure 5 shows the performance of all systems participating in task 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2008">
<title id=" W08-2202.xml">combining knowledge based methods and supervised learning for effective italian word sense disambiguation </title>
<section> a hybrid strategy for wsd </section>
<citcontext>
<prevsection>
<prevsent>jigsaw - it is knowledge-based wsd algorithm based on the assumption.
</prevsent>
<prevsent>that the adoption of different strategies depending on part-of-speech (pos) is better than using always the same strategy.
</prevsent>
</prevsection>
<citsent citstr=" W07-2088 ">
a brief description of jigsaw is given in section 5, more details are reported in basile et al  (2007<papid> W07-2088 </papid>b), basile et al  (2007<papid> W07-2088 </papid>a) and semeraro et al  (2007).</citsent>
<aftsection>
<nextsent>2.
</nextsent>
<nextsent>supervised learning procedure - k-nn classifier (mitchell, 1997), trained.
</nextsent>
<nextsent>on multisemcor corpus3 is adopted.
</nextsent>
<nextsent>details are given in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2012">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the semantic role labeler works not as well as our parser and we reached therefore the fourth place (ranked by the macro f1 score) in the joint task for syntactic and semantic dependency parsing.
</prevsent>
<prevsent>depedendency parsing and semantic role labeling improved in the last years significantly.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
one of the reasons are conll shared tasks for syntactic dependency parsing in the years 2006, 2007 (buch holz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007) <papid> D07-1096 </papid>and the conll shared task for joint parsing of syntactic and semantic dependencies in the year 2008 and of cause this shared task in 2009, cf.</citsent>
<aftsection>
<nextsent>(surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</nextsent>
<nextsent>et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2013">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the semantic role labeler works not as well as our parser and we reached therefore the fourth place (ranked by the macro f1 score) in the joint task for syntactic and semantic dependency parsing.
</prevsent>
<prevsent>depedendency parsing and semantic role labeling improved in the last years significantly.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
one of the reasons are conll shared tasks for syntactic dependency parsing in the years 2006, 2007 (buch holz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007) <papid> D07-1096 </papid>and the conll shared task for joint parsing of syntactic and semantic dependencies in the year 2008 and of cause this shared task in 2009, cf.</citsent>
<aftsection>
<nextsent>(surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</nextsent>
<nextsent>et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2014">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>depedendency parsing and semantic role labeling improved in the last years significantly.
</prevsent>
<prevsent>one of the reasons are conll shared tasks for syntactic dependency parsing in the years 2006, 2007 (buch holz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007) <papid> D07-1096 </papid>and the conll shared task for joint parsing of syntactic and semantic dependencies in the year 2008 and of cause this shared task in 2009, cf.</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
(surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</citsent>
<aftsection>
<nextsent>et al, 2009).
</nextsent>
<nextsent>the conll shared task 2009 is to parse syntactic and semantic dependencies ofseven languages.
</nextsent>
<nextsent>therefore, training and development data in form of annotated corpora for catalan, chinese, czech, english, german, japanese and spanish is provided, cf.
</nextsent>
<nextsent>(taule?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2018">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et al, 2006; surdeanu et al, 2008; <papid> W08-2121 </papid>burchardt et al, 2006; kawahara et al, 2002).</prevsent>
<prevsent>there are two main approaches to dependencyparsing: maximum spanning tree (mst) based dependency parsing and transition based dependency parsing, cf.</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
(eisner, 1996; <papid> C96-1058 </papid>nivre et al, 2004; <papid> W04-2407 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>our system uses the first approach since we saw better chance to improve the parsing speed and additionally, the mst had so far slightly better parsing results.
</nextsent>
<nextsent>for the task of semantic role labeling, we adopted pipeline architecture where we used for each step the same learning technique (svm) since we opted for the possibility to build synchronous combined parser with one score function.
</nextsent>
<nextsent>we adopted the second order mst parsing algorithm as outlined by eisner (1996).<papid> C96-1058 </papid></nextsent>
<nextsent>this algorithm has higher accuracy compared to the first order parsing algorithm since it considers also siblings and grandchildren of node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2019">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et al, 2006; surdeanu et al, 2008; <papid> W08-2121 </papid>burchardt et al, 2006; kawahara et al, 2002).</prevsent>
<prevsent>there are two main approaches to dependencyparsing: maximum spanning tree (mst) based dependency parsing and transition based dependency parsing, cf.</prevsent>
</prevsection>
<citsent citstr=" W04-2407 ">
(eisner, 1996; <papid> C96-1058 </papid>nivre et al, 2004; <papid> W04-2407 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>our system uses the first approach since we saw better chance to improve the parsing speed and additionally, the mst had so far slightly better parsing results.
</nextsent>
<nextsent>for the task of semantic role labeling, we adopted pipeline architecture where we used for each step the same learning technique (svm) since we opted for the possibility to build synchronous combined parser with one score function.
</nextsent>
<nextsent>we adopted the second order mst parsing algorithm as outlined by eisner (1996).<papid> C96-1058 </papid></nextsent>
<nextsent>this algorithm has higher accuracy compared to the first order parsing algorithm since it considers also siblings and grandchildren of node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2020">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et al, 2006; surdeanu et al, 2008; <papid> W08-2121 </papid>burchardt et al, 2006; kawahara et al, 2002).</prevsent>
<prevsent>there are two main approaches to dependencyparsing: maximum spanning tree (mst) based dependency parsing and transition based dependency parsing, cf.</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
(eisner, 1996; <papid> C96-1058 </papid>nivre et al, 2004; <papid> W04-2407 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>our system uses the first approach since we saw better chance to improve the parsing speed and additionally, the mst had so far slightly better parsing results.
</nextsent>
<nextsent>for the task of semantic role labeling, we adopted pipeline architecture where we used for each step the same learning technique (svm) since we opted for the possibility to build synchronous combined parser with one score function.
</nextsent>
<nextsent>we adopted the second order mst parsing algorithm as outlined by eisner (1996).<papid> C96-1058 </papid></nextsent>
<nextsent>this algorithm has higher accuracy compared to the first order parsing algorithm since it considers also siblings and grandchildren of node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2022">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> labeled dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the following two approaches are comm onto solve this problem.
</prevsent>
<prevsent>an additional algorithm labels the edges or the parsing algorithm itself is extended and the labeling algorithm is integrated into the parsing algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
mcdonald et al (2006) <papid> W06-2932 </papid>use an additional algorithm.</citsent>
<aftsection>
<nextsent>their two stage model hasa good computational complexity since the labeling algorithm contributes again only cubic time complexity to the algorithm and keeps therefore the joint algorithm still cubic.
</nextsent>
<nextsent>the algorithm selects the highest scored label due to the score function score(wi, label) + score(wj , label) and inserts the highest scored label into matrix.
</nextsent>
<nextsent>the scores are also used in the parsing algorithms and added tothe edge scores which improves the overall parsing results as well.
</nextsent>
<nextsent>in the first order parsing scenario, this procedure is sufficient since no combination of edges are considered by the parsing algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2023">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> non-projective dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>however, they could show that system can gain accuracy of about 2-4% which is lot.
</prevsent>
<prevsent>the dependency parser developed in the last years use two different techniques for non-projective dependency parsing.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
nivre and nilsson (2005) <papid> P05-1013 </papid>uses tree rewriting which is the most common technique.</citsent>
<aftsection>
<nextsent>with this technique, the training input to the parser is first pro jectivized by applying minimal number of lifting operations to the non-projective edges and encoding information about these lifts in edge labels.
</nextsent>
<nextsent>after these operations, the trees are projective and therefore projective dependency parser can be applied.
</nextsent>
<nextsent>during the training, the parser learns also to built trees with the lifted edges and so indirect to builtnon-projective dependency trees by applying the inverse operations to the lifting on the projective tree.mcdonald and pereira (2006) <papid> E06-1011 </papid>developed technique to rearrange edges in the tree in postprocessing step after the projective parsing has takenplace.</nextsent>
<nextsent>their approximate dependency parsing algorithm searches first the highest scoring projective parse tree and then it rearranges edges in the tree until the rearrangements does not increase the score for the tree anymore.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2026">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> learning framework.  </section>
<citcontext>
<prevsection>
<prevsent>their argument for the algorithm is that most edges in tree even in language with lot of non-projective sentences, the portion of non-projective edges are still small and therefore by starting with the highest scoring projective tree, typ 68 ically the highest scoring non-projective tree is only small number of transformations away.our experiments showed that with the non projective approximate dependency parsing algorithm and threshold for the improv ment of score higher than about 0.7, the parsing accuracy improves even for english slightly.
</prevsent>
<prevsent>with threshold of 1.1, we got the highest improvements.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
as learning technique, we use margin infused relaxed algorithm (mira) as developed by crammer et al (2003) and applied to dependency parsing by mcdonald et al (2005).<papid> P05-1012 </papid></citsent>
<aftsection>
<nextsent>the online algorithm in figure 1 processes one training instance on each iteration, and updates the parameters accordingly.
</nextsent>
<nextsent>algorithm 1: mira ? = {sx, tx}xx=1 // the set of training data consists // of sentences and the corresponding dependency trees (0) = 0,v = 0 for = 1 to for = 1 to wi+1 = update wi according to instance (sx, tx) = + wi+1 = i+ 1 end for end for = v/(n x) the inner loop ite rates over all sentences of the training set while the outer loop repeats the train times.
</nextsent>
<nextsent>the algorithm returns an averaged weight vector and uses an auxiliary weight vector that accumulates the values of after each iteration.
</nextsent>
<nextsent>at the end, the algorithm computes the average of all weight vectors by dividing it by the number of training iterations and sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2027">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> learning framework.  </section>
<citcontext>
<prevsection>
<prevsent>at the end, the algorithm computes the average of all weight vectors by dividing it by the number of training iterations and sentences.
</prevsent>
<prevsent>this helps to avoid over fitting, cf.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
(collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>the update function computes the update to the weight vector wi during the training so that wrong classified edges of the training instances are possibly correctly classified.
</nextsent>
<nextsent>this is computed by increasing the weight for the correct features and decreasing the weight for wrong features of the vectors for the tree of the training set ftx ? wi and the vector for the predicted dependency tree ft ? wi.
</nextsent>
<nextsent>the update function tries to keep the change tothe parameter vector wi as small as possible for correctly classifying the current instance with difference at least as large as the loss of the incorrect classifications.
</nextsent>
<nextsent>table 1, 4 and 2 give an overview of the selected features for our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2031">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the components of the pipeline are predicate selection (ps), argument identification (ai), argument classification (ac), and word sense disambiguation (wsd).
</prevsent>
<prevsent>in order to select the predicates, we look up thelemmas in the prob bank, nom bank, etc. if available, cf.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
(palmer et al, 2005; <papid> J05-1004 </papid>meyers et al, 2004).<papid> W04-2705 </papid>for all other components, we use the support vector machine mira to select and classify the semantic role labels as well as to disambiguate the word senese.</citsent>
<aftsection>
<nextsent>the ai component identifies the arguments of each predicate.
</nextsent>
<nextsent>it ite rates over the predicates and over the words of sentence.
</nextsent>
<nextsent>in the case that the score function is large or equal to zero the argument is added to the set of arguments of the predicate in question.
</nextsent>
<nextsent>table 5 lists for the attribute identification and semantic role labeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2032">
<title id=" W09-1210.xml">efficient parsing of syntactic and semantic dependency structures </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the components of the pipeline are predicate selection (ps), argument identification (ai), argument classification (ac), and word sense disambiguation (wsd).
</prevsent>
<prevsent>in order to select the predicates, we look up thelemmas in the prob bank, nom bank, etc. if available, cf.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
(palmer et al, 2005; <papid> J05-1004 </papid>meyers et al, 2004).<papid> W04-2705 </papid>for all other components, we use the support vector machine mira to select and classify the semantic role labels as well as to disambiguate the word senese.</citsent>
<aftsection>
<nextsent>the ai component identifies the arguments of each predicate.
</nextsent>
<nextsent>it ite rates over the predicates and over the words of sentence.
</nextsent>
<nextsent>in the case that the score function is large or equal to zero the argument is added to the set of arguments of the predicate in question.
</nextsent>
<nextsent>table 5 lists for the attribute identification and semantic role labeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2033">
<title id=" W09-1208.xml">multilingual dependency learning a huge feature engineering method to semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>seven languages, english plus catalan, chinese, czech, german, japanese and spanish, are involved (taule?
</prevsent>
<prevsent>et al., 2008; palmer and xue, 2009; hajic?
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
et al, 2006;surdeanu et al, 2008; <papid> W08-2121 </papid>burchardt et al, 2006; kawahara et al, 2002).</citsent>
<aftsection>
<nextsent>this paper presents our research for participation in the semantic-only (srlonly) challenge of the conll-2009 shared task, with this study is partially supported by cerg grant 9040861 (cityu 1318/03h), cityu strategic research grant 7002037, projects 60673041 and 60873041 under the national natural science foundation of china and project 2006aa01z147 under the 863?
</nextsent>
<nextsent>national high-tech research and development of china.
</nextsent>
<nextsent>highlight on our strategy to select features from large candidate set for maximum entropy learning.
</nextsent>
<nextsent>we opt for the maximum entropy model with gaussian prior as our learning model for all classification subtasks in the shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2034">
<title id=" W09-1208.xml">multilingual dependency learning a huge feature engineering method to semantic dependency parsing </title>
<section> system survey.  </section>
<citcontext>
<prevsection>
<prevsent>our implementation of the model adopts l-bfgs algorithm for parameter optimization as usual.
</prevsent>
<prevsent>no additional feature selection techniques are applied.
</prevsent>
</prevsection>
<citsent citstr=" W08-2127 ">
our system is basically improved from its early version for conll-2008 (zhao and kit, 2008).<papid> W08-2127 </papid></citsent>
<aftsection>
<nextsent>by introducing virtual root for every predicates, the job to determine both argument labels and predicate senses is formulated as word-pair classification task in four languages, namely, catalan, spanish,czech and japanese.
</nextsent>
<nextsent>in other three languages, chinese, english and german, predicate sense classifier is individually trained before argument label classification.
</nextsent>
<nextsent>note that traditionally (or you maysay that most semantic parsing systems did so) argument identification and classification are handled in two-stage pipeline, while ours always tackles them in one step, in addition, predicate sense classification are also included in this unique learning/test step for four of all languages.
</nextsent>
<nextsent>we keep using word-pair classification procedure to formulate semantic dependency parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2036">
<title id=" W09-1208.xml">multilingual dependency learning a huge feature engineering method to semantic dependency parsing </title>
<section> pruning argument candidates.  </section>
<citcontext>
<prevsection>
<prevsent>as predicates overtly known in the share task, we only consider how to effectively prune argument candidates.we adopt five types of argument pruning strategies for seven languages.
</prevsent>
<prevsent>all of them assume that syntactic dependency parsing tree is available.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
as for chinese and english, we continue to use dependency version of the pruning algorithm of (xue and palmer, 2004) <papid> W04-3212 </papid>as described in (zhao and kit, 2008).<papid> W08-2127 </papid></citsent>
<aftsection>
<nextsent>the pruning algorithm is readdressed as the following.
</nextsent>
<nextsent>initialization: set the given predicate candidate as the current node;(1) the current node and all of its syntactic children are selected as argument candidates.
</nextsent>
<nextsent>(2) reset the current node to its syntactic head and repeat step (1) until the root is reached.
</nextsent>
<nextsent>note that the given predicate candidate itself is excluded from the argument candidate list for chinese, that is slightly different from english.the above pruning algorithm has been shown effective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2040">
<title id=" W09-1208.xml">multilingual dependency learning a huge feature engineering method to semantic dependency parsing </title>
<section> evaluation results.  </section>
<citcontext>
<prevsection>
<prevsent>the first is that two results for development and test sets in the same language are quite close.
</prevsent>
<prevsent>the second is about out-of domain (ood) task.
</prevsent>
</prevsection>
<citsent citstr=" W09-1209 ">
though for each ood task, we just used the same model trained from the respective language and did nothing to strengthen it, this does not hinder our system to obtain top results in czech and english ood tasks.in addition, the feature template sets from auto matical selection procedure in this task were used for the joint task of this shared task, and also output top results according to the average score of semantic labeled f1 (zhao et al, 2009).<papid> W09-1209 </papid></citsent>
<aftsection>
<nextsent>59 average catalan chinese czech english german japanese spanish development with gold 81.24 81.52 78.32 86.96 84.19 77.75 78.67 81.32 development 80.46 80.66 77.90 85.35 84.01 76.55 78.41 80.39 test (official scores) 80.47 80.32 77.72 85.19 85.44 75.99 78.15 80.46 out-of-domain 74.34 85.44 73.31 64.26 table 6: semantic labeled f1 catalan chinese czech english german japanese spanish sense training memory (mb) 418.0 136.0 63.0 training time (min.)
</nextsent>
<nextsent>11.0 2.5 1.7 test time (min.)
</nextsent>
<nextsent>0.7 0.2 0.03 argument training memory (gb) 0.4 3.7 3.2 3.8 0.2 1.4 0.4 training time (hours) 3.0 13.8 24.9 12.4 0.2 6.1 4.4 test time (min.)
</nextsent>
<nextsent>3.0 144.0 27.1 88.0 1.0 4.2 7.0 table 7: computational cost
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2041">
<title id=" W09-1803.xml">bounding and comparing methods for correlation clustering beyond ilp </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>ng and cardie(2002) extend this work with better features, and develop the best-link heuristic, which finds better solutions.
</prevsent>
<prevsent>mccallum and wellner (2004) explicitly describe the problem as correlation clustering and use an approximate technique (bansal et al, 2004) to enforce transitivity.
</prevsent>
</prevsection>
<citsent citstr=" P08-2012 ">
recently finkel and manning(2008) <papid> P08-2012 </papid>show that the optimal ilp solution outperforms the first and best-link methods.</citsent>
<aftsection>
<nextsent>cohen and richman (2002) experiment with various heuristic solutions for the cross-document coreference task of grouping references to named entities.
</nextsent>
<nextsent>finally, correlation clustering has proven useful in several discourse tasks.
</nextsent>
<nextsent>barzilay and lapata (2006) <papid> N06-1046 </papid>use it for content aggregation in generation system.</nextsent>
<nextsent>in malioutov and barzilay (2006), it is used for topic segmentation since segments must be contiguous,the problem can be solved in polynomial time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2042">
<title id=" W09-1803.xml">bounding and comparing methods for correlation clustering beyond ilp </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>cohen and richman (2002) experiment with various heuristic solutions for the cross-document coreference task of grouping references to named entities.
</prevsent>
<prevsent>finally, correlation clustering has proven useful in several discourse tasks.
</prevsent>
</prevsection>
<citsent citstr=" N06-1046 ">
barzilay and lapata (2006) <papid> N06-1046 </papid>use it for content aggregation in generation system.</citsent>
<aftsection>
<nextsent>in malioutov and barzilay (2006), it is used for topic segmentation since segments must be contiguous,the problem can be solved in polynomial time.
</nextsent>
<nextsent>elsner and charniak (2008) <papid> P08-1095 </papid>address the related problem of disentanglement (which we explore in section 5.3), doing inference with the voting greedy al gorithm.</nextsent>
<nextsent>bertolacci and wirth (2007), goder and filkov (2008) and gionis et al (2007) conduct experiment son the closely related problem of consensus clustering, often solved by reduction to correlation cluster ing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2043">
<title id=" W09-1803.xml">bounding and comparing methods for correlation clustering beyond ilp </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>barzilay and lapata (2006) <papid> N06-1046 </papid>use it for content aggregation in generation system.</prevsent>
<prevsent>in malioutov and barzilay (2006), it is used for topic segmentation since segments must be contiguous,the problem can be solved in polynomial time.</prevsent>
</prevsection>
<citsent citstr=" P08-1095 ">
elsner and charniak (2008) <papid> P08-1095 </papid>address the related problem of disentanglement (which we explore in section 5.3), doing inference with the voting greedy al gorithm.</citsent>
<aftsection>
<nextsent>bertolacci and wirth (2007), goder and filkov (2008) and gionis et al (2007) conduct experiment son the closely related problem of consensus clustering, often solved by reduction to correlation clustering.
</nextsent>
<nextsent>the input to this problem is set of clusterings; the output is median?
</nextsent>
<nextsent>clustering which minimizes the sum of (rand) distance to the inputs.
</nextsent>
<nextsent>although these papers investigate some of the same algorithms we use, they use an unrealistic lower bound, and so cannot convincingly evaluate absolute performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2052">
<title id=" W08-1130.xml">osu2 generating referring expressions with a maximum entropy classifier </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W01-0813 ">
selection of natural-sounding referring expressions is useful in text generation and information summarization (kan et al, 2001).<papid> W01-0813 </papid></citsent>
<aftsection>
<nextsent>we use discourse-level feature predicates in maximum entropy classifier (berger et al, 1996) <papid> J96-1002 </papid>with binary and n-class classification to select referring expressions from list.</nextsent>
<nextsent>wefind that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward refer ring expressions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2054">
<title id=" W08-1130.xml">osu2 generating referring expressions with a maximum entropy classifier </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>selection of natural-sounding referring expressions is useful in text generation and information summarization (kan et al, 2001).<papid> W01-0813 </papid></prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we use discourse-level feature predicates in maximum entropy classifier (berger et al, 1996) <papid> J96-1002 </papid>with binary and n-class classification to select referring expressions from list.</citsent>
<aftsection>
<nextsent>wefind that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward refer ring expressions.
</nextsent>
<nextsent>referring expression generation is the task of inserting noun phrases that refer to mentioned extra linguistic entity into text.
</nextsent>
<nextsent>regis helpful for tasks such as text generation and information summarization (kan et al, 2001).<papid> W01-0813 </papid></nextsent>
<nextsent>the referring expressions generation challenge (belz and gatt, 2008) includes task based on the grec corpus, collection of introductory texts from wikipedia that includes articles about cities, countries, rivers, people, and mountains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2058">
<title id=" W08-1805.xml">a data driven approach to query expansion in question answering </title>
<section> answer extraction (ae) given knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>relevance feedback is widely explored technique for query expansion.
</prevsent>
<prevsent>it is often done using specific measure to select terms using limited set of ranked documents of size r; using larger set will bring term distribution closer to values over the whole corpus, and away from ones in documents relevant to query terms.
</prevsent>
</prevsection>
<citsent citstr=" H05-1020 ">
techniques are used to identify phrases relevant to query topic, in order to reduce noise (such as terms with low corpus frequency that relate to only single article) and query drift (roussinov and fan, 2005; <papid> H05-1020 </papid>allan, 1996).</citsent>
<aftsection>
<nextsent>in the context of qa, pizzato (2006) employs blind rf using the aquaint corpus in an attempt to improve performance when answering factoidquestions on personal names.
</nextsent>
<nextsent>this is similar approach to some content in this paper, though limited to the study of named entities, and does not attempt to examine extensions from the existing answer data.monz (2003) finds negative result when applying blind feedback for qa in trec 9, 10 and 11,and neutral result for trec 7 and 8s ad hoc retrieval tasks.
</nextsent>
<nextsent>monzs experiment, using = 10 and standard rocchio term weighting, also found further reduction in performance when was reduced (from 10 to 5).
</nextsent>
<nextsent>this is an isolated experiment using just one measure on limited set of questions, with no use of the available answer texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2059">
<title id=" W08-1510.xml">speech to speech translation for nurse patient interaction </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>however, if the acquisition of structural information is kept separate from the acquisition of vocabulary, the resulting system should learn both levels more efficiently.
</prevsent>
<prevsent>and by modifying the existing corpus to separate structure and vocabulary, we have been able to take full advantage of all the information in the bilingual corpus, producing higher quality mt without requiring large bodies of training data.
</prevsent>
</prevsection>
<citsent citstr=" P05-1069 ">
the most recent modification to this approach was the use of distance-based ordering (zens and ney, 2003) and lexicalized ordering (tillmann and zhang, 2005) <papid> P05-1069 </papid>to allow for multiple language models, including non-word models such as part-of-speech improved search algorithm, in order to improve its speed and effi ciency.</citsent>
<aftsection>
<nextsent>3.1.4 vui+gui system s-minds has flexible user interface that can be configured to use vui only or vui+gui for either the english speaker or the second language speaker.
</nextsent>
<nextsent>also, the english speaker can experience different user interface than the second-language speaker.
</nextsent>
<nextsent>the system has the flexibility to use multiple types of microphones, including open microphones, headsets, and telephone headsets.
</nextsent>
<nextsent>speech recognition can be confirmed by vui, gui, or both, and it can be configured to verify all utterances, no utterances, or just utterances that fall below certain confidence level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2060">
<title id=" W09-0440.xml">on the robustness of syntactic and semantic features for automatic mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is in many cases attributable to loss of recall, due to parsing errors or to lack of parsing at all, which may be partially ameliorated by backing off to lexical similarity.
</prevsent>
<prevsent>recently, there is growing interest in the development of automatic evaluation metrics which exploit linguistic knowledge at the syntactic and semantic levels.
</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
for instance, we may find metrics which compute similarities over shallow syntactic structures/sequences (gimenez and ma`rquez, 2007; popovic and ney, 2007), constituency trees (liu and gildea, 2005) <papid> W05-0904 </papid>and dependency trees (liu and gildea, 2005; <papid> W05-0904 </papid>amigo?</citsent>
<aftsection>
<nextsent>et al, 2006; mehay and brew, 2007; owczarzak et al, 2007).<papid> W07-0411 </papid></nextsent>
<nextsent>we may also find metrics operating over shallow semantic structures, such as named entities and semantic roles (gimenez and ma`rquez, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2062">
<title id=" W09-0440.xml">on the robustness of syntactic and semantic features for automatic mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, there is growing interest in the development of automatic evaluation metrics which exploit linguistic knowledge at the syntactic and semantic levels.
</prevsent>
<prevsent>for instance, we may find metrics which compute similarities over shallow syntactic structures/sequences (gimenez and ma`rquez, 2007; popovic and ney, 2007), constituency trees (liu and gildea, 2005) <papid> W05-0904 </papid>and dependency trees (liu and gildea, 2005; <papid> W05-0904 </papid>amigo?</prevsent>
</prevsection>
<citsent citstr=" W07-0411 ">
et al, 2006; mehay and brew, 2007; owczarzak et al, 2007).<papid> W07-0411 </papid></citsent>
<aftsection>
<nextsent>we may also find metrics operating over shallow semantic structures, such as named entities and semantic roles (gimenez and ma`rquez, 2007).
</nextsent>
<nextsent>linguistic metrics have been proven to produce more reliable system rankings than metrics limiting their scope to the lexical dimension, in particular when applied to test beds with rich system typology, i.e., test beds in which there are automatic outputs produced by systems based on different paradigms, e.g., statistical, rule-based and human-aided (gimenez and ma`rquez, 2007).
</nextsent>
<nextsent>the reason is that they are able to capture deep mtquality distinctions which occur beyond the shallow level of lexical similarities.
</nextsent>
<nextsent>however, these metrics have the limitation of relying on automatic linguistic processors, tools which are not equally available for all languages and whose performance may vary depending onthe type of analysis conducted and the application domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2063">
<title id=" W09-0440.xml">on the robustness of syntactic and semantic features for automatic mt evaluation </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>2.1 exploiting semantic similarity for.
</prevsent>
<prevsent>automatic mt evaluationdr? metrics analyze similarities between automatic and reference translations by comparing their respective drss.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
these are automatically obtained using the c&c; tools (clark and curran, 2004)<papid> P04-1014 </papid>2.</citsent>
<aftsection>
<nextsent>sentences are first parsed on the basis of combinatory categorial grammar (bos et al, 2004).<papid> C04-1180 </papid></nextsent>
<nextsent>then, the boxer component (bos, 2005) extracts drss.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2064">
<title id=" W09-0440.xml">on the robustness of syntactic and semantic features for automatic mt evaluation </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>automatic mt evaluationdr? metrics analyze similarities between automatic and reference translations by comparing their respective drss.
</prevsent>
<prevsent>these are automatically obtained using the c&c; tools (clark and curran, 2004)<papid> P04-1014 </papid>2.</prevsent>
</prevsection>
<citsent citstr=" C04-1180 ">
sentences are first parsed on the basis of combinatory categorial grammar (bos et al, 2004).<papid> C04-1180 </papid></citsent>
<aftsection>
<nextsent>then, the boxer component (bos, 2005) extracts drss.
</nextsent>
<nextsent>as an illustration, figure 1 shows the drs representation for the sentence everyman loves mary.?.
</nextsent>
<nextsent>the reader may find the out put of the boxer component (top) together with the equivalent first-order formula (bottom).
</nextsent>
<nextsent>drs may be viewed as semantic trees, which are built through the application of two types of drs conditions:basic conditions: one-place properties (pred icates), two-place properties (relations), named entities, time-expressions, cardinal expressions and equalities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2066">
<title id=" W09-0440.xml">on the robustness of syntactic and semantic features for automatic mt evaluation </title>
<section> experimental work.  </section>
<citcontext>
<prevsection>
<prevsent>chinese-to-english test bed description ? human likeness: metrics are evaluated interms of their ability to capture the features which distinguish human from automatic translations.
</prevsent>
<prevsent>the underlying assumption is that good translations should resemble human translations.
</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
human likeness is usually measured on the basis of discriminative power (lin and och, 2004<papid> P04-1077 </papid>b; amigo?</citsent>
<aftsection>
<nextsent>et al, 2005).
</nextsent>
<nextsent>in this work, metrics are evaluated both in terms of human acceptability and human likeness.
</nextsent>
<nextsent>in thecase of human acceptability, metric quality is measured on the basis of correlation with human assessments both at the sentence and document (i.e., system) levels.
</nextsent>
<nextsent>we compute pearson correlation coefficients.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2068">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> natural language parsing.  </section>
<citcontext>
<prevsection>
<prevsent>as we will see with some of our experiments, it may be necessary to find trade-off between generalizability and interpretability.
</prevsent>
<prevsent>further, it is not guaranteed that syntactic rulesinfered from manually annotated treebank produce the best language model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
this leads to 49 methods that use semi-supervised techniques on treebank-infered grammar backbone, such as (matsuzaki et al, 2005; <papid> P05-1010 </papid>petrov et al, 2006)<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>the plan of the paper is as follows : in the next section, we describe the available treebank for french, and how its structures can be interpreted.
</nextsent>
<nextsent>in section 3, we describe the typical problems encountered when parsing using plain probabilistic context-free grammar, and existing algorithmic solutions that try to circumvent these problems.
</nextsent>
<nextsent>next we describe experiments and results when training parsers on the french data.
</nextsent>
<nextsent>finally, we discuss related work and conclude.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2069">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> natural language parsing.  </section>
<citcontext>
<prevsection>
<prevsent>as we will see with some of our experiments, it may be necessary to find trade-off between generalizability and interpretability.
</prevsent>
<prevsent>further, it is not guaranteed that syntactic rulesinfered from manually annotated treebank produce the best language model.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
this leads to 49 methods that use semi-supervised techniques on treebank-infered grammar backbone, such as (matsuzaki et al, 2005; <papid> P05-1010 </papid>petrov et al, 2006)<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>the plan of the paper is as follows : in the next section, we describe the available treebank for french, and how its structures can be interpreted.
</nextsent>
<nextsent>in section 3, we describe the typical problems encountered when parsing using plain probabilistic context-free grammar, and existing algorithmic solutions that try to circumvent these problems.
</nextsent>
<nextsent>next we describe experiments and results when training parsers on the french data.
</nextsent>
<nextsent>finally, we discuss related work and conclude.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2072">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> algorithms for probabilistic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>though probabilistic context free grammars (pcfg) is baseline formalism for probabilistic parsing, it suffers fundamental problem for the purpose of natural language parsing : the independence assumptions made by the model are too strong.
</prevsent>
<prevsent>in other words all decisions are local to grammar rule.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
however as clearly pointed out by (johnson,1998) <papid> J98-4004 </papid>decisions have to take into account non local grammatical properties: for instance noun phrase realized in subject position is more likely tobe realized by pronoun than noun phrase realized in object position.</citsent>
<aftsection>
<nextsent>solving this first methodological issue, has led to solutions dubbed here after as un lexicalized statistical parsing (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003<papid> P03-1054 </papid>a; matsuzaki et al., 2005; <papid> P05-1010 </papid>petrov et al, 2006)<papid> P06-1055 </papid></nextsent>
<nextsent>a second class of non local decisions to be taken into account while parsing natural languages are related to handling lexical constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2075">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> algorithms for probabilistic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>in other words all decisions are local to grammar rule.
</prevsent>
<prevsent>however as clearly pointed out by (johnson,1998) <papid> J98-4004 </papid>decisions have to take into account non local grammatical properties: for instance noun phrase realized in subject position is more likely tobe realized by pronoun than noun phrase realized in object position.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
solving this first methodological issue, has led to solutions dubbed here after as un lexicalized statistical parsing (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003<papid> P03-1054 </papid>a; matsuzaki et al., 2005; <papid> P05-1010 </papid>petrov et al, 2006)<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>a second class of non local decisions to be taken into account while parsing natural languages are related to handling lexical constraints.
</nextsent>
<nextsent>as shown above the subcategorization properties ofa predicative word may have an impact on the decisions concerning the tree structures to be associated to given sentence.
</nextsent>
<nextsent>solving this second methodological issue has led to solutions dubbed hereafter as lexicalized parsing (charniak, 2000; <papid> A00-2018 </papid>collins, 1999).</nextsent>
<nextsent>in supervised setting, third and practical problem turns out to be critical: that of data sparseness since available treebanks are generally too small to get reasonable probability estimates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2084">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> algorithms for probabilistic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>a second class of non local decisions to be taken into account while parsing natural languages are related to handling lexical constraints.
</prevsent>
<prevsent>as shown above the subcategorization properties ofa predicative word may have an impact on the decisions concerning the tree structures to be associated to given sentence.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
solving this second methodological issue has led to solutions dubbed hereafter as lexicalized parsing (charniak, 2000; <papid> A00-2018 </papid>collins, 1999).</citsent>
<aftsection>
<nextsent>in supervised setting, third and practical problem turns out to be critical: that of data sparseness since available treebanks are generally too small to get reasonable probability estimates.
</nextsent>
<nextsent>three class of solutions are possible to reduce datasparseness: (1) enlarging the data manually or automatically (e.g.
</nextsent>
<nextsent>(mcclosky et al, 2006) <papid> N06-1020 </papid>uses self training to perform this step) (2) smoothing, usually this is performed using markov ization procedure (collins, 1999; klein and manning, 2003<papid> P03-1054 </papid>a) and (3) make the data more coarse (i.e. clustering).</nextsent>
<nextsent>3.1 lexicalized algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2085">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> algorithms for probabilistic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>in supervised setting, third and practical problem turns out to be critical: that of data sparseness since available treebanks are generally too small to get reasonable probability estimates.
</prevsent>
<prevsent>three class of solutions are possible to reduce datasparseness: (1) enlarging the data manually or automatically (e.g.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
(mcclosky et al, 2006) <papid> N06-1020 </papid>uses self training to perform this step) (2) smoothing, usually this is performed using markov ization procedure (collins, 1999; klein and manning, 2003<papid> P03-1054 </papid>a) and (3) make the data more coarse (i.e. clustering).</citsent>
<aftsection>
<nextsent>3.1 lexicalized algorithm.
</nextsent>
<nextsent>the first algorithm we use is the lexicalized parser of (collins, 1999).
</nextsent>
<nextsent>it is called lexicalized, as it annotates nonterminal nodes with an additional latent symbol: the head word of the subtree.
</nextsent>
<nextsent>this additional information attached to the categories aims at capturing bilexical dependencies in order to perform informed attachment choices.the addition of these numerous latent symbols to nonterminals naturally entails an over specialization of the resulting models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2091">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> algorithms for probabilistic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>to ensure generalization, it therefore requires to add additional simplifying assumptions formulated asa variant of usual nave bayesian-style simplifying assumptions: the probability of emitting non 51 head node is assumed to depend on the head and the mother node only, and not on other sibling nodes1.since collins demonstrated his models to significantly improve parsing accuracy over bare pcfg, lexicalization has been thought as major feature for probabilistic parsing.
</prevsent>
<prevsent>however two problems are worth stressing here: (1) the reason why these models improve over bare pcfgs is not guaranteed to be tied to the fact that they capturebilexical dependencies and (2) there is no guarantee that capturing non local lexical constraints yields an optimal language model.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
concerning (1) (gildea, 2001) <papid> W01-0521 </papid>showed that full lexicalization has indeed small impact on results : he reimplemented an emulation of collins?</citsent>
<aftsection>
<nextsent>model1 and found that removing all references to bilexical dependencies in the statistical model2, resulted in very small parsing performance decrease (parseval recall on wsj decreased from 86.1 to 85.6).
</nextsent>
<nextsent>further studies conducted by (bikel, 2004<papid> W04-3224 </papid>a) proved indeed that bilexical information were used by the most probable parses.</nextsent>
<nextsent>the idea is that most bilexical parameters are very similar to their back-off distribution and have therefore minor impact.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2092">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> algorithms for probabilistic grammar.  </section>
<citcontext>
<prevsection>
<prevsent>concerning (1) (gildea, 2001) <papid> W01-0521 </papid>showed that full lexicalization has indeed small impact on results : he reimplemented an emulation of collins?</prevsent>
<prevsent>model1 and found that removing all references to bilexical dependencies in the statistical model2, resulted in very small parsing performance decrease (parseval recall on wsj decreased from 86.1 to 85.6).</prevsent>
</prevsection>
<citsent citstr=" W04-3224 ">
further studies conducted by (bikel, 2004<papid> W04-3224 </papid>a) proved indeed that bilexical information were used by the most probable parses.</citsent>
<aftsection>
<nextsent>the idea is that most bilexical parameters are very similar to their back-off distribution and have therefore minor impact.
</nextsent>
<nextsent>in the case of french, this fact can only be more true, with one third of training data compared to english, and with much richer inflection that worsens lexical data sparseness.concerning (2) the addition of head word annotations is tied to the use of manually defined heuristics highly dependent on the annotation scheme of the ptb.
</nextsent>
<nextsent>for instance, collins?
</nextsent>
<nextsent>models integrate treatment of coordination that is not adequate for the ftb-like coordination annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2126">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>it clusters unknown words using typographical and morphological information.
</prevsent>
<prevsent>we 3(petrov et al, 2006)<papid> P06-1055 </papid>obtain an f-score=90.1 for sentences of less than 40 words.</prevsent>
</prevsection>
<citsent citstr=" P05-1038 ">
adapted these clues to french, following (arun and keller, 2005).<papid> P05-1038 </papid></citsent>
<aftsection>
<nextsent>finally we use as baseline standard pcfg algorithm, coupled with trigram tagger (we refer to this setup as tnt/lncky algorithm4).metrics for evaluation, we use the standard parseval metric of labeled precision/recall, along with unlabeled dependency evaluation, which isknown as more annotation-neutral metric.
</nextsent>
<nextsent>unlabeled dependencies are computed using the (lin, 1995) algorithm, and the dybro-johansens head propagation rules cited above5.
</nextsent>
<nextsent>the unlabeled dependency f-score gives the percentage of in put words (excluding punctuation) that receive the correct head.as usual for probabilistic parsing results, there sults are given for sentences of the test set of less than 40 words (which is true for 992 sentences of the test set), and punctuation is ignored for f-score computation with both metrics.
</nextsent>
<nextsent>4.2 comparison using minimal tagsets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2127">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>89.95 85.72 86.90 79.37 unlab.
</prevsent>
<prevsent>dep.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
f1 90.09 85.73 87.25 79.44 table 1: results for parsers trained on ftb with minimal tagset 4the tagger is tnt (brants, 2000), <papid> A00-1031 </papid>and the parser is lncky, that is distributed by mark johnson (http://www.cog.brown.edu/mj/software.htm).</citsent>
<aftsection>
<nextsent>formally because of the tagger, this is not strict pcfg setup.
</nextsent>
<nextsent>rather, it gives practical trade-off, in which the tagger includes the lexical smoothing for unknown and rare words.5for this evaluation, the gold constituent trees are converted into pseudo-gold dependency trees (that may contain errors).
</nextsent>
<nextsent>then parsed constituent trees are converted into parsed dependency trees, that are matched against the pseudo-gold trees.
</nextsent>
<nextsent>53 4.3 impact of training data size.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2134">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>impact should be more and more important as training material augments.
</prevsent>
<prevsent>0 2000 4000 6000 8000 10000 76 78 80 82 84 86 88 number of training sentences pa rs ev al s co re bky terminal=form+tag bky terminal=lemma+tag bky terminal=tagfigure 4: impact of clustering word forms (train ing on ftb with cc-tagset, in perfect-tagging)
</prevsent>
</prevsection>
<citsent citstr=" L08-1246 ">
previous works on french probabilistic parsing are those of (arun and keller, 2005), (<papid> P05-1038 </papid>schluter and van genabith, 2007), (schluter and van genabith, 2008).<papid> L08-1246 </papid></citsent>
<aftsection>
<nextsent>one major difficulty for comparison is thatall three works use different version of the training corpus.
</nextsent>
<nextsent>arun reports results on probabilistic parsing, using an older version of the ftb and using lexicalized models (collins m1 and m2 models, and the bigram model).
</nextsent>
<nextsent>it is difficult to compare our results with aruns work, since the tree bank he has used is obsolete (ftb-v0).
</nextsent>
<nextsent>he obtains for model 1 : lr=80.35 / lp=79.99, and for the bigram model : lr=81.15 / lp=80.84, with minimal tagset and internal tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2137">
<title id=" W09-1008.xml">on statistical parsing of french with supervised and semi supervised strategies </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>hence our conclusions (words help even with un lexicalized algorithm,and further grouping words into lemmas helps) hold independently of sampling.
</prevsent>
<prevsent>55 tagset (table 1) are comparable for collinsm1, and nearly 5 points higher for bky.
</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
it is also interesting to review (arun and keller, 2005) <papid> P05-1038 </papid>conclusion, built on comparison with the german situation : at that time lexicalization was thought (dubey and keller, 2003) <papid> P03-1013 </papid>to have no sizable improvement on german parsing, trained on the negra treebank, that uses flat structures.</citsent>
<aftsection>
<nextsent>so(arun and keller, 2005) <papid> P05-1038 </papid>conclude that since lexicalization helps much more for parsing french, with flat annotation, then word-order flexibility is the key-factor that makes lexicalization useful (if word order is fixed, cf.</nextsent>
<nextsent>french and english) and useless (if word order is flexible, cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2145">
<title id=" W09-1005.xml">great a finite state machine translation toolkit implementing a grammatical inference approach for transducer inference giati </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ti?
</prevsent>
<prevsent>, among all possible target strings t, that maximises the posterior probability: t?
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
= argmax pr(t|s) (1)the conditional probability pr(t|s) can be replaced by joint probability distribution pr(s, t) which is modelled by stochastic transducer being inferred through the giati methodology (casacu berta et al, 2004; casacuberta and vidal, 2004): <papid> J04-2004 </papid>t?</citsent>
<aftsection>
<nextsent>= argmax pr(s, t) (2)this paper describes great, software package for bilingual modelling from parallel corpus.
</nextsent>
<nextsent>great is finite-state toolkit which was bornto overcome the computational problems that previous implementations of giati (pic?, 2005) had in practice when huge amounts of data were used.even more, great is the result of very meticulous study of giati models, which improves the treatment of smoothing transitions in decoding time, and that also reduces the required time to translate an input sentence by means of an analysis that will depend on the granularity of the symbols.
</nextsent>
<nextsent>experiments for state-of-the-art, voluminous translation task, such as the europarl, are reported.
</nextsent>
<nextsent>in (gonzlez and casacuberta, 2007), the so called phrase-based finite-state transducers were concluded to be better modelling option forthis task than the ones that derive from word based approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2147">
<title id=" W08-1602.xml">context inducing nouns </title>
<section> what is complement-taking noun?.  </section>
<citcontext>
<prevsection>
<prevsent>(6) the situation that she had gotten herself into paralyzed bob.
</prevsent>
<prevsent>she had gotten herself into situation.
</prevsent>
</prevsection>
<citsent citstr=" W06-3907 ">
to explain how this is possible, we introduce the notion of implicative contexts (nairn et al, 2006), <papid> W06-3907 </papid>and claim that complement-taking nouns introduce context for the complement, whereas no such context is created for the adjuncts.</citsent>
<aftsection>
<nextsent>perhaps the easiest way to think of context is to imagine embedding the complement in an extra layer, with the layer adding information about how to adjust thetruth-value of its contents.2 this allows us to conclude in (5) that the speaker believes that mary and bob exist, as does the event of bobs paralysis, butthe event mary was ill does not.
</nextsent>
<nextsent>these are refered to as the (un)instantiability of the components in the sentence.
</nextsent>
<nextsent>contexts can be embedded within each other recursively, as in (7).
</nextsent>
<nextsent>note that these semantic contexts often, but not always, correspond to syntactic embedding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2150">
<title id=" W08-1602.xml">context inducing nouns </title>
<section> finding complement-taking nouns.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 syntactic classification.
</prevsent>
<prevsent>however, there are many complement-taking nouns that are not deverbal.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
to expand our lexicon of these nouns, we started with seed set garnered from the penn treebank (marcus et al., 1994), <papid> H94-1020 </papid>which uses distinctive tree structures for complement-taking nouns, and small list of linguistically prominent nouns.</citsent>
<aftsection>
<nextsent>for each of these lexical items, we extracted words in the same semantic class from wordnet.
</nextsent>
<nextsent>classes include words like fact, which direct attention to the clausal complement, as in (15), and nouns expressing emotion, as in (16).
</nextsent>
<nextsent>(15) its fact that mary came.
</nextsent>
<nextsent>(16) bobs joy that mary had returned reduced him to tears.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2151">
<title id=" W08-1602.xml">context inducing nouns </title>
<section> testing.  </section>
<citcontext>
<prevsection>
<prevsent>the test suites are run andthe results reported as part of the daily regression testing (chatzichrisafis et al, 2007).
</prevsent>
<prevsent>both naturally occurring and hand-crafted examples are used to ensure that the correct implications are being drawn.
</prevsent>
</prevsection>
<citsent citstr=" W08-0506 ">
natural examples test interactions between phenomena such as noun complementation and copular constructions, while hand-crafted examples allow isolation of the phenomenon and show that all cases are being tested (cohen et al,2008), <papid> W08-0506 </papid>e.g., that the correct ent ailments emerge under negation as well as in the positive case.our current test suites contain about 180 handcrafted examples.</citsent>
<aftsection>
<nextsent>the number of natural examples is harder to count as they occur somewhat rarely in the mixed-phenomena testsuites.
</nextsent>
<nextsent>one of our natural example files, which is based on newswire extracts from the pascal recognizing textual entailment challenge (dagan et al, 2005), shows an approximate breakdown of the uses of the word that is as shown in (23).
</nextsent>
<nextsent>this sample, which is somewhat biased towards verbal complements since it contains many examples that can be paraphrased as said that, nonetheless shows the relative scarcity of noun complements in the wild and underscores the importance of hand-crafted examples 13 for testing purposes.
</nextsent>
<nextsent>it it is clear that these noun complements were being analyzed incorrectly be fore; what is unclear is how much of an impact the mis analysis would have caused.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2154">
<title id=" W08-2105.xml">transforming meaning representation grammars to improve semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.query language to execute database queries.
</prevsent>
<prevsent>a machine learning system for semantic parsing takes nl sentences paired with their respective mrs as training data and induces semantic parser which can then map novel nl sentences into their mrs. the grammar of an mrl, which we will call meaning representation grammar (mrg), is assumed to be deterministic and context-free which is true for grammars of almost all the computer executable languages.
</prevsent>
</prevsection>
<citsent citstr=" P06-1115 ">
a semantic parsing learning system typically exploits the given mrg of the mrl to learn semantic parser (kate andmooney,2006; <papid> P06-1115 </papid>wong and mooney, 2006).<papid> N06-1056 </papid></citsent>
<aftsection>
<nextsent>although in different ways, but the systems presented in these papers learn how the nl phrases relate to the productions of the mrg, and using this information they parse test sentence to compositionally generate its best mr. in order to learn good semantic parser, it is necessary that the productions ofthe mrg accurately represent the semantics being expressed by the natural language.
</nextsent>
<nextsent>however, an mrl and its mrg are typically designed to best suit the application with little consideration for how well they correspond to the semantics of natural language.
</nextsent>
<nextsent>some other semantic parser learning systems which need mrl in the form of prolog (tang and mooney, 2001) or ?-calculus (zettlemoyer and collins, 2007; wong and mooney, 2007) <papid> P07-1121 </papid>do notuse productions of the mrg but instead use predicates of the mrl.</nextsent>
<nextsent>however, in order to learn good semantic parser, they still require that these predicates correspond well with the semantics of the natural language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2155">
<title id=" W08-2105.xml">transforming meaning representation grammars to improve semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.query language to execute database queries.
</prevsent>
<prevsent>a machine learning system for semantic parsing takes nl sentences paired with their respective mrs as training data and induces semantic parser which can then map novel nl sentences into their mrs. the grammar of an mrl, which we will call meaning representation grammar (mrg), is assumed to be deterministic and context-free which is true for grammars of almost all the computer executable languages.
</prevsent>
</prevsection>
<citsent citstr=" N06-1056 ">
a semantic parsing learning system typically exploits the given mrg of the mrl to learn semantic parser (kate andmooney,2006; <papid> P06-1115 </papid>wong and mooney, 2006).<papid> N06-1056 </papid></citsent>
<aftsection>
<nextsent>although in different ways, but the systems presented in these papers learn how the nl phrases relate to the productions of the mrg, and using this information they parse test sentence to compositionally generate its best mr. in order to learn good semantic parser, it is necessary that the productions ofthe mrg accurately represent the semantics being expressed by the natural language.
</nextsent>
<nextsent>however, an mrl and its mrg are typically designed to best suit the application with little consideration for how well they correspond to the semantics of natural language.
</nextsent>
<nextsent>some other semantic parser learning systems which need mrl in the form of prolog (tang and mooney, 2001) or ?-calculus (zettlemoyer and collins, 2007; wong and mooney, 2007) <papid> P07-1121 </papid>do notuse productions of the mrg but instead use predicates of the mrl.</nextsent>
<nextsent>however, in order to learn good semantic parser, they still require that these predicates correspond well with the semantics of the natural language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2156">
<title id=" W08-2105.xml">transforming meaning representation grammars to improve semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although in different ways, but the systems presented in these papers learn how the nl phrases relate to the productions of the mrg, and using this information they parse test sentence to compositionally generate its best mr. in order to learn good semantic parser, it is necessary that the productions ofthe mrg accurately represent the semantics being expressed by the natural language.
</prevsent>
<prevsent>however, an mrl and its mrg are typically designed to best suit the application with little consideration for how well they correspond to the semantics of natural language.
</prevsent>
</prevsection>
<citsent citstr=" P07-1121 ">
some other semantic parser learning systems which need mrl in the form of prolog (tang and mooney, 2001) or ?-calculus (zettlemoyer and collins, 2007; wong and mooney, 2007) <papid> P07-1121 </papid>do notuse productions of the mrg but instead use predicates of the mrl.</citsent>
<aftsection>
<nextsent>however, in order to learn good semantic parser, they still require that these predicates correspond well with the semantics of the natural language.
</nextsent>
<nextsent>there are also systems which learn semantic parsers from more detailed training data in the form of semantically augmented parse trees of nl sentences in which each internal node has syntactic and semantic label (ge 33 (a) nl: if the ball is in our midfield then player 5 should go to (-5,0).
</nextsent>
<nextsent>mr: (bpos (rec (pt -32 -35)(pt 0 35)) (do (player our {5})(pos (pt -5 0)))) (b) nl: which is the longest river in texas?
</nextsent>
<nextsent>mr: answer(longest(river(loc_2(stateid(texas?))))) (c) nl: which is the longest river in texas?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2157">
<title id=" W08-2105.xml">transforming meaning representation grammars to improve semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mr: select river.name from river where river.traverse=texas?
</prevsent>
<prevsent>and river.length= (select max(river.length) from river where river.traverse=texas?); figure 1: examples of nl sentences and their mrs from(a) the clang domain (b) geo query domain with functional mrl (c) geo query domain with sql.
</prevsent>
</prevsection>
<citsent citstr=" P06-2080 ">
and mooney, 2005; nguyen et al, 2006).<papid> P06-2080 </papid></citsent>
<aftsection>
<nextsent>for these systems to work well, it is also necessary that the semantic labels of the mrl correspond well with natural language semantics.
</nextsent>
<nextsent>if the mrg of domain-specific mrl does not correspond well with natural language semantics then manually re-engineering the mrg to work well for semantic parsing is tedious task and requires considerable domain expertise.
</nextsent>
<nextsent>in this paper, we present methods to automatically transform given mrg to make it more suitable for learning semantic parsers.
</nextsent>
<nextsent>no previous work addresses this issue to our best knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2160">
<title id=" W08-1132.xml">the fingerprint of human referring expressions and their surface realization with graph transducers isfp isgt isfpgt </title>
<section> is-gt: realization with graph.  </section>
<citcontext>
<prevsection>
<prevsent>(bohnet, 2006).
</prevsent>
<prevsent>we report et the first time about mate on the first international natural language generation conference, cf.
</prevsent>
</prevsection>
<citsent citstr=" W00-1436 ">
(bohnet et al., 2000).<papid> W00-1436 </papid></citsent>
<aftsection>
<nextsent>it was since then continuously enhanced and in the last years, large grammars for several languages such as catalan, english, finnish, french, german, polish, portougees have been developed within the european project marquis and patex pert, cf.
</nextsent>
<nextsent>(wanner et al, 2007), (lareau and wanner, 2007) and (mille and wanner, 2008).
</nextsent>
<nextsent>2.1 the referring expression models.
</nextsent>
<nextsent>a learning program builds referring expression model for each person that contributed referring expression to the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2161">
<title id=" W08-2210.xml">analyzing the explanation structure of procedural texts dealing with advice and warnings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>questions.
</prevsent>
<prevsent>this means identifying titles (which convey the main goals of the procedure), sequences of instructions serving these goals, and number of additional structures such as prerequisites, warnings, advice, illustrations, etc.
</prevsent>
</prevsection>
<citsent citstr=" W03-1107 ">
(takechi et al 2003, <papid> W03-1107 </papid>adam, 2001).</citsent>
<aftsection>
<nextsent>a response to an how-to question is then the well-formed text portion within the scope of the title that matches the question.
</nextsent>
<nextsent>in our perspective, procedural texts range from apparently simple cooking recipes to large maintenance manuals.
</nextsent>
<nextsent>they also include documents as diverse as teaching texts, medical notices, social behavior recommendations, directions for use, assembly notices, do-it-yourself notices, itinerary guides, advice texts, savoir-faire guides etc.
</nextsent>
<nextsent>(aouladomar et al, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2162">
<title id=" W08-2210.xml">analyzing the explanation structure of procedural texts dealing with advice and warnings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>induced support: for better ease of execution?.
</prevsent>
<prevsent>from our observations (which need further confirmation), generic supports are in general triggered by adjectives or by general purpose verbs used in the conclusion.the second situation (empty support in domain dependent situation) is more delicate and requires domain or lexical knowledge.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
we are investigating the use of principles of the generative lexicon (pustejovsky 1991) <papid> J91-4003 </papid>for that purpose.</citsent>
<aftsection>
<nextsent>very briefly, wind has in its telic role several predicates like push, take away, scatter, disperse, break, damage, ....
</nextsent>
<nextsent>when applied e.g. to gardening, such as planting new flowers, since these are not so mobile when planted, predicate like break or damage can be 126 fontan and saint-dizier.
</nextsent>
<nextsent>selected (selection principles in the generative lexicon remain however an open and very delicate problem).
</nextsent>
<nextsent>then, from statement such as: avoid planting flowers by high winds the support: because wind will damage or break flowers can be inferred.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2163">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are in fact important because they allow to structure information, thus fostering their search and reuse.
</prevsent>
<prevsent>however, it is well known that any knowledge-based system suffers from the so-called knowledge acquisition bottleneck, i.e. the difficulty to actually model the do main in question.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
as stated in (caraballo, 1999), <papid> P99-1016 </papid>wordnet has been an important lexical knowledge base, but it is insufficient for domain specific texts.</citsent>
<aftsection>
<nextsent>so, many attempts have been made to automatically produce taxonomies (grefenstette, 1994), but (caraballo, 1999) <papid> P99-1016 </papid>is certainly the first work which proposes complete overview of the problem by (1) automatically building hierarchical structure of nouns based on bottom-up clustering methods and (2) labeling the internal nodes of the resulting tree with hypernyms from the nouns clustered underneath by using patterns such as is kind of a?.</nextsent>
<nextsent>2008.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2165">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commons at tribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc sa/3.0/).
</prevsent>
<prevsent>some rights reserved.
</prevsent>
</prevsection>
<citsent citstr=" W06-0205 ">
in this paper, we are interested in dealing with the second problem of the construction of an organized lexical resource i.e. discovering general specific noun relationships, so that correct nouns are chosen to label internal nodes of any hierarchical knowledge base, such as the one proposed in (dias et al, 2006).<papid> W06-0205 </papid></citsent>
<aftsection>
<nextsent>most of the works proposed so far have (1) used predefined patterns or (2) automatically learned these patterns to identify hypernym/hyponym relationships.
</nextsent>
<nextsent>from the first paradigm, (hearst, 1992) <papid> C92-2082 </papid>first identifies set of lexico-syntactic patterns that are easily recognizable i.e. occur frequently and across text genre boundaries.</nextsent>
<nextsent>these can be called seed patterns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2166">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we are interested in dealing with the second problem of the construction of an organized lexical resource i.e. discovering general specific noun relationships, so that correct nouns are chosen to label internal nodes of any hierarchical knowledge base, such as the one proposed in (dias et al, 2006).<papid> W06-0205 </papid></prevsent>
<prevsent>most of the works proposed so far have (1) used predefined patterns or (2) automatically learned these patterns to identify hypernym/hyponym relationships.</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
from the first paradigm, (hearst, 1992) <papid> C92-2082 </papid>first identifies set of lexico-syntactic patterns that are easily recognizable i.e. occur frequently and across text genre boundaries.</citsent>
<aftsection>
<nextsent>these can be called seed patterns.
</nextsent>
<nextsent>based on these seeds, she proposes bootstrapping algorithm to semi-automatically acquire new more specific patterns.
</nextsent>
<nextsent>similarly, (carabal lo, 1999) <papid> P99-1016 </papid>uses predefined patterns such as is kind of y?</nextsent>
<nextsent>or x, y, and other zs?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2168">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>selective concept extraction is form of text skimming that selectively processes relevant text while effectively ignoring surrounding text that is thought to be irrelevant to the do main.
</prevsent>
<prevsent>a more challenging task is to automatically learn the relevant patterns for the hypernym/hyponym relationships.
</prevsent>
</prevsection>
<citsent citstr=" W06-0202 ">
in the context of pattern extraction, there exist many approaches as summarized in (stevenson and greenwood, 2006).<papid> W06-0202 </papid></citsent>
<aftsection>
<nextsent>the most well-known work in this area is certainly the one proposed by (snow et al, 2005) who use machine learning techniques to automatically replace hand-built knowledge.
</nextsent>
<nextsent>by using dependency path features extracted from parse trees, they introduce general-purpose formalization and generalization of these patterns.
</nextsent>
<nextsent>given training set of text containing known hypernym pairs, their algorithm automatically extracts useful dependency paths and applies them to new corpora to identify novel pairs.
</nextsent>
<nextsent>(sang and hof 97 mann, 2007) use similar way as (snow et al, 2006) to derive extraction patterns for hy pernym/hyponym relationships by using web search engine counts from pairs of words encountered in wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2169">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given training set of text containing known hypernym pairs, their algorithm automatically extracts useful dependency paths and applies them to new corpora to identify novel pairs.
</prevsent>
<prevsent>(sang and hof 97 mann, 2007) use similar way as (snow et al, 2006) to derive extraction patterns for hy pernym/hyponym relationships by using web search engine counts from pairs of words encountered in wordnet.
</prevsent>
</prevsection>
<citsent citstr=" N07-1043 ">
however, the most interesting work is certainly proposed by (bollegala et al, 2007) <papid> N07-1043 </papid>who extract patterns in two steps.</citsent>
<aftsection>
<nextsent>first, they find lexical relationships between synonym pairs based on snippets counts and apply wild cards to generalize the acquired knowledge.
</nextsent>
<nextsent>then, they apply svm classifier to determine whether new pair shows relation of synonymy or not, based on feature vector of lexical relationships.
</nextsent>
<nextsent>this technique could be applied to hypernym/hyponym relationships although the authors do not mention it.
</nextsent>
<nextsent>on the one hand, links between words that result from manual or semi-automatic acquisition of relevant predicative or discursive patterns (hearst, 1992; <papid> C92-2082 </papid>carballo, 1999) are fine and accurate, but the acquisition of these patterns is tedious task that requires substantial manual work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2174">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advantages of this approach are clear as it can be applied to any language or any domain without any previous knowledge, based on simple assumption: specific words tend to attract general words with more strength than the opposite.
</prevsent>
<prevsent>as (michelbacher et al, 2007) state: there is tendency for strong forward association from specific term like adenocarcinoma to the more general term cancer, whereas the association from cancer to adenocarcinoma is weak?.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
based on this assumption, we propose methodology based on directed graphs and the tex trank algorithm (mihalcea and tarau, 2004) <papid> W04-3252 </papid>to automatically induce general-specific noun relationships from web corpora frequency counts.</citsent>
<aftsection>
<nextsent>indeed, asymmetry in natural language processing can be seen as possible reason for 2 we must admit that other kinds of relationships may be covered.
</nextsent>
<nextsent>for that reason, we will speak about general specific relationships instead of hypernym/hyponym relationships.
</nextsent>
<nextsent>the degree of generality of terms (michelbacher et al, 2007).
</nextsent>
<nextsent>so, different asymmetric association measures are implemented to build the graphs upon which the text rank algorithm is applied and produces an ordered list of nouns, from the most general to the most specific.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2176">
<title id=" W08-2113.xml">fully unsupervised graph based discovery of general specific noun relationships from web corpora frequency counts </title>
<section> asymmetric association measures.  </section>
<citcontext>
<prevsection>
<prevsent>as consequence, fruit is more likely to be more general term than mango.
</prevsent>
<prevsent>based on this assumption, asymmetric association measures are necessary to induce these associations.
</prevsent>
</prevsection>
<citsent citstr=" P06-2084 ">
(pecina and schlesinger, 2006) <papid> P06-2084 </papid>and (tan et al, 2004) propose exhaustive lists of association measures from which we present the asymmetric ones that will be used to measure the degree of attractiveness between two nouns, and y, where f(.,.), p(.), p(.,.)</citsent>
<aftsection>
<nextsent>and are respectively the frequency function, the marginal probability function, the joint probability function and the total of digrams.
</nextsent>
<nextsent>( ) )),(),(),,(),(max( , blanquet-braun yxfyxfyxfyxf yxf ++ = (1) ??
</nextsent>
<nextsent>+ + = )( )|(log),( )( )|(log),( , )( )|(log),( )( )|(log),( max measure xp yxpyxp xp yxpyxp yp xypyxp yp xypyxp (2) [ ])|(),|(maxconfidence xypyxp= (3) ??
</nextsent>
<nextsent>+ + + + = 2)(.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2179">
<title id=" W09-1607.xml">sentence position revisited a robust lightweight update summarization  baseline algorithm </title>
<section> sub-optimal sentence position policy.  </section>
<citcontext>
<prevsection>
<prevsent>next, in section 4, we explain the current baselines and evaluation for multi-document summarization and finally in section 5, we discuss the need for an older baseline in the current context of the short summary task of update summarization.
</prevsent>
<prevsent>given large text collection and way to approximate the relevance for reasonably large subset of sentences, we could identify significant positional attributes for the genre of the collection.
</prevsent>
</prevsection>
<citsent citstr=" A97-1042 ">
our experiments are based on the work described in (linand hovy, 1997), <papid> A97-1042 </papid>whose experiments using the ziff davis corpus gave great insights on the selective power of the position method.</citsent>
<aftsection>
<nextsent>2.1 sentence position yield and optimal.
</nextsent>
<nextsent>position policy (opp) lin and hovy (1997) <papid> A97-1042 </papid>provide an empirical validation for the position hypothesis.</nextsent>
<nextsent>they describe method of deriving an optimal position policy for collection of texts within genre, as long as small setof topic keywords is defined for each text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2182">
<title id=" W09-1607.xml">sentence position revisited a robust lightweight update summarization  baseline algorithm </title>
<section> spp as an algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>summarization the query-focused multi-document summarization task at duc models the real world complex question answering task.
</prevsent>
<prevsent>given topic and set of 25relevant documents, this task is to synthesize fluent, well-organized 250 word summary of the documents that answers the question(s) in the topic state 49 ment/narration.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
the summaries from the above algorithm for theqf-mds were evaluated based on rouge metrics (lin, 2004).<papid> W04-1013 </papid></citsent>
<aftsection>
<nextsent>the average4 recall scores are reported for rouge-2 and rouge-su4 in table 1.also reported are the performance of the top performing system and the official baseline(s).
</nextsent>
<nextsent>this algorithm performed worse than most systems participating in the task that year and performed better5than only the first words?
</nextsent>
<nextsent>baseline and 3 other systems.
</nextsent>
<nextsent>system rouge-2 rouge-su4 first words?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2185">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a lower-order dependency parsing model is used to restrict the search space of the full model, thereby making it efficient.
</prevsent>
<prevsent>experiments on the penn wsj treebank show that the model achieves state-of-the-art performance, for both constituent and dependency accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
in global linear models (glms) for structured prediction, (e.g., (johnson et al, 1999; <papid> P99-1069 </papid>lafferty et al, 2001; collins, 2002; <papid> W02-1001 </papid>altun et al, 2003; taskar et al., 2004)), <papid> W04-3201 </papid>the optimal label y?</citsent>
<aftsection>
<nextsent>for an input is ? = arg max yy(x) ? f(x, y) (1)where y(x) is the set of possible labels for the input x; f(x, y) ? rd is feature vector that represents the pair (x, y); and is parameter vector.
</nextsent>
<nextsent>this paper describes glm for natural language parsing, trained using the averaged perceptron.
</nextsent>
<nextsent>the parser we describe recovers full syntactic representations, similar to those derived by probabilistic context-free grammar (pcfg).
</nextsent>
<nextsent>a key motivation for the use of glms in parsing is that they allow great deal of flexibility in the features which can be included in the definition of f(x, y).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2186">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a lower-order dependency parsing model is used to restrict the search space of the full model, thereby making it efficient.
</prevsent>
<prevsent>experiments on the penn wsj treebank show that the model achieves state-of-the-art performance, for both constituent and dependency accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
in global linear models (glms) for structured prediction, (e.g., (johnson et al, 1999; <papid> P99-1069 </papid>lafferty et al, 2001; collins, 2002; <papid> W02-1001 </papid>altun et al, 2003; taskar et al., 2004)), <papid> W04-3201 </papid>the optimal label y?</citsent>
<aftsection>
<nextsent>for an input is ? = arg max yy(x) ? f(x, y) (1)where y(x) is the set of possible labels for the input x; f(x, y) ? rd is feature vector that represents the pair (x, y); and is parameter vector.
</nextsent>
<nextsent>this paper describes glm for natural language parsing, trained using the averaged perceptron.
</nextsent>
<nextsent>the parser we describe recovers full syntactic representations, similar to those derived by probabilistic context-free grammar (pcfg).
</nextsent>
<nextsent>a key motivation for the use of glms in parsing is that they allow great deal of flexibility in the features which can be included in the definition of f(x, y).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2187">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a lower-order dependency parsing model is used to restrict the search space of the full model, thereby making it efficient.
</prevsent>
<prevsent>experiments on the penn wsj treebank show that the model achieves state-of-the-art performance, for both constituent and dependency accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
in global linear models (glms) for structured prediction, (e.g., (johnson et al, 1999; <papid> P99-1069 </papid>lafferty et al, 2001; collins, 2002; <papid> W02-1001 </papid>altun et al, 2003; taskar et al., 2004)), <papid> W04-3201 </papid>the optimal label y?</citsent>
<aftsection>
<nextsent>for an input is ? = arg max yy(x) ? f(x, y) (1)where y(x) is the set of possible labels for the input x; f(x, y) ? rd is feature vector that represents the pair (x, y); and is parameter vector.
</nextsent>
<nextsent>this paper describes glm for natural language parsing, trained using the averaged perceptron.
</nextsent>
<nextsent>the parser we describe recovers full syntactic representations, similar to those derived by probabilistic context-free grammar (pcfg).
</nextsent>
<nextsent>a key motivation for the use of glms in parsing is that they allow great deal of flexibility in the features which can be included in the definition of f(x, y).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2189">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the average sentence length in the dataset we use (the pennwsj treebank) is over 23 words; the grammar constant can easily take value of 1000 or greater.these factors make exact inference algorithms virtually intractable for training or decoding glms for full syntactic parsing.
</prevsent>
<prevsent>as result, inspite of the potential advantages of these methods, there has been very little previous work on applying glms for full parsing without the use of fairly severe restrictions or approximations.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
for example, the model in (taskar et al, 2004) <papid> W04-3201 </papid>is trained on only sentences of 15 words or less; reranking models (collins, 2000; charniak and johnson, 2005) <papid> P05-1022 </papid>restrict y(x) to be small set of parses from first-pass parser; see section 1.1 for discussion of other related work.</citsent>
<aftsection>
<nextsent>the following ideas are central to our approach: (1) tag-based, split table grammar.
</nextsent>
<nextsent>we describe novel, tag-based parsing formalism that allows full constituent-based trees to be recovered.
</nextsent>
<nextsent>a driving motivation for our approach comes from the flexibility of the feature-vector representations f(x, y) that can be used in the model.
</nextsent>
<nextsent>the formalism that we describe allows the incorporation of: (1) basic pcfg-style features; (2) theuse of features that are sensitive to bigram dependencies between pairs of words; and (3) features that are sensitive to trigram dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2190">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe method that leverages simple, first-order dependency parser to restrict the search space of the tag parser in training and testing.
</prevsent>
<prevsent>the lower-order parser runs in o(n3h) time where ? g; experiments show that it is remarkably effective in pruning the search space of the full tag parser.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
experiments on the penn wsj treebank show that the model recovers constituent structures with higher accuracy than the approaches of (charniak, 2000; <papid> A00-2018 </papid>collins, 2000; petrov and klein, 2007), <papid> N07-1051 </papid>and with similar level of performance to the reranking parser of (charniak and johnson, 2005).<papid> P05-1022 </papid>the model also recovers dependencies with significantly higher accuracy than state-of-the-art dependency parsers such as (koo et al, 2008; <papid> P08-1068 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>1.1 related work.
</nextsent>
<nextsent>previous work has made use of various restrictions or approximations that allow efficient training ofglms for parsing.
</nextsent>
<nextsent>this section describes the relationship between our work and this previous work.
</nextsent>
<nextsent>in reranking approaches, first-pass parser is used to enumerate small set of candidate parses for an input sentence; the reranking model, which is glm, is used to select between these parses (e.g., (ratnaparkhi et al, 1994; johnson et al., 1999; <papid> P99-1069 </papid>collins, 2000; charniak and johnson, 2005)).<papid> P05-1022 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2191">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe method that leverages simple, first-order dependency parser to restrict the search space of the tag parser in training and testing.
</prevsent>
<prevsent>the lower-order parser runs in o(n3h) time where ? g; experiments show that it is remarkably effective in pruning the search space of the full tag parser.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
experiments on the penn wsj treebank show that the model recovers constituent structures with higher accuracy than the approaches of (charniak, 2000; <papid> A00-2018 </papid>collins, 2000; petrov and klein, 2007), <papid> N07-1051 </papid>and with similar level of performance to the reranking parser of (charniak and johnson, 2005).<papid> P05-1022 </papid>the model also recovers dependencies with significantly higher accuracy than state-of-the-art dependency parsers such as (koo et al, 2008; <papid> P08-1068 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>1.1 related work.
</nextsent>
<nextsent>previous work has made use of various restrictions or approximations that allow efficient training ofglms for parsing.
</nextsent>
<nextsent>this section describes the relationship between our work and this previous work.
</nextsent>
<nextsent>in reranking approaches, first-pass parser is used to enumerate small set of candidate parses for an input sentence; the reranking model, which is glm, is used to select between these parses (e.g., (ratnaparkhi et al, 1994; johnson et al., 1999; <papid> P99-1069 </papid>collins, 2000; charniak and johnson, 2005)).<papid> P05-1022 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2193">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe method that leverages simple, first-order dependency parser to restrict the search space of the tag parser in training and testing.
</prevsent>
<prevsent>the lower-order parser runs in o(n3h) time where ? g; experiments show that it is remarkably effective in pruning the search space of the full tag parser.
</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
experiments on the penn wsj treebank show that the model recovers constituent structures with higher accuracy than the approaches of (charniak, 2000; <papid> A00-2018 </papid>collins, 2000; petrov and klein, 2007), <papid> N07-1051 </papid>and with similar level of performance to the reranking parser of (charniak and johnson, 2005).<papid> P05-1022 </papid>the model also recovers dependencies with significantly higher accuracy than state-of-the-art dependency parsers such as (koo et al, 2008; <papid> P08-1068 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>1.1 related work.
</nextsent>
<nextsent>previous work has made use of various restrictions or approximations that allow efficient training ofglms for parsing.
</nextsent>
<nextsent>this section describes the relationship between our work and this previous work.
</nextsent>
<nextsent>in reranking approaches, first-pass parser is used to enumerate small set of candidate parses for an input sentence; the reranking model, which is glm, is used to select between these parses (e.g., (ratnaparkhi et al, 1994; johnson et al., 1999; <papid> P99-1069 </papid>collins, 2000; charniak and johnson, 2005)).<papid> P05-1022 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2194">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe method that leverages simple, first-order dependency parser to restrict the search space of the tag parser in training and testing.
</prevsent>
<prevsent>the lower-order parser runs in o(n3h) time where ? g; experiments show that it is remarkably effective in pruning the search space of the full tag parser.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
experiments on the penn wsj treebank show that the model recovers constituent structures with higher accuracy than the approaches of (charniak, 2000; <papid> A00-2018 </papid>collins, 2000; petrov and klein, 2007), <papid> N07-1051 </papid>and with similar level of performance to the reranking parser of (charniak and johnson, 2005).<papid> P05-1022 </papid>the model also recovers dependencies with significantly higher accuracy than state-of-the-art dependency parsers such as (koo et al, 2008; <papid> P08-1068 </papid>mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>1.1 related work.
</nextsent>
<nextsent>previous work has made use of various restrictions or approximations that allow efficient training ofglms for parsing.
</nextsent>
<nextsent>this section describes the relationship between our work and this previous work.
</nextsent>
<nextsent>in reranking approaches, first-pass parser is used to enumerate small set of candidate parses for an input sentence; the reranking model, which is glm, is used to select between these parses (e.g., (ratnaparkhi et al, 1994; johnson et al., 1999; <papid> P99-1069 </papid>collins, 2000; charniak and johnson, 2005)).<papid> P05-1022 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2198">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a disadvantage of these approaches is that they donot recover full, constituent-based syntactic structures; the increased linguistic detail in full syntactic structures may be useful in nlp applications, or may improve dependency parsing accuracy, as is the case in our experiments.2 there has been some previous work on glm approaches for full syntactic parsing that make use of dynamic programming.
</prevsent>
<prevsent>taskar et al (2004) <papid> W04-3201 </papid>describe max-margin approach; however, in this work training sentences were limited to be of 15 words or less.</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
clark and curran (2004) <papid> P04-1014 </papid>describe log-linear glm for ccg parsing, trained on thepenn treebank.</citsent>
<aftsection>
<nextsent>this method makes use of paral lel ization across an 18 node cluster, together withup to 25gb of memory used for storage of dynamic programming structures for training data.clark and curran (2007) <papid> W07-1202 </papid>describe perceptron based approach for ccg parsing which is considerably more efficient, and makes use of super tagging model to prune the search space of the full parsing model.</nextsent>
<nextsent>recent work (petrov et al, 2007;finkel et al, 2008) <papid> P08-1109 </papid>describes log-linear glms applied to pcfg representations, but does not make use of dependency features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2199">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>taskar et al (2004) <papid> W04-3201 </papid>describe max-margin approach; however, in this work training sentences were limited to be of 15 words or less.</prevsent>
<prevsent>clark and curran (2004) <papid> P04-1014 </papid>describe log-linear glm for ccg parsing, trained on thepenn treebank.</prevsent>
</prevsection>
<citsent citstr=" W07-1202 ">
this method makes use of paral lel ization across an 18 node cluster, together withup to 25gb of memory used for storage of dynamic programming structures for training data.clark and curran (2007) <papid> W07-1202 </papid>describe perceptron based approach for ccg parsing which is considerably more efficient, and makes use of super tagging model to prune the search space of the full parsing model.</citsent>
<aftsection>
<nextsent>recent work (petrov et al, 2007;finkel et al, 2008) <papid> P08-1109 </papid>describes log-linear glms applied to pcfg representations, but does not make use of dependency features.</nextsent>
<nextsent>2.1 derivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2200">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>clark and curran (2004) <papid> P04-1014 </papid>describe log-linear glm for ccg parsing, trained on thepenn treebank.</prevsent>
<prevsent>this method makes use of paral lel ization across an 18 node cluster, together withup to 25gb of memory used for storage of dynamic programming structures for training data.clark and curran (2007) <papid> W07-1202 </papid>describe perceptron based approach for ccg parsing which is considerably more efficient, and makes use of super tagging model to prune the search space of the full parsing model.</prevsent>
</prevsection>
<citsent citstr=" P08-1109 ">
recent work (petrov et al, 2007;finkel et al, 2008) <papid> P08-1109 </papid>describes log-linear glms applied to pcfg representations, but does not make use of dependency features.</citsent>
<aftsection>
<nextsent>2.1 derivations.
</nextsent>
<nextsent>this section describes the idea of derivations inour parsing formalism.
</nextsent>
<nextsent>as in context-free grammars or tags, derivation in our approach is adata structure that specifies the sequence of operations used in combining basic (elementary) structures in grammar, to form full parse tree.
</nextsent>
<nextsent>the parsing formalism we use is related to the tree adjoining grammar (tag) formalisms described in (chiang, 2003; shen and joshi, 2005).<papid> H05-1102 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2202">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> the tag-based parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>this section describes the idea of derivations inour parsing formalism.
</prevsent>
<prevsent>as in context-free grammars or tags, derivation in our approach is adata structure that specifies the sequence of operations used in combining basic (elementary) structures in grammar, to form full parse tree.
</prevsent>
</prevsection>
<citsent citstr=" H05-1102 ">
the parsing formalism we use is related to the tree adjoining grammar (tag) formalisms described in (chiang, 2003; shen and joshi, 2005).<papid> H05-1102 </papid></citsent>
<aftsection>
<nextsent>however,an important difference of our work from this previous work is that our formalism is defined to be splittable?, allowing use of the efficient parsing algorithms of eisner (2000).
</nextsent>
<nextsent>a derivation in our model is pair e,d? where is set of spines, and is set of dependencies 2note however that the lower-order parser that we use to restrict the search space of the tag-based parser is based on the work of mcdonald et al (2005).<papid> P05-1012 </papid></nextsent>
<nextsent>see also (sagae et al, 2007) <papid> P07-1079 </papid>for method that uses dependency parser to restrict the search space of more complex hpsg parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2203">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> the tag-based parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>the parsing formalism we use is related to the tree adjoining grammar (tag) formalisms described in (chiang, 2003; shen and joshi, 2005).<papid> H05-1102 </papid></prevsent>
<prevsent>however,an important difference of our work from this previous work is that our formalism is defined to be splittable?, allowing use of the efficient parsing algorithms of eisner (2000).</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
a derivation in our model is pair e,d? where is set of spines, and is set of dependencies 2note however that the lower-order parser that we use to restrict the search space of the tag-based parser is based on the work of mcdonald et al (2005).<papid> P05-1012 </papid></citsent>
<aftsection>
<nextsent>see also (sagae et al, 2007) <papid> P07-1079 </papid>for method that uses dependency parser to restrict the search space of more complex hpsg parser.</nextsent>
<nextsent>10 (a) vp vbd ate np nn cake (b) vp vp vbd ate np nn cake figure 1: two example trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2204">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> the tag-based parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>however,an important difference of our work from this previous work is that our formalism is defined to be splittable?, allowing use of the efficient parsing algorithms of eisner (2000).
</prevsent>
<prevsent>a derivation in our model is pair e,d? where is set of spines, and is set of dependencies 2note however that the lower-order parser that we use to restrict the search space of the tag-based parser is based on the work of mcdonald et al (2005).<papid> P05-1012 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1079 ">
see also (sagae et al, 2007) <papid> P07-1079 </papid>for method that uses dependency parser to restrict the search space of more complex hpsg parser.</citsent>
<aftsection>
<nextsent>10 (a) vp vbd ate np nn cake (b) vp vp vbd ate np nn cake figure 1: two example trees.
</nextsent>
<nextsent>specifying how the spines are combined to form parse tree.
</nextsent>
<nextsent>the spines are similar to elementary trees in tag.
</nextsent>
<nextsent>some examples are as follows: np nnp john vp vbd ate np nn cake advp rb quickly advp rb luckily these structures do not have substitution nodes, as is common in tags.3 instead, the spines consist of lexical anchor together with series of unary projections, which usually correspond to different x-bar levels associated with the anchor.the operations used to combine spines are similar to the tag operations of adjunction and sister adjunction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2211">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> the tag-based parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>to feature vector.
</prevsent>
<prevsent>the function maps dependencies within to feature vectors.
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
this decomposition is similar to the first-order model of mcdonald et al (2005), <papid> P05-1012 </papid>but with the addition of the features.we will extend our model to include higher order features, in particular features based on sibling dependencies (mcdonald and pereira, 2006), <papid> E06-1011 </papid>and grandparent dependencies, as in (carreras, 2007).<papid> D07-1101 </papid></citsent>
<aftsection>
<nextsent>if = e,d? is derivation, then: ? s(y) is set of sibling dependencies.
</nextsent>
<nextsent>each sibling dependency is tuple h,m, l, s?.
</nextsent>
<nextsent>for each h,m, l, s?
</nextsent>
<nextsent>s the tuple h,m, l?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2219">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> implementation details.  </section>
<citcontext>
<prevsection>
<prevsent>thus the label features are sensitive only to the triple of nonterminals corresponding to the grammatical relation involved in an adjunction, and binary flag specifiying whether the operation is s-adjunction or r-adjunction.for the spine features e(x, i, ??), we use feature templates that are sensitive to the identity of the spine ?, together with contextual features ofthe string x. these features consider the identity of the words and part-of-speech tags in window that is centered on i and spans the range (i2) . . .
</prevsent>
<prevsent>x (i+2) . 4.2 extracting derivations from parse trees.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in the experiments in this paper, the following three-step process was used: (1) derivations were extracted from training set drawn from the penn wsj treebank, and then used to train parsingmodel; (2) the test data was parsed using there sulting model, giving derivation for each test data sentence; (3) the resulting test-data derivations were mapped back to penn-treebank style trees, using the method described in section 2.1.to achieve step (1), we first apply set of head finding rules which are similar to those described in (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>once the head-finding rules have been applied, it is straightforward to extract 14 precision recall 1 ppk07 ? ?
</nextsent>
<nextsent>88.3 fkm08 88.2 87.8 88.0 ch2000 89.5 89.6 89.6 co2000 89.9 89.6 89.8 pk07 90.2 89.9 90.1 this paper 91.4 90.7 91.1 cj05 ? ?
</nextsent>
<nextsent>91.4 h08 ? ?
</nextsent>
<nextsent>91.7 co2000(s24) 89.6 88.6 89.1 this paper (s24) 91.1 89.9 90.5 table 1: results for different methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2226">
<title id=" W08-2102.xml">tag dynamic programming and the perceptron for efficient feature rich parsing </title>
<section> implementation details.  </section>
<citcontext>
<prevsection>
<prevsent>91.4 h08 ? ?
</prevsent>
<prevsent>91.7 co2000(s24) 89.6 88.6 89.1 this paper (s24) 91.1 89.9 90.5 table 1: results for different methods.
</prevsent>
</prevsection>
<citsent citstr=" P08-1067 ">
ppk07, fkm08, ch2000, co2000, pk07, cj05 and h08 are results on section 23 of the penn wsj treebank, for the models of petrov et al (2007), finkel et al (2008), <papid> P08-1109 </papid>charniak (2000), <papid> A00-2018 </papid>collins (2000), petrov and klein (2007), <papid> N07-1051 </papid>charniak and johnson (2005), <papid> P05-1022 </papid>and huang (2008).<papid> P08-1067 </papid></citsent>
<aftsection>
<nextsent>(cj05 is the performance of an updated model at http://www.cog.brown.edu/mj/software.htm.)
</nextsent>
<nextsent>s24?
</nextsent>
<nextsent>denotes results on section 24 of the treebank.
</nextsent>
<nextsent>s23 s24 kcc08 unlabeled 92.0 91.0 kcc08 labeled 92.5 91.7 this paper 93.5 92.5 table 2: table showing unlabeled dependency accuracy for sections 23 and 24 of the treebank, using the method of (ya mada and matsumoto, 2003) to extract dependencies from parse trees from our model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2246">
<title id=" W08-2222.xml">wide coverage semantic analysis with boxer </title>
<section> practice.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 preprocessing.
</prevsent>
<prevsent>the input text needs to be token ised with one sentence per line.
</prevsent>
</prevsection>
<citsent citstr=" P07-2009 ">
in the context of this paper, boxer was put into action after using combined processing pipeline of the c&c; tools consisting of pos-tagging, named entity recognition, and parsing (curranet al, 2007).<papid> P07-2009 </papid></citsent>
<aftsection>
<nextsent>the pos tags are used to specify the lexical semantics for ambiguous ccg categories (see below); the named entity tags are transferred to the level of drss as well and added as sorts to named discourse referents.
</nextsent>
<nextsent>an example of ccg derivation is shown in figure 2.
</nextsent>
<nextsent>a virus --[lex] --[lex] by np:nb/n ---------------------[lex] -----------[fa] cervical cancer caused ((s:pss\np)\(s:pss\np))/np np:nb ---[lex] --[lex] ---[lex] --------------------------------------[fa] n/n is s:pss\np (s:pss\np)\(s:pss\np) ------------[fa] ----------------[lex] -----------------------------------------------[ba] (s:dcl\np)/(s:pss\np) s:pss\np ------------[tc] ---------------------------------------------------------------------[fa] np s:dcl\np --------------------------------------------------------------------------------------[ba] s:dcl figure 2: ccg derivation as generated by the c&c; tools 3.2 lexicon.
</nextsent>
<nextsent>in ccg, the syntactic lexicon comprises the set of lexical categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2247">
<title id=" W08-2222.xml">wide coverage semantic analysis with boxer </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>boxer is wide-coverage system for semantic interpretation.
</prevsent>
<prevsent>it takes as input ccgderivation of natural language expression, and produces formally interpret able semantic representations: either in the form of drss, or as formulas of first-order logic.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
the existence of ccgbank (hockenmaier, 2003) and robust parsers trained on it (clark and curran, 2004; <papid> P04-1014 </papid>bos et al, 2004) make boxer state-of-the-art open domain tool for deep semantic analysis.</citsent>
<aftsection>
<nextsent>boxers performance on the shared task for comparing semantic represtations was promising.
</nextsent>
<nextsent>it was able to produce drss for all texts.
</nextsent>
<nextsent>we cant quantify the quality of boxers output, as we dont have gold standard representations at our disposal.
</nextsent>
<nextsent>manually inspecting the output gives us the following impression: ? computed predicate argument structure is generally of good quality, including hard constructions involving control or coordination; ? discourse structure triggered by condition als, negation or discourse adverbs is overall correctly computed; ? some measure and time expressions are correctly analysed, others arent; ? several shallow analyses are given for lexical phrases that require deep analysis; ? bridging references and pronouns are not resolved in most cases; but when they are, they are mostly correctly resolved (high precision at the cost of recall).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2249">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 describes our system and different pivoting techniques.
</prevsent>
<prevsent>and section 5 presents our experimental results.
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
there has been lot of work on translation from chinese to english (wang et al , 2007; <papid> D07-1077 </papid>crego and mario, 2007; carpuat and wu, 2007; among others) and from arabic to english (sadat and habash, 2006, al-onaizan and papineni, 2006; among others).</citsent>
<aftsection>
<nextsent>there is also fair amount of work on translation into chinese from japanese, korean and english (isahara et al ., 2007; kim et al , 2002; ye et al , 2007; among others).
</nextsent>
<nextsent>in 2008, the national institute of standards and technology (nist) mt evaluation competition introduced english chinese as new evaluation track.1 much work has been done on exploiting multilingual corpora for mt or related tasks such as lexical induction or word alignment.
</nextsent>
<nextsent>schafer and yarowsky (2002) <papid> W02-2026 </papid>induced translation lexicons for languages without common parallel corpora using bridge language that is related to the target languages.</nextsent>
<nextsent>simard (1999) <papid> W99-0602 </papid>described sentence aligner that makes simultaneous decisions in trilingual parallel text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2250">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there is also fair amount of work on translation into chinese from japanese, korean and english (isahara et al ., 2007; kim et al , 2002; ye et al , 2007; among others).
</prevsent>
<prevsent>in 2008, the national institute of standards and technology (nist) mt evaluation competition introduced english chinese as new evaluation track.1 much work has been done on exploiting multilingual corpora for mt or related tasks such as lexical induction or word alignment.
</prevsent>
</prevsection>
<citsent citstr=" W02-2026 ">
schafer and yarowsky (2002) <papid> W02-2026 </papid>induced translation lexicons for languages without common parallel corpora using bridge language that is related to the target languages.</citsent>
<aftsection>
<nextsent>simard (1999) <papid> W99-0602 </papid>described sentence aligner that makes simultaneous decisions in trilingual parallel text.</nextsent>
<nextsent>kumar et al  (2007) <papid> D07-1005 </papid>improved arabic-english mt by using available parallel data in other languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2251">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in 2008, the national institute of standards and technology (nist) mt evaluation competition introduced english chinese as new evaluation track.1 much work has been done on exploiting multilingual corpora for mt or related tasks such as lexical induction or word alignment.
</prevsent>
<prevsent>schafer and yarowsky (2002) <papid> W02-2026 </papid>induced translation lexicons for languages without common parallel corpora using bridge language that is related to the target languages.</prevsent>
</prevsection>
<citsent citstr=" W99-0602 ">
simard (1999) <papid> W99-0602 </papid>described sentence aligner that makes simultaneous decisions in trilingual parallel text.</citsent>
<aftsection>
<nextsent>kumar et al  (2007) <papid> D07-1005 </papid>improved arabic-english mt by using available parallel data in other languages.</nextsent>
<nextsent>callison-burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for phrase-based mt. filali and bilmes (2005) improved word alignment by leveraging multilingual parallel trans lations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2252">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>schafer and yarowsky (2002) <papid> W02-2026 </papid>induced translation lexicons for languages without common parallel corpora using bridge language that is related to the target languages.</prevsent>
<prevsent>simard (1999) <papid> W99-0602 </papid>described sentence aligner that makes simultaneous decisions in trilingual parallel text.</prevsent>
</prevsection>
<citsent citstr=" D07-1005 ">
kumar et al  (2007) <papid> D07-1005 </papid>improved arabic-english mt by using available parallel data in other languages.</citsent>
<aftsection>
<nextsent>callison-burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for phrase-based mt. filali and bilmes (2005) improved word alignment by leveraging multilingual parallel translations.
</nextsent>
<nextsent>most related to our work on pivoting are the following: utiyama and isahara (2007) <papid> N07-1061 </papid>studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ 173 sentence and phrase pivoting strategies using three european languages (spanish, french and german).</nextsent>
<nextsent>their results showed that pivoting does not work as well as direct translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2253">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>kumar et al  (2007) <papid> D07-1005 </papid>improved arabic-english mt by using available parallel data in other languages.</prevsent>
<prevsent>callison-burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for phrase-based mt. filali and bilmes (2005) improved word alignment by leveraging multilingual parallel trans lations.</prevsent>
</prevsection>
<citsent citstr=" N07-1061 ">
most related to our work on pivoting are the following: utiyama and isahara (2007) <papid> N07-1061 </papid>studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ 173 sentence and phrase pivoting strategies using three european languages (spanish, french and german).</citsent>
<aftsection>
<nextsent>their results showed that pivoting does not work as well as direct translation.
</nextsent>
<nextsent>wu and wang (2007) <papid> P07-1108 </papid>focused on phrase pivoting.</nextsent>
<nextsent>they proposed an interpolated scheme that employs two phrase tables: one extracted from small amount of direct parallel data; and the other extracted from large amounts of indirect data with third pivoting language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2254">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>most related to our work on pivoting are the following: utiyama and isahara (2007) <papid> N07-1061 </papid>studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ 173 sentence and phrase pivoting strategies using three european languages (spanish, french and german).</prevsent>
<prevsent>their results showed that pivoting does not work as well as direct translation.</prevsent>
</prevsection>
<citsent citstr=" P07-1108 ">
wu and wang (2007) <papid> P07-1108 </papid>focused on phrase pivoting.</citsent>
<aftsection>
<nextsent>they proposed an interpolated scheme that employs two phrase tables: one extracted from small amount of direct parallel data; and the other extracted from large amounts of indirect data with third pivoting language.
</nextsent>
<nextsent>they compared results for different european language as well as chinese-japanese translation using english as pivoting language.
</nextsent>
<nextsent>their results show that simple pivoting does not improve over direct mt; however, extending the direct mt system with phrases learned through pivoting helps.
</nextsent>
<nextsent>babych et al  (2007) compared two methods for translating into english from ukrainian: direct ukrainian-english mt versus translation via cognate language, russian.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2255">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 direct a-c mt system.
</prevsent>
<prevsent>in our baseline direct a-c system, we used the arabic and chinese portions of our parallel corpus to train direct phrase-based mt system.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we use giza++ (och and ney, 2003) <papid> J03-1002 </papid>for 5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html 176 word alignment, and the pharaoh system suite to build the phrase table and decode (koehn, 2004).</citsent>
<aftsection>
<nextsent>the chinese language model (lm) used 200m words from theun corpus segmented in manner consistent with our training.
</nextsent>
<nextsent>the trigram lm was built using the srilm toolkit (stolcke, 2002).
</nextsent>
<nextsent>4.3 sentence pivoting mt system.
</nextsent>
<nextsent>the sentence pivoting system (a-s-c) used english as an interface between two separate pharse-based mt systems: an arabic-english direct system and an english-chinese direct system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2257">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>tuning and testing datasets are the same across all experiments and systems.
</prevsent>
<prevsent>in all our experiments, we decode using pharaoh (koehn, 2004) with distortion limit of 4 and maximum phrase length of 7.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
tuning is done for each experimental condition using ochs minimum error training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>note that for each set of experiments with the same data size, we draw chinese, arabic and english from the same chunk of three way parallel corpus.
</nextsent>
<nextsent>for example, in size experiments, the two phrase tables used to build new table in the phrase-pivoting approach are extracted respectively from the a-e and e-c systems built in the sentence-pivoting approach with size corpora.
</nextsent>
<nextsent>5.1 direct system results.
</nextsent>
<nextsent>table 4 shows the results of the direct translation system a-c.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2258">
<title id=" W09-0431.xml">improving arabic chinese statistical machine translation using english as pivot language </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>table 4 shows the results of the direct translation system a-c.
</prevsent>
<prevsent>it also includes the result for a-e and e-c direct translation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
as expected, as we double the size of the data, the bleu score (papineni et al , 2002) <papid> P02-1040 </papid>increases.</citsent>
<aftsection>
<nextsent>however, the rate of increase is not always consistent.
</nextsent>
<nextsent>in particular, the and conditions vary highly in a-e compared to a-c.
</nextsent>
<nextsent>this is odd especially given that we are comparing the same set of data from the three parallel corpora.
</nextsent>
<nextsent>we speculate that this may have to do with an oddity in that portion of the dataset that may have different quality than the rest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2260">
<title id=" W08-1003.xml">partofspeech tagging with a symbolic full parser using the tiger treebank to evaluate fips </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>further research has to show if these structural differences can be overcome in order to lead to meaningful comparison.
</prevsent>
<prevsent>the exact evaluation metric will also have to be chosen.
</prevsent>
</prevsection>
<citsent citstr=" D07-1066 ">
while parseval (black et al, 1991)is still one of the most important metrics, other measures may be more adapted to our problem (carroll et al, 2002; rehbein and van genabith, 2007).<papid> D07-1066 </papid></citsent>
<aftsection>
<nextsent>22
</nextsent>
<nextsent>as we remarked above, this article reports on work in progress.
</nextsent>
<nextsent>until now, we have been able to show that the general approach of evaluating fips with the help of the tiger treebank is valid.
</nextsent>
<nextsent>with very little adaptation work (see section 3.2), we managed to obtain 87.32% of pos-tagging accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2261">
<title id=" W09-1213.xml">multilingual semantic role labelling with markov logic </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>we will refer to these predicates as the token predicates.
</prevsent>
<prevsent>the second set extends the information provided in the closed track corpus: cpos/2 is coarse pos tag (first letter of actual pos tag); possiblearg/1 istrue if the pos tag the token is potential srl argument pos tag (e.g., punc is not); voice/2 denotes the voice for verbal tokens based on heuristics that use syntactic information, or based on features in the feat column of the data.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
we will refer to these predicates as the extended predicates.finally, the third set represents dependency information inspired by the features proposed by xue and palmer (2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>there are two types of predicate sin this set: paths and frames.
</nextsent>
<nextsent>paths capture the dependency path between two tokens, and frames the subcategorisation frame for token or pair of tokens.
</nextsent>
<nextsent>there are directed and undirected versions of paths, and labelled (with dependency relations) and un labelled versions of paths and frames.
</nextsent>
<nextsent>finally, we have frame predicate with the distance from the predicate to its head.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2262">
<title id=" W09-1213.xml">multilingual semantic role labelling with markov logic </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>our mln is tested on the following languages: catalan and spanish (taule?
</prevsent>
<prevsent>et al, 2008) , chinese (palmer and xue, 2009), czech (hajic?
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
et al, 2006),4 english (surdeanu et al, 2008), <papid> W08-2121 </papid>german (burchardt et al, 2006), japanese (kawahara et al, 2002).</citsent>
<aftsection>
<nextsent>table 5 presents the f1-scores and training/test times for the development and in-domain corpora.
</nextsent>
<nextsent>clearly, our model does better for english.
</nextsent>
<nextsent>this is 4for training we use only sentences shorter than 40 words in this corpus.
</nextsent>
<nextsent>structural constraints hasrole(p, a) ? argument(a) role(p, a, r) ? hasrole(p, a) argument(a) ? p.hasrole(p, a) hasrole(p, a) ? r.role(p, a, r) hard constraints role(p, a, r1) ? r1 6= r2 ? role(p, a, r2) sense(p, s1) ? s1 6= s2 ? sense(p, r2) role (p, a1, r) ? mod (r) ? a1 6= a2 ? role (p, a2, r) soft constraints role (p, a1, r) ? mod (r) ? a1 6= a2 ? role (p, a2, r) plemma(p,+l)ppos(a,+p)hasrole(p, a) ? sense(p,+f) plemma(p,+l)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2263">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present system developed for the conll-2009 shared task (hajic?
</prevsent>
<prevsent>et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
we extend the carreras (2007) <papid> D07-1101 </papid>parser to jointly annotate syntactic and semantic dependencies.</citsent>
<aftsection>
<nextsent>this state-of-the-art parser factor izes the built tree in second-order factors.
</nextsent>
<nextsent>we include semantic dependencies in the factors and extend their score function to combine syntactic and semantic scores.
</nextsent>
<nextsent>the parser is coupled with an on-line averaged perceptron (collins, 2002) <papid> W02-1001 </papid>as the learning method.</nextsent>
<nextsent>our averaged results for all seven languages are71.49 macro f1, 79.11 las and 63.06 semantic f1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2266">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this state-of-the-art parser factor izes the built tree in second-order factors.
</prevsent>
<prevsent>we include semantic dependencies in the factors and extend their score function to combine syntactic and semantic scores.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the parser is coupled with an on-line averaged perceptron (collins, 2002) <papid> W02-1001 </papid>as the learning method.</citsent>
<aftsection>
<nextsent>our averaged results for all seven languages are71.49 macro f1, 79.11 las and 63.06 semantic f1.
</nextsent>
<nextsent>systems that jointly annotate syntactic and semantic dependencies were introduced in the past conll 2008 shared task (surdeanu et al, 2008).<papid> W08-2121 </papid></nextsent>
<nextsent>these.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2267">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parser is coupled with an on-line averaged perceptron (collins, 2002) <papid> W02-1001 </papid>as the learning method.</prevsent>
<prevsent>our averaged results for all seven languages are71.49 macro f1, 79.11 las and 63.06 semantic f1.</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
systems that jointly annotate syntactic and semantic dependencies were introduced in the past conll 2008 shared task (surdeanu et al, 2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>these.
</nextsent>
<nextsent>systems showed promising results and proved the feasibility of joint syntactic and semantic parsing (henderson et al, 2008; <papid> W08-2122 </papid>llus and ma`rquez, 2008).</nextsent>
<nextsent>the eisner (1996) <papid> C96-1058 </papid>algorithm and its variants are commonly used in data-driven dependency pars ing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2268">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems that jointly annotate syntactic and semantic dependencies were introduced in the past conll 2008 shared task (surdeanu et al, 2008).<papid> W08-2121 </papid></prevsent>
<prevsent>these.</prevsent>
</prevsection>
<citsent citstr=" W08-2122 ">
systems showed promising results and proved the feasibility of joint syntactic and semantic parsing (henderson et al, 2008; <papid> W08-2122 </papid>llus and ma`rquez, 2008).</citsent>
<aftsection>
<nextsent>the eisner (1996) <papid> C96-1058 </papid>algorithm and its variants are commonly used in data-driven dependency pars ing.</nextsent>
<nextsent>improvements of this algorithm presented by mcdonald et al (2006) and carreras (2007) <papid> D07-1101 </papid>achieved state-of-the-art performance for english in the conll-2007 shared task (nivre et al, 2007).<papid> D07-1096 </papid>johansson and nugues (2008) <papid> W08-2123 </papid>presented system based on the carreras?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2269">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these.
</prevsent>
<prevsent>systems showed promising results and proved the feasibility of joint syntactic and semantic parsing (henderson et al, 2008; <papid> W08-2122 </papid>llus and ma`rquez, 2008).</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
the eisner (1996) <papid> C96-1058 </papid>algorithm and its variants are commonly used in data-driven dependency pars ing.</citsent>
<aftsection>
<nextsent>improvements of this algorithm presented by mcdonald et al (2006) and carreras (2007) <papid> D07-1101 </papid>achieved state-of-the-art performance for english in the conll-2007 shared task (nivre et al, 2007).<papid> D07-1096 </papid>johansson and nugues (2008) <papid> W08-2123 </papid>presented system based on the carreras?</nextsent>
<nextsent>extension of the eisner algorithm that ranked first in the past conll 2008 shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2273">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems showed promising results and proved the feasibility of joint syntactic and semantic parsing (henderson et al, 2008; <papid> W08-2122 </papid>llus and ma`rquez, 2008).</prevsent>
<prevsent>the eisner (1996) <papid> C96-1058 </papid>algorithm and its variants are commonly used in data-driven dependency pars ing.</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
improvements of this algorithm presented by mcdonald et al (2006) and carreras (2007) <papid> D07-1101 </papid>achieved state-of-the-art performance for english in the conll-2007 shared task (nivre et al, 2007).<papid> D07-1096 </papid>johansson and nugues (2008) <papid> W08-2123 </papid>presented system based on the carreras?</citsent>
<aftsection>
<nextsent>extension of the eisner algorithm that ranked first in the past conll 2008 shared task.
</nextsent>
<nextsent>we decided to extend the car-.
</nextsent>
<nextsent>reras (2007) parser to jointly annotate syntactic and semantic dependencies.
</nextsent>
<nextsent>the present year shared task has the incentive of being multilingual with each language presenting their own particularities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2275">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems showed promising results and proved the feasibility of joint syntactic and semantic parsing (henderson et al, 2008; <papid> W08-2122 </papid>llus and ma`rquez, 2008).</prevsent>
<prevsent>the eisner (1996) <papid> C96-1058 </papid>algorithm and its variants are commonly used in data-driven dependency pars ing.</prevsent>
</prevsection>
<citsent citstr=" W08-2123 ">
improvements of this algorithm presented by mcdonald et al (2006) and carreras (2007) <papid> D07-1101 </papid>achieved state-of-the-art performance for english in the conll-2007 shared task (nivre et al, 2007).<papid> D07-1096 </papid>johansson and nugues (2008) <papid> W08-2123 </papid>presented system based on the carreras?</citsent>
<aftsection>
<nextsent>extension of the eisner algorithm that ranked first in the past conll 2008 shared task.
</nextsent>
<nextsent>we decided to extend the car-.
</nextsent>
<nextsent>reras (2007) parser to jointly annotate syntactic and semantic dependencies.
</nextsent>
<nextsent>the present year shared task has the incentive of being multilingual with each language presenting their own particularities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2278">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>3) joint syntactic-semantic parsing.
</prevsent>
<prevsent>4) predicate classification.the preprocessing and feature extraction is intended to ease and improve the performance of the parser pre computing binary representation of 79 each sentence features.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
these features are borrowed from existing and widely-known systems (xue and palmer, 2004; <papid> W04-3212 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>carreras et al, 2006; <papid> W06-2925 </papid>surdeanu et al, 2007).</citsent>
<aftsection>
<nextsent>the following step is syntactic pre-parse.
</nextsent>
<nextsent>it is only required to pre-compute additional features(e.g., syntactic path, syntactic frame) from the syntax.
</nextsent>
<nextsent>these new features will be used for the semantic role component of the following joint parser.
</nextsent>
<nextsent>the joint parser is the core of the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2279">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>3) joint syntactic-semantic parsing.
</prevsent>
<prevsent>4) predicate classification.the preprocessing and feature extraction is intended to ease and improve the performance of the parser pre computing binary representation of 79 each sentence features.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
these features are borrowed from existing and widely-known systems (xue and palmer, 2004; <papid> W04-3212 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>carreras et al, 2006; <papid> W06-2925 </papid>surdeanu et al, 2007).</citsent>
<aftsection>
<nextsent>the following step is syntactic pre-parse.
</nextsent>
<nextsent>it is only required to pre-compute additional features(e.g., syntactic path, syntactic frame) from the syntax.
</nextsent>
<nextsent>these new features will be used for the semantic role component of the following joint parser.
</nextsent>
<nextsent>the joint parser is the core of the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2280">
<title id=" W09-1212.xml">a second order joint eisner model for syntactic and semantic dependency parsing </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>3) joint syntactic-semantic parsing.
</prevsent>
<prevsent>4) predicate classification.the preprocessing and feature extraction is intended to ease and improve the performance of the parser pre computing binary representation of 79 each sentence features.
</prevsent>
</prevsection>
<citsent citstr=" W06-2925 ">
these features are borrowed from existing and widely-known systems (xue and palmer, 2004; <papid> W04-3212 </papid>mcdonald et al, 2005; <papid> P05-1012 </papid>carreras et al, 2006; <papid> W06-2925 </papid>surdeanu et al, 2007).</citsent>
<aftsection>
<nextsent>the following step is syntactic pre-parse.
</nextsent>
<nextsent>it is only required to pre-compute additional features(e.g., syntactic path, syntactic frame) from the syntax.
</nextsent>
<nextsent>these new features will be used for the semantic role component of the following joint parser.
</nextsent>
<nextsent>the joint parser is the core of the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2289">
<title id=" W08-1704.xml">multilingual grammar resources in multilingual application development </title>
<section> parameterized grammar rules.  </section>
<citcontext>
<prevsection>
<prevsent>the lower lev els?
</prevsent>
<prevsent>include the language-family specific modules3bidirectional medslt exists currently for english spanish language pair.
</prevsent>
</prevsection>
<citsent citstr=" W07-1806 ">
details are provided in (bouillon et al ., 2007).<papid> W07-1806 </papid></citsent>
<aftsection>
<nextsent>and the language-specific modules.
</nextsent>
<nextsent>the modules for related languages decrease redundancy as related languages commonly share characteristics at least to some extent.
</nextsent>
<nextsent>4 the information in this modular structure is inherited top-down from the most generic to language specific.the first language to which we applied the parameterized rules and which had not been part ofthe original shared grammar framework development is modern greek.in the following we first describe the parameterized grammar rules.
</nextsent>
<nextsent>then we focus on how these rules are applied for greek.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2290">
<title id=" W08-1809.xml">topic indexing and retrieval for factoid qa </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>the topic repository stores topics, along their variant names and their onto logical types, in hash tables for fast look-up.
</prevsent>
<prevsent>building topic repository requires identifying topics within the givencorpus.
</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
for this we have used the c&c; named entity recogniser (curran and clark, 2003), <papid> W03-0424 </papid>which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics.</citsent>
<aftsection>
<nextsent>this also identifies the base type of subset of named entities as person, location and organisation.
</nextsent>
<nextsent>this is stored for later use in building type-separated indices.
</nextsent>
<nextsent>when named entity is identified, we first check whether it represents topic already found in the topic repository.this is done by checking the topic-name hash table in the repository, which serves as the main data storage for the variant names of topics.to resolve target named entity to the appropriate topic, we use wikipedias redirect table, which contains many common variant names forthe same topic.
</nextsent>
<nextsent>the topic-name hash table is updated accordingly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2291">
<title id=" W08-1809.xml">topic indexing and retrieval for factoid qa </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>(geographical knowledge).
</prevsent>
<prevsent>such diverse and significant knowledge, as well asthe breadth and the depth of the fine types contained in the topic-type hash table, enable very powerful match between the answer type from question to that of candidate topic.
</prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
the set of fine-grained answer types used here differs from the set of answer types such as li androth (2002) <papid> C02-1150 </papid>used elsewhere in that the set is open ended, and new types can be added for an entity at any time.the topic repository is used in re-ranking answer candidates by the fine-grained anwer type and for question topic identification, as well as in building topic document collection to be explained next.</citsent>
<aftsection>
<nextsent>3.2 the topic document collection.
</nextsent>
<nextsent>as noted, the textual content of topic is the set of all sentences in corpus that mentions this topic.
</nextsent>
<nextsent>67 (since anaphora resolution is not yet performed, the sentences that only mention particular topic anaphoric ally are missed.)
</nextsent>
<nextsent>such set of sentences is assembled into one file per topic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2292">
<title id=" W08-1809.xml">topic indexing and retrieval for factoid qa </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in predictive annotation (prager et al, 1999), the text of the target corpus is pre-processed in such way that phrases that are potential answers are marked and annotated with respect to their answer types (or qa-tokens as they call them) including person$ 1 , duration$, etc. then the text is indexed not only with ordinary terms but also with these qa-tokens as indexing elements.
</prevsent>
<prevsent>the main advantage of this approach is that qa-tokens areused as part of the query enhancing the passage retrieval performance.
</prevsent>
</prevsection>
<citsent citstr=" W01-1202 ">
our work in this paper usesthe same predictive annotation technique but differs in that the named entities are indexed as topics and are retrieved directly as answer candidates.similar to our approach, kim et al (2001) <papid> W01-1202 </papid>applies predictive annotation method to retrieve answers directly rather than supporting text.</citsent>
<aftsection>
<nextsent>for every potential answer in the corpus, set of text spans up to three sentences long (the sentence inwhich it appears, plus whatever following sentences that are linked to this sentence via lexical chain totalling no more than three sentences in size) is stored and later sued to retrieve potential answer.
</nextsent>
<nextsent>although similar to our work, the main difference is in the way the textual evidence is aggregated.
</nextsent>
<nextsent>in topic indexing and retrieval, all the evidence (aka textual content) available through out the corpus for possible answer is aggregated, whereas kim uses text spans up three sentences long from single document connected by coreference chain for each answer candidate.
</nextsent>
<nextsent>also, topic relations are not exploited as in our work (via bi-topic documents).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2293">
<title id=" W08-1809.xml">topic indexing and retrieval for factoid qa </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the extracted concept instance pairs of person name-title such as (bill 1 in their notation, the dollar sign at the end indicates that this is qa token rather than term.
</prevsent>
<prevsent>72 gates, chairman of microsoft) are used either solely or in conjunction with common qa system in producing answers.
</prevsent>
</prevsection>
<citsent citstr=" C04-1188 ">
(jijkoun et al (2004)<papid> C04-1188 </papid>follows similar approach.)</citsent>
<aftsection>
<nextsent>this basically information extraction approach taken here can complement our own work for the benefit of increased precision for select types of questions.
</nextsent>
<nextsent>in clifton and teahan (2004), their knowledge framework based qa system, qitekat, pre stores possible answers along with their corresponding question templates based on manual and automatic regular expression patterns.
</nextsent>
<nextsent>that the potential questions are stored as well the answers make this approach different from our approach.the bi-topic method in this paper has some similarity to katz and lin (2000).<papid> W00-1107 </papid></nextsent>
<nextsent>here, ternary relations are extracted off-line using manually constructed regular expression patterns on target text and stored in database for the use in question answering such as in the start qa system (katzet al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2294">
<title id=" W08-1809.xml">topic indexing and retrieval for factoid qa </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this basically information extraction approach taken here can complement our own work for the benefit of increased precision for select types of questions.
</prevsent>
<prevsent>in clifton and teahan (2004), their knowledge framework based qa system, qitekat, pre stores possible answers along with their corresponding question templates based on manual and automatic regular expression patterns.
</prevsent>
</prevsection>
<citsent citstr=" W00-1107 ">
that the potential questions are stored as well the answers make this approach different from our approach.the bi-topic method in this paper has some similarity to katz and lin (2000).<papid> W00-1107 </papid></citsent>
<aftsection>
<nextsent>here, ternary relations are extracted off-line using manually constructed regular expression patterns on target text and stored in database for the use in question answering such as in the start qa system (katzet al, 2002).
</nextsent>
<nextsent>with bi-topic documents in this paper, instead of the precise relations between thetwo topics, the aggregate context between two particular topics are captured by assembling all statements that mention these two topics together in onefile.
</nextsent>
<nextsent>while this does not give the exact characteristics of the relations involved, it does give some statistical characterization between the two topics to the benefit for qa.
</nextsent>
<nextsent>in this paper, we have presented the method of topic indexing and retrieval for qa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2295">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are not aware of any previous work on this task for hebrew.
</prevsent>
<prevsent>due to the problem above, the performance of many acquisition algorithms deteriorates unacceptably.
</prevsent>
</prevsection>
<citsent citstr=" P06-1038 ">
this happens, for example, in the (davidov and rappoport, 2006) <papid> P06-1038 </papid>algorithm that utilizes automatically detected function words as the main building block for pattern construction.</citsent>
<aftsection>
<nextsent>in order to overcome this problem, one should separate such prefixes from the compound words (words consisting of function morphemes attached to content words) in the input corpus.
</nextsent>
<nextsent>whenwe consider some particular word, there are frequently many options to split it to smaller strings.
</nextsent>
<nextsent>fortunately, the set of function words is small and closed, and the set of grammatical sequences of function prefixes is also small.
</nextsent>
<nextsent>hence we assume it does not cost us much to know in advance what are the possible sequences for specific language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2296">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we develop an unsupervised framework for segmentation of the function words for languages where context is important for correctsegmentation.
</prevsent>
<prevsent>our main target language is hebrew, and we experimented with arabicas well.as far as we know, there is no work on unsupervised segmentation of words in hebrew which does not utilize language-specific tools such as morphological analyzers.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
lee et al (2003) <papid> P03-1051 </papid>addressed supervised word segmentation in arabic and have some aspects similar to our approach.</citsent>
<aftsection>
<nextsent>as in their study, we 1transcription is according to (ornan, 2005), except for shin which is denoted by ?$?.
</nextsent>
<nextsent>also have pre-supplied list of possible prefix sequences and assume trigram model in order to find the most probable morpheme sequence.
</nextsent>
<nextsent>both studies evaluate performance on segmented text, and not just on words in the lexicon.
</nextsent>
<nextsent>however, their algorithm, while achieving good performance (97% accuracy), relies on training set ? manually segmented corpus of about 110,000 words, while our unsupervised framework doesnot require any annotation and is thus easier to implement and to apply to different domains and lan guages.snyder and barzilay (2008) <papid> P08-1084 </papid>study the task of unsupervised morphological segmentation of multiple languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2297">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>also have pre-supplied list of possible prefix sequences and assume trigram model in order to find the most probable morpheme sequence.
</prevsent>
<prevsent>both studies evaluate performance on segmented text, and not just on words in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" P08-1084 ">
however, their algorithm, while achieving good performance (97% accuracy), relies on training set ? manually segmented corpus of about 110,000 words, while our unsupervised framework doesnot require any annotation and is thus easier to implement and to apply to different domains and lan guages.snyder and barzilay (2008) <papid> P08-1084 </papid>study the task of unsupervised morphological segmentation of multiple languages.</citsent>
<aftsection>
<nextsent>their algorithm automatically induces segmentation and morpheme alignment of short parallel phrases from multilingual corpus.
</nextsent>
<nextsent>their corpus (the hebrew bible and translations)contains parallel phrases in english, arabic, hebrew and aramaic.
</nextsent>
<nextsent>they obtain 63.87 f-scorefor hebrew words segmentation (prefix and suf fix), where recall and precision is calculated based on all possible segmentation points.another type of segmentation algorithms involves utilization of language-specific morphological analyzers for complete morphological disambiguation.
</nextsent>
<nextsent>in hebrew each word usually has more than one possible pos (along with other attributes, such as gender, number, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2298">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in hebrew each word usually has more than one possible pos (along with other attributes, such as gender, number, etc.).
</prevsent>
<prevsent>assuming we have morphological analyzer (producing the set of possible analyses forgiven word), we can try to discover the correct segmentation of each word.
</prevsent>
</prevsection>
<citsent citstr=" J95-3004 ">
levinger et al (1995) <papid> J95-3004 </papid>developed method for disambiguation of the results provided by morphological analyzer for hebrew.</citsent>
<aftsection>
<nextsent>adler andel hadad (2006) <papid> P06-1084 </papid>proposed an unsupervised algorithm for word segmentation.</nextsent>
<nextsent>they estimate an initial language model (using (levinger et al, 1995))<papid> J95-3004 </papid>and improve this model with em.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2299">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>assuming we have morphological analyzer (producing the set of possible analyses forgiven word), we can try to discover the correct segmentation of each word.
</prevsent>
<prevsent>levinger et al (1995) <papid> J95-3004 </papid>developed method for disambiguation of the results provided by morphological analyzer for hebrew.</prevsent>
</prevsection>
<citsent citstr=" P06-1084 ">
adler andel hadad (2006) <papid> P06-1084 </papid>proposed an unsupervised algorithm for word segmentation.</citsent>
<aftsection>
<nextsent>they estimate an initial language model (using (levinger et al, 1995))<papid> J95-3004 </papid>and improve this model with em.</nextsent>
<nextsent>direct comparison to their work is problematic, however, sincewe avoid utilization of language-specific mor phology/pos analyzer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2301">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>direct comparison to their work is problematic, however, sincewe avoid utilization of language-specific mor phology/pos analyzer.
</prevsent>
<prevsent>there are also studies of this type that utilize labeled data (bar-haim et al, 2005), where the language model is learned from the training data.extensive research has been done on word segmentation, where, unlike in our study, the segmentation is evaluated for every word, regardless of its context.
</prevsent>
</prevsection>
<citsent citstr=" P03-1036 ">
creutz (2003) <papid> P03-1036 </papid>presents an algorithm for unsupervised segmentation under these assump tions.</citsent>
<aftsection>
<nextsent>he proposes probabilistic model which 37 utilizes the distributions of morpheme length and frequency to estimate the quality of the induced morphemes.
</nextsent>
<nextsent>dasgupta and ng (2007) <papid> N07-1020 </papid>improves over (creutz, 2003) <papid> P03-1036 </papid>by suggesting simpler ap proach.</nextsent>
<nextsent>they segment prefix using the word frequency with and without prefix.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2302">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>creutz (2003) <papid> P03-1036 </papid>presents an algorithm for unsupervised segmentation under these assump tions.</prevsent>
<prevsent>he proposes probabilistic model which 37 utilizes the distributions of morpheme length and frequency to estimate the quality of the induced morphemes.</prevsent>
</prevsection>
<citsent citstr=" N07-1020 ">
dasgupta and ng (2007) <papid> N07-1020 </papid>improves over (creutz, 2003) <papid> P03-1036 </papid>by suggesting simpler ap proach.</citsent>
<aftsection>
<nextsent>they segment prefix using the word frequency with and without prefix.
</nextsent>
<nextsent>other recent studies that follow the context-independent setup include (creutz and lagus, 2005; keshava and pitler, 2005; demberg, 2007).<papid> P07-1116 </papid></nextsent>
<nextsent>they test their methods on english, finnish and turkish.all of these studies, however, assume context in dependency of segmentation, disregarding the ambiguity that may come from context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2304">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dasgupta and ng (2007) <papid> N07-1020 </papid>improves over (creutz, 2003) <papid> P03-1036 </papid>by suggesting simpler ap proach.</prevsent>
<prevsent>they segment prefix using the word frequency with and without prefix.</prevsent>
</prevsection>
<citsent citstr=" P07-1116 ">
other recent studies that follow the context-independent setup include (creutz and lagus, 2005; keshava and pitler, 2005; demberg, 2007).<papid> P07-1116 </papid></citsent>
<aftsection>
<nextsent>they test their methods on english, finnish and turkish.all of these studies, however, assume context in dependency of segmentation, disregarding the ambiguity that may come from context.
</nextsent>
<nextsent>this makes it problematic to apply the proposed methods to context-dependent morphology types as in hebrew and arabic.the guiding goal in the present paper is the concept acquisition problem.
</nextsent>
<nextsent>concept acquisition of different kinds has been studied extensively.
</nextsent>
<nextsent>the two main classification axes for this task are the type of human input and annotation, and the basicalgorithmic approach used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2305">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the two main classification axes for this task are the type of human input and annotation, and the basicalgorithmic approach used.
</prevsent>
<prevsent>the two main algorithmic approaches are clustering of context feature vectors and pattern-based discovery.the first approach is to map each word to feature vector and cluster these vectors.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
example of such algorithms are (pereira et al, 1993) <papid> P93-1024 </papid>and (lin,1998) <papid> P98-2127 </papid>that use syntactic features in the vector definition.</citsent>
<aftsection>
<nextsent>pantel and lin (2002) improves on the latter by clustering by committee.recently, there is growing interest in the second main algorithmic approach, usage of lexico syntactic patterns.
</nextsent>
<nextsent>patterns have been shown to produce more accurate results than feature vectors, at lower computational cost on large corpora (pantel et al, 2004).<papid> C04-1111 </papid></nextsent>
<nextsent>thus (dorow et al, 2005) discover categories using two basic pre-specified patterns (x and y?, or y?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2306">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the two main classification axes for this task are the type of human input and annotation, and the basicalgorithmic approach used.
</prevsent>
<prevsent>the two main algorithmic approaches are clustering of context feature vectors and pattern-based discovery.the first approach is to map each word to feature vector and cluster these vectors.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
example of such algorithms are (pereira et al, 1993) <papid> P93-1024 </papid>and (lin,1998) <papid> P98-2127 </papid>that use syntactic features in the vector definition.</citsent>
<aftsection>
<nextsent>pantel and lin (2002) improves on the latter by clustering by committee.recently, there is growing interest in the second main algorithmic approach, usage of lexico syntactic patterns.
</nextsent>
<nextsent>patterns have been shown to produce more accurate results than feature vectors, at lower computational cost on large corpora (pantel et al, 2004).<papid> C04-1111 </papid></nextsent>
<nextsent>thus (dorow et al, 2005) discover categories using two basic pre-specified patterns (x and y?, or y?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2307">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>example of such algorithms are (pereira et al, 1993) <papid> P93-1024 </papid>and (lin,1998) <papid> P98-2127 </papid>that use syntactic features in the vector definition.</prevsent>
<prevsent>pantel and lin (2002) improves on the latter by clustering by committee.recently, there is growing interest in the second main algorithmic approach, usage of lexico syntactic patterns.</prevsent>
</prevsection>
<citsent citstr=" C04-1111 ">
patterns have been shown to produce more accurate results than feature vectors, at lower computational cost on large corpora (pantel et al, 2004).<papid> C04-1111 </papid></citsent>
<aftsection>
<nextsent>thus (dorow et al, 2005) discover categories using two basic pre-specified patterns (x and y?, or y?).
</nextsent>
<nextsent>some recent studies have proposed frameworks that attempt to avoid any implicit or explicit pre specification of patterns.
</nextsent>
<nextsent>davidov and rappoport (2006) <papid> P06-1038 </papid>proposed method that detects function words by their high frequency, and utilizes these words for the discovery of symmetric patterns.</nextsent>
<nextsent>their method is based on two assumptions: (1)some function words in the language symmetrically connect words belonging to the same cat egory; (2) such function words can be detected as the most frequent words in language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2313">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> unsupervised discovery of word.  </section>
<citcontext>
<prevsection>
<prevsent>the meaning of phrases constructed from those patterns is (almost) in variant to the order of the content words contained in them.
</prevsent>
<prevsent>an example forsuch pattern is and y?.
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
in order to identify such useful patterns, for each pattern we build graph following (widdows and dorow, 2002).<papid> C02-1114 </papid>the graph is constructed from node for each content word, and directed arc from the node x? to y? if the corresponding content words appear in the pattern such that x? precedes y?.</citsent>
<aftsection>
<nextsent>then we calculate several symmetry measures on the graph structure and select the patterns with best values for these measures.
</nextsent>
<nextsent>the third stage is the generation of categories.
</nextsent>
<nextsent>we extract tightly connected sets of words fromthe unified graph which combines all graphs of selected patterns.
</nextsent>
<nextsent>such sets of words define the desired categories.the patterns which include the and y?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2319">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> summary.  </section>
<citcontext>
<prevsection>
<prevsent>the method requires very little language-specific knowledge (theprefixes), and it can be applied to any morphologically rich language.
</prevsent>
<prevsent>we showed that this segmentation dramatically improves lexical acquisition in hebrew, where nearly 10 data is required to obtain the same number of concepts without segmentation.
</prevsent>
</prevsection>
<citsent citstr=" P07-1030 ">
while in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types (davidovet al, 2007; <papid> P07-1030 </papid>davidov and rappoport, 2008<papid> P08-1079 </papid>a; davidov and rappoport, 2008<papid> P08-1079 </papid>b).</citsent>
<aftsection>
<nextsent>many of these methods are mostly based on function words, and may greatly benefit from the proposed segmentation framework.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2320">
<title id=" W09-0805.xml">unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic </title>
<section> summary.  </section>
<citcontext>
<prevsection>
<prevsent>the method requires very little language-specific knowledge (theprefixes), and it can be applied to any morphologically rich language.
</prevsent>
<prevsent>we showed that this segmentation dramatically improves lexical acquisition in hebrew, where nearly 10 data is required to obtain the same number of concepts without segmentation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1079 ">
while in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types (davidovet al, 2007; <papid> P07-1030 </papid>davidov and rappoport, 2008<papid> P08-1079 </papid>a; davidov and rappoport, 2008<papid> P08-1079 </papid>b).</citsent>
<aftsection>
<nextsent>many of these methods are mostly based on function words, and may greatly benefit from the proposed segmentation framework.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2328">
<title id=" W08-1127.xml">the grec challenge 2008 overview and evaluation results </title>
<section> grec test set p: 31 short encyclopaedic texts.  </section>
<citcontext>
<prevsection>
<prevsent>pack.
</prevsent>
<prevsent>cost of 1.
</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
we also used the version of string-edit distance described by bangalore et al (2000) <papid> W00-1401 </papid>which normalises for length.</citsent>
<aftsection>
<nextsent>this version is denoted seb?
</nextsent>
<nextsent>below.
</nextsent>
<nextsent>for the single-re test sets, the global score is simply the average of all re-level scores.
</nextsent>
<nextsent>for testset c-2, we used an approach analogous to that described above for reg08-type accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2329">
<title id=" W08-1127.xml">the grec challenge 2008 overview and evaluation results </title>
<section> grec test set p: 31 short encyclopaedic texts.  </section>
<citcontext>
<prevsection>
<prevsent>as new and highly experimental method, we tried out an automatic approach to extrinsic evaluation.the basic idea was similar to that in the human based experiments described above: badly chosen reference chains seem likely to affect the readers ability to resolve res.
</prevsent>
<prevsent>in the automatic version, therole of the reader is played by an automatic coreference resolution tool and the expectation is that thetool performs worse (are less able to identify coreference chains correctly) with worse msr reference chains.to counteract the potential problem of results being function of specific coreference resolution algorithm or tool, we decided to use three different resolversthose included in lingpipe,5 javarap (qiu et al, 2004) and opennlp (morton, 2005)?
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
and to average results.there does not appear to be single standard eval 5http://alias-i.com/lingpipe/uation metric in the coreference resolution community, so we opted to use three: muc-6 (vilain et al, 1995), ceaf (luo, 2005), <papid> H05-1004 </papid>and b-cubed (bagga and baldwin, 1998), which seem to be the most widely accepted metrics.</citsent>
<aftsection>
<nextsent>all three metrics compute recall, precision and f-scores on aligned gold-standard and resolver-toolcoreference chains.
</nextsent>
<nextsent>they differ in how the alignment is obtained and what components of coreference chains are counted for calculating scores.
</nextsent>
<nextsent>results for the automatic extrinsic evaluations are reported below in terms of the f-scores from these three metrics, as well as in terms of their average.
</nextsent>
<nextsent>base-rand, base-freq, base-1st, base-name: we created four baseline systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2330">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work was performed in cooperation with the companysystran.
</prevsent>
<prevsent>we only consider the translation between french and english (in both directions).
</prevsent>
</prevsection>
<citsent citstr=" W08-0313 ">
the main differences to the previous years system(schwenk et al, 2008) <papid> W08-0313 </papid>are as follows: better usage of sys trans bilingual dictionary in the statistical system, less bilingual training data, additional language model training data (news-train08as distributed by the organizers), usage of comparable corpora to improve the translation model,and development of statistical post-editing system (spe).</citsent>
<aftsection>
<nextsent>these different components are described in the following.
</nextsent>
<nextsent>in the framework of the 2009 wmt shared translation task many resources were made available.
</nextsent>
<nextsent>the following sections describe how they were used to train the translation and language models of the systems.
</nextsent>
<nextsent>2.1 bilingual data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2331">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> used resources.  </section>
<citcontext>
<prevsection>
<prevsent>we also performed experiments with the provided so-called bilingual french/english gigaword corpus (575m english words in release 3).
</prevsent>
<prevsent>again, we were not able to achieve any improvement by adding this data to the training material of the translation model.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
these findings are somehow surprising since it was eventually believed by the community that adding large amounts of bitexts should improve the translation model, as it is usually observed for the language model (brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>in addition to these human generated bitexts,we also integrated high quality bilingual dictionary from systran.
</nextsent>
<nextsent>the entries of the dictionary were directly added to the bitexts.
</nextsent>
<nextsent>this technique has the potential advantage that the dictionary words could improve the alignments of these words when they also appear in the other bitexts.however, it is not guaranteed that multi-word expressions will be correctly aligned by giza++ and that only meaningful translations will actually appear in the phrase-table.
</nextsent>
<nextsent>a typical example is fire engine ? camion de pom piers, for which the individual constituent words are not good translations of each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2332">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> used resources.  </section>
<citcontext>
<prevsection>
<prevsent>the use of dictionary to improve an smt system was also investigated by 1lines 580934581316 and 599839600662.
</prevsent>
<prevsent>130 en smt fr used as queries per day articles candidate sentence pairs parallel sentences +5 day articles from english gigaword english translations gigaword french 174m words 133m words tail removal sentences with extra words at ends + 9.3m words parallel number / table comparison length removing wer 10.3m words figure 1: architecture of the parallel sentence extraction system (rauf and schwenk, 2009).
</prevsent>
</prevsection>
<citsent citstr=" H93-1039 ">
(brown et al, 1993).<papid> H93-1039 </papid></citsent>
<aftsection>
<nextsent>in comparison to our previous work (schwenk et al, 2008), <papid> W08-0313 </papid>we also included all verbs in the french subjonctif and passe?</nextsent>
<nextsent>simple tense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2334">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>adding the new news-train08 monolingual data had an important impact on the quality of the lm, even when the gigaword data is already included.
</prevsent>
<prevsent>data french english vocabulary size 407k 299k eparl+news 248.8 416.7 + ldc gigaword 142.2 194.9 + hansard and un 137.5 187.5 news-train08 alone 165.0 245.9 all 120.6 174.8 table 2: perplexities on the development data of various language models.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the goal of statistical machine translation (smt) is to produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</citsent>
<aftsection>
<nextsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (och and ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2335">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>adding the new news-train08 monolingual data had an important impact on the quality of the lm, even when the gigaword data is already included.
</prevsent>
<prevsent>data french english vocabulary size 407k 299k eparl+news 248.8 416.7 + ldc gigaword 142.2 194.9 + hansard and un 137.5 187.5 news-train08 alone 165.0 245.9 all 120.6 174.8 table 2: perplexities on the development data of various language models.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the goal of statistical machine translation (smt) is to produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</citsent>
<aftsection>
<nextsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (och and ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2336">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>data french english vocabulary size 407k 299k eparl+news 248.8 416.7 + ldc gigaword 142.2 194.9 + hansard and un 137.5 187.5 news-train08 alone 165.0 245.9 all 120.6 174.8 table 2: perplexities on the development data of various language models.
</prevsent>
<prevsent>the goal of statistical machine translation (smt) is to produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</nextsent>
<nextsent>the system is based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.first, word alignments in both directions are cal culated.</nextsent>
<nextsent>we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid>2 this speeds up the process and corrects an error of giza++ that can appear with rare words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2337">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (och and ney, 2002).<papid> P02-1038 </papid></prevsent>
<prevsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the system is based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.first, word alignments in both directions are cal culated.</citsent>
<aftsection>
<nextsent>we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid>2 this speeds up the process and corrects an error of giza++ that can appear with rare words.</nextsent>
<nextsent>this previously caused problems when adding the entries of the bilingual dictionary to the bitexts.phrases and lexical reorderings are extracted using the default settings of the moses toolkit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2338">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</prevsent>
<prevsent>the system is based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.first, word alignments in both directions are cal culated.</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid>2 this speeds up the process and corrects an error of giza++ that can appear with rare words.</citsent>
<aftsection>
<nextsent>this previously caused problems when adding the entries of the bilingual dictionary to the bitexts.phrases and lexical reorderings are extracted using the default settings of the moses toolkit.
</nextsent>
<nextsent>the parameters of moses are tuned on news-dev2009a, using the cmert tool.
</nextsent>
<nextsent>the basic architecture of the system is identical to the one used in the 2008 wmt evaluation (schwenk et al, 2008),.<papid> W08-0313 </papid></nextsent>
<nextsent>but we did not use two pass decoding and n-best list rescoring with continuous space language model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2340">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the spe system.  </section>
<citcontext>
<prevsection>
<prevsent>we provide also the performance of the different systems on the official test set, calculated after the evaluation.
</prevsent>
<prevsent>in most of the cases, the observed improvements carry over on the test set.
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
during the last years statistical post-editing systems have shown to achieve very competitive performance (simard et al, 2007; <papid> W07-0728 </papid>dugast et al, 2007).<papid> W07-0732 </papid></citsent>
<aftsection>
<nextsent>the main idea of this techniques is to use 2the source is available at http://www.cs.cmu.
</nextsent>
<nextsent>edu/ ? qing/ 132 corpus # en words dev09a dev09b test09 smt system eparl+nc 41.6m 21.89 21.78 23.80 eparl+nc+dict 44.0m 22.28 22.35# 24.13 eparl+nc+dict+afp 51.7m 22.21 21.43 23.88 spe system systran - 18.68 18.84 20.29 eparl+nc 44.2m 23.03 23.15 24.36 eparl+nc+afp 53.3m 22.95 23.15?
</nextsent>
<nextsent>24.62table 3: case sensitive nist bleu scores for the english-french systems.
</nextsent>
<nextsent>nc?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2341">
<title id=" W09-0423.xml">smt and spe machine translation systems for wmt09 </title>
<section> architecture of the spe system.  </section>
<citcontext>
<prevsection>
<prevsent>we provide also the performance of the different systems on the official test set, calculated after the evaluation.
</prevsent>
<prevsent>in most of the cases, the observed improvements carry over on the test set.
</prevsent>
</prevsection>
<citsent citstr=" W07-0732 ">
during the last years statistical post-editing systems have shown to achieve very competitive performance (simard et al, 2007; <papid> W07-0728 </papid>dugast et al, 2007).<papid> W07-0732 </papid></citsent>
<aftsection>
<nextsent>the main idea of this techniques is to use 2the source is available at http://www.cs.cmu.
</nextsent>
<nextsent>edu/ ? qing/ 132 corpus # en words dev09a dev09b test09 smt system eparl+nc 41.6m 21.89 21.78 23.80 eparl+nc+dict 44.0m 22.28 22.35# 24.13 eparl+nc+dict+afp 51.7m 22.21 21.43 23.88 spe system systran - 18.68 18.84 20.29 eparl+nc 44.2m 23.03 23.15 24.36 eparl+nc+afp 53.3m 22.95 23.15?
</nextsent>
<nextsent>24.62table 3: case sensitive nist bleu scores for the english-french systems.
</nextsent>
<nextsent>nc?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2342">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present new technique for transliteration which is based on deep belief networks (dbns), well studied approach in machine learning.
</prevsent>
<prevsent>transliteration can in principle be considered to be small-scale translation problem and, thus, some ideas presented here can be transferred to thema chine translation domain as well.transliteration has been in use in machine translation systems, e.g. russian-english, since the existence of the field of machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
how ever, to our knowledge it was first studied as machine learning problem by knight and graehl (1998) <papid> J98-4003 </papid>using probabilistic finite-state transducers.</citsent>
<aftsection>
<nextsent>subsequently, the performance of this system was greatly improved by combining different spelling and phonetic models (al-onaizan and knight,2002).
</nextsent>
<nextsent>huang et al (2004) <papid> N04-1036 </papid>construct probabilistic chinese-english edit model as part of alarger alignment solution using heuristic boot strapped procedure.</nextsent>
<nextsent>freitag and khadivi (2007) <papid> D07-1025 </papid>propose technique which combines conventional mt methods with single layer perceptron.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2343">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, to our knowledge it was first studied as machine learning problem by knight and graehl (1998) <papid> J98-4003 </papid>using probabilistic finite-state transducers.</prevsent>
<prevsent>subsequently, the performance of this system was greatly improved by combining different spelling and phonetic models (al-onaizan and knight,2002).</prevsent>
</prevsection>
<citsent citstr=" N04-1036 ">
huang et al (2004) <papid> N04-1036 </papid>construct probabilistic chinese-english edit model as part of alarger alignment solution using heuristic boot strapped procedure.</citsent>
<aftsection>
<nextsent>freitag and khadivi (2007) <papid> D07-1025 </papid>propose technique which combines conventional mt methods with single layer perceptron.</nextsent>
<nextsent>in contrast to these methods which strongly build on top of well-established natural language processing (nlp) techniques, we propose an alternative model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2344">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subsequently, the performance of this system was greatly improved by combining different spelling and phonetic models (al-onaizan and knight,2002).
</prevsent>
<prevsent>huang et al (2004) <papid> N04-1036 </papid>construct probabilistic chinese-english edit model as part of alarger alignment solution using heuristic boot strapped procedure.</prevsent>
</prevsection>
<citsent citstr=" D07-1025 ">
freitag and khadivi (2007) <papid> D07-1025 </papid>propose technique which combines conventional mt methods with single layer perceptron.</citsent>
<aftsection>
<nextsent>in contrast to these methods which strongly build on top of well-established natural language processing (nlp) techniques, we propose an alternative model.
</nextsent>
<nextsent>our new model is based on deep belief networks which have been shown to work well in other machine learning and pattern recognition areas (cf.
</nextsent>
<nextsent>section 2).
</nextsent>
<nextsent>since translation and transliteration are closely related and transliteration can be considered translation problem on the character level, we discuss various methods from both domains which are related to the proposed approach in the following.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2345">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 2).
</prevsent>
<prevsent>since translation and transliteration are closely related and transliteration can be considered translation problem on the character level, we discuss various methods from both domains which are related to the proposed approach in the following.
</prevsent>
</prevsection>
<citsent citstr=" P07-1080 ">
neural networks have been used in nlp in the past, e.g. for machine translation (asuncion castano et al, 1997) and constituent parsing (titov and henderson, 2007).<papid> P07-1080 </papid></citsent>
<aftsection>
<nextsent>however, it might not be straight-forward to obtain good results using neural networks in this domain.
</nextsent>
<nextsent>in general, when training neural network, one has to choose the structure of the neural network which involves certain trade-offs.
</nextsent>
<nextsent>if small network with no hidden layer is chosen, it can be efficiently trained but has very limited representational power, and may be unable to learn the relationships between the source and the target language.
</nextsent>
<nextsent>the dbn approach alleviates some of the problems that commonly occur when working with neural networks: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2346">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, these two models are combined into source-to-target encoding/decoding system (cf.
</prevsent>
<prevsent>section 2).
</prevsent>
</prevsection>
<citsent citstr=" P07-1020 ">
regarding that the target is generated and not searched in space of hypotheses (e.g. in word graph), our approach is similar to the approach presented by bangalore et al (2007) <papid> P07-1020 </papid>who present an mt system where the set of words of the target sentence is generated based on the full source sentence and then finite-state approach is used to reorder the words.</citsent>
<aftsection>
<nextsent>opposed to this approach we do not only generate the letters/words in the target sentence but we generate the full sentence with ordering.
</nextsent>
<nextsent>we evaluate the proposed methods on an arabic-english transliteration task where arabic city names have to be transcribed into the equivalent english spelling.
</nextsent>
<nextsent>transliteration although dbns are thoroughly described in the literature, e.g.
</nextsent>
<nextsent>(hinton et al, 2006), we give short overview on the ideas and techniques and introduce our notation.deep architectures in machine learning and artificial intelligence are becoming more and more popular after an efficient training algorithm has been proposed (hinton et al, 2006), although the idea is known for some years (ackley et al, 1985).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2349">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>i=1 p(ei|e i1 im+1), with being the size of the m-gram, we choose = 9.
</prevsent>
<prevsent>? sequence length model (commonly referred to as word penalty).
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
then, these models are fused in log-linear model(och and ney, 2002), <papid> P02-1038 </papid>and we tune the model scaling factors discriminatively on the development nbest list using the downhill simplex algorithm.</citsent>
<aftsection>
<nextsent>results from the rescoring experiments are given in table 4.the performance of the dbn system is improved on the dev data from 24.1% to 21.3% cer and on the eval data from 22.7% to 20.1% cer.
</nextsent>
<nextsent>238 3.6 application within system.
</nextsent>
<nextsent>combination framework although being clearly outperformed by thephrase-based mt system, we applied the transliteration candidates generated by the dbn approach within system combination framework.
</nextsent>
<nextsent>motivated by the fact that the dbn approach differs decisively from the other statistical approaches we applied to the machine transliteration task, we wanted to investigate the potential benefit of the diverse nature of the dbn transliterations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2350">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>motivated by the fact that the dbn approach differs decisively from the other statistical approaches we applied to the machine transliteration task, we wanted to investigate the potential benefit of the diverse nature of the dbn transliterations.
</prevsent>
<prevsent>taking the transliteration candidates obtained from another study which was intended to perform comparison of various statistical approaches to the transliteration task, we performed the system combination as is customary in speech recognition, i.e. following the recognizer output voting error reduction (rover) approach (fis cus, 1997).
</prevsent>
</prevsection>
<citsent citstr=" N04-1033 ">
the following methods were investigated: (monotone) phrase-based mt on character level: state-of-the-art phrase-based smt system (zens and ney, 2004) <papid> N04-1033 </papid>was used for name transliteration, i.e. translation of characters instead of words.</citsent>
<aftsection>
<nextsent>no reordering model was employed due to the monotonicity of the transliteration task, and the model scaling factors were tuned on maximum transliteration accuracy.
</nextsent>
<nextsent>data-driven grapheme-to-phoneme conversion: in grapheme-to-phoneme conversion (g2p), or phonetic transcription, we seek the most likely pronunciation (phoneme sequence) forgiven orthographic form (sequence of letters).
</nextsent>
<nextsent>then, grapheme-phoneme joint multi-gram, or gra phone for short, is pair of letter sequence and phoneme sequence of possibly different length (bisani and ney, 2008).
</nextsent>
<nextsent>the model training is done in two steps: first, maximum likelihood is used to infer the graphones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2351">
<title id=" W09-0438.xml">a deep learning approach to machine transliteration </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy (me) models are defined position-wise, whereas conditional random fields (crfs) consider full sequences.
</prevsent>
<prevsent>both models were trained according to the maximum class posterior criterion.
</prevsent>
</prevsection>
<citsent citstr=" W03-0420 ">
we used an me tagger (bender et al., 2003) <papid> W03-0420 </papid>and the freely available crf++ toolkit.2 results for each of the individual systems and different combinations are given in table 5.</citsent>
<aftsection>
<nextsent>as expected, the dbn transliterations cannot keep up with the other approaches.
</nextsent>
<nextsent>the additional models (g2p, crf and me) perform slightly better than the pbt method.
</nextsent>
<nextsent>if we look at combinations of systems without the dbn approach, we observe only marginal improvements of around 0.1-0.2% cer.
</nextsent>
<nextsent>interestingly, combination of all 4 models (pbt, g2p, me, crf) works as good as individual 3-way combinations (the same 11.9% on dev are obtained).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2352">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach allows us to analyse reorderings quantitatively, based on their number and span, and qualitatively, based on their relationship to the parse tree of one sentence.
</prevsent>
<prevsent>the method swe introduce are generally applicable, only requiring an aligned parallel corpus with parse over the source or the target side, and can be extended to allow for more than one reference sentence and derivations on both source and target sentences.using this method, we are able to compare there ordering capabilities of two important translation systems: phrase-based model and hierarchical model.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
phrase-based models (och and ney, 2004; <papid> J04-4002 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been major paradigm in statistical machine translation in the last few years, showing state-of-the-art performance formany language pairs.</citsent>
<aftsection>
<nextsent>they search all possible reorderings within restricted window, and their output is guided by the language model and lexicalised reordering model (och et al, 2004), <papid> N04-1021 </papid>both of which are local in scope.</nextsent>
<nextsent>however, the lack of structure in phrase-based models makes it very difficult to model long distance movement of words between languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2353">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach allows us to analyse reorderings quantitatively, based on their number and span, and qualitatively, based on their relationship to the parse tree of one sentence.
</prevsent>
<prevsent>the method swe introduce are generally applicable, only requiring an aligned parallel corpus with parse over the source or the target side, and can be extended to allow for more than one reference sentence and derivations on both source and target sentences.using this method, we are able to compare there ordering capabilities of two important translation systems: phrase-based model and hierarchical model.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
phrase-based models (och and ney, 2004; <papid> J04-4002 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been major paradigm in statistical machine translation in the last few years, showing state-of-the-art performance formany language pairs.</citsent>
<aftsection>
<nextsent>they search all possible reorderings within restricted window, and their output is guided by the language model and lexicalised reordering model (och et al, 2004), <papid> N04-1021 </papid>both of which are local in scope.</nextsent>
<nextsent>however, the lack of structure in phrase-based models makes it very difficult to model long distance movement of words between languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2354">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method swe introduce are generally applicable, only requiring an aligned parallel corpus with parse over the source or the target side, and can be extended to allow for more than one reference sentence and derivations on both source and target sentences.using this method, we are able to compare there ordering capabilities of two important translation systems: phrase-based model and hierarchical model.
</prevsent>
<prevsent>phrase-based models (och and ney, 2004; <papid> J04-4002 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been major paradigm in statistical machine translation in the last few years, showing state-of-the-art performance formany language pairs.</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
they search all possible reorderings within restricted window, and their output is guided by the language model and lexicalised reordering model (och et al, 2004), <papid> N04-1021 </papid>both of which are local in scope.</citsent>
<aftsection>
<nextsent>however, the lack of structure in phrase-based models makes it very difficult to model long distance movement of words between languages.
</nextsent>
<nextsent>synchronous grammar models can encode structural mappings between languages which allow complex, long distance reordering.
</nextsent>
<nextsent>some grammar-based models such as the hierarchical model (chiang, 2005) <papid> P05-1033 </papid>and the syntactified target language phrases model (marcu et al, 2006) have shown better performance than phrase-based models on certain language pairs.to date our understanding of the variation in reordering performance between phrase-based and synchronous grammar models has been limited to relative bleu scores.</nextsent>
<nextsent>however, callison-burch etal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2355">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the lack of structure in phrase-based models makes it very difficult to model long distance movement of words between languages.
</prevsent>
<prevsent>synchronous grammar models can encode structural mappings between languages which allow complex, long distance reordering.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
some grammar-based models such as the hierarchical model (chiang, 2005) <papid> P05-1033 </papid>and the syntactified target language phrases model (marcu et al, 2006) have shown better performance than phrase-based models on certain language pairs.to date our understanding of the variation in reordering performance between phrase-based and synchronous grammar models has been limited to relative bleu scores.</citsent>
<aftsection>
<nextsent>however, callison-burch etal.
</nextsent>
<nextsent>(2006) showed that bleu score alone is insufficient for comparing reordering as it only measures partial ordering on n-grams.
</nextsent>
<nextsent>there has been little direct research on empirically evaluating reordering.
</nextsent>
<nextsent>we evaluate the reordering characteristics of these two paradigms on chinese-english and arabic-english translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2356">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we apply our techniques to human aligned parallel treebank sentences in section 4, and to machine translation outputs in section 5.we summarise our findings in section 6.
</prevsent>
<prevsent>there are few empirical studies of reordering behaviour in the statistical machine translation literature.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
fox (2002) <papid> W02-1039 </papid>showed that many common reorderings fall outside the scope of synchronous grammars that only allow the reordering of child nodes.</citsent>
<aftsection>
<nextsent>this study was performed manually anddid not compare different language pairs or translation paradigms.
</nextsent>
<nextsent>there are some comparative studies of the reordering restrictions that can be imposed on the phrase-based or grammar-based models (zens and ney, 2003; <papid> P03-1019 </papid>wellington et al, 2006), however these do not look at the reordering performance of the systems.</nextsent>
<nextsent>chiang et al (2005)<papid> H05-1098 </papid>proposed more fine-grained method of comparing the output of two translation systems by using the frequency of pos sequences in the output.this method is first step towards better understanding of comparative reordering performance,but neglects the question of what kind of reordering is occurring in corpora and in translation out put.zollmann et al (2008) <papid> C08-1144 </papid>performed an empirical comparison of the bleu score performance of hierarchical models with phrase-based models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2357">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>fox (2002) <papid> W02-1039 </papid>showed that many common reorderings fall outside the scope of synchronous grammars that only allow the reordering of child nodes.</prevsent>
<prevsent>this study was performed manually anddid not compare different language pairs or translation paradigms.</prevsent>
</prevsection>
<citsent citstr=" P03-1019 ">
there are some comparative studies of the reordering restrictions that can be imposed on the phrase-based or grammar-based models (zens and ney, 2003; <papid> P03-1019 </papid>wellington et al, 2006), however these do not look at the reordering performance of the systems.</citsent>
<aftsection>
<nextsent>chiang et al (2005)<papid> H05-1098 </papid>proposed more fine-grained method of comparing the output of two translation systems by using the frequency of pos sequences in the output.this method is first step towards better understanding of comparative reordering performance,but neglects the question of what kind of reordering is occurring in corpora and in translation out put.zollmann et al (2008) <papid> C08-1144 </papid>performed an empirical comparison of the bleu score performance of hierarchical models with phrase-based models.</nextsent>
<nextsent>they tried to ascertain which is the stronger model under different reordering scenarios by varying distortion limits the strength of language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2358">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this study was performed manually anddid not compare different language pairs or translation paradigms.
</prevsent>
<prevsent>there are some comparative studies of the reordering restrictions that can be imposed on the phrase-based or grammar-based models (zens and ney, 2003; <papid> P03-1019 </papid>wellington et al, 2006), however these do not look at the reordering performance of the systems.</prevsent>
</prevsection>
<citsent citstr=" H05-1098 ">
chiang et al (2005)<papid> H05-1098 </papid>proposed more fine-grained method of comparing the output of two translation systems by using the frequency of pos sequences in the output.this method is first step towards better understanding of comparative reordering performance,but neglects the question of what kind of reordering is occurring in corpora and in translation out put.zollmann et al (2008) <papid> C08-1144 </papid>performed an empirical comparison of the bleu score performance of hierarchical models with phrase-based models.</citsent>
<aftsection>
<nextsent>they tried to ascertain which is the stronger model under different reordering scenarios by varying distortion limits the strength of language models.
</nextsent>
<nextsent>they show that the hierarchical models do slightly better for chinese-english systems, but worse for arabic-english.
</nextsent>
<nextsent>however, there was no analysis of the reorderings existing in their parallel corpora, or on what kinds of reorderings were produced in their output.
</nextsent>
<nextsent>we perform focused evaluation of these issues.birch et al (2008) <papid> D08-1078 </papid>proposed method for extracting reorderings from aligned parallel sen tences.we extend this method in order to constrain the reorderings to derivation over the source sentence where possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2359">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this study was performed manually anddid not compare different language pairs or translation paradigms.
</prevsent>
<prevsent>there are some comparative studies of the reordering restrictions that can be imposed on the phrase-based or grammar-based models (zens and ney, 2003; <papid> P03-1019 </papid>wellington et al, 2006), however these do not look at the reordering performance of the systems.</prevsent>
</prevsection>
<citsent citstr=" C08-1144 ">
chiang et al (2005)<papid> H05-1098 </papid>proposed more fine-grained method of comparing the output of two translation systems by using the frequency of pos sequences in the output.this method is first step towards better understanding of comparative reordering performance,but neglects the question of what kind of reordering is occurring in corpora and in translation out put.zollmann et al (2008) <papid> C08-1144 </papid>performed an empirical comparison of the bleu score performance of hierarchical models with phrase-based models.</citsent>
<aftsection>
<nextsent>they tried to ascertain which is the stronger model under different reordering scenarios by varying distortion limits the strength of language models.
</nextsent>
<nextsent>they show that the hierarchical models do slightly better for chinese-english systems, but worse for arabic-english.
</nextsent>
<nextsent>however, there was no analysis of the reorderings existing in their parallel corpora, or on what kinds of reorderings were produced in their output.
</nextsent>
<nextsent>we perform focused evaluation of these issues.birch et al (2008) <papid> D08-1078 </papid>proposed method for extracting reorderings from aligned parallel sen tences.we extend this method in order to constrain the reorderings to derivation over the source sentence where possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2360">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they show that the hierarchical models do slightly better for chinese-english systems, but worse for arabic-english.
</prevsent>
<prevsent>however, there was no analysis of the reorderings existing in their parallel corpora, or on what kinds of reorderings were produced in their output.
</prevsent>
</prevsection>
<citsent citstr=" D08-1078 ">
we perform focused evaluation of these issues.birch et al (2008) <papid> D08-1078 </papid>proposed method for extracting reorderings from aligned parallel sen tences.we extend this method in order to constrain the reorderings to derivation over the source sentence where possible.</citsent>
<aftsection>
<nextsent>reordering is largely driven by syntactic differences between languages and can involve complex rearrangements between nodes in synchronous trees.
</nextsent>
<nextsent>modeling reordering exactly would be sparse and heterogeneous and thus we make an important simplifying assumption in order for the detection and extraction of reordering data to be tractable and useful.
</nextsent>
<nextsent>we assume that reordering is binary process occurring between two blocks that are adjacent in the source.
</nextsent>
<nextsent>we extend the methods proposed by birch et al (2008) <papid> D08-1078 </papid>to identify and measure reordering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2370">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> measuring reordering.  </section>
<citcontext>
<prevsection>
<prevsent>we assume that reordering is binary process occurring between two blocks that are adjacent in the source.
</prevsent>
<prevsent>we extend the methods proposed by birch et al (2008) <papid> D08-1078 </papid>to identify and measure reordering.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
modeling reordering as the inversion in order of two adjacent blocks is similar to the approach taken by the inverse transduction model (itg) (wu, 1997), <papid> J97-3002 </papid>except that here we are not limited to binary tree.</citsent>
<aftsection>
<nextsent>we also detect and include non-syntactic reorderings as they constitute significant proportion of the reorderings.birch et al (2008) <papid> D08-1078 </papid>defined the extraction process for sentence pair that has been word aligned.</nextsent>
<nextsent>this method is simple, efficient and applicable toall aligned sentence pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2387">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> evaluating reordering in translation.  </section>
<citcontext>
<prevsection>
<prevsent>we com 200 none low medium high average rquantity ch-en 0 0.39 0.82 1.51 ar-en 0 0.10 0.25 0.57 number of sentences ch-en 105 367 367 367 ar-en 293 379 379 379 table 1.
</prevsent>
<prevsent>the rquantity and the number of sentences for each reordering test set.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
pare two state-of-the-art models: the phrase-basedsystem moses (koehn et al, 2007) (<papid> P07-2045 </papid>with lexicalised reordering), and the hierarchical model hi ero (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>we use default settings for both models: distortion limit of seven for moses, and maximum source span limit of 10 words for hiero.
</nextsent>
<nextsent>we trained both models on subsets of the nist 2008 datasets, consisting mainly of news data, totalling 547,420 ch-en and 1,069,658 ar en sentence pairs.
</nextsent>
<nextsent>we used trigram language model on the entire english side (211m words)of the nist 2008 chinese-english training corpus.
</nextsent>
<nextsent>minimum error rate training was performed on the 2002 nist test for ch-en, and the 2004 nist test set for ar-en.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2388">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> evaluating reordering in translation.  </section>
<citcontext>
<prevsection>
<prevsent>we com 200 none low medium high average rquantity ch-en 0 0.39 0.82 1.51 ar-en 0 0.10 0.25 0.57 number of sentences ch-en 105 367 367 367 ar-en 293 379 379 379 table 1.
</prevsent>
<prevsent>the rquantity and the number of sentences for each reordering test set.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
pare two state-of-the-art models: the phrase-basedsystem moses (koehn et al, 2007) (<papid> P07-2045 </papid>with lexicalised reordering), and the hierarchical model hi ero (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>we use default settings for both models: distortion limit of seven for moses, and maximum source span limit of 10 words for hiero.
</nextsent>
<nextsent>we trained both models on subsets of the nist 2008 datasets, consisting mainly of news data, totalling 547,420 ch-en and 1,069,658 ar en sentence pairs.
</nextsent>
<nextsent>we used trigram language model on the entire english side (211m words)of the nist 2008 chinese-english training corpus.
</nextsent>
<nextsent>minimum error rate training was performed on the 2002 nist test for ch-en, and the 2004 nist test set for ar-en.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2389">
<title id=" W09-0434.xml">a quantitative analysis of reordering phenomena </title>
<section> evaluating reordering in translation.  </section>
<citcontext>
<prevsection>
<prevsent>we use the test sets created in section 5.1 to explicitly isolate the effect reordering has on the performance of two translation systems.
</prevsent>
<prevsent>figure 7 and figure 8 show the bleu score results of the phrase-based model and the hierarchical model on the different reordering test sets.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
the 95% confidence intervals as calculated by bootstrap re sampling (koehn, 2004) <papid> W04-3250 </papid>are shown for each of the results.</citsent>
<aftsection>
<nextsent>we can see that the models show quite different behaviour for the different test sets and for the different language pairs.
</nextsent>
<nextsent>this demonstrates that reordering greatly influences the 201 none low med high all moseshiero 16 18 20 22 24 26figure 8.
</nextsent>
<nextsent>bleu scores for the different ar-en reordering test sets and the combination of all the groups forthe two translation models.
</nextsent>
<nextsent>the 95% confidence levels as measured by bootstrap re sampling are shown for each bar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2390">
<title id=" W09-1126.xml">using encyclopedic knowledge for automatic topic identification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in similar line of work, (bodo et al , 2007) examined the use of wikipedia and latent semantic analysis for the purposes of text categorization, but reported negative results when used for the categorization of the reuters-21578 dataset.
</prevsent>
<prevsent>others are exploring the use of graph propagation for deriving semantic information.
</prevsent>
</prevsection>
<citsent citstr=" D07-1061 ">
(hughes andra mage, 2007) <papid> D07-1061 </papid>described the use of biased pagerankover the wordnet graph to compute word pair semantic relatedness using the divergence of the probability values over the graph created by each word.</citsent>
<aftsection>
<nextsent>(ollivier and senellart, 2007) describes method to determine related wikipedia article using markov chain derived value called the green measure.
</nextsent>
<nextsent>differences exist between the page rank based methods used as baseline in their work and the method proposed here, since our system can use the content of the article, multiple starting points, and tighter control of the random jump probability via the bias value.
</nextsent>
<nextsent>finally, (syed et al , 2008) reported positive results by using various methods for topic prediction including the use of text similarity and spreading activation.
</nextsent>
<nextsent>the method was tested by using randomly selected wikipedia articles, where in addition to the categories listed on wikipedia page, nearby subsuming categories were also included as acceptable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2391">
<title id=" W08-2127.xml">parsing syntactic and semantic dependencies with two single stage maximum entropy models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>no additional feature selection techniques are applied.
</prevsent>
<prevsent>our system consists of three components to deal with syntactic and semantic dependency parsing and word sense determination, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
both parsing is formulated as single-stage word-pair classification problem, and the latter is carried out by search through the nombank (meyers et al, 2004) <papid> W04-2705 </papid>or the propbank (palmer et al, 2005) <papid> J05-1004 </papid>1 . 2.1 syntactic dependency parsing.</citsent>
<aftsection>
<nextsent>we use shift-reduce scheme to implement syntactic dependency parsing as in (nivre, 2003).
</nextsent>
<nextsent>ittakes step-wised, history- or transition-based approach.
</nextsent>
<nextsent>it is basically word-by-word method with projective constraint.
</nextsent>
<nextsent>in each step, the classifier checks word pair, e.g., top, the top of stack for processed words, and, next, the first word in the unprocessed word sequence, in orderto determine if dependent label should be assigned to them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2392">
<title id=" W08-2127.xml">parsing syntactic and semantic dependencies with two single stage maximum entropy models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>no additional feature selection techniques are applied.
</prevsent>
<prevsent>our system consists of three components to deal with syntactic and semantic dependency parsing and word sense determination, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
both parsing is formulated as single-stage word-pair classification problem, and the latter is carried out by search through the nombank (meyers et al, 2004) <papid> W04-2705 </papid>or the propbank (palmer et al, 2005) <papid> J05-1004 </papid>1 . 2.1 syntactic dependency parsing.</citsent>
<aftsection>
<nextsent>we use shift-reduce scheme to implement syntactic dependency parsing as in (nivre, 2003).
</nextsent>
<nextsent>ittakes step-wised, history- or transition-based approach.
</nextsent>
<nextsent>it is basically word-by-word method with projective constraint.
</nextsent>
<nextsent>in each step, the classifier checks word pair, e.g., top, the top of stack for processed words, and, next, the first word in the unprocessed word sequence, in orderto determine if dependent label should be assigned to them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2393">
<title id=" W08-2127.xml">parsing syntactic and semantic dependencies with two single stage maximum entropy models </title>
<section> reduce: pop top from the stack..  </section>
<citcontext>
<prevsection>
<prevsent>right-arc: add an arc from top to next.
</prevsent>
<prevsent>and push next onto the stack.
</prevsent>
</prevsection>
<citsent citstr=" D07-1097 ">
we implement left-to-right arc-eager parsing model in way that the parser scan through an input sequence from left to right and the right dependents are attached to their heads as soon as possible(hall et al, 2007).<papid> D07-1097 </papid></citsent>
<aftsection>
<nextsent>to construct single-stage system, we extend the left-/right-arc actions to their correspondent multi-label actions as necessary.
</nextsent>
<nextsent>including 32 left-arc and 66 right-arc actions, altogether 100-class problem is yielded for the parsing action classification for this shared task.
</nextsent>
<nextsent>since only projective sequences can be handled by the shift-reduce scheme, we apply the pseudo projective transformation introduced by (nivre and nilsson, 2005) <papid> P05-1013 </papid>to projectivize those non-projectivesequences.</nextsent>
<nextsent>our statistics show that only 7.6% sequences and less than 1% dependencies in the corpus provided for training are non-projective.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2395">
<title id=" W08-2127.xml">parsing syntactic and semantic dependencies with two single stage maximum entropy models </title>
<section> reduce: pop top from the stack..  </section>
<citcontext>
<prevsection>
<prevsent>to construct single-stage system, we extend the left-/right-arc actions to their correspondent multi-label actions as necessary.
</prevsent>
<prevsent>including 32 left-arc and 66 right-arc actions, altogether 100-class problem is yielded for the parsing action classification for this shared task.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
since only projective sequences can be handled by the shift-reduce scheme, we apply the pseudo projective transformation introduced by (nivre and nilsson, 2005) <papid> P05-1013 </papid>to projectivize those non-projectivesequences.</citsent>
<aftsection>
<nextsent>our statistics show that only 7.6% sequences and less than 1% dependencies in the corpus provided for training are non-projective.
</nextsent>
<nextsent>thus, we use simplified strategy to projectivize an input sequence.
</nextsent>
<nextsent>firstly, we simply replace the head of non-projective dependency by its original heads head but without any additional dependent label encoding for the purpose of deprojectivizing the output during decoding.
</nextsent>
<nextsent>secondly, if the above standard projectivization step cannot eliminate all basic extension x.sp itself, its previous two and next two s, and all bigrams within the five-clique window, (x is or i, and is form, lemma or pos.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2396">
<title id=" W08-2127.xml">parsing syntactic and semantic dependencies with two single stage maximum entropy models </title>
<section> reduce: pop top from the stack..  </section>
<citcontext>
<prevsection>
<prevsent>this algorithm can cover 98.5% arguments while reducing about 60% of the training samples, according to our statistics.
</prevsent>
<prevsent>however, this is achieved at the price of including syntactic parse tree as part of the input for semantic parsing.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
the feature set listed in table 3 is adopted for our semantic parsing, some of which are borrowed from (hacioglu, 2004).<papid> C04-1186 </papid></citsent>
<aftsection>
<nextsent>among them, dptreerelation returns the relationship of and in syntactic parse tree.
</nextsent>
<nextsent>its possible values include parent, sibling, child, uncle, grand parent etc. note that there is always path to the root in the syntactic parse tree for either or p. along the common part of these two paths, shareddprelpath returns the sequence of dependent labels collected from each node, and sharedpospath returns the corresponding sequence of pos tags.
</nextsent>
<nextsent>x.dprelpath and x.pospath return the pos tag sequence from xto the beginnings of shareddprelpath and shared pospath, respectively.
</nextsent>
<nextsent>a/p|dprelpath returns the concatenation of a.dprelpath and p.dprelpath.we may have an example to show how the feature bank advice works.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2399">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that by applying existing algorithms for computing simulation classes in description logic, we can obtain extremely efficient algorithms for relational referring expressions without any danger of running into infinite regress.
</prevsent>
<prevsent>the generation of referring expressions (gre) isone of the most active and successful research areas in natural language generation.
</prevsent>
</prevsection>
<citsent citstr=" P89-1009 ">
building upon dale and reiters work (dale, 1989; <papid> P89-1009 </papid>dale and reiter, 1995), various researchers have added extensions such as reference to sets (stone, 2000), <papid> W00-1416 </papid>more expressive logical connectives (van deemter, 2002), and relational expressions (dale and haddock, 1991).<papid> E91-1028 </papid></citsent>
<aftsection>
<nextsent>referring expressions (res) involving relations,in particular, have received increasing attention recently; especially in the context of spatial referring expressions in situated generation (e.g.
</nextsent>
<nextsent>(kelle her and kruijff, 2006)), <papid> P06-1131 </papid>where it seems particularly natural to use expressions such as the book on the table?.</nextsent>
<nextsent>however, the classical algorithm by dale and haddock (1991) <papid> E91-1028 </papid>was recently shown to be unable to generate satisfying resin practice (viethen anddale, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2400">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that by applying existing algorithms for computing simulation classes in description logic, we can obtain extremely efficient algorithms for relational referring expressions without any danger of running into infinite regress.
</prevsent>
<prevsent>the generation of referring expressions (gre) isone of the most active and successful research areas in natural language generation.
</prevsent>
</prevsection>
<citsent citstr=" W00-1416 ">
building upon dale and reiters work (dale, 1989; <papid> P89-1009 </papid>dale and reiter, 1995), various researchers have added extensions such as reference to sets (stone, 2000), <papid> W00-1416 </papid>more expressive logical connectives (van deemter, 2002), and relational expressions (dale and haddock, 1991).<papid> E91-1028 </papid></citsent>
<aftsection>
<nextsent>referring expressions (res) involving relations,in particular, have received increasing attention recently; especially in the context of spatial referring expressions in situated generation (e.g.
</nextsent>
<nextsent>(kelle her and kruijff, 2006)), <papid> P06-1131 </papid>where it seems particularly natural to use expressions such as the book on the table?.</nextsent>
<nextsent>however, the classical algorithm by dale and haddock (1991) <papid> E91-1028 </papid>was recently shown to be unable to generate satisfying resin practice (viethen anddale, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2401">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show that by applying existing algorithms for computing simulation classes in description logic, we can obtain extremely efficient algorithms for relational referring expressions without any danger of running into infinite regress.
</prevsent>
<prevsent>the generation of referring expressions (gre) isone of the most active and successful research areas in natural language generation.
</prevsent>
</prevsection>
<citsent citstr=" E91-1028 ">
building upon dale and reiters work (dale, 1989; <papid> P89-1009 </papid>dale and reiter, 1995), various researchers have added extensions such as reference to sets (stone, 2000), <papid> W00-1416 </papid>more expressive logical connectives (van deemter, 2002), and relational expressions (dale and haddock, 1991).<papid> E91-1028 </papid></citsent>
<aftsection>
<nextsent>referring expressions (res) involving relations,in particular, have received increasing attention recently; especially in the context of spatial referring expressions in situated generation (e.g.
</nextsent>
<nextsent>(kelle her and kruijff, 2006)), <papid> P06-1131 </papid>where it seems particularly natural to use expressions such as the book on the table?.</nextsent>
<nextsent>however, the classical algorithm by dale and haddock (1991) <papid> E91-1028 </papid>was recently shown to be unable to generate satisfying resin practice (viethen anddale, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2402">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>building upon dale and reiters work (dale, 1989; <papid> P89-1009 </papid>dale and reiter, 1995), various researchers have added extensions such as reference to sets (stone, 2000), <papid> W00-1416 </papid>more expressive logical connectives (van deemter, 2002), and relational expressions (dale and haddock, 1991).<papid> E91-1028 </papid></prevsent>
<prevsent>referring expressions (res) involving relations,in particular, have received increasing attention recently; especially in the context of spatial referring expressions in situated generation (e.g.</prevsent>
</prevsection>
<citsent citstr=" P06-1131 ">
(kelle her and kruijff, 2006)), <papid> P06-1131 </papid>where it seems particularly natural to use expressions such as the book on the table?.</citsent>
<aftsection>
<nextsent>however, the classical algorithm by dale and haddock (1991) <papid> E91-1028 </papid>was recently shown to be unable to generate satisfying resin practice (viethen anddale, 2006).</nextsent>
<nextsent>furthermore, the dale and haddock algorithm and most of its successors (such as (kelleher and kruijff, 2006)) <papid> P06-1131 </papid>are vulnerable to the problem of infinite regress?, where the algorithm jumps back and forth between generating descriptions for two related individuals infinitely, as in the book on the table which supports book on the table . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2409">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the dale and haddock algorithm and most of its successors (such as (kelleher and kruijff, 2006)) <papid> P06-1131 </papid>are vulnerable to the problem of infinite regress?, where the algorithm jumps back and forth between generating descriptions for two related individuals infinitely, as in the book on the table which supports book on the table . . .</prevsent>
<prevsent>in this paper, we propose to view gre as the problem of computing formula of description logic (dl) that denotes exactly the set of individuals that we want to refer to.</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
this very natural idea has been mentioned in passing before (krahmer et al , 2003; <papid> J03-1003 </papid>gardent and striegnitz, 2007); however, we take it one step further by proposing dl as an interlingua for comparing theres produced by different approaches to gre.</citsent>
<aftsection>
<nextsent>in this way, we can organize existing gre approaches in an expressiveness hierarchy.
</nextsent>
<nextsent>for instance, the classical dale and reiter algorithms compute purely conjunctive formulas; van deemter (2002) extends this language by adding the other propositional connectives, whereas dale and haddock (1991) <papid> E91-1028 </papid>extends it by allowing existential quantification.</nextsent>
<nextsent>furthermore, the view of gre as problem of computing dl formulas with given extension allows us to apply existing algorithms for the latter problem to obtain efficient algorithms for gre.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2425">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> generating referring expressions.  </section>
<citcontext>
<prevsection>
<prevsent>we will further pursue the idea of organizing gre approaches with respect to the variant of dl they use in section 5.
</prevsent>
<prevsent>for the rest of this paper, we assume that we are generating singular re, i.e., the target set will be singleton.
</prevsent>
</prevsection>
<citsent citstr=" W98-1419 ">
in this case, we will only be able to generate formula that denotes exactly = {a} (i.e., re that uniquely refers to a) if there is no 43 f1 floor 2 table 1 table 2 2 bowl cup 1 bowl 1 cup on on on on in in (a) (b) 1 rabbit 2 rabbit 3 rabbit 4 rabbith 1 hat 4 hat 2 hat 3 hat 1 flower 2 flower 1 bathtub in in in figure 1: (a) the dale and haddock (1991) <papid> E91-1028 </papid>scenario; (b) the stone and webber (1998) <papid> W98-1419 </papid>scenario.</citsent>
<aftsection>
<nextsent>other individual to which is similar; otherwise, any formula that is satisfied by is also satisfied by b. conversely, if we know that is not similar to any other individual, then there is formula that is satisfied by and not by anything else; this formula can serve as unique singular re.
</nextsent>
<nextsent>in other words, we can reduce the l-gre problem forgiven model to the problem of computing the l-similarity sets of this model.
</nextsent>
<nextsent>notice that this use of similarity sets can be seen as generalization of van deemters (2002) satellite sets?
</nextsent>
<nextsent>to relational descriptions.in the rest of this section, we will present algorithms that compute the similarity sets of given model for alc andel, together with characteristic formulas that denote them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2429">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>thus we consider the formulas computed by the el algorithm safer?
</prevsent>
<prevsent>with respect to realization.
</prevsent>
</prevsection>
<citsent citstr=" P97-1027 ">
of course, we share the problem of interfacing gre and realization with every other approach that separates these two modules, i.e., almost the entire gre literature (notable exceptions are, e.g., horacek (1997) <papid> P97-1027 </papid>and spud (stone and webber, 1998)).<papid> W98-1419 </papid></citsent>
<aftsection>
<nextsent>0 100 200 300 400 10 20 30 40 50 60 70 80 90 100 el alc figure 4: average run times (in ms) of the two algorithms on random models with different numbers of individuals.
</nextsent>
<nextsent>in principle, we believe that it is good idea to handle sentence planning and realization in single module; for instance, spud can use its awareness of the syntactic context to generate succinct res as in take the rabbit from the hat?.
</nextsent>
<nextsent>we hope that the ideas we have explored here for efficient and expressive regeneration can eventually be combined with recent efficient algorithms for integrated sentence planning and realization, such as in koller and stone (2007).<papid> P07-1043 </papid></nextsent>
<nextsent>one problem that arises in our approach is that 47 both algorithms derive some measure of efficiency from their freedom to build formulas without having to respect any linguistic constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2431">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>0 100 200 300 400 10 20 30 40 50 60 70 80 90 100 el alc figure 4: average run times (in ms) of the two algorithms on random models with different numbers of individuals.
</prevsent>
<prevsent>in principle, we believe that it is good idea to handle sentence planning and realization in single module; for instance, spud can use its awareness of the syntactic context to generate succinct res as in take the rabbit from the hat?.
</prevsent>
</prevsection>
<citsent citstr=" P07-1043 ">
we hope that the ideas we have explored here for efficient and expressive regeneration can eventually be combined with recent efficient algorithms for integrated sentence planning and realization, such as in koller and stone (2007).<papid> P07-1043 </papid></citsent>
<aftsection>
<nextsent>one problem that arises in our approach is that 47 both algorithms derive some measure of efficiency from their freedom to build formulas without having to respect any linguistic constraints.
</nextsent>
<nextsent>it seems straightforward, for instance, to extend krahmer etal.s (2003) approach such that it only considers subgraphs that can actually be realized, because their algorithm proceeds by genuine search for uniquely identifying subgraphs, and will simply take different branch of the search if some subgraph is useless.
</nextsent>
<nextsent>this would be harder in our case.
</nextsent>
<nextsent>our algorithms dont search in the same way; if we disallow certain refinements of partition, we have to allow the algorithms to backtrack and thus jeopardize the worst case polynomial runtime.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2432">
<title id=" W08-1107.xml">referring expressions as formulas of description logic </title>
<section> a unified perspective on gre </section>
<citcontext>
<prevsection>
<prevsent>5, along with the dl fragment they use.
</prevsent>
<prevsent>we already discussed some of these approaches in section 3.
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
furthermore, the non-relational but negative and disjunctive descriptions generated by van deemter (2002) are simply formulas of pl; and gardent (2002) <papid> P02-1013 </papid>generalizes this into generating formulas of elu (?), i.e., el plus disjunction and atomic negation.</citsent>
<aftsection>
<nextsent>the approach presented here fit swell into this landscape, and it completes the picture by showing how to generate res inalc, which combines all connectives used in any of these previous approaches.
</nextsent>
<nextsent>where our approach breaks new ground is in the way these formulas are computed: it successively refines decomposition of the domain into subsets.in this way, it is reminiscent of the incremental algorithm, which in fact can be seen as special case of the el algorithm.
</nextsent>
<nextsent>however, unlike dale and haddock (1991) <papid> E91-1028 </papid>and its successors, such as kelleher and kruijff (2006), <papid> P06-1131 </papid>we do not have to take special precautions to avoid infinite regress.</nextsent>
<nextsent>while dale and had docks algorithm attempts to generate re for single individual, for successive individuals in the model, our algorithms consider all individuals in gre algorithm dl variant dale and reiter (1995) cl van deemter (2002) pl dale and haddock (1991) <papid> E91-1028 </papid>el kelleher and kruijff (2006) <papid> P06-1131 </papid>el gardent (2002) <papid> P02-1013 </papid>elu (?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2444">
<title id=" W08-1104.xml">using spatial reference frames to generate grounded textual summaries of geo referenced data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data-to-text systems are nlg systems that generate texts from raw input data.
</prevsent>
<prevsent>many examples of such systems have been reported in the literature, which have been applied in number of domains and to different types of input.
</prevsent>
</prevsection>
<citsent citstr=" I05-5005 ">
for example, baby talk (portet et al, 2007) generates medical reports from sensors monitoring baby in neonatal intensive care unit, while (hallett and scott, 2005) <papid> I05-5005 </papid>describe system for generating reports from events in medical records.</citsent>
<aftsection>
<nextsent>sumtime (reiter et al, 2005), (coch, 1998) and fog (goldberg et al, 1994) generate weather forecasts from the output of weather computer simulation models, while (iordanskaja et al, 1992) <papid> C92-3158 </papid>and(rosner, 1987) both generate summaries from employment statistics.as the above examples show most work in data-to text up to now has concentrated almost exclusively on time series data.</nextsent>
<nextsent>work on generating text from spatial data has been reported in coral (dale et al, 2005), which generates route descriptions of path constructed from geographical information systems (gis) datasets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2445">
<title id=" W08-1104.xml">using spatial reference frames to generate grounded textual summaries of geo referenced data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many examples of such systems have been reported in the literature, which have been applied in number of domains and to different types of input.
</prevsent>
<prevsent>for example, baby talk (portet et al, 2007) generates medical reports from sensors monitoring baby in neonatal intensive care unit, while (hallett and scott, 2005) <papid> I05-5005 </papid>describe system for generating reports from events in medical records.</prevsent>
</prevsection>
<citsent citstr=" C92-3158 ">
sumtime (reiter et al, 2005), (coch, 1998) and fog (goldberg et al, 1994) generate weather forecasts from the output of weather computer simulation models, while (iordanskaja et al, 1992) <papid> C92-3158 </papid>and(rosner, 1987) both generate summaries from employment statistics.as the above examples show most work in data-to text up to now has concentrated almost exclusively on time series data.</citsent>
<aftsection>
<nextsent>work on generating text from spatial data has been reported in coral (dale et al, 2005), which generates route descriptions of path constructed from geographical information systems (gis) datasets.
</nextsent>
<nextsent>unlike the input to coral however, most geo referenced data contains only limited spatialinformation(in many cases, only latitude and longi tude).
</nextsent>
<nextsent>as (roy and reiter, 2005) point out, connecting language to the non-linguistic world is an important issue in cognitive science and aritificial intelligence; moreover, geographic data is becoming increasingly ubiquitous as the availability of low cost locational devices such as gps increases, and gis become more user friendly.
</nextsent>
<nextsent>therefore, we believe exploring the issue of generating textual reports grounded in real world geographical data is an important challenge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2446">
<title id=" W08-1104.xml">using spatial reference frames to generate grounded textual summaries of geo referenced data </title>
<section> population e.g. e.g. roads through the urban.  </section>
<citcontext>
<prevsection>
<prevsent>the basic events are generated by data analysis which are then abstracted into higher level concepts by data interpretation.
</prevsent>
<prevsent>as it is impossible to include all these events in such short summary our system also generates table as well as text shown in figure 5.
</prevsent>
</prevsection>
<citsent citstr=" W01-0802 ">
in our ka studies we have found experts use qualitative overview of weather conditions when writing forecasts to perform this task, confirming similar observations reported in (sripada et al, 2001).<papid> W01-0802 </papid></citsent>
<aftsection>
<nextsent>we take the same approach as experts in our system by including the internal information of the table (generated by the data analysis mod ule) as input to document planning.
</nextsent>
<nextsent>this serves asthe overview for content selection and allows construction of an initial document plan consisting of overview event leaf nodes.
</nextsent>
<nextsent>an example of this structure for the system output shown in figure 5 is given in figure 6.
</nextsent>
<nextsent>each overview event corresponds to column (or columns in the case of snow and rain) inthe table if the column indicates significant threshold for the parameter it describes (i.e. yes for ice).figure 6: overview event tree for the text output in figure 5 19 figure 5: example system output with text and partial table the next stage is to construct messages from the leaf nodes of the document plan.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2447">
<title id=" W08-1104.xml">using spatial reference frames to generate grounded textual summaries of geo referenced data </title>
<section> population e.g. e.g. roads through the urban.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 generating spatial references to.
</prevsent>
<prevsent>geographic areas approaches to reg to date have concentrated on distinguishing descriptions (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W06-1408 ">
(gatt and van deemter, 2007),(van deemter, 2006),(horacek, 2006),(<papid> W06-1408 </papid>krahmer et al, 2003),(<papid> J03-1003 </papid>dale and reiter, 1995); more specifically that is given domain, they look to generate description of target object that uniquely distinguishes it from all other objects within that domain.</citsent>
<aftsection>
<nextsent>in large geographic environment such as road network consisting of 1000s of points, where the task is to refer to an event occurring at asmall subset of those points, it is impractical (gen erated descriptions may be long and complex) and prohibitively expensive (large numbers of spatial relations between objects may have to be computed) to take this approach.
</nextsent>
<nextsent>a more practical approach is to generate spatial descriptions in terms of regions that are not strictly distinguishing (i.e. urban areas, high ground) rather than in terms of the points contained within that region.
</nextsent>
<nextsent>indeed, this is the strategy employed by human authors in our corpus.
</nextsent>
<nextsent>therefore, in description such as road surface temperatures will fall below zero in some places in the south west?, dis tractors can be defined as the set of points within the southwestern boundary that do not satisfy this premise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2448">
<title id=" W08-1104.xml">using spatial reference frames to generate grounded textual summaries of geo referenced data </title>
<section> population e.g. e.g. roads through the urban.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 generating spatial references to.
</prevsent>
<prevsent>geographic areas approaches to reg to date have concentrated on distinguishing descriptions (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
(gatt and van deemter, 2007),(van deemter, 2006),(horacek, 2006),(<papid> W06-1408 </papid>krahmer et al, 2003),(<papid> J03-1003 </papid>dale and reiter, 1995); more specifically that is given domain, they look to generate description of target object that uniquely distinguishes it from all other objects within that domain.</citsent>
<aftsection>
<nextsent>in large geographic environment such as road network consisting of 1000s of points, where the task is to refer to an event occurring at asmall subset of those points, it is impractical (gen erated descriptions may be long and complex) and prohibitively expensive (large numbers of spatial relations between objects may have to be computed) to take this approach.
</nextsent>
<nextsent>a more practical approach is to generate spatial descriptions in terms of regions that are not strictly distinguishing (i.e. urban areas, high ground) rather than in terms of the points contained within that region.
</nextsent>
<nextsent>indeed, this is the strategy employed by human authors in our corpus.
</nextsent>
<nextsent>therefore, in description such as road surface temperatures will fall below zero in some places in the south west?, dis tractors can be defined as the set of points within the southwestern boundary that do not satisfy this premise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2449">
<title id=" W08-1104.xml">using spatial reference frames to generate grounded textual summaries of geo referenced data </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>one forecast is generated per day which is then post-edited by an on duty forecaster before it issent to the client.
</prevsent>
<prevsent>while common in machine translation post-edit evaluations are still relatively rare in nlg.
</prevsent>
</prevsection>
<citsent citstr=" W05-1615 ">
the only large scale post-edit evaluation of an nlg system to our knowledge has been reported in (sripada et al, 2005).<papid> W05-1615 </papid></citsent>
<aftsection>
<nextsent>our current evaluation is small in comparison tothat evaluation; sumtime-mousam, the system being evaluated in that work was generating 150 draft forecasts per day.
</nextsent>
<nextsent>however, it does try to address some of the problems the authors encountered during that evaluation.
</nextsent>
<nextsent>the main issue outlined by (sripada 1n.b. this example is taken from route network that is landlocked and therefore coastal proximity is not taken into account in this case.
</nextsent>
<nextsent>parameter: snow class: flurries time point: 12:00 { reference frame boundary proportion altitude 0m: 0.0 100m: 0.0 200m: 0.0 300m: 0.07 400m: 1.0 500m: 1.0 direction centralne: 0.0 centralnw: 0.0 centralse: 0.0 centralsw: 0.0 eastnortheast: 0.0 eastsoutheast: 0.0 southsoutheast: 0.0 southsouthwest: 0.18 truenortheast: 0.0 truesoutheast: 0.0 truesouthwest: 0.56 westsouthwest: 0.23 population rural: 0.02 urban: 0.0 } figure 7: example input to content selection for reg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2451">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P07-2045 ">
we present simple method for generating translations with the moses toolkit (koehnet al, 2007) <papid> P07-2045 </papid>from existing hypotheses produced by other translation engines.</citsent>
<aftsection>
<nextsent>as the structures underlying these translation engines are not known, an evaluation based strategy is applied to select systems for combination.
</nextsent>
<nextsent>the experiments show promising improvements in terms of bleu.
</nextsent>
<nextsent>with the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.
</nextsent>
<nextsent>obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches:statistical machine translation (smt) and rule based machine translation (rbmt) systems of ten have complementary characteristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2452">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.
</prevsent>
<prevsent>obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches:statistical machine translation (smt) and rule based machine translation (rbmt) systems of ten have complementary characteristics.
</prevsent>
</prevsection>
<citsent citstr=" W08-0328 ">
previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an smt decoder (eisele et al, 2008; <papid> W08-0328 </papid>chen et al, 2007), <papid> W07-0726 </papid>and confusion networks (matusov et al., 2006; <papid> E06-1005 </papid>rosti et al, 2007; <papid> P07-1040 </papid>he et al, 2008).<papid> D08-1011 </papid></citsent>
<aftsection>
<nextsent>the approach by (eisele et al, 2008) <papid> W08-0328 </papid>aimed specifically at filling lexical gaps in an smt system with information from number of rbmt systems.</nextsent>
<nextsent>the output of the rbmt engines was word-aligned with the input, yielding total ofseven phrase tables which where simply concate nated to expand the phrase table constructed from the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2453">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.
</prevsent>
<prevsent>obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches:statistical machine translation (smt) and rule based machine translation (rbmt) systems of ten have complementary characteristics.
</prevsent>
</prevsection>
<citsent citstr=" W07-0726 ">
previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an smt decoder (eisele et al, 2008; <papid> W08-0328 </papid>chen et al, 2007), <papid> W07-0726 </papid>and confusion networks (matusov et al., 2006; <papid> E06-1005 </papid>rosti et al, 2007; <papid> P07-1040 </papid>he et al, 2008).<papid> D08-1011 </papid></citsent>
<aftsection>
<nextsent>the approach by (eisele et al, 2008) <papid> W08-0328 </papid>aimed specifically at filling lexical gaps in an smt system with information from number of rbmt systems.</nextsent>
<nextsent>the output of the rbmt engines was word-aligned with the input, yielding total ofseven phrase tables which where simply concate nated to expand the phrase table constructed from the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2454">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.
</prevsent>
<prevsent>obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches:statistical machine translation (smt) and rule based machine translation (rbmt) systems of ten have complementary characteristics.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an smt decoder (eisele et al, 2008; <papid> W08-0328 </papid>chen et al, 2007), <papid> W07-0726 </papid>and confusion networks (matusov et al., 2006; <papid> E06-1005 </papid>rosti et al, 2007; <papid> P07-1040 </papid>he et al, 2008).<papid> D08-1011 </papid></citsent>
<aftsection>
<nextsent>the approach by (eisele et al, 2008) <papid> W08-0328 </papid>aimed specifically at filling lexical gaps in an smt system with information from number of rbmt systems.</nextsent>
<nextsent>the output of the rbmt engines was word-aligned with the input, yielding total ofseven phrase tables which where simply concate nated to expand the phrase table constructed from the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2455">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.
</prevsent>
<prevsent>obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches:statistical machine translation (smt) and rule based machine translation (rbmt) systems of ten have complementary characteristics.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an smt decoder (eisele et al, 2008; <papid> W08-0328 </papid>chen et al, 2007), <papid> W07-0726 </papid>and confusion networks (matusov et al., 2006; <papid> E06-1005 </papid>rosti et al, 2007; <papid> P07-1040 </papid>he et al, 2008).<papid> D08-1011 </papid></citsent>
<aftsection>
<nextsent>the approach by (eisele et al, 2008) <papid> W08-0328 </papid>aimed specifically at filling lexical gaps in an smt system with information from number of rbmt systems.</nextsent>
<nextsent>the output of the rbmt engines was word-aligned with the input, yielding total ofseven phrase tables which where simply concate nated to expand the phrase table constructed from the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2456">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.
</prevsent>
<prevsent>obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches:statistical machine translation (smt) and rule based machine translation (rbmt) systems of ten have complementary characteristics.
</prevsent>
</prevsection>
<citsent citstr=" D08-1011 ">
previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an smt decoder (eisele et al, 2008; <papid> W08-0328 </papid>chen et al, 2007), <papid> W07-0726 </papid>and confusion networks (matusov et al., 2006; <papid> E06-1005 </papid>rosti et al, 2007; <papid> P07-1040 </papid>he et al, 2008).<papid> D08-1011 </papid></citsent>
<aftsection>
<nextsent>the approach by (eisele et al, 2008) <papid> W08-0328 </papid>aimed specifically at filling lexical gaps in an smt system with information from number of rbmt systems.</nextsent>
<nextsent>the output of the rbmt engines was word-aligned with the input, yielding total ofseven phrase tables which where simply concate nated to expand the phrase table constructed from the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2478">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>our system starts processing this corpus with standard phrase-based smt setup, using the moses toolkit (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>the hypothesis corpus is first tokenized and lowercased.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
then, we run giza++ (och andney, 2003) <papid> J03-1002 </papid>on the corpus to obtain word alignments in both directions.</citsent>
<aftsection>
<nextsent>the phrases are extracted from the intersection of the alignments with the grow?
</nextsent>
<nextsent>heuristics.
</nextsent>
<nextsent>in addition, we also generate reordering model with the default configuration as included in the moses toolkit.
</nextsent>
<nextsent>this hypothe sis?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2479">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>our hope is that the additional translation hypotheses could bring in new phrases or, more generally, new information that was not contained in the europarl model.
</prevsent>
<prevsent>in order to facilitate comparisons, we use in-domain lms for all setups.we investigate two alternative ways of integrating the additional phrases into the existing smt system: one is to take the hypothesis translation model described in section 3.1, the other is to construct system-specific models constructed with only translations from one system at time.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
although the moses decoder is able to work with two phrase tables at once (koehn and schroeder, 2007), <papid> W07-0733 </papid>it is difficult to use this method when there is more than one additional model.</citsent>
<aftsection>
<nextsent>the method requires tuning on at least six more features, which expands the search space for the translation task unnecessarily.
</nextsent>
<nextsent>we instead integrate the translation models from multiple sources by extending the phrase table.
</nextsent>
<nextsent>in contrast to the prior approach presented in (chen et al, 2007) <papid> W07-0726 </papid>and (eisele et al, 2008) <papid> W08-0328 </papid>which concatenates the phrase tables and adds new features as system markers, our extension method avoids duplicate entries in the final combined table.</nextsent>
<nextsent>given set of hypothesis translation models(derived from an arbitrary number of system out puts) and an original large translation model to be improved, we first sort the models by quality (see section 3.3), always assigning the highest priority to the original model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2486">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>lastly, we add new features(in the form of additional columns in the phrase ta ble) to the translation model to indicate each pairs origin.
</prevsent>
<prevsent>3.3 system evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
since both the system translations and the reference translations are available for the tuning 43 set, we first compare each output to the reference translation using bleu (papineni et al, 2001) and meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and combined scoring scheme provided by the ulctoolkit (gimenez and marquez, 2008).</citsent>
<aftsection>
<nextsent>in our experiments, we selected subset of 5 systems for the combination, in most cases, based on bleu.on the other hand, some systems may be designed in way that they deliver interesting unique translation segments.
</nextsent>
<nextsent>therefore, we also measure the similarity among system outputs as shown intable 2 in given collection by calculating average similarity scores across every pair of outputs.
</nextsent>
<nextsent>de-en fr-en es-en en-de en-fr en-es num.
</nextsent>
<nextsent>20 23 28 15 16 9 median 19.87 26.55 22.50 13.78 24.76 23.70 range 16.37 17.06 9.74 4.75 11.05 13.94 top 5 de-en fr-en es-en en-de en-fr en-es median 22.26 27.93 26.43 15.21 26.62 26.61 range 4.31 4.76 5.71 1.71 0.68 5.56 table 1: statistics of system outputs?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2487">
<title id=" W09-0405.xml">combining multiengine translations with moses </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>3.5 tuning.
</prevsent>
<prevsent>after building the models, it is essential to tune the smt system to optimize the feature weights.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we use minimal error rate training (och, 2003) <papid> P03-1021 </papid>to maximize bleu on the complete development data.</citsent>
<aftsection>
<nextsent>unlike the standard tuning procedure, we donot tune the final system directly.
</nextsent>
<nextsent>instead, we obtain the weights using models built from the tuning portion of the system outputs.
</nextsent>
<nextsent>for each combination variant, we first train models on the provided outputs corresponding tothe tuning set.
</nextsent>
<nextsent>this system, called the tuning system, is also tuned on the tuning set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2488">
<title id=" W08-2124.xml">a joint model for parsing syntactic and semantic dependencies </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper describes system that jointly parses syntactic and semantic dependencies, presented at the conll-2008 shared task (surdeanu et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
it combines online peceptron learning (collins, 2002) <papid> W02-1001 </papid>with parsing model based on the eisner algorithm (eisner, 1996), <papid> C96-1058 </papid>extended so asto jointly assign syntactic and semantic la bels.</citsent>
<aftsection>
<nextsent>overall results are 78.11 global 1 , 85.84 las, 70.35 semantic 1.
</nextsent>
<nextsent>official results for the shared task (63.29 global 1 ; 71.95 las; 54.52 semantic 1) were significantly lower due to bugs present at submission time.
</nextsent>
<nextsent>the main goal of this work was to construct joint learning architecture for syntactic-semantic parsing and to test whether the syntactic and semantic layers can benefit each other from the global training and inference.
</nextsent>
<nextsent>all the components of our system were built from scratch for this shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2490">
<title id=" W08-2124.xml">a joint model for parsing syntactic and semantic dependencies </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper describes system that jointly parses syntactic and semantic dependencies, presented at the conll-2008 shared task (surdeanu et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
it combines online peceptron learning (collins, 2002) <papid> W02-1001 </papid>with parsing model based on the eisner algorithm (eisner, 1996), <papid> C96-1058 </papid>extended so asto jointly assign syntactic and semantic la bels.</citsent>
<aftsection>
<nextsent>overall results are 78.11 global 1 , 85.84 las, 70.35 semantic 1.
</nextsent>
<nextsent>official results for the shared task (63.29 global 1 ; 71.95 las; 54.52 semantic 1) were significantly lower due to bugs present at submission time.
</nextsent>
<nextsent>the main goal of this work was to construct joint learning architecture for syntactic-semantic parsing and to test whether the syntactic and semantic layers can benefit each other from the global training and inference.
</nextsent>
<nextsent>all the components of our system were built from scratch for this shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2493">
<title id=" W08-2124.xml">a joint model for parsing syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all the components of our system were built from scratch for this shared task.
</prevsent>
<prevsent>due to strong time limitations, our design decisions were biased towards constructing simple and feasible system.our proposal is first order linear model that relies on an online averaged perceptron for learning (collins, 2002) <papid> W02-1001 </papid>and an extended eisner algorithm for the joint parsing inference.</prevsent>
</prevsection>
<citsent citstr=" W06-2925 ">
systems based on eisner algorithm (carreras et al., 2006; <papid> W06-2925 </papid>carreras, 2007) <papid> D07-1101 </papid>showed competitive performance in the syntactic parsing of the english language in some past conll shared tasks.</citsent>
<aftsection>
<nextsent>also, ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>we believe that extending the eisner algorithm to jointly parse syntactic and semantic dependencies it is natural step to follow.note that syntactic and semantic tasks are related but not identical.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2494">
<title id=" W08-2124.xml">a joint model for parsing syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all the components of our system were built from scratch for this shared task.
</prevsent>
<prevsent>due to strong time limitations, our design decisions were biased towards constructing simple and feasible system.our proposal is first order linear model that relies on an online averaged perceptron for learning (collins, 2002) <papid> W02-1001 </papid>and an extended eisner algorithm for the joint parsing inference.</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
systems based on eisner algorithm (carreras et al., 2006; <papid> W06-2925 </papid>carreras, 2007) <papid> D07-1101 </papid>showed competitive performance in the syntactic parsing of the english language in some past conll shared tasks.</citsent>
<aftsection>
<nextsent>also, ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>we believe that extending the eisner algorithm to jointly parse syntactic and semantic dependencies it is natural step to follow.note that syntactic and semantic tasks are related but not identical.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2495">
<title id=" W08-2124.xml">a joint model for parsing syntactic and semantic dependencies </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 preprocessing and feature extraction.
</prevsent>
<prevsent>all features in our system are calculated in the preprocessing phase.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
we use the features described in mcdonald et al (2005) <papid> P05-1012 </papid>and carreras et al(2006) <papid> W06-2925 </papid>as input for the syntactic parsing phase, except for the dynamic features from carreras et al (2006).<papid> W06-2925 </papid></citsent>
<aftsection>
<nextsent>the joint syntactic-semantic parser uses all the previous features and also specific features for semantic parsing from xue and palmer (2004) and surdeanu et al (2007).
</nextsent>
<nextsent>the features have been straightforwardly adapted to the dependency structure used in this shared task, by substituting any reference to syntactic constituent by the head of that constituent.
</nextsent>
<nextsent>about 5m features were extracted from the training corpus.
</nextsent>
<nextsent>the number of features was reduced to 222k using frequency threshold filter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2498">
<title id=" W08-2124.xml">a joint model for parsing syntactic and semantic dependencies </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>a simple post process assigns the most frequent sense to each identified predicate.
</prevsent>
<prevsent>frequencies were computed from the training corpus.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
experiments performed combining the best and second output of the joint parser and enforcing do main constraints via ilp (punyakanok et al, 2004) <papid> C04-1197 </papid>showed no significant improvements.</citsent>
<aftsection>
<nextsent>all the experiments reported here were done using the full training corpus, and results are presented on the development set.
</nextsent>
<nextsent>the number of features used by the syntactic parser is 177k.
</nextsent>
<nextsent>the joint parser uses45k additional features for recognizing semantic dependencies.
</nextsent>
<nextsent>figure 2 shows the learning curves from epoch 1 to 17 for several subsystems and variants.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2499">
<title id=" W08-2128.xml">a combined memory based semantic role labeler of english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems use different types of constituent syntax (shallow parsing, full parsing).
</prevsent>
<prevsent>we are aware of two systems that perform semantic role labeling based on dependency syntax previous to the conll-2008 shared task.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
hacioglu (2004) <papid> C04-1186 </papid>converts the data from the conll-2004 shared task into dependency trees and uses support vectormachines.</citsent>
<aftsection>
<nextsent>morante (2008) describes memory based semantic role labeling system for spanish based on gold standard dependency syntax.
</nextsent>
<nextsent>we developed memory-based system for the conll-2008 shared task in order to evaluate the performance of this methodology incompletely new semantic role labeling setting.
</nextsent>
<nextsent>the paper is organised as follows.
</nextsent>
<nextsent>in section 2the system is described, section 3 contains an analysis of the results, and section 4 puts forward some 208 conclusions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2500">
<title id=" W08-2128.xml">a combined memory based semantic role labeler of english </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the metric combines per-feature value distance metric with global feature weights that account for relative differences in discriminative power of the features.
</prevsent>
<prevsent>2.1 syntactic dependencies.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
the malt parser 0.4 1 (nivre, 2006; nivre et al, 2007) is an inductive dependency parser that uses four essential components: deterministic algorithm for building labeled projective dependencygraphs; history-based feature models for predicting the next parser action; support vector machines for mapping histories to parser actions;and graph transformations for recovering non projective structures.the learner type used was support vector machines, with the same parameter options reported by (nivre et al, 2006).<papid> W06-2933 </papid></citsent>
<aftsection>
<nextsent>the parser algorithm used was nivre, with the options and model (eng.par) for english as specified on http://w3.msi.vxu.se/users/jha/conll07/.
</nextsent>
<nextsent>thetagset.pos, tagset.cpos and tagset.dep were extracted from the training corpus.
</nextsent>
<nextsent>2.2 semantic dependencies.
</nextsent>
<nextsent>the semantics task consists of finding the predicates, assigning propbank or nombank frameto them and extracting their semantic role dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2501">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore we focus on improving performance for each subproblem: dependency parsing and semantic role labeling.
</prevsent>
<prevsent>in the past few years, research investigating higher-order dependency parsing algorithms has found its superiority to first-order parsing algorithms.
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
to reap the benefits of these advances, weuse higher-order projective dependency parsing algorithm (carreras, 2007) <papid> D07-1101 </papid>which is an extension of the span-based parsing algorithm (eisner, 1996), <papid> C96-1058 </papid>for syntactic dependency parsing.</citsent>
<aftsection>
<nextsent>in terms of semantic role labeling, we would like to capture global information about predicate argument structures in order to accurately predict the correct predicate-argument structure.
</nextsent>
<nextsent>previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></nextsent>
<nextsent>we explore different approach to deal with such information using global features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2502">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore we focus on improving performance for each subproblem: dependency parsing and semantic role labeling.
</prevsent>
<prevsent>in the past few years, research investigating higher-order dependency parsing algorithms has found its superiority to first-order parsing algorithms.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
to reap the benefits of these advances, weuse higher-order projective dependency parsing algorithm (carreras, 2007) <papid> D07-1101 </papid>which is an extension of the span-based parsing algorithm (eisner, 1996), <papid> C96-1058 </papid>for syntactic dependency parsing.</citsent>
<aftsection>
<nextsent>in terms of semantic role labeling, we would like to capture global information about predicate argument structures in order to accurately predict the correct predicate-argument structure.
</nextsent>
<nextsent>previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></nextsent>
<nextsent>we explore different approach to deal with such information using global features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2503">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to reap the benefits of these advances, weuse higher-order projective dependency parsing algorithm (carreras, 2007) <papid> D07-1101 </papid>which is an extension of the span-based parsing algorithm (eisner, 1996), <papid> C96-1058 </papid>for syntactic dependency parsing.</prevsent>
<prevsent>in terms of semantic role labeling, we would like to capture global information about predicate argument structures in order to accurately predict the correct predicate-argument structure.</prevsent>
</prevsection>
<citsent citstr=" D08-1008 ">
previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></citsent>
<aftsection>
<nextsent>we explore different approach to deal with such information using global features.
</nextsent>
<nextsent>use of global features for structured prediction problem has been explored by several nlp applications such as sequential labeling (finkel et al, 2005; <papid> P05-1045 </papid>krishnan and manning, 2006; <papid> P06-1141 </papid>kazama and torisawa, 2007) <papid> D07-1033 </papid>and dependency parsing (nakagawa, 2007) <papid> D07-1100 </papid>with agreat deal of success.</nextsent>
<nextsent>we attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2505">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></prevsent>
<prevsent>we explore different approach to deal with such information using global features.</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
use of global features for structured prediction problem has been explored by several nlp applications such as sequential labeling (finkel et al, 2005; <papid> P05-1045 </papid>krishnan and manning, 2006; <papid> P06-1141 </papid>kazama and torisawa, 2007) <papid> D07-1033 </papid>and dependency parsing (nakagawa, 2007) <papid> D07-1100 </papid>with agreat deal of success.</citsent>
<aftsection>
<nextsent>we attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.
</nextsent>
<nextsent>we present an approximate max-margin learning algorithm for argument classifiers with global features.
</nextsent>
<nextsent>as in previous work, we use linear model forde pendency parsing.
</nextsent>
<nextsent>the score function used in our dependency parser is defined as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2506">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></prevsent>
<prevsent>we explore different approach to deal with such information using global features.</prevsent>
</prevsection>
<citsent citstr=" P06-1141 ">
use of global features for structured prediction problem has been explored by several nlp applications such as sequential labeling (finkel et al, 2005; <papid> P05-1045 </papid>krishnan and manning, 2006; <papid> P06-1141 </papid>kazama and torisawa, 2007) <papid> D07-1033 </papid>and dependency parsing (nakagawa, 2007) <papid> D07-1100 </papid>with agreat deal of success.</citsent>
<aftsection>
<nextsent>we attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.
</nextsent>
<nextsent>we present an approximate max-margin learning algorithm for argument classifiers with global features.
</nextsent>
<nextsent>as in previous work, we use linear model forde pendency parsing.
</nextsent>
<nextsent>the score function used in our dependency parser is defined as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2507">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></prevsent>
<prevsent>we explore different approach to deal with such information using global features.</prevsent>
</prevsection>
<citsent citstr=" D07-1033 ">
use of global features for structured prediction problem has been explored by several nlp applications such as sequential labeling (finkel et al, 2005; <papid> P05-1045 </papid>krishnan and manning, 2006; <papid> P06-1141 </papid>kazama and torisawa, 2007) <papid> D07-1033 </papid>and dependency parsing (nakagawa, 2007) <papid> D07-1100 </papid>with agreat deal of success.</citsent>
<aftsection>
<nextsent>we attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.
</nextsent>
<nextsent>we present an approximate max-margin learning algorithm for argument classifiers with global features.
</nextsent>
<nextsent>as in previous work, we use linear model forde pendency parsing.
</nextsent>
<nextsent>the score function used in our dependency parser is defined as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2508">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous research dealt with such information using re-ranking (toutanova et al, 2005; johansson and nugues, 2008).<papid> D08-1008 </papid></prevsent>
<prevsent>we explore different approach to deal with such information using global features.</prevsent>
</prevsection>
<citsent citstr=" D07-1100 ">
use of global features for structured prediction problem has been explored by several nlp applications such as sequential labeling (finkel et al, 2005; <papid> P05-1045 </papid>krishnan and manning, 2006; <papid> P06-1141 </papid>kazama and torisawa, 2007) <papid> D07-1033 </papid>and dependency parsing (nakagawa, 2007) <papid> D07-1100 </papid>with agreat deal of success.</citsent>
<aftsection>
<nextsent>we attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.
</nextsent>
<nextsent>we present an approximate max-margin learning algorithm for argument classifiers with global features.
</nextsent>
<nextsent>as in previous work, we use linear model forde pendency parsing.
</nextsent>
<nextsent>the score function used in our dependency parser is defined as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2511">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>as the number of incorrect head predictions in the y?, and as 1.0.
</prevsent>
<prevsent>among the 7 languages of the task, 4 languages (czech, english, german and japanese) contain non-projective edges (13.94 %, 3.74 %, 25.79 % and 0.91 % respectively), therefore we need to deal with non-projectivity.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
in order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (nivre and nilsson, 2005).<papid> P05-1013 </papid></citsent>
<aftsection>
<nextsent>however, growth of the number of dependency labels by pseudo-projective transformation increases the dependency parser training time, so we did not adopt transformations.
</nextsent>
<nextsent>therefore, the parser ignores the presence of non-projective edges in the training and the testing phases.
</nextsent>
<nextsent>the features used for our dependency parser are based on those listed in (johansson, 2008).
</nextsent>
<nextsent>in addition, distance features are used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2515">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>however in contrast to re-ranking, we only have to prepare one model.
</prevsent>
<prevsent>the re-ranking approach requires other training datasets that are different from the data used in local model training.
</prevsent>
</prevsection>
<citsent citstr=" W08-2132 ">
3.2.2 features for argument classification the local features used in our system are the same as our previous work (watanabe et al, 2008) <papid> W08-2132 </papid>except for language dependent features.</citsent>
<aftsection>
<nextsent>the global features that used in our system are based on (johansson and nugues, 2008) <papid> D08-1008 </papid>that used for re-ranking.</nextsent>
<nextsent>local features word features: predicted lemma and predicted pos of the predicate, predicates head, argument candidate,argument candidates head, leftmost/rightmost dependent and leftmost/rightmost sibling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2520">
<title id=" W09-1218.xml">multilingual syntactic semantic dependency parsing with three stage approximate max margin linear models </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we believe that there is still room for improvements since we used only two types of global features for the argument classifier.
</prevsent>
<prevsent>another research direction is investigating joint approaches.
</prevsent>
</prevsection>
<citsent citstr=" W08-2122 ">
to the best of our knowledge, three 118 types of joint approaches have been proposed: n-best based approach (johansson and nugues, 2008), <papid> D08-1008 </papid>synchronous joint approach (henderson et al., 2008), <papid> W08-2122 </papid>and joint approach where parsing and srl are performed simultaneously (llus andma`rquez, 2008).</citsent>
<aftsection>
<nextsent>we attempted to perform nbest based joint approach, however, the expensive computational cost of the 2nd-order projective parser discouraged it.
</nextsent>
<nextsent>we would like to investigate syntactic-semantic joint approaches with reasonable time complexities.
</nextsent>
<nextsent>acknowledgments we would like to thank richard johansson for his advice on parser implementation, and the conll 2009 organizers (hajic?
</nextsent>
<nextsent>et al, 2009; taule?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2521">
<title id=" W09-0209.xml">svd feature selection for probabilistic taxonomy learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>taxonomies are extremely important knowledge repositories in variety of applications for natural language processing and knowledge representation.
</prevsent>
<prevsent>yet, manually built taxonomies suchas wordnet (miller, 1995) often lack in cover age when used in specific knowledge domains.
</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
automatically creating or extending taxonomies for specific domains is then very interesting area of research (osullivan et al, 1995; magnini and speranza, 2001; snow et al, 2006).<papid> P06-1101 </papid></citsent>
<aftsection>
<nextsent>automatic methods for learning taxonomies from corpora often use distributional hypothesis (harris, 1964) and exploit some induced lexical-syntactic patterns (hearst, 1992; <papid> C92-2082 </papid>pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></nextsent>
<nextsent>in these models, within very large set, candidate word pairs are selected as new word pairs in hyperonymy and added to an existing tax onomy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2524">
<title id=" W09-0209.xml">svd feature selection for probabilistic taxonomy learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>yet, manually built taxonomies suchas wordnet (miller, 1995) often lack in cover age when used in specific knowledge domains.
</prevsent>
<prevsent>automatically creating or extending taxonomies for specific domains is then very interesting area of research (osullivan et al, 1995; magnini and speranza, 2001; snow et al, 2006).<papid> P06-1101 </papid></prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
automatic methods for learning taxonomies from corpora often use distributional hypothesis (harris, 1964) and exploit some induced lexical-syntactic patterns (hearst, 1992; <papid> C92-2082 </papid>pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></citsent>
<aftsection>
<nextsent>in these models, within very large set, candidate word pairs are selected as new word pairs in hyperonymy and added to an existing taxonomy.
</nextsent>
<nextsent>candidate pairs are represented in some feature space.
</nextsent>
<nextsent>often, these feature spaces arehuge and, then, models may take into consideration noisy features.
</nextsent>
<nextsent>in machine learning, feature selection has been often used to reduce the dimensions in huge feature spaces.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2525">
<title id=" W09-0209.xml">svd feature selection for probabilistic taxonomy learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>yet, manually built taxonomies suchas wordnet (miller, 1995) often lack in cover age when used in specific knowledge domains.
</prevsent>
<prevsent>automatically creating or extending taxonomies for specific domains is then very interesting area of research (osullivan et al, 1995; magnini and speranza, 2001; snow et al, 2006).<papid> P06-1101 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
automatic methods for learning taxonomies from corpora often use distributional hypothesis (harris, 1964) and exploit some induced lexical-syntactic patterns (hearst, 1992; <papid> C92-2082 </papid>pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></citsent>
<aftsection>
<nextsent>in these models, within very large set, candidate word pairs are selected as new word pairs in hyperonymy and added to an existing taxonomy.
</nextsent>
<nextsent>candidate pairs are represented in some feature space.
</nextsent>
<nextsent>often, these feature spaces arehuge and, then, models may take into consideration noisy features.
</nextsent>
<nextsent>in machine learning, feature selection has been often used to reduce the dimensions in huge feature spaces.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2544">
<title id=" W09-0209.xml">svd feature selection for probabilistic taxonomy learning </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this is web extracted corpus of about 2700000 web pages containing more than 2 billion words.
</prevsent>
<prevsent>the corpus contains documents of different topics such as web, computers, education, public sphere, etc..
</prevsent>
</prevsection>
<citsent citstr=" N04-1016 ">
it has been largely demonstrated that the web documents 1we used the version 3.0 70 concrete nouns clas sense concrete nouns clas sense 1 banana vegetable 1 23 boat artifact 0 2 bottle artifact 0 24 bowl artifact 0 3 car artifact 0 25 cat animal 0 4 cherry vegetable 2 26 chicken animal 1 5 chisel artifact 0 27 corn vegetable 2 6 cow animal 0 28 cup artifact 0 7 dog animal 0 29 duck animal 0 8 eagle animal 0 30 elephant animal 0 9 hammer artifact 1 31 helicopter artifact 0 10 kettle artifact 0 32 knife artifact 0 11 lettuce vegetable 2 33 lion animal 0 12 motorcycle artifact 0 34 mushroom vegetable 4 13 onion vegetable 2 35 owl animal 0 14 peacock animal 1 36 pear vegetable 0 15 pen artifact 0 37 pencil artifact 0 16 penguin animal 0 38 pig animal 0 17 pineapple vegetable 1 39 potato vegetable 2 18 rocket artifact 0 40 scissors artifact 0 19 screwdriver artifact 0 41 ship artifact 0 20 snail animal 0 42 spoon artifact 0 21 swan animal 0 43 telephone artifact 1 22 truck artifact 0 44 turtle animal 1 table 2: concrete nouns, classes and senses selected in wordnet are good models for natural language (lapata and keller, 2004).<papid> N04-1016 </papid></citsent>
<aftsection>
<nextsent>as the focus of the paper is the analysis of the effect of the svd feature selection, we used as feature spaces both n-grams and bag-of-words.
</nextsent>
<nextsent>out of the ? , we selected only those pairs that appeared at distance of at most 3 tokens.
</nextsent>
<nextsent>using these 3 tokens, we generated three spaces: (1) 1-gram that contains mono grams, (2) 2-gram that contains mono grams and bigrams, and (3) the 3-gram space that contains mono grams, bigrams, and trigrams.
</nextsent>
<nextsent>for the purpose of this experiment, we used reduced stop list as classical stop words as punctuation, parenthesis, the verb to be are very relevant in the context of features for learning taxonomy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2549">
<title id=" W09-0212.xml">a graph theoretic algorithm for automatic extension of translation lexicons </title>
<section> related work on cross-lingual lexical.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 reports the results.
</prevsent>
<prevsent>we present our conclusions and directions for future research in section 7.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
acquisition the work by rapp (1999) <papid> P99-1067 </papid>is driven by the idea that word and its translation to another language are likely to co-occur with similar words.given german and an english corpus, he computes two word-by-word co-occurrence matrices,one for each language, whose columns span vector space representing the corresponding corpus.in order to find the english translation of german word, he uses base dictionary to translate all known column labels to english.</citsent>
<aftsection>
<nextsent>this yields new vector representation of the german word in the english vector space.
</nextsent>
<nextsent>this mapped vector is then compared to all english word vectors, the most similar ones being candidate translations.
</nextsent>
<nextsent>91 food lebensmittel receive erhalten award preis provide liefern evidence beweis buy kaufen book buch publish verlegen boat haus waste ablehnen figure 1: likely translations based on neighboring nodes rapp reports an accuracy of 72% for small number of test words with well-defined meaning.diab and finch (2000) first compute word similarities within each language corpus separately by comparing their co-occurrence vectors.
</nextsent>
<nextsent>their challenge then is to derive mapping from one language to the other (i.e. translation lexicon)which best preserves the intra-language word similarities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2550">
<title id=" W09-0212.xml">a graph theoretic algorithm for automatic extension of translation lexicons </title>
<section> related work on cross-lingual lexical.  </section>
<citcontext>
<prevsection>
<prevsent>they test their method on two corpora written in the same language and report accuracy rates ofover 90% on this pseudo-translation task.
</prevsent>
<prevsent>the approach is attractive in that it does not require seed lexicon.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
a drawback is its high computational cost.koehn and knight (2002) <papid> W02-0902 </papid>use (linear) combination of clues for bootstrapping an english german noun translation dictionary.</citsent>
<aftsection>
<nextsent>in addition to similar assumptions as above, they consider words to be likely translations of one another if they havethe same or similar spelling and/or occur with similar frequencies.
</nextsent>
<nextsent>koehn and knight reach an accuracy of 39% on test set consisting of the 1,000 most frequent english and german nouns.
</nextsent>
<nextsent>the experiment excludes verbs whose semantics are more complex than those of nouns.otero and campos (2005) extract english spanish pairs of lexico-syntactic patterns from asmall parallel corpus.
</nextsent>
<nextsent>they then construct context vectors for all english and spanish words by recording their frequency of occurrence in each of these patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2551">
<title id=" W09-0212.xml">a graph theoretic algorithm for automatic extension of translation lexicons </title>
<section> the graph model.  </section>
<citcontext>
<prevsection>
<prevsent>the grammatical relationships were extracted from the british national corpus (bnc) (100 million words), and the huge german corpus (hgc)(180 million words of newspaper text).
</prevsent>
<prevsent>we compiled list of english verb-object (v-o) pairs based on the verb-argument information extracted by (schulte im walde, 1998) from the bnc.
</prevsent>
</prevsection>
<citsent citstr=" C04-1024 ">
the german v-o pairs were extracted from syntactic analysis of the hgc carried out using the bitpar parser (schmid, 2004).<papid> C04-1024 </papid>we used only v-o pairs because they constitute far more sense-discriminative contexts than,for example, verb-subject pairs, but we plan to examine these and other grammatical relationships in future work.</citsent>
<aftsection>
<nextsent>we reduced english compound nouns to their heads and lemmatized all data.
</nextsent>
<nextsent>in english phrasal 93 english german low mid high low mid high v v v v v v 0.313 0.228 0.253 0.288 0.253 0.255 0.232 0.247 0.205 0.237 0.211 0.205 table 1: the 12 categories of test words, with mean relative ranks of test words verbs, we attach the particles to the verbs to distinguish them from the original verb (e.g put off vs. put).
</nextsent>
<nextsent>both the english and german v-o pairs were filtered using stop lists consisting of modal and auxiliary verbs as well as pronouns.
</nextsent>
<nextsent>to reduce noise, we decided to keep only those relationships which occurred at least three times in the respective corpus.the english and german data alike are then represented as bipartite graph whose nodes divide into two sets, verbs and nouns, and whose edges are the v-o relationships which connect verbs to nouns (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2552">
<title id=" W08-1110.xml">using tactical nlg to induce affective states empirical investigations </title>
<section> conclusion and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>another option is to use an objective observer during the experiment (e.g. videotaping the participants and observing the duration of smiles or frowns) to judge whether the subject is affected.
</prevsent>
<prevsent>yet another possibility would be only to measure emotional effects via performance on task that is known to be facilitated by particular emotions.
</prevsent>
</prevsection>
<citsent citstr=" P00-1020 ">
for instance, one could use the methods of (carenini and moore, 2000) <papid> P00-1020 </papid>to measure persuasiveness of different textual realisations that may induce emotions.</citsent>
<aftsection>
<nextsent>acknowledgments this work was supported by the epsrc grant affecting people with natural language?(ep/e011764/1) and also in part by science foundation ireland under cset grant (ngl/cset).
</nextsent>
<nextsent>we would like to thank the people who contributed to this study, most notably louise phillips, emiel krahmer, linda moxey, graeme ritchie, judith masthoff, albert gatt and kees van deemter.
</nextsent>
<nextsent>75
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2553">
<title id=" W09-1203.xml">joint memory based learning of syntactic and semantic dependencies in multiple languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we present the machine learning system submitted to the conll shared task 2009 (hajicet al, 2009).
</prevsent>
<prevsent>the task is an extension to multiple languages (burchardt et al, 2006; hajic?
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
et al, 2006; kawahara et al, 2002; palmer and xue, 2009; surdeanu et al, 2008; <papid> W08-2121 </papid>taule?</citsent>
<aftsection>
<nextsent>et al, 2008) of the conll shared task 2008, combining the identification and labeling of syntactic dependencies and semantic roles.
</nextsent>
<nextsent>our system is joint-learning system tested in the closed?
</nextsent>
<nextsent>challenge, i.e. without making use of external resources.our system operates in two phases: classification phase in which three memory-based classifiers predict different types of information, and ranking phase in which the output of the classifiers is combined by ranking the predictions.
</nextsent>
<nextsent>semantic and syntactic dependencies are jointly learned and processed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2554">
<title id=" W08-2215.xml">resolving paraphrases to support modeling language perception in an intelligent agent </title>
<section> overview of and rationale for studying paraphrase.  </section>
<citcontext>
<prevsection>
<prevsent>as result, most contributions devoted to paraphrase can be described as syntactic or light semantic.?
</prevsent>
<prevsent>in some contributions, processing semantics is constrained to finding synonyms, hyponyms, etc., in manually constructed wordnet, like wordnet or any of its progeny.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
some others do not relyon manually constructed knowledge resource but, rather, aim to determine distributional clustering of similar words in corpora (see, e.g. pereira et al (1993) <papid> P93-1024 </papid>or lin (2001)).</citsent>
<aftsection>
<nextsent>a few approaches to dealing with paraphrase actually go beyond the detection and use of synonyms.
</nextsent>
<nextsent>for example, lapata (2001) seeks to interpret the meanings of contextually elastic adjectives(such as fast, which means different things in fast highway and fast eater) by semi automatically constructing paraphrases for phrases that include such adjectives.
</nextsent>
<nextsent>these paraphrases use the original noun and the adjective (or any of its synonyms, taken from hand-constructed list) in its adverbial form and add corpus-derived candidate verb intended to explain the meaning of the adjective.
</nextsent>
<nextsent>results are evaluated by human judgments of whether paraphrase (e.g., highway travel quickly) is appropriate as an explanation of the meaning of fast in fast highway.ibrahim et al (2003) pursue the more immediate goal of supporting question answering system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2555">
<title id=" W08-2215.xml">resolving paraphrases to support modeling language perception in an intelligent agent </title>
<section> overview of and rationale for studying paraphrase.  </section>
<citcontext>
<prevsection>
<prevsent>results are evaluated by human judgments of whether paraphrase (e.g., highway travel quickly) is appropriate as an explanation of the meaning of fast in fast highway.ibrahim et al (2003) pursue the more immediate goal of supporting question answering system.
</prevsent>
<prevsent>creating paraphrases for questions helps to expand the queries to the textual resources that are mined for answers.
</prevsent>
</prevsection>
<citsent citstr=" C88-1065 ">
in an early version of this system, such paraphrase rules ? which included combination of lexical and syntactic transformations ? were created by hand (katz and levin, 1988).<papid> C88-1065 </papid></citsent>
<aftsection>
<nextsent>the new approach follows the methodology of lin and pantel (2001) for dynamically determining paraphrases in corpus by measuring the similarity of paths between nodes in syntactic de resolving paraphrases to support modeling language perception 181 pendency trees.
</nextsent>
<nextsent>this method was applied to pairs of sentences from different english translations of the same text.
</nextsent>
<nextsent>(the idea of using monolingual sentence-aligned?
</nextsent>
<nextsent>corpus is due to barzilay and mckeown (2001).)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2556">
<title id=" W08-2215.xml">resolving paraphrases to support modeling language perception in an intelligent agent </title>
<section> overview of and rationale for studying paraphrase.  </section>
<citcontext>
<prevsection>
<prevsent>this system, unlike ours, works at the level of strings (not concepts), does not automatically carry out disambiguation, and cannot handle complex sentences or long spans of text.
</prevsent>
<prevsent>since paraphrase recognition, when viewed broadly, is very challenging task, some developers choose to focus on narrow application area.
</prevsent>
</prevsection>
<citsent citstr=" W03-1606 ">
one such system,reported in brun and hagge (2003), <papid> W03-1606 </papid>detects paraphrases in texts about toxic products.</citsent>
<aftsection>
<nextsent>developers hand create rules using lexical and structural information, and system output is logical structures like phys_form(acetone,liquid), which means that the physical form of acetone is liquid.
</nextsent>
<nextsent>the approach taken in this work seems very appropriate for this narrow domain of interest.
</nextsent>
<nextsent>1.2 our research methodology.
</nextsent>
<nextsent>the research methodology we adopt has the following features, which will serve to orient it in the landscape of work by others.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2557">
<title id=" W08-2215.xml">resolving paraphrases to support modeling language perception in an intelligent agent </title>
<section> paraphrase-oriented eventualities.  </section>
<citcontext>
<prevsection>
<prevsent>if one chooses to use concept that is higher in the onto logical hierarchy, one may have to add further overt constraints to the meaning representation (like the one about the instrument of the motion-event above).
</prevsent>
<prevsent>if one chooses the lower-level, narrower onto logical concept to start with, such constraints may be inherent in its definition (as is the case with aerial-motion-event).
</prevsent>
</prevsection>
<citsent citstr=" C88-2100 ">
this preference is the inverse of the lexical choice in text generation off of text meaning representations (for details see nirenburg and nirenburg, 1988).<papid> C88-2100 </papid></citsent>
<aftsection>
<nextsent>ontosem can yield either of the above basic text meaning representations.
</nextsent>
<nextsent>in many applications ? for example, in interlingua-based machine translation ? this would be quite benign.
</nextsent>
<nextsent>however, it is possible to create extended meaning representations such that the above variability is eliminated.
</nextsent>
<nextsent>the method we use for this purpose relies on the dynamic tightening or relaxation of selectional restrictions and is described in detail in mahesh et al (1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2558">
<title id=" W08-2215.xml">resolving paraphrases to support modeling language perception in an intelligent agent </title>
<section> paraphrase-oriented eventualities.  </section>
<citcontext>
<prevsection>
<prevsent>as we see from this example, world knowledge stored in the ontology is leveraged to carry out the reasoning needed to detect that the abovementioned formal structures are paraphrases.
</prevsent>
<prevsent>such situations are somewhat similar to bridging references?
</prevsent>
</prevsection>
<citsent citstr=" P04-1019 ">
in the literature devoted to reference resolution (e.g. poesio et al, 2004) <papid> P04-1019 </papid>because knowledge bridge is needed to aid in the reference resolution of the entity.</citsent>
<aftsection>
<nextsent>a common source of this type of paraphrase derives from decisions about how to build the ontology.
</nextsent>
<nextsent>ontology building is complex task with the lesser of the evils?
</nextsent>
<nextsent>decisions to be made at every turn.
</nextsent>
<nextsent>two ontologies can be equally valid and yet look quite different.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2559">
<title id=" W08-2112.xml">an incremental bayesian model for learning syntactic categories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.as on the distributional information about the contexts in which they appear.
</prevsent>
<prevsent>several computational models have been proposed that draw on one or more of the above-mentioned properties in order to group words into discrete unlabeled categories.
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
most existing models only intend to show the relevance ofsuch properties to the acquisition of adult-like syntactic categories such as nouns and verbs; hence, they do not necessarily incorporate the types of learning mechanisms used by children (schutze, 1993; redington et al, 1998; clark, 2000; <papid> W00-0717 </papid>mintz, 2003; onnis and christiansen, 2005).</citsent>
<aftsection>
<nextsent>for example, in contrast to the above models, children acquire their knowledge of syntactic categories incrementally, processing the utterances they hear one at time.
</nextsent>
<nextsent>moreover, children appear to be sensitive to the fact that syntactic categories are partially defined in terms of other categories, e.g., nouns tend to follow determiners, and can be modified by adjectives.
</nextsent>
<nextsent>we thus argue that computational model should be incremental, and should use more abstract category knowledge to help better identify syntactic categories.
</nextsent>
<nextsent>incremental processing also allows modelto incorporate its partially-learned knowledge of categories, letting the model bootstrap its development.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2561">
<title id=" W08-2112.xml">an incremental bayesian model for learning syntactic categories </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, cartwright and brent (1997) propose 95an incremental model of syntactic category acquisition that uses series of linguistic preferences to find common patterns across sentence-length templates.their model presents an important incremental algorithm which is very effective for discovering categories in artificial languages.
</prevsent>
<prevsent>however, the models reliance on templates limits its applicability to transcripts of actual spoken language data, which contain high variability and noise.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
recent models that apply bayesian approaches to pos tagging are not incremental and assume fixed number of tags (goldwater and griffiths, 2007;<papid> P07-1094 </papid>toutanova and johnson, 2008).</citsent>
<aftsection>
<nextsent>in syntactic category acquisition, the true number of categories is unknown, and must be inferred from the input.
</nextsent>
<nextsent>we have developed computational model of syntactic category acquisition in children, and demonstrated its behaviour on corpus of naturalistic child directed data.
</nextsent>
<nextsent>the model is based on domain-general properties of feature similarity, in contrast to earlier,more linguistically-specific methods.
</nextsent>
<nextsent>the incremental nature of the algorithm contributes to substantial improvement in psychological plausibility over previous models of syntactic category learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2562">
<title id=" W09-1113.xml">learning where to look modeling eye movements in reading </title>
<section> a transition-based model </section>
<citcontext>
<prevsection>
<prevsent>given such system, we can train classifier to predict the next transition given the information in the currentconfiguration.
</prevsent>
<prevsent>in order to derive complete transition sequence, we start in an initial configuration,representing the readers state before the first fixation, and repeatedly apply the transition predicted bythe classifier until we reach terminal state, representing the readers state after having read the entire text.
</prevsent>
</prevsection>
<citsent citstr=" W06-2922 ">
at an abstract level, this is essentially the same idea as in transition-based dependency parsing (ya mada and matsumoto, 2003; nivre, 2006; attardi, 2006).<papid> W06-2922 </papid></citsent>
<aftsection>
<nextsent>in the following subsections, we discuss the different components of the model in turn, including the transition system, the classifier used, the features used to represent data, and the search algorithm used to derive complete transition sequences.
</nextsent>
<nextsent>4.1 transition system.
</nextsent>
<nextsent>a transition system is an abstract machine consisting of set of configurations and transitions between 95configurations.
</nextsent>
<nextsent>a configuration in the current system is triple = (l,r, ), where1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2563">
<title id=" W09-1107.xml">a method for stopping active learning based on stabilizing predictions and the need for user adjustable stopping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the proposed method is shown to fill gap in the level of aggressiveness available for stopping aland supports providing users with control over stopping behavior.
</prevsent>
<prevsent>the use of active learning (al) to reduce nlp annotation costs has generated considerable interest recently (e.g.
</prevsent>
</prevsection>
<citsent citstr=" I08-1048 ">
(bloodgood and vijay-shanker, 2009; baldridge and osborne, 2008; zhu et al, 2008<papid> I08-1048 </papid>a)).</citsent>
<aftsection>
<nextsent>to realize the savings in annotation efforts that al enables, we must have mechanism for knowing when to stop the annotation process.figure 1 is intended to motivate the value of stopping at the right time.
</nextsent>
<nextsent>the x-axis measures the number of human annotations that have been requested and ranges from 0 to 70,000.
</nextsent>
<nextsent>the y-axis measures ? this research was conducted while the first author was phd student at the university of delaware.
</nextsent>
<nextsent>0 1 2 3 4 5 6 7 104 65 70 75 80 85 90 active learning curve (f measure vs number of annotations) number of points for which annotations have been requested pe rfo rm an ce (f ea su re) stop point 1: stops too early; results in lower performing model stop point 2: good place to stop stop point 3: stops too late; wastes around 30,000 human annotations figure 1: hypothetical active learning curve with hypothetical stopping points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2571">
<title id=" W09-1107.xml">a method for stopping active learning based on stabilizing predictions and the need for user adjustable stopping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as pointed out by (vlachos, 2008), this stopping criterion is basedon the assumption that the learner/feature representation is incapable of fully explaining all the examples.
</prevsent>
<prevsent>however, this assumption is often violated andthen the performance of the method suffers (see section 4).
</prevsent>
</prevsection>
<citsent citstr=" D07-1082 ">
two stopping criteria (max-conf and min-err) are reported in (zhu and hovy, 2007).<papid> D07-1082 </papid></citsent>
<aftsection>
<nextsent>the max-conf method indicates to stop when the confidence of the model on each unlabeled example exceeds threshold.
</nextsent>
<nextsent>in the context of margin-based methods, max conf boils down to be simply generalization of the margin exhaustion method.
</nextsent>
<nextsent>min-err, reported to be superior to max-conf, says to stop when the accuracy of the most recent model on the current batch of queried examples exceeds some threshold (they use0.9).
</nextsent>
<nextsent>zhu et al (2008<papid> I08-1048 </papid>b) proposes the use of multicriteria-based stopping to handle setting the thresh 40 old for min-err.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2582">
<title id=" W09-1107.xml">a method for stopping active learning based on stabilizing predictions and the need for user adjustable stopping </title>
<section> a method for stopping active learning </section>
<citcontext>
<prevsection>
<prevsent>a simple way to define agreement between two models would be to measure the percentage of points on which the models make the samepredictions.
</prevsent>
<prevsent>however, experimental results on separate development dataset show then that the cutoff agreement at which to stop is sensitive to the dataset being used.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
this is because different datasets have different levels of agreement that can be expected by chance and simple percent agreement doesnt adjust for this.measurement of agreement between human annotators has received significant attention and in that context, the drawbacks of using percent agreement have been recognized (artstein and poesio, 2008).<papid> J08-4004 </papid></citsent>
<aftsection>
<nextsent>alternative metrics have been proposed that take chance agreement into account.
</nextsent>
<nextsent>in (artstein andpoesio, 2008), <papid> J08-4004 </papid>survey of several agreement metrics is presented.</nextsent>
<nextsent>most of the agreement metrics are of the form: agreement = ao ? ae1 ? ae , (1)where ao = observed agreement, and ae = agreement expected by chance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2602">
<title id=" W08-1302.xml">exploring an auxiliary distribution based approach to domain adaptation of a syntactic disambiguation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern statistical parsers are trained on large annotated corpora (treebanks) and their parameters are estimated to reflect properties of the training data.
</prevsent>
<prevsent>therefore, disambiguation component will be successful as long as the treebank it was trained on is representative for the input the model gets.however, as soon as the model is applied to an other domain, or text genre (lease et al, 2006), accuracy degrades considerably.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
for example, the performance of parser trained on the wall street journal (newspaper text) significantly drops when evaluated on the more varied brown (fiction/non fiction) corpus (gildea, 2001).<papid> W01-0521 </papid></citsent>
<aftsection>
<nextsent>a simple solution to improve performance on new domain is to construct parser specifically ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.for that domain.
</nextsent>
<nextsent>however, this amounts to hand labeling considerable amount of training data which is clearly very expensive and leads to an unsatisfactory solution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2603">
<title id=" W08-1302.xml">exploring an auxiliary distribution based approach to domain adaptation of a syntactic disambiguation model </title>
<section> background: maxent models.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our approach of exploring auxiliary distributions for domain adaptation.
</prevsent>
<prevsent>in section 4 the experimental design and empirical results are presented and discussed.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
maximum entropy (maxent) models are widely used in natural language processing (berger et al., 1996; <papid> J96-1002 </papid>ratnaparkhi, 1997; abney, 1997).<papid> J97-4005 </papid></citsent>
<aftsection>
<nextsent>inthis framework, disambiguation model is speci 9fied by set of feature functions describing properties of the data, together with their associatedweights.
</nextsent>
<nextsent>the weights are learned during the training procedure so that their estimated value determines the contribution of each feature.
</nextsent>
<nextsent>in the task of parsing, features appearing in correct parses are given increasing weight, while features in incorrect parses are given decreasing weight.
</nextsent>
<nextsent>once model is trained, it can be applied to parse selection that chooses the parse with the highest sum of feature weights.during the training procedure, the weights vector is estimated to best fit the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2604">
<title id=" W08-1302.xml">exploring an auxiliary distribution based approach to domain adaptation of a syntactic disambiguation model </title>
<section> background: maxent models.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our approach of exploring auxiliary distributions for domain adaptation.
</prevsent>
<prevsent>in section 4 the experimental design and empirical results are presented and discussed.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
maximum entropy (maxent) models are widely used in natural language processing (berger et al., 1996; <papid> J96-1002 </papid>ratnaparkhi, 1997; abney, 1997).<papid> J97-4005 </papid></citsent>
<aftsection>
<nextsent>inthis framework, disambiguation model is speci 9fied by set of feature functions describing properties of the data, together with their associatedweights.
</nextsent>
<nextsent>the weights are learned during the training procedure so that their estimated value determines the contribution of each feature.
</nextsent>
<nextsent>in the task of parsing, features appearing in correct parses are given increasing weight, while features in incorrect parses are given decreasing weight.
</nextsent>
<nextsent>once model is trained, it can be applied to parse selection that chooses the parse with the highest sum of feature weights.during the training procedure, the weights vector is estimated to best fit the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2608">
<title id=" W09-1416.xml">supervised classification for extracting biomedical events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most previous work on biomedical information extraction focuses on identifying relationships among biomedical entities (e.g. protein-protein interac tions).
</prevsent>
<prevsent>unlike relationships, which are in general characterized with pair of entities, events can be characterized with event types and multiple entities in varying roles.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the bionlp09 shared task addresses the extraction of bio-molecular events fromthe biomedical literature (kim et al, 2009).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>we participated in the event detection and characteriza tion?
</nextsent>
<nextsent>task (task 1).
</nextsent>
<nextsent>the goal was to recognize the events concerning the given proteins by detecting the event triggers, determining the event types, and identifying the event participants.in this study, we approach the problem as supervised classification task.
</nextsent>
<nextsent>we group the event types into three general classes based on the number and types of participants that they involve.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2609">
<title id=" W09-1416.xml">supervised classification for extracting biomedical events </title>
<section> event3: type: negative regulation trigger: inhibits.  </section>
<citcontext>
<prevsection>
<prevsent>our intuition is that, if candidate trigger and participant are far away from each other, it is less likely that they characterize an event.
</prevsent>
<prevsent>2.2.3 dependency relation features dependency parse tree captures the semantic predicate-argument dependencies among the wordsof sentence.
</prevsent>
</prevsection>
<citsent citstr=" D07-1024 ">
dependency tree paths between protein pairs have successfully been used to identify 112 protein interactions (bunescu and mooney, 2007; erkan et al, 2007).<papid> D07-1024 </papid></citsent>
<aftsection>
<nextsent>in this paper, we use the dependency paths to extract events.
</nextsent>
<nextsent>forgiven trigger/participant pair, we extract the shortest path from the trigger to the participant, from the dependency parse of the sentence.
</nextsent>
<nextsent>we use the mcclosky charniak parses which are converted to the stanford typed dependencies format and provided to the participants by the shared task organizers.
</nextsent>
<nextsent>previous approaches use both the words and the dependency relation types to represent the paths (bunescu and mooney, 2007; erkan et al, 2007).<papid> D07-1024 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2618">
<title id=" W09-0202.xml">word space models of lexical variation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some words may be restricted to specific register, while other ones may have different meanings in different regions.
</prevsent>
<prevsent>in corpus linguistics, the most straightforward way of finding such words that are typical of one language variety is to compile corpus of that variety and compare it to reference corpus of another variety.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
the most obvious comparison takes on the form of keyword analysis, which looks for the words that are significantly more frequent in the one corpus as compared to the other (dunning, 1993; <papid> J93-1003 </papid>scott, 1997; rayson et al, 2004).</citsent>
<aftsection>
<nextsent>for the purposes of language-variational study,this classic keyword approach often does not suffice, however.
</nextsent>
<nextsent>as kilgarriff has argued, keyword statistics are far too sensitive to high frequencies or topical differences to be used in the study of vocabulary differences (kilgarriff, 2001).
</nextsent>
<nextsent>we therefore put forward an approach that combines keyword statistics with distributional models of lexical semantics, or word space models (sahlgren,2006; bullinaria and levy, 2007; pado?
</nextsent>
<nextsent>and lap ata, 2007; peirsman, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2623">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one prominent approach to this question is thedictionary-based model of token meaning: the different meanings of word are set of distinct, disjoint senses enumerated in lexicon or ontology, such as wordnet.
</prevsent>
<prevsent>for each new occurrence, determining token meaning means choosing one of the senses, classification task known as word sense disambiguation (wsd).
</prevsent>
</prevsection>
<citsent citstr=" W06-2503 ">
unfortunately, this task has turned out to be very hard both for human annotators and for machines (kilgarriff and rosenzweig, 2000), not at least due to granularity problems with available resources (palmer et al, 2007; mccarthy, 2006).<papid> W06-2503 </papid></citsent>
<aftsection>
<nextsent>some researchers have gone so far as to suggest fundamental problems with the concept of categorical word senses (kilgarriff, 1997; hanks, 2000).
</nextsent>
<nextsent>an interesting alternative is offered by vector space models of word meaning (lund and burgess, 1996; mcdonald and brew, 2004) <papid> P04-1003 </papid>which characterize the meaning of word entirely without reference to word senses.word meaning is described in terms of vector in high dimensional vector space that is constructed with distributional methods.</nextsent>
<nextsent>semantic similarity is then simply distance to vectors of other words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2624">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, this task has turned out to be very hard both for human annotators and for machines (kilgarriff and rosenzweig, 2000), not at least due to granularity problems with available resources (palmer et al, 2007; mccarthy, 2006).<papid> W06-2503 </papid></prevsent>
<prevsent>some researchers have gone so far as to suggest fundamental problems with the concept of categorical word senses (kilgarriff, 1997; hanks, 2000).</prevsent>
</prevsection>
<citsent citstr=" P04-1003 ">
an interesting alternative is offered by vector space models of word meaning (lund and burgess, 1996; mcdonald and brew, 2004) <papid> P04-1003 </papid>which characterize the meaning of word entirely without reference to word senses.word meaning is described in terms of vector in high dimensional vector space that is constructed with distributional methods.</citsent>
<aftsection>
<nextsent>semantic similarity is then simply distance to vectors of other words.
</nextsent>
<nextsent>vector space models have been most successful in modeling the meaning ofword types (i.e. in constructing type vectors).
</nextsent>
<nextsent>the characterization of token meaning by corresponding token vectors would represent very interesting alternative to dictionary-based methods by providing direct, graded, unsupervised measure of (dis-)similarity between words in context that completely avoids reference to dictionary senses.
</nextsent>
<nextsent>however, there are still considerable theoretic aland practical problems, even though there is substantial body of work (landauer and dumais, 1997; schtze, 1998; kintsch, 2001; mitchell and lapata, 2008).<papid> P08-1028 </papid>in recent paper (erk and pad?, 2008), we have introduced the structured vector space ( svs) model which addresses this challenge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2625">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>vector space models have been most successful in modeling the meaning ofword types (i.e. in constructing type vectors).
</prevsent>
<prevsent>the characterization of token meaning by corresponding token vectors would represent very interesting alternative to dictionary-based methods by providing direct, graded, unsupervised measure of (dis-)similarity between words in context that completely avoids reference to dictionary senses.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
however, there are still considerable theoretic aland practical problems, even though there is substantial body of work (landauer and dumais, 1997; schtze, 1998; kintsch, 2001; mitchell and lapata, 2008).<papid> P08-1028 </papid>in recent paper (erk and pad?, 2008), we have introduced the structured vector space ( svs) model which addresses this challenge.</citsent>
<aftsection>
<nextsent>it yields one token vector per input word.
</nextsent>
<nextsent>token vectors are not computed by combining the lexical meaning of the surrounding words ? which risks resulting in topicality?
</nextsent>
<nextsent>vector ? but by modifying the type meaning of word with the semantic expectations of syntactically related words, which can be thought of as selectional preferences.
</nextsent>
<nextsent>for example, in catch ball, the token vector for ball is computed by combining the type vector of ball with vector for the selectional preferences of catch for its object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2627">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, this strategy remains vulnerable to all criticism concerning the annotation of categorical word senses, and also does not take advantage of the vector models?
</prevsent>
<prevsent>central asset, namely gradedness.
</prevsent>
</prevsection>
<citsent citstr=" W07-2009 ">
thus,paraphrase-based assessment for models of token meaning was proposed as representation-neutral disambiguation task that can replace wsd (mccarthy and navigli, 2007; <papid> W07-2009 </papid>mitchell and lapata, 2008).<papid> P08-1028 </papid></citsent>
<aftsection>
<nextsent>given word token in context and set of potential paraphrases,the task consists of identifying the subset of valid paraphrases.
</nextsent>
<nextsent>for example, in the following example, the first paraphrase is appropriate, but the second is not: (1) google acquired youtube ? google bought youtube (2) how children acquire skills 6?
</nextsent>
<nextsent>how children buy skills this task is graded in the sense that there is no disjoint set of labels from which exactly one is picked for each token; rather, the paraphrases form set of labels of which subset is appropriate for each word token, 57 and the appropriate sets for two tokens may overlap to varying degrees.
</nextsent>
<nextsent>in an ideal vector-based model, valid paraphrases such as (1) should possess similar vectors, and invalid ones such as (2) dissimilar ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2634">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> the structured vector space model.  </section>
<citcontext>
<prevsection>
<prevsent>in cognitive science, the central role of expectations about typical events on almost all aspects of human language processing is well-established (mcrae et al,1998; narayanan and jurafsky, 2002).
</prevsent>
<prevsent>in linguistics, expectations have long been used in semantic theories inthe form of selectional restrictions and selectional preferences (wilks, 1975), and more recently induced from corpora (resnik, 1996).
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
attention has mostly been limited to selectional preferences of verbs, which have been used for for variety of tasks (hindle and rooth, 1993; <papid> J93-1005 </papid>gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>a recent result that the svs model builds on is that selectional preferences can be represented as prototype vectors constructed from seen arguments (erk, 2007; <papid> P07-1028 </papid>pad?</nextsent>
<nextsent>et al, 2007).representing lemma meaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2635">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> the structured vector space model.  </section>
<citcontext>
<prevsection>
<prevsent>in cognitive science, the central role of expectations about typical events on almost all aspects of human language processing is well-established (mcrae et al,1998; narayanan and jurafsky, 2002).
</prevsent>
<prevsent>in linguistics, expectations have long been used in semantic theories inthe form of selectional restrictions and selectional preferences (wilks, 1975), and more recently induced from corpora (resnik, 1996).
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
attention has mostly been limited to selectional preferences of verbs, which have been used for for variety of tasks (hindle and rooth, 1993; <papid> J93-1005 </papid>gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>a recent result that the svs model builds on is that selectional preferences can be represented as prototype vectors constructed from seen arguments (erk, 2007; <papid> P07-1028 </papid>pad?</nextsent>
<nextsent>et al, 2007).representing lemma meaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2636">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> the structured vector space model.  </section>
<citcontext>
<prevsection>
<prevsent>in linguistics, expectations have long been used in semantic theories inthe form of selectional restrictions and selectional preferences (wilks, 1975), and more recently induced from corpora (resnik, 1996).
</prevsent>
<prevsent>attention has mostly been limited to selectional preferences of verbs, which have been used for for variety of tasks (hindle and rooth, 1993; <papid> J93-1005 </papid>gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1028 ">
a recent result that the svs model builds on is that selectional preferences can be represented as prototype vectors constructed from seen arguments (erk, 2007; <papid> P07-1028 </papid>pad?</citsent>
<aftsection>
<nextsent>et al, 2007).representing lemma meaning.
</nextsent>
<nextsent>to accommodate information about semantic expectations, the svs model extends the traditional representation of word meaning as single vector by set of vectors, each of which represents the words selectional preferences for each relation that the word can assume in its linguistic context.
</nextsent>
<nextsent>while we ultimately think of these relations as properly semantic?
</nextsent>
<nextsent>in the sense of semantic roles, the instantiation of svs we consider in this paper makes use of dependency relations as level of representation that generalizes over substantial amount of surface variation but that can be obtained automatically with high accuracy using current nlp tools.the idea is illustrated in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2638">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>vector space.
</prevsent>
<prevsent>we use dependency-based vector space that counts target word and context word 59 as co-occurring in sentence if they are connected by an informative?
</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
path in the dependency graph for the sentence.2 we build the space from minipar-parsed version of the british national corpus with dependency parses obtained from minipar (lin, 1993).<papid> P93-1016 </papid></citsent>
<aftsection>
<nextsent>it uses raw co-occurrence counts and 2000 dimensions.
</nextsent>
<nextsent>selectional preferences and reweighting.
</nextsent>
<nextsent>we use prototype-based selectional preference model (erk,2007).<papid> P07-1028 </papid></nextsent>
<nextsent>it models the selectional preferences of predicate for an argument position as the weighted centro id of the vectors for all headwords seen for this position in large corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2649">
<title id=" W09-0208.xml">paraphrase assessment in structured vector space exploring parameters and datasets </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>however, the use of wordnet information to create paraphrases results in very difficult corpus.
</prevsent>
<prevsent>we will investigate methods that exclude overly general hypernyms of the target words as paraphrases to alleviate the problems we see currently.discriminativity further suggests that paraphrase assessment can be improved by selectional preference representations that are trained to maximize the distance between valid and invalid paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" D08-1007 ">
such are presentation could be provided by discriminative formulations (bergsma et al, 2008), <papid> D08-1007 </papid>or by exemplar-based models that are able to deal better with the ambiguity present in the preferences of very general words.</citsent>
<aftsection>
<nextsent>another important topic for further research is the computation of token vectors that incorporate more than one context word.
</nextsent>
<nextsent>the current results we obtain forboth?
</nextsent>
<nextsent>are promising but limited; it appears that the successful integration of multiple context words requires strategies that go beyond simplistic addition or intersection of observed contexts.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2650">
<title id=" W08-2130.xml">discriminative learning of syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally f1 scores of 86.69, 69.95and 78.35 are obtained for syntactic dependencies, semantic dependencies and the whole system respectively in closed challenge.
</prevsent>
<prevsent>for open challenge the corresponding f1 scores are 86.69, 68.99 and 77.84.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
given sentences and corresponding part-of-speechof each word, the learning of syntactic and semantic dependency contains two separable goals: (1)building dependency tree that defines the syntactic dependency relationships between separated words; (2) specifying predicates (no matter verbsor nouns) of the sentences and labeling the semantic dependents for each predicate.in this paper discriminative parser is proposed to implement maximum entropy (me) models (berger, et al, 1996) <papid> J96-1002 </papid>to address the learningtask.</citsent>
<aftsection>
<nextsent>the system is divided into two main subsys tems: syntactic dependency parsing and semantic dependency labeling.
</nextsent>
<nextsent>the former is used to find awell-formed syntactic dependency tree that occupies all the words in the sentence.
</nextsent>
<nextsent>if edges are added between any two words, full-connected ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2651">
<title id=" W08-2130.xml">discriminative learning of syntactic and semantic dependencies </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the method used for semantic dependency labeling is somewhat different from syntactic dependencyparsing.
</prevsent>
<prevsent>the work of semantic labeling can be divided into two stages: predicate tagging and dependents recognizing.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
2.2.1 predicate tagging according to propbank (palmer, et al, 2005) <papid> J05-1004 </papid>and nombank (meyers, et al, 2004), <papid> W04-2705 </papid>predicates usually have several role sets corresponding to different meanings.</citsent>
<aftsection>
<nextsent>for example, the verb abandon has three role sets marked as ordinal numbers 01, 02 and 03 as described below.
</nextsent>
<nextsent>w p p i1 i+1 (p i1 , i ) (p , i+1 ) (p i2 , i ) (p , i+2 ) (p i3 , i ) (p , i+3 ) (p i1 , i , i+1 ) (w , i ) (w , i1 , i ) (w , i , i+1 ) (w , i2 , i ) (w , i , i+2 ) (w , i3 , i ) (w , i , i+3 ) (w , i1 , i , i+1 ) table 2: features used for predicate tagging.
</nextsent>
<nextsent> frame set   predicate lemma=abandon?   roleset id=abandon.01?
</nextsent>
<nextsent>name=leave behind?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2652">
<title id=" W08-2130.xml">discriminative learning of syntactic and semantic dependencies </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the method used for semantic dependency labeling is somewhat different from syntactic dependencyparsing.
</prevsent>
<prevsent>the work of semantic labeling can be divided into two stages: predicate tagging and dependents recognizing.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
2.2.1 predicate tagging according to propbank (palmer, et al, 2005) <papid> J05-1004 </papid>and nombank (meyers, et al, 2004), <papid> W04-2705 </papid>predicates usually have several role sets corresponding to different meanings.</citsent>
<aftsection>
<nextsent>for example, the verb abandon has three role sets marked as ordinal numbers 01, 02 and 03 as described below.
</nextsent>
<nextsent>w p p i1 i+1 (p i1 , i ) (p , i+1 ) (p i2 , i ) (p , i+2 ) (p i3 , i ) (p , i+3 ) (p i1 , i , i+1 ) (w , i ) (w , i1 , i ) (w , i , i+1 ) (w , i2 , i ) (w , i , i+2 ) (w , i3 , i ) (w , i , i+3 ) (w , i1 , i , i+1 ) table 2: features used for predicate tagging.
</nextsent>
<nextsent> frame set   predicate lemma=abandon?   roleset id=abandon.01?
</nextsent>
<nextsent>name=leave behind?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2653">
<title id=" W08-1404.xml">graph based keyword extraction for single document summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, according to our problem statement, the keyword is word presenting in the document summary.
</prevsent>
<prevsent>the supervised learning approach for keywords extraction was first suggested in (turney, 2000), where parametrized heuristic rules were combined with genetic algorithm into system - genex that automatically identified keywords in docu ment.for both our approaches, we utilize graph based representation for text documents.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
such representations may vary from very simple, syntactic ones like words connected by edges representing co-occurrence relation (mihalcea and tarau, 2004) <papid> W04-3252 </papid>to more complex ones like concepts connected by semantic relations (leskovec et al, 2004).</citsent>
<aftsection>
<nextsent>the main advantage of syntactic representation is its language in dependency, while the semantic graphs representation provide new characteristics of text such as its captured semantic structure that itself can serve as document surrogate and provide means for document navigation.
</nextsent>
<nextsent>authors of(leskovec et al, 2004) reduce the problem of summarization to acquiring machine learning models for mapping between the document graph and the graph of summary.
</nextsent>
<nextsent>using deep linguistic analysis, they extract sub-structures (subjectpredica teobject triples) from document semantic graphs in order to get summary.
</nextsent>
<nextsent>contrary to (leskovec etal., 2004), both our approaches work with syntactic representation that does not require almost any language-specific linguistic processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2668">
<title id=" W08-1404.xml">graph based keyword extraction for single document summarization </title>
<section> keywords extraction.  </section>
<citcontext>
<prevsection>
<prevsent>these algorithms recursively assign numerical weight to each element of hyper linked set of documents, determining how important each page is. hyper link to page counts as vote of support.
</prevsent>
<prevsent>a page that is linked to by many important pages (with high rank) receives high rank itself.
</prevsent>
</prevsection>
<citsent citstr=" P04-3020 ">
asimilar idea can be applied to lexical or semantic graphs extracted from text documents, in order to extract the most significant blocks (words,phrases, sentences, etc.) for the summary (mi halcea and tarau, 2004; <papid> W04-3252 </papid>mihalcea, 2004).<papid> P04-3020 </papid></citsent>
<aftsection>
<nextsent>in this paper, we apply the hits algorithm to document graphs and evaluate its performance on automatic unsupervised text unit extraction in the context of the text summarization task.
</nextsent>
<nextsent>the hits algorithm distinguishes between authorities?
</nextsent>
<nextsent>(pages with large number of incoming links) and hubs?
</nextsent>
<nextsent>(pages with large number of outgoing links).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2675">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the noun ontology is used in our work to help induce relationships involving concepts (senses of nouns) rather than just among words.
</prevsent>
<prevsent>this notion of inducing csk among concepts, rather than words,is key difference between our work and similar research.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
the work on verb ocean is similar to our research in the use of the web for acquiring relationships (chklovski and pantel, 2004).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>they used patterns of phrases in order to search the web for semantic relations among verbs.
</nextsent>
<nextsent>the knowledge they acquire falls into the category of csk, but the specific relationships are different than ours in that they are among verb word forms and senses are not resolved.
</nextsent>
<nextsent>concept net was created based on the open mind commonsense project (liu and singh, 2004).
</nextsent>
<nextsent>the project acquired knowledge through an interface on the web by having users play games and answer questions about words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2676">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>there are three layers of information: the first two, access and physical, contain meta data,while the third, logical layer, stores high level implicit meanings.
</prevsent>
<prevsent>only portion of cyc is available to the public.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
our method for acquiring knowledge is somewhat similar to that of (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>patterns are built manually.
</nextsent>
<nextsent>however, we do not use our manually constructed patterns (referred to as search phrases)to query the web.
</nextsent>
<nextsent>instead the search phrases are abstract patterns that are used to automatically generate more specific web queries by filling constituents based on lists of words.
</nextsent>
<nextsent>the semeval-2007 task 4 presents good overview of work in noun-noun relationships (girjuet al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2678">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>however, the type of relationship between words of topic signature and the wordnet concept is not made explicit, and the authors find the topic signatures are not very effective for word sense disambiguation.
</prevsent>
<prevsent>finally, we note one approach to using the web for nlp applications is to acquire knowledge on the fly.
</prevsent>
</prevsection>
<citsent citstr=" W08-2114 ">
previous work has approached solutions to word sense disambiguation by acquiring words or phrases directly based on the sentences or words being dis ambiguated (martinez et al, 2006; schwartz and gomez, 2008).<papid> W08-2114 </papid></citsent>
<aftsection>
<nextsent>these methods dynamically acquire the data at runtime, rather than automatically create common sense database of relations that is readily available.
</nextsent>
<nextsent>additionally, in our current approach, we are able to acquire explicit csk relationships.
</nextsent>
<nextsent>the two major phases of our framework, noun ac quisition?
</nextsent>
<nextsent>and concept analysis?, are outlined in figure 1 and described within this section.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2679">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> common sense acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>duplicate samples were removed to reduce the effects of web sites replicating the text of one another.
</prevsent>
<prevsent>2no longer supported by google 3http://developer.yahoo.com/search/ relation search phrase voice nouna is located prep nounb on, in nouna is found prep nounb passive nouna is situated prep nounb nouna is prep nounb put nouna prep nounb place nouna prep nounb on, in lay nouna prep nounb active set nouna prep nounb locate nouna prep nounb position nouna prep nounb hang nouna prep nounb on mount nouna prep nounb active attach nouna prep nounbtable 2: search phrases and relationships used for acquisition of csk.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
3.1.3 parse and match the results we want to achieve in this step should describe relationship: nouna is [in | on] nounb we use charniaks parser (charniak, 2000) <papid> A00-2018 </papid>on both the web query and the results returned from the webin order to ensure accuracy.</citsent>
<aftsection>
<nextsent>to demonstrate this process, we extend our example, place * in the refrig erator?.
</nextsent>
<nextsent>first, we get parse with * (nouna) represented as something?.
</nextsent>
<nextsent>(vp (vb place) (np (nn something)) (pp (in in) (np (dt the) (nn refrigerator)))) we now know the constituent(s) which replace ?(nn something)?
</nextsent>
<nextsent>will be our nouna.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2680">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we focus particular lyon the difficult problem of word sense disambiguation.
</prevsent>
<prevsent>due to the lack of sense tagged data, we were unable to find an annotated corpus with instances of all the nouns in table 3 as prepositional complements.
</prevsent>
</prevsection>
<citsent citstr=" P04-1039 ">
this was not surprising considering one of the reasons that minimally supervised approaches have become more popular is that they do not require hand-tagged training data (mihalcea, 2002; diab, 2004; <papid> P04-1039 </papid>mccarthy et al, 2004).<papid> P04-1036 </papid></citsent>
<aftsection>
<nextsent>we created corpus from sentences in wikipedia which contained the phrase in|on det lemma?, where det is determiner or possessive pronoun,lemma is noun from table 3, and in|on is preposition for either relationship described earlier.
</nextsent>
<nextsent>be low we have provided an example from our corpus where the knowledge from pocket?
</nextsent>
<nextsent>can be applied to disambiguate key?.
</nextsent>
<nextsent>now tonys key to the flat is in the pocket of his raincoat, so on returning to his flat some time later he realizes that he cannot get inside.the corpus5 contained total of 342 sentences, with one target noun annotated per sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2681">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we focus particular lyon the difficult problem of word sense disambiguation.
</prevsent>
<prevsent>due to the lack of sense tagged data, we were unable to find an annotated corpus with instances of all the nouns in table 3 as prepositional complements.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
this was not surprising considering one of the reasons that minimally supervised approaches have become more popular is that they do not require hand-tagged training data (mihalcea, 2002; diab, 2004; <papid> P04-1039 </papid>mccarthy et al, 2004).<papid> P04-1036 </papid></citsent>
<aftsection>
<nextsent>we created corpus from sentences in wikipedia which contained the phrase in|on det lemma?, where det is determiner or possessive pronoun,lemma is noun from table 3, and in|on is preposition for either relationship described earlier.
</nextsent>
<nextsent>be low we have provided an example from our corpus where the knowledge from pocket?
</nextsent>
<nextsent>can be applied to disambiguate key?.
</nextsent>
<nextsent>now tonys key to the flat is in the pocket of his raincoat, so on returning to his flat some time later he realizes that he cannot get inside.the corpus5 contained total of 342 sentences, with one target noun annotated per sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2682">
<title id=" W09-1701.xml">acquiring applicable common sense knowledge from the web </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>agreement was calculated as: agree = (?
</prevsent>
<prevsent>ic |s1i ? s2i| |s1i ? s2i| ) ? 342where s1 and s2 are the two sets of sense annotations, and is an instance of the corpus, c. the agreement and other data concerning corpus annotation can be found in table 4.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
as point of comparison, the senseval 3 all-words task had 75% agreement on nouns (snyder and palmer, 2004).<papid> W04-0811 </papid></citsent>
<aftsection>
<nextsent>a second evaluation of agreement was also done.
</nextsent>
<nextsent>the non-author annotations were treated as if they came 5available at: http://eecs.ucf.edu/hschwartz/csk/ 7 insts agree f1h f1rnd f1mfs on 131 79.9 84.7 28.2 71.0 in 211 80.8 91.9 27.2 67.8 both 342 80.5 89.2 27.6 69.0table 4: experimental corpus data for each relationship (on, in).
</nextsent>
<nextsent>insts: number of annotated instances; agree: inter-annotator agreement %; f1 values (precision = recall): h: human annotation, rnd: random baseline, mfs: most frequent sense baseline.
</nextsent>
<nextsent>without csk with csk f1all f1indeg f1all f1indeg on 62.6 63.4 64.9 67.2 in 68.7 69.7 71.6 72.5 both 66.4 67.3 69.0 70.5 ties 37 0 66 72table 5: f1 values (precision = recall) on our experimental corpus with and without csk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2683">
<title id=" W09-1316.xml">incorporating syntactic dependency information towards improved coding of lengthy medical concepts in clinical reports </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>we describe system which uses information found in syntactic dependencies to help in the coding of lengthy phrases.
</prevsent>
<prevsent>preliminary results using this approach are reported as proof-of-concept.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
syntactic dependency parsing has received much focus from the natural language processing community (eisner, 1996; <papid> C96-1058 </papid>kudo and matsumoto, 2000; <papid> W00-1303 </papid>nivre and scholz, 2004; <papid> C04-1010 </papid>yamada and matsumoto, 2003).</citsent>
<aftsection>
<nextsent>a syntactic dependency relation is an asymmetric relation between two words.
</nextsent>
<nextsent>one word is called the head, and the other word is called the modifier or dependent.
</nextsent>
<nextsent>a word in the sentence can play the role of the head in several dependency relations (i.e., it can have several modifiers) but each word can play the role of the modifier only once.
</nextsent>
<nextsent>a special word, named the root, does not play the role of the modifier in any relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2684">
<title id=" W09-1316.xml">incorporating syntactic dependency information towards improved coding of lengthy medical concepts in clinical reports </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>we describe system which uses information found in syntactic dependencies to help in the coding of lengthy phrases.
</prevsent>
<prevsent>preliminary results using this approach are reported as proof-of-concept.
</prevsent>
</prevsection>
<citsent citstr=" W00-1303 ">
syntactic dependency parsing has received much focus from the natural language processing community (eisner, 1996; <papid> C96-1058 </papid>kudo and matsumoto, 2000; <papid> W00-1303 </papid>nivre and scholz, 2004; <papid> C04-1010 </papid>yamada and matsumoto, 2003).</citsent>
<aftsection>
<nextsent>a syntactic dependency relation is an asymmetric relation between two words.
</nextsent>
<nextsent>one word is called the head, and the other word is called the modifier or dependent.
</nextsent>
<nextsent>a word in the sentence can play the role of the head in several dependency relations (i.e., it can have several modifiers) but each word can play the role of the modifier only once.
</nextsent>
<nextsent>a special word, named the root, does not play the role of the modifier in any relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2685">
<title id=" W09-1316.xml">incorporating syntactic dependency information towards improved coding of lengthy medical concepts in clinical reports </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>we describe system which uses information found in syntactic dependencies to help in the coding of lengthy phrases.
</prevsent>
<prevsent>preliminary results using this approach are reported as proof-of-concept.
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
syntactic dependency parsing has received much focus from the natural language processing community (eisner, 1996; <papid> C96-1058 </papid>kudo and matsumoto, 2000; <papid> W00-1303 </papid>nivre and scholz, 2004; <papid> C04-1010 </papid>yamada and matsumoto, 2003).</citsent>
<aftsection>
<nextsent>a syntactic dependency relation is an asymmetric relation between two words.
</nextsent>
<nextsent>one word is called the head, and the other word is called the modifier or dependent.
</nextsent>
<nextsent>a word in the sentence can play the role of the head in several dependency relations (i.e., it can have several modifiers) but each word can play the role of the modifier only once.
</nextsent>
<nextsent>a special word, named the root, does not play the role of the modifier in any relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2686">
<title id=" W09-1316.xml">incorporating syntactic dependency information towards improved coding of lengthy medical concepts in clinical reports </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>an example of dependencies in typical sentence found in radiology report is shown in figure 1.
</prevsent>
<prevsent>systems based on syntactic dependencies have been used successfully in several information retrieval experiments with results outperforming traditional retrieval systems (croft et al, 1991; gao et al, 2004; gonzalez et al, 2005; smeaton, 1986).
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
in particular, this method has been used for word sense disambiguation (lin, 1997) <papid> P97-1009 </papid>and thesaurus construction (lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>dependency trees have also been used for medical concept representation in the domains of radiology (steimann, 1998) and pathology (romacker et al, 1999).
</nextsent>
<nextsent>3.1 anatomy phrase extraction.
</nextsent>
<nextsent>for identifying anatomy phrases, we use specialized phrase parser trained to identify anatomy phrases within clinical reports.
</nextsent>
<nextsent>the input to the parser is sentence tagged with part-of-speech tag and semantic tag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2687">
<title id=" W09-1316.xml">incorporating syntactic dependency information towards improved coding of lengthy medical concepts in clinical reports </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>an example of dependencies in typical sentence found in radiology report is shown in figure 1.
</prevsent>
<prevsent>systems based on syntactic dependencies have been used successfully in several information retrieval experiments with results outperforming traditional retrieval systems (croft et al, 1991; gao et al, 2004; gonzalez et al, 2005; smeaton, 1986).
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
in particular, this method has been used for word sense disambiguation (lin, 1997) <papid> P97-1009 </papid>and thesaurus construction (lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>dependency trees have also been used for medical concept representation in the domains of radiology (steimann, 1998) and pathology (romacker et al, 1999).
</nextsent>
<nextsent>3.1 anatomy phrase extraction.
</nextsent>
<nextsent>for identifying anatomy phrases, we use specialized phrase parser trained to identify anatomy phrases within clinical reports.
</nextsent>
<nextsent>the input to the parser is sentence tagged with part-of-speech tag and semantic tag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2688">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both methods gave some improvements to translation quality as measured by bleuand meteor scores, though not consistently.
</prevsent>
<prevsent>all systems used both out-of domain and in-domain data as the mixed corpus had better scores in the baseline configuration.
</prevsent>
</prevsection>
<citsent citstr=" J07-3002 ">
it is an open question whether improved word alignment actually improves statistical mt. fraser and marcu (2007) <papid> J07-3002 </papid>found that improved alignments as measured by aer will not necessarily improve translation quality, whereas ganchev et al (2008)<papid> P08-1112 </papid>did improve translation quality on several language pairs by extending the alignment algorithm.for this years shared task we therefore studied the effects of improving word alignment in the context of our system for the wmt09 shared task.</citsent>
<aftsection>
<nextsent>two methods were tried: (i) applying giza++ in second phase to reordered training corpus, where reordering is based on the alignments fromthe first phase, and (ii) adding lexical data obtained as high-precision alignments from different word aligner.
</nextsent>
<nextsent>the submitted system includes the first method in addition to the processing of compounds and additional sequence models used by stymne et al (2008).<papid> W08-0317 </papid></nextsent>
<nextsent>heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2689">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both methods gave some improvements to translation quality as measured by bleuand meteor scores, though not consistently.
</prevsent>
<prevsent>all systems used both out-of domain and in-domain data as the mixed corpus had better scores in the baseline configuration.
</prevsent>
</prevsection>
<citsent citstr=" P08-1112 ">
it is an open question whether improved word alignment actually improves statistical mt. fraser and marcu (2007) <papid> J07-3002 </papid>found that improved alignments as measured by aer will not necessarily improve translation quality, whereas ganchev et al (2008)<papid> P08-1112 </papid>did improve translation quality on several language pairs by extending the alignment algorithm.for this years shared task we therefore studied the effects of improving word alignment in the context of our system for the wmt09 shared task.</citsent>
<aftsection>
<nextsent>two methods were tried: (i) applying giza++ in second phase to reordered training corpus, where reordering is based on the alignments fromthe first phase, and (ii) adding lexical data obtained as high-precision alignments from different word aligner.
</nextsent>
<nextsent>the submitted system includes the first method in addition to the processing of compounds and additional sequence models used by stymne et al (2008).<papid> W08-0317 </papid></nextsent>
<nextsent>heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2690">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is an open question whether improved word alignment actually improves statistical mt. fraser and marcu (2007) <papid> J07-3002 </papid>found that improved alignments as measured by aer will not necessarily improve translation quality, whereas ganchev et al (2008)<papid> P08-1112 </papid>did improve translation quality on several language pairs by extending the alignment algorithm.for this years shared task we therefore studied the effects of improving word alignment in the context of our system for the wmt09 shared task.</prevsent>
<prevsent>two methods were tried: (i) applying giza++ in second phase to reordered training corpus, where reordering is based on the alignments fromthe first phase, and (ii) adding lexical data obtained as high-precision alignments from different word aligner.</prevsent>
</prevsection>
<citsent citstr=" W08-0317 ">
the submitted system includes the first method in addition to the processing of compounds and additional sequence models used by stymne et al (2008).<papid> W08-0317 </papid></citsent>
<aftsection>
<nextsent>heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6.
</nextsent>
<nextsent>in this paper we report case-insensitive bleu scores (papineni et al, 2002), <papid> P02-1040 </papid>unless otherwise stated, calculated with the nist tool, and case insensitive meteor-ranking scores, without wordnet (agarwal and lavie, 2008).<papid> W08-0312 </papid></nextsent>
<nextsent>our baseline system uses compound splitting, compound merging and part-of speech/morphological sequence models (stymne et al, 2008).<papid> W08-0317 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2691">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the submitted system includes the first method in addition to the processing of compounds and additional sequence models used by stymne et al (2008).<papid> W08-0317 </papid></prevsent>
<prevsent>heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in this paper we report case-insensitive bleu scores (papineni et al, 2002), <papid> P02-1040 </papid>unless otherwise stated, calculated with the nist tool, and case insensitive meteor-ranking scores, without wordnet (agarwal and lavie, 2008).<papid> W08-0312 </papid></citsent>
<aftsection>
<nextsent>our baseline system uses compound splitting, compound merging and part-of speech/morphological sequence models (stymne et al, 2008).<papid> W08-0317 </papid></nextsent>
<nextsent>except for these additions it is similar to the baseline system of the workshop1.the translation system is factored phrase based translation system that uses the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and training, giza++ for word alignment (och and ney, 2003), <papid> J03-1002 </papid>and srilm (stolcke, 2002) for language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2692">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the submitted system includes the first method in addition to the processing of compounds and additional sequence models used by stymne et al (2008).<papid> W08-0317 </papid></prevsent>
<prevsent>heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6.</prevsent>
</prevsection>
<citsent citstr=" W08-0312 ">
in this paper we report case-insensitive bleu scores (papineni et al, 2002), <papid> P02-1040 </papid>unless otherwise stated, calculated with the nist tool, and case insensitive meteor-ranking scores, without wordnet (agarwal and lavie, 2008).<papid> W08-0312 </papid></citsent>
<aftsection>
<nextsent>our baseline system uses compound splitting, compound merging and part-of speech/morphological sequence models (stymne et al, 2008).<papid> W08-0317 </papid></nextsent>
<nextsent>except for these additions it is similar to the baseline system of the workshop1.the translation system is factored phrase based translation system that uses the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and training, giza++ for word alignment (och and ney, 2003), <papid> J03-1002 </papid>and srilm (stolcke, 2002) for language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2694">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we report case-insensitive bleu scores (papineni et al, 2002), <papid> P02-1040 </papid>unless otherwise stated, calculated with the nist tool, and case insensitive meteor-ranking scores, without wordnet (agarwal and lavie, 2008).<papid> W08-0312 </papid></prevsent>
<prevsent>our baseline system uses compound splitting, compound merging and part-of speech/morphological sequence models (stymne et al, 2008).<papid> W08-0317 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
except for these additions it is similar to the baseline system of the workshop1.the translation system is factored phrase based translation system that uses the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and training, giza++ for word alignment (och and ney, 2003), <papid> J03-1002 </papid>and srilm (stolcke, 2002) for language models.</citsent>
<aftsection>
<nextsent>minimum error rate training was used to tune the model feature weights (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>tuning was performed on the news-dev2009aset with 1025 sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2695">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we report case-insensitive bleu scores (papineni et al, 2002), <papid> P02-1040 </papid>unless otherwise stated, calculated with the nist tool, and case insensitive meteor-ranking scores, without wordnet (agarwal and lavie, 2008).<papid> W08-0312 </papid></prevsent>
<prevsent>our baseline system uses compound splitting, compound merging and part-of speech/morphological sequence models (stymne et al, 2008).<papid> W08-0317 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
except for these additions it is similar to the baseline system of the workshop1.the translation system is factored phrase based translation system that uses the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and training, giza++ for word alignment (och and ney, 2003), <papid> J03-1002 </papid>and srilm (stolcke, 2002) for language models.</citsent>
<aftsection>
<nextsent>minimum error rate training was used to tune the model feature weights (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>tuning was performed on the news-dev2009aset with 1025 sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2696">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>our baseline system uses compound splitting, compound merging and part-of speech/morphological sequence models (stymne et al, 2008).<papid> W08-0317 </papid></prevsent>
<prevsent>except for these additions it is similar to the baseline system of the workshop1.the translation system is factored phrase based translation system that uses the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for decoding and training, giza++ for word alignment (och and ney, 2003), <papid> J03-1002 </papid>and srilm (stolcke, 2002) for language models.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error rate training was used to tune the model feature weights (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>tuning was performed on the news-dev2009aset with 1025 sentences.
</nextsent>
<nextsent>all development testing was performed on the news-dev2009b set with 1026 sentences.
</nextsent>
<nextsent>2.1 sequence model based on part-of-speech.
</nextsent>
<nextsent>and morphology the translation models were factored with one additional output factor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2697">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>for german this factor was also used for compound merging.
</prevsent>
<prevsent>2.2 compound processing.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
prior to training and translation, compound processing was performed using an empirical method based on (koehn and knight, 2003; <papid> E03-1076 </papid>stymne, 2008).</citsent>
<aftsection>
<nextsent>words were split if they could be split into parts that occur in monolingual corpus.
</nextsent>
<nextsent>we chose the split with the highest arithmetic mean of the corpus frequencies of compound parts.
</nextsent>
<nextsent>we split nouns, adjectives and verbs into parts that were content words or particles.
</nextsent>
<nextsent>a part had to be at least 3 characters in length and stop list was used to avoid parts that often lead to errors,such as arische (aryan) in konsularische (con sular).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2698">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> domain adaptation.  </section>
<citcontext>
<prevsection>
<prevsent>this year three training corpora were available, asmall bilingual news commentary corpus, reasonably large europarl corpus, and very large monolingual news corpus, see table 1 for details.the bilingual data was filtered to remove sentences longer than 60 words.
</prevsent>
<prevsent>because the german news training corpus contained number of english sentences, this corpus was cleaned by removing sentences containing number of common english words.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
based on koehn and schroeder (2007) <papid> W07-0733 </papid>we adapted our system from last year, which was focused on europarl, to perform well on test data 2machinese syntax, from conn exor oy http://www.</citsent>
<aftsection>
<nextsent>connexor.eu corpus german english news-commentary09 81,141 europarl 1,331,262 news-train08 9,619,406 21,215,311 table 1: number of sentences in the corpora (after filtering) corpus ende deen bleu meteor bleu meteor news com.
</nextsent>
<nextsent>12.13 47.01 17.21 36.08 europarl 12.92 47.27 18.53 37.65 mixed 12.91 47.96 18.76 37.69 mixed+ 14.62 49.48 19.92 38.18 table 2: results of domain adaptation from the news domain.
</nextsent>
<nextsent>we used the possibility to include several translation models in the moses decoder by using multiple alternative decoding paths.
</nextsent>
<nextsent>we first trained systems on either bilingual news data or europarl.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2699">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> improved alignment by reordering.  </section>
<citcontext>
<prevsection>
<prevsent>using these sequence models in the mixed model, called mixed+, improved the results drastically, as shown in table 2.
</prevsent>
<prevsent>the other experiments reported in this paper are based on the mixed+ system.
</prevsent>
</prevsection>
<citsent citstr=" P07-1039 ">
word alignment with giza++ has been shown to improve from making the source and target language more similar, e.g., in terms of segmentation (ma et al, 2007) <papid> P07-1039 </papid>or word order.we used the following simple procedure to improve alignment of the training corpus by reordering the words in one of the texts according to the 121 corpus ende deen bleu meteor bleu meteor mixed+ 14.62 49.48 19.92 38.18 re-src 14.63 49.80 20.54 38.86 re-trg 14.51 48.62 20.48 38.73 table 3: results of reordering experiments word order in the other language: 1.</citsent>
<aftsection>
<nextsent>word align the corpus with giza++..
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>reorder the german words according to the.
</nextsent>
<nextsent>order of the english words they are aligned to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2700">
<title id=" W09-0421.xml">improving alignment for smt by reordering and augmenting the training corpus </title>
<section> augmenting the corpus with an.  </section>
<citcontext>
<prevsection>
<prevsent>in all experiments, the heuristic sym metrization of directed giza++ alignments was performed in the intended translation direction 3.
</prevsent>
<prevsent>3our experiments show that symmetrization in the wrong translation direction will result in lower translation quality scores.
</prevsent>
</prevsection>
<citsent citstr=" P06-1097 ">
extracted dictionary previous research (callison-burch et al, 2004;fraser and marcu, 2006) <papid> P06-1097 </papid>has shown that including word aligned data during training can improve translation results.</citsent>
<aftsection>
<nextsent>in our case we included dictionary extracted from the news-commentary corpus during the word alignment.
</nextsent>
<nextsent>using method originally developed for term extraction (merkel and foo, 2007), the newscommentary09 corpus was grammatically annotated and aligned using heuristic word aligner.
</nextsent>
<nextsent>candidate dictionary entries were extracted fromthe alignments.
</nextsent>
<nextsent>in order to optimize the quality of the dictionary, dictionary entry candidates were ranked according to their q-value, metric specifically designed for aligned data (merkel and foo, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2701">
<title id=" W09-0428.xml">morpho logics submission for the wmt 2009 shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our primary submissions were translated by meta morpho, purely rule based machine translation system (prszky and tihanyi, 2002).
</prevsent>
<prevsent>since last years workshop we improved the hungarian to english grammar of meta morpho by making more efficient the handling of certain structural ambiguities and making the way the system handles long sentences more robust.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the way meta morpho selects the translation to output is not optimal whether or not full parse for the source sentence could be obtained by its parser.1 thus we decided to experiment with hybrid system where translations and partial translations produced by meta morpho are ranked or assembled by the moses decoder (koehn et al., 2007) <papid> P07-2045 </papid>using target language model.</citsent>
<aftsection>
<nextsent>1 in the first case, simply the first translation is output.
</nextsent>
<nextsent>instead of considering all possible translations and selecting the best, while in the second case, the algorithm that combines the partial translations does not check how well the target language side of the pieces fit together.
</nextsent>
<nextsent>in addition, we created purely statistical morpheme based system (also using moses) for the hungarian to english task.
</nextsent>
<nextsent>however, results obtained with the latter setup have been clearly inferior in quality to those produced by the rule based system both in terms of bleu score and subjective human judgment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2702">
<title id=" W09-0801.xml">how to establish a verbal paradigm on the basis of ancient syriac manuscripts </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>for that reason our approach could be regarded as theory-driven, even though we consider it one of our main tasks to revise and refine the paradigm on the basis of the actual corpora.
</prevsent>
<prevsent>our encodings should be considered as hypotheses about the data that can be subjected to testing and experiment (section 4.6).
</prevsent>
</prevsection>
<citsent citstr=" W07-1516 ">
unlike projects that concern the acceleration of pos tagging (ringger et al, 2007; <papid> W07-1516 </papid>caroll et al., 2007) we start one level below, with the morphology.</citsent>
<aftsection>
<nextsent>encoding rather than tagging?
</nextsent>
<nextsent>is not just practical, but crucial methodological characteristic of our model.
</nextsent>
<nextsent>(for new insights that it produced regarding syriac morphology see the publications by bakker, van keulen and van peursen in the bibliography).
</nextsent>
<nextsent>we differ from the computer implementation of morphological rules (kiraz, 2001) in that our work is more deductive and focused on the interaction between ortho gra phy and morphology, because we start with the actual forms attested in the manuscripts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2703">
<title id=" W09-1404.xml">uzurich in the bionlp 2009 shared task </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 chunking using ltchunk.
</prevsent>
<prevsent>chunking can considerably reduce parsing complexity, while hardly affecting performance (prins, 2005).
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
in order to group contiguous sequences of nouns and verbs, we used ltchunk (mikheev, 1997).<papid> J97-3003 </papid></citsent>
<aftsection>
<nextsent>ltchunk annotates all noun and verb groups in the sentences.
</nextsent>
<nextsent>a chunk is an important unit in the analysis of biomedical texts.
</nextsent>
<nextsent>consider an np chunk liket cell-receptor-induced fasl up regula tion which contains two event triggers, amounting to mention of complex event.
</nextsent>
<nextsent>after applying ltchunk, we also detected chunk heads, with simple algorithm ? select last noun in noun groups, select last verb in verb groups.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2704">
<title id=" W09-1404.xml">uzurich in the bionlp 2009 shared task </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>29figure 1: dependency-syntax tree of the title of abstract 9360945: transcription factor nf-kappab regulates in ducible oct-2 gene expression in precursor lymphocytes.?
</prevsent>
<prevsent>the dependency relations link together the heads of the 5 chunks.the parser uses hand-written grammar expressing linguistic competence, and statistical language model that calculates lexicalized attachment probabilities, thus expressing linguistic performance.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the parser expresses distinctions that are especially important for predicate-argument based deep syntactic representation, as far as they are expressed in the training data generated from the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>this includes prepositional phrase attachments, control structures, appositions, relative clause anaphora, participles, gerunds, andargument/adjunct distinctions.
</nextsent>
<nextsent>the dependency label set is similar to the one used in the stanford scheme, the parser achieves state-of-the-art performance (haverinen et al, 2008).we have slightly adapted pro3gres to the biomedical domain.
</nextsent>
<nextsent>a class of nouns that varies considerably in the biomedical domain are relational nouns.
</nextsent>
<nextsent>they are syntactically marked because they can have several prepositional phrase arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2705">
<title id=" W09-1123.xml">improving text classification by a sense spectrum approach to term expansion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we approach our problem in three steps: (1) whether distributional semantics alone is enough forthe representation of word meaning, (2) whether semantic relatedness between word pairs can be expressed in an ordered form while preserving lexical field structure, and if (3) the uniqueness of entries in such an order can be expressed by functions rather than scalars such as distance.
</prevsent>
<prevsent>as we will show, this line of thought leads to performance improvement in text classification by using kernel-based feature weighting.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
since the early days of the vector space model, it has been debated whether it is proper carrier of meaning of texts (raghavan and wong, 1986), arguing if distributional similarity is an adequate proxy for lexical semantic relatedness (budanitsky and hirst, 2006).<papid> J06-1003 </papid></citsent>
<aftsection>
<nextsent>we argue for the need to enrich distributional semantics-based text representation by other components because with the statistical, i.e.devoid of word semantics approaches there is generally no way to improve both precision and recall at the same time, increasing one is done at the expense of the other.
</nextsent>
<nextsent>for example, casting wider net of search terms to improve recall of relevant item swill also bring in an even greater proportion of irrelevant items, lowering precision.
</nextsent>
<nextsent>in the mean time, practical approaches have been proliferating, especially with developments in kernel methods in the last decade (joachims, 1998; cristianini et al, 2002).
</nextsent>
<nextsent>some researchers suggested more general mathematical framework to accommodate the needs that the vector space model cannot satisfy (van rijs bergen, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2706">
<title id=" W09-1123.xml">improving text classification by a sense spectrum approach to term expansion </title>
<section> text classification with support vector.  </section>
<citcontext>
<prevsection>
<prevsent>one enrichment strategy is to use semantic smoothing kernel while calculating the similarity between two documents.
</prevsent>
<prevsent>any linear kernel for texts is characterized by k(ai,aj) = aissaj , wheres is an appropriately shaped matrix commonly referred to as semantic smoothing matrix (siolas and dalche?
</prevsent>
</prevsection>
<citsent citstr=" W05-0601 ">
buc, 2000; shawe-taylor and cristianini, 2004; basili et al, 2005; <papid> W05-0601 </papid>mavroeidis et al, 2005; bloehdorn et al, 2006).</citsent>
<aftsection>
<nextsent>the presence of changes the orthogonality of the vector space model, as this mapping should introduce term dependence.
</nextsent>
<nextsent>a recent attempt tried to manually construct with the help of lexical resource (siolas and dalche?
</nextsent>
<nextsent>buc,2000).
</nextsent>
<nextsent>the entries in the symmetric matrix express the semantic similarity between the terms and j. entries in this matrix are inversely proportional to the length of the wordnet hierarchy path linking the two terms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2709">
<title id=" W09-1123.xml">improving text classification by a sense spectrum approach to term expansion </title>
<section> text classification with support vector.  </section>
<citcontext>
<prevsection>
<prevsent>terms can be corpus- or genre-specific.
</prevsent>
<prevsent>manually constructed general-purpose lexical resources include many usages that are infrequent in particular corpus or genre of documents.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
for example, one of the 8 senses of company in wordnet is visitor/visitant, which is hyponym of person (lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>this sense of the term is practically never used in newspaper articles, hence distributional attributes should be taken into consideration.
</nextsent>
<nextsent>composite measures that combine the advantages of both approaches have also been developed (resnik, 1995; jiang and conrath, 1997).
</nextsent>
<nextsent>this paper relies on thejiang-conrath composite measure (jiang and con rath, 1997), which has been shown to be superior to other measures (budanitsky and hirst, 2006), <papid> J06-1003 </papid>and we also found that this measure works the best for the purpose.</nextsent>
<nextsent>the jiang-conrath metric measures the distance between two senses by using the hierarchy of wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2711">
<title id=" W08-1118.xml">evaluating an ontology driven wysiwym interface </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(handschuh et al, 2001; catarci et al, 2004).
</prevsent>
<prevsent>however, we believe that, for social scientists, natural language is the best medium to use, as the way they conduct their research and the structure of their documents and data indicate that they are more oriented towards text than graphics.
</prevsent>
</prevsection>
<citsent citstr=" P83-1023 ">
natural language approaches include gino (bernstein and kaufmann, 2006), an ontology editor with an approach reminiscent of natural language menus (tennant et al, 1983), <papid> P83-1023 </papid>and using controlled languages such as peng-d (schwitter and til brook, 2004).</citsent>
<aftsection>
<nextsent>such natural language approaches tend to restrict expressivity to ensure that every entry can be parsed, limiting the language and often making it stilted, so that there is small learning curve before the user knows which structures are allowed.
</nextsent>
<nextsent>in order to maintain full expressivity and to shorten the learning curve, we have elected to use wysiwym (what you see is what you meant)(power et al, 1998).
</nextsent>
<nextsent>this is natural language generation approach where the system generates feed 3http://www.w3.org/tr/owl-features/ 138back text for the user that is based on semantic representation.
</nextsent>
<nextsent>this representation is edited directly bythe user by manipulating the feedback text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2712">
<title id=" W08-1118.xml">evaluating an ontology driven wysiwym interface </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is natural language generation approach where the system generates feed 3http://www.w3.org/tr/owl-features/ 138back text for the user that is based on semantic representation.
</prevsent>
<prevsent>this representation is edited directly bythe user by manipulating the feedback text.
</prevsent>
</prevsection>
<citsent citstr=" W06-1414 ">
wysi wym has been used by number of other projects,such as mile (piwek et al, 2000) and clef (hal lett, 2006).<papid> W06-1414 </papid></citsent>
<aftsection>
<nextsent>as evaluation results in both of these projects were very positive (piwek, 2002; hallett etal., 2007), we felt that wysiwym would be suit able approach to use in our work.
</nextsent>
<nextsent>we have developed meta data elicitation tool that enables users to create meta data in the shape of ontology instance data; the tool is driven by the ontologies that define those instances.
</nextsent>
<nextsent>we are currently implementing wysiwym tool for querying, that uses the same interface as the meta data creation tool.
</nextsent>
<nextsent>we also aim to develop tool for presenting the results of the query, and for browsing the descriptions in the database.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2713">
<title id=" W08-1118.xml">evaluating an ontology driven wysiwym interface </title>
<section> ontologies in nlg.  </section>
<citcontext>
<prevsection>
<prevsent>theuser can fine-tune the surface form by adding adjectives, changing morphological information and the root of individual words; actions for which only basic linguistic knowledge is needed.
</prevsent>
<prevsent>this approach is outlined in more detail in (hielkema et al, 2007b).
</prevsent>
</prevsection>
<citsent citstr=" W90-0108 ">
the main challenge with this approach is that the specification is used to generate two surface forms; it remains to be seen whether specification that isfine-tuned through one surface form will accommodate the accurate generation of another.the penman upper model (bateman, 1990) <papid> W90-0108 </papid>supports the specification of linguistic information through different approach.</citsent>
<aftsection>
<nextsent>the upper model is adomain-independent ontology that supports sophisticated nlp.
</nextsent>
<nextsent>to make domain ontology available for nlp, its resources have to be placed in the hierarchy of the upper model; their place there determines their surface realisation.
</nextsent>
<nextsent>this task appears to require considerable linguistic expertise, but like the creation of our dependency trees could probably bemade easier for non-linguists through some special purpose interface.
</nextsent>
<nextsent>the best evaluation of our tool would be to let users deposit their resources in real-life contexts, but our tool is not ready for full deployment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2714">
<title id=" W08-1124.xml">generating baseball summaries from multiple perspectives by reordering content </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the end goal of this work is to build system that takes as input factual description of baseball game and neutral article about the game, then produces two other articles, each from particular teams point of view.there is previous work such as (robin and mckeown, 1996) on automatic summary generation of sports games, but our work goes further to generate multiple summaries.it is first necessary to define what is meant by perspective and multiple perspectives.
</prevsent>
<prevsent>the definition of perspective in this work is somewhat different froma more traditional meaning of perspective in literature, such as the third-person perspective discussed in (wiebe and rapaport, 1988).
</prevsent>
</prevsection>
<citsent citstr=" P06-1133 ">
our definition is much closer to that used in (lin and hauptmann, 2006), <papid> P06-1133 </papid>where they look at ideological perspectives of online articles on political, social, and cultural issues.</citsent>
<aftsection>
<nextsent>they look at the political domain of the issues between israel and palestine, and they try to infer, for each online article, whether it is written from the israeli perspective or the palestinian perspective.
</nextsent>
<nextsent>for our work, we are looking at the domain of baseball games, so we focus on the articles perspective in terms of the home team versus the visiting team.
</nextsent>
<nextsent>we first assume that the two opposing perspectives are expressed in the local news paper articles of the two teams, and we assume thatthe neutral perspective is expressed in the associated press articles published on an espn website (www.espn.com).
</nextsent>
<nextsent>we confirmed these assumptions via user study, then we identified some key factors contributing to an article having certain perspective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2715">
<title id=" W08-1124.xml">generating baseball summaries from multiple perspectives by reordering content </title>
<section> from neutral to one-sided perspective.  </section>
<citcontext>
<prevsection>
<prevsent>to compute the overlap of content, the articles were first tagged with player names and part-of 174 figure 1: pitch by pitch log of baseball game games all home visit 41 215 23 21 ave 5.24 0.56 0.51 table 1: number of at-bats described in all three articles, at-bats only in the home team articles, and at-bats only in the visit team articles for 41 games.
</prevsent>
<prevsent>speech tags, and simple pattern matching heuristics were used to automatically align the sentences in the articles with game events.
</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
the player names were downloaded from the mlb team sites accessible from www.mlb.com, and the pos tagging was done with the stanford pos tagger (toutanova and man ninig, 2000).<papid> W00-1308 </papid></citsent>
<aftsection>
<nextsent>pattern matching heuristics looked for co-occurrences of tags and words within certain window (e.g., {player} and homerun?
</nextsent>
<nextsent>within 3words), and the results from applying those heuristics were aligned with the at-bat feature vectors computed from the game log.
</nextsent>
<nextsent>testing on 45 articles hand-annotated by the first author, we achieveda precision of 79.0% and recall of 79.2% for alignment.
</nextsent>
<nextsent>the average number of at-bats in those hand annotated articles was 8.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2717">
<title id=" W09-0211.xml">a nonnegative tensor factor ization model for selectional preference induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the models generalization relies entirely on wordnet; there is no generalization among the verbs.
</prevsent>
<prevsent>the research in this paper is related to previous work on clustering.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
pereira et al (1993) <papid> P93-1024 </papid>use an information-theoretic based clustering approach, clustering nouns according to their distribution as direct objects among verbs.</citsent>
<aftsection>
<nextsent>their model is one sided clustering model: only the direct objects are clustered, there is no clustering among the verbs.rooth et al (1999) <papid> P99-1014 </papid>use an em-based clustering technique to induce clustering based on theco-occurrence frequencies of verbs with their subjects and direct objects.</nextsent>
<nextsent>as opposed to the method of pereira et al (1993), <papid> P93-1024 </papid>their model is two-sided: the verbs as well as the subjects/direct objects areclustered.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2718">
<title id=" W09-0211.xml">a nonnegative tensor factor ization model for selectional preference induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the research in this paper is related to previous work on clustering.
</prevsent>
<prevsent>pereira et al (1993) <papid> P93-1024 </papid>use an information-theoretic based clustering approach, clustering nouns according to their distribution as direct objects among verbs.</prevsent>
</prevsection>
<citsent citstr=" P99-1014 ">
their model is one sided clustering model: only the direct objects are clustered, there is no clustering among the verbs.rooth et al (1999) <papid> P99-1014 </papid>use an em-based clustering technique to induce clustering based on theco-occurrence frequencies of verbs with their subjects and direct objects.</citsent>
<aftsection>
<nextsent>as opposed to the method of pereira et al (1993), <papid> P93-1024 </papid>their model is two-sided: the verbs as well as the subjects/direct objects areclustered.</nextsent>
<nextsent>we will use similar model for evaluation purposes.recent approaches using distributional similarity methods for the induction of selectional preferences are the ones by erk (2007), <papid> P07-1028 </papid>bhagat et al (2007) <papid> D07-1017 </papid>and basili et al (2007).this research differs from the approaches mentioned above by its use of multi-way data: where the approaches above limit themselves to two-wayco-occurrences, this research will focus on cooccurrences for multi-way data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2720">
<title id=" W09-0211.xml">a nonnegative tensor factor ization model for selectional preference induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>their model is one sided clustering model: only the direct objects are clustered, there is no clustering among the verbs.rooth et al (1999) <papid> P99-1014 </papid>use an em-based clustering technique to induce clustering based on theco-occurrence frequencies of verbs with their subjects and direct objects.</prevsent>
<prevsent>as opposed to the method of pereira et al (1993), <papid> P93-1024 </papid>their model is two-sided: the verbs as well as the subjects/direct objects areclustered.</prevsent>
</prevsection>
<citsent citstr=" P07-1028 ">
we will use similar model for evaluation purposes.recent approaches using distributional similarity methods for the induction of selectional preferences are the ones by erk (2007), <papid> P07-1028 </papid>bhagat et al (2007) <papid> D07-1017 </papid>and basili et al (2007).this research differs from the approaches mentioned above by its use of multi-way data: where the approaches above limit themselves to two-wayco-occurrences, this research will focus on cooccurrences for multi-way data.</citsent>
<aftsection>
<nextsent>2.2 factor ization algorithms.
</nextsent>
<nextsent>2.2.1 two-way factorizations one of the best known factor ization algorithms is principal component analysis (pca, pearson(1901)).
</nextsent>
<nextsent>pca transforms the data into newco ordinate system, yielding the best possible fit in aleast square sense given limited number of dimensions.
</nextsent>
<nextsent>singular value decomposition (svd)is the generalization of the eigenvalue decomposition used in pca (wall et al, 2003).in information retrieval, singular value decomposition has been applied in latent semantic analysis (lsa, landauer and dumais (1997), landauer et al (1998)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2721">
<title id=" W09-0211.xml">a nonnegative tensor factor ization model for selectional preference induction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>their model is one sided clustering model: only the direct objects are clustered, there is no clustering among the verbs.rooth et al (1999) <papid> P99-1014 </papid>use an em-based clustering technique to induce clustering based on theco-occurrence frequencies of verbs with their subjects and direct objects.</prevsent>
<prevsent>as opposed to the method of pereira et al (1993), <papid> P93-1024 </papid>their model is two-sided: the verbs as well as the subjects/direct objects areclustered.</prevsent>
</prevsection>
<citsent citstr=" D07-1017 ">
we will use similar model for evaluation purposes.recent approaches using distributional similarity methods for the induction of selectional preferences are the ones by erk (2007), <papid> P07-1028 </papid>bhagat et al (2007) <papid> D07-1017 </papid>and basili et al (2007).this research differs from the approaches mentioned above by its use of multi-way data: where the approaches above limit themselves to two-wayco-occurrences, this research will focus on cooccurrences for multi-way data.</citsent>
<aftsection>
<nextsent>2.2 factor ization algorithms.
</nextsent>
<nextsent>2.2.1 two-way factorizations one of the best known factor ization algorithms is principal component analysis (pca, pearson(1901)).
</nextsent>
<nextsent>pca transforms the data into newco ordinate system, yielding the best possible fit in aleast square sense given limited number of dimensions.
</nextsent>
<nextsent>singular value decomposition (svd)is the generalization of the eigenvalue decomposition used in pca (wall et al, 2003).in information retrieval, singular value decomposition has been applied in latent semantic analysis (lsa, landauer and dumais (1997), landauer et al (1998)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2722">
<title id=" W09-0211.xml">a nonnegative tensor factor ization model for selectional preference induction </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus has been parsed with the dutch dependency parser alpino (van noord, 2006), and three-way co-occurrences of verbs with their respective subject and direct object relations have been extracted.
</prevsent>
<prevsent>as dimension sizes, the 1k most frequent verbs were used, together with the 10k most frequent subjects and10k most frequent direct objects, yielding ten sor of 1k ? 10k ? 10k.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
the resulting tensor isvery sparse, with only 0.0002% of the values being non-zero.the tensor has been adapted with straightforward extension of pointwise mutual information (church and hanks, 1990) <papid> J90-1003 </papid>for three-way cooccurrences, following equation 4.</citsent>
<aftsection>
<nextsent>negative values are set to zero.22this is not just an ad hoc conversion to enforce non negativity.
</nextsent>
<nextsent>negative values indicate smaller co-occurrenceprobability than the expected number of co-occurrences.
</nextsent>
<nextsent>setting those values to zero proves beneficial for similarity calculations (see e.g. bullinaria and levy (2007)).
</nextsent>
<nextsent>mi3(x,y,z) = log p(x,y,z) p(x)p(y)p(z) (4) the resulting matrix has been factor ized into dimensions (varying between 50 and 300) with the ntf algorithm described in section 3.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2724">
<title id=" W08-2134.xml">a cascaded syntactic and semantic dependency parsing system </title>
<section> semantic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>for each predicate, the probabilities of word in the sentence to be each semantic role are predicted in the semantic role classification stage.
</prevsent>
<prevsent>maximum entropy model is selected as our classifiers in thesestages.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
finally an ilp (integer linear programming) based method is adopted for post inference (punyakanok et al, 2004).<papid> C04-1197 </papid></citsent>
<aftsection>
<nextsent>3.2 predicate identification.
</nextsent>
<nextsent>the predicate identification is treated as binary classification problem.
</nextsent>
<nextsent>each word in sentence is predicted to be predicate or not to be.
</nextsent>
<nextsent>a set of features are extracted for each word, and an optimized subset of them are adopted in our final system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2725">
<title id=" W08-2134.xml">a cascaded syntactic and semantic dependency parsing system </title>
<section> semantic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the final optimized feature set for the task of predicate classification is (a1, a21, a23, a71, a72, a73, a74, a81, a82, a83, a84, a9, b11, b12, b22, b3, a71+a9).
</prevsent>
<prevsent>3.4 semantic role classification.
</prevsent>
</prevsection>
<citsent citstr=" W05-0627 ">
in our system, the identification and classification of semantic roles are achieved in single stage (liu et al, 2005) <papid> W05-0627 </papid>through one single classifier (actually two, one for noun predicates, and the other for verb predicates).</citsent>
<aftsection>
<nextsent>each word in sentence is given probabilities to be each semantic role (in cluding none of the these roles) for predicate.features introduced in addition to those of the previous subsections are the following: pos path (c11), rel path (c12): the pos path?
</nextsent>
<nextsent>feature consists of pos tags of the words along the path from word to the predicate.
</nextsent>
<nextsent>other than up?
</nextsent>
<nextsent>and down?, the left?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2726">
<title id=" W09-1112.xml">minimally supervised model of early language acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>21-month-olds use the number of nouns to understand sentences containing new verbs (yuan et al , 2007), generalize what they have learned about transitive word-order to new verbs (gertner et al , 2006), and make the predicted error, treating in transitive sentences containing two nouns as if they were transitive (gert ner and fisher, 2006).
</prevsent>
<prevsent>by 25 months, children have learned enough about english syntax to interpretconjoined-subject intransitives differently from tran sitives (naigles, 1990).
</prevsent>
</prevsection>
<citsent citstr=" W08-2111 ">
our previous computational experiments with asystem for automatic semantic role labeling (con nor et al , 2008) <papid> W08-2111 </papid>suggest that it is possible to learn to assign basic semantic roles based on the simple representations proposed by the structure-mapping view.</citsent>
<aftsection>
<nextsent>the classifiers features were limited to lexical information (nouns and verbs only) and the number and order of nouns in the sentence, and trained on asample of child-directed speech annotated in propbank (kingsbury and palmer, 2002) style.
</nextsent>
<nextsent>given this training, our classifier learned to label the first of two nouns as an agent and the second as patient.
</nextsent>
<nextsent>even amid the variability of casual speech, simply representing the target word as the first or the second of two nouns significantly boosts srl performance (relative to lexical baseline) on transitive sentences containing novel verbs.
</nextsent>
<nextsent>this result depends on key assumptions of the structure-mapping view, including abstract representations of semantic roles, and abstract but simple representations of sentence structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2727">
<title id=" W09-1112.xml">minimally supervised model of early language acquisition </title>
<section> learning model.  </section>
<citcontext>
<prevsection>
<prevsent>is single name, but they do not know all the predicating terms that may link multiple nouns into single noun phrase.
</prevsent>
<prevsent>the simplified learning task of the babysrl implements key assumption of the structure-mapping account:that at the start of multiword sentence comprehension children can tell which words in sentence are nouns (waxman and booth, 2001), and treat each noun as candidate argument.we further simplify the srl task such that classification is between two macro-roles: a0 (agent) and a1 (non-agent; all non-a0 arguments).
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
we did so because we reason that this simplified feedback scheme can be primarily informative for first stageof learning in which learners identify how their language identifies agents vs. non-agents in sentences.in addition, this level of role granularity is more consistent across verbs (palmer et al , 2005).<papid> J05-1004 </papid>for argument classification we use linear classifier trained with regularized perceptron update rule (grove and roth, 2001).</citsent>
<aftsection>
<nextsent>this learning algorithm provides simple and general linear classifier that works well in other language tasks, and allows us to inspect the weights of key features to determine their importance for classification.
</nextsent>
<nextsent>for the final predictions, the classifier usespredicate-level inference to ensure coherent argument assignments.
</nextsent>
<nextsent>in our task the only active constraints are that all nouns require tag, and that they have unique labels, which for this restricted case of a0 vs. not a0 means there will be only one agent.
</nextsent>
<nextsent>2.1 training and feedback.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2746">
<title id=" W08-1705.xml">speeding up lfg parsing using cstructure pruning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical breakdown of parsing time of xle components with the english grammar is morphology (1.6%), chart (5.8%) and unifier (92.6%).
</prevsent>
<prevsent>it is clear that the major bottleneck in processing is in unification.
</prevsent>
</prevsection>
<citsent citstr=" W07-1209 ">
cahill et al (2007) <papid> W07-1209 </papid>carried out preliminary experiment to test the theory that if fewer c-structures were passed to the unifier, overall parsing times would improve,while the accuracy of parsing would remain stable.</citsent>
<aftsection>
<nextsent>their experiments used state-of-the-art probabilistic treebank-based parsers to automatically ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>mark certain constituents on the input sentences,limiting the number of c-structures the xle parsing system would build.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2750">
<title id=" W08-1705.xml">speeding up lfg parsing using cstructure pruning </title>
<section> xle and the c-structure pruning.  </section>
<citcontext>
<prevsection>
<prevsent>the probability of tree is the product of the probabilities of each of the rules used to form the tree, including the rules that lead to lexical items (such as ? dog).
</prevsent>
<prevsent>the probability of rule is basically the number of times that that particular form of therule occurs in the training data divided by the number of times the rules category occurs in the training data, plus smoothing term.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
this is similar to the pruning described in charniak and johnson(2005) <papid> P05-1022 </papid>where edges in coarse-grained parse forest are pruned to allow full evaluation with fine grained categories.the pruner prunes at the level of individual constituents in the chart.</citsent>
<aftsection>
<nextsent>it calculates the probabilities of each of the subtrees of constituent and compares them.
</nextsent>
<nextsent>the probability of each subtree is compared with the best subtree probability for that constituent.
</nextsent>
<nextsent>if subtrees probability is lower than the best probability by given factor, then the subtree is pruned.
</nextsent>
<nextsent>in practice, the threshold is the natural logarithm of the factor used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2751">
<title id=" W08-1705.xml">speeding up lfg parsing using cstructure pruning </title>
<section> experiments on german.  </section>
<citcontext>
<prevsection>
<prevsent>this resulted in 25,677 full parses,21,279 fragmented parses and 1,518 parse failures.1 there are 52,959 features in the final pruning model.
</prevsent>
<prevsent>to establish the optimal pruning settings for german, we split the 2,000 saved sentences into371 development sentences and 1495 test sentences for final evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W04-1905 ">
we evaluated against the tiger dependency bank (forst et al, 2004) (<papid> W04-1905 </papid>tigerdb), dependency-based gold standard for german parsers that encodes grammatical relations similar to, though more fine-grained than,the ones in the tiger treebank as well as morphosyntactic features.</citsent>
<aftsection>
<nextsent>we experimented with the same pruning levels as in the english experiments.
</nextsent>
<nextsent>the results are given in table 3.the results on the development set show similar trend to the english results.
</nextsent>
<nextsent>a cutoff of 4 results in the fastest system, however at the expense1the reason there are more fragment parses than, forex ample, the results reported in rohrer and forst (2006) is that the bracketed input constrains the parser to only return parses compatible with the bracketed input.
</nextsent>
<nextsent>if there is no solution compatible with the brackets, then fragment parse is returned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2752">
<title id=" W08-1705.xml">speeding up lfg parsing using cstructure pruning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the sentences we extracted all contained examples of proper noun coordination and had been automatically chunked.
</prevsent>
<prevsent>training on this sub-corpus as well as the original tiger training data did have the desired effect of now parsing example (13) with c-structure pruning activated.
</prevsent>
</prevsection>
<citsent citstr=" W05-1511 ">
ninomiya et al (2005) <papid> W05-1511 </papid>investigate beam thresholding based on the local width to improve the speed of probabilistic hpsg parser.</citsent>
<aftsection>
<nextsent>in each cell of cyk chart, the method keeps only portion of the edges which have higher figure of merits compared to the other edges in the same cell.
</nextsent>
<nextsent>in particular, each cell keeps the edges whose figure of merit is greater than ? max - ?, where ? maxis the highest figure of merit among the edges in the chart.
</nextsent>
<nextsent>the term beam thresholding?
</nextsent>
<nextsent>is little confusing, since beam search is not necessary ? instead, the cyk chart is pruned directly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2756">
<title id=" W08-2119.xml">a treetostring phrase based model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experimental results of english-japanese and english-vietnamese translation showed significant improvement over two baseline phrase-based smt systems.
</prevsent>
<prevsent>based on the kind of linguistic information which is made use of, syntactic smt can be divided into four types: tree-to-string, string-to-tree, tree-to-tree,and hierarchical phrase-based.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
the tree-to-string approach (collins et al, 2005; nguyen and shimazu,2006; liu et al, 2006 <papid> P06-1077 </papid>and 2007) supposes that syntax of the source language is known.</citsent>
<aftsection>
<nextsent>this approach can be applied when source language parser is available.
</nextsent>
<nextsent>the string-to-tree approach (yamada and knight, 2001; galley et al, 2006) focuses on syntactic modelling of the target language in cases it has syntactic resources such as treebanks and parsers.
</nextsent>
<nextsent>thetree-to-tree approach models the syntax of both languages, therefore extra cost is required.
</nextsent>
<nextsent>the fourth approach (chiang, 2005) constraints phrases undercontext-free grammar structure without any requirement of linguistic annotation.in this paper, we present tree-to-string phrase based method which is based on synchronous cfgs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2760">
<title id=" W08-2119.xml">a treetostring phrase based model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>liu et al (2006) <papid> P06-1077 </papid>changed the translation unit from phrases to tree-to-string alignment templates (tats) while we do not.</prevsent>
<prevsent>tats was represented as xrs rules while we use synchronous cfg rules.</prevsent>
</prevsection>
<citsent citstr=" P07-1089 ">
in order to overcome the limitation thattats can not capture non-constituent phrasal translations, liu et al (2007) <papid> P07-1089 </papid>proposed forest-to-string rules while our system can naturally make use of such kindof phrasal translation by word-to-phrase tree trans for mation.</citsent>
<aftsection>
<nextsent>we carried out experiments with two language pairs english-japanese and english-vietnamese.
</nextsent>
<nextsent>our system achieved significant improvements over pharaoh, state-of-the-art phrase-based smt system.we also analyzed the dependence of translation quality on the level of syntactic analysis (shallow or deep).
</nextsent>
<nextsent>figure 1 shows the architecture of our system.
</nextsent>
<nextsent>the input of this system is source-language tree and the output is target-language string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2763">
<title id=" W08-2119.xml">a treetostring phrase based model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows the architecture of our system.
</prevsent>
<prevsent>the input of this system is source-language tree and the output is target-language string.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
this system uses all features of conventional phrase-based smt as in(koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>there are two new features including word-to-phrase tree transformation mod eland phrase reordering model.
</nextsent>
<nextsent>the decoding algo 1see section 6.2.
</nextsent>
<nextsent>143 rithm is tree-based search algorithm.figure 1: syntax-directed phrase-based smt architecture.
</nextsent>
<nextsent>we use an example of english-vietnamese translation to demonstrate the translation process as in figure 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2767">
<title id=" W08-2119.xml">a treetostring phrase based model for statistical machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>a number of tools were used in our experiments.vietnamese sentences were segmented using word segmentation program (nguyen et al, 2003).
</prevsent>
<prevsent>for learning phrase translations and decoding, we used pharaoh (koehn, 2004), state-of-the-art phrase based smt system which is available for research purpose.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
for word alignment, we used the giza++ tool (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>for learning language models, we used srilm toolkit (stolcke, 2002).
</nextsent>
<nextsent>for mt evaluation, we used bleu measure (papineni et al., 2001) calculated by the nist script version 11b.for the parsing task, we used charniaks parser (charniak, 2000).
</nextsent>
<nextsent>for experiments with chunking (or shallow parsing), we used crfs-based chunking tool 5 to split source sentence into syntactic chunks.
</nextsent>
<nextsent>then pseudo cfg rule over chunks is built to generate two-level syntactic tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2775">
<title id=" W08-2119.xml">a treetostring phrase based model for statistical machine translation </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>by word to-phrase tree transformation, all possible phrases are considered in translation.
</prevsent>
<prevsent>our method does not suppose uniform distribution over all possible phrase segment ations as (koehn et al, 2003) <papid> N03-1017 </papid>since each phrase tree has probability.</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
we believe that other kinds of translation unit such as n-gram (jos et al, 2006), factored phrasal translation (koehn and hoang, 2007), <papid> D07-1091 </papid>or treelet (quirk et al, 2005) can be used in this method.</citsent>
<aftsection>
<nextsent>we would like to consider this problem as future study.
</nextsent>
<nextsent>moreover we would like to use n-best trees as the input of our system.
</nextsent>
<nextsent>a number 149 method input theoretical decoding style linguistic phrase performance model information usage koehn et al (2003) <papid> N03-1017 </papid>string fsts beam search no yes baseline yamada and knight (2001) string scfgs parsing target no not better melamed (2003) string scfgs parsing both sides no not better chiang (2005) string scfgs parsing no yes better quirk et al (2005) dep.</nextsent>
<nextsent>tree tts parsing source yes better galley et al (2006) string tts parsing target yes better liu et al (2006) <papid> P06-1077 </papid>tree tts tree transf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2786">
<title id=" W08-2133.xml">semantic dependency parsing using nbest semantic role sequences and roleset information </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the argument identification uses different strategies for verbs, nouns, and other predicates.the argument classifier extracts features and labels semantic roles.
</prevsent>
<prevsent>none is used to indicate that word is not semantic argument.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
the classifier also uses different maximum entropy models for verbs, nouns, and other predicates 2.3.1 argument candidate identification as mentioned by pradhan et al (2004), <papid> N04-1030 </papid>argument identification poses significant bottle neck to improving performance of semantic role labeling system.</citsent>
<aftsection>
<nextsent>we tried an algorithm motivated from hacioglu (2004) <papid> C04-1186 </papid>which defined tree structured family membership of predicate to identify more probable argument candidates and prune the others.</nextsent>
<nextsent>however, we find that it works for verb and other predicate type, but does not work properly for noun predicate type.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2787">
<title id=" W08-2133.xml">semantic dependency parsing using nbest semantic role sequences and roleset information </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>none is used to indicate that word is not semantic argument.
</prevsent>
<prevsent>the classifier also uses different maximum entropy models for verbs, nouns, and other predicates 2.3.1 argument candidate identification as mentioned by pradhan et al (2004), <papid> N04-1030 </papid>argument identification poses significant bottle neck to improving performance of semantic role labeling system.</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
we tried an algorithm motivated from hacioglu (2004) <papid> C04-1186 </papid>which defined tree structured family membership of predicate to identify more probable argument candidates and prune the others.</citsent>
<aftsection>
<nextsent>however, we find that it works for verb and other predicate type, but does not work properly for noun predicate type.
</nextsent>
<nextsent>the main reason is due to the characteristics of arguments of noun predicates.
</nextsent>
<nextsent>first of all, noun predicate can be an argument for itself, whereas verb predicate cannot be.
</nextsent>
<nextsent>secondly, dependency relation paths from noun predicate to its arguments are usually shorter than verb predicate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2789">
<title id=" W08-2133.xml">semantic dependency parsing using nbest semantic role sequences and roleset information </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 global semantic role sequence.
</prevsent>
<prevsent>generation for local semantic role labeling, we assume that semantic roles of words are independent of each other.
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
toutanova et al (2005) <papid> P05-1073 </papid>and surdeanu etal.</citsent>
<aftsection>
<nextsent>(2007) show that global constraint and optimization are important in semantic role labeling.we use cky-based dynamic programming strategy, similar to surdeanu et al (2007), to verify whether role sequences satisfy global constraint and generate candidates of global semantic role sequences.
</nextsent>
<nextsent>in this paper, we just use one constraint: no duplicate arguments are allowed for verbal predicates.
</nextsent>
<nextsent>for verbal predicates, cky module builds list of all kinds of combinations of semantic roles augmented with their probabilities.
</nextsent>
<nextsent>while building the list of semantic role sequences, it removes the sequences that violate the global constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2791">
<title id=" W08-2203.xml">semantic representations of syntactically marked discourse status in cross linguistic perspective </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we explore how their approach leads to cross-linguistically unified treatments of demonstratives, overt pronouns and null anaphora as well.
</prevsent>
<prevsent>we find that cross-linguistic studies motivate different representations than we might have arrived at from just one language.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
our work grows out of the grammar matrix, multilingual grammar engineering project (bender et al, 2002; <papid> W02-1502 </papid>bender and flickinger, 2005) <papid> I05-2035 </papid>which strives to harmonize semantic representations across diverse languages.</citsent>
<aftsection>
<nextsent>the grammar matrix is couched within the head-driven phrase structure grammar (hpsg) framework (pollard and sag, 1994).
</nextsent>
<nextsent>we use minimal recur sion semantics (copestake et al, 2001, <papid> P01-1019 </papid>2005) as our semantic representation system.</nextsent>
<nextsent>2.1 minimal recur sion semantics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2792">
<title id=" W08-2203.xml">semantic representations of syntactically marked discourse status in cross linguistic perspective </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we explore how their approach leads to cross-linguistically unified treatments of demonstratives, overt pronouns and null anaphora as well.
</prevsent>
<prevsent>we find that cross-linguistic studies motivate different representations than we might have arrived at from just one language.
</prevsent>
</prevsection>
<citsent citstr=" I05-2035 ">
our work grows out of the grammar matrix, multilingual grammar engineering project (bender et al, 2002; <papid> W02-1502 </papid>bender and flickinger, 2005) <papid> I05-2035 </papid>which strives to harmonize semantic representations across diverse languages.</citsent>
<aftsection>
<nextsent>the grammar matrix is couched within the head-driven phrase structure grammar (hpsg) framework (pollard and sag, 1994).
</nextsent>
<nextsent>we use minimal recur sion semantics (copestake et al, 2001, <papid> P01-1019 </papid>2005) as our semantic representation system.</nextsent>
<nextsent>2.1 minimal recur sion semantics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2793">
<title id=" W08-2203.xml">semantic representations of syntactically marked discourse status in cross linguistic perspective </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work grows out of the grammar matrix, multilingual grammar engineering project (bender et al, 2002; <papid> W02-1502 </papid>bender and flickinger, 2005) <papid> I05-2035 </papid>which strives to harmonize semantic representations across diverse languages.</prevsent>
<prevsent>the grammar matrix is couched within the head-driven phrase structure grammar (hpsg) framework (pollard and sag, 1994).</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
we use minimal recur sion semantics (copestake et al, 2001, <papid> P01-1019 </papid>2005) as our semantic representation system.</citsent>
<aftsection>
<nextsent>2.1 minimal recur sion semantics.
</nextsent>
<nextsent>grammar matrix-derived grammars associate surface strings with mrs representations (or mrss), in bidirectional mapping that allows both parsing and generation.
</nextsent>
<nextsent>an mrs consists of multi set of elementary predications (eps), each of which is asingle relation with its associated arguments, labeled by handle; set of handle constraints relating the labels of eps to argument positions within other eps; and top handle indicating which of the labels has outermost scope (copestake et al, 2001, <papid> P01-1019 </papid>2005).</nextsent>
<nextsent>the mrss produced by these grammars are underspecified for scope, allowing multiple different fully-scoped variants, according to the handle constraints.each ep has predicate (pred) value and one or more argument positions, usually labeled arg0 through argn.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2799">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we focus on the following linguistic phenomena: passive, control and raising, noun modifiers, and meaningful vs. non-meaningful prepositions.
</prevsent>
<prevsent>we conclude that no one system provides all the features that we require, although each such feature is contained within at least one of the competing systems.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the aim of the work reported in this paper is to evaluate the extent to which proposed systems of grammatical relations (grs) reflect the kinds of deep linguistic knowledge required for semantic interpretation, in particular for deriving semantic representations suitable for domain reasoning in dialogue systems.grammatical relations either produced by or extracted from the output of wide-coverage syntactic parsers are currently used as input to shallow semantic parsers, which identify semantic relations that exist between predicators (typically verbs) and their dependents (gildea and jurafsky, 2002; <papid> J02-3001 </papid>erk and pado, 2006).</citsent>
<aftsection>
<nextsent>predicate-argument structure identified in this way can then be used in tasks like information extraction (surdeanu et al, 2003) <papid> P03-1002 </papid>and question answering (kaisser and webber, 2007).<papid> W07-1206 </papid></nextsent>
<nextsent>c ? 2008.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2800">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we conclude that no one system provides all the features that we require, although each such feature is contained within at least one of the competing systems.
</prevsent>
<prevsent>the aim of the work reported in this paper is to evaluate the extent to which proposed systems of grammatical relations (grs) reflect the kinds of deep linguistic knowledge required for semantic interpretation, in particular for deriving semantic representations suitable for domain reasoning in dialogue systems.grammatical relations either produced by or extracted from the output of wide-coverage syntactic parsers are currently used as input to shallow semantic parsers, which identify semantic relations that exist between predicators (typically verbs) and their dependents (gildea and jurafsky, 2002; <papid> J02-3001 </papid>erk and pado, 2006).</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
predicate-argument structure identified in this way can then be used in tasks like information extraction (surdeanu et al, 2003) <papid> P03-1002 </papid>and question answering (kaisser and webber, 2007).<papid> W07-1206 </papid></citsent>
<aftsection>
<nextsent>c ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>however, wide-coverage stochastic parsers areonly rarely used in dialogue systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2801">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we conclude that no one system provides all the features that we require, although each such feature is contained within at least one of the competing systems.
</prevsent>
<prevsent>the aim of the work reported in this paper is to evaluate the extent to which proposed systems of grammatical relations (grs) reflect the kinds of deep linguistic knowledge required for semantic interpretation, in particular for deriving semantic representations suitable for domain reasoning in dialogue systems.grammatical relations either produced by or extracted from the output of wide-coverage syntactic parsers are currently used as input to shallow semantic parsers, which identify semantic relations that exist between predicators (typically verbs) and their dependents (gildea and jurafsky, 2002; <papid> J02-3001 </papid>erk and pado, 2006).</prevsent>
</prevsection>
<citsent citstr=" W07-1206 ">
predicate-argument structure identified in this way can then be used in tasks like information extraction (surdeanu et al, 2003) <papid> P03-1002 </papid>and question answering (kaisser and webber, 2007).<papid> W07-1206 </papid></citsent>
<aftsection>
<nextsent>c ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>however, wide-coverage stochastic parsers areonly rarely used in dialogue systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2802">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>however, wide-coverage stochastic parsers areonly rarely used in dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to small domain (seneff, 1992; <papid> J92-1004 </papid>chang et al, 2002), or wide coverage deep parsers (allen et al, 2007; <papid> W07-1207 </papid>jordan et al, 2006; wolska and kruijff-korbayova, 2003; callaway et al., 2007; kay et al, 1994).</citsent>
<aftsection>
<nextsent>unlike in information retrieval and question answering tasks, the system often needs to be connected to knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries.
</nextsent>
<nextsent>in addition to identifying predicate argument relationships, such systems need to support variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and modality.while deep parsers produce precise semantic representations appropriate for such reasoning, they suffer from robustness problems.
</nextsent>
<nextsent>wide coverage dependency parsers could potentially provide more robust alternative, provided that their output is easy to convert into semantic representations for reasoning.section 2 introduces the kind of deep linguistic processing application which motivates our approach to grammatical relations.
</nextsent>
<nextsent>section 3 defines some underlying principles behind the kindof deep?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2803">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>however, wide-coverage stochastic parsers areonly rarely used in dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" W07-1207 ">
traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to small domain (seneff, 1992; <papid> J92-1004 </papid>chang et al, 2002), or wide coverage deep parsers (allen et al, 2007; <papid> W07-1207 </papid>jordan et al, 2006; wolska and kruijff-korbayova, 2003; callaway et al., 2007; kay et al, 1994).</citsent>
<aftsection>
<nextsent>unlike in information retrieval and question answering tasks, the system often needs to be connected to knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries.
</nextsent>
<nextsent>in addition to identifying predicate argument relationships, such systems need to support variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and modality.while deep parsers produce precise semantic representations appropriate for such reasoning, they suffer from robustness problems.
</nextsent>
<nextsent>wide coverage dependency parsers could potentially provide more robust alternative, provided that their output is easy to convert into semantic representations for reasoning.section 2 introduces the kind of deep linguistic processing application which motivates our approach to grammatical relations.
</nextsent>
<nextsent>section 3 defines some underlying principles behind the kindof deep?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2804">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>1we used simplified representation of quantifiers that assumes no scope ambiguity and uses skolem constants to represent existential quantification.
</prevsent>
<prevsent>this is sufficient for our particular application.
</prevsent>
</prevsection>
<citsent citstr=" C02-1067 ">
in general, more sophisticated quantifier representation would be necessary, for example that proposed in copestake et al (2005) or bos and oka (2002), <papid> C02-1067 </papid>but we leave the relevant evaluation for future work.</citsent>
<aftsection>
<nextsent>52
</nextsent>
<nextsent>we formulated four principles for deep grammatical relations representation.
</nextsent>
<nextsent>firstly, grammatical relations should, whenever possible, reflect relations between the predicators (i.e. content words as opposed to function words) in sentence.
</nextsent>
<nextsent>in addition, the same relation should correspond to the same role assignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2805">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> passive.  </section>
<citcontext>
<prevsection>
<prevsent>thus, for example, the analysis of tax induction is activated by the rela subunit will contain the gr dobj(activated,induction), and that of the proposed rules will include dobj(proposed,rules), where dobj is the relation between transitive verb and its (deep) direct object.we evaluated five gr-based output formats according to these two features.
</prevsent>
<prevsent>the results are presented in table 1, where for each representation format (the rows) and each usage class of passive participles (the columns), we provide the gr which goes from the participle to its deep object, 53 complement of complement of nominal nominal passive auxiliary raising verb post modifier pre modifier active hpsg arg2 (of verb arg12) rasp ncsubj:obj dobj ccgbank spss\np n/n s\np/[np] stanford nsubjpass - dobj parc subj - obj table 1: representation of deep objects in passive and active if such gr exists.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
3 the five gr representations compared are: hpsg predicate-argument structures extracted from the university of tokyo hpsg treebank (miyao, 2006) rasp grammatical relations as output by the rasp parser (briscoe et al, 2006)<papid> P06-4020 </papid>ccgbank predicate-argument dependencies extracted from ccgbank (hockenmaier and steedman, 2007) stanford grammatical relations output by the stanford parser (de marneffe et al, 2006)parc dependency structures used in the annotation of depbank (king et al, 2003) the first four columns in table 1 represent, for each of the four uses of passive participles listed above, the grammatical relation, if any, which typically joins passive participle to its deep object.</citsent>
<aftsection>
<nextsent>the rightmost column presents the label used for this relation in equivalent active clauses.
</nextsent>
<nextsent>adjacent columns have been collapsed where the same gr is used for both uses.
</nextsent>
<nextsent>the ideal system would have the same gr listed in each of the five columns.the grammatical relations used in the stanford, parc and rasp systems are atomic labels like subj, obj etc, although the latter system does allow for limited range of composite grs like ncsubj:obj (a non-clausal surface subject which realises deep object).
</nextsent>
<nextsent>in the hpsg system, verbal subjects and objects are represent edas arg1 and arg2 respectively of strict transitive verb type verb arg12.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2807">
<title id=" W08-1308.xml">lsquodeep grammatical relations for semantic interpretation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we conclude that none of the proposedgr annotation schemes contains everything we require for deep semantic processing, although each of the features/distinctions we included in our list of desiderata is provided by at least one system.many of the deep syntactic phenomena discussed here are known issues for shallow semantic tasks like semantic role labelling.
</prevsent>
<prevsent>for example, passive constructions are recognised source of noise in semantic role labelling systems (gildeaand jurafsky, 2002), <papid> J02-3001 </papid>and resolving controlled subjects provides more data for training models of selectional restrictions, which are known to be useful features for role labelling.</prevsent>
</prevsection>
<citsent citstr=" W03-1006 ">
more generally, chen and rambow (2003) <papid> W03-1006 </papid>demonstrate that focus on deep?</citsent>
<aftsection>
<nextsent>syntactic features results in more accurate stochastic semantic role lab eller than using surface information alone.note also that the deep grammatical role representation proposed here is meant to be theory neutral?, in the sense that it was not influenced by any one of the competing grammar formalisms to the exclusion of the others.
</nextsent>
<nextsent>indeed, it should be straightforward task to write grammar using either the hpsg, lfg, ccg or rasp-style underlying formalism which can produce an output representation consisting of deep relations, constructed in purely compositional manner.
</nextsent>
<nextsent>indeed, the syntactic phenomena discussed in this pape rare those which form the basis of numerous introductory textbooks on english generative syntax(haegeman, 1994; sag and wasow, 1999; bresnan, 2000).
</nextsent>
<nextsent>in addition, the phenomena which form the basis of the analysis in this paper were among those which had been the focus of significant amount of attention in the development of the semantic interpretation system underlying our domain-independent tutorial dialogue system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2808">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it lies at the heart of unsupervised learning, which has great potential advantages over supervised learning.
</prevsent>
<prevsent>this is especially true for nlp, due to the high efforts and costs incurred by the human annotations required for training supervised algorithms.
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
recent nlp problems addressed by clustering include pos induction (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007), <papid> P07-1094 </papid>word sense disambiguation (shin and choi, 2004), semantic role labeling (baldewein et al, 2004), <papid> W04-0817 </papid>pitch accent type disambiguation (levow, 2006) <papid> N06-1029 </papid>and grammar induction (klein, 2005).</citsent>
<aftsection>
<nextsent>evaluation of clustering results is challenging task.
</nextsent>
<nextsent>in this paper we address the external measures setting, where correct assignment of elements to classes is available and is used for evaluating the quality of another assignment of the elements intoclusters.
</nextsent>
<nextsent>many nlp works have used external clustering evaluation measures (see section 2).
</nextsent>
<nextsent>recently, two measures have been proposed that avoid many of the weaknesses of previous measure sand exhibit several attractive properties (see sections 2 and 3): the vi measure (meila, 2007) and the measure (rosenberg and hirschberg, 2007).<papid> D07-1043 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2809">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it lies at the heart of unsupervised learning, which has great potential advantages over supervised learning.
</prevsent>
<prevsent>this is especially true for nlp, due to the high efforts and costs incurred by the human annotations required for training supervised algorithms.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
recent nlp problems addressed by clustering include pos induction (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007), <papid> P07-1094 </papid>word sense disambiguation (shin and choi, 2004), semantic role labeling (baldewein et al, 2004), <papid> W04-0817 </papid>pitch accent type disambiguation (levow, 2006) <papid> N06-1029 </papid>and grammar induction (klein, 2005).</citsent>
<aftsection>
<nextsent>evaluation of clustering results is challenging task.
</nextsent>
<nextsent>in this paper we address the external measures setting, where correct assignment of elements to classes is available and is used for evaluating the quality of another assignment of the elements intoclusters.
</nextsent>
<nextsent>many nlp works have used external clustering evaluation measures (see section 2).
</nextsent>
<nextsent>recently, two measures have been proposed that avoid many of the weaknesses of previous measure sand exhibit several attractive properties (see sections 2 and 3): the vi measure (meila, 2007) and the measure (rosenberg and hirschberg, 2007).<papid> D07-1043 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2810">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it lies at the heart of unsupervised learning, which has great potential advantages over supervised learning.
</prevsent>
<prevsent>this is especially true for nlp, due to the high efforts and costs incurred by the human annotations required for training supervised algorithms.
</prevsent>
</prevsection>
<citsent citstr=" W04-0817 ">
recent nlp problems addressed by clustering include pos induction (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007), <papid> P07-1094 </papid>word sense disambiguation (shin and choi, 2004), semantic role labeling (baldewein et al, 2004), <papid> W04-0817 </papid>pitch accent type disambiguation (levow, 2006) <papid> N06-1029 </papid>and grammar induction (klein, 2005).</citsent>
<aftsection>
<nextsent>evaluation of clustering results is challenging task.
</nextsent>
<nextsent>in this paper we address the external measures setting, where correct assignment of elements to classes is available and is used for evaluating the quality of another assignment of the elements intoclusters.
</nextsent>
<nextsent>many nlp works have used external clustering evaluation measures (see section 2).
</nextsent>
<nextsent>recently, two measures have been proposed that avoid many of the weaknesses of previous measure sand exhibit several attractive properties (see sections 2 and 3): the vi measure (meila, 2007) and the measure (rosenberg and hirschberg, 2007).<papid> D07-1043 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2811">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it lies at the heart of unsupervised learning, which has great potential advantages over supervised learning.
</prevsent>
<prevsent>this is especially true for nlp, due to the high efforts and costs incurred by the human annotations required for training supervised algorithms.
</prevsent>
</prevsection>
<citsent citstr=" N06-1029 ">
recent nlp problems addressed by clustering include pos induction (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007), <papid> P07-1094 </papid>word sense disambiguation (shin and choi, 2004), semantic role labeling (baldewein et al, 2004), <papid> W04-0817 </papid>pitch accent type disambiguation (levow, 2006) <papid> N06-1029 </papid>and grammar induction (klein, 2005).</citsent>
<aftsection>
<nextsent>evaluation of clustering results is challenging task.
</nextsent>
<nextsent>in this paper we address the external measures setting, where correct assignment of elements to classes is available and is used for evaluating the quality of another assignment of the elements intoclusters.
</nextsent>
<nextsent>many nlp works have used external clustering evaluation measures (see section 2).
</nextsent>
<nextsent>recently, two measures have been proposed that avoid many of the weaknesses of previous measure sand exhibit several attractive properties (see sections 2 and 3): the vi measure (meila, 2007) and the measure (rosenberg and hirschberg, 2007).<papid> D07-1043 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2812">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we address the external measures setting, where correct assignment of elements to classes is available and is used for evaluating the quality of another assignment of the elements intoclusters.
</prevsent>
<prevsent>many nlp works have used external clustering evaluation measures (see section 2).
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
recently, two measures have been proposed that avoid many of the weaknesses of previous measure sand exhibit several attractive properties (see sections 2 and 3): the vi measure (meila, 2007) and the measure (rosenberg and hirschberg, 2007).<papid> D07-1043 </papid></citsent>
<aftsection>
<nextsent>however, each of these has serious drawback.
</nextsent>
<nextsent>the possible values of vi lie in [0, 2log ], where isthe size of the clustered dataset.
</nextsent>
<nextsent>hence it has limited use when comparing performance on different datasets.
</nextsent>
<nextsent>v measure values lie in [0, 1] regardless ofthe dataset, but the measure strongly favors clustering having many small clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2822">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> previous evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>dom (2001) proposed the measure, the sum of homogeneity term h(c|k) and model cost term calculated using coding theory argument: q(c,k) = h(c|k) + 1n ?|k| k=1 log (h(k)+|c|1 |c|1 ) where are the correct classes, are the induced clusters and h(k) is the number of elements in cluster k. dom also presented normalized version of the measure (called q2) whose range is (0, 1] and gives higher scores to clusterings that are preferable.
</prevsent>
<prevsent>as noted by (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>theq measure does not explicitly address the completeness of the suggested clustering.</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
due to the cost term, if two clusterings have the same h(c|k)value, the model prefers the one with the lower number of clusters, but the trade-off between homogeneity and completeness is not explicitly addressed.in the next section we describe the and vi mea 166 sures, which are it measures that explicitly assess both the homogeneity and completeness of the clustering solution.bcubed (bagga and baldwin, 1998) <papid> P98-1012 </papid>is an attractive measure that addresses both completeness and homogeneity.</citsent>
<aftsection>
<nextsent>it does not explicitly use it concepts and avoids mapping.
</nextsent>
<nextsent>in this paper we focus on and vi; detailed comparison with bcubed is out of our scope here and will be done in future work.several recent nlp papers used clustering techniques and evaluation measures.
</nextsent>
<nextsent>examples include(finkel and manning, 2008), <papid> P08-2012 </papid>using vi, rand index and clustering f-score for evaluating coreference resolution; (headden et al, 2008), <papid> C08-1042 </papid>using vi, v, greedy 1-to-1 and many-to-1 mapping for evaluating unsupervised pos induction; (walker and ringger, 2008), using clustering f-score, the adjusted rand index, v, vi and q2 for document clustering; and(reichart and rappoport, 2008), <papid> C08-1091 </papid>using greedy 1-to 1 and many-to-1 mappings for evaluating labeled parse tree induction.schulte im walde (2003) used clustering to induce semantic verb classes and extensively discussed non-it based clustering evaluation measures.pfitzner et al (2008) presented comparison of clustering evaluation measures (it based and others).</nextsent>
<nextsent>while their analysis is extensive, their experiments were confined to artificial data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2823">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> previous evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>it does not explicitly use it concepts and avoids mapping.
</prevsent>
<prevsent>in this paper we focus on and vi; detailed comparison with bcubed is out of our scope here and will be done in future work.several recent nlp papers used clustering techniques and evaluation measures.
</prevsent>
</prevsection>
<citsent citstr=" P08-2012 ">
examples include(finkel and manning, 2008), <papid> P08-2012 </papid>using vi, rand index and clustering f-score for evaluating coreference resolution; (headden et al, 2008), <papid> C08-1042 </papid>using vi, v, greedy 1-to-1 and many-to-1 mapping for evaluating unsupervised pos induction; (walker and ringger, 2008), using clustering f-score, the adjusted rand index, v, vi and q2 for document clustering; and(reichart and rappoport, 2008), <papid> C08-1091 </papid>using greedy 1-to 1 and many-to-1 mappings for evaluating labeled parse tree induction.schulte im walde (2003) used clustering to induce semantic verb classes and extensively discussed non-it based clustering evaluation measures.pfitzner et al (2008) presented comparison of clustering evaluation measures (it based and others).</citsent>
<aftsection>
<nextsent>while their analysis is extensive, their experiments were confined to artificial data.
</nextsent>
<nextsent>in this work, we experiment with complex nlp application using large real datasets.
</nextsent>
<nextsent>the (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and vi (meila, 2007) measures are it based measures.</nextsent>
<nextsent>in this section we give detailed description of these measures and analyze their properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2824">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> previous evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>it does not explicitly use it concepts and avoids mapping.
</prevsent>
<prevsent>in this paper we focus on and vi; detailed comparison with bcubed is out of our scope here and will be done in future work.several recent nlp papers used clustering techniques and evaluation measures.
</prevsent>
</prevsection>
<citsent citstr=" C08-1042 ">
examples include(finkel and manning, 2008), <papid> P08-2012 </papid>using vi, rand index and clustering f-score for evaluating coreference resolution; (headden et al, 2008), <papid> C08-1042 </papid>using vi, v, greedy 1-to-1 and many-to-1 mapping for evaluating unsupervised pos induction; (walker and ringger, 2008), using clustering f-score, the adjusted rand index, v, vi and q2 for document clustering; and(reichart and rappoport, 2008), <papid> C08-1091 </papid>using greedy 1-to 1 and many-to-1 mappings for evaluating labeled parse tree induction.schulte im walde (2003) used clustering to induce semantic verb classes and extensively discussed non-it based clustering evaluation measures.pfitzner et al (2008) presented comparison of clustering evaluation measures (it based and others).</citsent>
<aftsection>
<nextsent>while their analysis is extensive, their experiments were confined to artificial data.
</nextsent>
<nextsent>in this work, we experiment with complex nlp application using large real datasets.
</nextsent>
<nextsent>the (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and vi (meila, 2007) measures are it based measures.</nextsent>
<nextsent>in this section we give detailed description of these measures and analyze their properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2825">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> previous evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>it does not explicitly use it concepts and avoids mapping.
</prevsent>
<prevsent>in this paper we focus on and vi; detailed comparison with bcubed is out of our scope here and will be done in future work.several recent nlp papers used clustering techniques and evaluation measures.
</prevsent>
</prevsection>
<citsent citstr=" C08-1091 ">
examples include(finkel and manning, 2008), <papid> P08-2012 </papid>using vi, rand index and clustering f-score for evaluating coreference resolution; (headden et al, 2008), <papid> C08-1042 </papid>using vi, v, greedy 1-to-1 and many-to-1 mapping for evaluating unsupervised pos induction; (walker and ringger, 2008), using clustering f-score, the adjusted rand index, v, vi and q2 for document clustering; and(reichart and rappoport, 2008), <papid> C08-1091 </papid>using greedy 1-to 1 and many-to-1 mappings for evaluating labeled parse tree induction.schulte im walde (2003) used clustering to induce semantic verb classes and extensively discussed non-it based clustering evaluation measures.pfitzner et al (2008) presented comparison of clustering evaluation measures (it based and others).</citsent>
<aftsection>
<nextsent>while their analysis is extensive, their experiments were confined to artificial data.
</nextsent>
<nextsent>in this work, we experiment with complex nlp application using large real datasets.
</nextsent>
<nextsent>the (rosenberg and hirschberg, 2007) <papid> D07-1043 </papid>and vi (meila, 2007) measures are it based measures.</nextsent>
<nextsent>in this section we give detailed description of these measures and analyze their properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2830">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> grammar induction experiment.  </section>
<citcontext>
<prevsection>
<prevsent>the experiment.
</prevsent>
<prevsent>the lti algorithm has threestages: bracketing, initial labeling, and label clustering.
</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
bracketing is done from raw text using the unsupervised incremental parser of (seginer, 2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>initial labeling is done using the bmm model (borensztajn and zuidema, 2007), which aims at minimizing the grammar description length (mdl).
</nextsent>
<nextsent>finally, labels are clustered to desired number of labels using the k-means algorithm with syntactic features extracted from the initially labeled trees.
</nextsent>
<nextsent>we refer to this stage as mdl+sc (for syntactic clustering?).
</nextsent>
<nextsent>using mapping-based evaluation with two different mapping functions, the lti algorithm was shown to outperform previous work on unsupervised labeled parse tree induction.the mdl clustering step induces several thousand labels for corpora of several tens of thousands of constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2832">
<title id=" W09-1121.xml">the nvi clustering evaluation measure </title>
<section> grammar induction experiment.  </section>
<citcontext>
<prevsection>
<prevsent>since constituent labels follow the zipfian distribution, is much smaller than .in this paper we run the lti algorithm and evaluate its labeling quality using v, vi, nvi and nvik.
</prevsent>
<prevsent>we compare the quality of the clustering induced by the first clustering step alone (the mdl clustering) to the quality of the clustering induced by the full algorithm (i.e., first applying mdl and then clustering its output using the sc algorithm for or labels)3.
</prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
we follow the experimental setup in (reichartand rappoport, 2008), <papid> C08-1091 </papid>running the algorithm on english, german and chinese corpora: the wsj penn treebank (english), the negra corpus (brants, 1997)(german), and version 5.0 of the chinese penn tree bank (xue et al, 2002).<papid> C02-1145 </papid></citsent>
<aftsection>
<nextsent>in each corpus, we used the sentences of length at most 10,4 numbering 7422 (wsj10), 7542 (negra10) and 4626 (ctb10).
</nextsent>
<nextsent>the characteristics of the induced clusterings are shown in table 25.
</nextsent>
<nextsent>the table demonstrates the fact that mdl labeling, while perhaps capturing the 3note that our evaluation here has nothing to do with the evaluation done in (reichart and rappoport, 2008), <papid> C08-1091 </papid>which provided comparison of the full grammar induction results between different algorithms, using mapping-based measures.</nextsent>
<nextsent>we evaluate the labeling stages alone.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2840">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we achieve significant improvements in translation quality over related approaches, measured by manual as well as automaticevaluations.
</prevsent>
<prevsent>these results prove the viability of this approach for distant languages.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the emergence of phrase-based statistical machine translation (psmt) (koehn et al, 2003<papid> N03-1017 </papid>a)has been one of the major developments in statistical approaches to translation.</citsent>
<aftsection>
<nextsent>allowing translation of word sequences (phrases) instead of single words provides psmt with high degree of robustness in word selection and in local-word reordering.
</nextsent>
<nextsent>recent developments have shown that improvements in psmt quality are possible using syntax.
</nextsent>
<nextsent>one such development is the pre translation reordering approach, which adjusts the source sentence to resemble target-language word order prior to translation.
</nextsent>
<nextsent>this is typically done using rules that are either manually created or automatically learned from word-aligned parallel corpora.one particular variety of this approach, proposed by elming (2008), <papid> W08-0406 </papid>uses large set of linguistic features to automatically learn reordering rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2843">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent developments have shown that improvements in psmt quality are possible using syntax.
</prevsent>
<prevsent>one such development is the pre translation reordering approach, which adjusts the source sentence to resemble target-language word order prior to translation.
</prevsent>
</prevsection>
<citsent citstr=" W08-0406 ">
this is typically done using rules that are either manually created or automatically learned from word-aligned parallel corpora.one particular variety of this approach, proposed by elming (2008), <papid> W08-0406 </papid>uses large set of linguistic features to automatically learn reordering rules.</citsent>
<aftsection>
<nextsent>the rules are applied nondeterministically; however, phrase-internal word alignments are used to ensure that the intended reordering does not come undone because of phrase internal reordering (elming, 2008)<papid> W08-0406 </papid></nextsent>
<nextsent>this approach was shown to produce improved mt output on english-danish mt, relatively closely-related and similarly-structured language pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2850">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 6, we evaluate and discuss the results of our english-arabic mt system.
</prevsent>
<prevsent>much work has been done in syntactic reordering for smt, focusing on both source and target language syntax.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
in this paper, we adapt an approach that utilizes source-syntax information as opposed to target-side syntax systems (yamada and knight, 2001; <papid> P01-1067 </papid>galley et al, 2004).</citsent>
<aftsection>
<nextsent>this is because we are translating from english to arabi cand we are discouraged by recent results indicating arabic parsing is not at stage that makes it usable in mt (habash et al, 2006).
</nextsent>
<nextsent>while several recent authors using pre-translation (source side) reordering approach have achieved positive results, it has been difficult to integrate syntactic 69 information while retaining the strengths of the statistical approach.
</nextsent>
<nextsent>in some studies, reordering decisions are done deterministically?
</nextsent>
<nextsent>by supplying the decoder with canonical word order (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2851">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while several recent authors using pre-translation (source side) reordering approach have achieved positive results, it has been difficult to integrate syntactic 69 information while retaining the strengths of the statistical approach.
</prevsent>
<prevsent>in some studies, reordering decisions are done deterministically?
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
by supplying the decoder with canonical word order (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007).</citsent>
<aftsection>
<nextsent>these reordering rules are either manually specified or automatically learned from alignments; and they areal ways placed outside the actual psmt system.
</nextsent>
<nextsent>by contrast, other studies (crego and mario, 2007; zhang et al, 2007; li et al, 2007; <papid> P07-1091 </papid>elming, 2008)<papid> W08-0406 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options that areal lowed to contribute alongside other parameters.specifically, we follow the pre-translation reordering approach of elming (2008).<papid> W08-0406 </papid></nextsent>
<nextsent>this approach has been proven to remedy shortcomings of otherpre-translation reordering approaches by reordering the input word sequence, but scoring the out put word sequence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2852">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while several recent authors using pre-translation (source side) reordering approach have achieved positive results, it has been difficult to integrate syntactic 69 information while retaining the strengths of the statistical approach.
</prevsent>
<prevsent>in some studies, reordering decisions are done deterministically?
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
by supplying the decoder with canonical word order (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007).</citsent>
<aftsection>
<nextsent>these reordering rules are either manually specified or automatically learned from alignments; and they areal ways placed outside the actual psmt system.
</nextsent>
<nextsent>by contrast, other studies (crego and mario, 2007; zhang et al, 2007; li et al, 2007; <papid> P07-1091 </papid>elming, 2008)<papid> W08-0406 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options that areal lowed to contribute alongside other parameters.specifically, we follow the pre-translation reordering approach of elming (2008).<papid> W08-0406 </papid></nextsent>
<nextsent>this approach has been proven to remedy shortcomings of otherpre-translation reordering approaches by reordering the input word sequence, but scoring the out put word sequence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2853">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while several recent authors using pre-translation (source side) reordering approach have achieved positive results, it has been difficult to integrate syntactic 69 information while retaining the strengths of the statistical approach.
</prevsent>
<prevsent>in some studies, reordering decisions are done deterministically?
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
by supplying the decoder with canonical word order (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007).</citsent>
<aftsection>
<nextsent>these reordering rules are either manually specified or automatically learned from alignments; and they areal ways placed outside the actual psmt system.
</nextsent>
<nextsent>by contrast, other studies (crego and mario, 2007; zhang et al, 2007; li et al, 2007; <papid> P07-1091 </papid>elming, 2008)<papid> W08-0406 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options that areal lowed to contribute alongside other parameters.specifically, we follow the pre-translation reordering approach of elming (2008).<papid> W08-0406 </papid></nextsent>
<nextsent>this approach has been proven to remedy shortcomings of otherpre-translation reordering approaches by reordering the input word sequence, but scoring the out put word sequence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2854">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>by supplying the decoder with canonical word order (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007).</prevsent>
<prevsent>these reordering rules are either manually specified or automatically learned from alignments; and they areal ways placed outside the actual psmt system.</prevsent>
</prevsection>
<citsent citstr=" P07-1091 ">
by contrast, other studies (crego and mario, 2007; zhang et al, 2007; li et al, 2007; <papid> P07-1091 </papid>elming, 2008)<papid> W08-0406 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options that areal lowed to contribute alongside other parameters.specifically, we follow the pre-translation reordering approach of elming (2008).<papid> W08-0406 </papid></citsent>
<aftsection>
<nextsent>this approach has been proven to remedy shortcomings of otherpre-translation reordering approaches by reordering the input word sequence, but scoring the out put word sequence.
</nextsent>
<nextsent>elming (2008) <papid> W08-0406 </papid>only examined the approach within english ? danish, language pair that displays little reordering.</nextsent>
<nextsent>by contrast, in this paper, we target the more demanding reordering taskof translating between two distant languages, english and arabic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2859">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>elming (2008) <papid> W08-0406 </papid>only examined the approach within english ? danish, language pair that displays little reordering.</prevsent>
<prevsent>by contrast, in this paper, we target the more demanding reordering taskof translating between two distant languages, english and arabic.</prevsent>
</prevsection>
<citsent citstr=" N06-2013 ">
while much work has been done on arabic to english mt (habash and sadat, 2006; <papid> N06-2013 </papid>lee, 2004) <papid> N04-4015 </papid>mostly focusing on addressing the problems caused by the rich morphology of arabic, we handle the less described translation direction: english to arabic.</citsent>
<aftsection>
<nextsent>recently, there are some new publications on english to arabic mt. sarikaya and deng (2007) <papid> N07-2037 </papid>use joint morphological-lexical language models to re-rank the output of english dialectal-arabic mt, and badr et al (2008) <papid> P08-2039 </papid>report results on the value ofthe morphological decomposition of arabic during training and describe different techniques for re-composition of arabic in the output.</nextsent>
<nextsent>we differ from the previous efforts targeting arabic in that (1) we do not address morphology issues through segmentation (more on this in section 3) and (2)we focus on utilizing syntactic knowledge to address the reordering challenges of this translation direction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2861">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>elming (2008) <papid> W08-0406 </papid>only examined the approach within english ? danish, language pair that displays little reordering.</prevsent>
<prevsent>by contrast, in this paper, we target the more demanding reordering taskof translating between two distant languages, english and arabic.</prevsent>
</prevsection>
<citsent citstr=" N04-4015 ">
while much work has been done on arabic to english mt (habash and sadat, 2006; <papid> N06-2013 </papid>lee, 2004) <papid> N04-4015 </papid>mostly focusing on addressing the problems caused by the rich morphology of arabic, we handle the less described translation direction: english to arabic.</citsent>
<aftsection>
<nextsent>recently, there are some new publications on english to arabic mt. sarikaya and deng (2007) <papid> N07-2037 </papid>use joint morphological-lexical language models to re-rank the output of english dialectal-arabic mt, and badr et al (2008) <papid> P08-2039 </papid>report results on the value ofthe morphological decomposition of arabic during training and describe different techniques for re-composition of arabic in the output.</nextsent>
<nextsent>we differ from the previous efforts targeting arabic in that (1) we do not address morphology issues through segmentation (more on this in section 3) and (2)we focus on utilizing syntactic knowledge to address the reordering challenges of this translation direction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2862">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>by contrast, in this paper, we target the more demanding reordering taskof translating between two distant languages, english and arabic.
</prevsent>
<prevsent>while much work has been done on arabic to english mt (habash and sadat, 2006; <papid> N06-2013 </papid>lee, 2004) <papid> N04-4015 </papid>mostly focusing on addressing the problems caused by the rich morphology of arabic, we handle the less described translation direction: english to arabic.</prevsent>
</prevsection>
<citsent citstr=" N07-2037 ">
recently, there are some new publications on english to arabic mt. sarikaya and deng (2007) <papid> N07-2037 </papid>use joint morphological-lexical language models to re-rank the output of english dialectal-arabic mt, and badr et al (2008) <papid> P08-2039 </papid>report results on the value ofthe morphological decomposition of arabic during training and describe different techniques for re-composition of arabic in the output.</citsent>
<aftsection>
<nextsent>we differ from the previous efforts targeting arabic in that (1) we do not address morphology issues through segmentation (more on this in section 3) and (2)we focus on utilizing syntactic knowledge to address the reordering challenges of this translation direction.
</nextsent>
<nextsent>arabic is morphologically and syntactically complex language with many differences from english.
</nextsent>
<nextsent>arabic morphology has been well studied in the context of mt. previous results all suggest that some degree of tokenization is helpful when translating from arabic (habash and sadat, 2006; <papid> N06-2013 </papid>lee, 2004).<papid> N04-4015 </papid></nextsent>
<nextsent>however, when translating into morphologically rich language, target tokenization means that the translation process is broken into multiple steps (badr et al, 2008).<papid> P08-2039 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2863">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>by contrast, in this paper, we target the more demanding reordering taskof translating between two distant languages, english and arabic.
</prevsent>
<prevsent>while much work has been done on arabic to english mt (habash and sadat, 2006; <papid> N06-2013 </papid>lee, 2004) <papid> N04-4015 </papid>mostly focusing on addressing the problems caused by the rich morphology of arabic, we handle the less described translation direction: english to arabic.</prevsent>
</prevsection>
<citsent citstr=" P08-2039 ">
recently, there are some new publications on english to arabic mt. sarikaya and deng (2007) <papid> N07-2037 </papid>use joint morphological-lexical language models to re-rank the output of english dialectal-arabic mt, and badr et al (2008) <papid> P08-2039 </papid>report results on the value ofthe morphological decomposition of arabic during training and describe different techniques for re-composition of arabic in the output.</citsent>
<aftsection>
<nextsent>we differ from the previous efforts targeting arabic in that (1) we do not address morphology issues through segmentation (more on this in section 3) and (2)we focus on utilizing syntactic knowledge to address the reordering challenges of this translation direction.
</nextsent>
<nextsent>arabic is morphologically and syntactically complex language with many differences from english.
</nextsent>
<nextsent>arabic morphology has been well studied in the context of mt. previous results all suggest that some degree of tokenization is helpful when translating from arabic (habash and sadat, 2006; <papid> N06-2013 </papid>lee, 2004).<papid> N04-4015 </papid></nextsent>
<nextsent>however, when translating into morphologically rich language, target tokenization means that the translation process is broken into multiple steps (badr et al, 2008).<papid> P08-2039 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2880">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> the psmt system.  </section>
<citcontext>
<prevsection>
<prevsent>phrase internal reorderings at other points of the sentence, i.e. points that are not covered by rule, are not judged by the reordering model.
</prevsent>
<prevsent>our rule extraction does not learn every possible reordering between the two languages, but only the most general ones.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
if no rule has an opinion at certain point in sentence, the decoder is free to choose the phrase translation it prefers without reordering cost.separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as traditional psmt system(koehn et al, 2003<papid> N03-1017 </papid>b) or hierarchical phrase system (chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>we will, however, not examine this possibility further in the present paper.
</nextsent>
<nextsent>6.1 data.
</nextsent>
<nextsent>we learn the reordering rules from the ibmarabic-english aligned corpus (ibmac) (ittycheriah and roukos, 2005).<papid> H05-1012 </papid></nextsent>
<nextsent>of its total 13.9k sentence pairs, we only use 8.8k sentences because the rest of the corpus uses different normalizations for numerals that make the two sets incompatible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2882">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we will, however, not examine this possibility further in the present paper.
</prevsent>
<prevsent>6.1 data.
</prevsent>
</prevsection>
<citsent citstr=" H05-1012 ">
we learn the reordering rules from the ibmarabic-english aligned corpus (ibmac) (ittycheriah and roukos, 2005).<papid> H05-1012 </papid></citsent>
<aftsection>
<nextsent>of its total 13.9k sentence pairs, we only use 8.8k sentences because the rest of the corpus uses different normalizations for numerals that make the two sets incompatible.
</nextsent>
<nextsent>6.6k of the sentences (179k english and 146k arabic words) are used to learn rule, while the rest are used for development purposes.
</nextsent>
<nextsent>in addition to the manual alignment supplied with these data, we create an automatic word alignment for them usinggiza++ (och and ney, 2003) <papid> J03-1002 </papid>and the grow-diag final (gdf) symmetrization algorithm (koehn et al., 2005).</nextsent>
<nextsent>this was done together with the data used to train the mt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2883">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>of its total 13.9k sentence pairs, we only use 8.8k sentences because the rest of the corpus uses different normalizations for numerals that make the two sets incompatible.
</prevsent>
<prevsent>6.6k of the sentences (179k english and 146k arabic words) are used to learn rule, while the rest are used for development purposes.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in addition to the manual alignment supplied with these data, we create an automatic word alignment for them usinggiza++ (och and ney, 2003) <papid> J03-1002 </papid>and the grow-diag final (gdf) symmetrization algorithm (koehn et al., 2005).</citsent>
<aftsection>
<nextsent>this was done together with the data used to train the mt system.
</nextsent>
<nextsent>the english side is parsed using state-of-the-art statistical english parser (charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>two rule sets are learned based on the manual alignments (man) and the automatic alignments (gdf).the mt system is trained on corpus consisting of 126k sentences with 4.2m english and 3.3m arabic words in simple tokenization scheme.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2884">
<title id=" W09-0809.xml">syntactic reordering for english arabic phrase based machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the manual alignment supplied with these data, we create an automatic word alignment for them usinggiza++ (och and ney, 2003) <papid> J03-1002 </papid>and the grow-diag final (gdf) symmetrization algorithm (koehn et al., 2005).</prevsent>
<prevsent>this was done together with the data used to train the mt system.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the english side is parsed using state-of-the-art statistical english parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>two rule sets are learned based on the manual alignments (man) and the automatic alignments (gdf).the mt system is trained on corpus consisting of 126k sentences with 4.2m english and 3.3m arabic words in simple tokenization scheme.
</nextsent>
<nextsent>the domain is newswire (ldc news) taken from arabic news (ldc2004t17), etirr (ldc2004e72), english translation of arabic treebank (ldc2005e46), and ummah (ldc2004t18).
</nextsent>
<nextsent>although there are additional corpora available, we restricted ourselves to this set to allow for fast development cycle.
</nextsent>
<nextsent>we planto extend the data size in the future.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2897">
<title id=" W08-2109.xml">improving word segmentation by simultaneously learning phonotactics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hereafter, we use the phrase word segmentation?
</prevsent>
<prevsent>to mean some process which adds word boundaries to text that does not contain them.this papers focus is on unsupervised, incremental word segmentation algorithms; i.e., those that do not relyon preexisting knowledge of particular language, and those that segment the corpus one utterance at time.
</prevsent>
</prevsection>
<citsent citstr=" J00-3004 ">
this is in contrast to supervised word segmentation algorithms (e.g., teahan et al, 2000), <papid> J00-3004 </papid>which are typically used for segmenting text in documents written in languages that do not put spaces between their words likechinese.</citsent>
<aftsection>
<nextsent>(of course, unsupervised word segmentation algorithms also have this application.)
</nextsent>
<nextsent>this also differs from batch segmentation algorithms (goldwater, 2007; johnson, 2008<papid> W08-0704 </papid>b; fleck, 2008),<papid> P08-1016 </papid>which process the entire corpus at least once before out putting segmentation of the corpus.</nextsent>
<nextsent>unsupervised incremental algorithms are of interest to some psycho linguists and acquisition ists interested in the problem of language learning, as wellas theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving.phonotactic patterns are the rules that determine what sequences of phonemes or allophonesare allowable within words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2898">
<title id=" W08-2109.xml">improving word segmentation by simultaneously learning phonotactics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is in contrast to supervised word segmentation algorithms (e.g., teahan et al, 2000), <papid> J00-3004 </papid>which are typically used for segmenting text in documents written in languages that do not put spaces between their words likechinese.</prevsent>
<prevsent>(of course, unsupervised word segmentation algorithms also have this application.)</prevsent>
</prevsection>
<citsent citstr=" W08-0704 ">
this also differs from batch segmentation algorithms (goldwater, 2007; johnson, 2008<papid> W08-0704 </papid>b; fleck, 2008),<papid> P08-1016 </papid>which process the entire corpus at least once before out putting segmentation of the corpus.</citsent>
<aftsection>
<nextsent>unsupervised incremental algorithms are of interest to some psycho linguists and acquisition ists interested in the problem of language learning, as wellas theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving.phonotactic patterns are the rules that determine what sequences of phonemes or allophonesare allowable within words.
</nextsent>
<nextsent>learning the phono tactic patterns of language is usually modeled 65 separately from word segmentation; e.g., currentphonotactic learners such as coleman and pierrehumbert (1997), <papid> W97-1107 </papid>heinz (2007), or hayes and wilson (2008) are given word-sized units as input.</nextsent>
<nextsent>however, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2900">
<title id=" W08-2109.xml">improving word segmentation by simultaneously learning phonotactics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is in contrast to supervised word segmentation algorithms (e.g., teahan et al, 2000), <papid> J00-3004 </papid>which are typically used for segmenting text in documents written in languages that do not put spaces between their words likechinese.</prevsent>
<prevsent>(of course, unsupervised word segmentation algorithms also have this application.)</prevsent>
</prevsection>
<citsent citstr=" P08-1016 ">
this also differs from batch segmentation algorithms (goldwater, 2007; johnson, 2008<papid> W08-0704 </papid>b; fleck, 2008),<papid> P08-1016 </papid>which process the entire corpus at least once before out putting segmentation of the corpus.</citsent>
<aftsection>
<nextsent>unsupervised incremental algorithms are of interest to some psycho linguists and acquisition ists interested in the problem of language learning, as wellas theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving.phonotactic patterns are the rules that determine what sequences of phonemes or allophonesare allowable within words.
</nextsent>
<nextsent>learning the phono tactic patterns of language is usually modeled 65 separately from word segmentation; e.g., currentphonotactic learners such as coleman and pierrehumbert (1997), <papid> W97-1107 </papid>heinz (2007), or hayes and wilson (2008) are given word-sized units as input.</nextsent>
<nextsent>however, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2901">
<title id=" W08-2109.xml">improving word segmentation by simultaneously learning phonotactics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this also differs from batch segmentation algorithms (goldwater, 2007; johnson, 2008<papid> W08-0704 </papid>b; fleck, 2008),<papid> P08-1016 </papid>which process the entire corpus at least once before out putting segmentation of the corpus.</prevsent>
<prevsent>unsupervised incremental algorithms are of interest to some psycho linguists and acquisition ists interested in the problem of language learning, as wellas theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving.phonotactic patterns are the rules that determine what sequences of phonemes or allophonesare allowable within words.</prevsent>
</prevsection>
<citsent citstr=" W97-1107 ">
learning the phono tactic patterns of language is usually modeled 65 separately from word segmentation; e.g., currentphonotactic learners such as coleman and pierrehumbert (1997), <papid> W97-1107 </papid>heinz (2007), or hayes and wilson (2008) are given word-sized units as input.</citsent>
<aftsection>
<nextsent>however, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input.
</nextsent>
<nextsent>it is reasonable that the two processes feed into one another, and when infants acquire critical mass ofphonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (mattys and jusczyk, 2001).
</nextsent>
<nextsent>we use this insight, also suggested by venkataraman (2001) and recently utilized by fleck (2008) <papid> P08-1016 </papid>in different manner, to enhance brents (1999) model mbdp-1, and significantly increase segmentation accuracy.</nextsent>
<nextsent>we call this modified segmentation model mbdp-phon.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2904">
<title id=" W08-2109.xml">improving word segmentation by simultaneously learning phonotactics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>r(w ) = f(w ) ?
</prevsent>
<prevsent>( f(w )?
</prevsent>
</prevsection>
<citsent citstr=" P01-1013 ">
1 f(w ) ) 2 (2)otherwise, the word is novel, and its score is calculated using equation 3 1 (brent and tao, 2001), <papid> P01-1013 </papid>r(w ) = 6 pi 2 ? k ? ?</citsent>
<aftsection>
<nextsent>(a 1 )...p ?
</nextsent>
<nextsent>(a ) 1p ?
</nextsent>
<nextsent>( n1 ) 2 (3) where ? is the probability of particular phoneme occurring in the text.
</nextsent>
<nextsent>the third term of the equation for novel words is where the models unigram phonotactic model comes into play.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2919">
<title id=" W09-0601.xml">using nlg to help language impaired users tell stories and participate in social dialogues </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in their review of nlp and aac, newell, langer, and hickey (1998) suggest that nlg could be used to generate complete utterances from the limited input that aac users are able to provide.
</prevsent>
<prevsent>for example, the compan sion project (mccoy, pennington, badman 1998) used nlp and nlg techniques to expand telegraphic user input, such as mary go store?, into complete utterances, such as did mary go to the store?
</prevsent>
</prevsection>
<citsent citstr=" N06-2027 ">
netzer and elhadad (2006) <papid> N06-2027 </papid>allowed users to author utterances in the symbolic language bliss, and used nlg to translate this to english and hebrew texts.</citsent>
<aftsection>
<nextsent>in recent years there has been growing interest in data-to-text nlg systems (reiter, 2007); these systems generate texts based on sensor and other numerical data, supplemented with ontologies that specify domain knowledge.
</nextsent>
<nextsent>in principle, it seems that data-to-text techniques should allow nlg systems to provide more assistance than the syntactic help provided by compansion.
</nextsent>
<nextsent>for example, if the user wanted to talk about recent football (soccer) match, data-to-text system could get actual data about the match from the web, and generate potential utterances from this data, such as arsenal beat chelsea 2-1 and van persie scored two goals; the user could then select one of these to utter.
</nextsent>
<nextsent>in addition to helping users interact with other people, nlg techniques can also be used to educate and encourage children with disabilities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2920">
<title id=" W09-0601.xml">using nlg to help language impaired users tell stories and participate in social dialogues </title>
<section> discussion: challenges for nlg.  </section>
<citcontext>
<prevsection>
<prevsent>that is, not just list of facts and events, but structure with beginning and end, and with explanatory and other links between components (e.g., had math in the afternoon because we went swimming in the morning, if the child normally has math in the morning).
</prevsent>
<prevsent>we also wanted the narrative to be interesting and hold the interest of the person the child is communicating with.
</prevsent>
</prevsection>
<citsent citstr=" W08-1119 ">
as pointed out by reiter et al(2008), <papid> W08-1119 </papid>current nlg systems do not do good job of generating narratives.</citsent>
<aftsection>
<nextsent>similarly, in the social conversations project we want the system to generate social dialogue, not just list of facts about movies and songs.
</nextsent>
<nextsent>little previous research has been done on generating social (as opposed to task-oriented) dialogues.
</nextsent>
<nextsent>one exception is the neca socialite system (van deemter et al 2008), but this focused on techniques for expressing affect, not on high-level conversational structure.
</nextsent>
<nextsent>for both stories and social conversations, it would be extremely useful to be able to monitor what the conversational partner is saying.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2921">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, the weights encoded by the gradient of the separating hyperplanelearnt by the svm implicitly establish ranking between features in the kernel space.
</prevsent>
<prevsent>this property has been exploited in feature selection models based on approximations or transformations of the gradient, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
(rakotomamonjy, 2003), (weston et al, 2003) or (kudo and matsumoto, 2003).<papid> P03-1004 </papid></citsent>
<aftsection>
<nextsent>however, kernel based systems have two major drawbacks: first, new features may be discovered in the implicit space but they cannot be directly observed.
</nextsent>
<nextsent>second, since learning is carried out in the dual space, it is not possible to use the faster svm or perceptron algorithms optimized for linear spaces.
</nextsent>
<nextsent>consequently, the processing of large datasets can be computationally very expensive, limiting the useof large amounts of data for our research or applications.
</nextsent>
<nextsent>we propose an approach that tries to fill in thegap between explicit and implicit feature representations by 1) selecting the most relevant features in accordance with the weights estimated by the svmand 2) using these features to build an explicit representation of the kernel space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2922">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> tree kernel functions.  </section>
<citcontext>
<prevsection>
<prevsent>of our examples in vector space.a tree kernel function is convolution kernel (haussler, 1999) defined over pairs of trees.
</prevsent>
<prevsent>practically speaking, the kernel between two trees evaluates the number of substructures (or fragments) they have in common, i.e. it is measure of their overlap.
</prevsent>
</prevsection>
<citsent citstr=" E06-1015 ">
the function can be computed recursively in closed form, and quite efficient implementations are available (moschitti, 2006).<papid> E06-1015 </papid></citsent>
<aftsection>
<nextsent>different tk functions are characterized by alternative fragment definitions, e.g.
</nextsent>
<nextsent>(collins and duffy, 2002) <papid> P02-1034 </papid>and (kashima and koyanagi, 2002).</nextsent>
<nextsent>in the context of this paperwe will be focusing on the subset tree (sst) kernel described in (collins and duffy, 2002), <papid> P02-1034 </papid>which relies on fragment definition that does not allow to break production rules (i.e. if any child of node is included in fragment, then also all the other children have to).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2924">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> tree kernel functions.  </section>
<citcontext>
<prevsection>
<prevsent>the function can be computed recursively in closed form, and quite efficient implementations are available (moschitti, 2006).<papid> E06-1015 </papid></prevsent>
<prevsent>different tk functions are characterized by alternative fragment definitions, e.g.</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
(collins and duffy, 2002) <papid> P02-1034 </papid>and (kashima and koyanagi, 2002).</citsent>
<aftsection>
<nextsent>in the context of this paperwe will be focusing on the subset tree (sst) kernel described in (collins and duffy, 2002), <papid> P02-1034 </papid>which relies on fragment definition that does not allow to break production rules (i.e. if any child of node is included in fragment, then also all the other children have to).</nextsent>
<nextsent>as such, it is especially indicated for tasks involving constituency parsed texts.implicitly, tk function establishes correspondence between distinct fragments and dimensions insome fragment space, i.e. the space of all the possible fragments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2928">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, this is the only published work clearly focusing on feature selection for tree kernel functions.
</prevsent>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
</prevsection>
<citsent citstr=" J08-2003 ">
the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</citsent>
<aftsection>
<nextsent>iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></nextsent>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2931">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, this is the only published work clearly focusing on feature selection for tree kernel functions.
</prevsent>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
</prevsection>
<citsent citstr=" W03-1012 ">
the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</citsent>
<aftsection>
<nextsent>iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></nextsent>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2932">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, this is the only published work clearly focusing on feature selection for tree kernel functions.
</prevsent>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</citsent>
<aftsection>
<nextsent>iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></nextsent>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2933">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" H05-1018 ">
iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2934">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2935">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" W06-2902 ">
iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2936">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" W06-2909 ">
iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2937">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" W04-2403 ">
iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2938">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (graf et al, 2004), an approach to svm parallel ization is presented which is basedon divide-et-impera strategy to reduce optimization time.
</prevsent>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
</prevsection>
<citsent citstr=" W04-3222 ">
iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</nextsent>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2939">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
<prevsent>iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</citsent>
<aftsection>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.
</nextsent>
<nextsent>the former task requires binary boundary classifier (bc), whereas the second involves role multi-class classifier (rm).setup.
</nextsent>
<nextsent>if the constituency parse tree of sentence is available, we can look at all the pairs p, ni?, where ni is any node in the tree and is the node dominating w, and decide whether ni is an argument node or not, i.e. whether it exactly dominates all and only the words encoding any of wsarguments.
</nextsent>
<nextsent>the objects that we classify are subsets of the input parse tree that encompass both and ni.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2940">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of using compact graph representation to represent the support vectors of tk function is explored in (aiolli et al, 2006), where direct acyclic graph (dag) is employed.concerning the use of kernels for nlp, interesting models and results are described, for example, in (collins and duffy, 2002), <papid> P02-1034 </papid>(moschitti et al, 2008), <papid> J08-2003 </papid>kudo and matsumoto, 2003), <papid> P03-1004 </papid>(cumby and roth, 2003), (shen et al, 2003), (<papid> W03-1012 </papid>cancedda et al, 2003), (culotta and sorensen, 2004), (<papid> P04-1054 </papid>daume?</prevsent>
<prevsent>iii and marcu, 2004), (kazama and torisawa, 2005), (<papid> H05-1018 </papid>kudo et al, 2005), (<papid> P05-1024 </papid>titov and henderson, 2006), (<papid> W06-2902 </papid>moschitti et al, 2006), (<papid> W06-2909 </papid>moschitti and bejan, 2004) <papid> W04-2403 </papid>or (toutanova et al, 2004).<papid> W04-3222 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we tested our model on semantic role labeling (srl) benchmark, using propbank annotations (palmer et al, 2005) <papid> J05-1004 </papid>and automatic charniak parse trees (charniak, 2000) <papid> A00-2018 </papid>as provided for the conll 2005 evaluation campaign (carreras and ma`rquez, 2005).</citsent>
<aftsection>
<nextsent>srl can be decomposed intotwo tasks: boundary detection, where the word sequences that are arguments of predicate word ware identified, and role classification, where each argument is assigned the proper role.
</nextsent>
<nextsent>the former task requires binary boundary classifier (bc), whereas the second involves role multi-class classifier (rm).setup.
</nextsent>
<nextsent>if the constituency parse tree of sentence is available, we can look at all the pairs p, ni?, where ni is any node in the tree and is the node dominating w, and decide whether ni is an argument node or not, i.e. whether it exactly dominates all and only the words encoding any of wsarguments.
</nextsent>
<nextsent>the objects that we classify are subsets of the input parse tree that encompass both and ni.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2944">
<title id=" W09-1106.xml">efficient linearization of tree kernel functions </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>15% of the fragments contain the predicate node (which generally is the node encoding the predicate words pos tag), more than one third contain the candidate argument node and, of these, about one third are rooted in it.
</prevsent>
<prevsent>this last figure strongly suggests that the internal structure of an argument is indeed very powerful feature not only for role classification, as we would expect, but also for boundary detection.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
about 10% of the fragments contain both the predicate and the argument node, while about 1% encode the path feature traditionally used in explicit semantic role labeling models (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>about 5%encode sort of extended path feature, where the argument node is represented together with its descendants.
</nextsent>
<nextsent>overall, about 2/3 of the fragments contain at least some terminal symbol (i.e. words), generally preposition or an adverb.
</nextsent>
<nextsent>we presented supervised learning framework for support vector machines that tries to combine the power and modeling simplicity of convolution kernels with the advantages of linear kernels and explicit feature representations.
</nextsent>
<nextsent>we tested our modelon semantic role labeling benchmark and obtained very promising results in terms of accuracy and efficiency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2945">
<title id=" W08-1133.xml">referring expression generation using speaker based attribute selection and trainable realization attr </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, most of this work did not take into account: a) stylistic differences between speakers; or b) trainable surface realization approaches that combine semantic and word order information.
</prevsent>
<prevsent>in this paper we describe and evaluate several end-to-end referring expression generation algorithms that take into consideration speaker style and use data-driven surface realization techniques.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
there now exist numerous general-purpose algorithms for attribute selection used in referring expression generation (e.g., (dale and reiter, 1995;krahmer et al, 2003; <papid> J03-1003 </papid>belz and gatt, 2007)).</citsent>
<aftsection>
<nextsent>however, these algorithms by-and-large focus on the al gorithmic aspects of referring expression generation rather than on psycho linguistic factors that influence language production.
</nextsent>
<nextsent>for example, we know that humans exhibit individual style differences during language production that can be quite pronounced(e.g.
</nextsent>
<nextsent>(belz, 2007)).<papid> N07-1021 </papid></nextsent>
<nextsent>we also know that the language production process is subject to lexical priming, which means that words and concepts that have been used recently are likely to appear again (levelt, 1989).in this paper, we first explore the impact of individual style and priming on attribute selection for referring expression generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2946">
<title id=" W08-1133.xml">referring expression generation using speaker based attribute selection and trainable realization attr </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these algorithms by-and-large focus on the al gorithmic aspects of referring expression generation rather than on psycho linguistic factors that influence language production.
</prevsent>
<prevsent>for example, we know that humans exhibit individual style differences during language production that can be quite pronounced(e.g.
</prevsent>
</prevsection>
<citsent citstr=" N07-1021 ">
(belz, 2007)).<papid> N07-1021 </papid></citsent>
<aftsection>
<nextsent>we also know that the language production process is subject to lexical priming, which means that words and concepts that have been used recently are likely to appear again (levelt, 1989).in this paper, we first explore the impact of individual style and priming on attribute selection for referring expression generation.
</nextsent>
<nextsent>to get an idea of the potential improvement when modeling these factors, we implemented version of full brevity search (dale, 1992) that uses speaker-specific constraints, and another version that also uses recency constraints.
</nextsent>
<nextsent>we found that using speaker-specific constraints led to big performance gains for both tuna domains, while the use of recency constraints was not as effective for tuna-style tasks.
</nextsent>
<nextsent>we then modified dale and reiters classic attribute selection algorithm (dale and reiter, 1995) to model speaker specific constraints, and found performance gains in this more greedy approach as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2947">
<title id=" W08-1133.xml">referring expression generation using speaker based attribute selection and trainable realization attr </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we then modified dale and reiters classic attribute selection algorithm (dale and reiter, 1995) to model speaker specific constraints, and found performance gains in this more greedy approach as well.
</prevsent>
<prevsent>then we looked at surface realization for referring expression generation.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
there are several approaches to surface realization described in the literature (re iter and dale, 2000) ranging from hand-crafted template-based realizers to data-driven syntax-based realizers (langkilde and knight, 2000; bangalore and rambow, 2000).<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>template-based realization involves the insertion of attribute values into predetermined templates.
</nextsent>
<nextsent>data-driven syntax-basedmethods use syntactic relations between words (in cluding long-distance relations) for word ordering.
</nextsent>
<nextsent>other data-driven techniques exhaustively generate possible realizations with recourse to syntax inasmuch as it is reflected in local n-grams.
</nextsent>
<nextsent>such techniques have the advantage of being robust although they are inadequate to capture long-range dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2948">
<title id=" W08-1133.xml">referring expression generation using speaker based attribute selection and trainable realization attr </title>
<section> surface realization approaches.  </section>
<citcontext>
<prevsection>
<prevsent>min.
</prevsent>
<prevsent>furniture fb-m .36 .16 0 1 1 fb-f .81 .58 .40 1 0 fb-sf .95 .87 .79 1 0 fb-sr .93 .81 .71 1 0 dr-b .81 .60 .45 1 0 dr-sf .86 .64 .45 1 .04 people fb-m .26 .12 0 1 1 fb-f .58 .37 .28 1 0 fb-sf .94 .88 .84 1 .01 fb-sr .93 .85 .79 1 .01 dr-b .70 .45 .25 1 0 dr-sf .78 .55 .35 1 0 overall fb-m .32 .14 0 1 1 fb-f .70 .48 .34 1 0 fb-sf .95 .87 .81 1 .01 fb-sr .93 .83 .75 1 .01 dr-b .76 .53 .36 1 0 dr-sf .82 .60 .41 1 .02 table 1: results for attribute selection unfortunately, the number of states of the minimal permutation automaton of even linear automata (finite-state machine representation of string) grows exponentially with the number of words of the string.
</prevsent>
</prevsection>
<citsent citstr=" W05-0831 ">
so, instead of creating full permutation automaton, we choose to constrain permutations to be within local window of adjustable size (also see (kanthak et al, 2005)).<papid> W05-0831 </papid></citsent>
<aftsection>
<nextsent>data preparation the training data were used to build the models outlined above.
</nextsent>
<nextsent>the development data were then processed one-by-one.
</nextsent>
<nextsent>for our final submissions, we use training and development data to build our models.
</nextsent>
<nextsent>results table 1 shows the results for variations of full brevity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2949">
<title id=" W09-0614.xml">a wizardofoz environment to study referring expression generation in a situated spoken dialogue task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the users?
</prevsent>
<prevsent>responses to different res are then logged and studied.
</prevsent>
</prevsection>
<citsent citstr=" W09-0611 ">
(janarthanam and lemon, 2009) <papid> W09-0611 </papid>presented framework for reinforcement learning of optimal natural language generation strategies to choose appropriate res to users with different domain knowledge expertise.</citsent>
<aftsection>
<nextsent>for this, we need user simulations with different domain knowledge profiles that are sensitive to the systems choice of res.
</nextsent>
<nextsent>awoz environment is an ideal tool for data collection to build data-driven user simulations.
</nextsent>
<nextsent>how ever, our study requires novel woz environment.in section 2, we present prior related work.
</nextsent>
<nextsent>section 3 describes the task performed by participants.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2950">
<title id=" W08-1501.xml">mitigation of data sparsity in classifier based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more.
</prevsent>
<prevsent>all these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer.
</prevsent>
</prevsection>
<citsent citstr=" W06-3711 ">
it is quite common, though, to use other means of translation in parallel to the smt methods (gao etal., 2006; <papid> W06-3711 </papid>stallard et al, 2006).</citsent>
<aftsection>
<nextsent>concept classification, as an alternative translation method, has been successfully integrated in speech-to-speech translators (narayanan et al, 2003; ehsani et al, 2006).<papid> W06-3708 </papid></nextsent>
<nextsent>a well defined dialog domain, e.g. doctor-patientdialog, can be partly covered by number of concept classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2951">
<title id=" W08-1501.xml">mitigation of data sparsity in classifier based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer.
</prevsent>
<prevsent>it is quite common, though, to use other means of translation in parallel to the smt methods (gao etal., 2006; <papid> W06-3711 </papid>stallard et al, 2006).</prevsent>
</prevsection>
<citsent citstr=" W06-3708 ">
concept classification, as an alternative translation method, has been successfully integrated in speech-to-speech translators (narayanan et al, 2003; ehsani et al, 2006).<papid> W06-3708 </papid></citsent>
<aftsection>
<nextsent>a well defined dialog domain, e.g. doctor-patientdialog, can be partly covered by number of concept classes.
</nextsent>
<nextsent>upon successful classification of the input utterance, the translation task reduces to ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2952">
<title id=" W08-1501.xml">mitigation of data sparsity in classifier based translation </title>
<section> data and experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as the test corpus for this work, 1,000 phrases were randomly drawn from the above set and the rest were used for training.
</prevsent>
<prevsent>to make sure that the training set covered every class, one phrase per class was excluded from the test set selection process.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
to generate the n-best lists, phrase based smt(koehn et al, 2003) <papid> N03-1017 </papid>was used.</citsent>
<aftsection>
<nextsent>the intermediate language was farsi and the smt was trained on parallel english/farsi corpus with 148k lines (1.2m words) on the english side.
</nextsent>
<nextsent>this corpus was also used to build the classification background models in both languages.
</nextsent>
<nextsent>the smt was optimized using parallel development set with 915 lines (7.3k words) on the english side.
</nextsent>
<nextsent>4.2 classification accuracy measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2953">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there are quite lot of work on semantic classi?
</prevsent>
<prevsent>cation of words with corpus-based approach.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the earliest work in this direction are those of (hindle, 1990), (lin, 1998), (<papid> P98-2127 </papid>dagan et al, 1999), (chen and chen, 2000), (<papid> C00-1026 </papid>geffet and dagan, 2004) and (weeds and weir, 2005).<papid> J05-4002 </papid></citsent>
<aftsection>
<nextsent>they used distributionalsimilarity.
</nextsent>
<nextsent>similarity measures based on distributional hypothesis compare pair of weighted feature vectors that characterize two words.
</nextsent>
<nextsent>features typically correspond to other words that co-occur with the characterized word in the same context.
</nextsent>
<nextsent>lin (1998) <papid> P98-2127 </papid>proposed word similarity measure based on the distributional pattern of words which allows to construct thesaurus using parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2954">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there are quite lot of work on semantic classi?
</prevsent>
<prevsent>cation of words with corpus-based approach.
</prevsent>
</prevsection>
<citsent citstr=" C00-1026 ">
the earliest work in this direction are those of (hindle, 1990), (lin, 1998), (<papid> P98-2127 </papid>dagan et al, 1999), (chen and chen, 2000), (<papid> C00-1026 </papid>geffet and dagan, 2004) and (weeds and weir, 2005).<papid> J05-4002 </papid></citsent>
<aftsection>
<nextsent>they used distributionalsimilarity.
</nextsent>
<nextsent>similarity measures based on distributional hypothesis compare pair of weighted feature vectors that characterize two words.
</nextsent>
<nextsent>features typically correspond to other words that co-occur with the characterized word in the same context.
</nextsent>
<nextsent>lin (1998) <papid> P98-2127 </papid>proposed word similarity measure based on the distributional pattern of words which allows to construct thesaurus using parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2955">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there are quite lot of work on semantic classi?
</prevsent>
<prevsent>cation of words with corpus-based approach.
</prevsent>
</prevsection>
<citsent citstr=" J05-4002 ">
the earliest work in this direction are those of (hindle, 1990), (lin, 1998), (<papid> P98-2127 </papid>dagan et al, 1999), (chen and chen, 2000), (<papid> C00-1026 </papid>geffet and dagan, 2004) and (weeds and weir, 2005).<papid> J05-4002 </papid></citsent>
<aftsection>
<nextsent>they used distributionalsimilarity.
</nextsent>
<nextsent>similarity measures based on distributional hypothesis compare pair of weighted feature vectors that characterize two words.
</nextsent>
<nextsent>features typically correspond to other words that co-occur with the characterized word in the same context.
</nextsent>
<nextsent>lin (1998) <papid> P98-2127 </papid>proposed word similarity measure based on the distributional pattern of words which allows to construct thesaurus using parsed corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2957">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>lin (1998) <papid> P98-2127 </papid>proposed word similarity measure based on the distributional pattern of words which allows to construct thesaurus using parsed corpus.</prevsent>
<prevsent>he compared the result of automatically created thesaurus with wordnet and roget, andre ported that the result was signicantly closer to wordnet than roget thesaurus was.</prevsent>
</prevsection>
<citsent citstr=" W06-3811 ">
graph representations for word similarity have also been proposed by several researchers (jan nink and wiederhold, 1999; galley and mckeown, 2003; muller et al, 2006).<papid> W06-3811 </papid></citsent>
<aftsection>
<nextsent>sinha and mihalcea(2007) proposed graph-based algorithm for unsupervised word sense disambiguation which combines several semantic similarity measures including resniks metric (resnik, 1995), and algorithms for graph centrality.
</nextsent>
<nextsent>they reported that the results using the senseval-2 and senseval-3 english all-words datasets lead to relative error rate reductions of 5 ? 8% as compared to the previous work (mihalcea, 2005).<papid> H05-1052 </papid></nextsent>
<nextsent>in the context of graph-based clustering of words, widdows and dorow (2002) <papid> C02-1114 </papid>used graph model for unsupervised lexical acquisition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2958">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>graph representations for word similarity have also been proposed by several researchers (jan nink and wiederhold, 1999; galley and mckeown, 2003; muller et al, 2006).<papid> W06-3811 </papid></prevsent>
<prevsent>sinha and mihalcea(2007) proposed graph-based algorithm for unsupervised word sense disambiguation which combines several semantic similarity measures including resniks metric (resnik, 1995), and algorithms for graph centrality.</prevsent>
</prevsection>
<citsent citstr=" H05-1052 ">
they reported that the results using the senseval-2 and senseval-3 english all-words datasets lead to relative error rate reductions of 5 ? 8% as compared to the previous work (mihalcea, 2005).<papid> H05-1052 </papid></citsent>
<aftsection>
<nextsent>in the context of graph-based clustering of words, widdows and dorow (2002) <papid> C02-1114 </papid>used graph model for unsupervised lexical acquisition.</nextsent>
<nextsent>the graph structure is built by linking pairs of words which participate in particular syntactic relation ships.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2959">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>sinha and mihalcea(2007) proposed graph-based algorithm for unsupervised word sense disambiguation which combines several semantic similarity measures including resniks metric (resnik, 1995), and algorithms for graph centrality.
</prevsent>
<prevsent>they reported that the results using the senseval-2 and senseval-3 english all-words datasets lead to relative error rate reductions of 5 ? 8% as compared to the previous work (mihalcea, 2005).<papid> H05-1052 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
in the context of graph-based clustering of words, widdows and dorow (2002) <papid> C02-1114 </papid>used graph model for unsupervised lexical acquisition.</citsent>
<aftsection>
<nextsent>the graph structure is built by linking pairs of words which participate in particular syntactic relationships.
</nextsent>
<nextsent>an incremental cluster-building algorithm using the graph structure achieved 82% accuracy ata lexical acquisition task, evaluated against wordnet 10 classes, and each class consists of 20 words.
</nextsent>
<nextsent>matsuo et al (2006) <papid> W06-1664 </papid>proposed method of word clustering based on word similarity measure by web counts.</nextsent>
<nextsent>they used newman clustering for clustering algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2960">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the graph structure is built by linking pairs of words which participate in particular syntactic relationships.
</prevsent>
<prevsent>an incremental cluster-building algorithm using the graph structure achieved 82% accuracy ata lexical acquisition task, evaluated against wordnet 10 classes, and each class consists of 20 words.
</prevsent>
</prevsection>
<citsent citstr=" W06-1664 ">
matsuo et al (2006) <papid> W06-1664 </papid>proposed method of word clustering based on word similarity measure by web counts.</citsent>
<aftsection>
<nextsent>they used newman clustering for clustering algorithm.
</nextsent>
<nextsent>they evaluated their method using two sets of word classes.
</nextsent>
<nextsent>one is derived from the web data, and another is from wordnet.1 each set consists of 90 noun words.
</nextsent>
<nextsent>they reported that the results obtained by newman clustering were better than those obtained by average-link agglom erative clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2961">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>1.
</prevsent>
<prevsent>mutual information.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
church and hanks (1990) <papid> J90-1003 </papid>discussed the use of the mutual information statistics as way to identify variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/contentword) to lexico-syntactic co-occurrence preferences between verbs and prepositions (content word/function word).</citsent>
<aftsection>
<nextsent>let oi and oj be ono words retrieved from the web.
</nextsent>
<nextsent>the mutual information mi(oi, oj) is dened as: mi(oi, oj) = log sall ? f(oi, oj) soi ? soj , (1) where soi = ? koall f(oi, ok), (2) sall = ? oioall soi .
</nextsent>
<nextsent>(3) in eq.
</nextsent>
<nextsent>(1), f(oi, oj) refers to the frequency of oi and oj occurring together, and oall is set of all ono words retrieved from the web.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2962">
<title id=" W08-2005.xml">graph based clustering for semantic classification of onomatopoetic words </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>y), where d(x||y) refers to kullback-leibler and dened as: d(x||y) = n?
</prevsent>
<prevsent>i=1 xi ? log xi yi .
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
(6) 35 lee (1999) <papid> P99-1004 </papid>reported the best results with ? = 0.9.</citsent>
<aftsection>
<nextsent>we used the same value.
</nextsent>
<nextsent>we dened similarity metric by combining co-occurrence based and orthographic similarity measures2: sim(oi, oj) = mi(oi, oj)?
</nextsent>
<nextsent>(cos(oi, oj) + 1) (7) 3.3 the newman clustering algorithm.
</nextsent>
<nextsent>we classied ono words collected from the www.therefore, the clustering algorithm should be efcient and effective even in the very high dimensional spaces.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2963">
<title id=" W09-0619.xml">the effect of linguistic devices in information presentation messages on recall and comprehension </title>
<section> experiment 2: web-based recall of.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, conducting experiments online significantly reduces the effort involved in data collection for the experimenter.
</prevsent>
<prevsent>moreover, the website allows for convenient payment for both participants and the experimenter.
</prevsent>
</prevsection>
<citsent citstr=" P08-1080 ">
for these reasons, mt has recently been used in number of language experiments (e.g., kaisser et al, 2008; <papid> P08-1080 </papid>kittur et al, 2008).</citsent>
<aftsection>
<nextsent>4.1 participants.
</nextsent>
<nextsent>we had 60 participants reading the same materials that were used in experiment 1.
</nextsent>
<nextsent>mt does allow to place restrictions on participant location(only users from the us were allowed to participate to ensure english language skills), for instance, or the number of trials (each participant was only allowed to participate once).
</nextsent>
<nextsent>however,one cannot balance gender of participants or control for age and literacy reliably, as user provided data cannot be verified.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2964">
<title id=" W09-1216.xml">multilingual semantic parsing with a pipeline of linear classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents my submission for the semantic parsing track of the conll 2009 shared task on syntactic and semantic dependencies in multiple languages (hajic?
</prevsent>
<prevsent>et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
the submitted parser is simpler than the submission in which participated at the conll 2008 shared task on joint learning of syntactic and semantic dependencies (surdeanu etal., 2008), <papid> W08-2121 </papid>in which we used more complex committee based approach to both syntax and semantics (samuelsson et al, 2008).<papid> W08-2136 </papid></citsent>
<aftsection>
<nextsent>results are on par with our previous system, while the parser is orders of magnitude faster both at training and prediction timeand is able to process natural language text in catalan, chinese, czech, english, german, japanese andspanish.
</nextsent>
<nextsent>the parser depends on the input to be annotated with part-of-speech tags and syntactic dependencies.
</nextsent>
<nextsent>the semantic parser is implemented as pipeline of linear classifiers and greedy constraint satisfaction post-processing step.
</nextsent>
<nextsent>the implementation is very similar to the best performing subsystem of the committee based system in samuelsson et al (2008).<papid> W08-2136 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2965">
<title id=" W09-1216.xml">multilingual semantic parsing with a pipeline of linear classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents my submission for the semantic parsing track of the conll 2009 shared task on syntactic and semantic dependencies in multiple languages (hajic?
</prevsent>
<prevsent>et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W08-2136 ">
the submitted parser is simpler than the submission in which participated at the conll 2008 shared task on joint learning of syntactic and semantic dependencies (surdeanu etal., 2008), <papid> W08-2121 </papid>in which we used more complex committee based approach to both syntax and semantics (samuelsson et al, 2008).<papid> W08-2136 </papid></citsent>
<aftsection>
<nextsent>results are on par with our previous system, while the parser is orders of magnitude faster both at training and prediction timeand is able to process natural language text in catalan, chinese, czech, english, german, japanese andspanish.
</nextsent>
<nextsent>the parser depends on the input to be annotated with part-of-speech tags and syntactic dependencies.
</nextsent>
<nextsent>the semantic parser is implemented as pipeline of linear classifiers and greedy constraint satisfaction post-processing step.
</nextsent>
<nextsent>the implementation is very similar to the best performing subsystem of the committee based system in samuelsson et al (2008).<papid> W08-2136 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2967">
<title id=" W09-1216.xml">multilingual semantic parsing with a pipeline of linear classifiers </title>
<section> semantic parser.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 argument identification and labelling.
</prevsent>
<prevsent>in line with most previous pipe lined systems, identification and labelling of arguments are perform edas two separate steps.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
the classifiers in the identification step are trained with the standard l2-losssvm formulation, while the classifiers in the labelling step are trained using the method of crammer and singer.in order to reduce the number of candidate arguments in the identification step, apply the filtering technique of xue and palmer (2004), <papid> W04-3212 </papid>triviallyadopted to the dependency syntax formalism.</citsent>
<aftsection>
<nextsent>further, filtering heuristic is applied in which argument candidates with rare predicate / argument part of-speech combinations are removed; rare meaning that the argument candidate is actually an argument in less than 0.05% of the occurrences of the pair.these heuristics greatly reduce the number of instances in the argument identification step and improve performance by reducing noise from the training data.separate classifiers are trained for verbal predicates and for nominal predicates, both in order to save computational resources and because the frame structures do not generalise between verb aland nominal predicates.
</nextsent>
<nextsent>for czech, in order to reduce training time split the argument identification problem into three sub-problems: verbs, nouns and others, based on the part-of-speech of the predicate.
</nextsent>
<nextsent>in hindsight, after solving file encoding related bug which affected the separability of the czech dataset, split into verbal and nominal predicates would have sufficed.
</nextsent>
<nextsent>unfortunately was not able to rerun the czech experiments on time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2968">
<title id=" W09-1216.xml">multilingual semantic parsing with a pipeline of linear classifiers </title>
<section> semantic parser.  </section>
<citcontext>
<prevsection>
<prevsent>in hindsight, after solving file encoding related bug which affected the separability of the czech dataset, split into verbal and nominal predicates would have sufficed.
</prevsent>
<prevsent>unfortunately was not able to rerun the czech experiments on time.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
2.2.1 feature templates the following feature templates are used both for argument identification and argument labelling: predicatelemmasense predicate[pos/feats] position argument[pos/feats] argument[word/lemma] argumentwindowpositionlemma argumentwindowposition[pos/feats] leftsiblingword leftsibling[pos/feats] rightsiblingword rightsibling[pos/feats] leftdependentword rightdependent[pos/feats] relation path trigramrelationpath governor relation governor lemma governor[pos/feats]most of these features, introduced by gildea and jurafsky (2002), <papid> J02-3001 </papid>belong to the folklore by now.</citsent>
<aftsection>
<nextsent>the trigramrelationpath is soft?
</nextsent>
<nextsent>version of the relation path template, which treats the relation path as bag of triplets of directional labelled dependency relations.
</nextsent>
<nextsent>initial experiments suggested that this feature slightly improves performance, by overcoming local syntactic parse errors and data sparseness in the case of small training sets.
</nextsent>
<nextsent>2.2.2 predicate frame constraints following johansson and nugues (2008) impose the core argument consistency and con 104tinuation consistency constraints on the generated semantic frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2970">
<title id=" W09-0712.xml">towards an electronic dictionary of tamajaq language in niger </title>
<section> the tamajaq language.  </section>
<citcontext>
<prevsection>
<prevsent>lateral ? palatal plosive ? fricative ? semi vowel velar plosive g, ? fricative ? nasal ? glottal plosive fricative table 1a: articulary phone tics of tamajaq consonants 81 vowels close close-mid open-mid open palatal e central ? a labial o table 1b: articulary phone tics of tamajaq vowels 1.4 tools on computers.
</prevsent>
<prevsent>there are no specific taln tools for the tama jaq language.
</prevsent>
</prevsection>
<citsent citstr=" L08-1362 ">
however characters can be easily typed on french keyboards thanks to the afro keyboard layout (enguehard and al. 2008).<papid> L08-1362 </papid></citsent>
<aftsection>
<nextsent>we use the school editorial dictionary  diction naire tamajaq-franais destin?
</nextsent>
<nextsent>l enseignement du cycle debase 1 .
</nextsent>
<nextsent>it was written by the souteba1 project of the ded2 organisation in 2006.
</nextsent>
<nextsent>because it targets children, this dictionary consists only of 5,390 entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2971">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a synset is often further described by gloss, in this case:  an organisation to gain political power  and by explicit semantic relations to other synsets.
</prevsent>
<prevsent>fortunately, during the last years the research community has devised large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora.
</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
among others we can mention extended wordnet (mihalcea and moldovan, 2001), large collections of semantic preferences acquired from semcor (agirre and martinez, 2001, <papid> W01-0703 </papid>2002) or acquired from british national corpus (bnc) (mccarthy, 2001), large-scale topic signatures for each synset acquired from the web (agirre and de lacalle, 2004) or knowledge about individuals from wikipedia (suchanek et al, 2007).</citsent>
<aftsection>
<nextsent>obviously, all these semantic resources have been acquired using very different set of processes (snow et al, 2006), <papid> P06-1101 </papid>tools and corpora.</nextsent>
<nextsent>in fact, each semantic resource has different volume and accuracy figures when evaluated in common and controlled framework (cuadros and rigau, 2006).<papid> W06-1663 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2972">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fortunately, during the last years the research community has devised large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora.
</prevsent>
<prevsent>among others we can mention extended wordnet (mihalcea and moldovan, 2001), large collections of semantic preferences acquired from semcor (agirre and martinez, 2001, <papid> W01-0703 </papid>2002) or acquired from british national corpus (bnc) (mccarthy, 2001), large-scale topic signatures for each synset acquired from the web (agirre and de lacalle, 2004) or knowledge about individuals from wikipedia (suchanek et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
obviously, all these semantic resources have been acquired using very different set of processes (snow et al, 2006), <papid> P06-1101 </papid>tools and corpora.</citsent>
<aftsection>
<nextsent>in fact, each semantic resource has different volume and accuracy figures when evaluated in common and controlled framework (cuadros and rigau, 2006).<papid> W06-1663 </papid></nextsent>
<nextsent>however, not all available large-scale resources encode semantic relations between synsets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2973">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>among others we can mention extended wordnet (mihalcea and moldovan, 2001), large collections of semantic preferences acquired from semcor (agirre and martinez, 2001, <papid> W01-0703 </papid>2002) or acquired from british national corpus (bnc) (mccarthy, 2001), large-scale topic signatures for each synset acquired from the web (agirre and de lacalle, 2004) or knowledge about individuals from wikipedia (suchanek et al, 2007).</prevsent>
<prevsent>obviously, all these semantic resources have been acquired using very different set of processes (snow et al, 2006), <papid> P06-1101 </papid>tools and corpora.</prevsent>
</prevsection>
<citsent citstr=" W06-1663 ">
in fact, each semantic resource has different volume and accuracy figures when evaluated in common and controlled framework (cuadros and rigau, 2006).<papid> W06-1663 </papid></citsent>
<aftsection>
<nextsent>however, not all available large-scale resources encode semantic relations between synsets.
</nextsent>
<nextsent>in some cases, only relations between synsets and words have been acquired.
</nextsent>
<nextsent>this is the case of the topic signatures (agirre et al, 2000) acquired from the web (agirre and de lacalle, 2004).
</nextsent>
<nextsent>this is one of the largest semantic resources ever built with around one hundred million relations between synsets and semantically related 1symmetric relations are counted only once.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2974">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> topic signatures.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5, we present the evaluation framework used in this study.
</prevsent>
<prevsent>section 6 describes the results when evaluating different versions of knownet and finally, section 7 presents some concluding remarks and future work.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
topic signatures (ts) are word vectors related to particular topic (lin and hovy, 2000).<papid> C00-1072 </papid></citsent>
<aftsection>
<nextsent>topic signatures are built by retrieving context words of target topic from large corpora.
</nextsent>
<nextsent>in our case, we consider word senses as topics.
</nextsent>
<nextsent>basically, the acquisition of ts consists of: ? acquiring the best possible corpus examples for particular word sense (usually characterising each word sense as query and performing search on the corpus 2available at http://ixa.si.ehu.es/ixa/resources/sensecorpus 3these knownet versions can be downloaded from http://adimen.si.ehu.es 74 cuadros and rigau.
</nextsent>
<nextsent>table 2: ts of party#n#1 (first 10 out of 12,890 total words) tammany#n 0.0319 alinement#n 0.0316 federalist#n 0.0315 whig#n 0.0300 missionary#j 0.0229 democratic#n 0.0218 nazi#j 0.0202 republican#n 0.0189 constitutional#n 0.0186 organization#n 0.0163 for those examples that best match the queries) ? building the ts by deriving the context words that best represent the word sense from the selected corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2975">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> topic signatures.  </section>
<citcontext>
<prevsection>
<prevsent>table 2: ts of party#n#1 (first 10 out of 12,890 total words) tammany#n 0.0319 alinement#n 0.0316 federalist#n 0.0315 whig#n 0.0300 missionary#j 0.0229 democratic#n 0.0218 nazi#j 0.0202 republican#n 0.0189 constitutional#n 0.0186 organization#n 0.0163 for those examples that best match the queries) ? building the ts by deriving the context words that best represent the word sense from the selected corpora.
</prevsent>
<prevsent>the topic signatures acquired from the web (hereinafter tsweb) constitutes one of the largest available semantic resources with around 100 million relations (between synsets and words) (agirre and de lacalle, 2004).
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
inspired by the work of leacock et al (1998), <papid> J98-1006 </papid>tsweb was constructed using monosemous relatives from wn (syn onyms, hypernyms, direct and indirect hyponyms, and siblings), querying google and retrieving up to one thousand snippets per query (that is, word sense), extracting the salient words with distinctive frequency using tfidf.</citsent>
<aftsection>
<nextsent>thus, tsweb consist of alarge ordered list of words with weights associated to each of the senses of the poly semous nouns of wordnet 1.6.
</nextsent>
<nextsent>the number of constructed topic signatures is 35,250 with an average size per signature of 6,877 words.
</nextsent>
<nextsent>when evaluating tsweb, we used at maximum the first 700 words while for building knownet we used at maximum the first 20 words.
</nextsent>
<nextsent>for example, table 2 present the first words (lemmas and part-of-speech) and weights of the topic signature acquired for party#n#1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2976">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> topic signatures.  </section>
<citcontext>
<prevsection>
<prevsent>for example, table 2 present the first words (lemmas and part-of-speech) and weights of the topic signature acquired for party#n#1.
</prevsent>
<prevsent>it is our belief, that accurate semantic processing (such as wsd) would rely not only on sophisticated algorithms but on knowledge intensive approaches.
</prevsent>
</prevsection>
<citsent citstr=" W02-1304 ">
in fact,the cycling arquitecture of the meaning4 project demonstrated that acquiring better knowledge allow to perform better word sense disambiguation (wsd) and that having improved wsd systems we are able to acquire better knowledge (rigau et al, 2002).<papid> W02-1304 </papid></citsent>
<aftsection>
<nextsent>thus, we plan to acquire by fully automatic means highly connected and dense knowledge bases from large corpora or the web by using the knowledge already available, increasing the total number of relations from less than one million (the current number of available relations) to millions.
</nextsent>
<nextsent>4http://www.lsi.upc.edu/~nlp/meaning knownet: proposal for building knowledge bases from the web 75 the current proposal consist of: ? to follow cuadros et al (2005) and cuadros and rigau (2006) <papid> W06-1663 </papid>for acquiring highly accurate topic signatures for all monosemous words in wordnet (for instance, using infomap (dorow and widdows, 2003)).<papid> E03-1020 </papid></nextsent>
<nextsent>that is, to acquire word vectors closely related to particular monosemousword (for instance, air port#n#1) from bnc or other large text collections like gigaword, wikipedia or the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2978">
<title id=" W08-2207.xml">knownet a proposal for building highly connected and dense knowledge bases from the web </title>
<section> topic signatures.  </section>
<citcontext>
<prevsection>
<prevsent>in fact,the cycling arquitecture of the meaning4 project demonstrated that acquiring better knowledge allow to perform better word sense disambiguation (wsd) and that having improved wsd systems we are able to acquire better knowledge (rigau et al, 2002).<papid> W02-1304 </papid></prevsent>
<prevsent>thus, we plan to acquire by fully automatic means highly connected and dense knowledge bases from large corpora or the web by using the knowledge already available, increasing the total number of relations from less than one million (the current number of available relations) to millions.</prevsent>
</prevsection>
<citsent citstr=" E03-1020 ">
4http://www.lsi.upc.edu/~nlp/meaning knownet: proposal for building knowledge bases from the web 75 the current proposal consist of: ? to follow cuadros et al (2005) and cuadros and rigau (2006) <papid> W06-1663 </papid>for acquiring highly accurate topic signatures for all monosemous words in wordnet (for instance, using infomap (dorow and widdows, 2003)).<papid> E03-1020 </papid></citsent>
<aftsection>
<nextsent>that is, to acquire word vectors closely related to particular monosemousword (for instance, air port#n#1) from bnc or other large text collections like gigaword, wikipedia or the web.
</nextsent>
<nextsent>to apply very accurate knowledge based all words disambiguation algorithm to the topic signatures in order to obtain sense vectors instead of word vectors (for instance, using version of structural semantic interconnections algorithm (ssi) (navigli and velardi, 2005)).for instance, consider the first ten weighted words (with part-of-speech) appearing in the topic signature (ts) of the word sense airport#n#1 corresponding to the monosemous word airport, as shown in table 3.
</nextsent>
<nextsent>this ts has been obtained from bnc using infomap.
</nextsent>
<nextsent>from the ten words appearing in the ts, two of them do not appear in wn (corresponding to the proper names heathrow#n and gatwick#n), four words are monosemous (airport#n, airfield#n, travelling#n and passenger#n) and four other are polysemous (flight#n, train#n, station#n and ferry#n).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2979">
<title id=" W08-1305.xml">parser evaluation across frameworks without format conversion </title>
<section> converting analyses given in different.  </section>
<citcontext>
<prevsection>
<prevsent>converting an analysis given in certain for-.
</prevsent>
<prevsent>mat native to one framework to another native to differernt framework (e.g. converting from ccg (steedman, 2000) derivation tree to an hpsg (pollard and sag, 1994) phrase structure tree with avm)
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
framework-specific formats to some simpler format proposed as framework-independent evaluation schema (e.g. converting from 29 hpsg phrase structure tree with avm to gr (briscoe et al, 2006)) <papid> P06-4020 </papid>however, the feasibility of either solution isquestionable.</citsent>
<aftsection>
<nextsent>even conversion between two evaluation schemata which make use of the simplest representation of syntactic information in the form of dependencies is reported to be problematic by (miyao et al, 2007).
</nextsent>
<nextsent>in this paper, therefore, we propose different method of parser evaluation that makes no attempt at any conversion of syntactic structures and semantic representations.
</nextsent>
<nextsent>we remove the need forsuch conversion by abstracting away from comparison of syntactic structures and semantic representations.
</nextsent>
<nextsent>the basic idea is to generate list of names of phenomena with each parse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2985">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>a subtree in such hierarchy can be viewed as defining concept.
</prevsent>
<prevsent>a major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and clustering in that space.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
pereira (1993), curran (2002) and lin (1998) <papid> P98-2127 </papid>use syntactic features in the vector definition.</citsent>
<aftsection>
<nextsent>(pantel and lin, 2002) improves on the latter by clustering by committee.
</nextsent>
<nextsent>caraballo (1999) <papid> P99-1016 </papid>uses conjunction and appositive annotations in the vector representa tion.</nextsent>
<nextsent>several studies avoid requiring any syntacticannotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2986">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>pereira (1993), curran (2002) and lin (1998) <papid> P98-2127 </papid>use syntactic features in the vector definition.</prevsent>
<prevsent>(pantel and lin, 2002) improves on the latter by clustering by committee.</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
caraballo (1999) <papid> P99-1016 </papid>uses conjunction and appositive annotations in the vector representa tion.</citsent>
<aftsection>
<nextsent>several studies avoid requiring any syntacticannotation.
</nextsent>
<nextsent>some methods are based on decomposition of lexically-defined matrix (by svd, pca etc), e.g.
</nextsent>
<nextsent>(schutze, 1998; deer wester et al, 1990).while great effort has been made for improving the computational complexity of distributional methods (gorman and curran, 2006), <papid> P06-1046 </papid>they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets.the second main approach is to use lexico syntactic patterns.</nextsent>
<nextsent>patterns have been shown to produce more accurate results than feature vectors, ata lower computational cost on large corpora (pan tel et al, 2004).<papid> C04-1111 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2987">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>several studies avoid requiring any syntacticannotation.
</prevsent>
<prevsent>some methods are based on decomposition of lexically-defined matrix (by svd, pca etc), e.g.
</prevsent>
</prevsection>
<citsent citstr=" P06-1046 ">
(schutze, 1998; deer wester et al, 1990).while great effort has been made for improving the computational complexity of distributional methods (gorman and curran, 2006), <papid> P06-1046 </papid>they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets.the second main approach is to use lexico syntactic patterns.</citsent>
<aftsection>
<nextsent>patterns have been shown to produce more accurate results than feature vectors, ata lower computational cost on large corpora (pan tel et al, 2004).<papid> C04-1111 </papid></nextsent>
<nextsent>since (hearst, 1992), <papid> C92-2082 </papid>who used amanually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2988">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>some methods are based on decomposition of lexically-defined matrix (by svd, pca etc), e.g.
</prevsent>
<prevsent>(schutze, 1998; deer wester et al, 1990).while great effort has been made for improving the computational complexity of distributional methods (gorman and curran, 2006), <papid> P06-1046 </papid>they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets.the second main approach is to use lexico syntactic patterns.</prevsent>
</prevsection>
<citsent citstr=" C04-1111 ">
patterns have been shown to produce more accurate results than feature vectors, ata lower computational cost on large corpora (pan tel et al, 2004).<papid> C04-1111 </papid></citsent>
<aftsection>
<nextsent>since (hearst, 1992), <papid> C92-2082 </papid>who used amanually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds.</nextsent>
<nextsent>other studies develop concept acquisition for on-demand tasks where concepts are defined by user-providedseeds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2989">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(schutze, 1998; deer wester et al, 1990).while great effort has been made for improving the computational complexity of distributional methods (gorman and curran, 2006), <papid> P06-1046 </papid>they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets.the second main approach is to use lexico syntactic patterns.</prevsent>
<prevsent>patterns have been shown to produce more accurate results than feature vectors, ata lower computational cost on large corpora (pan tel et al, 2004).<papid> C04-1111 </papid></prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
since (hearst, 1992), <papid> C92-2082 </papid>who used amanually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds.</citsent>
<aftsection>
<nextsent>other studies develop concept acquisition for on-demand tasks where concepts are defined by user-providedseeds.
</nextsent>
<nextsent>many of these studies utilize information obtained by language-specific parsing and named entity recognition tools (dorow et al, 2005).
</nextsent>
<nextsent>pantel et al.
</nextsent>
<nextsent>(2004) reduce the depth of linguistic data used, but their method requires pos tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2990">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>however, this system contains many language-specific modules, including the utilization of parser in one of the processing stages.
</prevsent>
<prevsent>thus the majority of the existing pattern-based concept acquisition systems relyon pattern/word seeds or supervised language-specific tools, some of which are very inefficient.
</prevsent>
</prevsection>
<citsent citstr=" P06-1038 ">
davidov and rappoport (2006) <papid> P06-1038 </papid>developed framework which discovers concepts based on high frequency words and symmetry-based pattern graphproperties.</citsent>
<aftsection>
<nextsent>this framework allows fully unsupervised seed-less discovery of concepts without relying on language-specific tools.
</nextsent>
<nextsent>however, it completely ignores potentially useful syntactic or morphological information.
</nextsent>
<nextsent>for example, the pattern and his y?
</nextsent>
<nextsent>is useful for acquiring the concept of family member types,as in his siblings and his parents?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2991">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as result, incorporating at least some parsing information in language-independent and efficient manner could be beneficial.unsupervised parsing has been explored for several decades (see (clark, 2001; klein, 2005) for recent reviews).
</prevsent>
<prevsent>recently, unsupervised parsers havefor the first time outperformed the right branching heuristic baseline for english.
</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
these include ccm (klein and manning, 2002), <papid> P02-1017 </papid>the dmv and dmv+ccm models (klein and manning, 2004), (<papid> P04-1061 </papid>u)dop based models (bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b;bod, 2007), <papid> P07-1051 </papid>an exemplar based approach (den nis, 2005), guiding em using contrastive estimation (smith and eisner, 2006), <papid> P06-1072 </papid>and the incremental parser of seginer (2007) <papid> P07-1049 </papid>which we use here.</citsent>
<aftsection>
<nextsent>these works learn an unlabeled syntactic structure, dependency or constituency.
</nextsent>
<nextsent>in this work we use constituency trees as our syntactic representation.
</nextsent>
<nextsent>another important factor in concept acquisition is the source of textual data used.
</nextsent>
<nextsent>to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2992">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as result, incorporating at least some parsing information in language-independent and efficient manner could be beneficial.unsupervised parsing has been explored for several decades (see (clark, 2001; klein, 2005) for recent reviews).
</prevsent>
<prevsent>recently, unsupervised parsers havefor the first time outperformed the right branching heuristic baseline for english.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
these include ccm (klein and manning, 2002), <papid> P02-1017 </papid>the dmv and dmv+ccm models (klein and manning, 2004), (<papid> P04-1061 </papid>u)dop based models (bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b;bod, 2007), <papid> P07-1051 </papid>an exemplar based approach (den nis, 2005), guiding em using contrastive estimation (smith and eisner, 2006), <papid> P06-1072 </papid>and the incremental parser of seginer (2007) <papid> P07-1049 </papid>which we use here.</citsent>
<aftsection>
<nextsent>these works learn an unlabeled syntactic structure, dependency or constituency.
</nextsent>
<nextsent>in this work we use constituency trees as our syntactic representation.
</nextsent>
<nextsent>another important factor in concept acquisition is the source of textual data used.
</nextsent>
<nextsent>to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE2993">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as result, incorporating at least some parsing information in language-independent and efficient manner could be beneficial.unsupervised parsing has been explored for several decades (see (clark, 2001; klein, 2005) for recent reviews).
</prevsent>
<prevsent>recently, unsupervised parsers havefor the first time outperformed the right branching heuristic baseline for english.
</prevsent>
</prevsection>
<citsent citstr=" W06-2912 ">
these include ccm (klein and manning, 2002), <papid> P02-1017 </papid>the dmv and dmv+ccm models (klein and manning, 2004), (<papid> P04-1061 </papid>u)dop based models (bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b;bod, 2007), <papid> P07-1051 </papid>an exemplar based approach (den nis, 2005), guiding em using contrastive estimation (smith and eisner, 2006), <papid> P06-1072 </papid>and the incremental parser of seginer (2007) <papid> P07-1049 </papid>which we use here.</citsent>
<aftsection>
<nextsent>these works learn an unlabeled syntactic structure, dependency or constituency.
</nextsent>
<nextsent>in this work we use constituency trees as our syntactic representation.
</nextsent>
<nextsent>another important factor in concept acquisition is the source of textual data used.
</nextsent>
<nextsent>to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3001">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as result, incorporating at least some parsing information in language-independent and efficient manner could be beneficial.unsupervised parsing has been explored for several decades (see (clark, 2001; klein, 2005) for recent reviews).
</prevsent>
<prevsent>recently, unsupervised parsers havefor the first time outperformed the right branching heuristic baseline for english.
</prevsent>
</prevsection>
<citsent citstr=" P07-1051 ">
these include ccm (klein and manning, 2002), <papid> P02-1017 </papid>the dmv and dmv+ccm models (klein and manning, 2004), (<papid> P04-1061 </papid>u)dop based models (bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b;bod, 2007), <papid> P07-1051 </papid>an exemplar based approach (den nis, 2005), guiding em using contrastive estimation (smith and eisner, 2006), <papid> P06-1072 </papid>and the incremental parser of seginer (2007) <papid> P07-1049 </papid>which we use here.</citsent>
<aftsection>
<nextsent>these works learn an unlabeled syntactic structure, dependency or constituency.
</nextsent>
<nextsent>in this work we use constituency trees as our syntactic representation.
</nextsent>
<nextsent>another important factor in concept acquisition is the source of textual data used.
</nextsent>
<nextsent>to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3002">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as result, incorporating at least some parsing information in language-independent and efficient manner could be beneficial.unsupervised parsing has been explored for several decades (see (clark, 2001; klein, 2005) for recent reviews).
</prevsent>
<prevsent>recently, unsupervised parsers havefor the first time outperformed the right branching heuristic baseline for english.
</prevsent>
</prevsection>
<citsent citstr=" P06-1072 ">
these include ccm (klein and manning, 2002), <papid> P02-1017 </papid>the dmv and dmv+ccm models (klein and manning, 2004), (<papid> P04-1061 </papid>u)dop based models (bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b;bod, 2007), <papid> P07-1051 </papid>an exemplar based approach (den nis, 2005), guiding em using contrastive estimation (smith and eisner, 2006), <papid> P06-1072 </papid>and the incremental parser of seginer (2007) <papid> P07-1049 </papid>which we use here.</citsent>
<aftsection>
<nextsent>these works learn an unlabeled syntactic structure, dependency or constituency.
</nextsent>
<nextsent>in this work we use constituency trees as our syntactic representation.
</nextsent>
<nextsent>another important factor in concept acquisition is the source of textual data used.
</nextsent>
<nextsent>to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3003">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as result, incorporating at least some parsing information in language-independent and efficient manner could be beneficial.unsupervised parsing has been explored for several decades (see (clark, 2001; klein, 2005) for recent reviews).
</prevsent>
<prevsent>recently, unsupervised parsers havefor the first time outperformed the right branching heuristic baseline for english.
</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
these include ccm (klein and manning, 2002), <papid> P02-1017 </papid>the dmv and dmv+ccm models (klein and manning, 2004), (<papid> P04-1061 </papid>u)dop based models (bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b;bod, 2007), <papid> P07-1051 </papid>an exemplar based approach (den nis, 2005), guiding em using contrastive estimation (smith and eisner, 2006), <papid> P06-1072 </papid>and the incremental parser of seginer (2007) <papid> P07-1049 </papid>which we use here.</citsent>
<aftsection>
<nextsent>these works learn an unlabeled syntactic structure, dependency or constituency.
</nextsent>
<nextsent>in this work we use constituency trees as our syntactic representation.
</nextsent>
<nextsent>another important factor in concept acquisition is the source of textual data used.
</nextsent>
<nextsent>to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3004">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in this work we use constituency trees as our syntactic representation.
</prevsent>
<prevsent>another important factor in concept acquisition is the source of textual data used.
</prevsent>
</prevsection>
<citsent citstr=" P07-1030 ">
to take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (etzioni et al, 2005; davidov et al, 2007; <papid> P07-1030 </papid>pasca and van durme, 2008; davidov and rappoport, 2009).</citsent>
<aftsection>
<nextsent>while these methods have definite practical advantage of dealing with the most recent and comprehensive data, web-based evaluation has some methodological drawbacks such as limited repeatability (kilgarriff, 2007).
</nextsent>
<nextsent>in this study we apply our framework on offline corpora in settings similar to that of previous work, in order to be able to make proper comparisons.
</nextsent>
<nextsent>our method utilizes the information induced by unsupervised parsers.
</nextsent>
<nextsent>specifically, we make use of the bracketings induced by seginers parser1 (seginer,2007).<papid> P07-1049 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3006">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> efficient unsupervised parsing.  </section>
<citcontext>
<prevsection>
<prevsent>these corpora consists of newspaper texts.
</prevsent>
<prevsent>second, to obtain good results, manually created pos tags are used as input in all the unsupervised parsers mentioned above except of seginers, which uses raw sentences as input.
</prevsent>
</prevsection>
<citsent citstr=" C08-1042 ">
(headden et al, 2008) <papid> C08-1042 </papid>have shown that the performance of algorithms that require pos tags substantially decreases when using pos tags induced by unsupervised pos taggers instead of manually created ones.</citsent>
<aftsection>
<nextsent>seginers incremental parser is therefore the only fully unsupervised parser providing high quality parses.
</nextsent>
<nextsent>third, seginers parser is extremely fast.
</nextsent>
<nextsent>during its initial stage, the parser builds lexicon.
</nextsent>
<nextsent>our pentium 2.8ghb machines with 4ghb ram can storein memory the lexicon created by up to 0.2m sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3011">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> unsupervised pattern discovery.  </section>
<citcontext>
<prevsection>
<prevsent>many of the pattern candidates discovered in the previous stage are not usable.in order to find usable subset, we focus on the symmetric patterns.
</prevsent>
<prevsent>we define symmetric pattern as pattern in which the same pair of terms (c words)is likely to appear in both left-to-right and right-to left orders.
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
in order to identify symmetric patterns, for each pattern we define pattern graph g(p ), as proposed by (widdows and dorow, 2002).<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>if term pair (c1, c2) appears in pattern in some context, 3this paper does not use any punctuation since the parser is provided with sentences having all non-alphabetic characters removed.
</nextsent>
<nextsent>we assume word separation.
</nextsent>
<nextsent>c1,2 can be word or multiword expression.
</nextsent>
<nextsent>51 we add nodes c1, c2 to the graph and directed edgeep (c1, c2) between them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3045">
<title id=" W09-1108.xml">superior and efficient fully unsupervised pattern based concept acquisition using an unsupervised parser </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>timing requirements are modest, considering we parsed such large amounts of data.
</prevsent>
<prevsent>bnc parsing took 45 minutes, and the total single-machine processing time for the 68gb dmoz corpus was 4 days6.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
in comparison, state-of-art supervised parser (charniak and johnson, 2005) <papid> P05-1022 </papid>would process the same amount of data in 1.3 years7.</citsent>
<aftsection>
<nextsent>we have presented framework which utilizes an efficient fully unsupervised parser for unsupervised pattern-based discovery of concepts.
</nextsent>
<nextsent>we showed that utilization of unsupervised parser in pattern acquisition not only allows successful extraction of mwes but also improves the quality of obtained concepts, avoiding noise and adding new terms missed by the parse-less approach.
</nextsent>
<nextsent>at the same time, the framework remains fully unsupervised, allowing its straightforward application to different languages as supported by our bilingual evaluation.
</nextsent>
<nextsent>this research presents one more step towards th emerging of fully unsupervised techniques for lexical acquisition, allowing to extract semantic data without strong assumptions on domain or language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3046">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the learning procedure directly maximizes the likelihood of the training treebank, without the useof any language specific or linguistically constrained features.
</prevsent>
<prevsent>nonetheless, the resulting grammars encode many linguistically inter pre table patterns and give the best published parsing accuracies on three german treebanks.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
probabilistic context-free grammars (pcfgs) underlie most high-performance parsers in one way or an other (collins, 1999; charniak, 2000; <papid> A00-2018 </papid>charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>however, as demonstrated in charniak (1996) and klein and manning (2003), <papid> P03-1054 </papid>pcfg which simply takes the empirical rules and probabilities off of treebank does not perform well.</nextsent>
<nextsent>this naive grammar is poor one because its context freedom assumptions are too strong in some ways (e.g. it assumes that subject and object nps share the same distribution) and too weak in others (e.g. it assumes that long rewrites do not decompose into smaller steps).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3047">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the learning procedure directly maximizes the likelihood of the training treebank, without the useof any language specific or linguistically constrained features.
</prevsent>
<prevsent>nonetheless, the resulting grammars encode many linguistically inter pre table patterns and give the best published parsing accuracies on three german treebanks.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
probabilistic context-free grammars (pcfgs) underlie most high-performance parsers in one way or an other (collins, 1999; charniak, 2000; <papid> A00-2018 </papid>charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>however, as demonstrated in charniak (1996) and klein and manning (2003), <papid> P03-1054 </papid>pcfg which simply takes the empirical rules and probabilities off of treebank does not perform well.</nextsent>
<nextsent>this naive grammar is poor one because its context freedom assumptions are too strong in some ways (e.g. it assumes that subject and object nps share the same distribution) and too weak in others (e.g. it assumes that long rewrites do not decompose into smaller steps).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3048">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nonetheless, the resulting grammars encode many linguistically inter pre table patterns and give the best published parsing accuracies on three german treebanks.
</prevsent>
<prevsent>probabilistic context-free grammars (pcfgs) underlie most high-performance parsers in one way or an other (collins, 1999; charniak, 2000; <papid> A00-2018 </papid>charniak and johnson, 2005).<papid> P05-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
however, as demonstrated in charniak (1996) and klein and manning (2003), <papid> P03-1054 </papid>pcfg which simply takes the empirical rules and probabilities off of treebank does not perform well.</citsent>
<aftsection>
<nextsent>this naive grammar is poor one because its context freedom assumptions are too strong in some ways (e.g. it assumes that subject and object nps share the same distribution) and too weak in others (e.g. it assumes that long rewrites do not decompose into smaller steps).
</nextsent>
<nextsent>therefore, variety of techniques have been developed to both enrich and generalize the naive grammar, ranging from simple tree annotation and symbol splitting (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003) <papid> P03-1054 </papid>to full lexicalization and intricate smoothing (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>we view treebank parsing as the search for an optimally refined grammar consistent with coarse training treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3049">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, as demonstrated in charniak (1996) and klein and manning (2003), <papid> P03-1054 </papid>pcfg which simply takes the empirical rules and probabilities off of treebank does not perform well.</prevsent>
<prevsent>this naive grammar is poor one because its context freedom assumptions are too strong in some ways (e.g. it assumes that subject and object nps share the same distribution) and too weak in others (e.g. it assumes that long rewrites do not decompose into smaller steps).</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
therefore, variety of techniques have been developed to both enrich and generalize the naive grammar, ranging from simple tree annotation and symbol splitting (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003) <papid> P03-1054 </papid>to full lexicalization and intricate smoothing (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>we view treebank parsing as the search for an optimally refined grammar consistent with coarse training treebank.
</nextsent>
<nextsent>as result, we begin with the provided evaluation symbols (such as np, vp, etc.) but split them based on the statistical patterns in the training trees.
</nextsent>
<nextsent>a manual approach might take the symbol np and subdivide it into one sub symbol nps for subjects and another sub symbol npvpfor objects.
</nextsent>
<nextsent>however, rather than devising linguistically motivated features or splits, we take fully automated approach, in which each symbol is split into unconstrained subsymbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3052">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> latent variable parsing.  </section>
<citcontext>
<prevsection>
<prevsent>(b) the binarized tree with latent variables.
</prevsent>
<prevsent>grammars learned from the two treebanks.
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
in latent variable parsing (matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; petrov et al, 2006), <papid> P06-1055 </papid>we learn rule probabilities on latent annotations that, when marginalized out, maximize the likelihood of the unannotated training trees.</citsent>
<aftsection>
<nextsent>we use an automatic approach in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of the training treebank.
</nextsent>
<nextsent>in this section we briefly review the main ideasin latent variable parsing.
</nextsent>
<nextsent>this work has been previously published and we therefore provide onlya short overview.
</nextsent>
<nextsent>for more detailed exposition of the learning algorithm the reader is referred to petrov et al (2006).<papid> P06-1055 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3053">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> latent variable parsing.  </section>
<citcontext>
<prevsection>
<prevsent>(b) the binarized tree with latent variables.
</prevsent>
<prevsent>grammars learned from the two treebanks.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
in latent variable parsing (matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; petrov et al, 2006), <papid> P06-1055 </papid>we learn rule probabilities on latent annotations that, when marginalized out, maximize the likelihood of the unannotated training trees.</citsent>
<aftsection>
<nextsent>we use an automatic approach in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of the training treebank.
</nextsent>
<nextsent>in this section we briefly review the main ideasin latent variable parsing.
</nextsent>
<nextsent>this work has been previously published and we therefore provide onlya short overview.
</nextsent>
<nextsent>for more detailed exposition of the learning algorithm the reader is referred to petrov et al (2006).<papid> P06-1055 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3055">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> latent variable parsing.  </section>
<citcontext>
<prevsection>
<prevsent>this work has been previously published and we therefore provide onlya short overview.
</prevsent>
<prevsent>for more detailed exposition of the learning algorithm the reader is referred to petrov et al (2006).<papid> P06-1055 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
the corresponding inference procedure is described in detail in petrov and klein (2007).<papid> N07-1051 </papid></citsent>
<aftsection>
<nextsent>the parser, code, and trained models are available for download at http://nlp.cs.berkeley.edu.
</nextsent>
<nextsent>2.1 learning.
</nextsent>
<nextsent>starting with simple x-bar grammar, we use the expectation-maximization (em) algorithm to learn new grammar whose nonterminals are sub symbols of the original evaluation nonterminals.
</nextsent>
<nextsent>the x-bar grammar is created by binarizing the treebank trees;for each local tree rooted at an evaluation nonterminal x, we introduce cascade of new nodes labeled so that each node has at most two children,see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3057">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> latent variable parsing.  </section>
<citcontext>
<prevsection>
<prevsent>smoothing allows us to add larger number of annotations, each specializing in only fraction of the data, without over fitting our training set.
</prevsent>
<prevsent>34 2.2 inference.
</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
at inference time, we want to use the learned grammar to efficiently and accurately compute parse tree for give sentence.for efficiency, we employ hierarchical coarse to-fine inference scheme (charniak et al, 1998; <papid> W98-1115 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>petrov and klein, 2007) <papid> N07-1051 </papid>which vastly improves inference time with no loss in test set accuracy.</citsent>
<aftsection>
<nextsent>our method considers the splitting history of the final grammar, projecting it onto its increasingly refined prior stages.
</nextsent>
<nextsent>for each such projection of the refined grammar, we estimate the projections parameters from the source pcfg itself (rather than the original treebank), using techniques for infinite tree distributions and iterated fix point equations.
</nextsent>
<nextsent>we then rapidly pre-parse with each refinement stage in sequence, such that any item x:[i, j] with sufficiently low posterior probability triggers the pruning of its further refined variants in all subsequent finer parses.
</nextsent>
<nextsent>our refined grammars are over symbols of the form x-k where is an evaluation symbol (such as np) and is some indicator of sub symbol, which may encode something linguistic like parent annotation context, but which is formally just an integer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3065">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> latent variable parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we have several choices of how to select tree given these posterior distributions over trees.
</prevsent>
<prevsent>since computing the most likely parse tree is np-complete (simaan, 1992), we settle for an approximation that allows us to (partially) sum out the latent annotation.
</prevsent>
</prevsection>
<citsent citstr=" P96-1024 ">
in petrov and klein (2007) <papid> N07-1051 </papid>we relate this approximation to goodman (1996)<papid> P96-1024 </papid>s labeled brackets algorithm applied to rules and to matsuzaki et al (2005)<papid> P05-1010 </papid>s sentence specific variational approximation.</citsent>
<aftsection>
<nextsent>this procedure is substantially superior to simply erasing the latent annotations from the the viterbi derivation.
</nextsent>
<nextsent>2.3 results.
</nextsent>
<nextsent>in petrov and klein (2007) <papid> N07-1051 </papid>we trained models for english, chinese and german using the standard corpora and setups.</nextsent>
<nextsent>we applied our latent variable model directly to each of the treebanks, without any ? 40 words all parser lp lr lp lr english charniak et al (2005) 90.1 90.1 89.5 89.6 petrov and klein (2007) <papid> N07-1051 </papid>90.7 90.5 90.2 89.9 english (reranked) charniak et al (2005) 92.4 91.6 91.8 91.0 german (negra)dubey (2005) <papid> P05-1039 </papid>f1 76.3 petrov and klein (2007) <papid> N07-1051 </papid>80.8 80.7 80.1 80.1 chinese chiang et al (2002) 81.1 78.8 78.0 75.2 petrov and klein (2007) <papid> N07-1051 </papid>86.9 85.7 84.8 81.9 table 1: our split-and-merge latent variable approach produces the best published parsing performance on many languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3077">
<title id=" W08-1005.xml">parsing german with latent variable grammars </title>
<section> latent variable parsing.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 results.
</prevsent>
<prevsent>in petrov and klein (2007) <papid> N07-1051 </papid>we trained models for english, chinese and german using the standard corpora and setups.</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
we applied our latent variable model directly to each of the treebanks, without any ? 40 words all parser lp lr lp lr english charniak et al (2005) 90.1 90.1 89.5 89.6 petrov and klein (2007) <papid> N07-1051 </papid>90.7 90.5 90.2 89.9 english (reranked) charniak et al (2005) 92.4 91.6 91.8 91.0 german (negra)dubey (2005) <papid> P05-1039 </papid>f1 76.3 petrov and klein (2007) <papid> N07-1051 </papid>80.8 80.7 80.1 80.1 chinese chiang et al (2002) 81.1 78.8 78.0 75.2 petrov and klein (2007) <papid> N07-1051 </papid>86.9 85.7 84.8 81.9 table 1: our split-and-merge latent variable approach produces the best published parsing performance on many languages.</citsent>
<aftsection>
<nextsent>language dependent modifications.
</nextsent>
<nextsent>specifically, the same model hyper parameters (merging percentage and smoothing factor) were used in all experiments.table 1 summarizes the results: automatically inducing latent structure is technique that generalizes well across language boundaries and results in state of the art performance for chinese and german.
</nextsent>
<nextsent>on english, the parser is outperformed by the reranked output of charniak and johnson (2005), <papid> P05-1022 </papid>but it outperforms their underlying lexicalized parser.</nextsent>
<nextsent>we conducted experiments on the two treebanks provided for the 2008 parsing german shared task.both treebanks are annotated collections of german newspaper text, covering from similar top ics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3089">
<title id=" W09-0609.xml">referring expression generation through attribute based heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite wide variation in the way subjects refer across set of ten stimuli, we demonstrate that component elements of the referring expression generation process appear to generalise across participants to asignificant degree.
</prevsent>
<prevsent>this leads us to propose an alternative way of thinking of referring expression generation, where each attribute in description is provided by separate heuristic.
</prevsent>
</prevsection>
<citsent citstr=" W08-1131 ">
the last few years have witnessed considerable move towards empiricism in referring expression generation; this is evidenced both by the growing body of work that analyses and tries to replicate the content of corpora of human-produced referring expressions, and particularly by the significant participation in the tuna and grec challenge tasks built around such activities (see, for example, (belz and gatt, 2007; belz et al, 2008; gatt et al, 2008)).<papid> W08-1131 </papid></citsent>
<aftsection>
<nextsent>one increasingly widespreadobservationobvious in hindsight, but surprisingly absent from much earlier work on referring expression generation is that one persons referential behaviour differs from that of another: given the same referential task, different subjects will choose different referring expressions to identify target referent.
</nextsent>
<nextsent>faced with this apparent lack ofcross-speaker consistency in how to refer to entities, we might question the validity of any exercise that tries to develop an algorithm on the basis of data from multiple speakers.
</nextsent>
<nextsent>in this paper we revisit the corpus of data that was introduced and discussed in (viethen and dale, 2008<papid> W08-1109 </papid>a; viethen and dale, 2008<papid> W08-1109 </papid>b) withthe objective of determining what referential behaviour, if any, might be learned automatically from the data.</nextsent>
<nextsent>we find that, despite the apparent diversity of the data when we consider the production of referring expressions across subjects,a closer examination reveals that individual attributes within referring expressions do appear to be selected on the basis of contextual factors witha high degree of consistency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3090">
<title id=" W09-0609.xml">referring expression generation through attribute based heuristics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one increasingly widespreadobservationobvious in hindsight, but surprisingly absent from much earlier work on referring expression generation is that one persons referential behaviour differs from that of another: given the same referential task, different subjects will choose different referring expressions to identify target referent.
</prevsent>
<prevsent>faced with this apparent lack ofcross-speaker consistency in how to refer to entities, we might question the validity of any exercise that tries to develop an algorithm on the basis of data from multiple speakers.
</prevsent>
</prevsection>
<citsent citstr=" W08-1109 ">
in this paper we revisit the corpus of data that was introduced and discussed in (viethen and dale, 2008<papid> W08-1109 </papid>a; viethen and dale, 2008<papid> W08-1109 </papid>b) withthe objective of determining what referential behaviour, if any, might be learned automatically from the data.</citsent>
<aftsection>
<nextsent>we find that, despite the apparent diversity of the data when we consider the production of referring expressions across subjects,a closer examination reveals that individual attributes within referring expressions do appear to be selected on the basis of contextual factors witha high degree of consistency.
</nextsent>
<nextsent>this suggests that referring behaviour might be best thought of as consisting of combination of lower-level heuristics, with each individuals overall referring behaviour being constructed from potentially distinct combination of these common heuristics.
</nextsent>
<nextsent>in section 2 we describe the corpus we use forthe experiments in this paper.
</nextsent>
<nextsent>in section 3 we explore to what extent we can use this corpus to learn an algorithm for referring expression generation; in section 4 we look more closely at the nature of individual variation within the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3171">
<title id=" W09-0609.xml">referring expression generation through attribute based heuristics </title>
<section> individual variation.  </section>
<citcontext>
<prevsection>
<prevsent>approach with one model thatis trained on the characteristics of scenes, and an other that takes both the characteristics of scenes and the participant id into account.5 interestingly, the context-free?
</prevsent>
<prevsent>strategies work suprisingly well for predicting the inclusion of some attributes in the human data.
</prevsent>
</prevsection>
<citsent citstr=" L08-1090 ">
as has been noted in other work (see for example (viethen etal., 2008)), <papid> L08-1090 </papid>colour is often included in referring expressions irrespective of its discriminatory power, and this is borne out by the data here.</citsent>
<aftsection>
<nextsent>perhaps more sup rising is the large degree to which the inclusion of landmark size is captured by context free strategy.
</nextsent>
<nextsent>5as before, the results reported are for the accuracy of pruned j48 decision tree, under 10-fold cross-validation.
</nextsent>
<nextsent>62improvement on all attribues other than target colour improves when we take into account the characteristics of the scenes, consistent with our assumptions that context does matter.
</nextsent>
<nextsent>when we add participant id to the features used in the learner, performance improves further still, indicating that there are speaker-specific consistencies in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3172">
<title id=" W09-0609.xml">referring expression generation through attribute based heuristics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recently, stoia et al.
</prevsent>
<prevsent>(2006) attempt similar task, but this time inan interactive navigational domain; as well as determining what type of referring expression to use, they also try to learn whether modifier should be included.
</prevsent>
</prevsection>
<citsent citstr=" N01-1002 ">
cheng et al (2001) <papid> N01-1002 </papid>try to learn rules for the incorporation of non-referring modifiers into noun phrases.</citsent>
<aftsection>
<nextsent>a number of the contributions to the 2008 grec and tuna evaluation tasks (gatt et al, 2008) <papid> W08-1131 </papid>have made use of machine learning techniques.</nextsent>
<nextsent>the grec task is primarily concerned with the choice of form of reference (i.e. whether proper name, descriptive np or pronoun should be used), andso is less relevant to the focus of the present paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3174">
<title id=" W09-0609.xml">referring expression generation through attribute based heuristics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>much of the work on the tuna task is relevant, however, since this also is concerned with determining the content of referring expression sin terms of the attributes used to build distinguishing description.
</prevsent>
<prevsent>in particular, fabbrizio et al (2008) explore the impact of individual style and priming on attribute selection for referring expression generation, and bohnet (2008) uses nearest neighbour learning technique to acquire an individual referring expression generation model for each person.
</prevsent>
</prevsection>
<citsent citstr=" W08-1136 ">
other related approaches to attribute selection in the context of the tuna task are explored in (gervas et al, 2008; de lucena and paraboni, 2008; kelleher and mac namee, 2008; <papid> W08-1136 </papid>king, 2008).<papid> W08-1137 </papid></citsent>
<aftsection>
<nextsent>we know that peoples referential behaviour varies significantly.
</nextsent>
<nextsent>despite this apparent variation, we have demonstrated above that there does appear to be reasonable correlation between characteristics of the scene and the incorporation of particular attributes in referring expression.
</nextsent>
<nextsent>one way to con ceptualise this is that the decision as to whether or 64 not to incorporate given feature such as colour or size may vary from speaker to speaker; this is evidenced by the data.
</nextsent>
<nextsent>we might think of these as individual reference strategies; good example ofsuch strategy, widely attested across many experiments, is the decision to include colour in refer ring expression independent of its discriminatory power, perhaps because it is an easily perceivable and often-useful attribute.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3175">
<title id=" W09-0609.xml">referring expression generation through attribute based heuristics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>much of the work on the tuna task is relevant, however, since this also is concerned with determining the content of referring expression sin terms of the attributes used to build distinguishing description.
</prevsent>
<prevsent>in particular, fabbrizio et al (2008) explore the impact of individual style and priming on attribute selection for referring expression generation, and bohnet (2008) uses nearest neighbour learning technique to acquire an individual referring expression generation model for each person.
</prevsent>
</prevsection>
<citsent citstr=" W08-1137 ">
other related approaches to attribute selection in the context of the tuna task are explored in (gervas et al, 2008; de lucena and paraboni, 2008; kelleher and mac namee, 2008; <papid> W08-1136 </papid>king, 2008).<papid> W08-1137 </papid></citsent>
<aftsection>
<nextsent>we know that peoples referential behaviour varies significantly.
</nextsent>
<nextsent>despite this apparent variation, we have demonstrated above that there does appear to be reasonable correlation between characteristics of the scene and the incorporation of particular attributes in referring expression.
</nextsent>
<nextsent>one way to con ceptualise this is that the decision as to whether or 64 not to incorporate given feature such as colour or size may vary from speaker to speaker; this is evidenced by the data.
</nextsent>
<nextsent>we might think of these as individual reference strategies; good example ofsuch strategy, widely attested across many experiments, is the decision to include colour in refer ring expression independent of its discriminatory power, perhaps because it is an easily perceivable and often-useful attribute.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3176">
<title id=" W08-2218.xml">connective based local coherence analysis a lexicon for recognizing causal relationships </title>
<section> complications with connectives.  </section>
<citcontext>
<prevsection>
<prevsent>example shown at the beginning.
</prevsent>
<prevsent>for one thing, discourse units can be embedded into one another, using parenthetical material or appositions.
</prevsent>
</prevsection>
<citsent citstr=" J03-4002 ">
further, connectives can occasionally link text segments that are non-adjacent ? phenomenon that has been studied intensively by webber et al (2003) <papid> J03-4002 </papid>and also by wolf and gibson (2005).</citsent>
<aftsection>
<nextsent>an example from webber et al: john loves barolo.
</nextsent>
<nextsent>so he ordered three cases of the 97.
</nextsent>
<nextsent>but he had to cancel the order because then he discovered he was broke.
</nextsent>
<nextsent>here, the then is to be understood as linking the discovery event back to the ordering event rather than to the (adjacent) canceling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3177">
<title id=" W08-2218.xml">connective based local coherence analysis a lexicon for recognizing causal relationships </title>
<section> towards recognizing causal relations automatically.  </section>
<citcontext>
<prevsection>
<prevsent>in this step, we also consider the layer of logical document structure in order to avoid segments that would stretch across paragraphs or other kinds of boundaries.
</prevsent>
<prevsent>similarly, layer with the results of text tiling?
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
(breakdown of the text in terms of thematic units, in the tradition of hearst (1994)) <papid> P94-1002 </papid>could be used for this purpose, as well as as an attribution?</citsent>
<aftsection>
<nextsent>layer that identifies those modal contexts that attribute span of text to particular source (as in indirect speech).
</nextsent>
<nextsent>in this way, the module will generate hypotheses of coherence relations and related spans, for the time being solely on the basis of connectives occurring in the text.
</nextsent>
<nextsent>as explained, this information is represented in two additional analysis layers.
</nextsent>
<nextsent>modules following in the processing chain may combine the various hypotheses into the most likely overall relational tree structure for the paragraph (or set of such tree structures, see reitter and stede (2003)), or they may use the hypotheses directly for some application that does not relyon spanning tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3178">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate automatic extraction of hypernym information from textand conclude that the application of dependency patterns does not lead to substantially higher precision and recall scores than using lexical patterns.
</prevsent>
<prevsent>for almost decade, automatic sentence parsing systems with reasonable performance (90+% constituent precision/recall) have been available for english (charniak, 1999).
</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
in recent years there has been an increase in linguistic applications which use parsing as preprocessing step, e.g. snow et al (2006) <papid> P06-1101 </papid>and surdeanu et al (2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>one of the boosts for these new applications was the increasing powerof desktop computers, which allows for an easier access to the computing-intensive parsing results.
</nextsent>
<nextsent>another is the increased popularity of dependency parsing of which the results can easily be incorporated into followup systems.
</nextsent>
<nextsent>although there is consensus about the fact that the richness of the dependency structures should, in principle, enable better performance than lexical information or shallow parsing results, it is not clear if these better results can also be obtained in practice.a performance of 90% precision and recall at constituent level still leaves an average of one error ina medium-length sentence of ten words.
</nextsent>
<nextsent>these errors could degrade the performance of any approach which relies heavily on parser output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3179">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate automatic extraction of hypernym information from textand conclude that the application of dependency patterns does not lead to substantially higher precision and recall scores than using lexical patterns.
</prevsent>
<prevsent>for almost decade, automatic sentence parsing systems with reasonable performance (90+% constituent precision/recall) have been available for english (charniak, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
in recent years there has been an increase in linguistic applications which use parsing as preprocessing step, e.g. snow et al (2006) <papid> P06-1101 </papid>and surdeanu et al (2008).<papid> W08-2121 </papid></citsent>
<aftsection>
<nextsent>one of the boosts for these new applications was the increasing powerof desktop computers, which allows for an easier access to the computing-intensive parsing results.
</nextsent>
<nextsent>another is the increased popularity of dependency parsing of which the results can easily be incorporated into followup systems.
</nextsent>
<nextsent>although there is consensus about the fact that the richness of the dependency structures should, in principle, enable better performance than lexical information or shallow parsing results, it is not clear if these better results can also be obtained in practice.a performance of 90% precision and recall at constituent level still leaves an average of one error ina medium-length sentence of ten words.
</nextsent>
<nextsent>these errors could degrade the performance of any approach which relies heavily on parser output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3180">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> task and methods.  </section>
<citcontext>
<prevsection>
<prevsent>for example, color is hypernym of red which in turn is hypernym of scarlet.
</prevsent>
<prevsent>if is hypernym of than is hyponym of a. there has been quite lot of work on extracting hypernymy pairs from text.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the pioneering work of hearst (1992) <papid> C92-2082 </papid>applied fixed patterns like np1 , especially np2 to derive that np1 is hypernym of np2.</citsent>
<aftsection>
<nextsent>lately there has been lot of interest in acquiring such text patterns using set of hyper nymy examples, e.g. pantel et al (2004) <papid> C04-1111 </papid>and snow (2006).</nextsent>
<nextsent>application of such techniques has not been restricted to english but also involved other languages such as dutch (tjong kim sang and hofmann, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3181">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> task and methods.  </section>
<citcontext>
<prevsection>
<prevsent>if is hypernym of than is hyponym of a. there has been quite lot of work on extracting hypernymy pairs from text.
</prevsent>
<prevsent>the pioneering work of hearst (1992) <papid> C92-2082 </papid>applied fixed patterns like np1 , especially np2 to derive that np1 is hypernym of np2.</prevsent>
</prevsection>
<citsent citstr=" C04-1111 ">
lately there has been lot of interest in acquiring such text patterns using set of hyper nymy examples, e.g. pantel et al (2004) <papid> C04-1111 </papid>and snow (2006).</citsent>
<aftsection>
<nextsent>application of such techniques has not been restricted to english but also involved other languages such as dutch (tjong kim sang and hofmann, 2007).
</nextsent>
<nextsent>recent work has also examined extracting hypernym information from structured data, like wikipedia (sumida and torisawa, 2008).<papid> I08-2126 </papid></nextsent>
<nextsent>for our extraction work, we will closely follow the approach described in snow et al (2006): <papid> P06-1101 </papid>1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3182">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> task and methods.  </section>
<citcontext>
<prevsection>
<prevsent>lately there has been lot of interest in acquiring such text patterns using set of hyper nymy examples, e.g. pantel et al (2004) <papid> C04-1111 </papid>and snow (2006).</prevsent>
<prevsent>application of such techniques has not been restricted to english but also involved other languages such as dutch (tjong kim sang and hofmann, 2007).</prevsent>
</prevsection>
<citsent citstr=" I08-2126 ">
recent work has also examined extracting hypernym information from structured data, like wikipedia (sumida and torisawa, 2008).<papid> I08-2126 </papid></citsent>
<aftsection>
<nextsent>for our extraction work, we will closely follow the approach described in snow et al (2006): <papid> P06-1101 </papid>1.</nextsent>
<nextsent>collect from text corpus phrases (consecutive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3186">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>the first method used lexical patterns and relied on shallow processing techniques likepart-of-speech tagging and lemmatization.
</prevsent>
<prevsent>the second method used dependency patterns which relied on additional information obtained from dependency parsing.
</prevsent>
</prevsection>
<citsent citstr=" J07-4005 ">
in earlier work, mccarthy et al (2007) <papid> J07-4005 </papid>found that for word sense disambiguation using the sauri generated from dependency relations perform only slightly better than thesauri generated from proximity-based relations.</citsent>
<aftsection>
<nextsent>jijkoun et al (2004) <papid> C04-1188 </papid>showed that information obtained from dependency patterns significantly improved the performance of aquestion answering system.</nextsent>
<nextsent>li and roth (2001) <papid> W01-0706 </papid>report that preprocessing by shallow parsing allows fora more accurate post-processing of ill-formed sentences than preprocessing with full parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3187">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>the second method used dependency patterns which relied on additional information obtained from dependency parsing.
</prevsent>
<prevsent>in earlier work, mccarthy et al (2007) <papid> J07-4005 </papid>found that for word sense disambiguation using the sauri generated from dependency relations perform only slightly better than thesauri generated from proximity-based relations.</prevsent>
</prevsection>
<citsent citstr=" C04-1188 ">
jijkoun et al (2004) <papid> C04-1188 </papid>showed that information obtained from dependency patterns significantly improved the performance of aquestion answering system.</citsent>
<aftsection>
<nextsent>li and roth (2001) <papid> W01-0706 </papid>report that preprocessing by shallow parsing allows fora more accurate post-processing of ill-formed sentences than preprocessing with full parsing.</nextsent>
<nextsent>our study supports the findings of mccarthy etal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3188">
<title id=" W09-1122.xml">lexical patterns or dependency patterns which is better for hypernym extraction </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>in earlier work, mccarthy et al (2007) <papid> J07-4005 </papid>found that for word sense disambiguation using the sauri generated from dependency relations perform only slightly better than thesauri generated from proximity-based relations.</prevsent>
<prevsent>jijkoun et al (2004) <papid> C04-1188 </papid>showed that information obtained from dependency patterns significantly improved the performance of aquestion answering system.</prevsent>
</prevsection>
<citsent citstr=" W01-0706 ">
li and roth (2001) <papid> W01-0706 </papid>report that preprocessing by shallow parsing allows fora more accurate post-processing of ill-formed sentences than preprocessing with full parsing.</citsent>
<aftsection>
<nextsent>our study supports the findings of mccarthy etal.
</nextsent>
<nextsent>(2007).
</nextsent>
<nextsent>we found only minor differences in performances between the two preprocessing methods.
</nextsent>
<nextsent>the most important difference: about 20% extra positive cases that were identified by the dependency patterns applied to wikipedia data, can be overcome by increasing the dataset of the lexical patterns by half.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3189">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in combination with other high recall systems it yields an f-measure of 81%.
</prevsent>
<prevsent>in statistical natural language processing, considerable ingenuity and insight have been devoted to developing models of syntactic information, such as statistical parsers and taggers.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
successes in these syntactic tasks have recently paved the way to applying novel statistical learning technique sto levels of semantic representation, such as recovering the logical form of sentence for information extraction and question-answering applications (miller et al , 2000; <papid> A00-2030 </papid>ge and mooney, 2005; <papid> W05-0602 </papid>zettlemoyer and collins, 2007; wong and mooney, 2007).<papid> P07-1121 </papid>in this paper, we also focus our interest on learning semantic information.</citsent>
<aftsection>
<nextsent>differently from other work that has focussed on logical form, however,we explore the problem of recovering the syntactic structure of the sentence, the propositional ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>argument-structure of its main predicates, and the substantive labels assigned to the arguments in the propositional structure, the semantic roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3190">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in combination with other high recall systems it yields an f-measure of 81%.
</prevsent>
<prevsent>in statistical natural language processing, considerable ingenuity and insight have been devoted to developing models of syntactic information, such as statistical parsers and taggers.
</prevsent>
</prevsection>
<citsent citstr=" W05-0602 ">
successes in these syntactic tasks have recently paved the way to applying novel statistical learning technique sto levels of semantic representation, such as recovering the logical form of sentence for information extraction and question-answering applications (miller et al , 2000; <papid> A00-2030 </papid>ge and mooney, 2005; <papid> W05-0602 </papid>zettlemoyer and collins, 2007; wong and mooney, 2007).<papid> P07-1121 </papid>in this paper, we also focus our interest on learning semantic information.</citsent>
<aftsection>
<nextsent>differently from other work that has focussed on logical form, however,we explore the problem of recovering the syntactic structure of the sentence, the propositional ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>argument-structure of its main predicates, and the substantive labels assigned to the arguments in the propositional structure, the semantic roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3191">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in combination with other high recall systems it yields an f-measure of 81%.
</prevsent>
<prevsent>in statistical natural language processing, considerable ingenuity and insight have been devoted to developing models of syntactic information, such as statistical parsers and taggers.
</prevsent>
</prevsection>
<citsent citstr=" P07-1121 ">
successes in these syntactic tasks have recently paved the way to applying novel statistical learning technique sto levels of semantic representation, such as recovering the logical form of sentence for information extraction and question-answering applications (miller et al , 2000; <papid> A00-2030 </papid>ge and mooney, 2005; <papid> W05-0602 </papid>zettlemoyer and collins, 2007; wong and mooney, 2007).<papid> P07-1121 </papid>in this paper, we also focus our interest on learning semantic information.</citsent>
<aftsection>
<nextsent>differently from other work that has focussed on logical form, however,we explore the problem of recovering the syntactic structure of the sentence, the propositional ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>argument-structure of its main predicates, and the substantive labels assigned to the arguments in the propositional structure, the semantic roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3192">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>argument-structure of its main predicates, and the substantive labels assigned to the arguments in the propositional structure, the semantic roles.
</prevsent>
<prevsent>this rich output can be useful for information extraction and question-answering, but also for anaphora resolution and other tasks for which the structural information provided by full syntactic parsing is necessary.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the task of semantic role labelling (srl), as has been defined by previous researchers (gildea and jurafsky, 2002), <papid> J02-3001 </papid>requires collecting all the arguments that together with verb form predicate argument structure.</citsent>
<aftsection>
<nextsent>in most previous work, thetask has been decomposed into the argument identification and argument labelling subtasks: first the arguments of each specific verb in the sentence are identified by classifying constituents in the sentence as arguments or not arguments.
</nextsent>
<nextsent>the arguments are then labelled in second step.we propose to produce the rich syntactic semantic output in two steps, which are different from the argument identification and argument labelling subtasks.
</nextsent>
<nextsent>first, we generate trees that bear both syntactic and semantic annotation, such as those in figure 1.
</nextsent>
<nextsent>the parse tree, however, doesnot explicitly encode information about predicate argument structure, because it does not explicitly associate each semantic role to the verb that governs it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3193">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> the data.  </section>
<citcontext>
<prevsection>
<prevsent>we then report on two kinds of exper iments: we first evaluate the architecture on the joint task of syntactic and semantic parsing andthen evaluate the joint approach on the task of semantic role labelling.
</prevsent>
<prevsent>we conclude with discussion which highlights the practical and theoretical contribution of this work.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
our experiments on joint syntactic and semantic parsing use data that is produced automatically by merging the penn treebank (ptb) with propbank (prbk) (marcus et al , 1993; <papid> J93-2004 </papid>palmer et al , 2005),<papid> J05-1004 </papid>as shown in figure 1.</citsent>
<aftsection>
<nextsent>propbank encodes propositional information by adding layer of argument structure annotation to the syntactic structures of the penn treebank.
</nextsent>
<nextsent>1 verbal predicates in the penn treebank (ptb) receive label rel and their arguments are annotated with abstract semantic role labels, such as a0, a1, or aa for those complements of the predicative verb that are consideredarguments.
</nextsent>
<nextsent>those complements of the verb la 1 we use prbk data as they appear in the conll 2005 shared task.
</nextsent>
<nextsent>s np-a0 the authority vp vbd-rel dropped pp-tmp in(tmp) at np nn midnight pp-dir to(dir) to np qp $ 2.80 trillion figure 1: sample syntactic structure with semantic role labels.belled with semantic functional label in the original ptb receive the composite semantic role label am-x , where stands for labels such as loc, tmp or adv, for locative, temporal and adverbial modifiers respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3194">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> the data.  </section>
<citcontext>
<prevsection>
<prevsent>we then report on two kinds of exper iments: we first evaluate the architecture on the joint task of syntactic and semantic parsing andthen evaluate the joint approach on the task of semantic role labelling.
</prevsent>
<prevsent>we conclude with discussion which highlights the practical and theoretical contribution of this work.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
our experiments on joint syntactic and semantic parsing use data that is produced automatically by merging the penn treebank (ptb) with propbank (prbk) (marcus et al , 1993; <papid> J93-2004 </papid>palmer et al , 2005),<papid> J05-1004 </papid>as shown in figure 1.</citsent>
<aftsection>
<nextsent>propbank encodes propositional information by adding layer of argument structure annotation to the syntactic structures of the penn treebank.
</nextsent>
<nextsent>1 verbal predicates in the penn treebank (ptb) receive label rel and their arguments are annotated with abstract semantic role labels, such as a0, a1, or aa for those complements of the predicative verb that are consideredarguments.
</nextsent>
<nextsent>those complements of the verb la 1 we use prbk data as they appear in the conll 2005 shared task.
</nextsent>
<nextsent>s np-a0 the authority vp vbd-rel dropped pp-tmp in(tmp) at np nn midnight pp-dir to(dir) to np qp $ 2.80 trillion figure 1: sample syntactic structure with semantic role labels.belled with semantic functional label in the original ptb receive the composite semantic role label am-x , where stands for labels such as loc, tmp or adv, for locative, temporal and adverbial modifiers respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3195">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> the syntactic and semantic parser.  </section>
<citcontext>
<prevsection>
<prevsent>a tree structure with propbank labels is shown in figure 1.
</prevsent>
<prevsent>(the bold labels are not relevant for the moment and they will be explained later.)
</prevsent>
</prevsection>
<citsent citstr=" P07-1080 ">
architecture to achieve the complex task of joint syntactic and semantic parsing, we extend current state-of-the art statistical parser (titov and henderson, 2007)<papid> P07-1080 </papid>to learn semantic role annotation as well as syntactic structure.</citsent>
<aftsection>
<nextsent>the parser uses form of left-corner parsing strategy to map parse trees to sequences of derivation steps.
</nextsent>
<nextsent>we choose this parser because it exhibits the best performance for single generative parser,and does not impose hard independence assumptions.
</nextsent>
<nextsent>it is therefore promising for extensions to new tasks.
</nextsent>
<nextsent>following (titov and henderson,2007), <papid> P07-1080 </papid>we describe the original parsing architecture and our modifications to it as dynamic bayesian network.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3199">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> the syntactic and semantic parser.  </section>
<citcontext>
<prevsection>
<prevsent>not all state sin the history are relevant, however.
</prevsent>
<prevsent>the inter connectivity is defined dynamically based on the topological structure and the labels of the tree thatis being developed.
</prevsent>
</prevsection>
<citsent citstr=" N03-1014 ">
this inter-connectivity depends on notion of structural locality (hender son, 2003; <papid> N03-1014 </papid>musillo and merlo, 2006).<papid> N06-2026 </papid></citsent>
<aftsection>
<nextsent>2 2 specifically, the conditioning states are based on the in order to extend this model to learn decisions concerning joint syntactic-semantic representation, the semantic information needs to be highlighted in the model in several ways.
</nextsent>
<nextsent>we modify the network connectivity, and bias the learner.first, we take advantage of the networks dynamic connectivity to highlight the portion of the tree that bears semantic information.
</nextsent>
<nextsent>we augment the nodes that can influence parsing decisions at the current state by explicitly adding the vectors of latent variables related to the most recent childbearing semantic role label of either type (rel, a0 to a5 or am-x) to the connectivity of the current decision.
</nextsent>
<nextsent>these additions yield model that is sensitive to regularities in structurally defined sequences of nodes bearing semantic role labels, within and across constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3200">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> the syntactic and semantic parser.  </section>
<citcontext>
<prevsection>
<prevsent>not all state sin the history are relevant, however.
</prevsent>
<prevsent>the inter connectivity is defined dynamically based on the topological structure and the labels of the tree thatis being developed.
</prevsent>
</prevsection>
<citsent citstr=" N06-2026 ">
this inter-connectivity depends on notion of structural locality (hender son, 2003; <papid> N03-1014 </papid>musillo and merlo, 2006).<papid> N06-2026 </papid></citsent>
<aftsection>
<nextsent>2 2 specifically, the conditioning states are based on the in order to extend this model to learn decisions concerning joint syntactic-semantic representation, the semantic information needs to be highlighted in the model in several ways.
</nextsent>
<nextsent>we modify the network connectivity, and bias the learner.first, we take advantage of the networks dynamic connectivity to highlight the portion of the tree that bears semantic information.
</nextsent>
<nextsent>we augment the nodes that can influence parsing decisions at the current state by explicitly adding the vectors of latent variables related to the most recent childbearing semantic role label of either type (rel, a0 to a5 or am-x) to the connectivity of the current decision.
</nextsent>
<nextsent>these additions yield model that is sensitive to regularities in structurally defined sequences of nodes bearing semantic role labels, within and across constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3201">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> the syntactic and semantic parser.  </section>
<citcontext>
<prevsection>
<prevsent>enlarging the locality domain this way ensures for instance that the derivation of the role dir in figure 1 is not independent of the derivations of the roles tmp, rel (the predicate) and a0.
</prevsent>
<prevsent>second, this version of the bayesian network tags its sentences internally.
</prevsent>
</prevsection>
<citsent citstr=" W05-1509 ">
following (musillo and merlo, 2005), <papid> W05-1509 </papid>we split some part-of-speech tags into tags marked with semantic role labels.</citsent>
<aftsection>
<nextsent>the semantic role labels attached to non-terminal directly projected by pre terminal and belonging to few selected categories (dir, ext, loc, mnr, prp, caus or tmp) are propagated down to the pre-terminal part-of-speech tag of its head.
</nextsent>
<nextsent>3 this third extension biases the parser to learn the relationship between lexical items, semantic roles andthe constituents in which they occur.
</nextsent>
<nextsent>this technique is illustrated by the bold labels in figure 1.we compare this augmented model to simple baseline parser, that does not present any of the task-specific enhancements described above, stack configuration of the left-corner parser and the derivation tree built so far.
</nextsent>
<nextsent>the nodes in the partially built tree and stack configuration that are selected to determine the relevant states are the following: top, the node on top of the push down stack before the current derivation move; the left-corner ancestor of top (that is, the second top-most node on the parser stack); the left most child of top; and the most recent child of top, if any.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3204">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 reports the single systems?
</prevsent>
<prevsent>performance on the test set.
</prevsent>
</prevsection>
<citsent citstr=" W05-0639 ">
these results seem to indicate that methods like ours, basedon first step of propbank parsing, are comparable to other methods when learning regimes are factored out, contrary to pessimistic conclusions in previous work (yi and palmer, 2005).<papid> W05-0639 </papid></citsent>
<aftsection>
<nextsent>(yi and palmer, 2005) <papid> W05-0639 </papid>share the motivation of our work.they observe that the distributions of semantic la 6 in case of tie, the following verb is chosen for an a0 label and the preceding verb is chosen for all the other labels.</nextsent>
<nextsent>7 we should notice that all these models encode the feature path as syntactic path, because in exploratory data analysis we found that this feature performed quite bit better than path encoded taking into account the semantic roles assigned to the nodes on the path.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3206">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>concerning the learning model, we notice that simpler, and much faster to train, linear svm classifier performs almost as well as the more complex rbf classifier.
</prevsent>
<prevsent>it is therefore preferable if speed is important.
</prevsent>
</prevsection>
<citsent citstr=" W05-0635 ">
6 model conll 23 comments r (surdeanu and turmo, 2005) <papid> W05-0635 </papid>80.3 73.0 76.5 propbank frames to filter output, boosting (liu et al , 2005) <papid> W05-0627 </papid>80.5 72.8 76.4 single system + simple post-processing (moschitti et al , 2005) <papid> W05-0630 </papid>76.6 75.2 75.9 specialised kernels for each kind of role this paper 87.6 65.8 75.1 single system and model, locality features (ozgencil and mccracken, 2005) <papid> W05-0631 </papid>74.7 74.2 74.4 simple system, no external knowledge (johansson and nugues, 2005) <papid> W05-0624 </papid>75.5 73.2 74.3 uses only 3 sections for training table 3: final semantic role labelling results on test section 23 of propbank as encoded in the conll shared task for those conll 2005 participants not using ensemble learning or external resources.bels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of infor mation.</citsent>
<aftsection>
<nextsent>they also attempt to assign srl while parsing, by merging only the first two steps ofthe standard pipeline architecture, pruning and argument identification.
</nextsent>
<nextsent>their parser outputs binary argument-nonargument distinction.
</nextsent>
<nextsent>the actual fine-grained labelling is performed, as in other methods, by an ensemble classifier.
</nextsent>
<nextsent>results are not among the best and yi and palmer conclude that propbank parsing is too difficult and suffers from differences between chunk annotation and tree structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3207">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>concerning the learning model, we notice that simpler, and much faster to train, linear svm classifier performs almost as well as the more complex rbf classifier.
</prevsent>
<prevsent>it is therefore preferable if speed is important.
</prevsent>
</prevsection>
<citsent citstr=" W05-0627 ">
6 model conll 23 comments r (surdeanu and turmo, 2005) <papid> W05-0635 </papid>80.3 73.0 76.5 propbank frames to filter output, boosting (liu et al , 2005) <papid> W05-0627 </papid>80.5 72.8 76.4 single system + simple post-processing (moschitti et al , 2005) <papid> W05-0630 </papid>76.6 75.2 75.9 specialised kernels for each kind of role this paper 87.6 65.8 75.1 single system and model, locality features (ozgencil and mccracken, 2005) <papid> W05-0631 </papid>74.7 74.2 74.4 simple system, no external knowledge (johansson and nugues, 2005) <papid> W05-0624 </papid>75.5 73.2 74.3 uses only 3 sections for training table 3: final semantic role labelling results on test section 23 of propbank as encoded in the conll shared task for those conll 2005 participants not using ensemble learning or external resources.bels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of infor mation.</citsent>
<aftsection>
<nextsent>they also attempt to assign srl while parsing, by merging only the first two steps ofthe standard pipeline architecture, pruning and argument identification.
</nextsent>
<nextsent>their parser outputs binary argument-nonargument distinction.
</nextsent>
<nextsent>the actual fine-grained labelling is performed, as in other methods, by an ensemble classifier.
</nextsent>
<nextsent>results are not among the best and yi and palmer conclude that propbank parsing is too difficult and suffers from differences between chunk annotation and tree structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3208">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>concerning the learning model, we notice that simpler, and much faster to train, linear svm classifier performs almost as well as the more complex rbf classifier.
</prevsent>
<prevsent>it is therefore preferable if speed is important.
</prevsent>
</prevsection>
<citsent citstr=" W05-0630 ">
6 model conll 23 comments r (surdeanu and turmo, 2005) <papid> W05-0635 </papid>80.3 73.0 76.5 propbank frames to filter output, boosting (liu et al , 2005) <papid> W05-0627 </papid>80.5 72.8 76.4 single system + simple post-processing (moschitti et al , 2005) <papid> W05-0630 </papid>76.6 75.2 75.9 specialised kernels for each kind of role this paper 87.6 65.8 75.1 single system and model, locality features (ozgencil and mccracken, 2005) <papid> W05-0631 </papid>74.7 74.2 74.4 simple system, no external knowledge (johansson and nugues, 2005) <papid> W05-0624 </papid>75.5 73.2 74.3 uses only 3 sections for training table 3: final semantic role labelling results on test section 23 of propbank as encoded in the conll shared task for those conll 2005 participants not using ensemble learning or external resources.bels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of infor mation.</citsent>
<aftsection>
<nextsent>they also attempt to assign srl while parsing, by merging only the first two steps ofthe standard pipeline architecture, pruning and argument identification.
</nextsent>
<nextsent>their parser outputs binary argument-nonargument distinction.
</nextsent>
<nextsent>the actual fine-grained labelling is performed, as in other methods, by an ensemble classifier.
</nextsent>
<nextsent>results are not among the best and yi and palmer conclude that propbank parsing is too difficult and suffers from differences between chunk annotation and tree structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3209">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>concerning the learning model, we notice that simpler, and much faster to train, linear svm classifier performs almost as well as the more complex rbf classifier.
</prevsent>
<prevsent>it is therefore preferable if speed is important.
</prevsent>
</prevsection>
<citsent citstr=" W05-0631 ">
6 model conll 23 comments r (surdeanu and turmo, 2005) <papid> W05-0635 </papid>80.3 73.0 76.5 propbank frames to filter output, boosting (liu et al , 2005) <papid> W05-0627 </papid>80.5 72.8 76.4 single system + simple post-processing (moschitti et al , 2005) <papid> W05-0630 </papid>76.6 75.2 75.9 specialised kernels for each kind of role this paper 87.6 65.8 75.1 single system and model, locality features (ozgencil and mccracken, 2005) <papid> W05-0631 </papid>74.7 74.2 74.4 simple system, no external knowledge (johansson and nugues, 2005) <papid> W05-0624 </papid>75.5 73.2 74.3 uses only 3 sections for training table 3: final semantic role labelling results on test section 23 of propbank as encoded in the conll shared task for those conll 2005 participants not using ensemble learning or external resources.bels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of infor mation.</citsent>
<aftsection>
<nextsent>they also attempt to assign srl while parsing, by merging only the first two steps ofthe standard pipeline architecture, pruning and argument identification.
</nextsent>
<nextsent>their parser outputs binary argument-nonargument distinction.
</nextsent>
<nextsent>the actual fine-grained labelling is performed, as in other methods, by an ensemble classifier.
</nextsent>
<nextsent>results are not among the best and yi and palmer conclude that propbank parsing is too difficult and suffers from differences between chunk annotation and tree structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3210">
<title id=" W08-2101.xml">semantic parsing for high precision semantic role labelling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>concerning the learning model, we notice that simpler, and much faster to train, linear svm classifier performs almost as well as the more complex rbf classifier.
</prevsent>
<prevsent>it is therefore preferable if speed is important.
</prevsent>
</prevsection>
<citsent citstr=" W05-0624 ">
6 model conll 23 comments r (surdeanu and turmo, 2005) <papid> W05-0635 </papid>80.3 73.0 76.5 propbank frames to filter output, boosting (liu et al , 2005) <papid> W05-0627 </papid>80.5 72.8 76.4 single system + simple post-processing (moschitti et al , 2005) <papid> W05-0630 </papid>76.6 75.2 75.9 specialised kernels for each kind of role this paper 87.6 65.8 75.1 single system and model, locality features (ozgencil and mccracken, 2005) <papid> W05-0631 </papid>74.7 74.2 74.4 simple system, no external knowledge (johansson and nugues, 2005) <papid> W05-0624 </papid>75.5 73.2 74.3 uses only 3 sections for training table 3: final semantic role labelling results on test section 23 of propbank as encoded in the conll shared task for those conll 2005 participants not using ensemble learning or external resources.bels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of infor mation.</citsent>
<aftsection>
<nextsent>they also attempt to assign srl while parsing, by merging only the first two steps ofthe standard pipeline architecture, pruning and argument identification.
</nextsent>
<nextsent>their parser outputs binary argument-nonargument distinction.
</nextsent>
<nextsent>the actual fine-grained labelling is performed, as in other methods, by an ensemble classifier.
</nextsent>
<nextsent>results are not among the best and yi and palmer conclude that propbank parsing is too difficult and suffers from differences between chunk annotation and tree structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3211">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> context and problem.  </section>
<citcontext>
<prevsection>
<prevsent>1 rogets thesaurus (roget, 1852), miller and fellbaumswordnet (fellbaum, 1998) and long mans language activator (summers, 1993), being notable exceptions (for more details, see next section).
</prevsent>
<prevsent>2 of course, this does not preclude, that we may have to use words to refer to them in concept-based query.
</prevsent>
</prevsection>
<citsent citstr=" W06-1007 ">
3 while we agree with polgu`ere theoretically when he pleads for dictionary neutrality with regard to lexical access (polgu`ere, 2006), <papid> W06-1007 </papid>from practical point of view the situation is obviously quite different for the speaker and listener, even if both of them draw on the same resource.</citsent>
<aftsection>
<nextsent>9 neither do we know how to represent them.
</nextsent>
<nextsent>yet, there are ways around this problem as we will show.
</nextsent>
<nextsent>whether concepts and words are organized and accessed differently is question we cannot answer here.
</nextsent>
<nextsent>we can agree though on the fact that getting information concerning words is fairly un problematic when reading, at least in the caseof most western languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3212">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> context and problem.  </section>
<citcontext>
<prevsection>
<prevsent>unlike words in printed or electronic dictionaries, words in our mind may be inexis tent as tokens.
</prevsent>
<prevsent>what we seem to have in our minds are decomposed, abstract entities which need to be synthesized over time.
</prevsent>
</prevsection>
<citsent citstr=" C96-1002 ">
4ac 4 this may be very surprising, yet, this need not be the case if we consider the fact that speech errors are nearly always due to competing elements from the same level or an adjacent one, unless they are the result of surrounding concept which has been activated, or which is about to be translatedcording to levelt (levelt, 1996) <papid> C96-1002 </papid>the generation of words (synthesis) involves the following stages: conceptual preparation, lexical selection, phonological- and phonetic encoding,articulation.</citsent>
<aftsection>
<nextsent>bear in mind that having performed lexical selection?
</nextsent>
<nextsent>does not imply access to the phonetic form (see the experiments on the tip-of-the-tongue phenomenon).what can be concluded from these observations?
</nextsent>
<nextsent>it seems that underspecified input is sufficiently frequent to be considered as normal.
</nextsent>
<nextsent>hence we should accept it, and make the best out of it byusing whatever information is available (accessi ble), no matter how incomplete, since it may still contribute to find the wanted information, be it by reducing the search space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3213">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> related work and goal.  </section>
<citcontext>
<prevsection>
<prevsent>while more dictionaries have been built for the reader than for the writer, there have been someonomasiological attempts as early as in the middle of the 19th century.
</prevsent>
<prevsent>for example, rogets thesaurus (roget, 1852), tongs chinese and english instructor (tong, 1862), or boissieres ana logical dictionary (boissi`ere, 1862).
</prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
5 newer work includes melcuks ecd (melcuk et al , 1999), miller and fell baums wordnet (fellbaum,1998), richardson and dolans mindnet (richard sonet al , 1998), <papid> P98-2180 </papid>dongs hownet (dong anddong, 2006) and long mans language activator (summers, 1993).</citsent>
<aftsection>
<nextsent>there is also the work of into words.
</nextsent>
<nextsent>put differently, we do not store words at all in our mind, at least not in the laymans or lexicographers sense who consider word-forms and their meanings as one.
</nextsent>
<nextsent>if we are right, than rather continue to consider the human mind as word store we could consider it as word factory.
</nextsent>
<nextsent>indeed, by looking at some of the work done by psychologists who try to emulate the mental lexicon (for good survey see (harley, 2004), pages 359-374) one gets the impression that words are synthesized rather than located and read out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3214">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> the lexical matrix revisited.  </section>
<citcontext>
<prevsection>
<prevsent>if the user can find the item he is looking for in this list, search stops, otherwise it will continue, the user giving other words of the list, or words evoked by them.
</prevsent>
<prevsent>of course, remains the question of how to build this resource, in particular, how to populate theaxis devoted to the trigger words, i.e. access keys.
</prevsent>
</prevsection>
<citsent citstr=" P06-1036 ">
at present we consider three approaches: one, where we use the words occurring in word definitions (see also, (dutoit and nugues, 2002;bilac et al , 2004)), the other is to mine well balanced corpus, to find co-occurrences within given window (ferret and zock, 2006), <papid> P06-1036 </papid>the size depending bit on the text type (encyclopedia) or type of corpus.</citsent>
<aftsection>
<nextsent>still another solution would beto draw on the association lists produced by psychologists, see for example http://www.usf.edu/, or http://www.eat.rl.ac.uk.of course, the idea of using matrices in linguistics is not new.
</nextsent>
<nextsent>there are at least two authors who have proposed its use: m. gross (gross, 1984)<papid> P84-1058 </papid>used it for coding the syntactic behavior of lexical items, hence the term lexicon-grammar, and g. miller, the father of wn (miller et al , 1990) suggested it to support lexical access.</nextsent>
<nextsent>while the former work is not relevant for us here, millers proposal is. what are the differences between his proposal and ours?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3215">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> the lexical matrix revisited.  </section>
<citcontext>
<prevsection>
<prevsent>at present we consider three approaches: one, where we use the words occurring in word definitions (see also, (dutoit and nugues, 2002;bilac et al , 2004)), the other is to mine well balanced corpus, to find co-occurrences within given window (ferret and zock, 2006), <papid> P06-1036 </papid>the size depending bit on the text type (encyclopedia) or type of corpus.</prevsent>
<prevsent>still another solution would beto draw on the association lists produced by psychologists, see for example http://www.usf.edu/, or http://www.eat.rl.ac.uk.of course, the idea of using matrices in linguistics is not new.</prevsent>
</prevsection>
<citsent citstr=" P84-1058 ">
there are at least two authors who have proposed its use: m. gross (gross, 1984)<papid> P84-1058 </papid>used it for coding the syntactic behavior of lexical items, hence the term lexicon-grammar, and g. miller, the father of wn (miller et al , 1990) suggested it to support lexical access.</citsent>
<aftsection>
<nextsent>while the former work is not relevant for us here, millers proposal is. what are the differences between his proposal and ours?
</nextsent>
<nextsent>there are basically four main differences: 1.
</nextsent>
<nextsent>we use, collocations or access-words, i.e wsrather than synsets; hence, any of the following ws (cat, grey, computer device, cheese, speedy gonzales) could point toward the wmouse?, none of them are part of the meaning, leave alone synonyms.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3216">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> the lexical matrix revisited.  </section>
<citcontext>
<prevsection>
<prevsent>12 http://www.wikipedia.org 13 the optimal window-size depends probably on the text type (encyclopedia vs. un formatted text).
</prevsent>
<prevsent>yet, in the absence of clear criteria, we consider the optimal window-size as an open, empirical question.
</prevsent>
</prevsection>
<citsent citstr=" W04-2105 ">
14 this latter aspect is not implemented yet, but will be added in the future, as it is necessary component for easy navigation (zock and bilac, 2004; <papid> W04-2105 </papid>zock, 2006; zock, 2007).</citsent>
<aftsection>
<nextsent>14 5.3.3 corpus building we start arbitrarily from some page (for our experiment, we have chosen wine?
</nextsent>
<nextsent>as input), apply the algorithm outlined here above and pick then randomly noun within this page to fetch with this input new page on wikipedia.
</nextsent>
<nextsent>this process is repeated until given sample size is obtained (in our case 1000 pages).
</nextsent>
<nextsent>of course, instead of picking randomly noun, we could have decided to process all the nouns of given page, and to add then incrementally the nouns of the next pages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3217">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> the lexical matrix revisited.  </section>
<citcontext>
<prevsection>
<prevsent>part weve described briefly the results obtained by comparing two resources (wn and wikipedia) and various inputs.
</prevsent>
<prevsent>given the fact that the project is still quite young, only preliminary results can be shown at this point.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
our next steps will be to take closer look at the following work: clustering of similar words (lin, 1998), <papid> P98-2127 </papid>topic signatures (lin and hovy, 2000) <papid> C00-1072 </papid>and kilgariffs sketch engine (kilgarriff et al , 2004).we plan also to add other lexical functions to enrich our database with ws . we plan to experiment.</citsent>
<aftsection>
<nextsent>with corpora, trying to find out which ones are best for our purpose 15 and we will certainly experiment with the window size 16 to see which size is best for which text type.
</nextsent>
<nextsent>finally, we plan to insert in our am the relations holding between the w and the w . as these links are contained in our corpus,.
</nextsent>
<nextsent>we should be able to identify and type them.
</nextsent>
<nextsent>the question is, to what extent this can be done auto matically.obviously, the success of our resource will depend on the quality of the corpus, the quality of the ws, weights and links, and the representativ ity of all this forgiven population.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3218">
<title id=" W08-1902.xml">lexical access based on underspecified input </title>
<section> the lexical matrix revisited.  </section>
<citcontext>
<prevsection>
<prevsent>part weve described briefly the results obtained by comparing two resources (wn and wikipedia) and various inputs.
</prevsent>
<prevsent>given the fact that the project is still quite young, only preliminary results can be shown at this point.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
our next steps will be to take closer look at the following work: clustering of similar words (lin, 1998), <papid> P98-2127 </papid>topic signatures (lin and hovy, 2000) <papid> C00-1072 </papid>and kilgariffs sketch engine (kilgarriff et al , 2004).we plan also to add other lexical functions to enrich our database with ws . we plan to experiment.</citsent>
<aftsection>
<nextsent>with corpora, trying to find out which ones are best for our purpose 15 and we will certainly experiment with the window size 16 to see which size is best for which text type.
</nextsent>
<nextsent>finally, we plan to insert in our am the relations holding between the w and the w . as these links are contained in our corpus,.
</nextsent>
<nextsent>we should be able to identify and type them.
</nextsent>
<nextsent>the question is, to what extent this can be done auto matically.obviously, the success of our resource will depend on the quality of the corpus, the quality of the ws, weights and links, and the representativ ity of all this forgiven population.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3219">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic metrics to assess the quality of machine translations have been major enabler in improving the performance of mt systems, leading to many varied approaches to develop such metrics.
</prevsent>
<prevsent>initially, most metrics judged the quality of mt hypotheses by token sequence match (cf.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002).</citsent>
<aftsection>
<nextsent>these measures rate systems hypotheses by measuring the overlap in surface word sequences shared between hypothesis and reference translation.
</nextsent>
<nextsent>with improvements in the state-of-the-art in machine translation, the effectiveness of purely surface-oriented measures has been questioned (see e.g., callison-burch et al (2006)).
</nextsent>
<nextsent>in response, metrics have been proposed that attempt to integrate more linguistic information into the matching process to distinguish linguistically licensed from unwanted variation (gimenez andma`rquez, 2008).
</nextsent>
<nextsent>however, there is little agreement on what typesof knowledge are helpful: some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>or maxsim (chan and ng, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3221">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with improvements in the state-of-the-art in machine translation, the effectiveness of purely surface-oriented measures has been questioned (see e.g., callison-burch et al (2006)).
</prevsent>
<prevsent>in response, metrics have been proposed that attempt to integrate more linguistic information into the matching process to distinguish linguistically licensed from unwanted variation (gimenez andma`rquez, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
however, there is little agreement on what typesof knowledge are helpful: some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>or maxsim (chan and ng, 2008).</citsent>
<aftsection>
<nextsent>other proposals use structural information such as dependency edges (owczarzak et al, 2007).<papid> W07-0411 </papid></nextsent>
<nextsent>in this paper, we investigate an mt evaluation metric that is inspired by the similarity between this task and the textual entailment task (dagan et al, 2005), which this paper is based on work funded by the defense advanced research projects agency through ibm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3222">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in response, metrics have been proposed that attempt to integrate more linguistic information into the matching process to distinguish linguistically licensed from unwanted variation (gimenez andma`rquez, 2008).
</prevsent>
<prevsent>however, there is little agreement on what typesof knowledge are helpful: some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>or maxsim (chan and ng, 2008).</prevsent>
</prevsection>
<citsent citstr=" W07-0411 ">
other proposals use structural information such as dependency edges (owczarzak et al, 2007).<papid> W07-0411 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate an mt evaluation metric that is inspired by the similarity between this task and the textual entailment task (dagan et al, 2005), which this paper is based on work funded by the defense advanced research projects agency through ibm.
</nextsent>
<nextsent>the content does not necessarily reflect the views of the u.s. government, and no official endorsement should be inferred..
</nextsent>
<nextsent>hyp: virus was infected.
</nextsent>
<nextsent>ref: no one was infected by the virus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3223">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> textual entailment for mt evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>(2005) as concept that corresponds more closely to common sense?
</prevsent>
<prevsent>reasoning than classical, categorical entailment.
</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
textual entailment is defined as relation between two natural language sentences (a premise and hypothesis h) that holds if human reading would infer that is most likely true.information about the presence or absence of entailment between two sentences has been found to be beneficial for range of nlp tasks such as word sense disambiguation or question answering (dagan et al, 2006; <papid> P06-1057 </papid>harabagiu and hickl, 2006).<papid> P06-1114 </papid></citsent>
<aftsection>
<nextsent>our intuition is that this idea can also be fruitful in mt evaluation, as illustrated in figure 1.
</nextsent>
<nextsent>very good mt output should entail the reference translation.
</nextsent>
<nextsent>in contrast, missing hypothesis material breaks forward entailment; additional material breaks backward entailment; and for bad translations, entailment fails in both directions.
</nextsent>
<nextsent>work on the recognition of textual entailment (rte)has consistently found that the integration of more syntactic and semantic knowledge can yield gains over 37surface-based methods, provided that the linguistic analysis was sufficiently robust.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3224">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> textual entailment for mt evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>(2005) as concept that corresponds more closely to common sense?
</prevsent>
<prevsent>reasoning than classical, categorical entailment.
</prevsent>
</prevsection>
<citsent citstr=" P06-1114 ">
textual entailment is defined as relation between two natural language sentences (a premise and hypothesis h) that holds if human reading would infer that is most likely true.information about the presence or absence of entailment between two sentences has been found to be beneficial for range of nlp tasks such as word sense disambiguation or question answering (dagan et al, 2006; <papid> P06-1057 </papid>harabagiu and hickl, 2006).<papid> P06-1114 </papid></citsent>
<aftsection>
<nextsent>our intuition is that this idea can also be fruitful in mt evaluation, as illustrated in figure 1.
</nextsent>
<nextsent>very good mt output should entail the reference translation.
</nextsent>
<nextsent>in contrast, missing hypothesis material breaks forward entailment; additional material breaks backward entailment; and for bad translations, entailment fails in both directions.
</nextsent>
<nextsent>work on the recognition of textual entailment (rte)has consistently found that the integration of more syntactic and semantic knowledge can yield gains over 37surface-based methods, provided that the linguistic analysis was sufficiently robust.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3225">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> textual entailment for mt evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>thus, possible criticism to the use of te methods is that the features could become unreliable for ill-formed mt output.
</prevsent>
<prevsent>however, there is second difference between the tasks that works to our advantage.
</prevsent>
</prevsection>
<citsent citstr=" C08-1066 ">
due to its strict compositional nature, te requires an accurate semantic analysis of all sentence parts, since, for example, one mis analysed negation orcounterfactual embedding can invert the entailment status (maccartney and manning, 2008).<papid> C08-1066 </papid></citsent>
<aftsection>
<nextsent>in contrast, human mt judgments behave more additively: failure of translation with respect to single semantic dimension (e.g., polarity or tense) degrades its quality, but usually not crucially so.
</nextsent>
<nextsent>we therefore expect that even noisy entailment features can be predictive in mt evaluation.
</nextsent>
<nextsent>2.2 entailment-based prediction of mt quality.
</nextsent>
<nextsent>regression-based prediction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3226">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> textual entailment for mt evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>prediction method (withties) that uses the same sentence-level output as basic, but computes system-level quality differently,as the percentage of sentences where the systems hypothesis was scored better or at most ? worse than the best system, for some global tie interval?
</prevsent>
<prevsent>.features.
</prevsent>
</prevsection>
<citsent citstr=" N06-1006 ">
we use the stanford rte system (maccart ney et al, 2006) <papid> N06-1006 </papid>to generate set of entailment features (rte) for each pair of mt hypothesis and reference translation.</citsent>
<aftsection>
<nextsent>features are generated in both directions to avoid biases towards short or long translations.
</nextsent>
<nextsent>the stanford rte system uses three-stage architecture.
</nextsent>
<nextsent>it (a) constructs robust, dependency-based linguistic analysis of the two sentences; (b) identifies the best alignment between the two dependency graphs given similarity scores from range of lexical resources, using markov chain monte carlo sampling strategy; and (c) computes roughly 75 features over the aligned pair of dependency graphs.
</nextsent>
<nextsent>the different feature groups are shown in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3229">
<title id=" W09-0404.xml">machine translation evaluation with textual entailment features </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we plan to assess the additional benefit of the full entailment feature set against the tradmt feature set extended by proper lexical similarity metric, such as meteor.
</prevsent>
<prevsent>the computation of entailment features is more heavyweight than traditional mt evaluation metrics.we found the speed (about 6 per hypothesis on current pc) to be sufficient for easily judging the quality of datasets of the size conventionally used for mt evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
however, this may still be too expensive as part of an mt model that directly optimizes some performance measure, e.g., minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>40
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3230">
<title id=" W08-2228.xml">textual entailment as an evaluation framework for metaphor resolution a proposal </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>studies though counts vary widely because of theory-relativity, researchers?
</prevsent>
<prevsent>aims, and marked usage differences between genres.
</prevsent>
</prevsection>
<citsent citstr=" W06-3506 ">
gedigian et al (2006) <papid> W06-3506 </papid>note that 90% of uses of set of verbs of spatial motion, manipulation, and health in wall street journal corpus were metaphorical.</citsent>
<aftsection>
<nextsent>some metaphor examples arising in past rte datasets are the ts in t/h pairs (14), with human judgments no, yes, no and no respectively.
</nextsent>
<nextsent>(2) t: the technological triumph known as gps was incubated in the mind of ivan getting.
</nextsent>
<nextsent>h: ivan getting invented the gps.
</nextsent>
<nextsent>(3) t: convinced that pro-american officials are in the ascendancy in tokyo, they talk about turning japan into the britain of the far east.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3231">
<title id=" W08-2228.xml">textual entailment as an evaluation framework for metaphor resolution a proposal </title>
<section> why metaphor in nlp?.  </section>
<citcontext>
<prevsection>
<prevsent>can be omitted or replaced by dim?, darkest?, foulest?, hidden?, etc. ? by any compatible qualifier that emphasizes hidden ness or obstacles to accessibility.
</prevsent>
<prevsent>and the fact that such access difficulties are being emphasized is matter for general semantic reasoning about the qualifier.
</prevsent>
</prevsection>
<citsent citstr=" E03-1067 ">
generally, in metaphor understanding research, specialized system has been fed relatively small number of metaphorical inputs, and the correct outputs have been dictated by the researcher, (e.g. fass, 1997; falkenhainer et al, 1989; martin, 1990; barnden et al, 2003).<papid> E03-1067 </papid></citsent>
<aftsection>
<nextsent>however, metaphor in particular and figurative language in general suffers chronic lack of shared resources for proper evaluation of systems (markert and nissim, 2007).<papid> W07-2007 </papid></nextsent>
<nextsent>in using the rte evaluation framework, computational metaphor researchers may for the first time have sizable, shared datasets, and uniform evaluation method based on systematically and transparently collected human judgments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3233">
<title id=" W08-2228.xml">textual entailment as an evaluation framework for metaphor resolution a proposal </title>
<section> why metaphor in nlp?.  </section>
<citcontext>
<prevsection>
<prevsent>and the fact that such access difficulties are being emphasized is matter for general semantic reasoning about the qualifier.
</prevsent>
<prevsent>generally, in metaphor understanding research, specialized system has been fed relatively small number of metaphorical inputs, and the correct outputs have been dictated by the researcher, (e.g. fass, 1997; falkenhainer et al, 1989; martin, 1990; barnden et al, 2003).<papid> E03-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-2007 ">
however, metaphor in particular and figurative language in general suffers chronic lack of shared resources for proper evaluation of systems (markert and nissim, 2007).<papid> W07-2007 </papid></citsent>
<aftsection>
<nextsent>in using the rte evaluation framework, computational metaphor researchers may for the first time have sizable, shared datasets, and uniform evaluation method based on systematically and transparently collected human judgments.
</nextsent>
<nextsent>also, metaphor researchers will be challenged and inspired to connect metaphor more than before to other complex linguistic phenomena.nlp applications that rte serves have mostly not addressed metaphor, and neither have rte systems themselves.
</nextsent>
<nextsent>indeed, despite examples (1-4), rte dataset shave tended to avoid metaphor of more difficult types.
</nextsent>
<nextsent>metaphor in general can introduce additional context-sensitivity and indeterminacy in entailment, whereas rte challenges have mainly concentrated on t/h pairs supporting relatively crisp, uncontroversial judgments (zaenen et al (2005); rte organizers (personal communication); our own analysis of existing rte datasets in tech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3234">
<title id=" W08-2228.xml">textual entailment as an evaluation framework for metaphor resolution a proposal </title>
<section> roadmap: datasets and metaphor processing.  </section>
<citcontext>
<prevsection>
<prevsent>to find metaphor examples elsewhere, we will use known metaphorical phrases and lexical/syntactic templates as seeds for automated search over general corpora or web.
</prevsent>
<prevsent>we will also investigate the use or adaptation of other researchers?
</prevsent>
</prevsection>
<citsent citstr=" E06-1042 ">
automated detection/mining techniques (e.g. birke and sarkar, 2006; <papid> E06-1042 </papid>gedigian et al, 2006).<papid> W06-3506 </papid></citsent>
<aftsection>
<nextsent>we will develop metaphor processing algorithms on an integrated spectrum going from relatively shallow?
</nextsent>
<nextsent>forms of processing to relatively deep?
</nextsent>
<nextsent>forms.
</nextsent>
<nextsent>the deeper are for when more inference is necessary and feasible; when less necessary or feasible,the shallower are appropriate (but they can still involve at least partial parsing, approximate semantic analysis, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3237">
<title id=" W08-2228.xml">textual entailment as an evaluation framework for metaphor resolution a proposal </title>
<section> metaphor processing.  </section>
<citcontext>
<prevsection>
<prevsent>we aim also to recognize specific idiomatic phrases and systematic variations of them.
</prevsent>
<prevsent>we will consider looking for semantic restriction violations, which sometimes accompany metaphor (cf.
</prevsent>
</prevsection>
<citsent citstr=" J04-1002 ">
fass (1997) and mason (2004)), <papid> J04-1002 </papid>and using statistical techniques borrowed from such work as gedigian et al (2006).<papid> W06-3506 </papid>example (4) about recesses?</citsent>
<aftsection>
<nextsent>is similar to metaphor examples studied in the att meta project, and att-meta-style reasoning could handle the text.
</nextsent>
<nextsent>as for (2), note that the word incubate?
</nextsent>
<nextsent>may have directly usable lexicon-listed meaning (e.g., help to develop much as in wordnet 3.0).
</nextsent>
<nextsent>however, if the systems lexicon did not contain such sense, att-meta-style processing would apply.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3241">
<title id=" W08-2228.xml">textual entailment as an evaluation framework for metaphor resolution a proposal </title>
<section> metaphor processing.  </section>
<citcontext>
<prevsection>
<prevsent>the basis for such translation is view-neutral mapping adjuncts, special type of mappings that cover the shape of events and processes, temporal properties and relationships, causation, functioning, mental states, emotional states, value judgments and various other matters (agerri et al, 2007; barnden et al, 2003).<papid> E03-1067 </papid></prevsent>
<prevsent>rte-2 organisers claimed there has been trend towards using more deep inference and that this has been beneficial provided that it is based on enough knowledge.</prevsent>
</prevsection>
<citsent citstr=" W07-1409 ">
(see also bos and markert (2006) and clark et al (2007)).<papid> W07-1409 </papid></citsent>
<aftsection>
<nextsent>the depth and knowledge needs of att-metas processing are like those of deeper parts of existing rte systems, but att-meta is currently equipped only with small, hand-constructed knowledge bases.
</nextsent>
<nextsent>so, our main focus in deeper processing will actually be on shall owed, broadened form of att-meta-style reasoning.
</nextsent>
<nextsent>in this sense, we aim to look at common-sense knowledge resources such as concept net 3.0 which contains relationships such as causation, function, etc. ? the types of information transferred by some of att metas vnmas ? or modified wordnets enriched by extra, web-mined knowledge(veale and hao, 2008), where the extra knowledge is especially relevant to metaphorical usages.
</nextsent>
<nextsent>att-metas reasoning is by backwards chaining from goals derivable from context surrounding metaphor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3242">
<title id=" W09-0107.xml">parsed corpora for linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as consequence, such parsers now obtain competitive, if not superior, performance.
</prevsent>
<prevsent>zaenen (2004), for instance, points out that the (lfgbased) xle parser is fast, has statistical disambiguation component, and is robust, and thus allows full parsing to be incorporated in many applications.
</prevsent>
</prevsection>
<citsent citstr=" J07-4004 ">
clark and curran (2007) <papid> J07-4004 </papid>show that both accurate and highly efficient parsing is possible using ccg.</citsent>
<aftsection>
<nextsent>as consequence of this development, massive amounts of parsed sentences now become available.
</nextsent>
<nextsent>such large collections of syntactically annotated but not manually verified syntactic analyses are very useful resource for many purposes.
</nextsent>
<nextsent>in this position paper we focus on one purpose: linguistic analysis.
</nextsent>
<nextsent>our claim is, that very large parsed corpora are an important resource for linguists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3243">
<title id=" W09-0107.xml">parsed corpora for linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dependency structures are based on cgn (corpus gesproken nederlands, corpus of spoken dutch) (hoekstra et al , 2003), d-coi and lassy (van noord et al , 2006).dependency structures are stored in xml.
</prevsent>
<prevsent>advantages of the use of xml include the availability of general purpose search and visualization software.
</prevsent>
</prevsection>
<citsent citstr=" W07-1503 ">
for instance, we exploit xpath (standard xml query language) to search in large sets of dependency structures, and xquery to extract information from such large sets of dependency structures (bouma and kloosterman, 2002; bouma and kloosterman, 2007).<papid> W07-1503 </papid></citsent>
<aftsection>
<nextsent>out of topic the first illustration of our thesis that parsed corpora provide an interesting new resource for linguists, constitutes more of an anecdote than systematic study.
</nextsent>
<nextsent>we include the example, presented earlier in van noord (2009), because it is fairly easy to explain, and because it was how we be came aware ourselves of the potential of parsed corpora for the purpose of linguistics.in vander beek et al  (2002), the grammar underlying the alpino parser is presented in some detail.
</nextsent>
<nextsent>as an example of how the various specific rules of the grammar interact with the more general principles, the analysis of comparatives andthe interaction with generic principles for (rightward) extra position is illustrated.
</nextsent>
<nextsent>in short, comparatives such as comparative adjectives and the adverb anders as in the following example (1) license corresponding comparative phrases (such as phrases headed by dan (than)) by means of afeature which percolates according to the extra position principle.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3244">
<title id=" W09-1608.xml">an approach to text summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a variety of automated summarization schemes have been proposed recently.
</prevsent>
<prevsent>neats (lin and hovy, 2002) is sentence position, term frequency, topic signature and term clustering based approach and mead (radev et al, 2004) is centro id based approach.
</prevsent>
</prevsection>
<citsent citstr=" W04-3247 ">
iterative graph based ranking algorithms, such as klein bergs hits algorithm (kleinberg, 1999) and googles page rank (brin and page, 1998) have been traditionally and successfully used in web-link analysis, social networks and more recently in text processing applications (mihalcea and tarau, 2004), (mihalcea et al, 2004), (erkan and radev, 2004) <papid> W04-3247 </papid>and (mihal cea, 2004).</citsent>
<aftsection>
<nextsent>these iterative approaches have high time complexity and are practically slow in dynamic summarization.
</nextsent>
<nextsent>proposals are also made for coherence based automated summarization system (silber and mccoy, 2000).
</nextsent>
<nextsent>we propose novel text summarization technique that involves two basic operations, namely finding coherent chunks in the document and ranking the text in the individual coherent chunks formed.
</nextsent>
<nextsent>for finding coherent chunks in the document, we propose set of rules that identifies the connection between adjacent sentences in the document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3245">
<title id=" W08-1125.xml">a dynamic programming approach to document length constraints </title>
<section> document length constraints.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J00-2005 ">
a number of language engineering applications have addressed the issue of generating coherent documents under length constraints, including nlg applications, e.g., scifly (paris, et al 2008), stop (reiter, 2000), <papid> J00-2005 </papid>ilex (o donnell, 1997), and summarization applications, e.g., daniel marcu (1999).</citsent>
<aftsection>
<nextsent>these applications all address the issue by representing the content to be delivered as rhetorical tree and using some formulation of greedy algorithm that satisfies the length constraints by either selecting the most important elements of the tree or pruning the least important elements.1 as an example, consider the two sample outputs shown in figure 1.
</nextsent>
<nextsent>both outputs were produced by 1 the stop system identifies the problem as bin-packing.
</nextsent>
<nextsent>problem but then describes its mechanism using terms common to greedy algorithms (reiter, 2000).<papid> J00-2005 </papid></nextsent>
<nextsent>a prototype that delivers information about computer science department to prospective students via email; cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3247">
<title id=" W08-1801.xml">improving text retrieval precision and answer accuracy in question answering systems </title>
<section> improving text retrieval in isolation.  </section>
<citcontext>
<prevsection>
<prevsent>answer projection support was disabled for the purposes of this paper.
</prevsent>
<prevsent>1see: http://www.ephyra.info the common representation in openephyra is verb predicate-argument structure, augmented with named entity types, in which verb arguments are labeled with semantic roles in the style of propbank (kingsbury et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
this feature requires the separate download2 of semantic parser called assert (pradhan et al, 2004), <papid> N04-1030 </papid>which was trained on propbank.</citsent>
<aftsection>
<nextsent>see figure 1 for an example representation for the sentence, john loves mary.
</nextsent>
<nextsent>openephyra comes packaged with standard baseline methods for answer extraction and selection.
</nextsent>
<nextsent>for example, it extracts answers from retrieved text based on named entity instances matching the expected answer type as determined by the question analysis module.
</nextsent>
<nextsent>it can also look for predicate-argument structures that match the question structure, and can extract the argument corresponding to the argument in the question representing the interrogative phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3248">
<title id=" W08-1801.xml">improving text retrieval precision and answer accuracy in question answering systems </title>
<section> improving text retrieval in isolation.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 test collection.
</prevsent>
<prevsent>the corpus used in this experiment is the aquaint corpus (graff, 2002), the standard corpus for the trec3 qa evaluations held in 2002 through 2005.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
the corpus was prepared using mxterminator (reynar and ratnaparkhi,1997) <papid> A97-1004 </papid>for sentence segmentation, bbn identifinder (bikel et al, 1999) for named entity recognition, as well as the aforementioned assert for identification of verb predicate-argument structures and propbank-style semantic role labeling of the arguments.</citsent>
<aftsection>
<nextsent>the test collection consists of 109 questions from the qa track at trec 2002 with extensive document-level relevance judgments (bilotti et al, 2004; lin and katz, 2006) over the aquaintcorpus.
</nextsent>
<nextsent>a set of sentence-level judgments was pre 2see: http://www.cemantix.org3text retrieval conferences organized by the u.s. national institute of standards and technology 2 existing query #combine[sentence]( #any:person first person reach south pole ) top-ranked result dufek became the first person to land an airplane at the south pole.
</nextsent>
<nextsent>second-ranked result he reached the north pole in 1991.
</nextsent>
<nextsent>high-precision query #combine[sentence]( #max( #combine[target]( scored #max( #combine[./arg1]( #any:person )) #max( #combine[./arg2]( #max( #combine[target]( reach #max( #combine[./arg1]( south pole ))))))))) top-ranked result [arg1 norwegian explorer [person roald admundsen]] [target becomes] (relevant) [arg2 [arg0 first man] to [target reach] [arg1 [location south pole]]]figure 2: retrieval comparison between openephryas existing text retrieval component, and the high precision version it was replaced with, for question 1475, who was the first person to reach the south pole?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3249">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> syntactic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>our conll 2009 shared task (hajic?
</prevsent>
<prevsent>et al, 2009): multilingual syntactic and semantic dependencies system includes three cascaded components: syntactic parsing, predicate classification, and semantic role labeling.
</prevsent>
</prevsection>
<citsent citstr=" W08-2134 ">
we extend our conll 2008 graph-based model (che et al, 2008) <papid> W08-2134 </papid>in four ways: 1.</citsent>
<aftsection>
<nextsent>we use bigram features to choose multiple pos-.
</nextsent>
<nextsent>sible syntactic labels for one arc, and decide the optimal label during decoding.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>we extend the model with sibling features (mc-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3252">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> syntactic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we extend the model with sibling features (mc-.
</prevsent>
<prevsent>donald, 2006).tures.
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
rather than only using the left-most and rightmost grandchildren as carreras (2007) <papid> D07-1101 </papid>and johansson and nugues (2008) <papid> D08-1008 </papid>did, we use all left and right grandchildren in our model.</citsent>
<aftsection>
<nextsent>4.
</nextsent>
<nextsent>we adopt the pseudo-projective approach in-.
</nextsent>
<nextsent>troduced in (nivre and nilsson, 2005) <papid> P05-1013 </papid>to handle the non-projective languages including czech, german and english.</nextsent>
<nextsent>2.1 syntactic label determining.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3254">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> syntactic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we extend the model with sibling features (mc-.
</prevsent>
<prevsent>donald, 2006).tures.
</prevsent>
</prevsection>
<citsent citstr=" D08-1008 ">
rather than only using the left-most and rightmost grandchildren as carreras (2007) <papid> D07-1101 </papid>and johansson and nugues (2008) <papid> D08-1008 </papid>did, we use all left and right grandchildren in our model.</citsent>
<aftsection>
<nextsent>4.
</nextsent>
<nextsent>we adopt the pseudo-projective approach in-.
</nextsent>
<nextsent>troduced in (nivre and nilsson, 2005) <papid> P05-1013 </papid>to handle the non-projective languages including czech, german and english.</nextsent>
<nextsent>2.1 syntactic label determining.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3255">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> syntactic dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>4.
</prevsent>
<prevsent>we adopt the pseudo-projective approach in-.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
troduced in (nivre and nilsson, 2005) <papid> P05-1013 </papid>to handle the non-projective languages including czech, german and english.</citsent>
<aftsection>
<nextsent>2.1 syntactic label determining.
</nextsent>
<nextsent>the model of (che et al, 2008) <papid> W08-2134 </papid>decided one label for each arc before decoding according to unigram features, which caused lower labeled attachment score (las).</nextsent>
<nextsent>on the other hand, keeping all possible labels for each arc made the decoding in efficient.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3266">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> predicate classification.  </section>
<citcontext>
<prevsection>
<prevsent>classification: for each target word, support.
</prevsent>
<prevsent>vector machine (svm) classifier is used to classify its sense.
</prevsent>
</prevsection>
<citsent citstr=" W02-1006 ">
as reported by lee and ng (2002) <papid> W02-1006 </papid>and guo et al (2007), <papid> W07-2034 </papid>svm shows good performance on the wsd task.</citsent>
<aftsection>
<nextsent>here libsvm (chang and lin, 2001) is used.
</nextsent>
<nextsent>the linear kernel function is used and the trade off parameter is 1.
</nextsent>
<nextsent>data which does not appear in the training data, its first sense in the frame files is used.
</nextsent>
<nextsent>the semantic role labeling (srl) can be divided into two separate stages: semantic role classification (src) and post inference (pi).during the src stage, maximum entropy (berger et al, 1996) <papid> J96-1002 </papid>classifier is used to predict the probabilities of word in the sentence language no-duplicated-roles catalan arg0-agt, arg0-cau, arg1-pat, arg2-atr, arg2-loc chinese a0, a1, a2, a3, a4, a5, czech act, addr, crit, loc, pat, dir3, cond english a0, a1, a2, a3, a4, a5, german a0, a1, a2, a3, a4, a5, japanese de, ga, tmp, wo spanish arg0-agt, arg0-cau, arg1-pat, arg1-tem, arg2-atr,arg2-loc, arg2-null, arg4-des, argl-null, argm cau, argm-ext, argm-fin table 1: no-duplicated-roles for different languages to be each semantic role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3267">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> predicate classification.  </section>
<citcontext>
<prevsection>
<prevsent>classification: for each target word, support.
</prevsent>
<prevsent>vector machine (svm) classifier is used to classify its sense.
</prevsent>
</prevsection>
<citsent citstr=" W07-2034 ">
as reported by lee and ng (2002) <papid> W02-1006 </papid>and guo et al (2007), <papid> W07-2034 </papid>svm shows good performance on the wsd task.</citsent>
<aftsection>
<nextsent>here libsvm (chang and lin, 2001) is used.
</nextsent>
<nextsent>the linear kernel function is used and the trade off parameter is 1.
</nextsent>
<nextsent>data which does not appear in the training data, its first sense in the frame files is used.
</nextsent>
<nextsent>the semantic role labeling (srl) can be divided into two separate stages: semantic role classification (src) and post inference (pi).during the src stage, maximum entropy (berger et al, 1996) <papid> J96-1002 </papid>classifier is used to predict the probabilities of word in the sentence language no-duplicated-roles catalan arg0-agt, arg0-cau, arg1-pat, arg2-atr, arg2-loc chinese a0, a1, a2, a3, a4, a5, czech act, addr, crit, loc, pat, dir3, cond english a0, a1, a2, a3, a4, a5, german a0, a1, a2, a3, a4, a5, japanese de, ga, tmp, wo spanish arg0-agt, arg0-cau, arg1-pat, arg1-tem, arg2-atr,arg2-loc, arg2-null, arg4-des, argl-null, argm cau, argm-ext, argm-fin table 1: no-duplicated-roles for different languages to be each semantic role.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3268">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the linear kernel function is used and the trade off parameter is 1.
</prevsent>
<prevsent>data which does not appear in the training data, its first sense in the frame files is used.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the semantic role labeling (srl) can be divided into two separate stages: semantic role classification (src) and post inference (pi).during the src stage, maximum entropy (berger et al, 1996) <papid> J96-1002 </papid>classifier is used to predict the probabilities of word in the sentence language no-duplicated-roles catalan arg0-agt, arg0-cau, arg1-pat, arg2-atr, arg2-loc chinese a0, a1, a2, a3, a4, a5, czech act, addr, crit, loc, pat, dir3, cond english a0, a1, a2, a3, a4, a5, german a0, a1, a2, a3, a4, a5, japanese de, ga, tmp, wo spanish arg0-agt, arg0-cau, arg1-pat, arg1-tem, arg2-atr,arg2-loc, arg2-null, arg4-des, argl-null, argm cau, argm-ext, argm-fin table 1: no-duplicated-roles for different languages to be each semantic role.</citsent>
<aftsection>
<nextsent>we add virtual role null?
</nextsent>
<nextsent>(presenting none of roles is assigned) to the roles set, so we do not need semantic role identification stage anymore.
</nextsent>
<nextsent>for predicate of each language, two classifiers (one for noun predicates, and the other for verb predicates) predict probabilities of each word in sentence to be each semantic role (including virtual role null?).
</nextsent>
<nextsent>the features used in this stage are listed in table 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3270">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the probability of each word to be semantic rolefor predicate is given by the src stage.
</prevsent>
<prevsent>there sults generated by selecting the roles with the largest probabilities, however, do not satisfy some constrains.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
as we did in the last years system (che etal., 2008), <papid> W08-2134 </papid>we use the ilp (integer linear programming) (punyakanok et al, 2004) <papid> C04-1197 </papid>to get the global optimization, which is satisfied with three constrains: c1: each word should be labeled with one and only one label (including the virtual label null?).</citsent>
<aftsection>
<nextsent>c2: roles with small probability should never be labeled (except for the virtual role null?).
</nextsent>
<nextsent>the threshold we use in our system is 0.3.
</nextsent>
<nextsent>c3: statistics show that some roles (except for the virtual role null?)
</nextsent>
<nextsent>usually appear once fora predicate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3271">
<title id=" W09-1207.xml">multilingual dependency based syntactic and semantic parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we participate in the conll 2009 shared task with all 7 languages: catalan (taule?
</prevsent>
<prevsent>et al, 2008), chinese (palmer and xue, 2009), czech (hajic?
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
etal., 2006), english (surdeanu et al, 2008), <papid> W08-2121 </papid>german (burchardt et al, 2006), japanese (kawaharaet al, 2002), and spanish (taule?</citsent>
<aftsection>
<nextsent>et al, 2008).
</nextsent>
<nextsent>besides the closed challenge, we also submitted the open challenge results.
</nextsent>
<nextsent>our open challenge strategy is very simple.
</nextsent>
<nextsent>we add the srl development dataof each language into their training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3275">
<title id=" W09-0630.xml">realizing the costs template based surface realisation in the graph approach to referring expression generation </title>
<section> attribute selection.  </section>
<citcontext>
<prevsection>
<prevsent>the tuna challenge 2009 is the last in series of challenges using the tuna corpus of referring expressions (gatt et al 2007) for comparative evaluation of referring expression generation.the 2009 challenge is aimed at end-to-end referring expression generation, which encompasses two subtasks: (1) attribute selection, choosing number of attributes that uniquely characterize target object, distinguishing it from other objects in visual scene, and (2) realisation, converting the selected set of attributes into word string.our contributions to the previous challenges focused on subtask (1), but this year we focus on subtask (2).
</prevsent>
<prevsent>below, we briefly sketch how attribute selection is performed in our system, describe our newly developed realiser, and present our evaluation results on the tuna 2009 development set.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
we use the graph-based algorithm of krahmer et al (2003) <papid> J03-1003 </papid>for attribute selection.</citsent>
<aftsection>
<nextsent>in this approach, objects and their attributes are represented in graph as nodes and edges respectively, and attribute selection is seen as graph search problem that outputs the cheapest distinguishing graph, given particular cost function that assigns coststo attributes.
</nextsent>
<nextsent>by assigning zero costs to some attributes, e.g., the type of an object, the human tendency to mention redundant properties can be mimicked.
</nextsent>
<nextsent>for the tuna challenge 2009 we use the same settings as last year (krahmer et al 2008).<papid> W08-1138 </papid></nextsent>
<nextsent>the used cost function assigns zero cost to attributes that are highly frequent in the tuna corpus, while the other attributes have cost of either 1 (somewhat infrequent) or 2 (very infre quent).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3276">
<title id=" W09-0630.xml">realizing the costs template based surface realisation in the graph approach to referring expression generation </title>
<section> attribute selection.  </section>
<citcontext>
<prevsection>
<prevsent>in this approach, objects and their attributes are represented in graph as nodes and edges respectively, and attribute selection is seen as graph search problem that outputs the cheapest distinguishing graph, given particular cost function that assigns coststo attributes.
</prevsent>
<prevsent>by assigning zero costs to some attributes, e.g., the type of an object, the human tendency to mention redundant properties can be mimicked.
</prevsent>
</prevsection>
<citsent citstr=" W08-1138 ">
for the tuna challenge 2009 we use the same settings as last year (krahmer et al 2008).<papid> W08-1138 </papid></citsent>
<aftsection>
<nextsent>the used cost function assigns zero cost to attributes that are highly frequent in the tuna corpus, while the other attributes have cost of either 1 (somewhat infrequent) or 2 (very infre quent).
</nextsent>
<nextsent>the order in which attributes are addedis also controlled: to ensure that the cheapest attributes are added first, they are tried in the order of their frequency in the tuna (2008) training corpus.
</nextsent>
<nextsent>using these settings, last year the graph attribute selection algorithm made the top 3 on all evaluation measures (gatt et al 2008, <papid> W08-1131 </papid>table 11).</nextsent>
<nextsent>the main resource for realisation is set of templates, derived from the human-produced object descriptions in the tuna 2009 training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3277">
<title id=" W09-0630.xml">realizing the costs template based surface realisation in the graph approach to referring expression generation </title>
<section> attribute selection.  </section>
<citcontext>
<prevsection>
<prevsent>the used cost function assigns zero cost to attributes that are highly frequent in the tuna corpus, while the other attributes have cost of either 1 (somewhat infrequent) or 2 (very infre quent).
</prevsent>
<prevsent>the order in which attributes are addedis also controlled: to ensure that the cheapest attributes are added first, they are tried in the order of their frequency in the tuna (2008) training corpus.
</prevsent>
</prevsection>
<citsent citstr=" W08-1131 ">
using these settings, last year the graph attribute selection algorithm made the top 3 on all evaluation measures (gatt et al 2008, <papid> W08-1131 </papid>table 11).</citsent>
<aftsection>
<nextsent>the main resource for realisation is set of templates, derived from the human-produced object descriptions in the tuna 2009 training data.
</nextsent>
<nextsent>to construct the templates, we first grouped the descriptions by the combination of attributes theyexpressed.
</nextsent>
<nextsent>for instance, in the domain of furniture references, all descriptions expressing the attributes colour, type and orientation were grouped together.
</nextsent>
<nextsent>this was done for all combinations of attributes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3278">
<title id=" W09-1320.xml">towards retrieving relevant information for answering clinical comparison questions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the following examples illustrate the difference: comparative form: is ibuprofen better than paracetamol for treating pain?
</prevsent>
<prevsent>superlative form: is ibuprofen the best treatment for pain?
</prevsent>
</prevsection>
<citsent citstr=" P89-1020 ">
friedman (1989) <papid> P89-1020 </papid>developed one of the first computational treatments of comparative struc tures.</citsent>
<aftsection>
<nextsent>comparisons are challenging because they correspond to diverse range of syntactic forms such as coordinate or subordinate conjunctions, adverbial constructions or wh-relative-like clauses.
</nextsent>
<nextsent>comparisons are cross-categorical and encompass adjectives, quantifiers, and adverbs.
</nextsent>
<nextsent>adjectives and adverbs indicating comparisons occur in the following patterns: comparative adjectives and adverbs: regular adjectives and adverbs: adj/adv -er (e.g. safer) [[as/than]1 x] [for y] irregular adjectives and adverbs: e.g. worse/better [[as/than] x] [for y] analytical adjectives and adverbs: e.g. less/more adj/adv [than x] [for y] 1as/ than are optional.
</nextsent>
<nextsent>for example see or b: what is safer??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3279">
<title id=" W09-1320.xml">towards retrieving relevant information for answering clinical comparison questions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a small number of false positives were removed during manual post-processing.
</prevsent>
<prevsent>false positives were due to the fact that not all words tagged as superlatives are proper comparisons, but idiomatic expressions, such as best practise?, or proportional quantifiers (huddleston and pullum, 2002) such as most nsaids?.
</prevsent>
</prevsection>
<citsent citstr=" L08-1453 ">
(scheible (2008) <papid> L08-1453 </papid>distinguishes eight different classes in which the superlative construction is used in english but only five of the eight classes involve true comparisons.)</citsent>
<aftsection>
<nextsent>the result is subset of 742 comparison questions out of the the total corpus of 4580 q-a pairs.
</nextsent>
<nextsent>table 2.
</nextsent>
<nextsent>shows the number of occurrences for each item.
</nextsent>
<nextsent>pos tag/lexical item occurrences jjr 195 rbr 124 jjs 207 rbs 68 versus, instead of 18 compared to/with, differ from 45 comparison, difference 85 total 742 table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3280">
<title id=" W09-1320.xml">towards retrieving relevant information for answering clinical comparison questions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>abstracts and section 3.2 will show work on answering clinical questions about comparisons.
</prevsent>
<prevsent>3.1 interpretation of comparative structures.
</prevsent>
</prevsection>
<citsent citstr=" W07-1018 ">
(fiszman et al, 2007) <papid> W07-1018 </papid>describes work on automatically interpreting comparative constructions in medline?</citsent>
<aftsection>
<nextsent>abstracts.
</nextsent>
<nextsent>they use an extension of an 155 existing semantic processor, semrep (rindflesch and fiszman, 2003; rindflesch et al, 2005), from the unified medical language system resources to construct semantic predications for the extracted comparative expressions.
</nextsent>
<nextsent>fiszman et al concentrate on extracting structures in which two drugs are compared with respect to shared attribute?, such as drugs efficacy in treating certain condition, illustrated in the following in example: (3) losartan was more effective than atenolol in reducing cardiovascular morbidity and mortality inpatients with hyptertension, diabetes, and lvh.
</nextsent>
<nextsent>[example (20) in (fiszman et al 2007)] <papid> W07-1018 </papid>the drugs  relative merits in achieving their purpose is expressed by positions on scale.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3288">
<title id=" W08-1306.xml">large scale production of syntactic annotations to move forward </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.
</prevsent>
<prevsent>1 http://www.cis.upenn.edu/ ? treebank/ 2 http://www.natcorp.ox.ac.uk/trees using heuristic rules , then by extracting lexical entries with the application of inverse grammar rules.
</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
(cahill et al, 2004) <papid> P04-1041 </papid>managed to extract lfg subcategorisation frames and paths linking long distance dependencies reentrancies fromf-structures generated automatically for the penn ii treebank trees and used them in an long distance dependency resolution algorithm to parse new text.</citsent>
<aftsection>
<nextsent>they achieved around 80% f-score for fstructures parsing on the wsj part of the penn-ii treebank,a score comparable to the ones of the state-ofthe-art hand-crafted grammars.
</nextsent>
<nextsent>with similar results, (hockenmaier and steedman, 2007) translated the penn treebank into corpus of combinatory categorial grammar (ccg) derivations augmented with local and long-range word to word dependencies and used it to train wide-coverage statistical parsers.
</nextsent>
<nextsent>the development of the penn treebank have led to many similar proposals of corpus annotations 3 . however, the development of.
</nextsent>
<nextsent>such treebanks is very costly from an human point of view and represents longstanding effort, in particular for getting of rid of the annotation error sor inconsistencies, unavoidable for any kind of human annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3289">
<title id=" W08-1306.xml">large scale production of syntactic annotations to move forward </title>
<section> passage syntactic annotation.  </section>
<citcontext>
<prevsection>
<prevsent>element.
</prevsent>
<prevsent>specification 3.1 introduction.
</prevsent>
</prevsection>
<citsent citstr=" E03-1085 ">
the annotation formalism used in passage 7 is based on the easy one(vilnat et al, 2004) which whose first version was crafted in an experimental project peas (gendner et al, 2003), <papid> E03-1085 </papid>with inspiration taken from the propositions of (carroll et al, 2002).</citsent>
<aftsection>
<nextsent>the definition has been completed with the input of all the actors involved in the easy evaluation campaign (both parsers?
</nextsent>
<nextsent>developers and corpus providers) and refined with the input of passage participants.
</nextsent>
<nextsent>this formalism aims at making possible the comparison of all kinds of syntactic annotation (shallow or deep parsing, complete or partial analysis), without giving any advantage to any particular approach.
</nextsent>
<nextsent>it has six kinds of syntactic chunks?, we call constituent sand 14 kinds of relations the annotation formalism allows the annotation of minimal, continuous and non recursive constituents, as well as the encoding of relations wich represent syntactic functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3290">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however the results are still modest.
</prevsent>
<prevsent>mt research on vietnamese-french occurs even more rarely.
</prevsent>
</prevsection>
<citsent citstr=" W01-0809 ">
doan (2001) <papid> W01-0809 </papid>proposed translation module for vietnamese within its3, multilingual mt system based on the classical analysis-transfer-generation approach.</citsent>
<aftsection>
<nextsent>nguyen (2006) worked on vietnamese language and vietnamese-french text alignment.
</nextsent>
<nextsent>but no complete mt system for this pair of languages has been published so far.
</nextsent>
<nextsent>there are many approaches for mt: rule-based (direct translation, interlingua-based, transfer based), corpus-based (statistical, example-based) as well as hybrid approaches.
</nextsent>
<nextsent>we focus on building vietnamese-french statistical machine translation (smt) system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3291">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such an approach requires parallel bilingual corpus for source and target languages.
</prevsent>
<prevsent>using this corpus, we build statistical translation model for source/target languages and statistical language model for target language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
then the two models and search module are used to decode the best translation (brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>thus, the first task is to build large parallel bilingual text corpus.
</nextsent>
<nextsent>this corpus can be described as set of bilingual sentence pairs.
</nextsent>
<nextsent>at the moment, such large parallel corpus for viet namese-french is unavailable.
</nextsent>
<nextsent>(nguyen, 2006) presents vietnamese-french parallel corpus of law and economics documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3292">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such an approach requires parallel bilingual corpus for source and target languages.
</prevsent>
<prevsent>using this corpus, we build statistical translation model for source/target languages and statistical language model for target language.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
then the two models and search module are used to decode the best translation (brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>thus, the first task is to build large parallel bilingual text corpus.
</nextsent>
<nextsent>this corpus can be described as set of bilingual sentence pairs.
</nextsent>
<nextsent>at the moment, such large parallel corpus for viet namese-french is unavailable.
</nextsent>
<nextsent>(nguyen, 2006) presents vietnamese-french parallel corpus of law and economics documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3293">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> mining comparable text corpus.  </section>
<citcontext>
<prevsection>
<prevsent>extracting parallel documents or aligning documents from the two sets s1, s2 can be seen as finding the translation document d2 (in the set s2) of document d1 (in the set s1).
</prevsent>
<prevsent>we call this pair of documents d1-d2 parallel document pair (pdp).
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
for collecting bilingual text data for the two sets s1, s2, the web is an ideal source as it is large, free and available (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></citsent>
<aftsection>
<nextsent>for this kind of data, various methods to align documents have been proposed.
</nextsent>
<nextsent>documents can be simply aligned based on the anchor link, the clue in url (kraaij et al, 2003) <papid> J03-3003 </papid>or the web page structure (resnik and smith, 2003).</nextsent>
<nextsent>however, this information is not always available or trustworthy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3294">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> mining comparable text corpus.  </section>
<citcontext>
<prevsection>
<prevsent>for collecting bilingual text data for the two sets s1, s2, the web is an ideal source as it is large, free and available (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></prevsent>
<prevsent>for this kind of data, various methods to align documents have been proposed.</prevsent>
</prevsection>
<citsent citstr=" J03-3003 ">
documents can be simply aligned based on the anchor link, the clue in url (kraaij et al, 2003) <papid> J03-3003 </papid>or the web page structure (resnik and smith, 2003).</citsent>
<aftsection>
<nextsent>however, this information is not always available or trustworthy.
</nextsent>
<nextsent>the titles of documents d1, d2 can also be used (yang and li, 2002), but sometimes they are completely different.
</nextsent>
<nextsent>another useful source of information is invari ant words, such as named entities, dates, and numbers, which are often common in news data.
</nextsent>
<nextsent>we call these words special words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3295">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> mining comparable text corpus.  </section>
<citcontext>
<prevsection>
<prevsent>senalignmentd1-d2 = {sen1-sen2?| sen1 is zero/one/many sentence(s) in document d1, sen2 is zero/one/many sentence(s) in document d2, sen1-sen2 is considered as psp}.
</prevsent>
<prevsent>we call psp sen1-sen2 alignment type m:n when sen1 contains consecutive sentences and sen2 contains consecutive sentences.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
several automatic sentence alignment approaches have been proposed based on sentence length (brown et al, 1991) <papid> P91-1022 </papid>and lexical information (kay and roscheisen, 1993).<papid> J93-1006 </papid></citsent>
<aftsection>
<nextsent>a hybrid approach is presented in (gale and church, 1993) <papid> J93-1004 </papid>whose basic hypothesis is that longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sen tences?.</nextsent>
<nextsent>some tool kits such as hunalign1 and vanilla2 implement these approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3296">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> mining comparable text corpus.  </section>
<citcontext>
<prevsection>
<prevsent>senalignmentd1-d2 = {sen1-sen2?| sen1 is zero/one/many sentence(s) in document d1, sen2 is zero/one/many sentence(s) in document d2, sen1-sen2 is considered as psp}.
</prevsent>
<prevsent>we call psp sen1-sen2 alignment type m:n when sen1 contains consecutive sentences and sen2 contains consecutive sentences.
</prevsent>
</prevsection>
<citsent citstr=" J93-1006 ">
several automatic sentence alignment approaches have been proposed based on sentence length (brown et al, 1991) <papid> P91-1022 </papid>and lexical information (kay and roscheisen, 1993).<papid> J93-1006 </papid></citsent>
<aftsection>
<nextsent>a hybrid approach is presented in (gale and church, 1993) <papid> J93-1004 </papid>whose basic hypothesis is that longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sen tences?.</nextsent>
<nextsent>some tool kits such as hunalign1 and vanilla2 implement these approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3297">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> mining comparable text corpus.  </section>
<citcontext>
<prevsection>
<prevsent>we call psp sen1-sen2 alignment type m:n when sen1 contains consecutive sentences and sen2 contains consecutive sentences.
</prevsent>
<prevsent>several automatic sentence alignment approaches have been proposed based on sentence length (brown et al, 1991) <papid> P91-1022 </papid>and lexical information (kay and roscheisen, 1993).<papid> J93-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
a hybrid approach is presented in (gale and church, 1993) <papid> J93-1004 </papid>whose basic hypothesis is that longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sen tences?.</citsent>
<aftsection>
<nextsent>some tool kits such as hunalign1 and vanilla2 implement these approaches.
</nextsent>
<nextsent>however, they tend to work best when documents d1, d2 contain few sentence deletions and insertions, and mainly contain psps of type 1:1.
</nextsent>
<nextsent>1 http://mokk.bme.hu/resources/hunalign 2 http://nl.ijs.si/telri/vanilla/ 166 ma (2006) provides an open source software called champollion1 to solve this limitation.
</nextsent>
<nextsent>champollion permits alignment type m:n (m, = 0,1,2,3,4), so the length of sentence does not play an important role.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3298">
<title id=" W09-0430.xml">mining a comparable text corpus for a vietnamese french statistical machine translation system </title>
<section> application: vietnamese - french.  </section>
<citcontext>
<prevsection>
<prevsent>the system was built using the moses toolkit1.
</prevsent>
<prevsent>the moses toolkit contains all of the components needed to train both the translation model and the language model.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
it also contains tools for tuning these models using minimum error rate training and for evaluating the translation result using the bleu score (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>4.1 preparing data.
</nextsent>
<nextsent>from the entire corpus, we chose 50 pdps (351 psps) for developing (dev), 50 pdps (384 psps) for testing (tst), with the rest pdps (49,587 psps) reserved for training (trn).
</nextsent>
<nextsent>concerning the developing and testing psps, we manually verified and eliminated low quality psps, which produced 198 good quality psps for developing and 210 good quality psps for testing.
</nextsent>
<nextsent>the data used to create the language model were extracted from 49,587 psps of the training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3299">
<title id=" W09-0214.xml">semantic density analysis comparing word meaning across time and phonetic space </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in early english and examining and comparing phonaesthemes.
</prevsent>
<prevsent>the increase in available computing power over the last few decades has led to an explosion in the application of statistical methods to the analysis of texts.
</prevsent>
</prevsection>
<citsent citstr=" N06-2020 ">
researchers have applied these methods to wide range of tasks, from word-sense disambiguation (levin et al, 2006) <papid> N06-2020 </papid>to the summarization of texts (marcu, 2003) and the automatic scoring of student essays (riedel et al, 2006).</citsent>
<aftsection>
<nextsent>however, some fields of linguistics that have traditionally employed corpora as their source material, such as historical semantics, have yet to benefit from the application of these statistical methods.
</nextsent>
<nextsent>in this paper we demonstrate how an existing statistical tool (latent semantic analysis) can be adapted and used to automate and enhance some aspects of research in historical semantics and other fields whose focus is on the comparative analysis of word meanings within corpus.
</nextsent>
<nextsent>our method allows us to assess the semantic variation within the set of individual occurrences of given word type.
</nextsent>
<nextsent>this variation is inversely related to property of types that we call density ? intuitively, tendency to occur in highly similar contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3300">
<title id=" W09-0214.xml">semantic density analysis comparing word meaning across time and phonetic space </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>use of language relies on more than simple patterns of word co-occurrence ? for instance, we use syntactic structures and pragmatic reasoning to supplement the meaning of the individual lexemes we come across (e.g., fodor, 1995; grice, 1989 [1975]).
</prevsent>
<prevsent>it is therefore likely that while lsa captures some of the variability in meaning exhibited by words in context, it does not capture all of it.
</prevsent>
</prevsection>
<citsent citstr=" N03-1036 ">
indeed, there is growing body of methods that propose to integrate these two disparate sources of linguistic information (e.g., pado and lapata, 2007; widdows, 2003) <papid> N03-1036 </papid>certainly, the results reported in this paper suggest that enough of the meaning of words and contexts is captured to allow interesting inferences about semantic change and the relatedness of words to be drawn with reasonable degree of certainty.</citsent>
<aftsection>
<nextsent>however, it is possible that some important aspects of meaning are systematically ignored by the analysis.
</nextsent>
<nextsent>for instance, it remains to be seen whether this method can distinguish between processes like pejoration and amerlioration as they require fine grained distinction between good?
</nextsent>
<nextsent>and bad?
</nextsent>
<nextsent>meanings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3301">
<title id=" W08-2232.xml">topdown cohesion segmentation in summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some experiments about ctt and ltt methods are carried out for four classical  texts in summarization literature showing that the quality of the summarization using cohesion segmentation (ctt) is better than the quality using logical segmentation (ltt).
</prevsent>
<prevsent>389 390 tatar, mihis, and serban
</prevsent>
</prevsection>
<citsent citstr=" J02-4001 ">
text summarization has become the subject of an intense research in the last years and it is still an emerging field (orasan, 2006; radev et al, 2002; <papid> J02-4001 </papid>hovy, 2003; mani, 2001).</citsent>
<aftsection>
<nextsent>the research is done in the extracts (which we are treating in this paper) and abstracts areas.
</nextsent>
<nextsent>the most important task of summarization is to identify the most informative (salient) parts of text comparatively with the rest.
</nextsent>
<nextsent>a good segmentation of text could help in this identification (boguraev and neff, 2000; barzilay and elhadad, 1999; reynar, 1998).
</nextsent>
<nextsent>this paper proposes new method of linear text segmentation based on lexical cohesion of text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3302">
<title id=" W08-2232.xml">topdown cohesion segmentation in summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>namely, first single chain of disambiguated words in text is established, then the rips of this chain are considered.
</prevsent>
<prevsent>these rips are boundaries of the segments in the cohesion structure of the text.
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
due to some similarities with text tiling algorithm for topic shifts detection of hearst (1997), <papid> J97-1003 </papid>the method is called cohesion text tiling (ctt).</citsent>
<aftsection>
<nextsent>the paper is structured as follows: in section 2 we present the problem of word sense disambiguation by chain algorithm and the derived ctt method.
</nextsent>
<nextsent>in section 3, some notions about textual entailment and logical segmentation of text by ltt method are discussed.
</nextsent>
<nextsent>summarization by different methods after segmentation is the topic of section 4.
</nextsent>
<nextsent>the parallel application of ctt and ltt methods to four  classical  texts in summarization literature, two narrative and two newspapers, and some statistics of the results are presented in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3303">
<title id=" W08-2232.xml">topdown cohesion segmentation in summarization </title>
<section> a top-down cohesion segmentation method </section>
<citcontext>
<prevsection>
<prevsent>we finish the article with conclusions and possible further work directions.
</prevsent>
<prevsent>2.1 lexical chains.
</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
a lexical chain is sequence of words such that the meaning of each word from these quence can be obtained unambiguously from the meaning of the rest of words (morris and hirst, 1991; <papid> J91-1002 </papid>barzilay and elhadad, 1999; harabagiu and moldovan, 1997; silber and mccoy, 2002; <papid> J02-4004 </papid>stokes, 2004).</citsent>
<aftsection>
<nextsent>the map of all lexical chains of text provides representation of the lexical cohesive structure of the text.
</nextsent>
<nextsent>usually lexical chain is obtained in bottom-up fashion, by taking each candidate word of text, and finding an appropriate relation offered by thesaurus as rodget (morris and hirst, 1991) <papid> J91-1002 </papid>or wordnet (barzilay and elhadad, 1999).</nextsent>
<nextsent>if it is found, the word is inserted with the appropriate sense in the current chain, and the senses of the other words in the chain are updated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3304">
<title id=" W08-2232.xml">topdown cohesion segmentation in summarization </title>
<section> a top-down cohesion segmentation method </section>
<citcontext>
<prevsection>
<prevsent>we finish the article with conclusions and possible further work directions.
</prevsent>
<prevsent>2.1 lexical chains.
</prevsent>
</prevsection>
<citsent citstr=" J02-4004 ">
a lexical chain is sequence of words such that the meaning of each word from these quence can be obtained unambiguously from the meaning of the rest of words (morris and hirst, 1991; <papid> J91-1002 </papid>barzilay and elhadad, 1999; harabagiu and moldovan, 1997; silber and mccoy, 2002; <papid> J02-4004 </papid>stokes, 2004).</citsent>
<aftsection>
<nextsent>the map of all lexical chains of text provides representation of the lexical cohesive structure of the text.
</nextsent>
<nextsent>usually lexical chain is obtained in bottom-up fashion, by taking each candidate word of text, and finding an appropriate relation offered by thesaurus as rodget (morris and hirst, 1991) <papid> J91-1002 </papid>or wordnet (barzilay and elhadad, 1999).</nextsent>
<nextsent>if it is found, the word is inserted with the appropriate sense in the current chain, and the senses of the other words in the chain are updated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3308">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we analyze our approach in an annotation projection framework for dependency trees, and show how dependency parsers from two different paradigms (graph-based andtransition-based) can be trained on the resulting tree fragments.
</prevsent>
<prevsent>we train parsers for dutch to evaluate our method and to investigate to which degree graph-based and transition based parsers can benefit from incomplete training data.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we find that partial correspondence projection gives rise to parsers that outperform parsers trained on aggressively filtered datasets, and achieve unlabeled attachment scores that are only 5% behind the average uas for dutch in the conll-x shared task on supervised parsing (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>many weakly supervised approaches to nlp relyon heuristics or filtering techniques to deal with noise in unlabeled or automatically labeled training data,e.g., in the exploitation of parallel corpora for cross lingual projection of morphological, syntactic or semantic information.
</nextsent>
<nextsent>while heuristic approaches can implement (linguistic) knowledge that helps to detect noisy data (e.g., hwa et al (2005)), they are typically task- and language-specific and thus introduce component of indirect supervision.
</nextsent>
<nextsent>non-heuristicfiltering techniques, on the other hand, employ reliability measures (often unrelated to the task) to predict high-precision data points (e.g., yarowsky et al (2001)).<papid> H01-1035 </papid></nextsent>
<nextsent>in order to reach sufficient level of precision, filtering typically has to be aggressive, especially for highly structured tasks like parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3310">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many weakly supervised approaches to nlp relyon heuristics or filtering techniques to deal with noise in unlabeled or automatically labeled training data,e.g., in the exploitation of parallel corpora for cross lingual projection of morphological, syntactic or semantic information.
</prevsent>
<prevsent>while heuristic approaches can implement (linguistic) knowledge that helps to detect noisy data (e.g., hwa et al (2005)), they are typically task- and language-specific and thus introduce component of indirect supervision.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
non-heuristicfiltering techniques, on the other hand, employ reliability measures (often unrelated to the task) to predict high-precision data points (e.g., yarowsky et al (2001)).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>in order to reach sufficient level of precision, filtering typically has to be aggressive, especially for highly structured tasks like parsing.
</nextsent>
<nextsent>such aggressive filtering techniques incur massive data loss and enforce trade-offs between the quality and the amount of usable data.ideally, general filtering strategy for weakly supervised training of structured analysis tools should eliminate noisy subparts in the automatic annotation without discarding its high-precision aspects; thereby data loss would be kept to minimum.in this paper, we propose an extremely simple approach to noise reduction which greedily exploits partial correspondences in parallel corpus, i.e.,correspondences potentially covering only substructures of translated sentences.
</nextsent>
<nextsent>we implemented this method in an annotation projection framework to create training data for two dependency parsers representing different parsing paradigms: the mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>as an instance ofgraph-based dependency parsing, and the malt parser (nivre et al, 2006) <papid> W06-2933 </papid>to represent transition based dependency parsing.</nextsent>
<nextsent>in an empirical evaluation, we investigate how they react differently to incomplete and noisy training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3311">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to reach sufficient level of precision, filtering typically has to be aggressive, especially for highly structured tasks like parsing.
</prevsent>
<prevsent>such aggressive filtering techniques incur massive data loss and enforce trade-offs between the quality and the amount of usable data.ideally, general filtering strategy for weakly supervised training of structured analysis tools should eliminate noisy subparts in the automatic annotation without discarding its high-precision aspects; thereby data loss would be kept to minimum.in this paper, we propose an extremely simple approach to noise reduction which greedily exploits partial correspondences in parallel corpus, i.e.,correspondences potentially covering only substructures of translated sentences.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
we implemented this method in an annotation projection framework to create training data for two dependency parsers representing different parsing paradigms: the mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>as an instance ofgraph-based dependency parsing, and the malt parser (nivre et al, 2006) <papid> W06-2933 </papid>to represent transition based dependency parsing.</citsent>
<aftsection>
<nextsent>in an empirical evaluation, we investigate how they react differently to incomplete and noisy training data.
</nextsent>
<nextsent>despite its simplicity, the partial correspondence approach proves very effective and leads to parsers that achieve unlabeled attachment scores that are only 5% behind the average uas for dutch in the conll-x shared task (buchholz and marsi, 2006).<papid> W06-2920 </papid></nextsent>
<nextsent>after summary of related work in sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3312">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to reach sufficient level of precision, filtering typically has to be aggressive, especially for highly structured tasks like parsing.
</prevsent>
<prevsent>such aggressive filtering techniques incur massive data loss and enforce trade-offs between the quality and the amount of usable data.ideally, general filtering strategy for weakly supervised training of structured analysis tools should eliminate noisy subparts in the automatic annotation without discarding its high-precision aspects; thereby data loss would be kept to minimum.in this paper, we propose an extremely simple approach to noise reduction which greedily exploits partial correspondences in parallel corpus, i.e.,correspondences potentially covering only substructures of translated sentences.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
we implemented this method in an annotation projection framework to create training data for two dependency parsers representing different parsing paradigms: the mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>as an instance ofgraph-based dependency parsing, and the malt parser (nivre et al, 2006) <papid> W06-2933 </papid>to represent transition based dependency parsing.</citsent>
<aftsection>
<nextsent>in an empirical evaluation, we investigate how they react differently to incomplete and noisy training data.
</nextsent>
<nextsent>despite its simplicity, the partial correspondence approach proves very effective and leads to parsers that achieve unlabeled attachment scores that are only 5% behind the average uas for dutch in the conll-x shared task (buchholz and marsi, 2006).<papid> W06-2920 </papid></nextsent>
<nextsent>after summary of related work in sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3316">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(c) constrained fallback projection.
</prevsent>
<prevsent>annotation projection has been applied to many different nlp tasks.
</prevsent>
</prevsection>
<citsent citstr=" I08-1064 ">
on the word or phrase level, these include morphological analysis, part-of-speech tagging and np-bracketing (yarowsky et al, 2001),<papid> H01-1035 </papid>temporal analysis (spreyer and frank, 2008), <papid> I08-1064 </papid>or semantic role labeling (pado?</citsent>
<aftsection>
<nextsent>and lapata, 2006).
</nextsent>
<nextsent>inthese tasks, word labels can technically be introduced in isolation, without reference to the rest of the annotation.
</nextsent>
<nextsent>this means that an aggressive filter can be used to discard unreliable data points (wordsin sentence) without necessarily affecting high precision data points in the same sentence.
</nextsent>
<nextsent>by using only the bidirectional word alignment links, onecan implement very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3317">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>inthese tasks, word labels can technically be introduced in isolation, without reference to the rest of the annotation.
</prevsent>
<prevsent>this means that an aggressive filter can be used to discard unreliable data points (wordsin sentence) without necessarily affecting high precision data points in the same sentence.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
by using only the bidirectional word alignment links, onecan implement very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the bidirectional alignment filter is common practice (pado?
</nextsent>
<nextsent>andlapata, 2006); similar strategy is to discard entire sentences with low aggregated alignment scores (yarowsky et al, 2001).<papid> H01-1035 </papid></nextsent>
<nextsent>on the sentence level, hwa et al (2005) were the first to project dependency trees from english to spanish and chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3319">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3320">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3321">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" P04-1062 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3322">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3323">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3324">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3325">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules account for an enormous increase in the unlabeled f-score of the direct projections, from 33.9 to 65.7 for spanish and from 26.3 to 52.4 for chinese.
</prevsent>
<prevsent>but they need to be designed anew for every target language, which is time-consuming and requires knowledge of that language.
</prevsent>
</prevsection>
<citsent citstr=" P08-1061 ">
research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></citsent>
<aftsection>
<nextsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.
</nextsent>
<nextsent>our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</nextsent>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3326">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>research in the field of unsupervised and weakly supervised parsing ranges from various forms of emtraining (pereira and schabes, 1992; <papid> P92-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2004; <papid> P04-1062 </papid>smith and eisner, 2005) <papid> P05-1044 </papid>over bootstrapping approaches like self training (mcclosky et al, 2006) <papid> N06-1020 </papid>to feature-based enhancements of discriminative reranking models(koo et al, 2008) <papid> P08-1068 </papid>and the application of semi supervised svms (wang et al, 2008).<papid> P08-1061 </papid></prevsent>
<prevsent>the partial correspondence method we present in this paper is compatible with such approaches and can be combined with other weakly supervised machine learning schemes.</prevsent>
</prevsection>
<citsent citstr=" N06-1019 ">
our approach is similar to that of clark and curran (2006) <papid> N06-1019 </papid>who use partial training data (ccg lexical categories) for domain adaptation; however, they assume an existing ccg resource for the language in question to provide this data.</citsent>
<aftsection>
<nextsent>most state-of-the-art parsers for natural languages are data-driven and depend on the availability of sufficient amounts of labeled training data.
</nextsent>
<nextsent>however, manual creation of treebanks is time-consuming and labour-intensive.
</nextsent>
<nextsent>one way to avoid the expensive annotation process is to automatically label the training data using annotation projection (yarowsky et al., 2001): <papid> H01-1035 </papid>given suitable resource (such as aparser) in language l1, and word-aligned parallel corpus with languages l1 and l2, label the l1 portion of the parallel text (with the parser) and copy the annotations to the corresponding (i.e., aligned) elements in language l2.</nextsent>
<nextsent>this is illustrated in fig.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3328">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> projection of dependency trees.  </section>
<citcontext>
<prevsection>
<prevsent>we have implemented language-independent framework for dependency projection and use the europarl corpus (koehn, 2005) as the parallel text.europarl consists of the proceedings of the european parliament, professionally translated in 11 languages (approx.
</prevsent>
<prevsent>30mln words per language).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the data was aligned on the word level with giza++ (och and ney, 2003).<papid> J03-1002 </papid>1 in the experiments reported here, we use the language pair english-dutch, with english as the source for projection (l1) and dutchas l2.</citsent>
<aftsection>
<nextsent>the english portion of the europarl corpus was lemmatized and pos tagged with the tree tagger (schmid, 1994) and then parsed with malt parser (which is described in sec.
</nextsent>
<nextsent>6), trained on dependency-converted version of the wsj part from the penn treebank (marcus et al, 1994), <papid> H94-1020 </papid>but with the automatic pos tags.</nextsent>
<nextsent>the dutch sentences were only pos tagged (with treetagger).2 3.1 data loss through filtering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3329">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> projection of dependency trees.  </section>
<citcontext>
<prevsection>
<prevsent>the data was aligned on the word level with giza++ (och and ney, 2003).<papid> J03-1002 </papid>1 in the experiments reported here, we use the language pair english-dutch, with english as the source for projection (l1) and dutchas l2.</prevsent>
<prevsent>the english portion of the europarl corpus was lemmatized and pos tagged with the tree tagger (schmid, 1994) and then parsed with malt parser (which is described in sec.</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
6), trained on dependency-converted version of the wsj part from the penn treebank (marcus et al, 1994), <papid> H94-1020 </papid>but with the automatic pos tags.</citsent>
<aftsection>
<nextsent>the dutch sentences were only pos tagged (with treetagger).2 3.1 data loss through filtering.
</nextsent>
<nextsent>we quantitatively assess the impact of various filtering techniques on random sample of 100,000 english-dutch sentence pairs from europarl (avg.1following standard practice, we computed word alignments in both directions (l1 ? l2 and l2 ? l1); this gives rise to two unidirectional alignments.
</nextsent>
<nextsent>the bidirectional alignment is the intersection of the two unidirectional ones.
</nextsent>
<nextsent>2the dutch pos tags are used to train the monolingual parsers from the projected dependency trees (sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3330">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> projection of dependency trees.  </section>
<citcontext>
<prevsection>
<prevsent>starting with the left most word in the dutch sentence and its english translation (u and you), there is unidirectional alignment for the head of you: are is aligned to heeft, so is established as dependent of heeft via fallback.
</prevsent>
<prevsent>likewise, heeft can now be identified as the root node.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
note that the (incorrect) alignment between heeft and you will notbe pursued because it would lead to heeft being dependent of itself and thus violating the well formed 3i.e., single headedness and acyclicity; we do not require the trees to be projective, but instead train pseudo-projective models (nivre and nilsson, 2005) <papid> P05-1013 </papid>on the projected data (cf.</citsent>
<aftsection>
<nextsent>fn.
</nextsent>
<nextsent>5).
</nextsent>
<nextsent>14 #frags 1 2 3 415  15 #words  4 425 80 12 ? ?
</nextsent>
<nextsent>49 1,331 1,375 1,567 4,793 ? 1019 339 859 1,503 27,910 522 2030 17 45 143 20,756 10,087  30 0 5 5 4,813 23,362 table 2: fragmented parses projected with the alignment filter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3331">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> data-driven dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we use partial correspondence in combination with bidirectional projection.4 as can be seen in table 1 (bi+frags3?), this combination boosts the amount of usable data to range similar to that of the fallback technique for trees; but unlike the latter,partial correspondence continues to impose high precision filter (bidirectionality) while improving recall through relaxed structural requirements (partial correspondence).
</prevsent>
<prevsent>table 2 shows how fragment size varies with sentence length.
</prevsent>
</prevsection>
<citsent citstr=" D07-1013 ">
models for data-driven dependency parsing can be roughly divided into two paradigms: graph-based and transition-based models (mcdonald and nivre, 2007).<papid> D07-1013 </papid></citsent>
<aftsection>
<nextsent>5.1 graph-based models.
</nextsent>
<nextsent>in the graph-based approach, global optimization considers all possible arcs to find the tree t?
</nextsent>
<nextsent>s.t. t?
</nextsent>
<nextsent>= argmax td s(t ) = argmax td ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3336">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5), which were adjusted for noisy training data.
</prevsent>
<prevsent>thus improvements are likely with other settings: nivre et al (2006) <papid> W06-2933 </papid>report 81.35% for adutch malt parser with optimized parameter settings.</prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
mcdonald et al (2006) <papid> W06-2932 </papid>report 83.57% with mst.</citsent>
<aftsection>
<nextsent>words malt mst a. trees (bidirectional) 13,500 65.94 67.76 trees (fallback) 62,500 59.28 65.08 bi+frags3 68,000 55.09 57.14 bi+frags3 (fmalt/fmst) 68,000 69.15 70.02 b. trees (bidirectional) 100,000 61.86 69.91 trees (fallback) 100,000 60.05 64.84 bi+frags3 100,000 54.50 55.87 bi+frags3 (fmalt/fmst) 100,000 68.65 69.86 c. trees (bidirectional) 102,300 63.32 69.85 trees (fallback) 465,500 53.45 64.88 bi+frags3 523,000 51.48 57.20 bi+frags3 (fmalt/fmst) 523,000 69.52 70.33 table 4: uas of parsers trained on projected dependency structures for (a) sample of 100,000 sentences, subject to filtering, (b) 10 random samples, each with 100,000 words after filtering (average scores given), and (c) the entire europarl corpus, subject to filtering.
</nextsent>
<nextsent>7.2 results.
</nextsent>
<nextsent>table 4a summarizes the results of training parsers on the 100,000-sentence sample analyzed above.both the graph-based (mst) and the transition based (malt) parsers react similarly to the more orless aggressive filtering methods, but to different degrees.
</nextsent>
<nextsent>the first two rows of the table show the parsers trained on complete trees (trees (bidirectional)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3337">
<title id=" W09-1104.xml">data driven dependency parsing of new languages using incomplete and noisy training data </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>graph-based models do not benefit as much from additional partial structures, but instead are more robust to noisy training data, even when the training set is very small.in future work, we will explore how well the techniques presented here for english and dutch work for languages that are typo logically further apart, e.g., english-greek or english-finnish.
</prevsent>
<prevsent>moreover, we are going to investigate how our approach, which essentially ignores unknown parts of the annotation,compares to approaches that marginalize over hidden variables.
</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
we will also explore ways of combining graph-based and transition-based parsers along the lines of nivre and mcdonald (2008).<papid> P08-1108 </papid></citsent>
<aftsection>
<nextsent>acknowledgments the research reported in this paper has been supported by the german research foundation dfg as part of sfb 632 information structure?
</nextsent>
<nextsent>(project d4; pi: kuhn).
</nextsent>
<nextsent>19
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3338">
<title id=" W08-1808.xml">evaluation of automatically reformulated questions in question series </title>
<section> evaluation against the gold standard.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 choosing metric.
</prevsent>
<prevsent>there are many different systems which attempt to measure string similarity.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
we considered variety of tools like rouge (lin, 2004) <papid> W04-1013 </papid>and meteor (lavie and agarwal, 2007) <papid> W07-0734 </papid>but decided they were unsuitable for this task.</citsent>
<aftsection>
<nextsent>rouge and meteor were developed to compare larger stretches of text ? they are usually used to compare paragraphs rather than sentences.
</nextsent>
<nextsent>we decided developing our own metric would be simpler than trying to adapt one of these existing tools.
</nextsent>
<nextsent>to explore candidate similarity measures we created program which would take as input list of reformulations to be assessed and list of gold standard reformulations and compare them to each other using selection of different string comparison metrics.
</nextsent>
<nextsent>to find out which of these metrics best scored reformulations in the way which we expected, we created set of test reformulations to compare against the gold standard reformulations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3339">
<title id=" W08-1808.xml">evaluation of automatically reformulated questions in question series </title>
<section> evaluation against the gold standard.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 choosing metric.
</prevsent>
<prevsent>there are many different systems which attempt to measure string similarity.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
we considered variety of tools like rouge (lin, 2004) <papid> W04-1013 </papid>and meteor (lavie and agarwal, 2007) <papid> W07-0734 </papid>but decided they were unsuitable for this task.</citsent>
<aftsection>
<nextsent>rouge and meteor were developed to compare larger stretches of text ? they are usually used to compare paragraphs rather than sentences.
</nextsent>
<nextsent>we decided developing our own metric would be simpler than trying to adapt one of these existing tools.
</nextsent>
<nextsent>to explore candidate similarity measures we created program which would take as input list of reformulations to be assessed and list of gold standard reformulations and compare them to each other using selection of different string comparison metrics.
</nextsent>
<nextsent>to find out which of these metrics best scored reformulations in the way which we expected, we created set of test reformulations to compare against the gold standard reformulations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3340">
<title id=" W09-0215.xml">context theoretic semantics for natural language an overview </title>
<section> context-theoretic framework.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 distributional generality.
</prevsent>
<prevsent>the vector lattice nature of the space under consideration is important in the context-theoretic framework since it is used to define degree of entailment between strings.
</prevsent>
</prevsection>
<citsent citstr=" C04-1146 ">
our notion of entailment is 113 based on the concept of distributional generality(weeds et al , 2004), <papid> C04-1146 </papid>generalisation of the distributional hypothesis of harris (1985), in which itis assumed that terms with more general meaning will occur in wider array of contexts, an idea later developed by geffet and dagan (2005).</citsent>
<aftsection>
<nextsent>weeds et al  (2004) <papid> C04-1146 </papid>also found that frequency played large role in determining the direction of entailment, with the more general term often occurring more frequently.</nextsent>
<nextsent>the partial ordering of the vector lattice encapsulates these properties since x?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3342">
<title id=" W09-0215.xml">context theoretic semantics for natural language an overview </title>
<section> context theories for natural.  </section>
<citcontext>
<prevsection>
<prevsent>y?, i.e. completely entails if is sub sequence of y.many variations on this context theory are possible, for example using more complex mappings to l1(a?).
</prevsent>
<prevsent>the context theory can also be adapted to incorporate measure of lexical overlap between strings, an approach that, although simple, performs comparably to more complex techniques in tasks such as recognising textual entailment (dagan et al , 2005) 3.2 lexical entailment model.
</prevsent>
</prevsection>
<citsent citstr=" W05-1208 ">
glickman and dagan (2005) <papid> W05-1208 </papid>define their own model of entailment and apply it to the task of recognising textual entailment.</citsent>
<aftsection>
<nextsent>they estimate entailment between words based on occurrences in documents: they estimate lexical entailment probability lep(x, y) between two terms and to be lep(x, y) ? nx,ynywhere ny and nx,y denote the number of documents that the word occurs in and the words and both occur in respectively.
</nextsent>
<nextsent>we can describe this using context theory a,d, ?, ? ?, where is the set of documents, and x?(d) = { 1 if occurs in document 0 otherwise.
</nextsent>
<nextsent>in this case the estimate of lep(x, y) coincides with our own degree of entailment ent(x, y).there are many ways in which the multiplication ? can be defined on l1(d).
</nextsent>
<nextsent>the simplest one defines ed ? ef = ed if = and edef = 0 otherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3346">
<title id=" W09-0215.xml">context theoretic semantics for natural language an overview </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>incorporating this information is then straightforward: the representation of the sentence is the weighted sum of the representation of each possible meaning,where the weights are given by the probability distribution.
</prevsent>
<prevsent>computing the degree of entailment using this approach is computationally challenging, however we have shown that it is possible to estimate the degree of entailment by computing lower bound on this value by calculating pairwise degrees of entailment for each possible logical statement.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
mitchell and lapata (2008) <papid> P08-1028 </papid>proposed framework for composing meaning that is extremely general in nature: there is no requirement for linearity in the composition function, although in practice the authors do adopt this assumption.</citsent>
<aftsection>
<nextsent>indeed their multiplicative models?
</nextsent>
<nextsent>require composition of two vectors to be linear function of their ten sor product; this is equivalent to our requirement of distributivity with respect to vector space addi tion.various ways of composing vector based representations of meaning were investigated by widdows (2008), including the tensor product and direct sum.
</nextsent>
<nextsent>both of these are compatible with the context theoretic framework since they are distributive with respect to the vector space addition.clark et al  (2008) proposed method of composing meaning that generali ses montague seman tics; further work is required to determine how their method of composition relates to the context theoretic framework.erk and pado (2008) describe method of composition that allows the incorporation of selectional preferences; again further work is required to determine the relation between this work and the context-theoretic framework.
</nextsent>
<nextsent>118
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3347">
<title id=" W09-1319.xml">exploring two biomedical text genres for disease recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>despite significant body of literature in biomedical named entity recognition, most work has been focused on gene, protein, drug and chemical names through challenges such as biocreative1 or the trec genomics/chemical tracks (park and kim, 2006).
</prevsent>
<prevsent>other work addressed the identification of medical problems?
</prevsent>
</prevsection>
<citsent citstr=" W07-1014 ">
in clinical text (aronson et al  2007; <papid> W07-1014 </papid>meystre and haug, 2005).</citsent>
<aftsection>
<nextsent>this task was the topic of medical nlp challenge2, which released corpus of anonymized radiography reports annotated with icd9 codes.
</nextsent>
<nextsent>although there is some interest in the biomedical community in the identification of disease names and more specifically the identification of relationships between diseases and genes or proteins (rindflesh and fizman, 2003), there are very few resources available to train or evaluate automatic disease recognition systems.
</nextsent>
<nextsent>to the best of our knowledge, the only publicly available corpus for disease identification in the literature was developed by jimeno et al  (2008).
</nextsent>
<nextsent>the authors annotated 551 medline sentences with umls concepts and used this dataset to benchmark three different automatic methods for disease name recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3348">
<title id=" W09-1319.xml">exploring two biomedical text genres for disease recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>to assess the difficulty of disease recognition, we computed the inter-annotator agreement (iaa) on the 300-query corpus.
</prevsent>
<prevsent>agreement was computed at the disease mention level for all three annotators and at the disease concept level for the two annotators who produced umls annotations.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
inter-annotator agreement measures for nlp applications have been recently discussed by artstein and poesio (2008) <papid> J08-4004 </papid>who advocate for the use of chance corrected measures.</citsent>
<aftsection>
<nextsent>however, in our case, agreement was partly computed on very large set of categories (umls concepts) so we decided to use knowtators built-in feature, which computes iaa as the percentage of agreement and 148 allows partial string matches.
</nextsent>
<nextsent>for example, in the query dog model transient ischemic attacks?, annotator 1 selected ischemic attacks?
</nextsent>
<nextsent>as disorder while annotator 2 and 3 selected transient ischemic attacks?
</nextsent>
<nextsent>as umls concept c0007787: attacks, transient ischemic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3349">
<title id=" W09-0907.xml">language diversity across the consonant inventories a study in the framework of complex networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the use of network based model is motivated from the fact that in the recent years, complex networks have proved to be an extremely suitable framework for modeling and studying the structure and dynamics of linguistic systems (cancho and sole?, 2001; dorogovtsev and mendes, 2001; cancho and sole?, 2004; sole?
</prevsent>
<prevsent>et al, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P06-2017 ">
along the lines of the study presentedin (choudhury et al, 2006), <papid> P06-2017 </papid>we model the structure of the inventories through bipartite network,which has two different sets of nodes, one labeled by the languages and the other by the con sonants.</citsent>
<aftsection>
<nextsent>edges run in between these two sets depending on whether particular consonant is found in particular language.
</nextsent>
<nextsent>this network is termed the phonemelanguage network or planet in (choudhury et al, 2006).<papid> P06-2017 </papid></nextsent>
<nextsent>we construct five such networks that respectively represent the consonant inventories belonging to the five ma 51 jor language families namely, the indo-european (ie-planet), the afro-asiatic (aa-planet), theniger-congo (nc-planet), the austronesian (an planet) and the sino-tibetan (st-planet).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3355">
<title id=" W08-2229.xml">representing and visualizing calendar expressions in texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>those tasks have been particularly explored in three contexts: 1.
</prevsent>
<prevsent>systems which aim to set events on time scale depending on their duration.
</prevsent>
</prevsection>
<citsent citstr=" W01-1309 ">
and according to hierarchy of unities called granularities (schilder and habel, 2001); <papid> W01-1309 </papid>2.</citsent>
<aftsection>
<nextsent>systems for summarizing multi-documents (barzilay et al, 2001); <papid> H01-1065 </papid>and.</nextsent>
<nextsent>3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3356">
<title id=" W08-2229.xml">representing and visualizing calendar expressions in texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>systems which aim to set events on time scale depending on their duration.
</prevsent>
<prevsent>and according to hierarchy of unities called granularities (schilder and habel, 2001); <papid> W01-1309 </papid>2.</prevsent>
</prevsection>
<citsent citstr=" H01-1065 ">
systems for summarizing multi-documents (barzilay et al, 2001); <papid> H01-1065 </papid>and.</citsent>
<aftsection>
<nextsent>3.
</nextsent>
<nextsent>qa systems (pustejovsky et al, 1993; harabagiu and bejan, 2005)..
</nextsent>
<nextsent>please note that the proposition of the well-known standard temporalmeta-language named timeml (pustejovsky et al, 2003) initially took place in the context of qasystems worshop (pustejovsky, 2002), and mainly integrates two schemes of annotations ? namely tides timex2 (ferro et al, 2004) and sheffield stag (setzer and gaizauskas, 2000) ? which were essentially put forward from the analysis of ces.in this paper, we propose formal description of ces in written french texts, by explicitly distinguishing several classes of linguistic markers which must be interpreted as successive operators.
</nextsent>
<nextsent>this work is driven in order to propose set of fine and well-defined annotations which will be used to navigate temporally in an annotated document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3357">
<title id=" W08-2229.xml">representing and visualizing calendar expressions in texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>please note that the proposition of the well-known standard temporalmeta-language named timeml (pustejovsky et al, 2003) initially took place in the context of qasystems worshop (pustejovsky, 2002), and mainly integrates two schemes of annotations ? namely tides timex2 (ferro et al, 2004) and sheffield stag (setzer and gaizauskas, 2000) ? which were essentially put forward from the analysis of ces.in this paper, we propose formal description of ces in written french texts, by explicitly distinguishing several classes of linguistic markers which must be interpreted as successive operators.
</prevsent>
<prevsent>this work is driven in order to propose set of fine and well-defined annotations which will be used to navigate temporally in an annotated document.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
our approach differs from the preceding ones in two crucial ways: ? our goal is not to link ce to an event, neither to fix it on temporal line , using set of values relying on iso 8601 standard format (mani and wilson, 2000; <papid> P00-1010 </papid>setzer and gaizauskas, 2000; filatova and hovy, 2001); <papid> W01-1313 </papid>instead our goal is to link ces between themselves, that is to say to establish their qualitative relative positions (the set of those relations is named proper text calendar?); ? we design ce semantics as algebraic expressions.</citsent>
<aftsection>
<nextsent>1this research is funded with an anr grant (projet blanc conique).
</nextsent>
<nextsent>representing and visualizing calendar expressions in texts 367the remainder of this paper is organized as follows.
</nextsent>
<nextsent>in the next section, we introduce an algebra of ces.
</nextsent>
<nextsent>in section 3 we describe software application, which exploits functional representation, built with previous way exhibited operators and plugged in the navitexte platform, aiming to support text reading.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3358">
<title id=" W08-2229.xml">representing and visualizing calendar expressions in texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>please note that the proposition of the well-known standard temporalmeta-language named timeml (pustejovsky et al, 2003) initially took place in the context of qasystems worshop (pustejovsky, 2002), and mainly integrates two schemes of annotations ? namely tides timex2 (ferro et al, 2004) and sheffield stag (setzer and gaizauskas, 2000) ? which were essentially put forward from the analysis of ces.in this paper, we propose formal description of ces in written french texts, by explicitly distinguishing several classes of linguistic markers which must be interpreted as successive operators.
</prevsent>
<prevsent>this work is driven in order to propose set of fine and well-defined annotations which will be used to navigate temporally in an annotated document.
</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
our approach differs from the preceding ones in two crucial ways: ? our goal is not to link ce to an event, neither to fix it on temporal line , using set of values relying on iso 8601 standard format (mani and wilson, 2000; <papid> P00-1010 </papid>setzer and gaizauskas, 2000; filatova and hovy, 2001); <papid> W01-1313 </papid>instead our goal is to link ces between themselves, that is to say to establish their qualitative relative positions (the set of those relations is named proper text calendar?); ? we design ce semantics as algebraic expressions.</citsent>
<aftsection>
<nextsent>1this research is funded with an anr grant (projet blanc conique).
</nextsent>
<nextsent>representing and visualizing calendar expressions in texts 367the remainder of this paper is organized as follows.
</nextsent>
<nextsent>in the next section, we introduce an algebra of ces.
</nextsent>
<nextsent>in section 3 we describe software application, which exploits functional representation, built with previous way exhibited operators and plugged in the navitexte platform, aiming to support text reading.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3359">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> lexicon of phrase rephrasings.  </section>
<citcontext>
<prevsection>
<prevsent>dictionaries and semantic resources such as the sauri can be used to find words by following linksof different kinds from given entry point.
</prevsent>
<prevsent>wordnet (fellbaum, 1998) is one such resource.
</prevsent>
</prevsection>
<citsent citstr=" W04-2105 ">
for proposal of other kinds of links and navigational aids see also (zock and bilac, 2004; <papid> W04-2105 </papid>zock, 2006; zock, 2007).words are the traditional units that people expect to find in dictionaries.</citsent>
<aftsection>
<nextsent>whereas some types of dictionaries can contain multiword expressions,such as compound nouns and terms, those correspond to linguistically-motivated units.
</nextsent>
<nextsent>in order to rephrase phrases of any type with dictionary, writer may have to look up several words, combine various information and validate the result using her experience of the language or thr ought the use of concordancer.
</nextsent>
<nextsent>moreover, dictionary lookups are in most cases insensitive to the actual context of words in an existing text.
</nextsent>
<nextsent>it is therefore there sponsibility of its users to ensure that choice is appropriate forgiven context, which can be quite difficult, for example when writing in second language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3360">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> lexicon of phrase rephrasings.  </section>
<citcontext>
<prevsection>
<prevsent>it is therefore there sponsibility of its users to ensure that choice is appropriate forgiven context, which can be quite difficult, for example when writing in second language.
</prevsent>
<prevsent>one way of obtaining phrase rephrasings is by looking at phrases that occur in similar contexts in monolingual corpus (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P06-1011 ">
(munteanu and marcu, 2006)).<papid> P06-1011 </papid></citsent>
<aftsection>
<nextsent>in order to extract comprehensive phrase lexicon, very large number of sentences should be compared to extract potential rephrasings, which furthermore may often correspond to phrases that are too remotely connected.
</nextsent>
<nextsent>parallel corpora provide the interesting advantage that it is reasonable to assume that elements from one side of the corpus should be aligned to elements on the other side, and that associations of elements can be reinforced by the number of times they occur in the corpus.
</nextsent>
<nextsent>various approaches for word alignment from parallel corpora have been proposed (see e.g.(och and ney, 2003)), <papid> J03-1002 </papid>and the phrase-based approach to statistical machine translation (koehnet al, 2003) <papid> N03-1017 </papid>has led to the development of heuristics for obtaining alignments between phrases of any number of words.</nextsent>
<nextsent>unfortunately, monolingual parallel corpora aligned at the sentence level, such as various translations of novel in foreign language, are resources that are extremely scarce.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3361">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> lexicon of phrase rephrasings.  </section>
<citcontext>
<prevsection>
<prevsent>in order to extract comprehensive phrase lexicon, very large number of sentences should be compared to extract potential rephrasings, which furthermore may often correspond to phrases that are too remotely connected.
</prevsent>
<prevsent>parallel corpora provide the interesting advantage that it is reasonable to assume that elements from one side of the corpus should be aligned to elements on the other side, and that associations of elements can be reinforced by the number of times they occur in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
various approaches for word alignment from parallel corpora have been proposed (see e.g.(och and ney, 2003)), <papid> J03-1002 </papid>and the phrase-based approach to statistical machine translation (koehnet al, 2003) <papid> N03-1017 </papid>has led to the development of heuristics for obtaining alignments between phrases of any number of words.</citsent>
<aftsection>
<nextsent>unfortunately, monolingual parallel corpora aligned at the sentence level, such as various translations of novel in foreign language, are resources that are extremely scarce.
</nextsent>
<nextsent>using bilingual parallel corpora, much more common resource, one can obtain various possible phrase translations forgiven source phrase, as well as some estimate of the distribution of probabilities for the various translations of that phrase.
</nextsent>
<nextsent>such ? alignements can capture lexical translations (e.g. exi geons ? ask for, call for, demand, expect, request, etc.) and phrasal literal or idiomatic translations (e.g. un bon debut ? good approach, good first move, good starting point, positive initiative, an encouraging start, the right road, etc.), but can also capture noise depending on the alignment heuristics used (e.g. les etats candid ats (candi date countries) ? member states, the candidate countries were to, the accession countries have called for, candidate, the, etc.) different target phrases associated with given source phrase can either represent paraphrases or phrases with different meanings.
</nextsent>
<nextsent>among the limitations of this type of phrasal alignments are their inability to modelnon-consecutive words and to generalize the con 78 tents of phrases, and the fact that their translations are not conditioned on their context.if phrase extraction is performed in two opposite directions, then it is possible to find the possible translations of given phrase (and their conditional probabilities), and then to translate back those phrases into the original language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3362">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> lexicon of phrase rephrasings.  </section>
<citcontext>
<prevsection>
<prevsent>in order to extract comprehensive phrase lexicon, very large number of sentences should be compared to extract potential rephrasings, which furthermore may often correspond to phrases that are too remotely connected.
</prevsent>
<prevsent>parallel corpora provide the interesting advantage that it is reasonable to assume that elements from one side of the corpus should be aligned to elements on the other side, and that associations of elements can be reinforced by the number of times they occur in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
various approaches for word alignment from parallel corpora have been proposed (see e.g.(och and ney, 2003)), <papid> J03-1002 </papid>and the phrase-based approach to statistical machine translation (koehnet al, 2003) <papid> N03-1017 </papid>has led to the development of heuristics for obtaining alignments between phrases of any number of words.</citsent>
<aftsection>
<nextsent>unfortunately, monolingual parallel corpora aligned at the sentence level, such as various translations of novel in foreign language, are resources that are extremely scarce.
</nextsent>
<nextsent>using bilingual parallel corpora, much more common resource, one can obtain various possible phrase translations forgiven source phrase, as well as some estimate of the distribution of probabilities for the various translations of that phrase.
</nextsent>
<nextsent>such ? alignements can capture lexical translations (e.g. exi geons ? ask for, call for, demand, expect, request, etc.) and phrasal literal or idiomatic translations (e.g. un bon debut ? good approach, good first move, good starting point, positive initiative, an encouraging start, the right road, etc.), but can also capture noise depending on the alignment heuristics used (e.g. les etats candid ats (candi date countries) ? member states, the candidate countries were to, the accession countries have called for, candidate, the, etc.) different target phrases associated with given source phrase can either represent paraphrases or phrases with different meanings.
</nextsent>
<nextsent>among the limitations of this type of phrasal alignments are their inability to modelnon-consecutive words and to generalize the con 78 tents of phrases, and the fact that their translations are not conditioned on their context.if phrase extraction is performed in two opposite directions, then it is possible to find the possible translations of given phrase (and their conditional probabilities), and then to translate back those phrases into the original language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3363">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> evaluation of rephrasings in context.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed ranking should reflect as best as possible the preferences of the user for the task at hand in order to minimize reading time and maintain the users interest in using the phrase lexicon.
</prevsent>
<prevsent>it is essential to give the user some control over how the results are returned depending on what is more important to her.
</prevsent>
</prevsection>
<citsent citstr=" P06-1036 ">
for example, (ferret and zock, 2006) <papid> P06-1036 </papid>have proposed to present results from dictionary enriched with topical associations in chunks to allow for categorial search.</citsent>
<aftsection>
<nextsent>there will be cases where the user may find acceptable only grammatical results, while inother cases the user might accept agrammatical results provided they contain interesting suggestions.
</nextsent>
<nextsent>moreover, it seems extremely important that result ranking can take into account the phrase substitution into the original context.
</nextsent>
<nextsent>considering how the proposed phrase lexicon isbuilt, the pivot paraphrasing probability of equation 1 (piv) can be used as baseline ordering.
</nextsent>
<nextsent>such model reflects some strength of association between rephrased phrase and the original phrase using the extracted phrases and conditional probabilities derived from bilingual training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3364">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> evaluation of rephrasings in context.  </section>
<citcontext>
<prevsection>
<prevsent>mm ? = 1), and is the original sentence and the place holder for the rephrased phrase.
</prevsent>
<prevsent>s(p 2 , 1 , c) = ? mm ? h (p 1 , 2 , c) (2) 3.1 control over fluency.
</prevsent>
</prevsection>
<citsent citstr=" P07-1044 ">
as noted by (mutton et al, 2007), <papid> P07-1044 </papid>the notion of sentence-level fluency is not uniform ely agreed upon, and its evaluation by human judges is sometimes found subjective, but in practice judges can obtain high levels of agreement about what can be considered fluent or not.</citsent>
<aftsection>
<nextsent>like (callison-burch,2007), we can use language model (lm) to assess the local fluency of sentence after phrase has been substituted with rephrasing.
</nextsent>
<nextsent>a degradation in score (with fluent original sentence) can indicate that the rephrasing segment should be adapted to the sentence, and/or that the sentence itself should be modified in order to integrate the new phrase as is. syntax parsers can produce various information that can be relevant for assessing the fluency of sentences, which can be used as features from different parsers for classification that can correlate well with human judgment (mutton et al, 2007).<papid> P07-1044 </papid>when substituting part of sentence with another phrase and if this substitution does notre quire other changes in the sentence, then at least the dependency relationships between words out side that phrase should be preserved.</nextsent>
<nextsent>this seems coherent with our objective of focussing on the task of phrase rephrasing when it is possible to modify only given phrase and obtain an accept able result.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3371">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the actual meaning of words depends on the context in which they are used.
</prevsent>
<prevsent>the work done by the team of gross on lexicon-grammar (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P84-1058 ">
(gross, 1984)) <papid> P84-1058 </papid>showed that relatively small set of clause patterns and syntactic constraints suffices to cover most of common french.</citsent>
<aftsection>
<nextsent>comparable monolingual corpora have been used for automatic paraphrasing.
</nextsent>
<nextsent>barzilay andlee (barzilay and lee, 2003) <papid> N03-1003 </papid>learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases.</nextsent>
<nextsent>their corpus contained newsagency articles on thesame events, which allows precise sentence paraphrasing, but on small sets of phenomena andfor limited domain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3372">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(gross, 1984)) <papid> P84-1058 </papid>showed that relatively small set of clause patterns and syntactic constraints suffices to cover most of common french.</prevsent>
<prevsent>comparable monolingual corpora have been used for automatic paraphrasing.</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
barzilay andlee (barzilay and lee, 2003) <papid> N03-1003 </papid>learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases.</citsent>
<aftsection>
<nextsent>their corpus contained newsagency articles on thesame events, which allows precise sentence paraphrasing, but on small sets of phenomena andfor limited domain.
</nextsent>
<nextsent>as sentential paraphrasing is more likely to alter meaning, quirk et al (quirk et al, 2004) <papid> W04-3219 </papid>approached paraphrasing as monotonous decoding by phrase-based smt system.</nextsent>
<nextsent>their corpus consisted of monolingual sentences extracted from comparable corpus that were automatically aligned so as to allow aligned phrase extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3373">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>barzilay andlee (barzilay and lee, 2003) <papid> N03-1003 </papid>learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases.</prevsent>
<prevsent>their corpus contained newsagency articles on thesame events, which allows precise sentence paraphrasing, but on small sets of phenomena andfor limited domain.</prevsent>
</prevsection>
<citsent citstr=" W04-3219 ">
as sentential paraphrasing is more likely to alter meaning, quirk et al (quirk et al, 2004) <papid> W04-3219 </papid>approached paraphrasing as monotonous decoding by phrase-based smt system.</citsent>
<aftsection>
<nextsent>their corpus consisted of monolingual sentences extracted from comparable corpus that were automatically aligned so as to allow aligned phrase extraction.
</nextsent>
<nextsent>pang et al (pang et al, 2003) <papid> N03-1024 </papid>used parallel monolingual corpora built from news stories that had been independantly translated several times to learn lattices from syntax-based alignment process.</nextsent>
<nextsent>bannard and callison-burch (bannard andcallison-burch, 2005) proposed to use pivot translation for paraphrasing phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3374">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as sentential paraphrasing is more likely to alter meaning, quirk et al (quirk et al, 2004) <papid> W04-3219 </papid>approached paraphrasing as monotonous decoding by phrase-based smt system.</prevsent>
<prevsent>their corpus consisted of monolingual sentences extracted from comparable corpus that were automatically aligned so as to allow aligned phrase extraction.</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
pang et al (pang et al, 2003) <papid> N03-1024 </papid>used parallel monolingual corpora built from news stories that had been independantly translated several times to learn lattices from syntax-based alignment process.</citsent>
<aftsection>
<nextsent>bannard and callison-burch (bannard andcallison-burch, 2005) proposed to use pivot translation for paraphrasing phrases.
</nextsent>
<nextsent>fujita (fujita, 2005) proposed transfer-and-revision framework using linguistic knowledge for generating paraphrases in japanese and model for error detection.
</nextsent>
<nextsent>at the lexical level, recent evaluation on english lexical substitution was held (mccarthy and navigli, 2007) <papid> W07-2009 </papid>in which systems had to find lexical synonyms and disambiguate the context.</nextsent>
<nextsent>in this article, we have presented an approach for obtaining rephrasings for short text spans from parallel bilingual corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3375">
<title id=" W08-1911.xml">looking up phrase rephrasings via a pivot language </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>bannard and callison-burch (bannard andcallison-burch, 2005) proposed to use pivot translation for paraphrasing phrases.
</prevsent>
<prevsent>fujita (fujita, 2005) proposed transfer-and-revision framework using linguistic knowledge for generating paraphrases in japanese and model for error detection.
</prevsent>
</prevsection>
<citsent citstr=" W07-2009 ">
at the lexical level, recent evaluation on english lexical substitution was held (mccarthy and navigli, 2007) <papid> W07-2009 </papid>in which systems had to find lexical synonyms and disambiguate the context.</citsent>
<aftsection>
<nextsent>in this article, we have presented an approach for obtaining rephrasings for short text spans from parallel bilingual corpora.
</nextsent>
<nextsent>these rephrasings can be ranked according to user-defined preferences, and the weights of the models used can be dynamically adjusted by user depending on what features are more important to her, for instance after an initial list of candidates has been proposed by the system.
</nextsent>
<nextsent>indeed, good candidates include paraphrases, but also more generally phrases that could help writer revise text with some shifts in meaning, even if at the cost of some corrections to make the resulting text grammatical.
</nextsent>
<nextsent>furthermore, search for rephrasings can be iteratively performed using candidate rephrasings as source phrases, and theuser can have some fine-grained control if selecting or rejecting possible pivot phrases manually.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3376">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
<prevsent>some rights reserved.german-english translation.
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
goldwater and mcclosky (2005) <papid> H05-1085 </papid>improved czech-english translation by applying different heuristics to increase the equivalence of czech and english text.</citsent>
<aftsection>
<nextsent>specially for arabic-english translation, lee (2004) <papid> N04-4015 </papid>used the arabic part of speech and english parts of speech (pos) alignment probabilities to retain an arabic affix, drop it from the corpus or merge it back to stem.</nextsent>
<nextsent>the resulting system outperformed the original arabic system trained on 3.3 million sentence pairs corpora when using monotone decoding.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3377">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some rights reserved.german-english translation.
</prevsent>
<prevsent>goldwater and mcclosky (2005) <papid> H05-1085 </papid>improved czech-english translation by applying different heuristics to increase the equivalence of czech and english text.</prevsent>
</prevsection>
<citsent citstr=" N04-4015 ">
specially for arabic-english translation, lee (2004) <papid> N04-4015 </papid>used the arabic part of speech and english parts of speech (pos) alignment probabilities to retain an arabic affix, drop it from the corpus or merge it back to stem.</citsent>
<aftsection>
<nextsent>the resulting system outperformed the original arabic system trained on 3.3 million sentence pairs corpora when using monotone decoding.
</nextsent>
<nextsent>however, an improvement in monotone decoding is no guarantee for an improvement over the best baseline achievable with full word forms.
</nextsent>
<nextsent>our experiments showed that ansmt phrase-based translation using 4 words distance reordering could gain four bleu points over monotone decoding.
</nextsent>
<nextsent>sadat and habash (2006) explored wide range of arabic word-level preprocessing and produced better translation results for system trained on 5 million arabic words.what all the above methodologies do not provide is means to disambiguate morphological analysis for machine translation based on thewords?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3378">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of the english translation.
</prevsent>
<prevsent>thus an appropriate preprocessing technique should be guided by english translation and bring the word context into account.in this paper we describe context-based morphological analysis for arabic-english translation that take full account morphemes alignment to english text.
</prevsent>
</prevsection>
<citsent citstr=" H05-1060 ">
the preprocessing uses the arabic morphology disambiguation in (smith et al, 2005) <papid> H05-1060 </papid>forfull morphological analysis and learns the removing morphemes model based on the viterbi alignment of english to full morphological analysis.</citsent>
<aftsection>
<nextsent>we tested the model with two training corpora of 5.2 millions arabic words(177k sentences) in news domain and 159k arabic words (20k sentences)in travel conversation domain and gain improvement over the original arabic translation in bothexperiments.
</nextsent>
<nextsent>the system that trained on sub sample corpora of 5 millions sentence pairs corpora also showed one bleu score improvement over the original arabic system on unseen test set.
</nextsent>
<nextsent>we will explain our technique in the next section and briefly review the phrase based smt model in section 3.
</nextsent>
<nextsent>the experiment results will be presented in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3383">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>we removed case marker morphemes and got the full morphology corpus.
</prevsent>
<prevsent>2.2 annotate morphemes.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
to extract the arabic morphemes that align to english text, we use english as the source corpus and aligned to arabic morpheme corpus using giza++ (och and ney, 2003) <papid> J03-1002 </papid>toolkit.</citsent>
<aftsection>
<nextsent>theibm3 and ibm4 (brown et al, 1994) word alignment models select each word in the source sentence, generate fertility and list of target words that connect to it.
</nextsent>
<nextsent>this generative process would constrain source words to find alignments in the target sentence.
</nextsent>
<nextsent>using english as source corpus,the alignment models force english words to generate their alignments in the arabic morphemes.giza++ outputs viterbi alignment for every sentence pair in the training corpus as depicted in (b) and (c) of figure (1).
</nextsent>
<nextsent>in our experiment, only 5% of english words are not aligned to any arabic morpheme in the viterbi alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3384">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>or retained?
</prevsent>
<prevsent>belongs to the set of sequence labelling problems.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
the conditional random fields (crf) (lafferty et al, 2001) model has shown great benefits in similar applications of natural language processing such as part-of-speech tagging, noun phrase chunking (sha and pereira, 2003), <papid> N03-1028 </papid>morphology disambiguation(smith et al, 2005).<papid> H05-1060 </papid></citsent>
<aftsection>
<nextsent>we apply the crf model to our morpheme tagging problem.
</nextsent>
<nextsent>137let = {(a,t)} be the full morphology training corpus wherea = 1 |p 1 2 |p 2 . . .
</nextsent>
<nextsent>a |p is morphology arabic sentence, i is morpheme in the sentence and i is its pos;t = 1 2 . . .
</nextsent>
<nextsent>t is the tag sequence of a, each i is either delete dor retained?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3386">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> phrase-based smt system.  </section>
<citcontext>
<prevsection>
<prevsent>alignment combination heuristic.
</prevsent>
<prevsent>the phrase table consisted of phrase pairs up toseven words long.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
the system used tri-gram language model built from sri (stolcke, 2002) toolkit with modified kneser-ney interpolation smoothing technique (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>by default, the moses decoder uses 6 tokens distance reordering windows.
</nextsent>
<nextsent>in this section we present experiment results using our arabic morphology preprocessing technique.
</nextsent>
<nextsent>4.1 datasets.
</nextsent>
<nextsent>we tested our morphology technique on small dataset of 20k sentence pairs and medium size dataset of 177k sentence pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3387">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> experiment results.  </section>
<citcontext>
<prevsection>
<prevsent>both of them had 16 reference translations per source sentence.
</prevsent>
<prevsent>the english side of the training corpus was used to build the language model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
to optimize the parameters of the decoder, we performed minimum error rate training on iwslt04 optimizing for the ibm-bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>4.1.2 newswire corpora we also tested the impact of our morphology technique on parallel corpus in the news domain.the corpora were collected from ldcs full arabic news translation corpora and small portion of un data.
</nextsent>
<nextsent>the details of the data are give in table 3.
</nextsent>
<nextsent>the data consists of 177k sentence pairs, 5.2m words on the arabic and 6m words on the english side.
</nextsent>
<nextsent>arabic engori full reduced sentences 177035 tokens 5.2m 9.3m 6.2m 6.2m types 155k 47k 47k 68k table 3: newswire corpus statistic swe used two test sets from past nist evaluations as test data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3388">
<title id=" W08-2118.xml">context based arabic morphological analysis for machine translation </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the model significantly outperformed the original arabic systems on small and mid-size corpora and unseen test set on large training corpora.
</prevsent>
<prevsent>the model treats morphology processing task as sequence labelling problem.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
therefore, other machine learning techniques such as perceptron (collins, 2002) <papid> W02-1001 </papid>could also be applied for this problem.</citsent>
<aftsection>
<nextsent>the paper also discussed the relation between the size of the reordering window and morphology processing.
</nextsent>
<nextsent>in future investigations, we plan to extend the model such that merging morphemes is included.
</nextsent>
<nextsent>we also intent to study the impact of phrase length and phrase extraction heuristics.
</nextsent>
<nextsent>acknowledgement we thank noah smith for useful comments and suggestions and providing us with the morphology disambiguation toolkit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3389">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>it certainly istrue that grammar-based analyses typically represent predicate-argument structure and perhaps also quantifier scope.
</prevsent>
<prevsent>but one can recover predicate argument structure using statistical methods (seethe work on semantic role labeling and propbank?
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
parsing (palmer et al, 2005)), <papid> J05-1004 </papid>and presumably similar methods could be used to resolve quantifier scope as well.i suspect the main reason why statistical parsing has concentrated on more superficial syntactic structure (such as phrase structure) is because there arent many actual applications for the syntactic analyses our parsers return.</citsent>
<aftsection>
<nextsent>given the current state-of-the-art in knowledge representation and artificial intelligence, even if we could produce completely accurate logical forms in some higher-order logic, its not clear whether we could do anything useful with them.
</nextsent>
<nextsent>its hard to find real applications that benefit from even syntactic information, and the information any such applications actually use is often fairly superficial.
</nextsent>
<nextsent>for example, some research systems for named entity detection and extraction use parsing to identify noun phrases (which are potentially name entities) as well as the verbs that govern them, but they ignore the rest of the syntactic structure.
</nextsent>
<nextsent>in fact, many applications of statistical parsers simply use them as language models, i.e., one parses to obtain the probability that the parser assigns to the string and throws away the parses it computes in the process (jelinek, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3390">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in the grammar-based approaches all linguistic knowledge is contained in the grammar, which the computational linguist implementing the parsing framework doesnt actually have to understand.all she has to do is correctly implement an inference engine for grammars written in the relevant grammar formalism.
</prevsent>
<prevsent>by contrast, statistical parsers define the probability of parse in terms of its (statistical) features or properties, and parser designer needs to choose which features their parser will use, and many of these features reflect at least an intuitive understanding of linguistic dependencies.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
for example, statistical parsers from magerman (1995) <papid> P95-1037 </papid>on use features based onhead-dependent relationships.</citsent>
<aftsection>
<nextsent>(the parsers developed by the berkeley group are notable exception (petrov and klein, 2007)).<papid> N07-1051 </papid></nextsent>
<nextsent>while its true that only small fraction of our knowledge about linguistic structure winds up expressed by features in modern statistical parsers, as discussed above theres no reason to expect all of our scientific knowledge to be relevant to any engineering problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3391">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>by contrast, statistical parsers define the probability of parse in terms of its (statistical) features or properties, and parser designer needs to choose which features their parser will use, and many of these features reflect at least an intuitive understanding of linguistic dependencies.
</prevsent>
<prevsent>for example, statistical parsers from magerman (1995) <papid> P95-1037 </papid>on use features based onhead-dependent relationships.</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
(the parsers developed by the berkeley group are notable exception (petrov and klein, 2007)).<papid> N07-1051 </papid></citsent>
<aftsection>
<nextsent>while its true that only small fraction of our knowledge about linguistic structure winds up expressed by features in modern statistical parsers, as discussed above theres no reason to expect all of our scientific knowledge to be relevant to any engineering problem.
</nextsent>
<nextsent>and while many of the features usedin statistical parsers dont correspond to linguistic constraints, nobody seriously claims that humans understand language only using linguistic constraints of the kind expressed informal grammars.
</nextsent>
<nextsent>i suspect that many of the features that have been shown to be useful in statistical parsing encode psycho linguistic marked ness preferences (e.g., attachment preferences) and at least some aspects of world knowledge (e.g., that the direct object of eat?
</nextsent>
<nextsent>is likely to be food).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3392">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>is likely to be food).
</prevsent>
<prevsent>moreover, its not necessary for statistical model to exactly replicate linguistic constraint inorder for it to effectively capture the corresponding generalization: all thats necessary is that the statistical features cover?
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
the relevant examples.for example, adding subject-verb agreement feature to the charniak-johnson parser (charniak and johnson, 2005) <papid> P05-1022 </papid>has no measurable effect on parsing accuracy.</citsent>
<aftsection>
<nextsent>after doing this experiment realized this shouldnt be surprising: the charniak parser already conditions each arguments part-of speech (pos) on its governors pos, and since pos tags distinguish singular and plural nouns and verbs, these general head-argument pos features capture most cases of subject-verb agreement.
</nextsent>
<nextsent>note that im not claiming that subject-verb agreement isnt real linguistic constraint or thatit doesnt play an important role in human parsing.
</nextsent>
<nextsent>i think that the type of input (e.g., treebanks) and the kinds of abilities (e.g., to exactly count the occurences of many different constructions) available to our machines may be so different to what is available to child that the features that work best in our parsers need not bear much relationship to those used by humans.
</nextsent>
<nextsent>still, view the design of the features used in statistical parsers as fundamentally linguistic issue (albeit one with computational consequences,since the search problem in parsing is largely determined by the features involved), and expect there is still more to learn about which combinations of features are most useful for statistical parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3393">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>i think that the type of input (e.g., treebanks) and the kinds of abilities (e.g., to exactly count the occurences of many different constructions) available to our machines may be so different to what is available to child that the features that work best in our parsers need not bear much relationship to those used by humans.
</prevsent>
<prevsent>still, view the design of the features used in statistical parsers as fundamentally linguistic issue (albeit one with computational consequences,since the search problem in parsing is largely determined by the features involved), and expect there is still more to learn about which combinations of features are most useful for statistical parsing.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
my guess is that the features used in e.g., the collins (2003) <papid> J03-4003 </papid>or charniak (2000) <papid> A00-2018 </papid>parsers are probably close to optimal for english penn treebank parsing (marcus et al, 1993), <papid> J93-2004 </papid>but that other features might improve parsing of other languages or even other english genres.</citsent>
<aftsection>
<nextsent>unfortunately changing the features used in these parsers typically involves significant reprogramming, which makes it difficult for linguists to experiment with new features.
</nextsent>
<nextsent>however, it mightbe possible to develop kind of statistical parsing framework that makes it possible to define new features and integrate them into statistical parser without any programming which would make it easy to explore novel combinations of statistical features; see goodman (1998) for an interesting suggestion along these lines.from high-level perspective, the grammar based approaches and the statistical approaches both view parsing fundamentally in the same way, namely as specialized kind of inference problem.
</nextsent>
<nextsent>these days view parsing as deduction?
</nextsent>
<nextsent>(one of the slogans touted by the grammar-based crowd)as unnecessarily restrictive; after all, psych olin guistic research shows that humans are exquisitely 5 sensitive to distributional information, so why shouldnt we let our parsers use that information as well?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3394">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>i think that the type of input (e.g., treebanks) and the kinds of abilities (e.g., to exactly count the occurences of many different constructions) available to our machines may be so different to what is available to child that the features that work best in our parsers need not bear much relationship to those used by humans.
</prevsent>
<prevsent>still, view the design of the features used in statistical parsers as fundamentally linguistic issue (albeit one with computational consequences,since the search problem in parsing is largely determined by the features involved), and expect there is still more to learn about which combinations of features are most useful for statistical parsing.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
my guess is that the features used in e.g., the collins (2003) <papid> J03-4003 </papid>or charniak (2000) <papid> A00-2018 </papid>parsers are probably close to optimal for english penn treebank parsing (marcus et al, 1993), <papid> J93-2004 </papid>but that other features might improve parsing of other languages or even other english genres.</citsent>
<aftsection>
<nextsent>unfortunately changing the features used in these parsers typically involves significant reprogramming, which makes it difficult for linguists to experiment with new features.
</nextsent>
<nextsent>however, it mightbe possible to develop kind of statistical parsing framework that makes it possible to define new features and integrate them into statistical parser without any programming which would make it easy to explore novel combinations of statistical features; see goodman (1998) for an interesting suggestion along these lines.from high-level perspective, the grammar based approaches and the statistical approaches both view parsing fundamentally in the same way, namely as specialized kind of inference problem.
</nextsent>
<nextsent>these days view parsing as deduction?
</nextsent>
<nextsent>(one of the slogans touted by the grammar-based crowd)as unnecessarily restrictive; after all, psych olin guistic research shows that humans are exquisitely 5 sensitive to distributional information, so why shouldnt we let our parsers use that information as well?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3395">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>i think that the type of input (e.g., treebanks) and the kinds of abilities (e.g., to exactly count the occurences of many different constructions) available to our machines may be so different to what is available to child that the features that work best in our parsers need not bear much relationship to those used by humans.
</prevsent>
<prevsent>still, view the design of the features used in statistical parsers as fundamentally linguistic issue (albeit one with computational consequences,since the search problem in parsing is largely determined by the features involved), and expect there is still more to learn about which combinations of features are most useful for statistical parsing.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
my guess is that the features used in e.g., the collins (2003) <papid> J03-4003 </papid>or charniak (2000) <papid> A00-2018 </papid>parsers are probably close to optimal for english penn treebank parsing (marcus et al, 1993), <papid> J93-2004 </papid>but that other features might improve parsing of other languages or even other english genres.</citsent>
<aftsection>
<nextsent>unfortunately changing the features used in these parsers typically involves significant reprogramming, which makes it difficult for linguists to experiment with new features.
</nextsent>
<nextsent>however, it mightbe possible to develop kind of statistical parsing framework that makes it possible to define new features and integrate them into statistical parser without any programming which would make it easy to explore novel combinations of statistical features; see goodman (1998) for an interesting suggestion along these lines.from high-level perspective, the grammar based approaches and the statistical approaches both view parsing fundamentally in the same way, namely as specialized kind of inference problem.
</nextsent>
<nextsent>these days view parsing as deduction?
</nextsent>
<nextsent>(one of the slogans touted by the grammar-based crowd)as unnecessarily restrictive; after all, psych olin guistic research shows that humans are exquisitely 5 sensitive to distributional information, so why shouldnt we let our parsers use that information as well?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3396">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>these days view parsing as deduction?
</prevsent>
<prevsent>(one of the slogans touted by the grammar-based crowd)as unnecessarily restrictive; after all, psych olin guistic research shows that humans are exquisitely 5 sensitive to distributional information, so why shouldnt we let our parsers use that information as well?
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
and as abney (1997) <papid> J97-4005 </papid>showed, it is mathematically straight-forward to define probability distributions over the representations used by virtually any theory of grammar (even those ofchomskys minimalism), which means that theoretically the arsenal of statistical methods for parsing and learning can be applied to any grammar just as well.in the late 1990s explored these kinds of statistical models for lexical-functional grammar (bresnan, 1982; johnson et al, 1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>the hope was that statistical features based on lfgs richer representations (specifically, -structures) might result in better parsing accuracy.
</nextsent>
<nextsent>however, this seems not to be the case.
</nextsent>
<nextsent>as mentioned above, ab neys formulation of probabilistic models makes essentially no demands on what linguistic representations actually are; all that is required is that the statistical features are functions that map each representation to real number.
</nextsent>
<nextsent>these are used to map set of linguistic representations (say, the set of all grammatical analyses) to set of vectors of real numbers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3397">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>these days view parsing as deduction?
</prevsent>
<prevsent>(one of the slogans touted by the grammar-based crowd)as unnecessarily restrictive; after all, psych olin guistic research shows that humans are exquisitely 5 sensitive to distributional information, so why shouldnt we let our parsers use that information as well?
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
and as abney (1997) <papid> J97-4005 </papid>showed, it is mathematically straight-forward to define probability distributions over the representations used by virtually any theory of grammar (even those ofchomskys minimalism), which means that theoretically the arsenal of statistical methods for parsing and learning can be applied to any grammar just as well.in the late 1990s explored these kinds of statistical models for lexical-functional grammar (bresnan, 1982; johnson et al, 1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>the hope was that statistical features based on lfgs richer representations (specifically, -structures) might result in better parsing accuracy.
</nextsent>
<nextsent>however, this seems not to be the case.
</nextsent>
<nextsent>as mentioned above, ab neys formulation of probabilistic models makes essentially no demands on what linguistic representations actually are; all that is required is that the statistical features are functions that map each representation to real number.
</nextsent>
<nextsent>these are used to map set of linguistic representations (say, the set of all grammatical analyses) to set of vectors of real numbers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3398">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>this meant that didnt actually need the -structures to define the probability distributionsi was interested in; all needed were the corresponding c-structure or phrase-structure trees.and of course there are many ways of obtaining phrase-structure trees.
</prevsent>
<prevsent>at the time my colleague eugene charniak was developing statistical phrase-structure parser that was more robust and had broader coverage than the lfg parser was working with, and found generally got better performance if used the trees his parser produced, so thats what did.
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
this leads to the discriminative re-ranking approach developed by collins and koo (2005), <papid> J05-1003 </papid>in which statistical parser trained on treebank is used to produce set of candidate parses which are then re-ranked?</citsent>
<aftsection>
<nextsent>by an abney-style probabilistic model.i suspect these robustness and coverage problems of grammar-based parsing are symptoms of fundamental problem in the standard way that grammar-based parsing is understood.
</nextsent>
<nextsent>first, think grammar-based approaches face dilemma:on the one hand the explosion of ambiguity suggests that some sentences get too many parses, while the problems of coverage show that some sentences get too few, i.e., zero, parses.
</nextsent>
<nextsent>while its possible that there is single grammar that can resolve this dilemma, my point here is that each of these problems suggests we need to modify the grammars in exactly the opposite way, i.e., generally tighten the constraints in order to reduce ambiguity, while generally relax the constraints in order to allow more parses for sentences that have no parses at all.second, think this dilemma only arises be cause the grammar-based approach to parsing is fundamentally designed around the goal of distinguishing grammatical from ungrammatical sentences.
</nextsent>
<nextsent>while agree with pullum (2007) thatgrammaticality is and should be central to syntactic theory, suspect it is not helpful to view parsing (by machines or humans) as byproduct of proving the grammaticality of sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3399">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> grammar-based and statistical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>andre turn parse for that sentence.
</prevsent>
<prevsent>such an approach might be regarded as way of formalizing the idea that ungrammatical sentences are interpreted by analogy with grammatical ones.
</prevsent>
</prevsection>
<citsent citstr=" P04-1005 ">
(charniak and proposed noisy channel model along these lines for parsing transcribed speech (johnson and charniak, 2004)).<papid> P04-1005 </papid></citsent>
<aftsection>
<nextsent>another possible approach involves modifying our interpretation of the grammar itself.
</nextsent>
<nextsent>we could obtain an open world model by relaxing our interpretation of some or all of the constraints in thegrammar.
</nextsent>
<nextsent>instead of viewing them as hard constraints that define set of grammatical constructions, we reinterpret them as viola ble, probabilistic features.
</nextsent>
<nextsent>for example, instead of interpreting subject-verb agreement as hard constraint that rules out certain syntactic analyses, we reinterpret it as soft constraint that penalizes analyses in which subject-verb agreement fails.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3400">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> statistical models and linguistics.  </section>
<citcontext>
<prevsection>
<prevsent>just to be clear: psycho linguistics and language acquisition are experimental disciplines, and dont expect the average researcher in those fields to start doing computational linguistics any time soon.
</prevsent>
<prevsent>however, do think there are an emerging cadre of young researchers in both fields applying ideas and results from computational linguistics in their work and using experimental results from their field to develop and improve the computational models.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
for example, in psycho linguistics researchers such as hale (2006) and levy (2008)are using probabilistic models of syntactic structure to make predictions about human sentence processing, and bachrach (2008) is using predictions from the roark (2001) <papid> J01-2004 </papid>parser to help explain the patterns of fmri activation observed during sentence comprehension.</citsent>
<aftsection>
<nextsent>in the field of language acquisition computational linguists such as klein and manning (2004) <papid> P04-1061 </papid>have studied the unsupervised acquisition of syntactic structure, while linguists such as boersma and hayes (2001), goldsmith (2001), <papid> J01-2001 </papid>pater (2008) and albright and hayes (2003) are developing probabilistic models of the acquisition of phonology and/or morphology, and frank et al (2007) experimentally tests the predictions of bayesian model of lexical acquisition.</nextsent>
<nextsent>since have more experience with computational models of language acquisition, ill concentrate on this topic for the rest of this section.much of this work can be viewed under the slogan structured statistical learning?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3401">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> statistical models and linguistics.  </section>
<citcontext>
<prevsection>
<prevsent>however, do think there are an emerging cadre of young researchers in both fields applying ideas and results from computational linguistics in their work and using experimental results from their field to develop and improve the computational models.
</prevsent>
<prevsent>for example, in psycho linguistics researchers such as hale (2006) and levy (2008)are using probabilistic models of syntactic structure to make predictions about human sentence processing, and bachrach (2008) is using predictions from the roark (2001) <papid> J01-2004 </papid>parser to help explain the patterns of fmri activation observed during sentence comprehension.</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
in the field of language acquisition computational linguists such as klein and manning (2004) <papid> P04-1061 </papid>have studied the unsupervised acquisition of syntactic structure, while linguists such as boersma and hayes (2001), goldsmith (2001), <papid> J01-2001 </papid>pater (2008) and albright and hayes (2003) are developing probabilistic models of the acquisition of phonology and/or morphology, and frank et al (2007) experimentally tests the predictions of bayesian model of lexical acquisition.</citsent>
<aftsection>
<nextsent>since have more experience with computational models of language acquisition, ill concentrate on this topic for the rest of this section.much of this work can be viewed under the slogan structured statistical learning?.
</nextsent>
<nextsent>that is, specifying the structures over which the learning algorithm generalizes is just as important as specifying the learning algorithm itself.
</nextsent>
<nextsent>one of the things like about this work is that it gets beyond the naive nature-versus-nurture arguments that characterize some of the earlier theoretical work on language acquisition.
</nextsent>
<nextsent>instead, these computational models become tools for investigating the effect of specific structural assumptions on the acquisition process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3402">
<title id=" W09-0103.xml">how the statistical revolution changes computational linguistics </title>
<section> statistical models and linguistics.  </section>
<citcontext>
<prevsection>
<prevsent>however, do think there are an emerging cadre of young researchers in both fields applying ideas and results from computational linguistics in their work and using experimental results from their field to develop and improve the computational models.
</prevsent>
<prevsent>for example, in psycho linguistics researchers such as hale (2006) and levy (2008)are using probabilistic models of syntactic structure to make predictions about human sentence processing, and bachrach (2008) is using predictions from the roark (2001) <papid> J01-2004 </papid>parser to help explain the patterns of fmri activation observed during sentence comprehension.</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
in the field of language acquisition computational linguists such as klein and manning (2004) <papid> P04-1061 </papid>have studied the unsupervised acquisition of syntactic structure, while linguists such as boersma and hayes (2001), goldsmith (2001), <papid> J01-2001 </papid>pater (2008) and albright and hayes (2003) are developing probabilistic models of the acquisition of phonology and/or morphology, and frank et al (2007) experimentally tests the predictions of bayesian model of lexical acquisition.</citsent>
<aftsection>
<nextsent>since have more experience with computational models of language acquisition, ill concentrate on this topic for the rest of this section.much of this work can be viewed under the slogan structured statistical learning?.
</nextsent>
<nextsent>that is, specifying the structures over which the learning algorithm generalizes is just as important as specifying the learning algorithm itself.
</nextsent>
<nextsent>one of the things like about this work is that it gets beyond the naive nature-versus-nurture arguments that characterize some of the earlier theoretical work on language acquisition.
</nextsent>
<nextsent>instead, these computational models become tools for investigating the effect of specific structural assumptions on the acquisition process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3403">
<title id=" W09-0706.xml">partofspeech tagging of northern sotho disambiguating polysemous function words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we aim at high accuracy in thepos-tagging, and at minimizing the amount of unknown word forms in arbitrary unseen corpora, by using guess ers for the open word classes.
</prevsent>
<prevsent>1.2 recent work.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
a few publications, so far, deal with pos-tagging of northern sotho; most prominently, de schryver and de pauw (2007) have presented the maxtag method, tagger based on maximum entropy 38 learning (berger et al , 1996) <papid> J96-1002 </papid>as implemented in the machine learning package maxent (le, 2004).when trained on manually annotated text, it extracts features such as the first and last letter of each word, or the first two and last two letters or the first three and last three letters of each word;it takes the word and the tag preceding and following the item to be tagged, etc., to decide about word/tag probabilities.</citsent>
<aftsection>
<nextsent>de schryver and de pauw report an accuracy of 93.5 % on unseen data, using small training corpus of only ca.
</nextsent>
<nextsent>10,000 word forms.other work is only partly engaged in pos tagging, e.g. kotzes (2008) finite state analysis of the verb complex of northern sotho.
</nextsent>
<nextsent>this study does not cover all parts of speech and can thus not be directly compared with our work.
</nextsent>
<nextsent>taljard et al  (2008) and van rooy and pretorius (2003) present tagsets for northern sotho and the closely related language setswana, but they focus on the definition of the tagsets without discussing their automatic application in detail.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3404">
<title id=" W09-0706.xml">partofspeech tagging of northern sotho disambiguating polysemous function words </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>emphatic and possessive pronouns are represented on three levels (e.g. proposspers becomes pro.poss.pers)2.
</prevsent>
<prevsent>in preliminary experiment, we compared several taggers3 on our manually annotated data.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
apart from the rf-tagger (schmid and laws, 2008), we also used the tree-tagger (schmid, 1994), the tnt tagger (brants, 2000) <papid> A00-1031 </papid>and mbt (daelemans et al , 2007).</citsent>
<aftsection>
<nextsent>4.1 comparing taggers.
</nextsent>
<nextsent>the results give relatively homogenous picture, with the rf-tagger achieving median of 94.16 %when utilising lexicon containing several thousand nouns and verbs.
</nextsent>
<nextsent>it leads to 91 % accuracy without this lexicon (to simulate similar conditions as for tnt or mbt where no external lexicon was offered).
</nextsent>
<nextsent>tnt achieves 91.01 %, and mbt 87.68 %.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3405">
<title id=" W08-2107.xml">picking them up and figuring them out verb particle constructions noise and idiomaticity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</prevsent>
<prevsent>some rights reserved.
</prevsent>
</prevsection>
<citsent citstr=" W04-0403 ">
baldwin (2005) and sharoff (2004)), <papid> W04-0403 </papid>as basis for helping to determine whether given sequence of words is in fact an mwe.</citsent>
<aftsection>
<nextsent>although some research aims at developing methods for dealing with mwes in general (e.g. zhang et al (2006), ramisch et al (2008)), there is also some work that deals with specific types of mwes (e.g. pearce (2002) on collocations and villavicencio (2005) on verb-particle constructions (vpcs)) as each of these mwe types has distinct distributional and linguistic characteristics.
</nextsent>
<nextsent>vpcs are combinations of verbs and particles, such as take off in our plane took off late, that dueto their complex characteristics and flexible nature, provide real challenge for nlp.
</nextsent>
<nextsent>in particular, there is lack of adequate resources to identify and treat them, and those that are available provide only limited coverage, in face of the huge number of combinations in use.
</nextsent>
<nextsent>for tasks like parsing and generation, it is essential to know whether givenvpc is possible or not, to avoid for example using combinations that sound unnatural or ungrammatical to native speakers (e.g. give/lend/grant out for the conveying of something to someone or some place - (fraser, 1976)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3406">
<title id=" W08-2107.xml">picking them up and figuring them out verb particle constructions noise and idiomaticity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic methods for the identification of idiomaticity in mwes have been 1 see baldwin et al (2004) for discussion of the effects of multiword expressions like vpcs on parsers performance.
</prevsent>
<prevsent>49 proposed using variety of approaches such as statistical, substitutional, distributional, etc.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
(e.g.mccarthy et al (2003), <papid> W03-1810 </papid>bannard (2005) and fa zly and stevenson (2006)).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>in particular, fazlyand stevenson (2006) <papid> E06-1043 </papid>look at the correlation between syntactic fixed ness (in terms of e.g. passivisation, choice of determiner type and pluralisation) and non-compositionality of verb-noun compounds such as shoot the breeze.in this work we investigate the automatic extraction of vpcs, looking into variety of methods, combining linguistic with statistical information, ranging from frequencies to association measures: mutual information (mi), ? 2 and entropy.</nextsent>
<nextsent>we also investigate the determination of compositionality of vpcs verifying whether the degree of semantic flexibility of vpc combined with some statistical information can be used to determine if it is idiomatic or compositional.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3407">
<title id=" W08-2107.xml">picking them up and figuring them out verb particle constructions noise and idiomaticity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic methods for the identification of idiomaticity in mwes have been 1 see baldwin et al (2004) for discussion of the effects of multiword expressions like vpcs on parsers performance.
</prevsent>
<prevsent>49 proposed using variety of approaches such as statistical, substitutional, distributional, etc.
</prevsent>
</prevsection>
<citsent citstr=" E06-1043 ">
(e.g.mccarthy et al (2003), <papid> W03-1810 </papid>bannard (2005) and fa zly and stevenson (2006)).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>in particular, fazlyand stevenson (2006) <papid> E06-1043 </papid>look at the correlation between syntactic fixed ness (in terms of e.g. passivisation, choice of determiner type and pluralisation) and non-compositionality of verb-noun compounds such as shoot the breeze.in this work we investigate the automatic extraction of vpcs, looking into variety of methods, combining linguistic with statistical information, ranging from frequencies to association measures: mutual information (mi), ? 2 and entropy.</nextsent>
<nextsent>we also investigate the determination of compositionality of vpcs verifying whether the degree of semantic flexibility of vpc combined with some statistical information can be used to determine if it is idiomatic or compositional.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3410">
<title id=" W08-2107.xml">picking them up and figuring them out verb particle constructions noise and idiomaticity </title>
<section> weighting the results up.  </section>
<citcontext>
<prevsection>
<prevsent>this could probably be explained by either the choice of simple wsd heuristics for selecting synsets, or because the indirect synonymy information is too far related to the original verb tobe used in variational patterns.
</prevsent>
<prevsent>inspecting the generated variations, we notice that most of the synonym synsets are related to secondary senses orvery specific uses of verb and are thus not correctly disambiguated.in what concerns the wns sets, only the smallest and first synset were kept, suggesting again thatit may not be good idea to maximise the synonyms set and for future work, we intent to establish threshold for synset to be taken intoaccount.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
in addition, we can also infer positive contribution of the frequency of sense withthe choice of the first synset returned by wordnet resulting in reasonable wsd heuristic (which is compatible with the results by mccarthy et al (2004)).<papid> P04-1036 </papid></citsent>
<aftsection>
<nextsent>on the other hand, the algorithm selected the first, the smallest and the biggest of the levinssets.
</nextsent>
<nextsent>this probably happens because the majority of these verbs belongs only to one or two, but never to great number of classes.
</nextsent>
<nextsent>since the gran ularity of the classes is coarser than for synsets, the heuristics often offer four equal or very close entropies and thus redundant information.
</nextsent>
<nextsent>as an overall result, the last iteration shown in table 3 indicates precision of 61.9% for the classifier in detecting idiomatic vpcs, that is to say that we automatically retrieved 176 vpcs where 67 are false positives and 109 are truly idiomatic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3412">
<title id=" W09-1115.xml">investigating automatic alignment methods for slide generation from academic papers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a robust system capable of generating slide presentations from papers would save the author much tedium when organizing her presentations.
</prevsent>
<prevsent>in this paper we investigate this task from novel perspective.
</prevsent>
</prevsection>
<citsent citstr=" W99-0204 ">
while others have developed interesting approaches to slide generation from documents by modeling the problem in unique way (utiyama and hasida, 1999; <papid> W99-0204 </papid>shibata and kurohashi, 2005), <papid> I05-1066 </papid>the aim of the research this paper initiates is to discover how humans create slide presentations, focusing more specifically on academic pa pers.</citsent>
<aftsection>
<nextsent>thus we take corpus-based approach to the problem, and as first step focus on the task of automatically aligning slide presentations to academic papers.we built corpus of 296 slide-paper pairs and implemented four slide to paper align ers which utilize popular information retrieval methods such as tf idf term weighting and query expansion.
</nextsent>
<nextsent>in this paper we show that, in this application, tf-idf term weighting is inferior to simpler scoring mechanism based only on the number of matched terms and query expansion degrades aligner performance.
</nextsent>
<nextsent>our best aligner achieves an accuracy of 75%.
</nextsent>
<nextsent>automatic slide generation from documents is thus far under-investigated topic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3413">
<title id=" W09-1115.xml">investigating automatic alignment methods for slide generation from academic papers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a robust system capable of generating slide presentations from papers would save the author much tedium when organizing her presentations.
</prevsent>
<prevsent>in this paper we investigate this task from novel perspective.
</prevsent>
</prevsection>
<citsent citstr=" I05-1066 ">
while others have developed interesting approaches to slide generation from documents by modeling the problem in unique way (utiyama and hasida, 1999; <papid> W99-0204 </papid>shibata and kurohashi, 2005), <papid> I05-1066 </papid>the aim of the research this paper initiates is to discover how humans create slide presentations, focusing more specifically on academic pa pers.</citsent>
<aftsection>
<nextsent>thus we take corpus-based approach to the problem, and as first step focus on the task of automatically aligning slide presentations to academic papers.we built corpus of 296 slide-paper pairs and implemented four slide to paper align ers which utilize popular information retrieval methods such as tf idf term weighting and query expansion.
</nextsent>
<nextsent>in this paper we show that, in this application, tf-idf term weighting is inferior to simpler scoring mechanism based only on the number of matched terms and query expansion degrades aligner performance.
</nextsent>
<nextsent>our best aligner achieves an accuracy of 75%.
</nextsent>
<nextsent>automatic slide generation from documents is thus far under-investigated topic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3418">
<title id=" W09-0612.xml">an alignment capable micro planner for natural language generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, mutual alignment of user and dialogue system might make the conversation itself more natural and, presumably, cognitively more lightweight for the user.
</prevsent>
<prevsent>in this paper we present computational model for parts of the interactive alignment model that are particularly important in the context of natural language generation.
</prevsent>
</prevsection>
<citsent citstr=" W02-0111 ">
we describe how this model has been incorporated into the existing spud lite system (stone et al, 2003; stone, 2002) <papid> W02-0111 </papid>to yield the alignment-capable micro planner spud prime.</citsent>
<aftsection>
<nextsent>in section 2 we describe previous approaches to integrate alignment into natural language generation.
</nextsent>
<nextsent>in sections 3 and 4, we present our priming based model of alignment and its implementation in spud prime.
</nextsent>
<nextsent>in section 5, we describe resultsof an evaluation on corpus of task-oriented dialogue, and in section 6 we conclude our work and describe possible future directions.
</nextsent>
<nextsent>82
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3420">
<title id=" W08-1806.xml">answer validation by information distance calculation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with automatic answer validation, the system will carry out different refinements of its searching criteria to check the relevance of new candidate answers.
</prevsent>
<prevsent>in addition, since most of qa systems relyon complex architectures and the evaluation of their performances requires huge amount of work, the automatic assessment of candidates with respect to given question will speed up both algorithm refinement and testing.
</prevsent>
</prevsection>
<citsent citstr=" P06-1112 ">
currently, answer validation is mainly viewed as classification problem or ranking problem.different models, such as support vector machine (shen and klakow, 2006) <papid> P06-1112 </papid>and maximum entropy model (ittycheriah et al, 2001), <papid> N01-1005 </papid>are used to integrate sophisticated linguistic features to determine the correctness of candidates.</citsent>
<aftsection>
<nextsent>the answer validation exercise (penas et al , 2007) aims at developing systems able to decide whether the answer is correct or not.
</nextsent>
<nextsent>they formulate answer validation as text entailment problem.
</nextsent>
<nextsent>these approaches are dependent on sophisticated linguistic analysis of syntactic and semantic relations between question and candidates.
</nextsent>
<nextsent>it is quite expensive to use deep analysis for automatic answer validation, especially in large scale dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3421">
<title id=" W08-1806.xml">answer validation by information distance calculation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with automatic answer validation, the system will carry out different refinements of its searching criteria to check the relevance of new candidate answers.
</prevsent>
<prevsent>in addition, since most of qa systems relyon complex architectures and the evaluation of their performances requires huge amount of work, the automatic assessment of candidates with respect to given question will speed up both algorithm refinement and testing.
</prevsent>
</prevsection>
<citsent citstr=" N01-1005 ">
currently, answer validation is mainly viewed as classification problem or ranking problem.different models, such as support vector machine (shen and klakow, 2006) <papid> P06-1112 </papid>and maximum entropy model (ittycheriah et al, 2001), <papid> N01-1005 </papid>are used to integrate sophisticated linguistic features to determine the correctness of candidates.</citsent>
<aftsection>
<nextsent>the answer validation exercise (penas et al , 2007) aims at developing systems able to decide whether the answer is correct or not.
</nextsent>
<nextsent>they formulate answer validation as text entailment problem.
</nextsent>
<nextsent>these approaches are dependent on sophisticated linguistic analysis of syntactic and semantic relations between question and candidates.
</nextsent>
<nextsent>it is quite expensive to use deep analysis for automatic answer validation, especially in large scale dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3424">
<title id=" W08-1806.xml">answer validation by information distance calculation </title>
<section> answer validation with information.  </section>
<citcontext>
<prevsection>
<prevsent>7.
</prevsent>
<prevsent>definitional patterns: several heuristic pat-.
</prevsent>
</prevsection>
<citsent citstr=" N04-1007 ">
terns, as introduced at (hildebrandt et al , 2004), <papid> N04-1007 </papid>are added into our final pattern sets, such as c?, f??.</citsent>
<aftsection>
<nextsent>by such heuristic rules, the original pattern set is obtained from question sentence.
</nextsent>
<nextsent>the patterns are initially enclosed in quotation marks, which means exact matching.
</nextsent>
<nextsent>however, by eliminating these quotations, or reducing the scope that they cover, the matching is relaxed as words co-occurrence.
</nextsent>
<nextsent>the patterns are expanded into different strict-level patterns by adding or removing quotation marks for each tokens or adjacent tokens combination.several condition pattern samples are shown in table 1 table 1: sample condition patterns, ? ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3425">
<title id=" W08-1706.xml">from grammar independent construction enumeration to lexical types in computational grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the design is not geared to any particular framework of computational grammar or linguistics.
</prevsent>
<prevsent>examples will be offered relative to hpsg- and lfg- grammars, and the actual conversions from templates to lexical types so far developed relate to hpsg grammars using the lkb platform (cf.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
(copestake 2002)), based on the  hpsg grammar matrix  design ((bender et al 2002)).<papid> W02-1502 </papid></citsent>
<aftsection>
<nextsent>our exposition will be based on the design as it relates to the lkb-grammar nor source (cf.
</nextsent>
<nextsent>(beermann and hellan 2004)) and verb construction enumeration for norwegian.
</nextsent>
<nextsent>the enterprise here presented has lines going back at least to the mid and late 80ies, both regarding test suite development (e.g., (flickinger et al 1987), (lehmann et al 1996)) <papid> C96-2120 </papid>and argument frame inventories ((hellan et al 1889)).</nextsent>
<nextsent>by template for verb construction we under stand standardized way of exposing selected features of the construction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3426">
<title id=" W08-1706.xml">from grammar independent construction enumeration to lexical types in computational grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our exposition will be based on the design as it relates to the lkb-grammar nor source (cf.
</prevsent>
<prevsent>(beermann and hellan 2004)) and verb construction enumeration for norwegian.
</prevsent>
</prevsection>
<citsent citstr=" C96-2120 ">
the enterprise here presented has lines going back at least to the mid and late 80ies, both regarding test suite development (e.g., (flickinger et al 1987), (lehmann et al 1996)) <papid> C96-2120 </papid>and argument frame inventories ((hellan et al 1889)).</citsent>
<aftsection>
<nextsent>by template for verb construction we under stand standardized way of exposing selected features of the construction.
</nextsent>
<nextsent>exposed features are classificatory features, and in this respect, template may be regarded as type.
</nextsent>
<nextsent>a system for enumerating templates should be designed such that they are, internal to given language, complete and transparent, and across languages, comparable both in templates shared and in templates distinct.
</nextsent>
<nextsent>technologically they should be as low level as possible, and platform independent, and be equally accessible to practising field linguists as to nlp researchers in computational settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3428">
<title id=" W09-0628.xml">report on the first nlg challenge on generating instructions in virtual environments give </title>
<section> the give challenge.  </section>
<citcontext>
<prevsection>
<prevsent>nlg systems are notoriously hardto evaluate.
</prevsent>
<prevsent>on the one hand, simply comparing system outputs to gold standard using automatic comparison algorithms has limited value be cause there can be multiple generated outputs that are equally good.
</prevsent>
</prevsection>
<citsent citstr=" P08-2050 ">
finding metrics that account for this variability and produce results consistent with human judgments and task performance measures is difficult (belz and gatt, 2008; <papid> P08-2050 </papid>stent et al., 2005; foster, 2008).</citsent>
<aftsection>
<nextsent>human assessments of system outputs are preferred, but lab-based evaluations that allow human subjects to assess each aspect of the systems functionality are expensive and time-consuming, thereby favoring larger labs with adequate resources to conduct human subjects studies.
</nextsent>
<nextsent>human assessment studies are also difficult to replicate across sites, so system developers that are geographically separated find it difficult to compare different approaches to the same problem, which in turn leads to an overall difficulty in measuring progress in the field.
</nextsent>
<nextsent>the give-1 evaluation was conducted via client/server architecture which allows any user with an internet connection to provide system evaluation data.
</nextsent>
<nextsent>internet-based studies have been shown to provide generous amounts of data in other areas of ai (von ahn and dabbish, 2004; orkin and roy, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3429">
<title id=" W09-0628.xml">report on the first nlg challenge on generating instructions in virtual environments give </title>
<section> the give challenge.  </section>
<citcontext>
<prevsection>
<prevsent>due to its appeal to younger students, the task can also be used as pedagogical exercise to stimulate interest among secondary-school students in the research challenges found in nlg or computational linguistics more broadly.embedding the nlg task in virtual world encourages the participating research teams to consider communication in situated setting.
</prevsent>
<prevsent>this makes the nlg task quite different than in other nlg challenges.
</prevsent>
</prevsection>
<citsent citstr=" W06-1412 ">
for example, experiments have shown that human instruction givers make the instruction follower move to different location in order to use simpler referring expression (re)(stoia et al, 2006).<papid> W06-1412 </papid></citsent>
<aftsection>
<nextsent>that is, regeneration becomes very different problem than the classical non-situated dale &amp; reiter style regeneration, which focuses on generating res that are single noun phrases in the context of an unchanging world.on the other hand, because the virtual environments scenario is so open-ended, it ? and specifically the instruction-giving task ? can potentially be of interest to wide range of nlg researchers.this is most obvious for research in sentence planning (gre, aggregation, lexical choice) and realization (the real-time nature of the task imposes high demands on the systems efficiency).
</nextsent>
<nextsent>but if 166extended to two-way dialog, the task can also involve issues of prosody generation (i.e., research on text/concept-to-speech generation), discourse generation, and human-robot interaction.
</nextsent>
<nextsent>finally, the game world can be scaled to focus on specific issues in nlg, such as the generation of res or the generation of navigation instructions.
</nextsent>
<nextsent>now we describe the method we applied to obtain experimental data, and sketch the software infrastructure we developed for this purpose.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3430">
<title id=" W08-0904.xml">recognizing noisy roman ized japanese words in learner english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since roman words are roman ized japanese words and thus are unknown to pos taggers, they degrades the performance of pos taggers.
</prevsent>
<prevsent>in spell checking, they are major source of false positives because theyare unknown words as just mentioned.
</prevsent>
</prevsection>
<citsent citstr=" A00-2019 ">
in error detection, most methods such as chodorow and leacock (2000), <papid> A00-2019 </papid>izumi et al (2003), <papid> P03-2026 </papid>nagata et al (2005), nagata et al (2006), <papid> P06-1031 </papid>and han et al (2004), han et al (2006) use pos tagger and/or chunker to detect errors.</citsent>
<aftsection>
<nextsent>again, roman words degrades their performances.
</nextsent>
<nextsent>when viewed from another perspective, roman words play an interesting role in second language acquisition.
</nextsent>
<nextsent>it would be interesting to see what roman words are used in the writing of japanese learners of english.
</nextsent>
<nextsent>a frequency list of roman words should be useful in vocabulary learning and teaching.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3431">
<title id=" W08-0904.xml">recognizing noisy roman ized japanese words in learner english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since roman words are roman ized japanese words and thus are unknown to pos taggers, they degrades the performance of pos taggers.
</prevsent>
<prevsent>in spell checking, they are major source of false positives because theyare unknown words as just mentioned.
</prevsent>
</prevsection>
<citsent citstr=" P03-2026 ">
in error detection, most methods such as chodorow and leacock (2000), <papid> A00-2019 </papid>izumi et al (2003), <papid> P03-2026 </papid>nagata et al (2005), nagata et al (2006), <papid> P06-1031 </papid>and han et al (2004), han et al (2006) use pos tagger and/or chunker to detect errors.</citsent>
<aftsection>
<nextsent>again, roman words degrades their performances.
</nextsent>
<nextsent>when viewed from another perspective, roman words play an interesting role in second language acquisition.
</nextsent>
<nextsent>it would be interesting to see what roman words are used in the writing of japanese learners of english.
</nextsent>
<nextsent>a frequency list of roman words should be useful in vocabulary learning and teaching.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3432">
<title id=" W08-0904.xml">recognizing noisy roman ized japanese words in learner english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since roman words are roman ized japanese words and thus are unknown to pos taggers, they degrades the performance of pos taggers.
</prevsent>
<prevsent>in spell checking, they are major source of false positives because theyare unknown words as just mentioned.
</prevsent>
</prevsection>
<citsent citstr=" P06-1031 ">
in error detection, most methods such as chodorow and leacock (2000), <papid> A00-2019 </papid>izumi et al (2003), <papid> P03-2026 </papid>nagata et al (2005), nagata et al (2006), <papid> P06-1031 </papid>and han et al (2004), han et al (2006) use pos tagger and/or chunker to detect errors.</citsent>
<aftsection>
<nextsent>again, roman words degrades their performances.
</nextsent>
<nextsent>when viewed from another perspective, roman words play an interesting role in second language acquisition.
</nextsent>
<nextsent>it would be interesting to see what roman words are used in the writing of japanese learners of english.
</nextsent>
<nextsent>a frequency list of roman words should be useful in vocabulary learning and teaching.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3433">
<title id=" W08-0904.xml">recognizing noisy roman ized japanese words in learner english </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 describes experiments conducted to evaluate the method and discusses the results.
</prevsent>
<prevsent>basically, no methods for recognizing roman words have been proposed in the past.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
however, there have been great deal of work related to roman words.transliteration and back-transliteration often involve roman ization from japanese katakana words into their equivalents spelled in roman alphabets as in knight and graehl (1998) <papid> J98-4003 </papid>and brill et al (2001).for example, knight and graehl (1998) <papid> J98-4003 </papid>back trans literate japanese katakana words into english via japanese roman ized equivalents.</citsent>
<aftsection>
<nextsent>transliteration and back-transliteration, however, are different tasks from ours.
</nextsent>
<nextsent>transliteration and back-transliteration are task where given english and japanese katakana words are put into their corresponding japanese katakana and english words, respectively, whereas our task is to recognize roman words in english text written by learners of english.more related to our task is loan word identification; our task can be viewed as loan word identification where loan words are roman words in englishtext.
</nextsent>
<nextsent>jeong et al (1999) describe method for distinguishing between foreign and pure korean words in korean text.
</nextsent>
<nextsent>nwesri et al(2006) <papid> W06-1631 </papid>propose method for identifying foreign words in arabic text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3437">
<title id=" W08-0904.xml">recognizing noisy roman ized japanese words in learner english </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>transliteration and back-transliteration are task where given english and japanese katakana words are put into their corresponding japanese katakana and english words, respectively, whereas our task is to recognize roman words in english text written by learners of english.more related to our task is loan word identification; our task can be viewed as loan word identification where loan words are roman words in englishtext.
</prevsent>
<prevsent>jeong et al (1999) describe method for distinguishing between foreign and pure korean words in korean text.
</prevsent>
</prevsection>
<citsent citstr=" W06-1631 ">
nwesri et al(2006) <papid> W06-1631 </papid>propose method for identifying foreign words in arabic text.</citsent>
<aftsection>
<nextsent>khaltar et al (2006) <papid> P06-1083 </papid>extract loan words from mongolian corpora using japanese loan word dictionary.</nextsent>
<nextsent>these methods are fundamentally different from ours in the following two points.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3438">
<title id=" W08-0904.xml">recognizing noisy roman ized japanese words in learner english </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>jeong et al (1999) describe method for distinguishing between foreign and pure korean words in korean text.
</prevsent>
<prevsent>nwesri et al(2006) <papid> W06-1631 </papid>propose method for identifying foreign words in arabic text.</prevsent>
</prevsection>
<citsent citstr=" P06-1083 ">
khaltar et al (2006) <papid> P06-1083 </papid>extract loan words from mongolian corpora using japanese loan word dictionary.</citsent>
<aftsection>
<nextsent>these methods are fundamentally different from ours in the following two points.
</nextsent>
<nextsent>first, the target text in our task is full of spelling errors both in rom anand english words.
</nextsent>
<nextsent>second, the above methods require annotated training data and/or other sources of knowledge such as japanese loan word dictionary that are hard to obtain in our task.
</nextsent>
<nextsent>this section briefly introduces the spelling system of roman words which is needed to under stand the rest of this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3440">
<title id=" W09-1003.xml">dialogue act prediction using stochastic context free grammar induction </title>
<section> using structural properties of.  </section>
<citcontext>
<prevsection>
<prevsent>task-oriented dialogue one of the best known regularities that are observed in dialogue are the two-part structures, known as adjacency pairs (schegloff, 1968), like question-answer or greeting-greeting.
</prevsent>
<prevsent>a simple model of predicting plausible next dialogue act that deals with such regularities could be based on bigrams, and to include more context also higher-order n-grams could be used.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
for instance, stolcke et al (2000) <papid> J00-3003 </papid>explore n-gram models based on transcribed words and prosodic information for swbd-damsl dialogue acts in the switchboard corpus (godfrey et al, 1992).</citsent>
<aftsection>
<nextsent>after training back-off n-gram models (katz, 1987) of 7 different order using frequency smoothing (witten and bell, 1991), it was concluded that trigrams andhigher-order n-grams offer small gain in predi cation performance with respect to bigrams.
</nextsent>
<nextsent>apart from adjacency pairs, there is variety of more complex re-occurring interaction patterns.for instance, the following utterances with corresponding dialogue act types illustrate clarification sub-dialogue within an information-request dialogue: 1 a: how do do fax?
</nextsent>
<nextsent>question 2 b: do you want to send question or print one?
</nextsent>
<nextsent>such structures have received considerable attention and their models are often referred to as discourse/dialogue grammars (polanyi and scha, 1984) <papid> P84-1085 </papid>or conversational/dialogue games (levin and moore, 1988).as also remarked by levin (1999), predicting and recognising dialogue games using n-grammodels is not really successful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3441">
<title id=" W09-1003.xml">dialogue act prediction using stochastic context free grammar induction </title>
<section> a: want to print it answer </section>
<citcontext>
<prevsection>
<prevsent>apart from adjacency pairs, there is variety of more complex re-occurring interaction patterns.for instance, the following utterances with corresponding dialogue act types illustrate clarification sub-dialogue within an information-request dialogue: 1 a: how do do fax?
</prevsent>
<prevsent>question 2 b: do you want to send question or print one?
</prevsent>
</prevsection>
<citsent citstr=" P84-1085 ">
such structures have received considerable attention and their models are often referred to as discourse/dialogue grammars (polanyi and scha, 1984) <papid> P84-1085 </papid>or conversational/dialogue games (levin and moore, 1988).as also remarked by levin (1999), predicting and recognising dialogue games using n-grammodels is not really successful.</citsent>
<aftsection>
<nextsent>there are various causes for this.
</nextsent>
<nextsent>the flat horizontal structure of n-grams does not allow (hierarchical) grouping of symbols.
</nextsent>
<nextsent>this may weaken the predictive power and reduces the power of the representation since nested structures such as exemplified above cannot be represented in straightforward way.a better solution would be to express the structure of dialogue games by context-free grammar (cfg) representation in which the terminals are dialogue acts and the non-terminals denote conversational games.
</nextsent>
<nextsent>construction of cfg would require explicit specification of discourse grammar, which could be done by hand, but it would be great advantage if cfgs could automatically be induced from the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3442">
<title id=" W09-1003.xml">dialogue act prediction using stochastic context free grammar induction </title>
<section> n-gram language models </section>
<citcontext>
<prevsection>
<prevsent>nagata and morimoto (1994) describe statistical model of discourse based on trigrams of utterances classified by custom speech act types.
</prevsent>
<prevsent>they report 39.7% prediction accuracy for the top candidate and 61.7% for the top three candidates.
</prevsent>
</prevsection>
<citsent citstr=" P95-1016 ">
in the context of the dialogue component of thespeech-to-speech translation system verb mobil, reithinger and maier (1995) <papid> P95-1016 </papid>use n-gram dialogue act probabilities to suggest the most likely dialogue act.</citsent>
<aftsection>
<nextsent>in later work, alexandersson and reithinger (1997) describe an approach which comes close to the work reported in this paper: using grammar induction, plan operators are semi automatically derived and combined with statistical disambiguation component.
</nextsent>
<nextsent>this system is claimed to have an accuracy score of around 70% on turn management classes.
</nextsent>
<nextsent>another study is that of poesio and mikheev (1998), in which prediction based on the previous dialogue act is compared with prediction based on the context of dialogue games.
</nextsent>
<nextsent>using the map task corpus annotated with moves?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3443">
<title id=" W09-1003.xml">dialogue act prediction using stochastic context free grammar induction </title>
<section> act prediction experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the application domain of the fax device is complex but small: the domain model consists of 70 entities with at most 10 properties, 72 higher-level actions or tasks, and 45 different settings.
</prevsent>
<prevsent>representations of semantic content are often expressed in some form of predicate logic typeformula.
</prevsent>
</prevsection>
<citsent citstr=" J90-3001 ">
examples are quasi logical forms (alshawi, 1990), <papid> J90-3001 </papid>dynamic predicate logic (groe nendijk and stokhof, 1991), and underspecified discourse representation theory (reyle, 1993).</citsent>
<aftsection>
<nextsent>the sc in the dataset is in simplified first order logic similar to quasi logical forms, and is suitable to support feasible reasoning, for which also theorem provers, model builders, and model checkers can be used.
</nextsent>
<nextsent>the following utterances and their corresponding sc characterise the dataset: 1 wat moet ik nu doen?
</nextsent>
<nextsent>(what do have to do now?)
</nextsent>
<nextsent>x . next-step(x) 2 druk op een toets (press button) . press(x) ? button(x) 3 druk op de groene toets (press the green button) . press(x) ? button(x) ? color(x,green?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3444">
<title id=" W08-2008.xml">concept graph based biomedical automatic summarization using ontologies </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the alternative could be to normalise the sentences scores by the number of concepts.
</prevsent>
<prevsent>secondly, concepts associated with general semantic types in umls, as functional concept, temporal concept, entity and language, could be ignored, since they do not contribute to distinguish what sentences are significant.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
finally, in order to formally evaluate the method and the different heuristics, large-scale evaluation on the biomed corpus is under way, based on computing the rouge measures (lin, 2004).<papid> W04-1013 </papid></citsent>
<aftsection>
<nextsent>acknowledgements this research is funded by the ministerio de educacion ciencia (tin2006-14433-c02-01), universidad complutense de madrid and direcciongeneral de universidades investigacion de la co munidad de madrid (ccg07-ucm/tic 2803).
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3445">
<title id=" W08-1707.xml">designing test suites for grammar based systems in applications </title>
<section> phenomenon sets.  </section>
<citcontext>
<prevsection>
<prevsent>focused test suites are also good for quickly diagnosing problems.
</prevsent>
<prevsent>if all the broken examples are in the deverbal test suite, for example, it gives grammar engineers good idea of where to look for bugs.
</prevsent>
</prevsection>
<citsent citstr=" W08-0506 ">
the majority of the test suites are organized by syntactic and semantic phenomena and are designed to test all known variants of that phenomenon (see (cohen et al, 2008) <papid> W08-0506 </papid>on the need to use test suites designed to test system coverage as well as real-world corpora).</citsent>
<aftsection>
<nextsent>for the question answering system, these include topics such as anaphora, appositives, copulars, negation, dever bal nouns and adjectives, implicatives and factives,temporals, cardinality and quantifiers, comparatives, possess ives, context introducing nouns, and pertainyms.
</nextsent>
<nextsent>these categories align with many of 50those cited by (bos, 2008) in his discussion of semantic parser coverage.
</nextsent>
<nextsent>some example passage query pairs for deverbal nouns are shown in (3).(3) a. p: eds abdication of the throne was welcome.
</nextsent>
<nextsent>q: ed abdicated the throne.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3446">
<title id=" W08-1707.xml">designing test suites for grammar based systems in applications </title>
<section> regression on representations.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the passage-query pairs canbe roughly divided as to those using just linguistic meaning, those using logical reasoning, those requiring plausible reasoning, and finally those requiring world knowledge.
</prevsent>
<prevsent>although the boundaries between these are not always clear (sekine et al., 2007), having rough division helps in guiding development.
</prevsent>
</prevsection>
<citsent citstr=" C96-2120 ">
there has been significant work on regression testing of systems output representations (nerbonne et al, 1988; cooper et al, 1996; lehmann et al,1996; <papid> C96-2120 </papid>oepen et al, 1998; oepen et al, 2002): designing of the test suites, running and maintaining them, and tracking the results over time.</citsent>
<aftsection>
<nextsent>as mentioned in the previous discussion, for complex system such as question-answering system, having regression testing that depends on the performance of the system rather than on details of the representations has significant advantages forde velopment because the regression test suites do not have to be redone whenever there is change to the system and because the gold standard items (i.e.,the passage-query pairs with answers) can be created by those less familiar with the details of the system.
</nextsent>
<nextsent>however, having small but representative set of banked representations at each major level of system output has proven useful for detecting unintended changes that may not immediately disturb the passage-query pairs.3 this is especially the case3in addition to running regression tests against representa with the sanity sets and the most basic query sets: with these the query is identical to or very closely resembles the passage so that changes to the representation on the passage side will also be in the representation on the query side and hence may not be detected as erroneous by the entailment and contradiction detection.for the question-answering system, 1200 sentences covering basic syntactic and semantic types form test suite for representations.
</nextsent>
<nextsent>the best representation currently produced by the system is stored for the syntax, the linguistic semantics, and the abstract knowledge representation levels.
</nextsent>
<nextsent>toallow for greater stability over time and less sensitivity to minor feature changes in the rule sets, it is possible to bank only the most important feature sin the representations may, e.g. the core predicate argument structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3447">
<title id=" W08-1707.xml">designing test suites for grammar based systems in applications </title>
<section> discussion and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 wh-questions.
</prevsent>
<prevsent>the test suites as described have not yet been systematically extended to wh-questions.
</prevsent>
</prevsection>
<citsent citstr=" W08-0502 ">
the query tions, the syntax, semantics, and abstract knowledge representation have type declarations (crouch and king, 2008) <papid> W08-0502 </papid>which help to detect malformed representations.</citsent>
<aftsection>
<nextsent>53sets can be easily extended to involve some substitution of wh-phrases for arguments and adjuncts in the passage, as in (10).
</nextsent>
<nextsent>(10) a. p: john broke the box.
</nextsent>
<nextsent>q: who broke the box?
</nextsent>
<nextsent>b. p: john broke the box.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3448">
<title id=" W09-0623.xml">investigating content selection for language generation using machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sucha scorecard would typically contain large number of statistics pertaining to the game as whole as well as individual players (e.g. see figure 1).
</prevsent>
<prevsent>our aim is to identify which statistics should be selected by the nlg system.much work has been done in the field of content selection, in diverse range of domains e.g. weather forecasts (coch, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W03-1016 ">
approaches are usually domain specific and predominantly based on structured tables of well-defined input data.duboue and mckeown (2003) <papid> W03-1016 </papid>attempted statistical approach to content selection using substantial corpus of biographical summaries paired with selected content, where they extracted rule sand patterns linking the two.</citsent>
<aftsection>
<nextsent>they then used machine learning to ascertain what was relevant.barzilay and lapata (2005) <papid> H05-1042 </papid>extended this approach but applying it to sports domain (amer ican football), similarly viewing content selection as classification task and additionally taking account of contextual dependencies between data, and found that this improved results compared to content-agnostic baseline.</nextsent>
<nextsent>we aim throughout to extend and improve upon barzilay and lapatas methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3449">
<title id=" W09-0623.xml">investigating content selection for language generation using machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our aim is to identify which statistics should be selected by the nlg system.much work has been done in the field of content selection, in diverse range of domains e.g. weather forecasts (coch, 1998).
</prevsent>
<prevsent>approaches are usually domain specific and predominantly based on structured tables of well-defined input data.duboue and mckeown (2003) <papid> W03-1016 </papid>attempted statistical approach to content selection using substantial corpus of biographical summaries paired with selected content, where they extracted rule sand patterns linking the two.</prevsent>
</prevsection>
<citsent citstr=" H05-1042 ">
they then used machine learning to ascertain what was relevant.barzilay and lapata (2005) <papid> H05-1042 </papid>extended this approach but applying it to sports domain (amer ican football), similarly viewing content selection as classification task and additionally taking account of contextual dependencies between data, and found that this improved results compared to content-agnostic baseline.</citsent>
<aftsection>
<nextsent>we aim throughout to extend and improve upon barzilay and lapatas methods.
</nextsent>
<nextsent>we emphasise that content selection through statistical machine learning is relatively new area ? approaches prior to duboue and mckeowns are, in principle, much less portable ? and as such there is not an enormous body of work to build upon.this work offers novel algorithm for data-to text alignment, presents new grouping?
</nextsent>
<nextsent>method for sharing knowledge across similar but distinct learning instances and shows that holding back certain data from the machine learner, and reintroducing it later on can improve results.
</nextsent>
<nextsent>we first must obtain appropriately aligned cricket data, for the purposes of machine learning.our data comes from the online wisden alma nack (cricinfo, 2007), which we used to download 133 match report/scorecard pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3454">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently, pupa allows obtaining high quality parses without any human involvement.
</prevsent>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</nextsent>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3455">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently, pupa allows obtaining high quality parses without any human involvement.
</prevsent>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</nextsent>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3456">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently, pupa allows obtaining high quality parses without any human involvement.
</prevsent>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
</prevsection>
<citsent citstr=" W06-2912 ">
the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</nextsent>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3472">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently, pupa allows obtaining high quality parses without any human involvement.
</prevsent>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
</prevsection>
<citsent citstr=" P06-1072 ">
the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</nextsent>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3473">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently, pupa allows obtaining high quality parses without any human involvement.
</prevsent>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></citsent>
<aftsection>
<nextsent>many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</nextsent>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3474">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
<prevsent>the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1022 ">
many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</citsent>
<aftsection>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
<nextsent>in the highly variable web, where many of these systems are used, it is very difficult to create representative corpus for manual annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3475">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
<prevsent>the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></prevsent>
</prevsection>
<citsent citstr=" J08-2005 ">
many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</citsent>
<aftsection>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
<nextsent>in the highly variable web, where many of these systems are used, it is very difficult to create representative corpus for manual annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3476">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
<prevsent>the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-1117 ">
many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</citsent>
<aftsection>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
<nextsent>in the highly variable web, where many of these systems are used, it is very difficult to create representative corpus for manual annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3477">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in unsupervised parsing an algorithm should uncover the syntactic structure of an input sentence without using any manually created structural training data.
</prevsent>
<prevsent>the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-1087 ">
many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</citsent>
<aftsection>
<nextsent>to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></nextsent>
<nextsent>in the highly variable web, where many of these systems are used, it is very difficult to create representative corpus for manual annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3478">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the last decade has seen significant progress in this field of research (klein and manning, 2002; <papid> P02-1017 </papid>klein and manning, 2004; <papid> P04-1061 </papid>bod, 2006<papid> W06-2912 </papid>a; bod, 2006<papid> W06-2912 </papid>b; smith and eisner, 2006; <papid> P06-1072 </papid>seginer, 2007).<papid> P07-1049 </papid></prevsent>
<prevsent>many nlp systems use the output of supervised parsers (e.g., (kwok et al, 2001) for qa, (moldovan et al, 2003) <papid> N03-1022 </papid>for ie, (punyakanok et al, 2008) <papid> J08-2005 </papid>for srl, (srikumar et al, 2008) <papid> P08-1117 </papid>for textual inference and (avramidis and koehn, 2008) <papid> P08-1087 </papid>for mt).</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
to achieve good performance, these parsers should be trained on large amounts of manually created training data from domain similar to that of the sentences they parse (lease and charniak, 2005; mcclosky and charniak, 2008).<papid> P08-2026 </papid></citsent>
<aftsection>
<nextsent>in the highly variable web, where many of these systems are used, it is very difficult to create representative corpus for manual annotation.
</nextsent>
<nextsent>the high cost of manual annotation of training data for supervised parsers imposes significant burden on their usage.a possible answer to this problem can be provided by high quality parses produced by unsupervised parsers that require little to no manual efforts for their training.
</nextsent>
<nextsent>these parses can be used either as input for applications, or as training material for modern supervised parsers whose output will in turn be used by applications.
</nextsent>
<nextsent>although unsupervised parser results improve, the quality of many of the parses they produce is still too low for such goals.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3481">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when requirements are relaxed, only asking for an f-score higher than 85%, percentage is still low, 42% for wsj10 and 15% for negra10.in this paper we address the task of fully unsupervised assessment of high quality parses cre 156 ated by an unsupervised parser.
</prevsent>
<prevsent>the assessment should be unsupervised in order to avoid the problems mentioned above with manually trained supervised parsers.
</prevsent>
</prevsection>
<citsent citstr=" W06-1604 ">
assessing the quality of learning algorithms output and selecting high quality instance shas been addressed for supervised algorithms (caru ana and niculescu-mizil, 2006) and specifically for supervised parsers (yates et al, 2006; <papid> W06-1604 </papid>reichart and rappoport, 2007; <papid> P07-1052 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>ravi et al, 2008).<papid> D08-1093 </papid></citsent>
<aftsection>
<nextsent>moreover, it has been shownto be valuable for supervised parser adaptation between domains (sagae and tsujii, 2007; <papid> D07-1111 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>chen et al, 2008).<papid> C08-1015 </papid></nextsent>
<nextsent>however, as far as we know the present paper is the first to address the task of unsupervised assessment of the quality of parses created by unsupervised parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3483">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when requirements are relaxed, only asking for an f-score higher than 85%, percentage is still low, 42% for wsj10 and 15% for negra10.in this paper we address the task of fully unsupervised assessment of high quality parses cre 156 ated by an unsupervised parser.
</prevsent>
<prevsent>the assessment should be unsupervised in order to avoid the problems mentioned above with manually trained supervised parsers.
</prevsent>
</prevsection>
<citsent citstr=" P07-1052 ">
assessing the quality of learning algorithms output and selecting high quality instance shas been addressed for supervised algorithms (caru ana and niculescu-mizil, 2006) and specifically for supervised parsers (yates et al, 2006; <papid> W06-1604 </papid>reichart and rappoport, 2007; <papid> P07-1052 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>ravi et al, 2008).<papid> D08-1093 </papid></citsent>
<aftsection>
<nextsent>moreover, it has been shownto be valuable for supervised parser adaptation between domains (sagae and tsujii, 2007; <papid> D07-1111 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>chen et al, 2008).<papid> C08-1015 </papid></nextsent>
<nextsent>however, as far as we know the present paper is the first to address the task of unsupervised assessment of the quality of parses created by unsupervised parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3486">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when requirements are relaxed, only asking for an f-score higher than 85%, percentage is still low, 42% for wsj10 and 15% for negra10.in this paper we address the task of fully unsupervised assessment of high quality parses cre 156 ated by an unsupervised parser.
</prevsent>
<prevsent>the assessment should be unsupervised in order to avoid the problems mentioned above with manually trained supervised parsers.
</prevsent>
</prevsection>
<citsent citstr=" I08-2097 ">
assessing the quality of learning algorithms output and selecting high quality instance shas been addressed for supervised algorithms (caru ana and niculescu-mizil, 2006) and specifically for supervised parsers (yates et al, 2006; <papid> W06-1604 </papid>reichart and rappoport, 2007; <papid> P07-1052 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>ravi et al, 2008).<papid> D08-1093 </papid></citsent>
<aftsection>
<nextsent>moreover, it has been shownto be valuable for supervised parser adaptation between domains (sagae and tsujii, 2007; <papid> D07-1111 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>chen et al, 2008).<papid> C08-1015 </papid></nextsent>
<nextsent>however, as far as we know the present paper is the first to address the task of unsupervised assessment of the quality of parses created by unsupervised parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3488">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when requirements are relaxed, only asking for an f-score higher than 85%, percentage is still low, 42% for wsj10 and 15% for negra10.in this paper we address the task of fully unsupervised assessment of high quality parses cre 156 ated by an unsupervised parser.
</prevsent>
<prevsent>the assessment should be unsupervised in order to avoid the problems mentioned above with manually trained supervised parsers.
</prevsent>
</prevsection>
<citsent citstr=" D08-1093 ">
assessing the quality of learning algorithms output and selecting high quality instance shas been addressed for supervised algorithms (caru ana and niculescu-mizil, 2006) and specifically for supervised parsers (yates et al, 2006; <papid> W06-1604 </papid>reichart and rappoport, 2007; <papid> P07-1052 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>ravi et al, 2008).<papid> D08-1093 </papid></citsent>
<aftsection>
<nextsent>moreover, it has been shownto be valuable for supervised parser adaptation between domains (sagae and tsujii, 2007; <papid> D07-1111 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>chen et al, 2008).<papid> C08-1015 </papid></nextsent>
<nextsent>however, as far as we know the present paper is the first to address the task of unsupervised assessment of the quality of parses created by unsupervised parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3490">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the assessment should be unsupervised in order to avoid the problems mentioned above with manually trained supervised parsers.
</prevsent>
<prevsent>assessing the quality of learning algorithms output and selecting high quality instance shas been addressed for supervised algorithms (caru ana and niculescu-mizil, 2006) and specifically for supervised parsers (yates et al, 2006; <papid> W06-1604 </papid>reichart and rappoport, 2007; <papid> P07-1052 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>ravi et al, 2008).<papid> D08-1093 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
moreover, it has been shownto be valuable for supervised parser adaptation between domains (sagae and tsujii, 2007; <papid> D07-1111 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>chen et al, 2008).<papid> C08-1015 </papid></citsent>
<aftsection>
<nextsent>however, as far as we know the present paper is the first to address the task of unsupervised assessment of the quality of parses created by unsupervised parsers.
</nextsent>
<nextsent>our pos-based unsupervised parse assessment(pupa) algorithm uses statistics about pos tag sequences in batch of parsed sentences1.
</nextsent>
<nextsent>the constituents in the batch are represented using the pos sequences of their yield and of the yields of neighboring constituents.
</nextsent>
<nextsent>constituents whose representation is frequent in the output of the parser are considered to be of high quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3493">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the assessment should be unsupervised in order to avoid the problems mentioned above with manually trained supervised parsers.
</prevsent>
<prevsent>assessing the quality of learning algorithms output and selecting high quality instance shas been addressed for supervised algorithms (caru ana and niculescu-mizil, 2006) and specifically for supervised parsers (yates et al, 2006; <papid> W06-1604 </papid>reichart and rappoport, 2007; <papid> P07-1052 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>ravi et al, 2008).<papid> D08-1093 </papid></prevsent>
</prevsection>
<citsent citstr=" C08-1015 ">
moreover, it has been shownto be valuable for supervised parser adaptation between domains (sagae and tsujii, 2007; <papid> D07-1111 </papid>kawahara and uchimoto, 2008; <papid> I08-2097 </papid>chen et al, 2008).<papid> C08-1015 </papid></citsent>
<aftsection>
<nextsent>however, as far as we know the present paper is the first to address the task of unsupervised assessment of the quality of parses created by unsupervised parsers.
</nextsent>
<nextsent>our pos-based unsupervised parse assessment(pupa) algorithm uses statistics about pos tag sequences in batch of parsed sentences1.
</nextsent>
<nextsent>the constituents in the batch are represented using the pos sequences of their yield and of the yields of neighboring constituents.
</nextsent>
<nextsent>constituents whose representation is frequent in the output of the parser are considered to be of high quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3495">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>2www.seggu.net/ccl.
</prevsent>
<prevsent>the-art results without using manually created postags.
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
the pos tags we use are induced by the unsupervised tagger of (clark, 2003)<papid> E03-1009 </papid>3.</citsent>
<aftsection>
<nextsent>since both tagger and parser do not require any manual annotation,pupa identifies high quality parses without any human involvement.
</nextsent>
<nextsent>the incremental parser of (seginer, 2007) <papid> P07-1049 </papid>does not give any prediction of its output quality, and extracting such prediction from its internal data structures is not straightforward.</nextsent>
<nextsent>such prediction can be given by supervised parsers in terms of the parse likelihood, but this was shown to be of medium quality (reichart and rappoport, 2007).<papid> P07-1052 </papid>while the algorithms of yates et al (2006), <papid> W06-1604 </papid>kawahara and uchimoto (2008) <papid> I08-2097 </papid>and ravi et al (2008) <papid> D08-1093 </papid>are supervised (section 3), the ensemble based sepa algorithm (reichart and rappoport, 2007) <papid> P07-1052 </papid>can be applied to unsupervised parsers in way that preserves the unsupervised nature of the selection task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3550">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the first work, high quality parses were selected using an ensemble method, while in the second binary classifier was used (see above).
</prevsent>
<prevsent>the first system achieved the highest score in the conll2007 shared task on domain adaptation of dependency parsers, and the second system improved over the basic self-training protocol.
</prevsent>
</prevsection>
<citsent citstr=" J07-1003 ">
chen et al (2008)<papid> C08-1015 </papid>parsed target domain sentences and used short dependencies information, which is often accurate, to adapt dependency parser to the chinese language.automatic quality assessment has been extensively explored for machine translation (ueffing and ney, 2007) <papid> J07-1003 </papid>and speech recognition (koo et al, 2001).</citsent>
<aftsection>
<nextsent>other nlp tasks where it has been explored include semi-supervised relation extraction (rosenfeld and feldman, 2007), <papid> P07-1076 </papid>ie (culotta and mccallum, 2004), <papid> N04-4028 </papid>qa (chu-carroll et al, 2003), and dialog systems (lin and weng, 2008).<papid> P08-2055 </papid></nextsent>
<nextsent>the idea of representing constituent by its yield 160 and (a different definition of) context is used by theccm unsupervised parsing model (klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3551">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the first system achieved the highest score in the conll2007 shared task on domain adaptation of dependency parsers, and the second system improved over the basic self-training protocol.
</prevsent>
<prevsent>chen et al (2008)<papid> C08-1015 </papid>parsed target domain sentences and used short dependencies information, which is often accurate, to adapt dependency parser to the chinese language.automatic quality assessment has been extensively explored for machine translation (ueffing and ney, 2007) <papid> J07-1003 </papid>and speech recognition (koo et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" P07-1076 ">
other nlp tasks where it has been explored include semi-supervised relation extraction (rosenfeld and feldman, 2007), <papid> P07-1076 </papid>ie (culotta and mccallum, 2004), <papid> N04-4028 </papid>qa (chu-carroll et al, 2003), and dialog systems (lin and weng, 2008).<papid> P08-2055 </papid></citsent>
<aftsection>
<nextsent>the idea of representing constituent by its yield 160 and (a different definition of) context is used by theccm unsupervised parsing model (klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>as far as we know the current work isthe first to use unsupervised pos tags for the selection of high quality parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3552">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the first system achieved the highest score in the conll2007 shared task on domain adaptation of dependency parsers, and the second system improved over the basic self-training protocol.
</prevsent>
<prevsent>chen et al (2008)<papid> C08-1015 </papid>parsed target domain sentences and used short dependencies information, which is often accurate, to adapt dependency parser to the chinese language.automatic quality assessment has been extensively explored for machine translation (ueffing and ney, 2007) <papid> J07-1003 </papid>and speech recognition (koo et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" N04-4028 ">
other nlp tasks where it has been explored include semi-supervised relation extraction (rosenfeld and feldman, 2007), <papid> P07-1076 </papid>ie (culotta and mccallum, 2004), <papid> N04-4028 </papid>qa (chu-carroll et al, 2003), and dialog systems (lin and weng, 2008).<papid> P08-2055 </papid></citsent>
<aftsection>
<nextsent>the idea of representing constituent by its yield 160 and (a different definition of) context is used by theccm unsupervised parsing model (klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>as far as we know the current work isthe first to use unsupervised pos tags for the selection of high quality parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3553">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the first system achieved the highest score in the conll2007 shared task on domain adaptation of dependency parsers, and the second system improved over the basic self-training protocol.
</prevsent>
<prevsent>chen et al (2008)<papid> C08-1015 </papid>parsed target domain sentences and used short dependencies information, which is often accurate, to adapt dependency parser to the chinese language.automatic quality assessment has been extensively explored for machine translation (ueffing and ney, 2007) <papid> J07-1003 </papid>and speech recognition (koo et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" P08-2055 ">
other nlp tasks where it has been explored include semi-supervised relation extraction (rosenfeld and feldman, 2007), <papid> P07-1076 </papid>ie (culotta and mccallum, 2004), <papid> N04-4028 </papid>qa (chu-carroll et al, 2003), and dialog systems (lin and weng, 2008).<papid> P08-2055 </papid></citsent>
<aftsection>
<nextsent>the idea of representing constituent by its yield 160 and (a different definition of) context is used by theccm unsupervised parsing model (klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>as far as we know the current work isthe first to use unsupervised pos tags for the selection of high quality parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3557">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> evaluation setup.  </section>
<citcontext>
<prevsection>
<prevsent>in the second measure, the constituent f-score of each of the parses in the set is computed, and then results are averaged.there are applications that use individual constituents from the output of parser while other sneed the whole parse tree.
</prevsent>
<prevsent>for example, if these lected set is used for training supervised parsers such as the collins parser (collins, 1999), which collects constituent statistics, the constituent f-score of the selected set is the important measure.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
in applications such as the syntax based machine translation model of (yamada and knight, 2001), <papid> P01-1067 </papid>low quality tree might lead to errorenous translation of the sentence.</citsent>
<aftsection>
<nextsent>for such applications the average f-score is more indicative.
</nextsent>
<nextsent>these measures thus represent complementary aspects of set quality and we consider both of them.
</nextsent>
<nextsent>the parser we use is the incremental parser of(seginer, 2007), <papid> P07-1049 </papid>pos tags are induced using the unsupervised pos tagger of ((clark, 2003)<papid> E03-1009 </papid>, ney essen morph model).</nextsent>
<nextsent>in each experiment, the tagger was trained with the raw sentences of the experiment corpus, and then the corpus words were pos tagged.the output of the unsupervised pos tagger depends on random initialization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3561">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>for future work, we intend to use parses selected by pupa from the output of unsupervised parsers as training data for supervised parsers, and in nlp applications that use parse trees.
</prevsent>
<prevsent>a challenge forthe first direction is the fact that state of the art supervised parsers require labeled parse trees, while modern unsupervised parsers create unlabeled trees.
</prevsent>
</prevsection>
<citsent citstr=" P06-1111 ">
combining pupa with algorithms for labeled parse trees induction (haghighi and klein, 2006; <papid> P06-1111 </papid>reichart and rappoport, 2008) <papid> C08-1091 </papid>is one direction to overcome this challenge.</citsent>
<aftsection>
<nextsent>we also intend to use pupa to assess the quality of parses created by supervised parsers.
</nextsent>
<nextsent>163
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3562">
<title id=" W09-1120.xml">automatic selection of high quality parses created by a fully unsupervised parser </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>for future work, we intend to use parses selected by pupa from the output of unsupervised parsers as training data for supervised parsers, and in nlp applications that use parse trees.
</prevsent>
<prevsent>a challenge forthe first direction is the fact that state of the art supervised parsers require labeled parse trees, while modern unsupervised parsers create unlabeled trees.
</prevsent>
</prevsection>
<citsent citstr=" C08-1091 ">
combining pupa with algorithms for labeled parse trees induction (haghighi and klein, 2006; <papid> P06-1111 </papid>reichart and rappoport, 2008) <papid> C08-1091 </papid>is one direction to overcome this challenge.</citsent>
<aftsection>
<nextsent>we also intend to use pupa to assess the quality of parses created by supervised parsers.
</nextsent>
<nextsent>163
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3563">
<title id=" W09-0701.xml">collecting and evaluating speech recognition corpora for nine southern bantu languages </title>
<section> initial asr results.  </section>
<citcontext>
<prevsection>
<prevsent>cepstral mean normalisation (cmn) as well as cepstral variance normalisation (cmv) are used to perform speaker independent normalisation.
</prevsent>
<prevsent>a diagonal covariancematrix is used; to partially compensate for this incorrect assumption of feature independence semi tied transforms are applied.
</prevsent>
</prevsection>
<citsent citstr=" L08-1497 ">
a flat phone-based language model is employed throughout.as rough benchmark of acceptable phonemerecognition accuracy, recently reported results obtained by (morales et al, 2008) <papid> L08-1497 </papid>on similar-sized telephone corpus in american english (n-timit) are also shown in tab.</citsent>
<aftsection>
<nextsent>2.
</nextsent>
<nextsent>we see that the lwazi results compare very well with this benchmark.
</nextsent>
<nextsent>an important issue in asr corpus design is 6 figure 3: effective distances in terms of the mean of the bhattacharyya bound between single phoneme (/n/-nbl top and /a/-nbl bottom) and each of its closest matches within the set of phonemes investigated.
</nextsent>
<nextsent>language % corr % acc avg # total # phons speakers isi ndebele 74.21 65.41 28.66 200 isi xhosa 69.25 57.24 17.79 210 isizulu 71.18 60.95 23.42 201 tshivenda 76.37 66.78 19.53 201 sepedi 66.44 55.19 16.45 199 sesotho 68.17 54.79 18.57 200 setswana 69.00 56.19 20.85 207 siswati 74.19 64.46 30.66 208 xitsonga 70.32 59.41 14.35 199n-timit 64.07 55.73 - table 2: initial results for south african asr systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3564">
<title id=" W09-1010.xml">comparing learners for boolean partitions implications for morphological paradigms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, show that problem of learning morphological paradigm is similar to problem of learning partition of the space of boolean functions.
</prevsent>
<prevsent>i describe several learners that solve this problem in different ways, and compare their basic properties.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
lately, there has been lot of work on acquiring paradigms as part of the word-segmentation problem (zeman, 2007; goldsmith, 2001; <papid> J01-2001 </papid>snover et al, 2002).<papid> W02-0602 </papid></citsent>
<aftsection>
<nextsent>however, the problem of learning the distribution of affixes within paradigms as function of their semantic (or syntactic) features ismuch less explored to my knowledge.
</nextsent>
<nextsent>this problem can be described as follows: suppose that the segmentation has already been established.
</nextsent>
<nextsent>can we now predict what affixes should appear inwhat contexts, where by context?
</nextsent>
<nextsent>i mean something quite general: some specification of semantic (and/or syntactic) features of the utterance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3565">
<title id=" W09-1010.xml">comparing learners for boolean partitions implications for morphological paradigms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, show that problem of learning morphological paradigm is similar to problem of learning partition of the space of boolean functions.
</prevsent>
<prevsent>i describe several learners that solve this problem in different ways, and compare their basic properties.
</prevsent>
</prevsection>
<citsent citstr=" W02-0602 ">
lately, there has been lot of work on acquiring paradigms as part of the word-segmentation problem (zeman, 2007; goldsmith, 2001; <papid> J01-2001 </papid>snover et al, 2002).<papid> W02-0602 </papid></citsent>
<aftsection>
<nextsent>however, the problem of learning the distribution of affixes within paradigms as function of their semantic (or syntactic) features ismuch less explored to my knowledge.
</nextsent>
<nextsent>this problem can be described as follows: suppose that the segmentation has already been established.
</nextsent>
<nextsent>can we now predict what affixes should appear inwhat contexts, where by context?
</nextsent>
<nextsent>i mean something quite general: some specification of semantic (and/or syntactic) features of the utterance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3566">
<title id=" W08-1908.xml">extracting sense trees from the romanian thesaurus by sense segmentation x26 dependency parsing </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>parsing, dssd looks for and succeeds to separate the two essential processes within dictionary entry pars ing: sense tree construction and sense definition parsing.
</prevsent>
<prevsent>the key tools to accomplish the task of (autonomous) sense tree building consist in defining the dictionary sense marker classes, establishing tree-like hierarchy of these classes, and using proper searching procedure of sense markers within the dssd parsing algorithm.
</prevsent>
</prevsection>
<citsent citstr=" C88-1027 ">
a similar but more general approach, using the same techniques and data structures for (romanian) free text parsing is scd (segmentation-cohesion dependency) (curteanu; 1988, <papid> C88-1027 </papid>2006), which dssd is inspired from.</citsent>
<aftsection>
<nextsent>a dssd based parser is implemented in java, building currently 91% correct sense trees from dtlr (dicionarul tezaur al ? 2008.
</nextsent>
<nextsent>licensed under the creative commons attri bution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>limbii romne ? romanian language thesaurus) entries, with significant resources to improve and enlarge the dtlr lexical semantics analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3567">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in 2004 and 2005, the shared tasks were dedicated to semantic role labeling (srl) in monolingual setting (english).
</prevsent>
<prevsent>in 2006 and 2007 the shared tasks were devoted to the parsing of syntactic dependencies, using corpora from up to 13 languages.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
in 2008, the shared task(surdeanu et al, 2008) <papid> W08-2121 </papid>used unified dependency based formalism, which modeled both syntactic dependencies and semantic roles for english.</citsent>
<aftsection>
<nextsent>theconll-2009 shared task has built on the 2008 results by providing data for six more languages (catalan, chinese, czech, german, japanese and span ish) in addition to the original english1.
</nextsent>
<nextsent>it has thus naturally extended the path taken by the five most recent conll shared tasks.as in 2008, the conll-2009 shared task combined dependency parsing and the task of identifying and labeling semantic arguments of verbs (andother parts of speech whenever available).
</nextsent>
<nextsent>participants had to choose from two tasks: ? joint task (syntactic dependency parsing and semantic role labeling), or ? srl-only task (syntactic dependency parses have been provided by the organizers, usingstate-of-the art parsers for the individual lan guages).
</nextsent>
<nextsent>1there are some format changes and deviations from the 2008 task data specification; see sect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3572">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> lemma gold-standard lemma of form.  </section>
<citcontext>
<prevsection>
<prevsent>the number of empty lines (i.e. the number of sentences) equals the number of lines beginning with 1?.
</prevsent>
<prevsent>the data contain no spaces nor double tabs.some statistics on the data can be seen in tables 2, 3 and 4.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
whereas the training sizes of the data have not been that different as they were e.g. for the 2007 shared task on multilingual dependency parsing (nivre et al, 2007)<papid> D07-1096 </papid>6, substantial differences existed in the distribution of the predicates and arguments, the input features, the out-of-vocabulary rates, and other statistical characteristics of the data.</citsent>
<aftsection>
<nextsent>data sizes have been relatively uniform in all the datasets, with japanese having the smallest dataset 6http://nextens.uvt.nl/depparse-wiki/ data overview 6 containing data for srl annotation training.
</nextsent>
<nextsent>to compensate at least for the dependency parsing part, an additional, large japanese corpus with syntactic dependency annotation has been provided.
</nextsent>
<nextsent>the average sentence length, the vocabulary sizes for form and lemma fields and the oov rates characterize quite naturally the properties of there spective languages (in the domain of the training and evaluation data).
</nextsent>
<nextsent>it is no surprise that the formoov rate is the highest for czech, highly inflectional language, and that the lemma oov rate is the highest for german (as consequence of keeping compounds as single lemma).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3573">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> lemma gold-standard lemma of form.  </section>
<citcontext>
<prevsection>
<prevsent>et al, 2009), which gives full combined accuracy (plemma+ppos+pfeat) slightly under 96%.
</prevsent>
<prevsent>phead and pdeprel were generated by the (cross-trained) mst parser for czech (chu?
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
liu/edmonds algorithm, (mcdonald et al, 2005)), <papid> H05-1066 </papid>which has typical dependency accuracy around 85%.</citsent>
<aftsection>
<nextsent>the valency lexicon, converted from (hajic?
</nextsent>
<nextsent>et al, 2003), has four columns: 1.
</nextsent>
<nextsent>lemma (can occur several times in the lexicon, with different frames) 2.
</nextsent>
<nextsent>frame identifier (as found in the pred column) 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3576">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> lemma gold-standard lemma of form.  </section>
<citcontext>
<prevsection>
<prevsent>for the conll-2008 shared task evaluation, this corpus was extended by the task organizers to cover the subset of the brown corpus used as secondary testing dataset.
</prevsent>
<prevsent>from this corpus we only used ne boundaries to derive name 11dependencies between ne tokens, e.g., we create name dependency from mary to smith given the ne mention mary smith.?
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
proposition bank (propbank) ? the propbank annotation (palmer et al, 2005) <papid> J05-1004 </papid>classifies the arguments of all the main verbs in the penn treebank corpus, other than be.</citsent>
<aftsection>
<nextsent>arguments are numbered (arg0, arg1, . . .)
</nextsent>
<nextsent>based on lexical entries or frame files.
</nextsent>
<nextsent>different sets of arguments are assumed for different rolesets.
</nextsent>
<nextsent>dependent constituents that fall into categories independent of the lexical entries are classified as various types of adjuncts (argm-tmp, -adv, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3577">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> lemma gold-standard lemma of form.  </section>
<citcontext>
<prevsection>
<prevsent>different sets of arguments are assumed for different rolesets.
</prevsent>
<prevsent>dependent constituents that fall into categories independent of the lexical entries are classified as various types of adjuncts (argm-tmp, -adv, etc.).
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
nombank ? nombank annotation (meyers et al., 2004) <papid> W04-2705 </papid>uses essentially the same framework as propbank to annotate arguments of nouns.</citsent>
<aftsection>
<nextsent>differences between propbank and nombank stem from differences between noun and verb argument structure; differences in treatment ofnouns and verbs in the penn treebank; and differences in the sophistication of previous research about noun and verb argument structure.
</nextsent>
<nextsent>only the subset of nouns that take arguments are annotated in nombank and only subset of the non-argument siblings of nouns are marked as argm.
</nextsent>
<nextsent>the complete merging process and the conversion from the constituent representation to dependencies is detailed in (surdeanu et al, 2008).<papid> W08-2121 </papid></nextsent>
<nextsent>the main difference between the 2008 and 2009version of the corpora is the generation of word lemmas.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3580">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>o ly th sy st em th at ha e co rr es po di g pa pe in th pr ce ed in gs ar in cl de d. cr n ym u se d: sy ta ct ic de pe de ci es , pr ed ic at e, ar gu en t,i id en tifi ca tio , cl as sifi ca tio . v er ll rc h. st an ds fo th co pl et sy st em ar ch ite ct re ;d rc h. st an ds fo th ar ch ite ct re ft he sy ta ct ic pa rs er ;d o b. in di ca te if th final pa rs er u tp tw as ge er at ed sin pa rs er co bi at io ;d in fe re ce st an ds fo th ty pe fi fe re ce se fo sy ta ct ic pa rs in g; pa rc h. st an ds th ty pe fa rc hi te ct re se fo pa ic ;p c m b. in di ca te if th pa u tp t as ge er at ed th ro gh sy st em co bi at io ;p in fe re ce st an ds fo th th ty pe fi fe re ce se fo pa ic ;j in tl ea rn in g/ pt . in di ca te if so e fo rm fjo in tl ea rn in o o pt im iz at io w as im pl em en te fo th sy ta ct ic + se antic gl ba lt as k; l et ho ds lists th m m et ho ds se th ro gh u tt he co pl et sy st em . a th rs ft o sy st em s: ? ro n ? an ? li ? di dn ? ts bm it pa pe r, so th ei sy st em s?
</prevsent>
<prevsent>ar ch ite ct re ar u kn ow . t he sy bo l+ in di ca te se qu en tia lp ro ce ss in (ot he rw ise , pa ra lle l/jo in t).
</prevsent>
</prevsection>
<citsent citstr=" D07-1101 ">
th || ea s th at se er al di ffe re ta rc hi te ct re sp an in m lti pl su bt as ks ra in pa ra lle l. m st l /e as se by cd n al (20 05 ), st by ca rr er as (20 07 ),<papid> D07-1101 </papid>m st by ei sn er (20 00 ), st o = st w ith hi gh er rd er fe at re (si bl in gs + al lg ra dc hi ld re ).</citsent>
<aftsection>
<nextsent>d he sy st em n ifi es th sy ta ct ic an se antic la be ls in to n la be l, an tr ai s cl as sifi er o er th em . it is th s di ffi cu lt to split th sy st em ch ar ac te ristic in to ? ? /?
</nextsent>
<nextsent>pa ? pa rt . 15 when comparing table 7 with the tables 5 and 6).
</nextsent>
<nextsent>this years task has been demanding in several respects, but certainly the most difficulty came fromthe fact that participants had to tackle all seven languages.
</nextsent>
<nextsent>it is encouraging that despite this added af fort the number of participating systems has been almost the same as last year (20 vs. 22 in 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3581">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>(llus et al,2009) present joint approach based on an extension of eisners parser to accommodate also semantic dependency labels.
</prevsent>
<prevsent>this architecture is similar to the one presented by the same authors in the past edition, with the extension to second-order syntactic parsing and particular setting for catalan and spanish.
</prevsent>
</prevsection>
<citsent citstr=" W09-1205 ">
(gesmundo et al, 2009) <papid> W09-1205 </papid>use an incremental parsing model with synchronous syntactic and semantic derivations and joint probability model for syntactic and semantic dependency struc tures.</citsent>
<aftsection>
<nextsent>the system uses single input queue but two separate stacks and synchronizes syntactic and semantic derivations at every word.
</nextsent>
<nextsent>the synchronous derivations are modeled with an incremental sig moid belief network that has latent variables for both syntactic and semantic states and connections from syntax to semantics and vice versa.
</nextsent>
<nextsent>(dai et al., 2009) <papid> W09-1202 </papid>designed an iterative system to exploit the inter-connections between the different subtasks of the conll shared task.</nextsent>
<nextsent>the idea is to decompose the joint learning problem into four subtasks?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3582">
<title id=" W09-1201.xml">the conll2009 shared task syntactic and semantic dependencies in multiple languages </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the system uses single input queue but two separate stacks and synchronizes syntactic and semantic derivations at every word.
</prevsent>
<prevsent>the synchronous derivations are modeled with an incremental sig moid belief network that has latent variables for both syntactic and semantic states and connections from syntax to semantics and vice versa.
</prevsent>
</prevsection>
<citsent citstr=" W09-1202 ">
(dai et al., 2009) <papid> W09-1202 </papid>designed an iterative system to exploit the inter-connections between the different subtasks of the conll shared task.</citsent>
<aftsection>
<nextsent>the idea is to decompose the joint learning problem into four subtasks?
</nextsent>
<nextsent>syntactic dependency identification, syntactic dependency labeling, semantic dependency identification and semantic dependency labeling.
</nextsent>
<nextsent>the initial step is to use pipeline approach to use the input ofone subtask as input to the next, in the order specified.
</nextsent>
<nextsent>the iterative steps then use additional features that are not available in the initial step to improve the accuracy of the overall system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3583">
<title id=" W09-1219.xml">a simple generative pipeline approach to dependency parsing and semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system was required to find the following information: ? parent (syntactic dependency) for each token 1 for more details on the two tasks and challenges, see haji et al.
</prevsent>
<prevsent>(2009).
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
label for each syntactic dependency (to ken) ? label for every predicate ? for every token (predicate or non predicate) and every predicate in the sentence, say whether there is semantic relation between and (a is an argument of p) and if so, provide label for the relation (role of the argument) the organizers of the shared task provided training and evaluation data (haji et al, 2006; surdeanu et al, 2008; <papid> W08-2121 </papid>burchardt et al, 2006; taul?</citsent>
<aftsection>
<nextsent>et al., 2008; kawahara et al, 2002; xue and palmer, 2009) converted to uniform conll shared task format.
</nextsent>
<nextsent>the system is sequence of three components: surface syntactic parser, syntactic tagger that assigns labels to the syntactic dependencies and semantic classifier (labels both the predicates and the roles of their arguments).
</nextsent>
<nextsent>we did not attempt to gain advantage from training joint classifier for all the subtasks.
</nextsent>
<nextsent>we did not have time to do much beyond putting together the basic infrastructure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3584">
<title id=" W09-1219.xml">a simple generative pipeline approach to dependency parsing and semantic role labeling </title>
<section> post-evaluation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we performed some preliminary experiments focused on the syntactic parser.
</prevsent>
<prevsent>as mentioned in section 2.1, many features of the parser have to be turned off unless the parser understands the part-of-speech and morphological features.
</prevsent>
</prevsection>
<citsent citstr=" L08-1429 ">
we used dz inter set (zeman, 2008) <papid> L08-1429 </papid>to convert czech and english conll pos+feat strings to pdt like positional tags.</citsent>
<aftsection>
<nextsent>then we switched back on the parser options that use up the tags and re-ran parsing.
</nextsent>
<nextsent>the results (table 6) confirm that the tag manipulation significantly improves czech parsing while it does not help with english.
</nextsent>
<nextsent>7 this is design flaw that we overlooked.
</nextsent>
<nextsent>most likely, making empty apred one of the predictable values would im prove accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3585">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experimental results show that the training time of our algorithm are about 50 times faster than support vector machines with polynomial kernel on the average while maintaining state of-the-art accuracy and faster classification speed.
</prevsent>
<prevsent>several boosting-based learning algorithms have been applied to natural language processing problems successfully.
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
these include text categorization (schapire and singer, 2000), natural language parsing (collins and koo, 2005), <papid> J05-1003 </papid>english syntactic chunking (kudo et al, 2005)<papid> P05-1024 </papid>and so on.</citsent>
<aftsection>
<nextsent>c ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.furthermore, classifiers based on boosting based learners have shown fast classification speed (kudo et al, 2005)<papid> P05-1024 </papid></nextsent>
<nextsent>however, boosting-based learning algorithms require long training time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3586">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experimental results show that the training time of our algorithm are about 50 times faster than support vector machines with polynomial kernel on the average while maintaining state of-the-art accuracy and faster classification speed.
</prevsent>
<prevsent>several boosting-based learning algorithms have been applied to natural language processing problems successfully.
</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
these include text categorization (schapire and singer, 2000), natural language parsing (collins and koo, 2005), <papid> J05-1003 </papid>english syntactic chunking (kudo et al, 2005)<papid> P05-1024 </papid>and so on.</citsent>
<aftsection>
<nextsent>c ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.furthermore, classifiers based on boosting based learners have shown fast classification speed (kudo et al, 2005)<papid> P05-1024 </papid></nextsent>
<nextsent>however, boosting-based learning algorithms require long training time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3593">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> fast rule learner.  </section>
<citcontext>
<prevsection>
<prevsent>) if ( u(f )   ?) continue; ## upper bound of gain foreach (f ? ) ## generate candidates k+1 = gen(f , f); if (?
</prevsent>
<prevsent>p i=1 [[f k+1 ? i ]]) k+1 = (f k+1 ? k+1 ); end foreach end foreach return weak-learner(f k+1 , s,w ); figure 3: find optimal feature-sets with given weights distributes features to subsets of features, called buckets, based on frequencies of features.
</prevsent>
</prevsection>
<citsent citstr=" D07-1033 ">
however, we guess training using subset of features depends on how to distribute features to buckets like online learning algorithms that generally depend on the order of the training examples (kazama and torisawa, 2007).<papid> D07-1033 </papid>to alleviate the dependency on selected buckets, we propose method that redistributes features, called weight-based distribution (w-dist).</citsent>
<aftsection>
<nextsent>w-dist redistributes features to buckets based on the weight of feature defined as r (f) = m i=1 r,i [[{f} ? i ]]for each ? after examining all buckets.
</nextsent>
<nextsent>figure 2 describes an overview of w-dist. 3.3 weak learner for learning several rules.
</nextsent>
<nextsent>we propose weak learner that learns several rules from small portion of candidate rules.
</nextsent>
<nextsent>figure 3 describes an overview of the weak learner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3598">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> pos tagging and text chunking.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 english pos tagging.
</prevsent>
<prevsent>we used the penn wall street journal treebank (marcus et al, 1994).
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we split the treebank into training (sections 0-18), development (sections 19 21) and test (sections 22-24) as in (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>we used the following candidate pos tags, called candidate feature, in addition to commonly used features (gimenez and m`arquez, 2003; toutanova et al, 2003) <papid> N03-1033 </papid>shown in figure 5.</nextsent>
<nextsent>we collect candidate pos tags of each word from the automatically tagged corpus provided forthe shared task of english named entity recognition in conll 2003.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3599">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> pos tagging and text chunking.  </section>
<citcontext>
<prevsection>
<prevsent>we used the penn wall street journal treebank (marcus et al, 1994).
</prevsent>
<prevsent>we split the treebank into training (sections 0-18), development (sections 19 21) and test (sections 22-24) as in (collins, 2002).<papid> W02-1001 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
we used the following candidate pos tags, called candidate feature, in addition to commonly used features (gimenez and m`arquez, 2003; toutanova et al, 2003) <papid> N03-1033 </papid>shown in figure 5.</citsent>
<aftsection>
<nextsent>we collect candidate pos tags of each word from the automatically tagged corpus provided forthe shared task of english named entity recognition in conll 2003.
</nextsent>
<nextsent>4 the corpus includes 17,003,926 words with pos tags and chunk tags 4 http://www.cnts.ua.ac.be/conll2003 /ner/ ? words and pos tags in 5-word window.
</nextsent>
<nextsent>labels assigned to two words on the right.
</nextsent>
<nextsent>candidate chunk tags of words in 5-word window figure 6: feature types for text chunking annotated by pos tagger and text chunker.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3601">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> pos tagging and text chunking.  </section>
<citcontext>
<prevsection>
<prevsent>5 this task aims to identify 10 types of chunks, such as, np, vp and pp, and so on.
</prevsent>
<prevsent>the data consists of subsets of penn wall street journal treebank; training (sections 15-18) and test (section 20).
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
we prepared the development set from section 21 of the treebank as in (tsuruoka and tsujii, 2005).<papid> H05-1059 </papid></citsent>
<aftsection>
<nextsent>6 each base phrase consists of one word or more.to identify word chunks, we use ioe2 representation.
</nextsent>
<nextsent>the chunks are represented by the following tags: e-x is used for end word of chunk of class x. i-x is used for non-end word in an chunk.
</nextsent>
<nextsent>o is used for word outside of any chunk.
</nextsent>
<nextsent>for instance, ?[he] (np) [reckons] (vp) [the current account deficit] (np)...?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3602">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 experimental settings.
</prevsent>
<prevsent>we compared adaboost.sdf with support vector machines (svm).
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
svm has shown good performance on pos tagging (gimenez and m`arquez, 2003) and text chunking (kudo and matsumoto, 2001).<papid> N01-1025 </papid></citsent>
<aftsection>
<nextsent>furthermore, svm with polynomial kernel implicitly expands all feature combinations with out increasing the computational costs.
</nextsent>
<nextsent>thus, we compared adaboost.sdf with svm.
</nextsent>
<nextsent>8to evaluate the effectiveness of candidate features, we examined two types of experiments with candidate features and without them.
</nextsent>
<nextsent>we list the statics of training sets in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3603">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we measured testing speeds of taggers and chun kers based on rules or models listed in table 5.
</prevsent>
<prevsent>10we examined two types of fast classification algorithms for polynomial kernel: polynomial kernel inverted (pki) and polynomial kernel expanded (pke).
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
the pki leads to about 2 to 12 times improvements, and the pke leads to 30 to 300 compared with normal classification approach of svm (kudo and matsumoto, 2003).<papid> P03-1004 </papid></citsent>
<aftsection>
<nextsent>11 the pos-taggers based on adaboost.sdf, svm with pki, and svm with pke processed4,052 words, 159 words, and 1,676 words per second, respectively.
</nextsent>
<nextsent>the chunk ers based on these three methods processed 2,732 words, 113 words, and 1,718 words per second, respectively.
</nextsent>
<nextsent>10 we list average speeds of three times tests measured with machine with xeon 3.8 ghz cpu and 4 gb of memory.
</nextsent>
<nextsent>11 we use chunker yamcha for evaluating classification speeds based on pki or pke (http://www.chasen.org/taku/software/ yamcha/).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3609">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy obtained with models converted by pke are slightly lower than the accuracy obtained with their original models in our experiments.
</prevsent>
<prevsent>22 table 5: comparison with previous best results: (top : pos tagging, bottom: text chunking ) pos tagging ?=1 perceptron (collins, 2002) <papid> W02-1001 </papid>97.11 dep.</prevsent>
</prevsection>
<citsent citstr=" P07-1096 ">
networks (toutanova et al, 2003) <papid> N03-1033 </papid>97.24 svm (gimenez and m`arquez, 2003) 97.05 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>97.15 guided learning for bidirectional sequence classification (shen et al, 2007) <papid> P07-1096 </papid>97.33 adaboost.sdf with candidate features (?=2,?=1,?=100, w-dist) 97.32 adaboost.sdf with candidate features (?=2,?=10,?=10, f-dist) 97.32 svm with candidate features (c=0.1, d=2) 97.32 text chunking ?=1 regularized winnow + full parser output (zhang et al, 2001) 94.17 svm-voting (kudo and matsumoto, 2001) <papid> N01-1025 </papid>93.91 aso + unlabeled data (ando and zhang, 2005) <papid> P05-1001 </papid>94.39 crf+reranking(kudo et al, 2005)<papid> P05-1024 </papid>94.12 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>93.70 laso (approximate large margin update) (daume iii and marcu, 2005) 94.4 hysol (suzuki et al, 2007) <papid> D07-1083 </papid>94.36 adaboost.sdf with candidate featuers (?=2,?=1,?=?, w-dist) 94.32 adaboost.sdf with candidate featuers (?=2,?=10,?=10,w-dist) 94.30 svm with candidate features (c=1, d=2) 94.31one of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.</citsent>
<aftsection>
<nextsent>svm learns final hypothesis as linear combination of the training examples using some coefficients.
</nextsent>
<nextsent>in contrast, this boosting-based rule learner learns final hypothesis that is subset of candidate rules (kudo and matsumoto, 2004).<papid> W04-3239 </papid></nextsent>
<nextsent>6.1 comparison with previous best results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3612">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy obtained with models converted by pke are slightly lower than the accuracy obtained with their original models in our experiments.
</prevsent>
<prevsent>22 table 5: comparison with previous best results: (top : pos tagging, bottom: text chunking ) pos tagging ?=1 perceptron (collins, 2002) <papid> W02-1001 </papid>97.11 dep.</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
networks (toutanova et al, 2003) <papid> N03-1033 </papid>97.24 svm (gimenez and m`arquez, 2003) 97.05 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>97.15 guided learning for bidirectional sequence classification (shen et al, 2007) <papid> P07-1096 </papid>97.33 adaboost.sdf with candidate features (?=2,?=1,?=100, w-dist) 97.32 adaboost.sdf with candidate features (?=2,?=10,?=10, f-dist) 97.32 svm with candidate features (c=0.1, d=2) 97.32 text chunking ?=1 regularized winnow + full parser output (zhang et al, 2001) 94.17 svm-voting (kudo and matsumoto, 2001) <papid> N01-1025 </papid>93.91 aso + unlabeled data (ando and zhang, 2005) <papid> P05-1001 </papid>94.39 crf+reranking(kudo et al, 2005)<papid> P05-1024 </papid>94.12 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>93.70 laso (approximate large margin update) (daume iii and marcu, 2005) 94.4 hysol (suzuki et al, 2007) <papid> D07-1083 </papid>94.36 adaboost.sdf with candidate featuers (?=2,?=1,?=?, w-dist) 94.32 adaboost.sdf with candidate featuers (?=2,?=10,?=10,w-dist) 94.30 svm with candidate features (c=1, d=2) 94.31one of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.</citsent>
<aftsection>
<nextsent>svm learns final hypothesis as linear combination of the training examples using some coefficients.
</nextsent>
<nextsent>in contrast, this boosting-based rule learner learns final hypothesis that is subset of candidate rules (kudo and matsumoto, 2004).<papid> W04-3239 </papid></nextsent>
<nextsent>6.1 comparison with previous best results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3618">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy obtained with models converted by pke are slightly lower than the accuracy obtained with their original models in our experiments.
</prevsent>
<prevsent>22 table 5: comparison with previous best results: (top : pos tagging, bottom: text chunking ) pos tagging ?=1 perceptron (collins, 2002) <papid> W02-1001 </papid>97.11 dep.</prevsent>
</prevsection>
<citsent citstr=" D07-1083 ">
networks (toutanova et al, 2003) <papid> N03-1033 </papid>97.24 svm (gimenez and m`arquez, 2003) 97.05 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>97.15 guided learning for bidirectional sequence classification (shen et al, 2007) <papid> P07-1096 </papid>97.33 adaboost.sdf with candidate features (?=2,?=1,?=100, w-dist) 97.32 adaboost.sdf with candidate features (?=2,?=10,?=10, f-dist) 97.32 svm with candidate features (c=0.1, d=2) 97.32 text chunking ?=1 regularized winnow + full parser output (zhang et al, 2001) 94.17 svm-voting (kudo and matsumoto, 2001) <papid> N01-1025 </papid>93.91 aso + unlabeled data (ando and zhang, 2005) <papid> P05-1001 </papid>94.39 crf+reranking(kudo et al, 2005)<papid> P05-1024 </papid>94.12 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>93.70 laso (approximate large margin update) (daume iii and marcu, 2005) 94.4 hysol (suzuki et al, 2007) <papid> D07-1083 </papid>94.36 adaboost.sdf with candidate featuers (?=2,?=1,?=?, w-dist) 94.32 adaboost.sdf with candidate featuers (?=2,?=10,?=10,w-dist) 94.30 svm with candidate features (c=1, d=2) 94.31one of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.</citsent>
<aftsection>
<nextsent>svm learns final hypothesis as linear combination of the training examples using some coefficients.
</nextsent>
<nextsent>in contrast, this boosting-based rule learner learns final hypothesis that is subset of candidate rules (kudo and matsumoto, 2004).<papid> W04-3239 </papid></nextsent>
<nextsent>6.1 comparison with previous best results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3619">
<title id=" W08-2103.xml">a fast boosting based learner for feature rich tagging and chunking </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>networks (toutanova et al, 2003) <papid> N03-1033 </papid>97.24 svm (gimenez and m`arquez, 2003) 97.05 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>97.15 guided learning for bidirectional sequence classification (shen et al, 2007) <papid> P07-1096 </papid>97.33 adaboost.sdf with candidate features (?=2,?=1,?=100, w-dist) 97.32 adaboost.sdf with candidate features (?=2,?=10,?=10, f-dist) 97.32 svm with candidate features (c=0.1, d=2) 97.32 text chunking ?=1 regularized winnow + full parser output (zhang et al, 2001) 94.17 svm-voting (kudo and matsumoto, 2001) <papid> N01-1025 </papid>93.91 aso + unlabeled data (ando and zhang, 2005) <papid> P05-1001 </papid>94.39 crf+reranking(kudo et al, 2005)<papid> P05-1024 </papid>94.12 me based bidirectional inference (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>93.70 laso (approximate large margin update) (daume iii and marcu, 2005) 94.4 hysol (suzuki et al, 2007) <papid> D07-1083 </papid>94.36 adaboost.sdf with candidate featuers (?=2,?=1,?=?, w-dist) 94.32 adaboost.sdf with candidate featuers (?=2,?=10,?=10,w-dist) 94.30 svm with candidate features (c=1, d=2) 94.31one of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.</prevsent>
<prevsent>svm learns final hypothesis as linear combination of the training examples using some coefficients.</prevsent>
</prevsection>
<citsent citstr=" W04-3239 ">
in contrast, this boosting-based rule learner learns final hypothesis that is subset of candidate rules (kudo and matsumoto, 2004).<papid> W04-3239 </papid></citsent>
<aftsection>
<nextsent>6.1 comparison with previous best results.
</nextsent>
<nextsent>we list previous best results on english pos tagging and text chunking in table 5.
</nextsent>
<nextsent>these results obtained with the taggers and chunk ers based onadaboost.sdf and svm showed competitive measure with previous best results.
</nextsent>
<nextsent>these show that candidate features contribute to create state of-the-art taggers and chunkers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3628">
<title id=" W09-0203.xml">unsupervised classification with dependency based word spaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recently the distribution of the occurrence within simple patterns defined in the form of regular expressions that are supposed to capture explicit semantic relations was explored as the basis of distributional similarity (almuhareb and poesio, 2004).
</prevsent>
<prevsent>whereas dependency based semantic space shave been shown to surpass other word space models for number of problems (pad?
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
and lapata, 2007; lin, 1998), <papid> P98-2127 </papid>for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better (poesio and almuhareb, 2005<papid> W05-1003 </papid>b; almuhareb and poesio, 2005b).</citsent>
<aftsection>
<nextsent>we want to show that dependency based spaces also fare better in these tasks if the dependency relations used are selected reasonably.
</nextsent>
<nextsent>at the same time we want to show that such system can bebuilt with freely available components and with out the need to relyon the index of proprietary search engine vendor.
</nextsent>
<nextsent>we propose to use the web acquired data of the ukwac (ferraresi et al, 2008), which is huge but still manageable and comes in pre-cleaned version with html markup removed.
</nextsent>
<nextsent>it can easily be fed into parser like minipar which allows for the subsequent extraction of dependency relations of different types and complexity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3629">
<title id=" W09-0203.xml">unsupervised classification with dependency based word spaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recently the distribution of the occurrence within simple patterns defined in the form of regular expressions that are supposed to capture explicit semantic relations was explored as the basis of distributional similarity (almuhareb and poesio, 2004).
</prevsent>
<prevsent>whereas dependency based semantic space shave been shown to surpass other word space models for number of problems (pad?
</prevsent>
</prevsection>
<citsent citstr=" W05-1003 ">
and lapata, 2007; lin, 1998), <papid> P98-2127 </papid>for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better (poesio and almuhareb, 2005<papid> W05-1003 </papid>b; almuhareb and poesio, 2005b).</citsent>
<aftsection>
<nextsent>we want to show that dependency based spaces also fare better in these tasks if the dependency relations used are selected reasonably.
</nextsent>
<nextsent>at the same time we want to show that such system can bebuilt with freely available components and with out the need to relyon the index of proprietary search engine vendor.
</nextsent>
<nextsent>we propose to use the web acquired data of the ukwac (ferraresi et al, 2008), which is huge but still manageable and comes in pre-cleaned version with html markup removed.
</nextsent>
<nextsent>it can easily be fed into parser like minipar which allows for the subsequent extraction of dependency relations of different types and complexity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3632">
<title id=" W09-0203.xml">unsupervised classification with dependency based word spaces </title>
<section> word space construction.  </section>
<citcontext>
<prevsection>
<prevsent>the examples are slightly simplified versions of sentences found in ukwac.19 thus, an occurrence of any path, irrespective of length or grammatical relations that are involved, increases the count of the respective basis element by one.
</prevsent>
<prevsent>we implemented three different association functions, a, to transform the raw frequency counts and weight the influence of the different cooccurrences.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
we worked with an implementation of the log likelihood ratio (g-score) as proposed by dunning (1993) <papid> J93-1003 </papid>and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of curran and moens (2002).<papid> W02-0908 </papid></citsent>
<aftsection>
<nextsent>we also experimented with different frequency cutoffs removing dimensions that occur very frequently or very rarely.
</nextsent>
<nextsent>for all our experiments we used the ukwac cor pus1 to construct the word spaces, which was parsed using minipar.
</nextsent>
<nextsent>the latter provides lemma information, which we used as possible target and context words.
</nextsent>
<nextsent>the word vectors we built from this data were represented as pseudo documents inan inverted index.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3633">
<title id=" W09-0203.xml">unsupervised classification with dependency based word spaces </title>
<section> word space construction.  </section>
<citcontext>
<prevsection>
<prevsent>the examples are slightly simplified versions of sentences found in ukwac.19 thus, an occurrence of any path, irrespective of length or grammatical relations that are involved, increases the count of the respective basis element by one.
</prevsent>
<prevsent>we implemented three different association functions, a, to transform the raw frequency counts and weight the influence of the different cooccurrences.
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
we worked with an implementation of the log likelihood ratio (g-score) as proposed by dunning (1993) <papid> J93-1003 </papid>and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of curran and moens (2002).<papid> W02-0908 </papid></citsent>
<aftsection>
<nextsent>we also experimented with different frequency cutoffs removing dimensions that occur very frequently or very rarely.
</nextsent>
<nextsent>for all our experiments we used the ukwac cor pus1 to construct the word spaces, which was parsed using minipar.
</nextsent>
<nextsent>the latter provides lemma information, which we used as possible target and context words.
</nextsent>
<nextsent>the word vectors we built from this data were represented as pseudo documents inan inverted index.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3635">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 root-and-pattern morphology and.
</prevsent>
<prevsent>finite-state systems the special problems and challenges embodied by semitic languages have been recognized from the early days of applying finite-state methods to natural language morphological analysis.
</prevsent>
</prevsection>
<citsent citstr=" C88-1064 ">
the language model which finite-state methods have been most successful in describinga model where morphemes concatenate in mostly strict linear order does not translate con genially to the typeof root-and-pattern morphology found in e.g. arabic and hebrew (kataja and koskenniemi, 1988; <papid> C88-1064 </papid>lavie et al, 1988).</citsent>
<aftsection>
<nextsent>in arabic, as in most semitic languages, verb shave for long time been analyzed as consisting of three elements: (most often) triconsonan tal root, such as ktb (h. h ?), vowel pattern containing grammatical information such as voice (e.g. the vowel a) and derivational template, such as cvcvc indicating the class of the verb, all of which are interdigitated to build stem, such as katab (i.   ?).1 this stem is in turn subject tomore familiar morphological constructions including pre fixation and suffix ation, yielding information such as number, person, etc, such as kataba ( i.  j?), the third person singular masculine perfect form.
</nextsent>
<nextsent>the difficulty of capturing this interdigitationprocess is not an inherent shortcoming of finite state automata or transducers perse, but rather result of the methods that are commonly used to construct automata.
</nextsent>
<nextsent>regular expressions that contain operations such as concatenation, union, intersection, as well as morpho tactic descriptions through right-linear grammars offer an unwieldy functionality when it comes to inter leaving strings with one another in regulated way.
</nextsent>
<nextsent>but, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. beesley (1996, <papid> C96-1017 </papid>1998b,a)),the question of how to do it becomes one of construction, not feasibility.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3636">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difficulty of capturing this interdigitationprocess is not an inherent shortcoming of finite state automata or transducers perse, but rather result of the methods that are commonly used to construct automata.
</prevsent>
<prevsent>regular expressions that contain operations such as concatenation, union, intersection, as well as morpho tactic descriptions through right-linear grammars offer an unwieldy functionality when it comes to inter leaving strings with one another in regulated way.
</prevsent>
</prevsection>
<citsent citstr=" C96-1017 ">
but, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. beesley (1996, <papid> C96-1017 </papid>1998b,a)),the question of how to do it becomes one of construction, not feasibility.</citsent>
<aftsection>
<nextsent>1.2 multitape automata.
</nextsent>
<nextsent>one early approach, suggested by kay (1987) <papid> E87-1002 </papid>and later pursued in different variants by kiraz (1994), <papid> C94-1029 </papid>variants by kiraz (2000) <papid> J00-1006 </papid>among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with n-tape automaton, where tapes would carry precisely this inter leaving 1following auto segmental analyses, this paper assumes the model where the vocal ization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as cacac as is assumed more traditionally.</nextsent>
<nextsent>which analysis to choose largely matter of convenience, and the methods in this paper apply to either one.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3637">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. beesley (1996, <papid> C96-1017 </papid>1998b,a)),the question of how to do it becomes one of construction, not feasibility.</prevsent>
<prevsent>1.2 multitape automata.</prevsent>
</prevsection>
<citsent citstr=" E87-1002 ">
one early approach, suggested by kay (1987) <papid> E87-1002 </papid>and later pursued in different variants by kiraz (1994), <papid> C94-1029 </papid>variants by kiraz (2000) <papid> J00-1006 </papid>among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with n-tape automaton, where tapes would carry precisely this inter leaving 1following auto segmental analyses, this paper assumes the model where the vocal ization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as cacac as is assumed more traditionally.</citsent>
<aftsection>
<nextsent>which analysis to choose largely matter of convenience, and the methods in this paper apply to either one.
</nextsent>
<nextsent>19that is called for in semitic interdigitation.
</nextsent>
<nextsent>how ever, large-scale multitape solutions containing the magnitude of information in standard arabic dictionaries such as wehr (1979) have not been re ported.to our knowledge, two large-scale morphological analyzers for arabic that strive for reasonable completeness have been been built: one by xerox and one by tim buckwalter (buckwalter, 2004).
</nextsent>
<nextsent>the xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in beesley and karttunen (2003), while buck walters syst emis procedural approach written in perl which decomposes word and simultaneously consults lex ica for constraining the possible decompositions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3638">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. beesley (1996, <papid> C96-1017 </papid>1998b,a)),the question of how to do it becomes one of construction, not feasibility.</prevsent>
<prevsent>1.2 multitape automata.</prevsent>
</prevsection>
<citsent citstr=" C94-1029 ">
one early approach, suggested by kay (1987) <papid> E87-1002 </papid>and later pursued in different variants by kiraz (1994), <papid> C94-1029 </papid>variants by kiraz (2000) <papid> J00-1006 </papid>among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with n-tape automaton, where tapes would carry precisely this inter leaving 1following auto segmental analyses, this paper assumes the model where the vocal ization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as cacac as is assumed more traditionally.</citsent>
<aftsection>
<nextsent>which analysis to choose largely matter of convenience, and the methods in this paper apply to either one.
</nextsent>
<nextsent>19that is called for in semitic interdigitation.
</nextsent>
<nextsent>how ever, large-scale multitape solutions containing the magnitude of information in standard arabic dictionaries such as wehr (1979) have not been re ported.to our knowledge, two large-scale morphological analyzers for arabic that strive for reasonable completeness have been been built: one by xerox and one by tim buckwalter (buckwalter, 2004).
</nextsent>
<nextsent>the xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in beesley and karttunen (2003), while buck walters syst emis procedural approach written in perl which decomposes word and simultaneously consults lex ica for constraining the possible decompositions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3639">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. beesley (1996, <papid> C96-1017 </papid>1998b,a)),the question of how to do it becomes one of construction, not feasibility.</prevsent>
<prevsent>1.2 multitape automata.</prevsent>
</prevsection>
<citsent citstr=" J00-1006 ">
one early approach, suggested by kay (1987) <papid> E87-1002 </papid>and later pursued in different variants by kiraz (1994), <papid> C94-1029 </papid>variants by kiraz (2000) <papid> J00-1006 </papid>among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with n-tape automaton, where tapes would carry precisely this inter leaving 1following auto segmental analyses, this paper assumes the model where the vocal ization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as cacac as is assumed more traditionally.</citsent>
<aftsection>
<nextsent>which analysis to choose largely matter of convenience, and the methods in this paper apply to either one.
</nextsent>
<nextsent>19that is called for in semitic interdigitation.
</nextsent>
<nextsent>how ever, large-scale multitape solutions containing the magnitude of information in standard arabic dictionaries such as wehr (1979) have not been re ported.to our knowledge, two large-scale morphological analyzers for arabic that strive for reasonable completeness have been been built: one by xerox and one by tim buckwalter (buckwalter, 2004).
</nextsent>
<nextsent>the xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in beesley and karttunen (2003), while buck walters syst emis procedural approach written in perl which decomposes word and simultaneously consults lex ica for constraining the possible decompositions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3640">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such transductions seldom provide grammatical component-wise alignment information telling which parts of the unanalyzed words contribute to which parts of the grammatical information.
</prevsent>
<prevsent>particularly if morphemes signifying grammatical category are discontinuous, this information is difficult to provide naturally in finite-automaton based system without many tapes.
</prevsent>
</prevsection>
<citsent citstr=" W05-0703 ">
a multi-tape solution, on the other hand, 2two anonymous reviewers point out the work by habash et al (2005) <papid> W05-0703 </papid>and habash and rambow (2006) <papid> P06-1086 </papid>who report an effort to analyze arabic with such multitape system basedon work by kiraz (2000), <papid> J00-1006 </papid>work by kiraz (2001) that relies on custom algorithms devised for multitape alphabet.</citsent>
<aftsection>
<nextsent>although habash and rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above.
</nextsent>
<nextsent>these approaches also use small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the face of it appear to scale well to more than handful of tapes without special precautions.
</nextsent>
<nextsent>20 tinput a a a troot t tform form tptrn v v tpaff taffp +3p +masc +sg tvoc a tvocp +act . . .
</nextsent>
<nextsent>table 1: possible alignment of 8 tapes to capture arabic verbal morphology.can provide this information by virtue of its construction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3641">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such transductions seldom provide grammatical component-wise alignment information telling which parts of the unanalyzed words contribute to which parts of the grammatical information.
</prevsent>
<prevsent>particularly if morphemes signifying grammatical category are discontinuous, this information is difficult to provide naturally in finite-automaton based system without many tapes.
</prevsent>
</prevsection>
<citsent citstr=" P06-1086 ">
a multi-tape solution, on the other hand, 2two anonymous reviewers point out the work by habash et al (2005) <papid> W05-0703 </papid>and habash and rambow (2006) <papid> P06-1086 </papid>who report an effort to analyze arabic with such multitape system basedon work by kiraz (2000), <papid> J00-1006 </papid>work by kiraz (2001) that relies on custom algorithms devised for multitape alphabet.</citsent>
<aftsection>
<nextsent>although habash and rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above.
</nextsent>
<nextsent>these approaches also use small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the face of it appear to scale well to more than handful of tapes without special precautions.
</nextsent>
<nextsent>20 tinput a a a troot t tform form tptrn v v tpaff taffp +3p +masc +sg tvoc a tvocp +act . . .
</nextsent>
<nextsent>table 1: possible alignment of 8 tapes to capture arabic verbal morphology.can provide this information by virtue of its construction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3643">
<title id=" W09-0803.xml">revisiting multitape automata for semitic morphological analysis and generation </title>
<section> construction.  </section>
<citcontext>
<prevsection>
<prevsent>to give an overview of some of the subsequent constraints that are still necessary, we include here few descriptions and examples (where the starred(***) tape snippets exemplify illegal configura tions):?
</prevsent>
<prevsent>every root consonant has matching consonant on the input tape t1 a a a t2 t t1 a a a t2*** r ? vowel in the input which is matched by v in the pattern, must have corresponding vocal ization vowel t1 a a a t4 v v t7 a t1 a a a t4 v v t7*** i?
</prevsent>
</prevsection>
<citsent citstr=" W98-1007 ">
a position where there is symbol in the in put either has symbol in the pattern tape or symbol in the affix tape (but not both) t1 a a a t4 v v t5 t1 a a a t4 v v t5*** 7the idea to preserve the gemina tion in the grammar is similar to the solutions regarding gemina tion and spreading of forms ii, v, and ix documented in beesley (1998<papid> W98-1007 </papid>b) and habash and rambow (2006).<papid> P06-1086 </papid></citsent>
<aftsection>
<nextsent>23 4.4 the final automaton.
</nextsent>
<nextsent>as mentioned above, the symbols {t1, . . .
</nextsent>
<nextsent>, tn}are only used during construction of the automaton for the convenience of writing the grammar, and shall be removed after intersecting the base language with the rules languages.
</nextsent>
<nextsent>this is simple substitution tx ? , i.e. the empty string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3646">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, msa does not allow re-ordering.
</prevsent>
<prevsent>the translation edit rate (ter)(snover et al, 2006) produces an alignment between two strings and allows shifts of blocks of words.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
the availability of the ter software has made it easy to build high performance system combination baseline (rosti et al, 2007).<papid> P07-1040 </papid>the pair-wise ter alignment originally described by sim et al (2007) has various limitations.</citsent>
<aftsection>
<nextsent>first, the hypotheses are aligned independently against the skeleton which determines the word order of the output.
</nextsent>
<nextsent>the same word fromtwo different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling.
</nextsent>
<nextsent>rosti et al (2008)<papid> W08-0329 </papid>described an incremental ter alignment to mitigate these problems.</nextsent>
<nextsent>the incremental ter alignment used global order in which the hypotheses were aligned.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3648">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, the hypotheses are aligned independently against the skeleton which determines the word order of the output.
</prevsent>
<prevsent>the same word fromtwo different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling.
</prevsent>
</prevsection>
<citsent citstr=" W08-0329 ">
rosti et al (2008)<papid> W08-0329 </papid>described an incremental ter alignment to mitigate these problems.</citsent>
<aftsection>
<nextsent>the incremental ter alignment used global order in which the hypotheses were aligned.
</nextsent>
<nextsent>second, the ter software matches words with identical surface strings.
</nextsent>
<nextsent>the pairwise alignment methods proposed by ayan et al (2008), <papid> C08-1005 </papid>he et al (2008), <papid> D08-1011 </papid>and matusov et al (2006) <papid> E06-1005 </papid>are able to match also synonyms and words with identical stems.</nextsent>
<nextsent>third, the ter software uses setof heuristics which is not always optimal in determining the block shifts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3649">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the incremental ter alignment used global order in which the hypotheses were aligned.
</prevsent>
<prevsent>second, the ter software matches words with identical surface strings.
</prevsent>
</prevsection>
<citsent citstr=" C08-1005 ">
the pairwise alignment methods proposed by ayan et al (2008), <papid> C08-1005 </papid>he et al (2008), <papid> D08-1011 </papid>and matusov et al (2006) <papid> E06-1005 </papid>are able to match also synonyms and words with identical stems.</citsent>
<aftsection>
<nextsent>third, the ter software uses setof heuristics which is not always optimal in determining the block shifts.
</nextsent>
<nextsent>karakos et al (2008) <papid> P08-2021 </papid>proposed using inversion transduction grammars to produce different pair-wise alignments.</nextsent>
<nextsent>this paper is organized as follows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3650">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the incremental ter alignment used global order in which the hypotheses were aligned.
</prevsent>
<prevsent>second, the ter software matches words with identical surface strings.
</prevsent>
</prevsection>
<citsent citstr=" D08-1011 ">
the pairwise alignment methods proposed by ayan et al (2008), <papid> C08-1005 </papid>he et al (2008), <papid> D08-1011 </papid>and matusov et al (2006) <papid> E06-1005 </papid>are able to match also synonyms and words with identical stems.</citsent>
<aftsection>
<nextsent>third, the ter software uses setof heuristics which is not always optimal in determining the block shifts.
</nextsent>
<nextsent>karakos et al (2008) <papid> P08-2021 </papid>proposed using inversion transduction grammars to produce different pair-wise alignments.</nextsent>
<nextsent>this paper is organized as follows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3651">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the incremental ter alignment used global order in which the hypotheses were aligned.
</prevsent>
<prevsent>second, the ter software matches words with identical surface strings.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the pairwise alignment methods proposed by ayan et al (2008), <papid> C08-1005 </papid>he et al (2008), <papid> D08-1011 </papid>and matusov et al (2006) <papid> E06-1005 </papid>are able to match also synonyms and words with identical stems.</citsent>
<aftsection>
<nextsent>third, the ter software uses setof heuristics which is not always optimal in determining the block shifts.
</nextsent>
<nextsent>karakos et al (2008) <papid> P08-2021 </papid>proposed using inversion transduction grammars to produce different pair-wise alignments.</nextsent>
<nextsent>this paper is organized as follows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3652">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the pairwise alignment methods proposed by ayan et al (2008), <papid> C08-1005 </papid>he et al (2008), <papid> D08-1011 </papid>and matusov et al (2006) <papid> E06-1005 </papid>are able to match also synonyms and words with identical stems.</prevsent>
<prevsent>third, the ter software uses setof heuristics which is not always optimal in determining the block shifts.</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
karakos et al (2008) <papid> P08-2021 </papid>proposed using inversion transduction grammars to produce different pair-wise alignments.</citsent>
<aftsection>
<nextsent>this paper is organized as follows.
</nextsent>
<nextsent>a refined incremental alignment algorithm is described in section 2.
</nextsent>
<nextsent>experimental evaluation comparing the pair-wise and incremental ter alignment algorithms with the refined alignment algorithm on wmt09 system combination task is presented in section 3.
</nextsent>
<nextsent>conclusions and future work are presented in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3656">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> incremental hypothesis alignment.  </section>
<citcontext>
<prevsection>
<prevsent>the ter software assigns zero cost for matching tokens and cost of one for all errors including insertions, deletions, substitutions, and blockshifts.
</prevsent>
<prevsent>ayan et al (2008) <papid> C08-1005 </papid>modified the ter software to consider substitutions of synonyms with reduced cost.</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
recently, snover et al (2009) <papid> W09-0441 </papid>extended the ter algorithm in similar fashion to produce new evaluation metric, ter plus (terp), which allows tuning of the edit costs inorder to maximize correlation with human judg ment.</citsent>
<aftsection>
<nextsent>the incremental alignment with flexible matching uses wordnet (fellbaum, 1998) to find all possible synonyms and words with identical stems in set of hypotheses.
</nextsent>
<nextsent>substitutions involving synonyms and words with identical stems are considered with reduced cost of 0.2.
</nextsent>
<nextsent>2.3 modified shift heuristics.
</nextsent>
<nextsent>the ter is computed by trying shifts of blocks of words that have an exact match somewhere else in the reference in order to find re-ordering of the hypothesis with lower edit distance to the reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3659">
<title id=" W09-0409.xml">incremental hypothesis alignment with flexible matching for building confusion networks bbn system description for wmt09 system combination task </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the english bigram and 5-gram language models were interpolated from four lm components trained on the english monolingual europarl (45m tokens) and news (510m tokens) corpora, and the english sides ofthe news commentary (2m tokens) and gigafren (683m tokens) parallel corpora.
</prevsent>
<prevsent>the interpolation weights were tuned to minimize perplexity on news-dev2009 set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the system combination weights ? one for each system, lm weight, and word and null insertion penalties ? were tuned to maximize the bleu (papineni et al, 2002) <papid> P02-1040 </papid>score on the tuning set (newssyscomb2009).</citsent>
<aftsection>
<nextsent>since the system combination was performed on tokenized and lower cased outputs, trigram based true caser was trained on all news training data.
</nextsent>
<nextsent>the tuning may be summarized as follows: 1.
</nextsent>
<nextsent>tokenize and lowercase the outputs;.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3663">
<title id=" W08-2131.xml">discriminative vs generative approaches in semantic role labeling </title>
<section> syntactic dependencies.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 summarizes our results and suggests possible improvements.
</prevsent>
<prevsent>we used non-projective dependency parser based on spanning tree algorithms.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
the parameters were determined based on the experimental results of the english task in (mcdonald et al, 2005), <papid> P05-1012 </papid>i.e. we used projective parsing and first order feature set during training.</citsent>
<aftsection>
<nextsent>due to the new representation of hyphenated words in both training and testing data of our shared task and the absence of the gold partof speech (gpos) column in the test data, the format of the conll08 shared task is slightly different from the format of the conll05 shared task, which is supported by the mcdonalds parser.
</nextsent>
<nextsent>we reformatted the data accordingly.
</nextsent>
<nextsent>the resulting labeled attachment score on the test set is 87.39% for wsj and 80.46% for brown.
</nextsent>
<nextsent>our first approach to srl consists of four distinct stages: (1) predicate identification, (2) predicate labeling, (3) argument identification, and (4) argument labeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3664">
<title id=" W08-2131.xml">discriminative vs generative approaches in semantic role labeling </title>
<section> the 4-stage discriminative approach.  </section>
<citcontext>
<prevsection>
<prevsent>feature1 and fea ture2 are sparser than the other two features andare better features as they include lexical information.
</prevsent>
<prevsent>last two features are less sparse, covering most of the development data, i.e. their histograms give non-zero values in the development phase.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
in order to match all the instances in the development and use the semantic information, cascade of the features is implemented similar to the one done by gildea and jurafsky(2002), <papid> J02-3001 </papid>although no weighting and kind of back-off smoothing is used.</citsent>
<aftsection>
<nextsent>first, match is searched in the histogram of the first feature, if not found it is searched in the followinghistogram.
</nextsent>
<nextsent>after match, the most frequent argument with that match is returned.
</nextsent>
<nextsent>table 1 gives the performance (4-stage, verb4, noun4, all4).
</nextsent>
<nextsent>one problem with the four-stage approach is that the later stages provide no feedback to the earlier ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3665">
<title id=" W09-1312.xml">towards automatic generation of gene summary </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>table1.
</prevsent>
<prevsent>two examples of human-written gene summaries not include enough informative words for gene summaries.
</prevsent>
</prevsection>
<citsent citstr=" W04-3247 ">
next, the remaining sentences are ranked by the sum of two individual scores: a) an authority score from lexical page rank algorithm (erkan and radev, 2004) <papid> W04-3247 </papid>and b) similarity score between the sentence and the gene ontology (go) terms with which the gene is annotated (to date, over 190,000 genes have two or more associated go terms).</citsent>
<aftsection>
<nextsent>finally, redundant sentences are removed and top ranked sentences are nominated for the target gene.
</nextsent>
<nextsent>in order to evaluate our system, we assembled gold standard dataset consisting of handwritten summaries for 7,294 human genes and conducted an intrinsic evaluation by measuring the amount of overlap between the machine-selected sentences and human-written summaries.
</nextsent>
<nextsent>our metric for the evaluation was rouge1, widely used intrinsic summarization evaluation metric.
</nextsent>
<nextsent>summarization systems aim to extract salient text fragments, especially sentences, from the original documents to form summary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3669">
<title id=" W09-1312.xml">towards automatic generation of gene summary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>approaches based on sentence position (edmundson, 1969), cue phrase (mckeown and radev, 1995), word frequency (teufel and moens, 1997), and discourse segmentation (boguraev and kennedy, 1997) have been reported.
</prevsent>
<prevsent>radev et al (radev et al, 2004) developed an extractive multi document summarizer, mead, which extracts summary from multiple documents based on the document cluster centro id, position and first sentence overlap.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
recently, graph-based ranking methods, such as lexpagerank (erkan and radev, 2004) <papid> W04-3247 </papid>and text rank (mihalcea and tarau, 2004), <papid> W04-3252 </papid>1 http://haydn.isi.edu/rouge/ have been proposed for multi-document summari zation.</citsent>
<aftsection>
<nextsent>similar to the original page rank algorithm, these methods make use of similarity relationships between sentences and then rank sentences according to the votes?
</nextsent>
<nextsent>or recommendations?
</nextsent>
<nextsent>from their neighboring sentences.
</nextsent>
<nextsent>lin and hovy (2000) <papid> C00-1072 </papid>first introduced topic signatures which are topic relevant terms for summa rization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3670">
<title id=" W09-1312.xml">towards automatic generation of gene summary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>or recommendations?
</prevsent>
<prevsent>from their neighboring sentences.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
lin and hovy (2000) <papid> C00-1072 </papid>first introduced topic signatures which are topic relevant terms for summa rization.</citsent>
<aftsection>
<nextsent>afterwards, this technique was successfully used in number of summarization systems (hickl et al, 2007, gupta and nenkova et al., 2007).
</nextsent>
<nextsent>in order to improve sentence selection, we adopted the idea in similar way to identify terms that tend to appear frequently in gene summaries and subsequently filter sentences that include none or few such terms.
</nextsent>
<nextsent>compared with newswire document summarization, much less attention has been paid to summarizing medline documents for genic information.
</nextsent>
<nextsent>ling et al (ling et al, 2006 and 2007) presented an automatic gene summary generation system that constructs summary based on six aspects of gene, such as gene products, mutant phenotype, etc. in their system, sentences were ranked according to a) the relevance to each category (namely the aspect), b) the relevance to the document where they are from; and c) the position where sentences are located.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3675">
<title id=" W09-1312.xml">towards automatic generation of gene summary </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>although the length of reference summaries varies, the majority of these summaries contain 80 to 120 words.
</prevsent>
<prevsent>to produce summary of similar length, we decided to select five sentences consisting of about 100 words.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
for the intrinsic evaluation of large number of summaries, we made use of the rouge metrics that has been widely used in automatic evaluation of summarization systems (lin and hovy, 2003; <papid> N03-1020 </papid>hickl et al, 2007).</citsent>
<aftsection>
<nextsent>it provides set of evaluation metrics to measure the quality of summary by counting overlapping units such as n-grams or word sequences between the generated summary and its reference summary.
</nextsent>
<nextsent>5 ftp://ftp.ncbi.nih.gov/gene/data/asn_binary/ 102 we computed three rouge measures for each summary, namely rouge-1 (unigram based), rouge-2 (bigram based) and rouge-su4 (skip-bigram and unigram) (lin and hovy, 2003).<papid> N03-1020 </papid></nextsent>
<nextsent>among them, rouge-1 has been shown to agree most with human judgments (lin and hovy, 2003).<papid> N03-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3680">
<title id=" W08-1106.xml">extractive vs nlg based abs tractive summarization of evaluative text the effect of corpus controversiality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are two main approaches to the task of sum marizationextraction and abstraction (hahn and mani, 2000).
</prevsent>
<prevsent>extraction involves concatenating extracts taken from the corpus into summary, whereas abstraction involves generating novel sentences from information extracted from the corpus.
</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
it has been observed that in the context of multi document summarization of news articles, extraction may be inappropriate because it may produce summaries which are overly verbose or biased towards some sources (barzilay et al, 1999).<papid> P99-1071 </papid></citsent>
<aftsection>
<nextsent>how ever, there has been little work identifying specific factors which might affect the performance of each strategy in summarizing evaluative documents containing opinions and preferences, such as customer reviews or blogs.
</nextsent>
<nextsent>this work aims to address this gap by exploring one dimension along which the effectiveness of the two paradigms could vary; namely, the controversiality of the opinions contained in the corpus.in this paper, we make the following contributions.
</nextsent>
<nextsent>firstly, we define measure of controversiality of opinions in the corpus based on information entropy.
</nextsent>
<nextsent>secondly, we run user study to test the hypothesis that controversial corpus has greater need of abs tractive methods and consequently of nlg techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3681">
<title id=" W08-1106.xml">extractive vs nlg based abs tractive summarization of evaluative text the effect of corpus controversiality </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this method is used in our study for generating abs tractive summaries.the results of the user study support our hypothesis that nlg summarizer outperforms an extractive summarizer by more when the contro versiality is high.
</prevsent>
<prevsent>there has been little work comparing extractive and abs tractive multi-document summarization.
</prevsent>
</prevsection>
<citsent citstr=" E06-1039 ">
a previous study on summarizing evaluative text (carenini et. al, 2006) <papid> E06-1039 </papid>showed that extraction and abstraction performed about equally well, though for different reasons.</citsent>
<aftsection>
<nextsent>the study, however, did not 1authors are listed in alphabetical order.
</nextsent>
<nextsent>33look at the effect of the controversiality of the corpus on the relative performance of the two strate gies.to the best of our knowledge, the task of measuring the controversiality of opinions in corpus has not been studied before.
</nextsent>
<nextsent>some well known measures are related to this task, including variance, information entropy, and measures of inter rater reliability.
</nextsent>
<nextsent>(e.g. fleiss  kappa (fleiss, 1971), krippendorff alpha (krippendorff, 1980)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3682">
<title id=" W08-1106.xml">extractive vs nlg based abs tractive summarization of evaluative text the effect of corpus controversiality </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the design of the task may intrinsically favour abs tractive or extractive summarization.
</prevsent>
<prevsent>as an extreme example, asking for list of specific comments from users would clearly favour extractive summarization.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
another method for summary evaluation is the pyramid method (nenkova and passonneau, 2004), <papid> N04-1019 </papid>which takes into account the fact that human summaries with different content can be equally infor mative.</citsent>
<aftsection>
<nextsent>multiple human summaries are taken to be models, and chunks of meaning known as summary content units (scu) are manually identified.
</nextsent>
<nextsent>peer summaries are evaluated based on how many scus they share with the model summaries, and the number of model summaries in which these scus are found.
</nextsent>
<nextsent>although this method has been tested in duc 2006 and duc 2005 (passonneau et al., 2006), (passonneau et al, 2005) in the domain of news articles, it has not been tested for evaluative text.
</nextsent>
<nextsent>a pilot study that we conducted on set of customer reviews on product using the pyramid method revealed several problems specific to the evaluative domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3683">
<title id=" W08-1106.xml">extractive vs nlg based abs tractive summarization of evaluative text the effect of corpus controversiality </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>clearly, only one of these positions should be regarded as correct.
</prevsent>
<prevsent>further work is needed to resolve these problems.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
there are also automatic methods for summary evaluation, such as rouge (lin, 2004), <papid> W04-1013 </papid>which gives score based on the similarity in these quences of words between human-written model summary and the machine summary.</citsent>
<aftsection>
<nextsent>while rouge scores have been shown to often correlate quite well with human judgements (nenkova et al, 2007), they do not provide insights into the specific strengths and weaknesses of the summary.
</nextsent>
<nextsent>the method of summarization evaluation used in this work is to ask users to complete questionnaire about summaries that they are presented with.
</nextsent>
<nextsent>the questionnaire consists of questions asking for likert ratings and is adapted from the questionnaire in (carenini et al, 2006).<papid> E06-1039 </papid></nextsent>
<nextsent>in our user study, we compare an abs tractive and an extractive multi-document summarizer that are both developed specifically for the evaluative domain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3685">
<title id=" W08-1106.xml">extractive vs nlg based abs tractive summarization of evaluative text the effect of corpus controversiality </title>
<section> representative systems.  </section>
<citcontext>
<prevsection>
<prevsent>the questionnaire consists of questions asking for likert ratings and is adapted from the questionnaire in (carenini et al, 2006).<papid> E06-1039 </papid></prevsent>
<prevsent>in our user study, we compare an abs tractive and an extractive multi-document summarizer that are both developed specifically for the evaluative domain.</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
these summarizers have been found to produce quantitatively similar results, and both significantly outperform baseline summarizer, which is the mead summarization framework with all options set to the default (radev et al, 2000).<papid> W00-0403 </papid>both summarizers relyon information extraction from the corpus.</citsent>
<aftsection>
<nextsent>first, sentences with opinions need to be identified, along with the features of the entity that are evaluated, the strength, and polarity (positive or negative) of the evaluation.
</nextsent>
<nextsent>for instance, in corpus of customer reviews, the sentence excellent picture quality - on par with my pioneer, panasonic, and jvc players.?
</nextsent>
<nextsent>contains an opinion on the feature picture quality of dvd player, and is very positive evaluation (+3 on scale from -3 to +3).
</nextsent>
<nextsent>we relyon methods from previous work for these tasks (hu and liu, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3686">
<title id=" W08-1106.xml">extractive vs nlg based abs tractive summarization of evaluative text the effect of corpus controversiality </title>
<section> representative systems.  </section>
<citcontext>
<prevsection>
<prevsent>content selection consists of repeating the following two steps until the desired number of udfs have been selected: (i) greedily selecting the most important udf (ii) recalculating the measure of importance scores for the remaining udfs.the content structuring, micro planning, andre alization stages of sea are adapted from gea.
</prevsent>
<prevsent>each selected udf is realized in the final summary by one clause, generated from template pattern based on the number and distribution of polarity/strength evaluations of the udf.
</prevsent>
</prevsection>
<citsent citstr=" W00-1407 ">
for example, the udf video output with an average polarity/strength of near -3 might be realized as several customers found the video output to be terri ble.while experimenting with the sea summa riz er, we noticed that the document structuring of sea summaries, which is adapted from gea and is based on guidelines from argumentation theory (carenini and moore, 2000), <papid> W00-1407 </papid>sometimes sounded unnatural.</citsent>
<aftsection>
<nextsent>we found that controversially rated udf features (roughly balanced positive and negative evaluations) were treated as contrasts to those which were un controversially rated (either mostly positive, or mostly negative evaluations).
</nextsent>
<nextsent>in sea, contrast relations between features are realized by cue phrases signalling contrast such as however?
</nextsent>
<nextsent>and although?.
</nextsent>
<nextsent>these cue phrases appear to signal contrast that is too strong for the relation between controversial and uncontroversial features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3689">
<title id=" W08-2230.xml">addressing the resource bottleneck to create largescale annotated texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>375 376 chamberlain, poesio, and kruschwitz
</prevsent>
<prevsent>syntactically annotated language resources have long been around, but the greatest obstacle to progress towards systems able to extract semantic information from text is the lack of semantically annotated corpora large enough to be used to train an devaluate semantic interpretation methods.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
recent efforts to create resources to support large evaluation initiatives in the usa such as automatic context extraction (ace), trans lingual information detection, extraction and summarization (tides), and gale are beginning to change this, but just at point when the community is beginning to realize that even the 1m word annotated corpora created insubstantial efforts such as prop-bank (palmer et al, 2005) <papid> J05-1004 </papid>and the ontonotes initiative (hovy et al, 2006) are likely to be too small.</citsent>
<aftsection>
<nextsent>unfortunately, the creation of 100m-plus corpora via hand annotation is likely to be prohibitively expensive.
</nextsent>
<nextsent>such large hand-annotation effort would be even less sensible in the case of semantic annotation tasks such as coreference or word sense disambiguation, given on the one side the greater difficulty of agreeing on neutral?
</nextsent>
<nextsent>theoretical framework, on the other the difficulty of achieving more than moderate agreement on semantic judgments (poesio and artstein, 2005).<papid> W05-0311 </papid>the anawiki project1 presents an effort to create high-quality, large-scale anaphoric ally annotated resources (poesio et al, 2008) by taking advantage of the collaboration of the web community, both through co-operative annotation efforts using traditional annotation tools and through the use of game-like interfaces.</nextsent>
<nextsent>this makes anawiki very ambitious project.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3690">
<title id=" W08-2230.xml">addressing the resource bottleneck to create largescale annotated texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, the creation of 100m-plus corpora via hand annotation is likely to be prohibitively expensive.
</prevsent>
<prevsent>such large hand-annotation effort would be even less sensible in the case of semantic annotation tasks such as coreference or word sense disambiguation, given on the one side the greater difficulty of agreeing on neutral?
</prevsent>
</prevsection>
<citsent citstr=" W05-0311 ">
theoretical framework, on the other the difficulty of achieving more than moderate agreement on semantic judgments (poesio and artstein, 2005).<papid> W05-0311 </papid>the anawiki project1 presents an effort to create high-quality, large-scale anaphoric ally annotated resources (poesio et al, 2008) by taking advantage of the collaboration of the web community, both through co-operative annotation efforts using traditional annotation tools and through the use of game-like interfaces.</citsent>
<aftsection>
<nextsent>this makes anawiki very ambitious project.
</nextsent>
<nextsent>it is not clear to what extend expert annotations can in fact be substituted by those judgements submitted by the general public as partof game.
</nextsent>
<nextsent>if successful, anawiki will actually be more than just an anaphora annotation tool.
</nextsent>
<nextsent>we see it as framework aimed at creating large-scale annotated corpora in general.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3692">
<title id=" W08-2140.xml">applying sentence simplification to the conll2008 shared task </title>
<section> sentence simplification.  </section>
<citcontext>
<prevsection>
<prevsent>the main technical interest of our method is sentence simplification system.
</prevsent>
<prevsent>this system is described indepth in (vickrey and koller, 2008); for lack of space, we omit many details, including discussion of related work, from this paper.current semantic role labeling systems rely primarily on syntactic features in order to identify and classify roles.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
features derived from syntactic parse of the sentence have proven particularly useful (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>for example, the syntactic subject of eat?
</nextsent>
<nextsent>is nearly always the ? 2008.
</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3693">
<title id=" W08-1708.xml">towards domain independent deep linguistic processing ensuring portability and re usability of lexicalised grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on these findings, it has become clear that it is crucial to explore and develop efficient methods for automated (deep) lexical acquisition(henceforward (d)la), the process of automatically recovering missing entries in the lexicons of deep grammars.
</prevsent>
<prevsent>recently, various high-quality dla approaches have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" W05-1008 ">
(baldwin, 2005), <papid> W05-1008 </papid>as well as (zhang and kordoni, 2006), (van de cruys,2006) and (nicholson et al, 2008) describe efficient methods towards the task of lexicon acquisition for large-scale deep grammars for english,dutch and german.</citsent>
<aftsection>
<nextsent>they treat dla as classification task and make use of various robust and efficient machine learning techniques to perform the acquisition process.however, it is our claim that to achieve better and more practically useful results, apart from good learning algorithms, we also need to incorporate into the learning process fine-grained linguistic information which deep grammars inherently include and provide for.
</nextsent>
<nextsent>as we clearly show in the following, it is not sufficient to only develop and use good and complicated classification algorithms.
</nextsent>
<nextsent>we must look at the detailed linguistic information that is already included and provided for by the grammar itself and try to capture and makeas much use of it as possible, for this is the information we aim at learning when performing dla.
</nextsent>
<nextsent>57 in this way, the learning process is facilitated and at the same time it is as much as possible ensured that its outcome be linguistically more informative and, thus, practically more useful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3694">
<title id=" W08-1708.xml">towards domain independent deep linguistic processing ensuring portability and re usability of lexicalised grammars </title>
<section> coverage test with the gg.  </section>
<citcontext>
<prevsection>
<prevsent>in the experiments we report here two corpora of different kind and size have been used.
</prevsent>
<prevsent>the first one has been extracted from the frankfurter rundschau newspaper and contains about 614k sentences that have between 5 and 20 tokens.
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
the second corpus is subset of the german part of the wacky project (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></citsent>
<aftsection>
<nextsent>the wacky project aims at the creation of large corpora for different languages, including german,from various web sources, such as online newspapers and magazines, legal texts, internet fora,university and science web sites, etc. the german part, named dewac (web as corpus), contains about 93m sentences and 1.65 billion tokens.
</nextsent>
<nextsent>the subset used in our experiments is extracted by randomly selecting 2.57m sentences that have between 4 and 30 tokens.
</nextsent>
<nextsent>these corpora have been chosen because it is interesting to observe the grammar performance on relatively balanced newspaper corpus that does not include so many long sentences and sophisticated linguistic constructions and to compare it with the performance of the grammar on random open domain text corpus.
</nextsent>
<nextsent>the sentences are fed into the pet hpsg parser (callmeier, 2000) with the gg loaded.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3695">
<title id=" W08-1708.xml">towards domain independent deep linguistic processing ensuring portability and re usability of lexicalised grammars </title>
<section> dla experiments with the gg.  </section>
<citcontext>
<prevsection>
<prevsent>it is then mapped to most popular lexical type for that pos.
</prevsent>
<prevsent>table 5 shows the relevant mappings.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
pos majority lexical type noun count-noun-le - c-n-f verb trans-nerg-str-verb-le haben-auxf adj adj-non-prd-le adv intersect-adv-le table 5: pos tags to lexical types mapping again for comparison, we have built another simple baseline model using the tnt pos tagger(brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>tnt is general-purpose hmm based trigram tagger.
</nextsent>
<nextsent>we have trained the tagging models with all the lexical types as the tagset.
</nextsent>
<nextsent>the tagger tags the whole sentence but only the output tags for the unknown words are taken to generate lexical entries and to be considered for the evaluation.
</nextsent>
<nextsent>the precis ions of the different prediction models are given in table 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3696">
<title id=" W08-1508.xml">rapid portability among domains in an interactive spoken language translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as support for our approach, we apply our current slt system, now optimized for the healthcare domain, to sample utterances from the military, emergency service, and law enforcement domains, with discussion of numerous specific sentences.
</prevsent>
<prevsent>recent years have seen increasing research and commercial activity in the area of spoken language translation (slt) for mission-critical applications.
</prevsent>
</prevsection>
<citsent citstr=" W06-3706 ">
in the healthcare area, for instance, such products as converser (dillinger &amp; seligman, 2006), <papid> W06-3706 </papid>s-minds (www.fluentialinc.com), and med-slt (bouillon et al, 2005) are coming into use.</citsent>
<aftsection>
<nextsent>for military applications, products like phraselator (www.phraselator.com) and s-minds (www.fluentialinc.com) have been deployed.
</nextsent>
<nextsent>however, the demand for real-time translation is by no means restricted to these areas: it is clear in numerous other areas not yet extensively addressed ? emergency services, law enforcement, and others.
</nextsent>
<nextsent>ideally, system produced for one such domain (e.g., health care) could be easily ported to other domains.
</nextsent>
<nextsent>however, porting has in practice proven difficult.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3698">
<title id=" W08-1508.xml">rapid portability among domains in an interactive spoken language translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our translation grammars (presently licensed from commercial source, and further developed with our collaboration) are similarly designed to cover the structures of wide-ranging general texts and spoken discourse.
</prevsent>
<prevsent>to deal with the errors that inevitably follow as coverage grows, we provide set of facilities that enable users from both sides of the language barrier to 40 interactively monitor and correct such errors.
</prevsent>
</prevsection>
<citsent citstr=" W06-3701 ">
we have described these interactive techniques in (dillinger and seligman, 2004; zong and seligman, 2005; dillinger and seligman, 2006; <papid> W06-3706 </papid>and seligman and dillinger, 2006).<papid> W06-3701 </papid></citsent>
<aftsection>
<nextsent>with users thus integrated into the speech translation loop, automatically translated spoken conversations can range widely with acceptable accuracy (seligman, 2000).
</nextsent>
<nextsent>users can move among domains with relative freedom, even in advance of lexical or other domain specialization, because most domains are already covered to some degree.
</nextsent>
<nextsent>after quick summary of our approach (in section 2), we will demonstrate this flexibility (in section 3).
</nextsent>
<nextsent>while our systems facilities for monitoring and correction of asr and mt are vital for accuracy and confidence in wide-ranging conversations, they can be time consuming.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3702">
<title id=" W08-1508.xml">rapid portability among domains in an interactive spoken language translation system </title>
<section> highly interactive, broad-coverage.  </section>
<citcontext>
<prevsection>
<prevsent>using this paraphrase of the initial input, even monolingual user can make an initial judgment concerning the quality of the preliminary machine translation output.
</prevsent>
<prevsent>if errors are seen, the user can modify specific parts of the input and retranslate.
</prevsent>
</prevsection>
<citsent citstr=" W06-3711 ">
(other systems, e.g. ibms mastor (gao et al 2006), <papid> W06-3711 </papid>have also employed re-translation.</citsent>
<aftsection>
<nextsent>our implementations, however, exploit proprietary technologies to ensure that the lexical senses used during back-translation accurately reflect those used in forward translation.
</nextsent>
<nextsent>we also allow users to modify part or all of the input before regenerating the translation and back-translation.)
</nextsent>
<nextsent>in addition, if uncertainty remains about the correctness of given word sense, we supply proprietary set of meaning cues?
</nextsent>
<nextsent>synonyms, definitions, examples, pictures, etc. ? which have been drawn from various resources, collated in database (called select?), and aligned with the respective lexica of the relevant mt systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3703">
<title id=" W09-1111.xml">mining the web for reciprocal relationships </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>although the concept of reciprocity has been studied lot in different disciplines such as social sciences (gergen et al, 1980), anthropology (sahlins, 1972),economics (fehr and gachter, 2000), and philosophy (becker, 1990), linguists have started to look deeper into this problem only more recently.
</prevsent>
<prevsent>more over, to the best of our knowledge, in computational linguistics the problem is novel.in linguistics, most of the work on reciprocity focuses on mono-clausal reciprocal constructions, in particular on the quantifiers each other and one an other (dalrymple et al, 1998; heim, 1991; konig,2005).
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
most of this work has been done by language typologists (maslova and nedjalkov, 2005;haspelmath, 2007) who are interested in how reciprocal constructions of these types vary from one language to another and they do this through comparative studies of large sets of worlds languages.in computational linguistics, our pattern discovery procedure extends over previous approaches that use surface patterns as indicators of semantic relations between nouns or verbs ((hearst, 1998; chklovski and pantel, 2004; <papid> W04-3205 </papid>etzioni et al, 2004; turney, 2006; <papid> J06-3003 </papid>davidov and rappoport, 2008) <papid> P08-1079 </papid>inter alia).</citsent>
<aftsection>
<nextsent>we extend over these approaches in two ways:(i) our patterns indicate new type of relation between verbs, (ii) instead of seed or hook words we 76 use set of simple but effective pronoun templates which ensure the validity of the patterns extracted.
</nextsent>
<nextsent>to the best of our knowledge, the rest of our reciprocity model is novel.
</nextsent>
<nextsent>in particular, we use novel procedure which extracts pairs of reciprocal instances and present two novel unsupervised clustering methods which group the instance pairs in meaningful ways.
</nextsent>
<nextsent>we also present some interesting observations on the data thus obtained and suggest future research directions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3704">
<title id=" W09-1111.xml">mining the web for reciprocal relationships </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>although the concept of reciprocity has been studied lot in different disciplines such as social sciences (gergen et al, 1980), anthropology (sahlins, 1972),economics (fehr and gachter, 2000), and philosophy (becker, 1990), linguists have started to look deeper into this problem only more recently.
</prevsent>
<prevsent>more over, to the best of our knowledge, in computational linguistics the problem is novel.in linguistics, most of the work on reciprocity focuses on mono-clausal reciprocal constructions, in particular on the quantifiers each other and one an other (dalrymple et al, 1998; heim, 1991; konig,2005).
</prevsent>
</prevsection>
<citsent citstr=" J06-3003 ">
most of this work has been done by language typologists (maslova and nedjalkov, 2005;haspelmath, 2007) who are interested in how reciprocal constructions of these types vary from one language to another and they do this through comparative studies of large sets of worlds languages.in computational linguistics, our pattern discovery procedure extends over previous approaches that use surface patterns as indicators of semantic relations between nouns or verbs ((hearst, 1998; chklovski and pantel, 2004; <papid> W04-3205 </papid>etzioni et al, 2004; turney, 2006; <papid> J06-3003 </papid>davidov and rappoport, 2008) <papid> P08-1079 </papid>inter alia).</citsent>
<aftsection>
<nextsent>we extend over these approaches in two ways:(i) our patterns indicate new type of relation between verbs, (ii) instead of seed or hook words we 76 use set of simple but effective pronoun templates which ensure the validity of the patterns extracted.
</nextsent>
<nextsent>to the best of our knowledge, the rest of our reciprocity model is novel.
</nextsent>
<nextsent>in particular, we use novel procedure which extracts pairs of reciprocal instances and present two novel unsupervised clustering methods which group the instance pairs in meaningful ways.
</nextsent>
<nextsent>we also present some interesting observations on the data thus obtained and suggest future research directions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3705">
<title id=" W09-1111.xml">mining the web for reciprocal relationships </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>although the concept of reciprocity has been studied lot in different disciplines such as social sciences (gergen et al, 1980), anthropology (sahlins, 1972),economics (fehr and gachter, 2000), and philosophy (becker, 1990), linguists have started to look deeper into this problem only more recently.
</prevsent>
<prevsent>more over, to the best of our knowledge, in computational linguistics the problem is novel.in linguistics, most of the work on reciprocity focuses on mono-clausal reciprocal constructions, in particular on the quantifiers each other and one an other (dalrymple et al, 1998; heim, 1991; konig,2005).
</prevsent>
</prevsection>
<citsent citstr=" P08-1079 ">
most of this work has been done by language typologists (maslova and nedjalkov, 2005;haspelmath, 2007) who are interested in how reciprocal constructions of these types vary from one language to another and they do this through comparative studies of large sets of worlds languages.in computational linguistics, our pattern discovery procedure extends over previous approaches that use surface patterns as indicators of semantic relations between nouns or verbs ((hearst, 1998; chklovski and pantel, 2004; <papid> W04-3205 </papid>etzioni et al, 2004; turney, 2006; <papid> J06-3003 </papid>davidov and rappoport, 2008) <papid> P08-1079 </papid>inter alia).</citsent>
<aftsection>
<nextsent>we extend over these approaches in two ways:(i) our patterns indicate new type of relation between verbs, (ii) instead of seed or hook words we 76 use set of simple but effective pronoun templates which ensure the validity of the patterns extracted.
</nextsent>
<nextsent>to the best of our knowledge, the rest of our reciprocity model is novel.
</nextsent>
<nextsent>in particular, we use novel procedure which extracts pairs of reciprocal instances and present two novel unsupervised clustering methods which group the instance pairs in meaningful ways.
</nextsent>
<nextsent>we also present some interesting observations on the data thus obtained and suggest future research directions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3707">
<title id=" W09-1111.xml">mining the web for reciprocal relationships </title>
<section> clustering of reciprocal eventualities.  </section>
<citcontext>
<prevsection>
<prevsent>thus, given cluster, not only is there reciprocal relationship between verbs in the eo group with the verbs in the er group, but there is often kind of similarity relationship between the verbs within each eo or er group.
</prevsent>
<prevsent>this approach gives precise and concrete relations between verbs, but while it could be well-suitedto some applications (such as knowledge base construction or automatic verb classification (joanis et al., 2008)5) it has disadvantages in the context of grouping these verbs together.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the clusters are small and sparse, and the results are difficult to interpret, as there are many overlapping clusters.5these verb classes correspond to some extent to the verb net (kipper et al, 2000) or framenet-style (baker et al, 1998) <papid> P98-1013 </papid>verb classes such as admire, judgment.</citsent>
<aftsection>
<nextsent>79 ..
</nextsent>
<nextsent>cheat hurt forgive despise hate betray figure 1: sample of our data as bipartite graph.
</nextsent>
<nextsent>some edges have been omitted for readability.
</nextsent>
<nextsent>the nodes {eo=betray?, eo=cheat?,er=despise?, er=hate?}
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3708">
<title id=" W09-1111.xml">mining the web for reciprocal relationships </title>
<section> experimental data and results.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample, without additional information it is not clear how pair like (know, ask) might relate to others.
</prevsent>
<prevsent>5.4 polarity word identification.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
for this procedure we used the subjectivity clues (wilson et al, 2005) <papid> H05-1044 </papid>which provides 8,220 entries.</citsent>
<aftsection>
<nextsent>from all the 10,882 eventuality pairs, 40.1% of the total number of words were in the subjectivity lexicon, while 36.9% of the pairs had both words in the subjectivity lexicon.
</nextsent>
<nextsent>table 4 shows all possible combinations of pairs of affective values and their associated probabilities in the corpus.
</nextsent>
<nextsent>these values are computed for those pairs where both words have known polarity.
</nextsent>
<nextsent>as one might expect, each polarity class is most likely to be reciprocated by itself: good for good(altruism) and bad for bad (retaliation).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3709">
<title id=" W08-1117.xml">the effect of dialogue system output style variation on users evaluation judgments and input style </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there is to our knowledge no system that varies the style of its output in the interpersonal dimension as we have done in sam mie.
</prevsent>
<prevsent>work on animated conversational agents has addressed various issues concerning agents displaying their personality, but this usually concerns emotional states and personality traits, rather than the personal/impersonal alteration.
</prevsent>
</prevsection>
<citsent citstr=" W06-1405 ">
(isard et al, 2006)<papid> W06-1405 </papid>model personality and alignment in generated dialogues between pairs of agents using openccg and an over-generation and ranking approach, guided by set of language models.</citsent>
<aftsection>
<nextsent>their approach probably could produce the personal/impersonal style variation as an effect of personality or side-effect of syntactic alignment.
</nextsent>
<nextsent>the question whether system should generate output in personal or impersonal style has been addressed by (nass and brave, 2005): they observe that agents that use i? are generally perceived more like person than those that do not.
</nextsent>
<nextsent>however, systems tend to be more positively rated when consistent with respect to such parameters as personality, gender, ontology (human vs. machine), etc. onthe basis of an investigation of range of user attitudes to their simulated system with synthetic vs. recorded voice, they conclude that recorded voice system is perceived as more human-like and thus entitled to use i?, whereas synthetic-voice system is not perceived as human enough to use i? to refer to itself (nass et al, 2006).
</nextsent>
<nextsent>another question is whether system output style influences users?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3710">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>event extraction, the classical?
</prevsent>
<prevsent>information extraction (ie) task, has progressed from message understanding conference (muc)-style single template extraction to the more comprehensive multi-lingual automatic content extraction (ace) extraction including more fine-grained types.
</prevsent>
</prevsection>
<citsent citstr=" N07-1067 ">
this extension has made event extraction more widely applicable in many nlp tasks including cross lingual document retrieval (hakkani-tur et al, 2007) and question answering (schiffman et al, 2007).<papid> N07-1067 </papid></citsent>
<aftsection>
<nextsent>various supervised learning approaches 1 http://www.nist.gov/speech/tests/ace/ have been explored for ace multi-lingual event extraction (e.g. grishman et al, 2005; ahn, 2006; <papid> W06-0901 </papid>hardy et al, 2006; tan et al, 2008; chen and ji, 2009).</nextsent>
<nextsent>all of these previous literatures showed that one main bottleneck of event extraction lies in low recall.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3711">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>information extraction (ie) task, has progressed from message understanding conference (muc)-style single template extraction to the more comprehensive multi-lingual automatic content extraction (ace) extraction including more fine-grained types.
</prevsent>
<prevsent>this extension has made event extraction more widely applicable in many nlp tasks including cross lingual document retrieval (hakkani-tur et al, 2007) and question answering (schiffman et al, 2007).<papid> N07-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-0901 ">
various supervised learning approaches 1 http://www.nist.gov/speech/tests/ace/ have been explored for ace multi-lingual event extraction (e.g. grishman et al, 2005; ahn, 2006; <papid> W06-0901 </papid>hardy et al, 2006; tan et al, 2008; chen and ji, 2009).</citsent>
<aftsection>
<nextsent>all of these previous literatures showed that one main bottleneck of event extraction lies in low recall.
</nextsent>
<nextsent>its challenging task to recognize the different forms in which an event may be expressed, given the limited amount of training data.
</nextsent>
<nextsent>the goal of this paper is to improve the performance of bilingual (english and chinese) state-of-the-art event extraction system without accessing its internal algorithms or annotating additional data.
</nextsent>
<nextsent>as for separate research theme, extensive techniques have been used to produce word clusters or paraphrases from large unlabeled corpora (brown et al, 1990; pereira et al, 1993; <papid> P93-1024 </papid>lee and pereira, 1999, <papid> P99-1005 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003).<papid> N03-1024 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3712">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its challenging task to recognize the different forms in which an event may be expressed, given the limited amount of training data.
</prevsent>
<prevsent>the goal of this paper is to improve the performance of bilingual (english and chinese) state-of-the-art event extraction system without accessing its internal algorithms or annotating additional data.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
as for separate research theme, extensive techniques have been used to produce word clusters or paraphrases from large unlabeled corpora (brown et al, 1990; pereira et al, 1993; <papid> P93-1024 </papid>lee and pereira, 1999, <papid> P99-1005 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>for example, (bannard and callison-burch, 2005) and (callison-burch, 2008) described method to extract paraphrases from largely available bilingual corpora.
</nextsent>
<nextsent>the resulting clusters contain words with similar semantic information and therefore can be useful to augment small amount of annotated data.
</nextsent>
<nextsent>we will automatically extract cross-lingual predicate clusters using two different approaches based on bilingual parallel corpora and cross-lingual ie respectively; and then use the derived clusters to improve event extraction.
</nextsent>
<nextsent>we propose new learning method called inductive learning to exploit the derived predicate clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3713">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its challenging task to recognize the different forms in which an event may be expressed, given the limited amount of training data.
</prevsent>
<prevsent>the goal of this paper is to improve the performance of bilingual (english and chinese) state-of-the-art event extraction system without accessing its internal algorithms or annotating additional data.
</prevsent>
</prevsection>
<citsent citstr=" P99-1005 ">
as for separate research theme, extensive techniques have been used to produce word clusters or paraphrases from large unlabeled corpora (brown et al, 1990; pereira et al, 1993; <papid> P93-1024 </papid>lee and pereira, 1999, <papid> P99-1005 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>for example, (bannard and callison-burch, 2005) and (callison-burch, 2008) described method to extract paraphrases from largely available bilingual corpora.
</nextsent>
<nextsent>the resulting clusters contain words with similar semantic information and therefore can be useful to augment small amount of annotated data.
</nextsent>
<nextsent>we will automatically extract cross-lingual predicate clusters using two different approaches based on bilingual parallel corpora and cross-lingual ie respectively; and then use the derived clusters to improve event extraction.
</nextsent>
<nextsent>we propose new learning method called inductive learning to exploit the derived predicate clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3714">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its challenging task to recognize the different forms in which an event may be expressed, given the limited amount of training data.
</prevsent>
<prevsent>the goal of this paper is to improve the performance of bilingual (english and chinese) state-of-the-art event extraction system without accessing its internal algorithms or annotating additional data.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
as for separate research theme, extensive techniques have been used to produce word clusters or paraphrases from large unlabeled corpora (brown et al, 1990; pereira et al, 1993; <papid> P93-1024 </papid>lee and pereira, 1999, <papid> P99-1005 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>for example, (bannard and callison-burch, 2005) and (callison-burch, 2008) described method to extract paraphrases from largely available bilingual corpora.
</nextsent>
<nextsent>the resulting clusters contain words with similar semantic information and therefore can be useful to augment small amount of annotated data.
</nextsent>
<nextsent>we will automatically extract cross-lingual predicate clusters using two different approaches based on bilingual parallel corpora and cross-lingual ie respectively; and then use the derived clusters to improve event extraction.
</nextsent>
<nextsent>we propose new learning method called inductive learning to exploit the derived predicate clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3716">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its challenging task to recognize the different forms in which an event may be expressed, given the limited amount of training data.
</prevsent>
<prevsent>the goal of this paper is to improve the performance of bilingual (english and chinese) state-of-the-art event extraction system without accessing its internal algorithms or annotating additional data.
</prevsent>
</prevsection>
<citsent citstr=" W03-1608 ">
as for separate research theme, extensive techniques have been used to produce word clusters or paraphrases from large unlabeled corpora (brown et al, 1990; pereira et al, 1993; <papid> P93-1024 </papid>lee and pereira, 1999, <papid> P99-1005 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>for example, (bannard and callison-burch, 2005) and (callison-burch, 2008) described method to extract paraphrases from largely available bilingual corpora.
</nextsent>
<nextsent>the resulting clusters contain words with similar semantic information and therefore can be useful to augment small amount of annotated data.
</nextsent>
<nextsent>we will automatically extract cross-lingual predicate clusters using two different approaches based on bilingual parallel corpora and cross-lingual ie respectively; and then use the derived clusters to improve event extraction.
</nextsent>
<nextsent>we propose new learning method called inductive learning to exploit the derived predicate clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3718">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>its challenging task to recognize the different forms in which an event may be expressed, given the limited amount of training data.
</prevsent>
<prevsent>the goal of this paper is to improve the performance of bilingual (english and chinese) state-of-the-art event extraction system without accessing its internal algorithms or annotating additional data.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
as for separate research theme, extensive techniques have been used to produce word clusters or paraphrases from large unlabeled corpora (brown et al, 1990; pereira et al, 1993; <papid> P93-1024 </papid>lee and pereira, 1999, <papid> P99-1005 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>for example, (bannard and callison-burch, 2005) and (callison-burch, 2008) described method to extract paraphrases from largely available bilingual corpora.
</nextsent>
<nextsent>the resulting clusters contain words with similar semantic information and therefore can be useful to augment small amount of annotated data.
</nextsent>
<nextsent>we will automatically extract cross-lingual predicate clusters using two different approaches based on bilingual parallel corpora and cross-lingual ie respectively; and then use the derived clusters to improve event extraction.
</nextsent>
<nextsent>we propose new learning method called inductive learning to exploit the derived predicate clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3719">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> cross-lingual predicate cluster acqui-.  </section>
<citcontext>
<prevsection>
<prevsent>pora in the first approach, we take use of the 852 chinese event trigger words in ace05 training corpora as our anchor set?.
</prevsent>
<prevsent>for each chinese trigger, we search its automatically aligned english words from chinese-english parallel corpus including 50,000 sentence pairs (part of global autonomous language exploitation y3 machine translation training corpora) to construct an english predicate cluster.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the word alignment was obtained by running giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>in each cluster we record the frequency of each unique english word.
</nextsent>
<nextsent>then we conduct the same procedure in the other direction to construct chinese predicate clusters anchored by english triggers.
</nextsent>
<nextsent>state-of-the-art chinese-english word alignment error rate is about 40% (deng and byrne, 2005).<papid> H05-1022 </papid></nextsent>
<nextsent>therefore the resulting cross-lingual clusters include lot of word alignment errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3720">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> cross-lingual predicate cluster acqui-.  </section>
<citcontext>
<prevsection>
<prevsent>in each cluster we record the frequency of each unique english word.
</prevsent>
<prevsent>then we conduct the same procedure in the other direction to construct chinese predicate clusters anchored by english triggers.
</prevsent>
</prevsection>
<citsent citstr=" H05-1022 ">
state-of-the-art chinese-english word alignment error rate is about 40% (deng and byrne, 2005).<papid> H05-1022 </papid></citsent>
<aftsection>
<nextsent>therefore the resulting cross-lingual clusters include lot of word alignment errors.
</nextsent>
<nextsent>in order to address this problem, we filter the clusters by only keeping those predicates including the original predicate forms in ace training data or eng lish/chinese propbank (palmer et al, 2005; <papid> J05-1004 </papid>xue and palmer, 2009).</nextsent>
<nextsent>4.2 acquisition from cross-lingual ie.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3721">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> cross-lingual predicate cluster acqui-.  </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art chinese-english word alignment error rate is about 40% (deng and byrne, 2005).<papid> H05-1022 </papid></prevsent>
<prevsent>therefore the resulting cross-lingual clusters include lot of word alignment errors.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
in order to address this problem, we filter the clusters by only keeping those predicates including the original predicate forms in ace training data or eng lish/chinese propbank (palmer et al, 2005; <papid> J05-1004 </papid>xue and palmer, 2009).</citsent>
<aftsection>
<nextsent>4.2 acquisition from cross-lingual ie.
</nextsent>
<nextsent>based on the intuition that machine translation (mt) may translate chinese trigger word into different english words in different contexts, we employ the second approach using cross-lingual ie techniques (hakkani-tur et al, 2007) on tdt5 chinese corpus to generate more clusters.
</nextsent>
<nextsent>we apply the following two cross-lingual ie pipelines: chinese ie_mt: apply chinese ie on the chinese texts to get set of chinese triggers ch-trigger-set1, and then use word alignments to translate (project) ch-trigger-set1 into set of english triggers en trigger-set1; mt_english ie: translate chinese texts into english, and then apply english ie on the translated texts to get set of english triggers en-trigger-set2.
</nextsent>
<nextsent>for any chinese trigger ch-trigger in ch-trigger set1, if its corresponding translation en-trigger in en-trigger-set1 is the same as that in en-triggerset2, then we add en-trigger into the cluster anchored by ch-trigger.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3722">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> cross-lingual predicate cluster acqui-.  </section>
<citcontext>
<prevsection>
<prevsent>we apply the english and chinese ie systems as described in (grishman et al, 2005; chen and ji, 2009).
</prevsent>
<prevsent>both cross-lingual ie pipelines need machine translation to translate chinese documents (for english ie) or project the extraction results from chinese ie into english.
</prevsent>
</prevsection>
<citsent citstr=" N04-1033 ">
we use the rwth aachen chinese-to-english statistical phrase-based machine translation system (zens and ney, 2004) <papid> N04-1033 </papid>for these purposes.</citsent>
<aftsection>
<nextsent>4.3 derived cross-lingual predicate clusters.
</nextsent>
<nextsent>applying the above two approaches we obtained 438 english predicate clusters and 543 chinese.
</nextsent>
<nextsent>predicate clusters.
</nextsent>
<nextsent>for example, for trigger ??(injure)?, we can get the following two predicate clusters with their frequency in the parallel corpora: ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3723">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> inductive learning.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 global inference.
</prevsent>
<prevsent>for each background document bd, we apply the baseline event extraction and get set of back ground events.
</prevsent>
</prevsection>
<citsent citstr=" P08-1030 ">
we then apply the cross-document inference techniques as described in (ji and grishman, 2008) <papid> P08-1030 </papid>to improve trigger and argument labeling performance by favoring interpretation consistency across the test events and background events.</citsent>
<aftsection>
<nextsent>this approach is based on the premise that many events will be reported multiple times from different sources in different forms.
</nextsent>
<nextsent>this naturally occurs in the test document and the background document because they include triggers from the same predicate cluster.
</nextsent>
<nextsent>by aggregating events across each pair of test document td and background document bd, we conduct the following statistical global inference: ? to remove triggers and arguments with low confidence in td and bd; ? to adjust trigger and argument identification and classification to achieve consistency across td and bd.
</nextsent>
<nextsent>in this way we can propagate highly consistent and frequent triggers and arguments with high global confidence to override other, lower confidence, extraction results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3724">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>it further 33 proves that using the test set itself is not enough, we need to explore new predicates to serve as background evidence.
</prevsent>
<prevsent>in addition we also applied bootstrapping approach using relevant unlabeled data and obtained limited improvement ? about 1.6% f-measure gain for english.
</prevsent>
</prevsection>
<citsent citstr=" W06-0206 ">
as ji and grishman (2006) <papid> W06-0206 </papid>pointed out, both self-training and bootstrapping methods require good data selection scheme.</citsent>
<aftsection>
<nextsent>but not for any test set we can easily find relevant unlabeled data.
</nextsent>
<nextsent>therefore the approach presented in this paper is less expensive ? we can automatically generate background data while introducing new evidence.
</nextsent>
<nextsent>an alternative way of incorporating the cross lingual predicate clusters would follow (miller et al., 2004), <papid> N04-1043 </papid>namely encoding the cluster membership as an additional feature in the supervised learning procedure of the baseline event tagger.</nextsent>
<nextsent>however in the situation where we cannot directly change the algorithms of the baseline system, our approach of inductive learning is more flexible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3725">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>but not for any test set we can easily find relevant unlabeled data.
</prevsent>
<prevsent>therefore the approach presented in this paper is less expensive ? we can automatically generate background data while introducing new evidence.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
an alternative way of incorporating the cross lingual predicate clusters would follow (miller et al., 2004), <papid> N04-1043 </papid>namely encoding the cluster membership as an additional feature in the supervised learning procedure of the baseline event tagger.</citsent>
<aftsection>
<nextsent>however in the situation where we cannot directly change the algorithms of the baseline system, our approach of inductive learning is more flexible.
</nextsent>
<nextsent>our approach of extracting predicate clusters is related to some prior work on paraphrase or word cluster discovery, either from mono-lingual parallel corpora (e.g. barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003) <papid> N03-1024 </papid>or cross-lingual parallel corpora (e.g. bannard and callison-burch, 2005; callison-burch, 2008).</nextsent>
<nextsent>shinyama and sekine (2003) <papid> W03-1609 </papid>presented an approach of extracting paraphrases using names, dates and numbers as anchors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3731">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however in the situation where we cannot directly change the algorithms of the baseline system, our approach of inductive learning is more flexible.
</prevsent>
<prevsent>our approach of extracting predicate clusters is related to some prior work on paraphrase or word cluster discovery, either from mono-lingual parallel corpora (e.g. barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003) <papid> N03-1024 </papid>or cross-lingual parallel corpora (e.g. bannard and callison-burch, 2005; callison-burch, 2008).</prevsent>
</prevsection>
<citsent citstr=" W03-1609 ">
shinyama and sekine (2003) <papid> W03-1609 </papid>presented an approach of extracting paraphrases using names, dates and numbers as anchors.</citsent>
<aftsection>
<nextsent>hasegawa et al (2004) <papid> P04-1053 </papid>described paraphrase discovery approach based on clustering concurrent name pairs.</nextsent>
<nextsent>several recent studies have stressed the benefits of using paraphrases or word clusters to improve ie components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3732">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our approach of extracting predicate clusters is related to some prior work on paraphrase or word cluster discovery, either from mono-lingual parallel corpora (e.g. barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; ibrahim et al, 2003; <papid> W03-1608 </papid>pang et al, 2003) <papid> N03-1024 </papid>or cross-lingual parallel corpora (e.g. bannard and callison-burch, 2005; callison-burch, 2008).</prevsent>
<prevsent>shinyama and sekine (2003) <papid> W03-1609 </papid>presented an approach of extracting paraphrases using names, dates and numbers as anchors.</prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
hasegawa et al (2004) <papid> P04-1053 </papid>described paraphrase discovery approach based on clustering concurrent name pairs.</citsent>
<aftsection>
<nextsent>several recent studies have stressed the benefits of using paraphrases or word clusters to improve ie components.
</nextsent>
<nextsent>for example, (miller et al, 2004) <papid> N04-1043 </papid>proved that word clusters can significantly improve english name tagging.</nextsent>
<nextsent>the idea of using predicates in the same cluster for candidate trigger replacement is similar to ge et al(1998) <papid> W98-1119 </papid>who used local context replacement for pronoun resolution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3734">
<title id=" W09-1704.xml">cross lingual predicate cluster acquisition to improve bilingual event extraction by inductive learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several recent studies have stressed the benefits of using paraphrases or word clusters to improve ie components.
</prevsent>
<prevsent>for example, (miller et al, 2004) <papid> N04-1043 </papid>proved that word clusters can significantly improve english name tagging.</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
the idea of using predicates in the same cluster for candidate trigger replacement is similar to ge et al(1998) <papid> W98-1119 </papid>who used local context replacement for pronoun resolution.</citsent>
<aftsection>
<nextsent>to the best of our knowledge, our work presented the first experiment of using cross-lingual predicate paraphrases for the ace event extraction task.
</nextsent>
<nextsent>in this paper we described two approaches to extract cross-lingual predicate clusters, and designed new inductive learning framework to effectively incorporate these clusters for event extraction.
</nextsent>
<nextsent>without using any additional data or changing the baseline algorithms, we demonstrated that this method can significantly enhance the performance of state-of-the-art bilingual event tagger.
</nextsent>
<nextsent>we have noticed that the current filtering scheme based on propbank may be too restricted to keep enough informative predicates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3735">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we observe that portions of the extracted knowledge are comparable to results of recent work on class attribute extraction.
</prevsent>
<prevsent>239 240 van durme and schubert
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
several early studies in large-scale text processing (liakata and pulman, 2002; gildeaand palmer, 2002; <papid> P02-1031 </papid>schubert, 2002) showed that having access to sentences syntax enabled credible, automated semantic analysis.</citsent>
<aftsection>
<nextsent>these studies suggest that the use of increasingly sophisticated linguistic analysis tools could enable an explosion in available symbolic knowledge.
</nextsent>
<nextsent>nonetheless, much of the subsequent work in extraction has remained averse to the use of the linguistic deep structure of text; this decision is typically justified by desire to keep the extraction system as computationally lightweight as possible.
</nextsent>
<nextsent>the acquisition of background knowledge is not an activity that needs to occur online; we argue that as long as the extractor will finish in reasonable period of time, the speed of such system is an issue of secondary importance.
</nextsent>
<nextsent>accuracy and usefulness of knowledge should be of paramount concern, especially as the increase in available computational power makes such heavy?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3736">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>results show the feasibility of extraction via the use of sophisticated natural language processing as applied to web texts.
</prevsent>
<prevsent>given that the concern here is with open knowledge extraction, the myriad projects that target few pre specified types of relations occurring in large corpus are set aside.
</prevsent>
</prevsection>
<citsent citstr=" C92-4212 ">
among early efforts, one might count work on deriving selectional preferences(e.g., zernik (1992); <papid> C92-4212 </papid>resnik (1993); <papid> H93-1054 </papid>clark and weir (1999)) <papid> W99-0631 </papid>or partial predicate argument structure (e.g., abney (1996)) as steps in the direction of open knowledge extraction, though typically few of the tuples obtained (often type of subject plus verb, or verb plus type of object) can be interpreted as complete items of world knowledge.</citsent>
<aftsection>
<nextsent>another somewhat relevant line of research was initiated by zelle and mooney (1996), concerned with learning to map nl database queries into formal db queries (a kind of semantic interpretation).
</nextsent>
<nextsent>this was pursued further, for instance, by zettlemoyer and collins (2005) and wong and mooney (2007), <papid> P07-1121 </papid>aimed at learning log-linear models, or (in the latter case) synchronous cf grammars augmented with lambda operators, for mapping english queries to db queries.</nextsent>
<nextsent>however, this approach requires annotation of texts with logical forms, and extending this approach to general texts would seemingly require massive corpus of hand-annotated text ? and the logical forms would have to cover far more phenomena than are found in db queries (e.g., attitudes, generalized quantifiers, etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3737">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>results show the feasibility of extraction via the use of sophisticated natural language processing as applied to web texts.
</prevsent>
<prevsent>given that the concern here is with open knowledge extraction, the myriad projects that target few pre specified types of relations occurring in large corpus are set aside.
</prevsent>
</prevsection>
<citsent citstr=" H93-1054 ">
among early efforts, one might count work on deriving selectional preferences(e.g., zernik (1992); <papid> C92-4212 </papid>resnik (1993); <papid> H93-1054 </papid>clark and weir (1999)) <papid> W99-0631 </papid>or partial predicate argument structure (e.g., abney (1996)) as steps in the direction of open knowledge extraction, though typically few of the tuples obtained (often type of subject plus verb, or verb plus type of object) can be interpreted as complete items of world knowledge.</citsent>
<aftsection>
<nextsent>another somewhat relevant line of research was initiated by zelle and mooney (1996), concerned with learning to map nl database queries into formal db queries (a kind of semantic interpretation).
</nextsent>
<nextsent>this was pursued further, for instance, by zettlemoyer and collins (2005) and wong and mooney (2007), <papid> P07-1121 </papid>aimed at learning log-linear models, or (in the latter case) synchronous cf grammars augmented with lambda operators, for mapping english queries to db queries.</nextsent>
<nextsent>however, this approach requires annotation of texts with logical forms, and extending this approach to general texts would seemingly require massive corpus of hand-annotated text ? and the logical forms would have to cover far more phenomena than are found in db queries (e.g., attitudes, generalized quantifiers, etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3738">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>results show the feasibility of extraction via the use of sophisticated natural language processing as applied to web texts.
</prevsent>
<prevsent>given that the concern here is with open knowledge extraction, the myriad projects that target few pre specified types of relations occurring in large corpus are set aside.
</prevsent>
</prevsection>
<citsent citstr=" W99-0631 ">
among early efforts, one might count work on deriving selectional preferences(e.g., zernik (1992); <papid> C92-4212 </papid>resnik (1993); <papid> H93-1054 </papid>clark and weir (1999)) <papid> W99-0631 </papid>or partial predicate argument structure (e.g., abney (1996)) as steps in the direction of open knowledge extraction, though typically few of the tuples obtained (often type of subject plus verb, or verb plus type of object) can be interpreted as complete items of world knowledge.</citsent>
<aftsection>
<nextsent>another somewhat relevant line of research was initiated by zelle and mooney (1996), concerned with learning to map nl database queries into formal db queries (a kind of semantic interpretation).
</nextsent>
<nextsent>this was pursued further, for instance, by zettlemoyer and collins (2005) and wong and mooney (2007), <papid> P07-1121 </papid>aimed at learning log-linear models, or (in the latter case) synchronous cf grammars augmented with lambda operators, for mapping english queries to db queries.</nextsent>
<nextsent>however, this approach requires annotation of texts with logical forms, and extending this approach to general texts would seemingly require massive corpus of hand-annotated text ? and the logical forms would have to cover far more phenomena than are found in db queries (e.g., attitudes, generalized quantifiers, etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3739">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>among early efforts, one might count work on deriving selectional preferences(e.g., zernik (1992); <papid> C92-4212 </papid>resnik (1993); <papid> H93-1054 </papid>clark and weir (1999)) <papid> W99-0631 </papid>or partial predicate argument structure (e.g., abney (1996)) as steps in the direction of open knowledge extraction, though typically few of the tuples obtained (often type of subject plus verb, or verb plus type of object) can be interpreted as complete items of world knowledge.</prevsent>
<prevsent>another somewhat relevant line of research was initiated by zelle and mooney (1996), concerned with learning to map nl database queries into formal db queries (a kind of semantic interpretation).</prevsent>
</prevsection>
<citsent citstr=" P07-1121 ">
this was pursued further, for instance, by zettlemoyer and collins (2005) and wong and mooney (2007), <papid> P07-1121 </papid>aimed at learning log-linear models, or (in the latter case) synchronous cf grammars augmented with lambda operators, for mapping english queries to db queries.</citsent>
<aftsection>
<nextsent>however, this approach requires annotation of texts with logical forms, and extending this approach to general texts would seemingly require massive corpus of hand-annotated text ? and the logical forms would have to cover far more phenomena than are found in db queries (e.g., attitudes, generalized quantifiers, etc.).
</nextsent>
<nextsent>another line of relevant work is that on semantic role labelling.
</nextsent>
<nextsent>one early example was mindnet (richardson et al, 1998), <papid> P98-2180 </papid>which was based on collecting 24 semantic role relations from mrds such as the american heritage dictionary.</nextsent>
<nextsent>more recent representative efforts includes that of gildea and jurafsky (2002), <papid> J02-3001 </papid>gildea and palmer (2002), <papid> P02-1031 </papid>and punyakanok et al (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3740">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>however, this approach requires annotation of texts with logical forms, and extending this approach to general texts would seemingly require massive corpus of hand-annotated text ? and the logical forms would have to cover far more phenomena than are found in db queries (e.g., attitudes, generalized quantifiers, etc.).
</prevsent>
<prevsent>another line of relevant work is that on semantic role labelling.
</prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
one early example was mindnet (richardson et al, 1998), <papid> P98-2180 </papid>which was based on collecting 24 semantic role relations from mrds such as the american heritage dictionary.</citsent>
<aftsection>
<nextsent>more recent representative efforts includes that of gildea and jurafsky (2002), <papid> J02-3001 </papid>gildea and palmer (2002), <papid> P02-1031 </papid>and punyakanok et al (2008).</nextsent>
<nextsent>the relevance of this work comes from the fact that identifying the arguments of the verbs in sentence is first step towards forming predications, and these may in many cases correspond to items of world knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3741">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>another line of relevant work is that on semantic role labelling.
</prevsent>
<prevsent>one early example was mindnet (richardson et al, 1998), <papid> P98-2180 </papid>which was based on collecting 24 semantic role relations from mrds such as the american heritage dictionary.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
more recent representative efforts includes that of gildea and jurafsky (2002), <papid> J02-3001 </papid>gildea and palmer (2002), <papid> P02-1031 </papid>and punyakanok et al (2008).</citsent>
<aftsection>
<nextsent>the relevance of this work comes from the fact that identifying the arguments of the verbs in sentence is first step towards forming predications, and these may in many cases correspond to items of world knowledge.
</nextsent>
<nextsent>open knowledge extraction through compositional language processing 241liakata and pulman (2002) built system for recovering davidson ian predicate argument structures from the penn treebank through the application of small set of syntactic templates targeting head nodes of verb arguments.
</nextsent>
<nextsent>the authors illustrate their results for the sentence apple ii owners, for example, had to use their television sets as screens and stored data on audiocassettes?
</nextsent>
<nextsent>(along with the treebank anno tations); they obtain the following qlf, where verb stems serve as predicates, and arguments are represented by the headwords of the source phrases: have(e1,owner, (use(e3,owner,set), and as(e3,screen)), and (store(e2,owner,datum), and on(e2,audiocassette)))for test set of 100 treebank sentences, the authors report recall figures for various aspects of such qlfs ranging from 87% to 96%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3743">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(along with the treebank anno tations); they obtain the following qlf, where verb stems serve as predicates, and arguments are represented by the headwords of the source phrases: have(e1,owner, (use(e3,owner,set), and as(e3,screen)), and (store(e2,owner,datum), and on(e2,audiocassette)))for test set of 100 treebank sentences, the authors report recall figures for various aspects of such qlfs ranging from 87% to 96%.
</prevsent>
<prevsent>while qlf like the one above cannot in itself be regarded as world knowledge, one can readily imagine postprocessing steps that could in many cases obtain credible propositions from such qlfs.
</prevsent>
</prevsection>
<citsent citstr=" W03-0902 ">
how accurate the results would be with machine-parsed sentences is at this point unknown.in the same year, schubert (2002) described project aimed directly at the extraction of general world knowledge from treebank text, and schubert and tong (2003)<papid> W03-0902 </papid>provided the results of hand-assessment of the resulting propositions.</citsent>
<aftsection>
<nextsent>the brown corpus yielded about 117,000 distinct simple propositions (somewhat more than 2 per sentence, of variable quality).
</nextsent>
<nextsent>like liakata and pulmans approach the method relied on the computation of uns coped logical forms from treebank trees, but it abstracted propositional information along the way, typically discarding modifiers at deeper levels from lfs at higher levels, and also replacing nps (including named entities) by their types as far as possible.
</nextsent>
<nextsent>judges found about 2/3 of the output propositions (when automatically verbalized in english) acceptable as general claims about the world.
</nextsent>
<nextsent>the next section provides more detail on the extraction system, called knext, employed in this work.clark et al (2003), <papid> W03-0901 </papid>citing the 2002 work of schubert, report undertaking similar extraction effort for the 2003 reuters corpus, based on parses produced by the boeing parser, (see holm back et al (2000)), and obtained 1.1 million subject-verb object fragments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3744">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>like liakata and pulmans approach the method relied on the computation of uns coped logical forms from treebank trees, but it abstracted propositional information along the way, typically discarding modifiers at deeper levels from lfs at higher levels, and also replacing nps (including named entities) by their types as far as possible.
</prevsent>
<prevsent>judges found about 2/3 of the output propositions (when automatically verbalized in english) acceptable as general claims about the world.
</prevsent>
</prevsection>
<citsent citstr=" W03-0901 ">
the next section provides more detail on the extraction system, called knext, employed in this work.clark et al (2003), <papid> W03-0901 </papid>citing the 2002 work of schubert, report undertaking similar extraction effort for the 2003 reuters corpus, based on parses produced by the boeing parser, (see holm back et al (2000)), and obtained 1.1 million subject-verb object fragments.</citsent>
<aftsection>
<nextsent>their goal was eventually to employ such tuples as common-sense expectations to guide the interpretation of text and the retrieval of possibly relevant knowledge in question-answering.
</nextsent>
<nextsent>this goal, unlike the goal of inferential use of extracted knowledge, does not necessarily require the extracted information to be in the form of logical propositions.
</nextsent>
<nextsent>still, since many of their tuples were in form that could be quite directly converted into propositional forms similar to those of schubert, their work indicated the potential for scala bility in parser-based approaches to information extraction or knowledge extraction.
</nextsent>
<nextsent>a recent project aimed at large-scale, open extraction of tuples of text fragments representing verbal predicates and their arguments is text runner (banko et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3745">
<title id=" W08-2219.xml">open knowledge extraction through compositional language processing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, numerous improvements have been made to the semantic interpretation rules, the filtering techniques, and other components of the system.
</prevsent>
<prevsent>the extraction procedure is as follows: 1.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
parse each sentence using treebank-trained parser (collins, 1997; <papid> P97-1003 </papid>charniak,.</citsent>
<aftsection>
<nextsent>1999).
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>pre process the parse tree, for better interpret ability (e.g., distinguish different.
</nextsent>
<nextsent>types of sbar phrases and different types of pps, identify temporal phrases, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3748">
<title id=" W08-2206.xml">how well do semantic relatedness measures perform a meta study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we argue that the definition of shared task might bring us considerably closer to understanding the concept of semantic relatedness.
</prevsent>
<prevsent>59 60 cramer
</prevsent>
</prevsection>
<citsent citstr=" P06-1113 ">
various applications in natural language processing, such as question answering(novischi and moldovan, 2006), <papid> P06-1113 </papid>topic detection (carthy, 2004), and text summarization (barzilay and elhadad, 1997), <papid> W97-0703 </papid>relyon semantic relatedness (similarity or dis tance)1 measures either based on wordnets and/or corpus statistics as resource.</citsent>
<aftsection>
<nextsent>in the hytex project, funded by the german research foundation, we develop strategies for the text-to-hypertext conversion using text-grammatical features.
</nextsent>
<nextsent>one strand of research in this project consists of topic-based linking methods using lexical chaining as resource (cramer and finthammer, 2008).
</nextsent>
<nextsent>lexical chaining is well-knownmethod to calculate partial text representations; it relies on semantic relatedness values as basic input.
</nextsent>
<nextsent>we therefore implemented2 eight semantic relatedness measures ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3749">
<title id=" W08-2206.xml">how well do semantic relatedness measures perform a meta study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we argue that the definition of shared task might bring us considerably closer to understanding the concept of semantic relatedness.
</prevsent>
<prevsent>59 60 cramer
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
various applications in natural language processing, such as question answering(novischi and moldovan, 2006), <papid> P06-1113 </papid>topic detection (carthy, 2004), and text summarization (barzilay and elhadad, 1997), <papid> W97-0703 </papid>relyon semantic relatedness (similarity or dis tance)1 measures either based on wordnets and/or corpus statistics as resource.</citsent>
<aftsection>
<nextsent>in the hytex project, funded by the german research foundation, we develop strategies for the text-to-hypertext conversion using text-grammatical features.
</nextsent>
<nextsent>one strand of research in this project consists of topic-based linking methods using lexical chaining as resource (cramer and finthammer, 2008).
</nextsent>
<nextsent>lexical chaining is well-knownmethod to calculate partial text representations; it relies on semantic relatedness values as basic input.
</nextsent>
<nextsent>we therefore implemented2 eight semantic relatedness measures ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3750">
<title id=" W08-2206.xml">how well do semantic relatedness measures perform a meta study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical chaining is well-knownmethod to calculate partial text representations; it relies on semantic relatedness values as basic input.
</prevsent>
<prevsent>we therefore implemented2 eight semantic relatedness measures ?
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
(hirst and st-onge, 1998; jiang and conrath, 1997; leacock and chodorow, 1998; lin, 1998; resnik, 1995; wu and palmer, 1994) ? <papid> P94-1019 </papid>based on germanet3 lemnitzer and kunze (2002) and three based on google co-occurrence counts (cilibrasi and vi tanyi, 2007).</citsent>
<aftsection>
<nextsent>in order to evaluate the performance of these measures we conducted two human judgment experiments and computed the correlation between the human judgment and the values of the eleven semantic measures.
</nextsent>
<nextsent>we also compared our results with those reported in the literature and found that the correlations between human judgments and semantic measures are extremely scattered.
</nextsent>
<nextsent>in this paper we compare the correlation of our own human judgment experiments and the results ofthree similar studies.
</nextsent>
<nextsent>in our opinion this comparison points to the necessity of thorough analysis of the methods used in these experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3751">
<title id=" W08-2206.xml">how well do semantic relatedness measures perform a meta study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>are the semantic relatedness measures proposed in the literature able to capture all of these aspects?
</prevsent>
<prevsent>in this paper we intend to open the abovementioned analysis and therefore assembled set of aspects which we consider to be important in order to answer these questions.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
consequently, the remainder of this paper is structured as follows: in section 2 we 1the notions of semantic relatedness, similarity, and distance measure are controversially discussed in the literature, e.g. budanitsky and hirst (2006).<papid> J06-1003 </papid></citsent>
<aftsection>
<nextsent>however, semantic similarity and relatedness seem to be the predominant terms in this context.
</nextsent>
<nextsent>budanitsky and hirst (2006) <papid> J06-1003 </papid>define them as follows: word-pairs are considered to be semantically similar if synonymy or hypernymy relation holds.</nextsent>
<nextsent>in contrast, word-pairs are considered to be semantically related if systematic relation, such as synonymy, antonymy, hypernymy, holonymy, or an unsystematic relation holds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3758">
<title id=" W08-2206.xml">how well do semantic relatedness measures perform a meta study </title>
<section> our human judgement experiments.  </section>
<citcontext>
<prevsection>
<prevsent>sun-weather) etc. we arranged these 25 pairs into sequences in order to focus our subjects?
</prevsent>
<prevsent>attention on small semantic relatedness distinctions.
</prevsent>
</prevsection>
<citsent citstr=" P06-2072 ">
4since in most wordnets cross-pos relations are very sparse, researchers currently investigate relation types able to connect the noun, verb, and adjective sub-graphs (e.g. marrafa and mendes (2006) <papid> P06-2072 </papid>or lemnitzer et al (2008)).</citsent>
<aftsection>
<nextsent>however, these new relations are not yet integrated on large scale and therefore should not (or even cannot) be used in semantic relatedness measures.
</nextsent>
<nextsent>furthermore, calculating semantic relatedness between words with different pos might introduce additional challenges potentially as yet unidentified, which calls for careful exploration.5in this paper and in most comparable studies, the term analytical means that the word-pairs are handpicked.
</nextsent>
<nextsent>obviously, the disadvantage of this approach is its sensibility to idiosyncrasies, which might extremely bias the outcome of the experiments.
</nextsent>
<nextsent>62 cramer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3797">
<title id=" W08-2138.xml">desrl a linear time semantic role labeling system </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in the parsing sub-task we use combination strategy on top of three individual parsing models, two developed in-house desr lefttoright and desr revision righttoleft?
</prevsent>
<prevsent>and third using an off-the shelf parser, malt 1.0.0 1 . 2.1 desr.
</prevsent>
</prevsection>
<citsent citstr=" W06-2922 ">
lefttoright this model is version of desr (attardi, 2006), <papid> W06-2922 </papid>deterministic classifier-based shift/reduceparser.</citsent>
<aftsection>
<nextsent>the parser processes input tokens advancing on the input from left to right with shift actions and accumulates processed tokens on stack with reduce actions.
</nextsent>
<nextsent>the parser has been adapted for this years shared task and extended with additional classifiers, e.g., multilayer perceptron and multiple svms.
</nextsent>
<nextsent>2 the parser uses the following features: 1.
</nextsent>
<nextsent>split lemma: from tokens 1, 0, 1, prev(0),.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3798">
<title id=" W08-2138.xml">desrl a linear time semantic role labeling system </title>
<section> hdist: from 1, 0.  </section>
<citcontext>
<prevsection>
<prevsent>the addition of this feature yields an increase of 0.80% in labeled accuracy on the development set.
</prevsent>
<prevsent>2.2 revision parser: desr.
</prevsent>
</prevsection>
<citsent citstr=" N07-1049 ">
revision righttoleft our second individual parsing model implements an alternative to the method of revising parse trees of attardi and ciaramita (2007) (<papid> N07-1049 </papid>see also (hall &amp; novak, 2005)).</citsent>
<aftsection>
<nextsent>the original approach consisted intraining classifier to revise the errors of baseline parser.
</nextsent>
<nextsent>the approach assumed that only local revisions to the parse tree would be needed, since the dependency parser mostly gets individual phrases correctly.
</nextsent>
<nextsent>the experiments showed that indeed most of the corrections can be expressed by small set of (about 20) complex movement rules.
</nextsent>
<nextsent>furthermore, there was evidence that one could get higher improvements from the tree revision classifier if this was trained on the output of lower accuracy parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3799">
<title id=" W08-2138.xml">desrl a linear time semantic role labeling system </title>
<section> hdist: from 1, 0.  </section>
<citcontext>
<prevsection>
<prevsent>devel wsj brown unlabeled 1 92.69 90.88 86.96 labeled 1 (pic) 87.29 84.87 71.99 labeled 1 (sense 1) 79.62 78.94 70.11 table 4: scores of the pic component.mentioned earlier.
</prevsent>
<prevsent>these results show that voting helps significantly (+1.56% over the best single parser) even though inter-dependent models were used.
</prevsent>
</prevsection>
<citsent citstr=" N06-2033 ">
however, our simple voting scheme does not guarantee that well-formed tree is generated, leaving room for further improvements; e.g., as in (sagae &amp; lavie, 2006).<papid> N06-2033 </papid></citsent>
<aftsection>
<nextsent>4.2 analysis of srl.
</nextsent>
<nextsent>table 3 shows the labeled and unlabeled 1 scores of our srl component as we move from gold to predicted information for syntax and pic.
</nextsent>
<nextsent>for the shared task setting predicted syntax and predictedpic?
</nextsent>
<nextsent>we show results for the two inference strategies implemented: greedy and reranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3800">
<title id=" W08-2208.xml">combining word sense and usage for modeling frame semantics </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>

<prevsent>models of lexical meaning are explicit or implicit basic components of any text processing system devoted to information extraction, question answering or dialogue.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
several paradigms proposed for variety of notions, such as word sense (miller et al, 1990) or frame semantics (baker et al, 1998), <papid> P98-1013 </papid>have given rise to large scale resources, respectively wordnet and framenet.</citsent>
<aftsection>
<nextsent>recent studies (e.g. shen and lapata (2007)) <papid> D07-1002 </papid>show that the use of framenet can potentially improve the performance of question answering systems.</nextsent>
<nextsent>yet, shen and lapata (2007) <papid> D07-1002 </papid>also point out that the low coverage of the current version of framenet significantly limits the expected boost in performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3801">
<title id=" W08-2208.xml">combining word sense and usage for modeling frame semantics </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>models of lexical meaning are explicit or implicit basic components of any text processing system devoted to information extraction, question answering or dialogue.
</prevsent>
<prevsent>several paradigms proposed for variety of notions, such as word sense (miller et al, 1990) or frame semantics (baker et al, 1998), <papid> P98-1013 </papid>have given rise to large scale resources, respectively wordnet and framenet.</prevsent>
</prevsection>
<citsent citstr=" D07-1002 ">
recent studies (e.g. shen and lapata (2007)) <papid> D07-1002 </papid>show that the use of framenet can potentially improve the performance of question answering systems.</citsent>
<aftsection>
<nextsent>yet, shen and lapata (2007) <papid> D07-1002 </papid>also point out that the low coverage of the current version of framenet significantly limits the expected boost in performance.</nextsent>
<nextsent>other studies have shown similar evidences for recognizing textual entailment (rte) (clark et al, 2007; <papid> W07-1409 </papid>burchardt et al, 2008): most examples of the rte challenges corpora can be solved at the predicate-argument structure level, but framenet coverage is still major problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3803">
<title id=" W08-2208.xml">combining word sense and usage for modeling frame semantics </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>recent studies (e.g. shen and lapata (2007)) <papid> D07-1002 </papid>show that the use of framenet can potentially improve the performance of question answering systems.</prevsent>
<prevsent>yet, shen and lapata (2007) <papid> D07-1002 </papid>also point out that the low coverage of the current version of framenet significantly limits the expected boost in performance.</prevsent>
</prevsection>
<citsent citstr=" W07-1409 ">
other studies have shown similar evidences for recognizing textual entailment (rte) (clark et al, 2007; <papid> W07-1409 </papid>burchardt et al, 2008): most examples of the rte challenges corpora can be solved at the predicate-argument structure level, but framenet coverage is still major problem.</citsent>
<aftsection>
<nextsent>approaches to (semi-)automatically acquire frame information are then today priority to solve these problems.
</nextsent>
<nextsent>despite this, not many efforts have been paid so far in this direction.
</nextsent>
<nextsent>burchardt et al (2005) presented detour, system for predicting frame assignment of potential lexical units not covered by framenet, by using the paradigmatic information enclosed in wordnet.
</nextsent>
<nextsent>although the authors do not fully solve the problem related to the fuzzy relationships between senses and frames, they propose an empirical association measure for ranking frame candidates according to sense information as stored in wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3804">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>traditionally, grammar rules have been carefully handcrafted, such as those used in lingo (car roll et al , 1999), openccg (white, 2004) andxle (crouch et al , 2007).
</prevsent>
<prevsent>as hand crafting grammar rules is time-consuming, language-dependentand domain-specific, recent years have witnessed research on extracting wide-coverage grammars automatically from annotated corpora, for both parsing and generation.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
fergus (bangalore and rambow,2000) <papid> C00-1007 </papid>took dependency structures as inputs, and produced xtag derivations by stochastic tree model automatically acquired from an annotated corpus.</citsent>
<aftsection>
<nextsent>nakanishi et al  (2005) <papid> W05-1510 </papid>presented log-linear models for chart generator using hpsg grammar acquired from the penn-ii treebank.</nextsent>
<nextsent>from the same treebank, cahill and van genabith (2006) <papid> P06-1130 </papid>automatically extracted wide-coverage lfg approximations for pcfg-based generation model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3805">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as hand crafting grammar rules is time-consuming, language-dependentand domain-specific, recent years have witnessed research on extracting wide-coverage grammars automatically from annotated corpora, for both parsing and generation.
</prevsent>
<prevsent>fergus (bangalore and rambow,2000) <papid> C00-1007 </papid>took dependency structures as inputs, and produced xtag derivations by stochastic tree model automatically acquired from an annotated corpus.</prevsent>
</prevsection>
<citsent citstr=" W05-1510 ">
nakanishi et al  (2005) <papid> W05-1510 </papid>presented log-linear models for chart generator using hpsg grammar acquired from the penn-ii treebank.</citsent>
<aftsection>
<nextsent>from the same treebank, cahill and van genabith (2006) <papid> P06-1130 </papid>automatically extracted wide-coverage lfg approximations for pcfg-based generation model.</nextsent>
<nextsent>in addition to applying statistical techniques to automatically acquire generation grammars, over the last decade, there has been lot of interest in generate-and-select paradigm for surface realisation.the paradigm is characterised by separation between generation and selection, in which symbolic or rule-based methods are used to generate space of possible paraphrases, and statistical methods are used to select one or more outputs from the space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3806">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fergus (bangalore and rambow,2000) <papid> C00-1007 </papid>took dependency structures as inputs, and produced xtag derivations by stochastic tree model automatically acquired from an annotated corpus.</prevsent>
<prevsent>nakanishi et al  (2005) <papid> W05-1510 </papid>presented log-linear models for chart generator using hpsg grammar acquired from the penn-ii treebank.</prevsent>
</prevsection>
<citsent citstr=" P06-1130 ">
from the same treebank, cahill and van genabith (2006) <papid> P06-1130 </papid>automatically extracted wide-coverage lfg approximations for pcfg-based generation model.</citsent>
<aftsection>
<nextsent>in addition to applying statistical techniques to automatically acquire generation grammars, over the last decade, there has been lot of interest in generate-and-select paradigm for surface realisation.the paradigm is characterised by separation between generation and selection, in which symbolic or rule-based methods are used to generate space of possible paraphrases, and statistical methods are used to select one or more outputs from the space.
</nextsent>
<nextsent>starting from langkilde (2002) who used n-gram language model to rank generated output strings, asubstantial number of traditional handcrafted surface realisers have been augmented with sophisticated stochastic rankers (velldal and oepen, 2005; white et al , 2007; cahill et al , 2007).
</nextsent>
<nextsent>it is interesting to note that, while the study of how the granularity of context-free grammars (cfg) affects the performance of parser (e.g. in the form 86 n1:ip [?=?]
</nextsent>
<nextsent>n2:np [subj=?]
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3808">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>f4 ? ?
</prevsent>
<prevsent>pred ?i? ntype proper num sg ? ?
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
: ? ?(n1)=?(n3)=?(n5)=f1 ?(n2)=?(n4)=f2 ?(n6)=?(n8)=f3 ?(n7)=f4 figure 1: c- and f-structures with ? links for the sentence ?l???ionof grammar transforms (johnson, 1998) <papid> J98-4004 </papid>and lexicalisation (collins, 1997)) <papid> P97-1003 </papid>has attracted substantial attention, to our knowledge, there has been lot less research on this subject for surface realisation, process that is generally regarded as the reverse process of parsing.</citsent>
<aftsection>
<nextsent>moreover, while most of the research so far has concentrated on english or european languages, we are also interested in generation for other languages with diverse properties, such as chinese which is currently focus language in parsing (bikel, 2004; cao et al , 2007).
</nextsent>
<nextsent>in this paper, we investigate three generative pcfg models for chinese generation based onwide-coverage lfg grammars automatically extracted from the penn chinese treebank (ctb).
</nextsent>
<nextsent>ourwork is couched in the framework of lexical functional grammar and is implemented in chart-style generator.
</nextsent>
<nextsent>we briefly describe lfg and the basic generation model in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3809">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>f4 ? ?
</prevsent>
<prevsent>pred ?i? ntype proper num sg ? ?
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
: ? ?(n1)=?(n3)=?(n5)=f1 ?(n2)=?(n4)=f2 ?(n6)=?(n8)=f3 ?(n7)=f4 figure 1: c- and f-structures with ? links for the sentence ?l???ionof grammar transforms (johnson, 1998) <papid> J98-4004 </papid>and lexicalisation (collins, 1997)) <papid> P97-1003 </papid>has attracted substantial attention, to our knowledge, there has been lot less research on this subject for surface realisation, process that is generally regarded as the reverse process of parsing.</citsent>
<aftsection>
<nextsent>moreover, while most of the research so far has concentrated on english or european languages, we are also interested in generation for other languages with diverse properties, such as chinese which is currently focus language in parsing (bikel, 2004; cao et al , 2007).
</nextsent>
<nextsent>in this paper, we investigate three generative pcfg models for chinese generation based onwide-coverage lfg grammars automatically extracted from the penn chinese treebank (ctb).
</nextsent>
<nextsent>ourwork is couched in the framework of lexical functional grammar and is implemented in chart-style generator.
</nextsent>
<nextsent>we briefly describe lfg and the basic generation model in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3810">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> lfg-based generation.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 generation from f-structures.
</prevsent>
<prevsent>the generation task in lfg is to determine which sentences correspond to specified f-structure, given particular grammar, such as (1).
</prevsent>
</prevsection>
<citsent citstr=" C00-1062 ">
kaplan and wedekind (2000) <papid> C00-1062 </papid>proved that the set of strings generated by an lfg grammar from fully specified f-structures is context-free language.</citsent>
<aftsection>
<nextsent>basedon this theoretical cornerstone, cahill and van genabith (2006) <papid> P06-1130 </papid>presented pcfg-based chart generator using wide-coverage lfg approximations automatically extracted from the penn-ii treebank.</nextsent>
<nextsent>the lfg-based statistical generation model defines the conditional probability (t |f ), for each candidate functionally annotated c-structure tree (whichfully specifies surface realisation) given an structure . the generation model searches for the tbest that maximises (t |f ) (eq.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3816">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> disambiguation models.  </section>
<citcontext>
<prevsection>
<prevsent>the basic generation model presented in (cahilland van genabith, 2006) <papid> P06-1130 </papid>used simple probabilistic context-free grammars.</prevsent>
<prevsent>however, the independence assumptions implicit in pcfg models may not be appropriate to best capture natural languagephenomena.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
methodologies such as lexicalisation (collins, 1997; <papid> P97-1003 </papid>charniak, 2000) <papid> A00-2018 </papid>and tree transformations (johnson, 1998), <papid> J98-4004 </papid>weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple pcfgs.</citsent>
<aftsection>
<nextsent>in this section we study the effect of such methods in lfg-based generation for chinese.
</nextsent>
<nextsent>3.1 history-based mode lthe history-based (hb) approach which incorporates more context information has worked wellin parsing (collins, 1997; <papid> P97-1003 </papid>charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>resembling history-based models for parsing, hogan et al  (2007) <papid> D07-1028 </papid>presented history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation modelof (cahill and van genabith, 2006).<papid> P06-1130 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3821">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> disambiguation models.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we study the effect of such methods in lfg-based generation for chinese.
</prevsent>
<prevsent>3.1 history-based mode lthe history-based (hb) approach which incorporates more context information has worked wellin parsing (collins, 1997; <papid> P97-1003 </papid>charniak, 2000).<papid> A00-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1028 ">
resembling history-based models for parsing, hogan et al  (2007) <papid> D07-1028 </papid>presented history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation modelof (cahill and van genabith, 2006).<papid> P06-1130 </papid></citsent>
<aftsection>
<nextsent>the history based model increases the context by simply including the parent grammatical function gf of the structure in addition to the local ?-linked feature set in the conditioning context (eq.
</nextsent>
<nextsent>3).
</nextsent>
<nextsent>the f-structureannotated cfg rule expanding n3 in the history based model is shown in the second line (hb-pcfg) of table 1.1 (t |f ) = ? ? in feats = {ai|ai ? ?(x)} (f gf) = ?(x) (x ? |x,feats,gf) (3) the history-based model is motivated by english data, for example, to generate the appropriate case for pronouns in subject position and object position, respectively.
</nextsent>
<nextsent>though chinese does not distinguish cases, we expect the f-structure parent gf to help predict grammar rule expansions more accurately in the tree derivation than the simple pcfg model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3824">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> chart generation and smoothing.  </section>
<citcontext>
<prevsection>
<prevsent>therefore we adopt the right binarisation method in our generation algorithm.
</prevsent>
<prevsent>algorithms 4.1 chart generation algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
the pcfg-based generation algorithms are implemented in terms of chart generator (kay, 1996).<papid> P96-1027 </papid></citsent>
<aftsection>
<nextsent>in the generation algorithm, each (sub-)f-structure indexes (sub-)chart.
</nextsent>
<nextsent>each local chart generates the most probable trees for the local f-structure in bottom-up manner: ? generating lexical edges from the the local gf pred and some atomic features representing function words, mood or aspect etc. 3except for prepositional phrases, localiser and some verbal phrases.
</nextsent>
<nextsent>89 np(m) nr [adjunct] ??
</nextsent>
<nextsent>shanghai nn [adjunct] ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3825">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> chart generation and smoothing.  </section>
<citcontext>
<prevsection>
<prevsent>particular lexical rules can be captured in general lexical macros abstracting away 4we use unknown words as cover term to refer to all words occurring in the test set but not in the training set.
</prevsent>
<prevsent>from particular surface forms to lemmas, e.g. the lexical macro encapsuling the above lexical rule is {pred=$lemma, ntype=common, num=sg}, which generally associates to common nouns nn in the ctb.
</prevsent>
</prevsection>
<citsent citstr=" J96-2001 ">
according to the assumption that unknown words have probability distribution similar to hapax lego menon (baayen and sproat, 1996), <papid> J96-2001 </papid>we predict the part-of-speech of unknown words from infrequent words in the training set by automatically extracting lexical macros corresponding to the particular set of f-structure features.</citsent>
<aftsection>
<nextsent>the probability of the potential pos tag associated to feature set is estimated according to eq.
</nextsent>
<nextsent>(6).
</nextsent>
<nextsent>p (t|f) = count(t, f)n i=1 count(ti, f) (6) 4.3 rule smoothing.
</nextsent>
<nextsent>the coverage of grammar rules increases with the size of training data and in theory all the rules can be fully covered by training set, if it is big enough.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3826">
<title id=" W08-1112.xml">accurate and robust lfgbased generation for chinese </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the c-structure trees of the test and development data were also automatically converted to f-structures as input to the generator.
</prevsent>
<prevsent>type with features without features pcfg 22,372 8,548 hb-pcfg 28,487 11,969 lex-pcfg 325,094 286,468 table 3: number of rules in the training set the generation system is evaluated against theraw text of the test data in terms of accuracy and coverage.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
following (langkilde, 2002) and other work on general-purpose generators, we adopt bleu score (papineni et al , 2002), <papid> P02-1040 </papid>average simple string accuracy (ssa) and percentage of exactly matched sentences for accuracy evaluation.6 for coverage evaluation, we measure the percentage of input structures that generate sentence.table 4 reports the initial experiments on the simple pcfg, hb-based pcfg and lexicalised pcfg models.</citsent>
<aftsection>
<nextsent>the results in the left column evaluate all input f-structures, the right column evaluate only those f-structures which yield complete sentence.the results show that the lexicalised model outperforms the baseline pcfg model.
</nextsent>
<nextsent>the hb model is the most accurate for complete sentences, but with reduced coverage compared to the other two models.
</nextsent>
<nextsent>however the low coverage of sentences completely generated due to unknown words and unmatched rules makes the results unusable in prac6we are aware of the limitations in fully automatic evaluation metrics, and in an ideal scenario, we would complement the bleu and ssa scores by human evaluation.
</nextsent>
<nextsent>unfortunately, this is beyond the scope of the current paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3828">
<title id=" W09-1602.xml">speech retrieval in unknown languages a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>#the student authors contribute equally.
</prevsent>
<prevsent>previous work on cross-lingual speech retrieval mostly leverages on intensive knowledge about allthe languages involved.
</prevsent>
</prevsection>
<citsent citstr=" W03-1508 ">
most reported work investigates retrieval in target language, in response toaudio or text queries given in different source language (meng et al, 2000; virga and khudanpur,2003).<papid> W03-1508 </papid></citsent>
<aftsection>
<nextsent>usually, the speech media in the target language, and the audio queries in the source language,are converted to speech recognition transcripts using large-vocabulary automatic speech recognizers (lvasr) trained for the target language and the source language respectively.
</nextsent>
<nextsent>the text queries, or transcribed audio queries, are translated to the target language.
</nextsent>
<nextsent>text retrieval techniques are applied to retrieve speech, by retrieving the corresponding lvasr transcription in the target language.
</nextsent>
<nextsent>in such systems, large-vocabulary speech recognizer trained on the target language is essential, which requires the existence of dictionary and labeled acoustic training data in that language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3829">
<title id=" W09-1602.xml">speech retrieval in unknown languages a pilot study </title>
<section> speech retrieval through subword.  </section>
<citcontext>
<prevsection>
<prevsent>to deal with the significant noise in the subword recognition output, and to emphasize the sequential information, we use the recognizer to obtain sub word lattices instead of one-best hypotheses.
</prevsent>
<prevsent>these lattices can be represented as weighted automata,which are compact representations of large number of alternative subword sequences, each associated with weight indicating the uncertainty of the data.
</prevsent>
</prevsection>
<citsent citstr=" W04-2907 ">
therefore, indexing speech in unknown language can be achieved by indexing the corresponding weighted automata with quasi-languageindependent sub words associated with the state tran sitions.we adopt the weighted automata indexation algorithm reported in (allauzen et al, 2004), <papid> W04-2907 </papid>which is optimal for searching subword sequences, as it takes time linear in the sum of the query size and the number of speech media entries where it appears.</citsent>
<aftsection>
<nextsent>the automata indexation algorithm also preserves these quential information, which is crutial for this task.
</nextsent>
<nextsent>we leverage on two kinds of knowledge for query expansion, namely empirical phone confusion and knowledge-based phone confusion.
</nextsent>
<nextsent>an illustration of our speech retrieval system is presented in figure 2.
</nextsent>
<nextsent>we detail the indexing approaching as well as query expansion and retrieval in this section.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3832">
<title id=" W08-2122.xml">a latent variable model of synchronous parsing for syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a larger model trained after the deadline achieves80.5% macro-average f1, 87.6% syntactic dependencies las, and 73.1% semantic dependencies f1.
</prevsent>
<prevsent>successes in syntactic tasks, such as statistical parsing and tagging, have recently paved the wayto statistical learning techniques for levels of semantic representation, such as recovering the logical form of sentence for information extraction and question-answering applications (e.g.
</prevsent>
</prevsection>
<citsent citstr=" N06-2026 ">
(wongand mooney, 2007)) or jointly learning the syntactic structure of the sentence and the propositional argument-structure of its main predicates (musillo and merlo, 2006; <papid> N06-2026 </papid>merlo and musillo, 2008).</citsent>
<aftsection>
<nextsent>in this vein, the conll 2008 shared task sets the challenge of learning jointly both syntactic dependencies (extracted from the penn treebank (marcus et al, 1993) ) <papid> J93-2004 </papid>and semantic dependencies (ex tracted both from propbank (palmer et al, 2005) ? ? <papid> J05-1004 </papid>2008.</nextsent>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3833">
<title id=" W08-2122.xml">a latent variable model of synchronous parsing for syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>successes in syntactic tasks, such as statistical parsing and tagging, have recently paved the wayto statistical learning techniques for levels of semantic representation, such as recovering the logical form of sentence for information extraction and question-answering applications (e.g.
</prevsent>
<prevsent>(wongand mooney, 2007)) or jointly learning the syntactic structure of the sentence and the propositional argument-structure of its main predicates (musillo and merlo, 2006; <papid> N06-2026 </papid>merlo and musillo, 2008).</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in this vein, the conll 2008 shared task sets the challenge of learning jointly both syntactic dependencies (extracted from the penn treebank (marcus et al, 1993) ) <papid> J93-2004 </papid>and semantic dependencies (ex tracted both from propbank (palmer et al, 2005) ? ? <papid> J05-1004 </papid>2008.</citsent>
<aftsection>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>0 authors in alphabetical order.and nombank (meyers et al, 2004) under unified representation.
</nextsent>
<nextsent>we propose solution that uses generative history-based model to predict the most likely derivation of synchronous dependency parser for both syntactic and semantic dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3834">
<title id=" W08-2122.xml">a latent variable model of synchronous parsing for syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>successes in syntactic tasks, such as statistical parsing and tagging, have recently paved the wayto statistical learning techniques for levels of semantic representation, such as recovering the logical form of sentence for information extraction and question-answering applications (e.g.
</prevsent>
<prevsent>(wongand mooney, 2007)) or jointly learning the syntactic structure of the sentence and the propositional argument-structure of its main predicates (musillo and merlo, 2006; <papid> N06-2026 </papid>merlo and musillo, 2008).</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
in this vein, the conll 2008 shared task sets the challenge of learning jointly both syntactic dependencies (extracted from the penn treebank (marcus et al, 1993) ) <papid> J93-2004 </papid>and semantic dependencies (ex tracted both from propbank (palmer et al, 2005) ? ? <papid> J05-1004 </papid>2008.</citsent>
<aftsection>
<nextsent>licensed under the creative commonsattribution-noncommercial-share alike 3.0 un ported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
</nextsent>
<nextsent>some rights reserved.
</nextsent>
<nextsent>0 authors in alphabetical order.and nombank (meyers et al, 2004) under unified representation.
</nextsent>
<nextsent>we propose solution that uses generative history-based model to predict the most likely derivation of synchronous dependency parser for both syntactic and semantic dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3835">
<title id=" W08-2122.xml">a latent variable model of synchronous parsing for syntactic and semantic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>0 authors in alphabetical order.and nombank (meyers et al, 2004) under unified representation.
</prevsent>
<prevsent>we propose solution that uses generative history-based model to predict the most likely derivation of synchronous dependency parser for both syntactic and semantic dependencies.
</prevsent>
</prevsection>
<citsent citstr=" W07-2218 ">
our probabilistic model is based on incremental sigmoid belief networks (isbns), recently proposed latent variable model for syntactic structure prediction, which has shown very good behaviour for both constituency (titov and henderson, 2007<papid> W07-2218 </papid>a) and dependency parsing (titov and henderson, 2007<papid> W07-2218 </papid>b).</citsent>
<aftsection>
<nextsent>the ability of isbns to induce their features automatically enables us to extend this architecture to learning synchronous parse of syntax and semantics without modification of the main architecture.
</nextsent>
<nextsent>by solving the problem with synchronous parsing, probabilistic model is learnt which maximises the joint probability of the syntactic and semantic dependencies and thereby guarantees that the output structure is globally coherent, while at the same time building the two structures separately.
</nextsent>
<nextsent>this extension of the isbn architecture is therefore applicable to other problems where two independent, but related, levels of representation are being learnt, such as statistical machine translation.
</nextsent>
<nextsent>currently the largest model we have trained achieves 80.5% macro-average f1 performance for the joint task, 87.6% syntactic dependencies las, and 73.1% semantic dependencies f1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3849">
<title id=" W08-2122.xml">a latent variable model of synchronous parsing for syntactic and semantic dependencies </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>thetwo dependency structures are specified as these quence of actions for synchronous parser, which requires each dependency structure to be projec 178 tivised separately.
</prevsent>
<prevsent>2.1 synchronous derivations.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
the derivations for syntactic dependency trees are the same as specified in (titov and henderson, 2007<papid> W07-2218 </papid>b), which are based on the shift-reduce style parser of (nivre et al, 2006).<papid> W06-2933 </papid></citsent>
<aftsection>
<nextsent>the derivations use astack and an input queue.
</nextsent>
<nextsent>there are actions for creating leftward or rightward arc between the top of the stack and the front of the queue, for popping word from the stack, and for shifting word fromthe queue to the stack.
</nextsent>
<nextsent>the derivations for semantic dependency graphs use virtually the same set of actions, but impose fewer constraints on when they can be applied, due to the fact that word in semantic dependency graph can have more than one parent.
</nextsent>
<nextsent>an additional action predicate was introduced to label predicate with sense s. let d be syntactic dependency tree with derivation 1 , ..., m d , and sbe semantic dependency graph with derivation 1 , ..., m s . to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3883">
<title id=" W08-1115.xml">whats in a message interpreting geo referenced data for the visually impaired </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(ferres etal, 2006) generates textual descriptions of information in graphs and enables user querying.
</prevsent>
<prevsent>sumtime1summarises time-series data and roadsafe2 generates travel advisories and looks at spatial time-seriesdata.
</prevsent>
</prevsection>
<citsent citstr=" C86-1134 ">
while there is no prior work on generating textual descriptions of geo-referenced data, there have been studies on describing spatial data in the context of route directions ((geldof, 2003), (marciniak and strube, 2004)), scene descriptions (novak, 1986), <papid> C86-1134 </papid>geometric descriptions (mitkov, 1990) <papid> C90-3093 </papid>and spatial descriptions (ebert et al 1996).data-to-text generation projects like atlas.txt differ from the traditional three-stage pipeline generation architecture of most nlg systems (reiter and dale, 2000) because they need to analyse the data in order to determine data abstractions before then going on to the traditional three stages of document planning, micro-planning and realisation, as was put forward by (sripada, reiter et al 2001).</citsent>
<aftsection>
<nextsent>content determination has been described as involving collective classification problem (barzilay and lapata, 1more information can be found at http://www.csd.abdn.ac.uk/research/sumtime.
</nextsent>
<nextsent>2see http://www.csd.abdn.ac.uk/research/roadsafe.
</nextsent>
<nextsent>2005) and in the context of data-to-text systems.
</nextsent>
<nextsent>since our system involves data-to-text nlg, content determination has more in common with the two stage process of (sripada, reiter et al 2001) than the classification process of (barzilay and lapata, 2005).<papid> H05-1042 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3884">
<title id=" W08-1115.xml">whats in a message interpreting geo referenced data for the visually impaired </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(ferres etal, 2006) generates textual descriptions of information in graphs and enables user querying.
</prevsent>
<prevsent>sumtime1summarises time-series data and roadsafe2 generates travel advisories and looks at spatial time-seriesdata.
</prevsent>
</prevsection>
<citsent citstr=" C90-3093 ">
while there is no prior work on generating textual descriptions of geo-referenced data, there have been studies on describing spatial data in the context of route directions ((geldof, 2003), (marciniak and strube, 2004)), scene descriptions (novak, 1986), <papid> C86-1134 </papid>geometric descriptions (mitkov, 1990) <papid> C90-3093 </papid>and spatial descriptions (ebert et al 1996).data-to-text generation projects like atlas.txt differ from the traditional three-stage pipeline generation architecture of most nlg systems (reiter and dale, 2000) because they need to analyse the data in order to determine data abstractions before then going on to the traditional three stages of document planning, micro-planning and realisation, as was put forward by (sripada, reiter et al 2001).</citsent>
<aftsection>
<nextsent>content determination has been described as involving collective classification problem (barzilay and lapata, 1more information can be found at http://www.csd.abdn.ac.uk/research/sumtime.
</nextsent>
<nextsent>2see http://www.csd.abdn.ac.uk/research/roadsafe.
</nextsent>
<nextsent>2005) and in the context of data-to-text systems.
</nextsent>
<nextsent>since our system involves data-to-text nlg, content determination has more in common with the two stage process of (sripada, reiter et al 2001) than the classification process of (barzilay and lapata, 2005).<papid> H05-1042 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3885">
<title id=" W08-1115.xml">whats in a message interpreting geo referenced data for the visually impaired </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2see http://www.csd.abdn.ac.uk/research/roadsafe.
</prevsent>
<prevsent>2005) and in the context of data-to-text systems.
</prevsent>
</prevsection>
<citsent citstr=" H05-1042 ">
since our system involves data-to-text nlg, content determination has more in common with the two stage process of (sripada, reiter et al 2001) than the classification process of (barzilay and lapata, 2005).<papid> H05-1042 </papid></citsent>
<aftsection>
<nextsent>however notable difference between our domain and the meteorology domain described in(sripada, reiter et al 2001), is that for us, arriving at an overview before communicating the data to the end-user involves not just data analysis but also scene description to aid in our visualisation goal.
</nextsent>
<nextsent>system the atlas.txt system aims to be able to take geo referenced data in tabular form, perform data analysis to determine significant features in the data, and then communicate these significant features via text.
</nextsent>
<nextsent>data analysis for atlas.txt involves clustering to find regions in the geography with similar values of census variable.
</nextsent>
<nextsent>data analysis also involves trending to find spatial trends in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3886">
<title id=" W08-1914.xml">the computation of associative responses to multiword stimuli </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>only words that are strongly in-terconnected or have strong associations to external stimuli can be uttered or written down.
</prevsent>
<prevsent>pre-supposing the validity of the law of associa-tion, it should be possible to derive free word associations from the distribution of words in texts.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
following church &amp; hanks (1990), <papid> J90-1003 </papid>rapp (2004), and wettler et al (2005) this actually seems to be successful.</citsent>
<aftsection>
<nextsent>the recent simulation algorithms generate results which largely agree with the free word associations as found in the association norms.
</nextsent>
<nextsent>an example is shown in ta-ble 1, where the observed and the simulated re-sponses to the stimulus word cold are compared.
</nextsent>
<nextsent>102 observed response number of subjects predicted response number of subjects hot ice warm water freeze wet feet freezing nose room sneeze sore winter 34 10 7 5 3 3 2 2 2 2 2 2 2 hot winter weather warm water heat ice wet wind temperature shiver freeze rain 34 2 0 7 5 1 10 3 0 0 0 3 0 table 1: observed and predicted associative responses to the stimulus word cold.
</nextsent>
<nextsent>when judging these results it should be kept in mind that among subjects there is some variation of responses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3887">
<title id=" W08-1914.xml">the computation of associative responses to multiword stimuli </title>
<section> simulation program.  </section>
<citcontext>
<prevsection>
<prevsent>this is window size that corresponds with what had been found appropriate for the computation of associations in other studies (e.g. rapp, 2004).
</prevsent>
<prevsent>as the co-occurrence counts largely depend on overall word frequency, some association meas-ure needs to be applied to eliminate this unde-sired influence.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
many previous studies have shown that the log-likelihood ratio is well suited for this purpose (dunning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>it successfully eliminates word-frequency effects and empha-sizes significant word pairs by comparing their observed co-occurrence counts with their ex-pected co-occurrence counts.
</nextsent>
<nextsent>it can be expected that the log-likelihood ratio produces an accurate ranking of word pairs that highly correlates with human judgment (dunning, 1993), <papid> J93-1003 </papid>although there are other measures which come close in performance (e.g. rapp, 1998).</nextsent>
<nextsent>to compute the associations to pairs of stimu-lus words, it would in principle be possible to consider text positions where both stimulus words occur together, and to count the co-occurrence frequencies with their neighboring words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3889">
<title id=" W08-1914.xml">the computation of associative responses to multiword stimuli </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>definition solu-tion length words of this length rank bnc rank guardian rank wikipedia 2-3 what bargain hunters enjoy sales 5 4254 1014 70 338 4-5 written acknowledgement receipt 7 5371 2 44 355 6-7 such and nothing more mere 4 2916 16 17 4 10-11 bird dove 4 2916 17 87 4 14-15 opposed to less more 4 2916 42 34 5 18-19 what this puzzle is hard 4 2916 1486 115 384 22-23 an animal of prey lion 4 2916 84 16 324 26-27 the close of day evening 7 5371 603 494 185 28-29 to elude evade 5 4254 80 64 38 30-31 the plural of is are 3 1424 238 119 412 8-9 to cultivate farm 4 2916 2316 2783 1070 12-13 bar of wood or iron rail 4 2916 1658 1419 925 16-17 what artists learn to do draw 4 2916 227 1437 86 20-21 fastened tied 4 2916 15 2335 2078 24-25 found on the seashore sand 4 2916 124 19 757 10-18 the fibre of the gomuti palm doh 3 1424 585 279 711 6-22 what we all should be moral 5 4254 4107 1163 51 4-26 day dream reverie 6 5371 489 572 2 2-11 talon sere 4 2916 676 803 492 19-28 pigeon dove 4 2916 36 8 1 f-7 part of your head face 4 2916 63 20 143 23-30 river in russia neva 4 2916 174 413 3 1-32 to govern rule 4 2916 48 9 13 33-34 an aromatic plant nard 4 2916 616 2753 393 n-8 fist neif 4 2916 --- --- --- 24-31 to agree with side 4 2916 2836 2393 1387 3-12 part of ship spar 4 2916 2693 1932 90 20-29 one tane 4 2916 2814 2773 2680 5-27 exchanging trading 7 5371 3444 5216 2347 9-25 sunk in mud mired 5 4254 3 2 1 13-21 boy lad 3 1424 3 2 2 average rank 891.6 922.3 520.2 table 2: crossword puzzle definitions and the computed ranks of their solutions based on three corpora.
</prevsent>
<prevsent>means that solution does not occur in corpus (not taken into account when computing average ranks).
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
107 tions from monolingual english and german cor-pora, i.e. from corpora that are not translations of each other (rapp, 1999).<papid> P99-1067 </papid></citsent>
<aftsection>
<nextsent>this is rather difficult task.
</nextsent>
<nextsent>as our textual basis, for german we use the faz corpus as described above, with exactly the same pre-processing.
</nextsent>
<nextsent>for english we use simi-larly sized corpus of the newspaper the guard-ian?, with analogous pre-processing.
</nextsent>
<nextsent>we apply two-stage procedure to compute the translation of source language word: first, by considering the log-likelihood ratios, its strongest source language associations are de-termined and translated to the target language using small pocket dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3891">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that maximises the conditional posterior probability p(e|f).
</prevsent>
<prevsent>this probabilistic formulation of translation has driven development of state-of-the-art systems which are able to learn from parallel corpora which were generated for other purposes ? direct result of employing mathematical framework that we can reason about independently of any particular model.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></citsent>
<aftsection>
<nextsent>alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></nextsent>
<nextsent>we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3892">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that maximises the conditional posterior probability p(e|f).
</prevsent>
<prevsent>this probabilistic formulation of translation has driven development of state-of-the-art systems which are able to learn from parallel corpora which were generated for other purposes ? direct result of employing mathematical framework that we can reason about independently of any particular model.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></citsent>
<aftsection>
<nextsent>alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></nextsent>
<nextsent>we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3893">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that maximises the conditional posterior probability p(e|f).
</prevsent>
<prevsent>this probabilistic formulation of translation has driven development of state-of-the-art systems which are able to learn from parallel corpora which were generated for other purposes ? direct result of employing mathematical framework that we can reason about independently of any particular model.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></citsent>
<aftsection>
<nextsent>alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></nextsent>
<nextsent>we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3894">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this probabilistic formulation of translation has driven development of state-of-the-art systems which are able to learn from parallel corpora which were generated for other purposes ? direct result of employing mathematical framework that we can reason about independently of any particular model.
</prevsent>
<prevsent>for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></citsent>
<aftsection>
<nextsent>we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</nextsent>
<nextsent>most models define multiple derivations for each translation; the probability of translation is thus the sum over all of its derivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3895">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this probabilistic formulation of translation has driven development of state-of-the-art systems which are able to learn from parallel corpora which were generated for other purposes ? direct result of employing mathematical framework that we can reason about independently of any particular model.
</prevsent>
<prevsent>for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></citsent>
<aftsection>
<nextsent>we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</nextsent>
<nextsent>most models define multiple derivations for each translation; the probability of translation is thus the sum over all of its derivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3898">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this probabilistic formulation of translation has driven development of state-of-the-art systems which are able to learn from parallel corpora which were generated for other purposes ? direct result of employing mathematical framework that we can reason about independently of any particular model.
</prevsent>
<prevsent>for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1062 ">
alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></citsent>
<aftsection>
<nextsent>we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</nextsent>
<nextsent>most models define multiple derivations for each translation; the probability of translation is thus the sum over all of its derivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3900">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
<prevsent>alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-1012 ">
we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</citsent>
<aftsection>
<nextsent>most models define multiple derivations for each translation; the probability of translation is thus the sum over all of its derivations.
</nextsent>
<nextsent>unfortunately,finding the maximum probability translation is np hard for all but the most trivial of models in this setting (simaan, 1996).
</nextsent>
<nextsent>it is thus necessary to resort to approximations for this sum and the search for its maximum e?.
</nextsent>
<nextsent>the most common of these approximations is the max-derivation approximation, which for many models can be computed in polynomial time via dynamic programming (dp).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3901">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, we can train smt models using maximum likelihood estimation (brown et al, 1993;<papid> J93-2003 </papid>och and ney, 2000; <papid> C00-2163 </papid>marcu and wong, 2002).<papid> W02-1018 </papid></prevsent>
<prevsent>alternatively, we can train to minimise probabilistic conceptions of risk (expected loss) with respect to translation metrics, thereby obtaining better results for those metrics (kumar and byrne, 2004; <papid> N04-1022 </papid>smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></prevsent>
</prevsection>
<citsent citstr=" D08-1033 ">
we can also use bayesian inference techniques to avoid resorting to heuristics that damage the probabilistic interpretation of the models (zhang et al, 2008; <papid> P08-1012 </papid>denero et al., 2008; <papid> D08-1033 </papid>blunsom et al, 2009).</citsent>
<aftsection>
<nextsent>most models define multiple derivations for each translation; the probability of translation is thus the sum over all of its derivations.
</nextsent>
<nextsent>unfortunately,finding the maximum probability translation is np hard for all but the most trivial of models in this setting (simaan, 1996).
</nextsent>
<nextsent>it is thus necessary to resort to approximations for this sum and the search for its maximum e?.
</nextsent>
<nextsent>the most common of these approximations is the max-derivation approximation, which for many models can be computed in polynomial time via dynamic programming (dp).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3902">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>normalization factor z(f) required by many probabilistic algorithms.
</prevsent>
<prevsent>in this work, we solve these problems using amonte carlo technique with none of the above drawbacks.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
our technique is based on novel gibbs sampler that draws samples from the posterior distribution of phrase-based translation model (koehn et al, 2003) <papid> N03-1017 </papid>but operates in linear time with respect to the number of input words (section 2).</citsent>
<aftsection>
<nextsent>we show 102 that it is effective for both decoding (section 3) and minimum risk training (section 4).
</nextsent>
<nextsent>translation models we begin by assuming phrase-based translation model in which the input sentence, , is segmented into phrases, which are sequences of adjacent words.1 each foreign phrase is translated into the target language, to produce an output sentence and an alignment representing the mapping from source to target phrases.
</nextsent>
<nextsent>phrases are allowed to be reordered during translation.
</nextsent>
<nextsent>the model is defined with log-linear form, with feature function vector and parametrised by weight vector ?, as described in koehn et al (2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3905">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> decoding.  </section>
<citcontext>
<prevsection>
<prevsent>for the german and french systems, the dev2006 set was used for model tuning and the test2007 (in-domain) and news-dev2009b (out-of-domain) sets for testing.
</prevsent>
<prevsent>for the arabic system, the mt02 set (10 reference translations) was used for tuning and mt03 (4 reference translations) was used for evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N07-1018 ">
to reduce the size of the phrase table, we used the association-score technique suggested by johnson et al (2007<papid> N07-1018 </papid>a).</citsent>
<aftsection>
<nextsent>translation quality is reported using case-insensitive bleu (papineni et al., 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>3.2 translation performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3907">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> decoding.  </section>
<citcontext>
<prevsection>
<prevsent>for the arabic system, the mt02 set (10 reference translations) was used for tuning and mt03 (4 reference translations) was used for evaluation.
</prevsent>
<prevsent>to reduce the size of the phrase table, we used the association-score technique suggested by johnson et al (2007<papid> N07-1018 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
translation quality is reported using case-insensitive bleu (papineni et al., 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>3.2 translation performance.
</nextsent>
<nextsent>for the experiments reported in this section, we used feature weights trained with minimum error rate training (mert; och, 2003) . <papid> P03-1021 </papid>because mert ignores the denominator in equation 1, it is invari ant with respect to the scale of the weight vector ? ?</nextsent>
<nextsent>the moses implementation simply normalises the weight vector it finds by its `1-norm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3908">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> decoding.  </section>
<citcontext>
<prevsection>
<prevsent>translation quality is reported using case-insensitive bleu (papineni et al., 2002).<papid> P02-1040 </papid></prevsent>
<prevsent>3.2 translation performance.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for the experiments reported in this section, we used feature weights trained with minimum error rate training (mert; och, 2003) . <papid> P03-1021 </papid>because mert ignores the denominator in equation 1, it is invari ant with respect to the scale of the weight vector ? ?</citsent>
<aftsection>
<nextsent>the moses implementation simply normalises the weight vector it finds by its `1-norm.
</nextsent>
<nextsent>however, when we use these weights in true probabilistic model, the scaling factor affects the behaviour of the model since it determines how peaked or flat the distribution is. if the scaling factor is too small, then the distribution is too flat and the sampler spends too much time exploring unimportant probability regions.
</nextsent>
<nextsent>if it is too large, then the distribution is too peaked and the sampler may concentrate on very narrow probability region.
</nextsent>
<nextsent>we optimised the scaling factor on 200-sentence portion of the tuning set, finding that multiplicative factor of 10 worked best for fr-en and multiplicative factor of 6 for de-en.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3909">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> decoding.  </section>
<citcontext>
<prevsection>
<prevsent>we optimised the scaling factor on 200-sentence portion of the tuning set, finding that multiplicative factor of 10 worked best for fr-en and multiplicative factor of 6 for de-en.
</prevsent>
<prevsent>3 the first experiment shows the effect of different initialisations and numbers of sampler iterations onmax-derivation decoding performance of the sampler.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the moses decoder (koehn et al, 2007) <papid> P07-2045 </papid>was used to generate the starting hypothesis, either in full dp max-derivation mode, or alternatively with restrictions on the features and reordering, or with zero weights to simulate random initial isation, and the number of iterations varied from 100 to 200,000, with 100 iteration burn-in in each case.</citsent>
<aftsection>
<nextsent>figure 3shows the variation of model score with sampler iteration, for the different starting points, and for both language pairs.
</nextsent>
<nextsent>3we experimented with annealing, where the scale factor is gradually increased to sharpen the distribution while sampling.
</nextsent>
<nextsent>however, we found no improvements with annealing.
</nextsent>
<nextsent>105 ? 20.1 ? 20.0 ? 19.9 ? 19.8 ? 19.7 ? 19.6 iterations model score 100 1000 10000 french english initialisationfull mono nolm zero ? 40.6 ? 40.4 ? 40.2 ? 40.0 ? 39.8 iterations model score 100 1000 10000 100000 german english initialisationfull mono nolm zero figure 3: mean maximum model score, as function of iteration number and starting point.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3911">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> minimum risk training.  </section>
<citcontext>
<prevsection>
<prevsent>in the previous section, we described how our sampler can be used to search for the best translation under variety of decoding criteria (max derivation, translation, and minimum risk).
</prevsent>
<prevsent>however, there appeared to be little benefit to marginalizing over the latent derivations.
</prevsent>
</prevsection>
<citsent citstr=" P08-1024 ">
this is almost certainly side effect of the mert training approach that was usedto construct the models so as to maximise the performance of the model on its single best derivation,without regard to the shape of the rest of the distribution (blunsom et al, 2008).<papid> P08-1024 </papid></citsent>
<aftsection>
<nextsent>in this section we describe further application of the gibbs sampler: to do unbiased minimum risk training.
</nextsent>
<nextsent>while there have been at least two previous attempts to do minimum risk training for mt, both approaches relied on biased k-best approximations (smith and eisner, 2006; <papid> P06-2101 </papid>zens and ney, 2007).<papid> N07-1062 </papid></nextsent>
<nextsent>since we sample from the whole distribution, we will have more accurate risk assessment.the risk, or expected loss, of probabilistic translation model on corpus d, defined with respect toa particular loss function `e?(e), where e?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3919">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with the sampler this restriction ismitigated: any function of h(e, f, a) may participate in the translation model subject only to its own computability.
</prevsent>
<prevsent>freed from the rusty manacles of dynamic programming, we anticipate development of many useful features.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
our sampler is similar to the decoder of german net al (2001), <papid> P01-1030 </papid>which starts with an approximate solution and then incrementally improves it via operators such as retrans and merge-split.</citsent>
<aftsection>
<nextsent>it is also similar to the estimator of marcu and wong (2002),<papid> W02-1018 </papid>who employ the same operators to search the alignment space from heuristic initialisation.</nextsent>
<nextsent>although the operators are similar, the use is different.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3921">
<title id=" W09-1114.xml">monte carlo inference and maximization for phrase based translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these previous efforts employed their operators in greedy hill-climbing search.
</prevsent>
<prevsent>in contrast, our operators are applied probabilistically, making them theoretically well-founded for variety of inference problems.
</prevsent>
</prevsection>
<citsent citstr=" W06-1673 ">
our use of gibbs sampling follows from its increasing use in bayesian inference problems in nlp (finkel et al, 2006; <papid> W06-1673 </papid>johnson et al, 2007<papid> N07-1018 </papid>b).</citsent>
<aftsection>
<nextsent>most closely related is the work of denero et al (2008), <papid> D08-1033 </papid>who derive gibbs sampler for phrase-based alignment, using it to infer phrase translation probabilities.</nextsent>
<nextsent>the use of monte carlo techniques to calculate posteriors is similar to that of chappelier and rajman (2000) who use those techniques to find the best parse under models where the derivation and the parse are not isomorphic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3929">
<title id=" W09-0626.xml">what game theory can do for nlg the case of vague language invited talk </title>
<section> game theory.  </section>
<citcontext>
<prevsection>
<prevsent>more specifically, many nlg systems invitea game-theoretical analysis ? or an optimality theoretic analysis, which can come down to the same thing (dekker and van rooij 2000; van deemter 2004 for an application to nlg).
</prevsent>
<prevsent>suppose want to state that all old people are entitled to certain benefits (cf.
</prevsent>
</prevsection>
<citsent citstr=" W09-0615 ">
khan et al 2009): <papid> W09-0615 </papid>a. old men and old women are entitled to benefits.</citsent>
<aftsection>
<nextsent>b. old men and women are entitled to benefits.
</nextsent>
<nextsent>which of these two linguistic forms should choose?
</nextsent>
<nextsent>this depends on the strategy of the hearer.
</nextsent>
<nextsent>if the hearer interprets (b) as concerning all women (rather only the old ones) then my utterance will have misfired to an extent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3930">
<title id=" W09-0626.xml">what game theory can do for nlg the case of vague language invited talk </title>
<section> game theory.  </section>
<citcontext>
<prevsection>
<prevsent>can helpthe generals to cooperate and win the battle.
</prevsent>
<prevsent>essentially the same things happens when you try to meet friend: neither of you may care where and when to meet, as long as the two of you end up in the same place at the same time; communication, of course, can help you achieve this goal.
</prevsent>
</prevsection>
<citsent citstr=" W09-0616 ">
applications of game theory to language now come in many flavours (see e.g. klabunde 2009, <papid> W09-0616 </papid>this conference).</citsent>
<aftsection>
<nextsent>in this paper want to engage in small case study: the expression of quantitative information in english.
</nextsent>
<nextsent>more specifically,i will focus on the fact that quantitative information is often only communicated vaguely.
</nextsent>
<nextsent>when thermometer, for example, measures your body temperature as 39.82 celcius, your doctor might express this by saying that your temperature is 39.8 degrees?, but he might also round this off even further, saying that it is approximately 40 degrees?.
</nextsent>
<nextsent>even more vaguely, she might tell youthat you have high fever?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3931">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe here the two sys tran/university of edinburgh submissions for wmt2009.
</prevsent>
<prevsent>they involve statisticalpost-editing model with particular handling of named entities (english to french and german to english) and the extraction of phrasal rules (english to french).
</prevsent>
</prevsection>
<citsent citstr=" N07-1064 ">
previous results had shown rather satisfying performance for hybrid systems such as the statistical phrase-based post-editing (spe) (simard et al ., 2007) <papid> N07-1064 </papid>combination in comparison with purelyphrase-based statistical models, reaching similar bleu scores and often receiving better human judgement (german to english at wmt2007) against the bleu metric.</citsent>
<aftsection>
<nextsent>this last result was in accordance with the previous acknowledgment (callison-burch et al , 2006) that systems of too differing structure could not be compared reliably with bleu.
</nextsent>
<nextsent>we participated in the recent work shop on machine translation (wmt09) in the language pairs english to french and german toenglish.
</nextsent>
<nextsent>on the one hand we trained post editing system with an additional special treatment to avoid the loss of entities such as dates andnumbers.
</nextsent>
<nextsent>on the other hand we trained an additional english-to-french system (as secondarysubmission) that made use of automatically extracted linguistic entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3932">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> statistical post editing systems.  </section>
<citcontext>
<prevsection>
<prevsent>the latter is part of on going work motivated by the desire to both make use of corpus statistics and keep the advantage of the often (relative to automatic metricss scores)higher rankin human judgement given to rule based systems on out-of-domain data, as seen on figure 1: translation with pbmt post-editing the wmt 2008 results for both english to french and german to english (callison-burch et al , 2008).
</prevsent>
<prevsent>2.1 baseline.
</prevsent>
</prevsection>
<citsent citstr=" W07-0732 ">
the basic setup is identical to the one described in (dugast et al , 2007).<papid> W07-0732 </papid></citsent>
<aftsection>
<nextsent>a statistical translation model is trained between the rule-based translation of the source-side and the target-side of the parallel corpus.
</nextsent>
<nextsent>this is done separately for each parallel corpus.
</nextsent>
<nextsent>language models are trained on each target half of the parallel corpora and also on additional in-domain corpora.
</nextsent>
<nextsent>figure 1 shows the translation process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3933">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> statistical post editing systems.  </section>
<citcontext>
<prevsection>
<prevsent>we only made use of the news commentary and the europarl corpora.
</prevsent>
<prevsent>we used additional in-domain news corpora to train 5 grams language models, according to the baseline recommendations.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
weights for these separate models were tuned through the mert algorithm provided in the moses toolkit (koehn et al , 2007), <papid> P07-2045 </papid>using the provided news tuning set.</citsent>
<aftsection>
<nextsent>2.2 trimming.
</nextsent>
<nextsent>in statistical translation model, trimming of the phrase table had been shown to be beneficial (johnson et al , 2007).<papid> D07-1103 </papid></nextsent>
<nextsent>for our post-editing model, we can afford to perform an even more aggressive trimming of the phrase table, since the rule-based system already provides us with translation andwe only aim at correcting the most frequent er rors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3934">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> statistical post editing systems.  </section>
<citcontext>
<prevsection>
<prevsent>weights for these separate models were tuned through the mert algorithm provided in the moses toolkit (koehn et al , 2007), <papid> P07-2045 </papid>using the provided news tuning set.</prevsent>
<prevsent>2.2 trimming.</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
in statistical translation model, trimming of the phrase table had been shown to be beneficial (johnson et al , 2007).<papid> D07-1103 </papid></citsent>
<aftsection>
<nextsent>for our post-editing model, we can afford to perform an even more aggressive trimming of the phrase table, since the rule-based system already provides us with translation andwe only aim at correcting the most frequent errors.
</nextsent>
<nextsent>therefore, we suppress all unique phrase pairs before calculating the probabilities for the final phrase table.
</nextsent>
<nextsent>2.3 avoiding the loss of entities.
</nextsent>
<nextsent>deleted and spurious content is well known problem for statistical models (chiang et al ,2008).<papid> D08-1064 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3935">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> statistical post editing systems.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we suppress all unique phrase pairs before calculating the probabilities for the final phrase table.
</prevsent>
<prevsent>2.3 avoiding the loss of entities.
</prevsent>
</prevsection>
<citsent citstr=" D08-1064 ">
deleted and spurious content is well known problem for statistical models (chiang et al ,2008).<papid> D08-1064 </papid></citsent>
<aftsection>
<nextsent>though we do not know of any study proving it, it seems obvious that named entities that would be either deleted or added to the output out of nowhere is an especially problematic kind of rule-based french reference french ent date et ent date ent numeric et ent numeric de golfe . du golfe ent date . decennie ent numeric ans et ent numeric . . table 1: examples of problematic phrase pairs error for the translation quality.
</nextsent>
<nextsent>the rule-basedtranslation engine benefits from an entity recognition layer for numbers, dates and hours, addresses, company names and uris.
</nextsent>
<nextsent>we therefore trim?
</nextsent>
<nextsent>(delete) from the extracted phrase pairs any item that would not translate all entities from the source(i.e. the rbmt output) to the target or add spurious entities which were not present in the source side of the phrase pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3937">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>post editing setups were tuned on the news tuning set.
</prevsent>
<prevsent>we presented few improvements to the statistical post editing setup.
</prevsent>
</prevsection>
<citsent citstr=" C08-1115 ">
they are part of an effort to better integrate linguistic, rule-based system and the statistical correcting layer also illustrated in (ueffing et al , 2008).<papid> C08-1115 </papid></citsent>
<aftsection>
<nextsent>moreover, we presented dictionary extraction setup which resulted in an improvement of 2 to 3 bleu points over the base line rule-based system when in-domain,as can beseen in table 4.
</nextsent>
<nextsent>this however improved translation very little on the news?
</nextsent>
<nextsent>domain which was used for evaluation.
</nextsent>
<nextsent>we think that is different issue, namely of domain adaptation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3939">
<title id=" W09-0419.xml">statistical post editing and dictionary extraction systranedinburgh submissions for aclwmt2009 </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>domain which was used for evaluation.
</prevsent>
<prevsent>we think that is different issue, namely of domain adaptation.
</prevsent>
</prevsection>
<citsent citstr=" W08-0327 ">
in order topush further this rule-extraction approach and according to our previous work (dugast et al , 2007) (<papid> W07-0732 </papid>dugast et al , 2008), <papid> W08-0327 </papid>the most promising would probably be the use of alternative meanings and language model to decode the best translation in such lattice.</citsent>
<aftsection>
<nextsent>another path for improvement would be to try and extract rules with more fea 113tures, such as constraints of lexical subcategorization as they already exist in the manually entered entries.
</nextsent>
<nextsent>finally, we would like to try combining the dictionary extraction setup with statistical post-editing layer to see if the latter supersedes the former.
</nextsent>
<nextsent>acknowledgement we would like to thank the anonymous reviewers for their comments and corrections.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3940">
<title id=" W09-0411.xml">translation combination using factored word substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even the most advanced mt technology as summarized by(lopez, 2008), including the best statistical, rule based and example-based systems, produces out put rife with errors.
</prevsent>
<prevsent>those systems may employ different algorithms or vary in the linguistic resources they use which in turn leads to different characteristic errors.
</prevsent>
</prevsection>
<citsent citstr=" D07-1105 ">
besides continued research on improving mttechniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages (macherey and och, 2007; <papid> D07-1105 </papid>rosti et al, 2007<papid> P07-1040 </papid>a).current approaches for system combination involve post-editing methods (dugast et al, 2007;<papid> W07-0732 </papid>theison, 2007), re-ranking strategies, or shallow phrase substitution.</citsent>
<aftsection>
<nextsent>the combination procedure applied for this pape tries to optimize word-level translations within trusted?
</nextsent>
<nextsent>sentence frame selected due to the high quality of its syntactic structure.
</nextsent>
<nextsent>the underlying idea of the approach is the improvement of given (original) translation through the exploitation of additional translations of the same text.
</nextsent>
<nextsent>this can be seen as simplified version of (rosti et al, 2007<papid> P07-1040 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3941">
<title id=" W09-0411.xml">translation combination using factored word substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even the most advanced mt technology as summarized by(lopez, 2008), including the best statistical, rule based and example-based systems, produces out put rife with errors.
</prevsent>
<prevsent>those systems may employ different algorithms or vary in the linguistic resources they use which in turn leads to different characteristic errors.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
besides continued research on improving mttechniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages (macherey and och, 2007; <papid> D07-1105 </papid>rosti et al, 2007<papid> P07-1040 </papid>a).current approaches for system combination involve post-editing methods (dugast et al, 2007;<papid> W07-0732 </papid>theison, 2007), re-ranking strategies, or shallow phrase substitution.</citsent>
<aftsection>
<nextsent>the combination procedure applied for this pape tries to optimize word-level translations within trusted?
</nextsent>
<nextsent>sentence frame selected due to the high quality of its syntactic structure.
</nextsent>
<nextsent>the underlying idea of the approach is the improvement of given (original) translation through the exploitation of additional translations of the same text.
</nextsent>
<nextsent>this can be seen as simplified version of (rosti et al, 2007<papid> P07-1040 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3945">
<title id=" W09-0411.xml">translation combination using factored word substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even the most advanced mt technology as summarized by(lopez, 2008), including the best statistical, rule based and example-based systems, produces out put rife with errors.
</prevsent>
<prevsent>those systems may employ different algorithms or vary in the linguistic resources they use which in turn leads to different characteristic errors.
</prevsent>
</prevsection>
<citsent citstr=" W07-0732 ">
besides continued research on improving mttechniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages (macherey and och, 2007; <papid> D07-1105 </papid>rosti et al, 2007<papid> P07-1040 </papid>a).current approaches for system combination involve post-editing methods (dugast et al, 2007;<papid> W07-0732 </papid>theison, 2007), re-ranking strategies, or shallow phrase substitution.</citsent>
<aftsection>
<nextsent>the combination procedure applied for this pape tries to optimize word-level translations within trusted?
</nextsent>
<nextsent>sentence frame selected due to the high quality of its syntactic structure.
</nextsent>
<nextsent>the underlying idea of the approach is the improvement of given (original) translation through the exploitation of additional translations of the same text.
</nextsent>
<nextsent>this can be seen as simplified version of (rosti et al, 2007<papid> P07-1040 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3950">
<title id=" W09-0411.xml">translation combination using factored word substitution </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the alignment between source text and translations is needed to identify translation options within the different systems?
</prevsent>
<prevsent>translations.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignment is computed using the giza++ toolkit (ochand ney, 2003), <papid> J03-1002 </papid>only one-to-one word alignments are employed.</citsent>
<aftsection>
<nextsent>select substitution candidates.
</nextsent>
<nextsent>for the shared task, we decide to substitute nouns, verbs and adjectives based on the available postags.
</nextsent>
<nextsent>initially, any such source word is considered as possible substitution candidate.as we do not want to require substitution can 70 didates to have exactly the same pos tag as the source, we use groups of similar?
</nextsent>
<nextsent>tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3951">
<title id=" W09-0610.xml">a model for human readable instruction generation using level based discourse planning and dynamic inference of attributes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm returns list of attribute-value pairs that correspond to the semantic content of there ferring expression to be realized.
</prevsent>
<prevsent>the algorithm operates by ite rating over the list of available attributes, looking for one that is known to the user and rules out the largest number of elements of the contrast set that have not already been ruled out.
</prevsent>
</prevsection>
<citsent citstr=" W05-1607 ">
referring expression generation in physically situated environments has been studied in (kelle her and kruijff, 2005).<papid> W05-1607 </papid></citsent>
<aftsection>
<nextsent>the goal of this work is to develop embodied conversational robots that are capable of natural, fluent visually situated dialog with one or more interlocutors.
</nextsent>
<nextsent>in this kind of situation very important aspect to take into account is how to refer to objects located in the physical environment.
</nextsent>
<nextsent>the authors present in the paper computational framework for the generation of spatial locative expressions in such contexts, relying on the reiter and dale (reiter and dale, 1992) <papid> C92-1038 </papid>algorithm.another interesting work related to referring expression generation in spatial environments can be found in (varges, 2005).<papid> W05-1627 </papid></nextsent>
<nextsent>the author uses the mapsof the map task dialogue corpus as domain models, and treats spatial descriptions as referring expressions that distinguish particular points on themap from all other points (considered as distrac tors).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3952">
<title id=" W09-0610.xml">a model for human readable instruction generation using level based discourse planning and dynamic inference of attributes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of this work is to develop embodied conversational robots that are capable of natural, fluent visually situated dialog with one or more interlocutors.
</prevsent>
<prevsent>in this kind of situation very important aspect to take into account is how to refer to objects located in the physical environment.
</prevsent>
</prevsection>
<citsent citstr=" C92-1038 ">
the authors present in the paper computational framework for the generation of spatial locative expressions in such contexts, relying on the reiter and dale (reiter and dale, 1992) <papid> C92-1038 </papid>algorithm.another interesting work related to referring expression generation in spatial environments can be found in (varges, 2005).<papid> W05-1627 </papid></citsent>
<aftsection>
<nextsent>the author uses the mapsof the map task dialogue corpus as domain models, and treats spatial descriptions as referring expressions that distinguish particular points on themap from all other points (considered as distrac tors).
</nextsent>
<nextsent>related research can be found in (stoia et al, 2006), <papid> N06-2040 </papid>where study of how humans give orders in navigation environmnets and an algorithm implementing the observed behaviour is shown.</nextsent>
<nextsent>there are many other approaches to instruction giving.directly related with this work, it is worth mentioning coral (dale and geldof, 2003), which shows full architecture for instruction giving,and real (muller, 2002), which shows multimodal system (graphics and text) for communicating with the user, adapting them to user behaviour.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3953">
<title id=" W09-0610.xml">a model for human readable instruction generation using level based discourse planning and dynamic inference of attributes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of this work is to develop embodied conversational robots that are capable of natural, fluent visually situated dialog with one or more interlocutors.
</prevsent>
<prevsent>in this kind of situation very important aspect to take into account is how to refer to objects located in the physical environment.
</prevsent>
</prevsection>
<citsent citstr=" W05-1627 ">
the authors present in the paper computational framework for the generation of spatial locative expressions in such contexts, relying on the reiter and dale (reiter and dale, 1992) <papid> C92-1038 </papid>algorithm.another interesting work related to referring expression generation in spatial environments can be found in (varges, 2005).<papid> W05-1627 </papid></citsent>
<aftsection>
<nextsent>the author uses the mapsof the map task dialogue corpus as domain models, and treats spatial descriptions as referring expressions that distinguish particular points on themap from all other points (considered as distrac tors).
</nextsent>
<nextsent>related research can be found in (stoia et al, 2006), <papid> N06-2040 </papid>where study of how humans give orders in navigation environmnets and an algorithm implementing the observed behaviour is shown.</nextsent>
<nextsent>there are many other approaches to instruction giving.directly related with this work, it is worth mentioning coral (dale and geldof, 2003), which shows full architecture for instruction giving,and real (muller, 2002), which shows multimodal system (graphics and text) for communicating with the user, adapting them to user behaviour.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3954">
<title id=" W09-0610.xml">a model for human readable instruction generation using level based discourse planning and dynamic inference of attributes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the authors present in the paper computational framework for the generation of spatial locative expressions in such contexts, relying on the reiter and dale (reiter and dale, 1992) <papid> C92-1038 </papid>algorithm.another interesting work related to referring expression generation in spatial environments can be found in (varges, 2005).<papid> W05-1627 </papid></prevsent>
<prevsent>the author uses the mapsof the map task dialogue corpus as domain models, and treats spatial descriptions as referring expressions that distinguish particular points on themap from all other points (considered as distrac tors).</prevsent>
</prevsection>
<citsent citstr=" N06-2040 ">
related research can be found in (stoia et al, 2006), <papid> N06-2040 </papid>where study of how humans give orders in navigation environmnets and an algorithm implementing the observed behaviour is shown.</citsent>
<aftsection>
<nextsent>there are many other approaches to instruction giving.directly related with this work, it is worth mentioning coral (dale and geldof, 2003), which shows full architecture for instruction giving,and real (muller, 2002), which shows multimodal system (graphics and text) for communicating with the user, adapting them to user behaviour.
</nextsent>
<nextsent>the model of virtual guide presented here addresses four specific issues: how to construct representation of the world with higher levels of representation, how to generate higher instructions referring to the more abstract levels of representation, how the construction of references is implemented in terms of reference agents.
</nextsent>
<nextsent>a brief overview of the complete architecture of the module is also included.
</nextsent>
<nextsent>3.1 constructing the world.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3957">
<title id=" W09-0610.xml">a model for human readable instruction generation using level based discourse planning and dynamic inference of attributes </title>
<section> a functional model of virtual guide </section>
<citcontext>
<prevsection>
<prevsent>combining these agents in different ways generates different reference sentences, some of them longer but more specific, others shorter but ambiguous.
</prevsent>
<prevsent>what we triedto achieve is to find the right combination of reference agents that create the shortest non-ambiguoussentence.
</prevsent>
</prevsection>
<citsent citstr=" W08-1109 ">
this is not natural approach, as some one could prefer to have an ambiguous (but more human) spatial relation (viethen and dale, 2008) <papid> W08-1109 </papid>in reference sentence.</citsent>
<aftsection>
<nextsent>or for example, someone could prefer having longer reference like the big red box thats on the third shelf from the bottom?
</nextsent>
<nextsent>than perfectly specific (but not natural) reference like the 3 kg box?.
</nextsent>
<nextsent>71 real world world analysis expanded world goals disambiguation approximation stage alerts instruction tree1 2 3 levels guide manag erguide agent 1guide agent 2 g. 3.1g.
</nextsent>
<nextsent>3.n ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3960">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we additionally explore parsing with the inclusion of grammatical function information.
</prevsent>
<prevsent>explicit grammatical functions are important to german language understanding, but they are numerous, and navely incorporating them into parser which assumes small phrasal category inventory causes large performance reductions due to increasing sparsity.
</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
recent papers provide mixed evidence as to whether techniques that increase statistical parsing performance for english also improve german parsing performance (dubey and keller, 2003;<papid> P03-1013 </papid>kubler et al, 2006).</citsent>
<aftsection>
<nextsent>we provide systematic exploration of this topic to shed light on what techniques might benefit german parsing and show general trends in the relative performance increases for each technique.
</nextsent>
<nextsent>while these results vary across treebanks, due to differences in annotation schemes as discussed by kubler (2005), we also find similarities and provide explanations for the trend differences based on the annotation schemes.
</nextsent>
<nextsent>we address three parsing techniques: (i) markov ization, (ii) lexicalization, and (iii) state splitting (i.e., subcategorization).
</nextsent>
<nextsent>these techniques are not independent, and we thus examine how lexicalization and markov ization interact, since lexicalization for german has been the most contentious area in the literature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3962">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we address three parsing techniques: (i) markov ization, (ii) lexicalization, and (iii) state splitting (i.e., subcategorization).
</prevsent>
<prevsent>these techniques are not independent, and we thus examine how lexicalization and markov ization interact, since lexicalization for german has been the most contentious area in the literature.
</prevsent>
</prevsection>
<citsent citstr=" C04-1056 ">
many of these techniques have been investigated in other work (schiehlen, 2004; <papid> C04-1056 </papid>dubey, 2004; dubey, 2005), <papid> P05-1039 </papid>but, we hope that by consolidating, replicating, improving, and clarifying previous results we can contribute to the re-evaluation of german probabilistic parsing after somewhat confusing start to initial literature in this area.</citsent>
<aftsection>
<nextsent>one feature of german that differs markedly from english is substantial free word order.
</nextsent>
<nextsent>this requires the marking of grammatical functions on phrases to indicate their syntactic function in sentences (subject, object, etc.), whereas for english these functions can be derived from configurations (chomsky,1965; de marneffe et al, 2006).
</nextsent>
<nextsent>while some similar functions are present in english treebanks, they are used more frequently in german treebanks and many more unique functions and category-function pairings exist.
</nextsent>
<nextsent>because of the relatively free word ordering in german, the usefulness of parses is substantially increased by generating them with this information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3963">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we address three parsing techniques: (i) markov ization, (ii) lexicalization, and (iii) state splitting (i.e., subcategorization).
</prevsent>
<prevsent>these techniques are not independent, and we thus examine how lexicalization and markov ization interact, since lexicalization for german has been the most contentious area in the literature.
</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
many of these techniques have been investigated in other work (schiehlen, 2004; <papid> C04-1056 </papid>dubey, 2004; dubey, 2005), <papid> P05-1039 </papid>but, we hope that by consolidating, replicating, improving, and clarifying previous results we can contribute to the re-evaluation of german probabilistic parsing after somewhat confusing start to initial literature in this area.</citsent>
<aftsection>
<nextsent>one feature of german that differs markedly from english is substantial free word order.
</nextsent>
<nextsent>this requires the marking of grammatical functions on phrases to indicate their syntactic function in sentences (subject, object, etc.), whereas for english these functions can be derived from configurations (chomsky,1965; de marneffe et al, 2006).
</nextsent>
<nextsent>while some similar functions are present in english treebanks, they are used more frequently in german treebanks and many more unique functions and category-function pairings exist.
</nextsent>
<nextsent>because of the relatively free word ordering in german, the usefulness of parses is substantially increased by generating them with this information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3964">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>a new parsing model could be written to treat separate grammatical functions for nodes as first class objects, rather than just con catenating phrasal categories and functions.
</prevsent>
<prevsent>finally, assignment of grammatical functions could be leftto separate post-processing phase, which could exploit not only case information inside noun phrases but joint information across the subcategorization frames of predicates.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we use the stanford parser (klein and manning, 2003<papid> P03-1054 </papid>b) for all experiments.</citsent>
<aftsection>
<nextsent>an advantage of this parser for baseline experiments is that it provides clean, simple implementations of component models, with many configuration options.
</nextsent>
<nextsent>we show results in most instances for evaluations both with and without grammatical functions and with and without gold tags.
</nextsent>
<nextsent>when training and parsing with the inclusion of grammatical functions, we treat each pairing of basic category and grammatical function as one new category.
</nextsent>
<nextsent>rules are learned for each such category with separate orthographic form, with no attempt to learn general rules for nodes with the same basic category but different functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3969">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> markov ization.  </section>
<citcontext>
<prevsection>
<prevsent>these results are 41 tuba-d/z tiger negra horiz.
</prevsent>
<prevsent>vertical markov order vertical markov order vertical markov order order 1 2 3 1 2 3 1 2 3 1 86.50 88.60 88.71 76.69 77.40 76.46 76.63 77.20 75.91 (+2.76) (+1.21) (+0.89) (+3.54) (+3.57) (+3.27) (+2.39) (+2.06) (+2.08) 2 86.55 88.61 88.84 75.91 75.30 74.20 76.39 75.39 73.77 (+2.63) (+1.22) (+0.90) (+3.22) (+3.09) (+3.10) (+3.40) (+2.20) (+2.16) 3 86.47 88.56 88.74 75.27 74.08 72.88 75.30 74.22 72.53 (+2.63) (+1.18) (+0.90) (+3.36) (+3.41) (+2.85) (+3.74) (+2.12) (+2.60) ? 86.04 88.41 88.67 74.44 73.26 71.96 74.48 73.50 71.84 (+2.17) (+1.07) (+0.91) (+3.10) (+3.02) (+2.51) (+3.31) (+1.97) (+3.02) table 2: factored parsing results for tuba-d/z, tiger, and negra when tagging is done by the parser.
</prevsent>
</prevsection>
<citsent citstr=" P06-3004 ">
numbers in italics show difference between factored parser and pcfg, where improvements over the pcfg are positive.comparable to maier (2006), <papid> P06-3004 </papid>which found 36% improvement using an un lexicalized pcfg; these absolute improvements hold despite the fact that the maier (2006) <papid> P06-3004 </papid>parser has results with 24% absolute lower f1 than those in this paper.</citsent>
<aftsection>
<nextsent>in this section we examine how the addition of grammatical functions for training and evaluation affectsperformance.
</nextsent>
<nextsent>as noted previously, we add grammatical functions simply by concatenating them to the dependent phrasal categories and calling each unique symbol pcfg nonterminal; this is an obvious way to adapt an existing pcfg parser, but not sophisticated model of grammatical functions.
</nextsent>
<nextsent>we also present our shared task results (table 6).
</nextsent>
<nextsent>4.1 effects on evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3971">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> inclusion of grammatical functions.  </section>
<citcontext>
<prevsection>
<prevsent>the stanford parser was initially designed under the assumption of small phrasal category set, and makes no attempts to smooth grammar rule probabilities (smoothing only probabilities 43of words having certain tag and probabilities of de pendencies).
</prevsent>
<prevsent>while this approach is in general not optimal when many category splits are used inside the parser ? smoothing helps, cf.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
petrov et al (2006) ? <papid> P06-1055 </papid>it becomes untenable as the category set grows large, multi-faceted, and sparse.</citsent>
<aftsection>
<nextsent>this is particularly evident given the results in table 7 that show the precipitous decline in f1 on the tiger corpus, where the general problems are exacerbated by the flatter annotation style of tiger.
</nextsent>
<nextsent>in the tables in section 3, we showed the utility of lexicalization for german parsing when grammatical functions are not required.
</nextsent>
<nextsent>this contrasts strongly with the results of (dubey and keller, 2003;<papid> P03-1013 </papid>dubey, 2004) where no performance increases (indeed, performance decreases) are reported from lex icalization.</nextsent>
<nextsent>lexicalization shows fairly consistent 23% gains on the negra and tiger treebanks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3974">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> lexicalization.  </section>
<citcontext>
<prevsection>
<prevsent>this falloff, in addition to overall issues of sparsity, helps explain the drop in performance with the addition of grammatical functions: our possible gain from lexicalized parsing is decreased by the increasing rate of failure for the factored parser.
</prevsent>
<prevsent>thus, for future german work to gain from lexicalization, it may be necessary to explore smoothing the grammar or working with diminished tagset without grammatical functions.lexicalized parsing focuses on identifying dependencies.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
as recognized by collins (2003), <papid> J03-4003 </papid>identifying dependencies between words allows for better evaluation of attachment accuracy, diminishing total parse able dataset sent.</citsent>
<aftsection>
<nextsent>w.o. gfs with gfs tuba-d/z 2611 2610 2197 tiger 2535 2534 1592 table 8: number of sentences parse able by the factored lexicalized parser.
</nextsent>
<nextsent>if the factored model fails to return parse, the parser returns the best pcfg parse, so the parser maintains 100% coverage.
</nextsent>
<nextsent>tuba-d/z tiger gold tags 91.00 90.21 auto.
</nextsent>
<nextsent>tags 86.90 83.39 gold tags -gf 89.89 88.97 auto.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3975">
<title id=" W08-1006.xml">parsing three german treebanks lexicalized and un lexicalized baselines </title>
<section> lexicalization.  </section>
<citcontext>
<prevsection>
<prevsent>or generated during parsing (auto.
</prevsent>
<prevsent>tags?); grammatical functions were used for the first two results and omitted for the final two (?-gf?).spurious effects on labeled bracketing f1 of different annotation schemes.
</prevsent>
</prevsection>
<citsent citstr=" D07-1066 ">
in particular, rehbein and van genabith (2007) <papid> D07-1066 </papid>correctly emphasize how f1scores are very dependent on the amount of branching structure in treebank, and are hence not validly comparable across annotation styles.</citsent>
<aftsection>
<nextsent>we evaluate performance on identifying unlabeled dependencies between heads and modifiers, extracting dependencies automatically from the parse trees.
</nextsent>
<nextsent>most heads in the tuba-d/z and tiger treebanks are marked,and we use marked heads when possible for training and evaluation.
</nextsent>
<nextsent>when heads were not marked, we used heuristic rules to identify the likely head.
</nextsent>
<nextsent>broadly consistent with the results of rehbein andvan genabith (2007), <papid> D07-1066 </papid>table 9 shows that the disparity in performance between tuba-d/z and tigeris much smaller when measuring dependency accuracy rather than labeled bracketing f1, especially when using gold tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3980">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the nict statistical machine translation (smt) system used for the shared task of the fourth workshop on statistical machine translation.
</prevsent>
<prevsent>we participated in the spanish english translation task under the constrained condition.
</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
for the training of the smt engines,we used two parallel spanish-english corpora provided by the organizers: the europarl (ep) corpus (koehn, 2005), which consists of 1.4m parallel sentences extracted from the proceedings of the european parliament, and the news commentary (nc) corpus (callison-burch et al, 2008), which consists of 74k parallel sentences taken from major news outlets like bbc, der spiegel, and le monde.in order to adapt smt systems to specific domain, recent research focuses on model adaptation techniques that adjust their parameters basedon information about the evaluation domain (fos ter and kuhn, 2007; <papid> W07-0717 </papid>finch and sumita, 2008<papid> W08-0334 </papid>a).</citsent>
<aftsection>
<nextsent>statistical models can be trained on in-domain and out-of-domain datasets and combined at run-time using probabilistic weighting between domain-specific statistical models.
</nextsent>
<nextsent>as the official wmt09 evaluation testset consists of documents taken from the news domain, we applied statistical model adaptation techniques to combine translation models (tm), language models (lm) and distortion models (dm) trained on (a) the in-domain nc corpus and (b) the out-of-domain ep corpus (cf.
</nextsent>
<nextsent>section 2).
</nextsent>
<nextsent>one major problem in the given translation task was the large amount of out-of-vocabulary (oov)words, i.e., source language words that do not occur in the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3981">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the nict statistical machine translation (smt) system used for the shared task of the fourth workshop on statistical machine translation.
</prevsent>
<prevsent>we participated in the spanish english translation task under the constrained condition.
</prevsent>
</prevsection>
<citsent citstr=" W08-0334 ">
for the training of the smt engines,we used two parallel spanish-english corpora provided by the organizers: the europarl (ep) corpus (koehn, 2005), which consists of 1.4m parallel sentences extracted from the proceedings of the european parliament, and the news commentary (nc) corpus (callison-burch et al, 2008), which consists of 74k parallel sentences taken from major news outlets like bbc, der spiegel, and le monde.in order to adapt smt systems to specific domain, recent research focuses on model adaptation techniques that adjust their parameters basedon information about the evaluation domain (fos ter and kuhn, 2007; <papid> W07-0717 </papid>finch and sumita, 2008<papid> W08-0334 </papid>a).</citsent>
<aftsection>
<nextsent>statistical models can be trained on in-domain and out-of-domain datasets and combined at run-time using probabilistic weighting between domain-specific statistical models.
</nextsent>
<nextsent>as the official wmt09 evaluation testset consists of documents taken from the news domain, we applied statistical model adaptation techniques to combine translation models (tm), language models (lm) and distortion models (dm) trained on (a) the in-domain nc corpus and (b) the out-of-domain ep corpus (cf.
</nextsent>
<nextsent>section 2).
</nextsent>
<nextsent>one major problem in the given translation task was the large amount of out-of-vocabulary (oov)words, i.e., source language words that do not occur in the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3991">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these approaches depend on the coverage of the utilized external dictionaries.
</prevsent>
<prevsent>data sparseness problems due to inflectional variations were previously addressed by applying word transformations using stemming or lemmatization (popovic and ney, 2005; gupta and federico, 2006).
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
a tight integration of morphosyntactic information into the translation model was proposed by (koehn and hoang, 2007) <papid> D07-1091 </papid>where lemma and morphological information are translated separately, and this information is combined on the output side to generate the translation.</citsent>
<aftsection>
<nextsent>however, these approaches still suffer from thedata sparseness problem, since lemmata and inflectional forms never seen in the training corpus cannot be translated.
</nextsent>
<nextsent>in order to generate translations for unknown words, previous approaches focused on transliteration methods, where sequence of characters is mapped from one writing system into an other.
</nextsent>
<nextsent>for example, in order to translate names and technical terms, (knight and graehl, 1997) <papid> P97-1017 </papid>introduced probabilistic model that replaces japanese 105katakana1 words with phonetic ally equivalent english words.</nextsent>
<nextsent>more recently, (finch and sumita, 2008<papid> W08-0334 </papid>b) proposed transliteration method that isbased directly on techniques developed for phrase based smt, and transforms character sequence from one language into another in subwordlevel, character-based manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE3992">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these approaches still suffer from thedata sparseness problem, since lemmata and inflectional forms never seen in the training corpus cannot be translated.
</prevsent>
<prevsent>in order to generate translations for unknown words, previous approaches focused on transliteration methods, where sequence of characters is mapped from one writing system into an other.
</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
for example, in order to translate names and technical terms, (knight and graehl, 1997) <papid> P97-1017 </papid>introduced probabilistic model that replaces japanese 105katakana1 words with phonetic ally equivalent english words.</citsent>
<aftsection>
<nextsent>more recently, (finch and sumita, 2008<papid> W08-0334 </papid>b) proposed transliteration method that isbased directly on techniques developed for phrase based smt, and transforms character sequence from one language into another in subwordlevel, character-based manner.</nextsent>
<nextsent>we extend this approach by exploiting the phrase-table of the baseline smt system to train phrase-based transliteration model that generates english translations of spanish oov words as described in section 3.the effects of the proposed techniques are investigated in detail in section 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4023">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the nc devset (2,438/1,378 oovs) contains twice as many untranslatable spanish words as the nc evalset (1,168/73 oovs) and the ep devset (912/63 oovs).
</prevsent>
<prevsent>in addition, the high language perplexity figures for this years testset show thatthe translation quality output for both baseline systems is expected to be much lower than those forthe ep evaluation datasets.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in this paper, translation quality is evaluated according to (1) the bleu metrics which calculates the geometric mean of gram precision by the system output with respect to reference translations (papineni et al, 2002),<papid> P02-1040 </papid>and (2) the meteor metrics that calculates uni gram overlaps between translations (banerjee andlavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>scores of both metrics range between 0 (worst) and 1 (best) and are displayed in percent figures.
</nextsent>
<nextsent>4.1 baseline.
</nextsent>
<nextsent>our baseline system is fairly typical phrase based machine translation system (finch and sumita, 2008<papid> W08-0334 </papid>a) built within the framework of feature-based exponential model containing the following features: table 1: language resources corpus train dev eval nc spanish sentences 74k 2,001 2,007 words 2,048k 49,116 56,081 vocab 61k 9,047 8,638 length 27.6 24.5 27.9 oov (%) ? 5.2 / 2.9 1.4 / 0.9 english sentences 74k 2,001 2,007 words 1,795k 46,524 49,693 vocab 47k 8,110 7,541 length 24.2 23.2 24.8 oov (%) ? 5.2 / 2.9 1.2 / 0.9 perplexity ? 349 / 381 348 / 458 ep spanish sentences 1,404k 1,861 2,000 words 41,003k 50,216 61,293 vocab 170k 7,422 8,251 length 29.2 27.0 30.6 oov (%) ? 2.4 / 0.1 2.4 / 0.2 english sentences 1,404k 1,861 2,000 words 39,354k 48,663 59,145 vocab 121k 5,869 6,428 length 28.0 26.1 29.6 oov (%) ? 1.8 / 0.1 1.9 / 0.1 perplexity ? 210 / 72 305 / 125 table 2: testset 2009 corpus test nc spanish sentences 3,027 words 80,591 vocab 12,616 length 26.6 ? source-target phrase translation probability ? inverse phrase translation probability ? source-target lexical weighting probability ? inverse lexical weighting probability ? phrase penalty ? language model probability ? lexical reordering probability ? simple distance-based distortion model ? word penalty for the training of the statistical models, standard word alignment (giza++ (och and ney, 2003)) <papid> J03-1002 </papid>and language modeling (srilm (stolcke,2002)) tools were used.</nextsent>
<nextsent>we used 5-gram language models trained with modified knesser-ney smoothing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4024">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the nc devset (2,438/1,378 oovs) contains twice as many untranslatable spanish words as the nc evalset (1,168/73 oovs) and the ep devset (912/63 oovs).
</prevsent>
<prevsent>in addition, the high language perplexity figures for this years testset show thatthe translation quality output for both baseline systems is expected to be much lower than those forthe ep evaluation datasets.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
in this paper, translation quality is evaluated according to (1) the bleu metrics which calculates the geometric mean of gram precision by the system output with respect to reference translations (papineni et al, 2002),<papid> P02-1040 </papid>and (2) the meteor metrics that calculates uni gram overlaps between translations (banerjee andlavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>scores of both metrics range between 0 (worst) and 1 (best) and are displayed in percent figures.
</nextsent>
<nextsent>4.1 baseline.
</nextsent>
<nextsent>our baseline system is fairly typical phrase based machine translation system (finch and sumita, 2008<papid> W08-0334 </papid>a) built within the framework of feature-based exponential model containing the following features: table 1: language resources corpus train dev eval nc spanish sentences 74k 2,001 2,007 words 2,048k 49,116 56,081 vocab 61k 9,047 8,638 length 27.6 24.5 27.9 oov (%) ? 5.2 / 2.9 1.4 / 0.9 english sentences 74k 2,001 2,007 words 1,795k 46,524 49,693 vocab 47k 8,110 7,541 length 24.2 23.2 24.8 oov (%) ? 5.2 / 2.9 1.2 / 0.9 perplexity ? 349 / 381 348 / 458 ep spanish sentences 1,404k 1,861 2,000 words 41,003k 50,216 61,293 vocab 170k 7,422 8,251 length 29.2 27.0 30.6 oov (%) ? 2.4 / 0.1 2.4 / 0.2 english sentences 1,404k 1,861 2,000 words 39,354k 48,663 59,145 vocab 121k 5,869 6,428 length 28.0 26.1 29.6 oov (%) ? 1.8 / 0.1 1.9 / 0.1 perplexity ? 210 / 72 305 / 125 table 2: testset 2009 corpus test nc spanish sentences 3,027 words 80,591 vocab 12,616 length 26.6 ? source-target phrase translation probability ? inverse phrase translation probability ? source-target lexical weighting probability ? inverse lexical weighting probability ? phrase penalty ? language model probability ? lexical reordering probability ? simple distance-based distortion model ? word penalty for the training of the statistical models, standard word alignment (giza++ (och and ney, 2003)) <papid> J03-1002 </papid>and language modeling (srilm (stolcke,2002)) tools were used.</nextsent>
<nextsent>we used 5-gram language models trained with modified knesser-ney smoothing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4035">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>scores of both metrics range between 0 (worst) and 1 (best) and are displayed in percent figures.
</prevsent>
<prevsent>4.1 baseline.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
our baseline system is fairly typical phrase based machine translation system (finch and sumita, 2008<papid> W08-0334 </papid>a) built within the framework of feature-based exponential model containing the following features: table 1: language resources corpus train dev eval nc spanish sentences 74k 2,001 2,007 words 2,048k 49,116 56,081 vocab 61k 9,047 8,638 length 27.6 24.5 27.9 oov (%) ? 5.2 / 2.9 1.4 / 0.9 english sentences 74k 2,001 2,007 words 1,795k 46,524 49,693 vocab 47k 8,110 7,541 length 24.2 23.2 24.8 oov (%) ? 5.2 / 2.9 1.2 / 0.9 perplexity ? 349 / 381 348 / 458 ep spanish sentences 1,404k 1,861 2,000 words 41,003k 50,216 61,293 vocab 170k 7,422 8,251 length 29.2 27.0 30.6 oov (%) ? 2.4 / 0.1 2.4 / 0.2 english sentences 1,404k 1,861 2,000 words 39,354k 48,663 59,145 vocab 121k 5,869 6,428 length 28.0 26.1 29.6 oov (%) ? 1.8 / 0.1 1.9 / 0.1 perplexity ? 210 / 72 305 / 125 table 2: testset 2009 corpus test nc spanish sentences 3,027 words 80,591 vocab 12,616 length 26.6 ? source-target phrase translation probability ? inverse phrase translation probability ? source-target lexical weighting probability ? inverse lexical weighting probability ? phrase penalty ? language model probability ? lexical reordering probability ? simple distance-based distortion model ? word penalty for the training of the statistical models, standard word alignment (giza++ (och and ney, 2003)) <papid> J03-1002 </papid>and language modeling (srilm (stolcke,2002)) tools were used.</citsent>
<aftsection>
<nextsent>we used 5-gram language models trained with modified knesser-ney smoothing.
</nextsent>
<nextsent>the language models were trained on the target side of the provided training corpora.
</nextsent>
<nextsent>minimum error rate training (mert) with respect to bleu score was used to tune the decoders parameters, and performed using the technique proposed in (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>for the translation, the inhouse multi-stack phrase-based decoder cleopatra was used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4036">
<title id=" W09-0418.xml">nictwmt09 model adaptation and transliteration for spanish english smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used 5-gram language models trained with modified knesser-ney smoothing.
</prevsent>
<prevsent>the language models were trained on the target side of the provided training corpora.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error rate training (mert) with respect to bleu score was used to tune the decoders parameters, and performed using the technique proposed in (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>for the translation, the inhouse multi-stack phrase-based decoder cleopatra was used.
</nextsent>
<nextsent>the automatic evaluation scores of the baseline systems trained on (a) only the nc corpus and (b) only on the ep corpus are summarized in table 3.
</nextsent>
<nextsent>107 table 3: baseline performance nc eval ep eval bleu meteor bleu meteor baseline 17.56 40.52 33.00 56.50 4.2 effects of model adaptation.
</nextsent>
<nextsent>in order to investigate the effect of model adaptation, each model component was optimized separately using the method described in section 2.table 4 summarizes the automatic evaluation results for various model combinations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4037">
<title id=" W09-0704.xml">a computational approach to yorxf9baacute morphology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1988).
</prevsent>
<prevsent>we represent our realizational analysis of sy in the katr formalism (finkel, shen, stump &thesayi; 2002).
</prevsent>
</prevsection>
<citsent citstr=" E89-1009 ">
katr is based on datr, formal language for representing lexical knowledge designed and implemented by roger evans and gerald gazdar (evans &amp; gazdar 1989).<papid> E89-1009 </papid></citsent>
<aftsection>
<nextsent>our information about sy is primarily due to the expertise of the second author.
</nextsent>
<nextsent>this research is part of larger effort aimed at elucidating the morphological structure of naturallanguages.
</nextsent>
<nextsent>in particular, we are interested in identifying the ways in which default-inheritance relations describe languages morphology as wellas the theoretical relevance of the traditional notion of principal parts.
</nextsent>
<nextsent>to this end, we have applied similar techniques to hebrew (finkel &amp; stump 2007), latin (finkel &amp; stump to appear, 2009b), and french (finkel &amp; stump to appear, 2009a).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4038">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that for systems with many features, there is extensive variation in outcomes, both on the development data and on the test data.
</prevsent>
<prevsent>we analyze the causes of this variation and propose modifications to the mert procedure that improve stability while helping performance on test data.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
most recent approaches in smt, eg (koehn et al , 2003; <papid> N03-1017 </papid>chiang, 2005), <papid> P05-1033 </papid>use log-linear model to combine probabilistic features.</citsent>
<aftsection>
<nextsent>minimum error rate training (mert) aims to find the set of loglinear weights that yields the best translation performance on development corpus according tosome metric such as bleu.
</nextsent>
<nextsent>this is an essential step in smt training that can significantly improve performance on test corpus compared to setting weights by hand.
</nextsent>
<nextsent>mert is difficult problem, however, because calculating bleu as function of log-linear weights requires decoding,which is an expensive operation.
</nextsent>
<nextsent>moreover, be cause this function is not differentiable, efficient gradient-based optimization algorithms cannot be used.ochs procedure is the most widely-used version of mert for smt (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4039">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that for systems with many features, there is extensive variation in outcomes, both on the development data and on the test data.
</prevsent>
<prevsent>we analyze the causes of this variation and propose modifications to the mert procedure that improve stability while helping performance on test data.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
most recent approaches in smt, eg (koehn et al , 2003; <papid> N03-1017 </papid>chiang, 2005), <papid> P05-1033 </papid>use log-linear model to combine probabilistic features.</citsent>
<aftsection>
<nextsent>minimum error rate training (mert) aims to find the set of loglinear weights that yields the best translation performance on development corpus according tosome metric such as bleu.
</nextsent>
<nextsent>this is an essential step in smt training that can significantly improve performance on test corpus compared to setting weights by hand.
</nextsent>
<nextsent>mert is difficult problem, however, because calculating bleu as function of log-linear weights requires decoding,which is an expensive operation.
</nextsent>
<nextsent>moreover, be cause this function is not differentiable, efficient gradient-based optimization algorithms cannot be used.ochs procedure is the most widely-used version of mert for smt (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4040">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is an essential step in smt training that can significantly improve performance on test corpus compared to setting weights by hand.
</prevsent>
<prevsent>mert is difficult problem, however, because calculating bleu as function of log-linear weights requires decoding,which is an expensive operation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
moreover, be cause this function is not differentiable, efficient gradient-based optimization algorithms cannot be used.ochs procedure is the most widely-used version of mert for smt (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>to reduce computational cost, it relies on the key technique of optimizing weights over n-best lists of translation hypotheses rather than over all possible hypotheses.
</nextsent>
<nextsent>this allows the most probable hypothesis under given set of weight sand the corresponding bleu scoreto be found by enumerating n-best entries rather than decoding.
</nextsent>
<nextsent>some variant on powells algorithm (press et al , 2002)is typically used to maximize bleu in this setting.
</nextsent>
<nextsent>the n-best lists are constructed by alternating decoding and bleu maximization operations: decoding adds new hypotheses to the current lists, then bleu is maximized over the lists to find new best weights for the subsequent decoding step, etc. this process continues until no new hypotheses are found.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4042">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>one possible approach to estimating log-linear weights on features is to dispense with the n-best lists employed by ochs procedure and, instead,to optimize weights by directly accessing the decoder.
</prevsent>
<prevsent>the disadvantage of this approach is thatfar more iterations of decoding of the full development set are required.
</prevsent>
</prevsection>
<citsent citstr=" N04-1033 ">
in (zens and ney, 2004) <papid> N04-1033 </papid>the downhill simplex method is used to estimate the weights; around 200 iterations are required for convergence to occur.</citsent>
<aftsection>
<nextsent>however, each iteration is unusually fast, because only monotone decoding is permitted (i.e., the order of phrases in the target language mirrors that in the source language).
</nextsent>
<nextsent>similarly, cettolo and federico (2004) apply the simplex method to optimize weights directly using the decoder.
</nextsent>
<nextsent>in their experiments on nist 2003chinese-english data, they found about 100 iterations of decoding were required.
</nextsent>
<nextsent>although they obtained consistent and stable performance gains for mt, these were inferior to the gains yielded by ochs procedure in (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4045">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in their experiments on nist 2003chinese-english data, they found about 100 iterations of decoding were required.
</prevsent>
<prevsent>although they obtained consistent and stable performance gains for mt, these were inferior to the gains yielded by ochs procedure in (och, 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1055 ">
taking ochs mert procedure as baseline, (zens et al , 2007) <papid> D07-1055 </papid>experiment with different training criteria for smt and obtain the best results for criterion they call expected bleu score?.moore and quirk (2008) <papid> C08-1074 </papid>share the goal under lying our own research: improving, rather than replacing, ochs mert procedure.</citsent>
<aftsection>
<nextsent>they focuson the step in the procedure where the set of feature weights optimizing bleu (or some other mt metric) for an n-best list is estimated.
</nextsent>
<nextsent>typically, several different starting points are tried for this set of weights; often, one of the starting points is the best set of weights found for the previous set of n-best hypotheses.
</nextsent>
<nextsent>the other starting points are often chosen randomly.
</nextsent>
<nextsent>in this paper, moore and quirk look at the best way of generating the random starting points; they find that starting points generated by random walk from previous maxima are superior to those generated from uniform distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4046">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in their experiments on nist 2003chinese-english data, they found about 100 iterations of decoding were required.
</prevsent>
<prevsent>although they obtained consistent and stable performance gains for mt, these were inferior to the gains yielded by ochs procedure in (och, 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" C08-1074 ">
taking ochs mert procedure as baseline, (zens et al , 2007) <papid> D07-1055 </papid>experiment with different training criteria for smt and obtain the best results for criterion they call expected bleu score?.moore and quirk (2008) <papid> C08-1074 </papid>share the goal under lying our own research: improving, rather than replacing, ochs mert procedure.</citsent>
<aftsection>
<nextsent>they focuson the step in the procedure where the set of feature weights optimizing bleu (or some other mt metric) for an n-best list is estimated.
</nextsent>
<nextsent>typically, several different starting points are tried for this set of weights; often, one of the starting points is the best set of weights found for the previous set of n-best hypotheses.
</nextsent>
<nextsent>the other starting points are often chosen randomly.
</nextsent>
<nextsent>in this paper, moore and quirk look at the best way of generating the random starting points; they find that starting points generated by random walk from previous maxima are superior to those generated from uniform distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4047">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the criterion used throughout the paper to judge the performance of mert is the bleu score on the development test set (rather than, for instance, the variance of that score, or the bleu score on held-out test data).
</prevsent>
<prevsent>another contribution of the paper is ingenious methods for pruning the set of n-best hypotheses at each iteration.
</prevsent>
</prevsection>
<citsent citstr=" W08-0304 ">
cer et al (2008) <papid> W08-0304 </papid>also aim at improving ochs mert.</citsent>
<aftsection>
<nextsent>they focus on the search for the best set of weights for an n-best list that follows choice of starting point.
</nextsent>
<nextsent>they propose modified version of powells in which diagonal?
</nextsent>
<nextsent>directions are chosen at random.
</nextsent>
<nextsent>they also modify the objective function used by powells to reflect the width of the optima found.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4048">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they also modify the objective function used by powells to reflect the width of the optima found.
</prevsent>
<prevsent>they are able to show that their modified version of mert outperforms both version using powells, and more heuristic search algorithm devised by philipp koehnthat they call koehn coordinate descent, as measured on the development set and two test datasets.
</prevsent>
</prevsection>
<citsent citstr=" P08-2010 ">
(duh and kirchhoff, 2008) <papid> P08-2010 </papid>ingeniously uses mert as weak learner in boosting algorithm that is applied to the n-best reranking task, with good results (a gain of about 0.8 bleu on the test set).</citsent>
<aftsection>
<nextsent>recently, some interesting work has been done on what might be considered generalization of ochs procedure (macherey et al , 2008).<papid> D08-1076 </papid></nextsent>
<nextsent>in this generalization, candidate hypotheses in each iteration of the procedure are represented as lattices,rather than as n-best lists.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4049">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they are able to show that their modified version of mert outperforms both version using powells, and more heuristic search algorithm devised by philipp koehnthat they call koehn coordinate descent, as measured on the development set and two test datasets.
</prevsent>
<prevsent>(duh and kirchhoff, 2008) <papid> P08-2010 </papid>ingeniously uses mert as weak learner in boosting algorithm that is applied to the n-best reranking task, with good results (a gain of about 0.8 bleu on the test set).</prevsent>
</prevsection>
<citsent citstr=" D08-1076 ">
recently, some interesting work has been done on what might be considered generalization of ochs procedure (macherey et al , 2008).<papid> D08-1076 </papid></citsent>
<aftsection>
<nextsent>in this generalization, candidate hypotheses in each iteration of the procedure are represented as lattices,rather than as n-best lists.
</nextsent>
<nextsent>this makes it possible for far greater proportion of the search space to be represented: graph density of 40 arcs per phrase was used, which corresponds to an n-best size of more than two octillion (2 ? 1027) entries.
</nextsent>
<nextsent>experimental results for three nist 2008 tasks were very encouraging: though bleu scores forthe lattice variant of ochs procedure did not typically exceed those for the n-best variant on development data, on test data the lattice variant outperformed the n-best approach by between 0.6 and 2.5 bleu points.
</nextsent>
<nextsent>the convergence behaviour of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4050">
<title id=" W09-0439.xml">stabilizing minimum error rate training </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>hmm and ibm2 models were used to perform separate word alignments, which were symmetrized by the usual diag-and?
</prevsent>
<prevsent>algorithm prior to phrase extraction.
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
decoding used beam search with the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>we used two separate log-linear models for mert:?
</nextsent>
<nextsent>large: 16 phrase-table features, 2 4-gram language model features, 1 distortion feature,and 1 word-count feature (20 features in to tal).?
</nextsent>
<nextsent>small: 2 phrase-table features, 1 4-gram language model feature, 1 distortion feature, and 1 word-count feature (5 features in total).
</nextsent>
<nextsent>the phrase-table features for the large model were derived as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4054">
<title id=" W09-0608.xml">class based ordering of pre nominal modifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the order of modifiers before noun affects the meaning and fluency of generated utterances.
</prevsent>
<prevsent>determining ways to order modifiersprenominally has been an area of considerable research (cf.
</prevsent>
</prevsection>
<citsent citstr=" P99-1018 ">
shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000).<papid> P00-1012 </papid>in this paper, we establish and evaluate classification system that can be used to order pre nominal modifiers automatically.</citsent>
<aftsection>
<nextsent>this may be implemented in surface realization component of natural language generation system, or may be used to help specify the ordering of properties that feed into referring expression generation algorithm.
</nextsent>
<nextsent>predictions of pre nominal modifier ordering based on these classes are shown to be robust and accurate.
</nextsent>
<nextsent>the work here diverges from the approaches commonly employed in modifier classification by assuming no underlying relationship between semantics and pre nominal order or morphology and pre nominal order.
</nextsent>
<nextsent>the approach instead relies on generalizing empirical evidence from corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4055">
<title id=" W09-0608.xml">class based ordering of pre nominal modifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the order of modifiers before noun affects the meaning and fluency of generated utterances.
</prevsent>
<prevsent>determining ways to order modifiersprenominally has been an area of considerable research (cf.
</prevsent>
</prevsection>
<citsent citstr=" P00-1012 ">
shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000).<papid> P00-1012 </papid>in this paper, we establish and evaluate classification system that can be used to order pre nominal modifiers automatically.</citsent>
<aftsection>
<nextsent>this may be implemented in surface realization component of natural language generation system, or may be used to help specify the ordering of properties that feed into referring expression generation algorithm.
</nextsent>
<nextsent>predictions of pre nominal modifier ordering based on these classes are shown to be robust and accurate.
</nextsent>
<nextsent>the work here diverges from the approaches commonly employed in modifier classification by assuming no underlying relationship between semantics and pre nominal order or morphology and pre nominal order.
</nextsent>
<nextsent>the approach instead relies on generalizing empirical evidence from corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4057">
<title id=" W09-0608.xml">class based ordering of pre nominal modifiers </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>briefly, given pre nominal modifiers andina training corpus, the direct evidence method utilizes probabilistic reasoning to determine whether the frequency count of the ordered sequence a,b  or  b,a  is stronger.
</prevsent>
<prevsent>the transit ivity method makes inferences about unseen order ings among pre nominal modifiers; given third pre nominal modifier c, where precedes and bprecedes c, the authors can conclude that precedes c. in the clustering method, an order similarity metric is used to group modifiers together that share similar relative order to other modi fiers.shaw and hatzivassiloglou achieve their highest prediction accuracy of 90.67% using their tran sit ivity technique on pre nominal modifiers from medical corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
however, with their system trained on the medical corpus and then tested on the wall street journal corpus (marcus et al, 1993), <papid> J93-2004 </papid>they achieve an overall prediction accuracy of only 54%.</citsent>
<aftsection>
<nextsent>the authors conclude that prenomi nal modifier ordering is domain-specific.malouf (2000) <papid> P00-1012 </papid>continues this work, determining the order for sequences of pre nominal adjectives by examining several different statistical and machine learning techniques.</nextsent>
<nextsent>these achieve good results, ranging from 78.28% to 89.73% accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4060">
<title id=" W09-0608.xml">class based ordering of pre nominal modifiers </title>
<section> the problem of ordering pre nominal.  </section>
<citcontext>
<prevsection>
<prevsent>for example, consider the alternation given in figure 1.
</prevsent>
<prevsent>some combinations of modifiers before noun are more marked than others, although all are strictly speaking grammatical.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
this speaks to the need for broad modifier classes to order pre nominal modifiers, where individual modifiers 51 (1) big beautiful white wooden house (2) white wooden beautiful big house (3) comfortable red chair (4) red comfortable chair (5) big rectangular green chinese silk carpet (6) chinese big silk green rectangular carpet figure 1: grammatical modifier alternations (vendler, 1968: 122)may be ordered separately as required by particular contexts.along these lines, almost all referring expression generation algorithms relyon the availability of predefined ordering or weighting of properties(dale and reiter, 1995; van deemter, 2002; krahmer et al, 2003).<papid> J03-1003 </papid></citsent>
<aftsection>
<nextsent>this requires that for every referent, an ordered or weighted listing of all the properties that can apply to it must be created before referring expression generation begins.
</nextsent>
<nextsent>in these models, the order or weights of the input properties map to the order of the output modifiers.however, the method used to determine the ordering or weighting of properties is an open issue.
</nextsent>
<nextsent>the difficulty with capturing the ordering of properties and their corresponding modifiers stems from the problem of data sparsity.
</nextsent>
<nextsent>in the example in figure 1, the modifier silkmay be rare enough inany corpus that finding it in combination with an other modifier, in order to create generalization about its ordering constraints, is nearly impossible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4064">
<title id=" W08-1703.xml">a more precise analysis of punctuation for broad coverage surface realization with ccg </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>to illustrate the input to openccg, consider the semantic dependency graph in figure 1.
</prevsent>
<prevsent>in the graph, each node has lexical predication (e.g. make.03) and set of semantic features (e.g. numsg); nodes are connected via dependency relations (e.g. arg0?).
</prevsent>
</prevsection>
<citsent citstr=" P02-1041 ">
internally, such graphs are represented using hybrid logic dependency semantics (hlds), dependency-based approach to representing linguistic meaning (baldridge and kruijff, 2002).<papid> P02-1041 </papid></citsent>
<aftsection>
<nextsent>in hlds, each semantic head (cor responding to node in the graph) is associated with nominal that identifies its discourse referent, and relations between heads and their dependents he h2 aa1 heh3  det   arg0   arg1   tense pres  num sg  arg0  w1 want.01 m1  arg1   genrel   arg1   tense pres p1point h1have.03 make.03  arg0  figure 1: semantic dependency graph from the ccgbank for he has point he wants to make [.
</nextsent>
<nextsent>] are modeled as modal relations.
</nextsent>
<nextsent>punctuation the linguistic analysis aims to make broad coverage openccg grammar extracted from the ccg bank (white et al, 2007) more precise by adding lexicalized punctuation categories to deal with constructions involving punctuation.
</nextsent>
<nextsent>the original ccgbank corpus does not have lexical categories for punctuation; instead, punctuation marks carry categories derived from their part of speech tags and form part of binary rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4065">
<title id=" W08-1703.xml">a more precise analysis of punctuation for broad coverage surface realization with ccg </title>
<section> the ccgbank augmented with punctuation.  </section>
<citcontext>
<prevsection>
<prevsent>blind testing with hypertagging.
</prevsent>
<prevsent>hypertag-.
</prevsent>
</prevsection>
<citsent citstr=" P08-1022 ">
ging (espinosa et al, 2008) <papid> P08-1022 </papid>is super tagging for surface realization; it improves realizer speed and coverage with large grammars by predicting lexical category assignments with maximum entropy model.</citsent>
<aftsection>
<nextsent>tested in the three conditions above with and without the balanced punctuation filter.
</nextsent>
<nextsent>7 results.
</nextsent>
<nextsent>non-blind testing results in table 1 indicate that both exact match figures as well bleu scores in crease substantially in comparison to the baselines when punctuation augmented grammar is used.
</nextsent>
<nextsent>the difference is especially notable when oraclen-gram scoring is used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4066">
<title id=" W08-1703.xml">a more precise analysis of punctuation for broad coverage surface realization with ccg </title>
<section> the punctuation-enhanced grammars were.  </section>
<citcontext>
<prevsection>
<prevsent>1.3% increase in exact match figures as well as ahalf bleu point improvement; planned collection of human judgments may reveal that these improvements are more meaningful than the scores would indicate.baseline 2, which models all punctuation, performs very badly with flm scoring though it does better than the minimal punctuation baseline 1 with oracle scoring.
</prevsent>
<prevsent>the main reason for this is that, without any semantic or syntactic features to constrain punctuation categories, they tend to reapply to their own output, clogging up the chart.this results in low number of complete realizations as well as exact matches.
</prevsent>
</prevsection>
<citsent citstr=" D07-1028 ">
while direct comparisons cannot really be made across grammar frameworks, as inputs vary in their semantic depth and specificity, we observe that our all-sentences bleu score of 0.7323 exceeds that of hogan et al (2007), <papid> D07-1028 </papid>who report top score of 0.6882 including special treatment of multi-word units (though their coverage is near100%).</citsent>
<aftsection>
<nextsent>nakanishi et al (2005) <papid> W05-1510 </papid>and langkilde 23 geary (2002) report scores several points higher, though the former is limited to sentences of length 20 or less, and the latters coverage is much lower.</nextsent>
<nextsent>8 conclusion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4067">
<title id=" W08-1703.xml">a more precise analysis of punctuation for broad coverage surface realization with ccg </title>
<section> the punctuation-enhanced grammars were.  </section>
<citcontext>
<prevsection>
<prevsent>the main reason for this is that, without any semantic or syntactic features to constrain punctuation categories, they tend to reapply to their own output, clogging up the chart.this results in low number of complete realizations as well as exact matches.
</prevsent>
<prevsent>while direct comparisons cannot really be made across grammar frameworks, as inputs vary in their semantic depth and specificity, we observe that our all-sentences bleu score of 0.7323 exceeds that of hogan et al (2007), <papid> D07-1028 </papid>who report top score of 0.6882 including special treatment of multi-word units (though their coverage is near100%).</prevsent>
</prevsection>
<citsent citstr=" W05-1510 ">
nakanishi et al (2005) <papid> W05-1510 </papid>and langkilde 23 geary (2002) report scores several points higher, though the former is limited to sentences of length 20 or less, and the latters coverage is much lower.</citsent>
<aftsection>
<nextsent>8 conclusion.
</nextsent>
<nextsent>we have shown that incorporating more precise analysis of punctuation into broad-coverage reversible grammar extracted from the ccgbankyields substantial increases in the number of exact matches and bleu scores when performing surface realization with openccg, contributing to state-of-the-art results.
</nextsent>
<nextsent>our discussion has also highlighted the inadequacy of using syntactic features to control punctuation placement in ccg,leading us to develop filter to ensure appropriately balanced commas and dashes.
</nextsent>
<nextsent>in future work, we plan to investigate more satisfactory grammatical treatment involving constraints in independent orthographic derivations, perhaps along the lines of the autonomous prosodic derivations which steedman and prevost (1994) discuss.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4068">
<title id=" W09-1002.xml">on bootstrapping of linguistic features for bootstrapping grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>structural properties of natural language syntax on the other hand might be characterized by mildly context-free grammars (joshi et al, 1991), where at least large subset could be characterized by regular and context-free gram mars.2 1this article is builds on joint work and articles with k. elghamri, j. herring, t. ikuta, p. rodrigues, g. schrementi and colleagues at the institute of croatian language and linguistics and the university of zadar.
</prevsent>
<prevsent>the research activities were partially funded by several grants over couple of years,at indiana university and from the croatian ministry of science, education and sports of the republic of croatia.
</prevsent>
</prevsection>
<citsent citstr=" P90-1030 ">
2we are abstracting away from concrete linguistic models and theories, and their particular complexity, as discussed e.g. in (ristad, 1990) <papid> P90-1030 </papid>or (tesar and smolensky, 2000).ignoring for the time being extra-linguistic conditions and cues for linguistic properties, and independent of the complexity of specific linguistic levels for particular languages, we assume that specific properties at one particular linguistic level correlate with properties at another level.</citsent>
<aftsection>
<nextsent>in natural languages certain phonological processes might be triggered at morphological boundaries only, e.g.
</nextsent>
<nextsent>(chomsky and halle, 1968), or prosodic properties correlate with syntactic phrase boundaries and semantic properties, e.g.
</nextsent>
<nextsent>(inkelas and zec, 1990).
</nextsent>
<nextsent>similarly, lexical properties, as for example stress patterns and morphological structure tend to be specific to certain word types (e.g.substantives, but not function words).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4069">
<title id=" W09-1002.xml">on bootstrapping of linguistic features for bootstrapping grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in principle, the study of how this might be modeled, and what the minimal assumptions about the grammar properties and the induction algorithm could be, could start top-down, by assuming maximal knowledge of the target grammar, and subsequently eliminating elements that are obviously learn able in an unsupervised way, or fall out as side-effects.
</prevsent>
<prevsent>alternatively, bottom-up approach could start with the question about how much supervision has to beadded to an unsupervised model in order to converge to concise grammar.
</prevsent>
</prevsection>
<citsent citstr=" W04-1302 ">
here we favor the bottom-up approach, and ask how simple properties of grammar can be learned in an unsupervised way, and how cues could be identified that allow for the induction of higher level properties of the target grammar, or other linguistic levels, by for example favoring some structural hypotheses over others.in this article we will discuss in detail several experiments of morphological cue induction for lexical classification (cavar et al, 2004<papid> W04-1302 </papid>a) and (cavar et al, 2004<papid> W04-1302 </papid>b) using vector space models for category induction and subsequent rule formation.</citsent>
<aftsection>
<nextsent>furthermore, we discuss structural cohesion measured via entropy-based statistics on the basis of distributional properties for unsupervised syntactic structure induction (cavar et al, 2004<papid> W04-1302 </papid>c)from raw text, and compare the results with syntactic corpora like the penn treebank.</nextsent>
<nextsent>we expand these results with recent experiments in the domain of unsupervised induction of phonotactic regularities and phonological structure (cavar and cavar, 2009), providing cues for morphological structure induction and syntactic phrasing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4078">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dimensions of the space represent the contexts in which each target word has been observed.
</prevsent>
<prevsent>distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, aswords with similar meaning tend to occur in similar contexts.
</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
because of this property, vector space models have been used successfully both in computational linguistics (manning et al, 2008; snow et al, 2006; <papid> P06-1101 </papid>gorman and curran, 2006; <papid> P06-1046 </papid>schutze,1998) and in cognitive science (landauer and dumais, 1997; lowe and mcdonald, 2000; mcdonald and ramscar, 2001).</citsent>
<aftsection>
<nextsent>given the known problems with defining globally appropriate senses (kilgarriff,1997; hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses.vector space models typically compute one vector per target word (what we will call word type vec tors), summing co-occurrence counts over all corpus tokens of the target.
</nextsent>
<nextsent>if the target word is polyse mous, the representation will constitute union over the uses or senses of the word.
</nextsent>
<nextsent>such model does not provide information on the amount of variance in each dimension: do values on each dimension vary lot across occurrences of the target?
</nextsent>
<nextsent>also, it does not provide information on co-occurrences of feature values in occurrences of the target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4080">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the dimensions of the space represent the contexts in which each target word has been observed.
</prevsent>
<prevsent>distance between vectors in semantic space predicts the degree of semantic similarity between the corresponding words, aswords with similar meaning tend to occur in similar contexts.
</prevsent>
</prevsection>
<citsent citstr=" P06-1046 ">
because of this property, vector space models have been used successfully both in computational linguistics (manning et al, 2008; snow et al, 2006; <papid> P06-1101 </papid>gorman and curran, 2006; <papid> P06-1046 </papid>schutze,1998) and in cognitive science (landauer and dumais, 1997; lowe and mcdonald, 2000; mcdonald and ramscar, 2001).</citsent>
<aftsection>
<nextsent>given the known problems with defining globally appropriate senses (kilgarriff,1997; hanks, 2000), vector space models are especially interesting for their ability to represent word meaning without relying on dictionary senses.vector space models typically compute one vector per target word (what we will call word type vec tors), summing co-occurrence counts over all corpus tokens of the target.
</nextsent>
<nextsent>if the target word is polyse mous, the representation will constitute union over the uses or senses of the word.
</nextsent>
<nextsent>such model does not provide information on the amount of variance in each dimension: do values on each dimension vary lot across occurrences of the target?
</nextsent>
<nextsent>also, it does not provide information on co-occurrences of feature values in occurrences of the target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4081">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this description is flexible, depending on the target word in question, rather than uniform for all words through fixed distance threshold from the targets type vector.
</prevsent>
<prevsent>one possible application of region models of word meaning is in the task of determining the appropriateness of paraphrase in given context (connor and roth,2007).
</prevsent>
</prevsection>
<citsent citstr=" P08-1078 ">
this task is highly relevant for textual entailment (szpektor et al, 2008).<papid> P08-1078 </papid></citsent>
<aftsection>
<nextsent>current vector space approaches typically compare the target words token vector to the type vector of the potential paraphrase (mitchell and lapata, 2008; <papid> P08-1028 </papid>erk and pado,2008).</nextsent>
<nextsent>a region model could instead test the targets token vector for inclusion in the potential paraphrases region.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4083">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one possible application of region models of word meaning is in the task of determining the appropriateness of paraphrase in given context (connor and roth,2007).
</prevsent>
<prevsent>this task is highly relevant for textual entailment (szpektor et al, 2008).<papid> P08-1078 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
current vector space approaches typically compare the target words token vector to the type vector of the potential paraphrase (mitchell and lapata, 2008; <papid> P08-1028 </papid>erk and pado,2008).</citsent>
<aftsection>
<nextsent>a region model could instead test the targets token vector for inclusion in the potential paraphrases region.
</nextsent>
<nextsent>this section discusses existing vector space models and compares vector space models in computational linguistics to feature-based models of human concept representation in psychology.vector space models.
</nextsent>
<nextsent>vector space models represent the meaning of target word as vector in high-dimensional space (lund and burgess, 1996;landauer and dumais, 1997; sahlgren and karlgren, 2005; pado?
</nextsent>
<nextsent>and lapata, 2007; jones and me whort, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4085">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>raw counts are often transformed, forex ample using log-likelihood transformation (lowe, 2001).
</prevsent>
<prevsent>sometimes the vector space as whole is transformed using dimensionality reduction (lan dauer and dumais, 1997).
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
in nlp, vector space models have featured most prominently in information retrieval (manning et al., 2008), but have also been used for ontology learning (lin, 1998; <papid> P98-2127 </papid>snow et al, 2006; <papid> P06-1101 </papid>gorman and curran, 2006) <papid> P06-1046 </papid>and word sense-related tasks(mccarthy et al, 2004; <papid> P04-1036 </papid>schutze, 1998).</citsent>
<aftsection>
<nextsent>in psychology, vector space models have been used to model synonymy (landauer and dumais, 1997;pado?
</nextsent>
<nextsent>and lapata, 2007), lexical priming phenomena (lowe and mcdonald, 2000), and similarity judgments (mcdonald and ramscar, 2001).
</nextsent>
<nextsent>there have also been studies on inducing hyponymy information from vector space representations.
</nextsent>
<nextsent>gef fet and dagan (2005) use dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand ina subset relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4089">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>raw counts are often transformed, forex ample using log-likelihood transformation (lowe, 2001).
</prevsent>
<prevsent>sometimes the vector space as whole is transformed using dimensionality reduction (lan dauer and dumais, 1997).
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
in nlp, vector space models have featured most prominently in information retrieval (manning et al., 2008), but have also been used for ontology learning (lin, 1998; <papid> P98-2127 </papid>snow et al, 2006; <papid> P06-1101 </papid>gorman and curran, 2006) <papid> P06-1046 </papid>and word sense-related tasks(mccarthy et al, 2004; <papid> P04-1036 </papid>schutze, 1998).</citsent>
<aftsection>
<nextsent>in psychology, vector space models have been used to model synonymy (landauer and dumais, 1997;pado?
</nextsent>
<nextsent>and lapata, 2007), lexical priming phenomena (lowe and mcdonald, 2000), and similarity judgments (mcdonald and ramscar, 2001).
</nextsent>
<nextsent>there have also been studies on inducing hyponymy information from vector space representations.
</nextsent>
<nextsent>gef fet and dagan (2005) use dimension re-weighting scheme, then predict entailment when the most highly weighted dimensions of two verbs stand ina subset relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4091">
<title id=" W09-1109.xml">representing words as regions in vector space </title>
<section> task, data, and implementation.  </section>
<citcontext>
<prevsection>
<prevsent>we computed word type vectors from the training half of the bnc, using syntax-based vector space (pado?
</prevsent>
<prevsent>and lapata, 2007) of 500 dimensions, with raw co-occurrence counts as dimension values.
</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
we used the dv package1 to compute type vectors from minipar (lin, 1993) <papid> P93-1016 </papid>parse of the bnc.we computed token vectors by combining the target verbs type vector with the type vector of the word occurring as the targets direct object.</citsent>
<aftsection>
<nextsent>we test three methods for combining type vectors: first, component-wise multiplication (below called mult), which showed best results in mitchell and lapatas(2008) <papid> P08-1028 </papid>analysis.</nextsent>
<nextsent>second, component-wise averaging (below called avg), variant of type vector addition, method often used for computing token vec tors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4097">
<title id=" W09-0408.xml">machine translation system combination with flexible word ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many systems for machine translation, with different underlying approaches, are of competitivequality.
</prevsent>
<prevsent>nonetheless these approaches and systems have different strengths and weaknesses.
</prevsent>
</prevsection>
<citsent citstr=" W08-0329 ">
by offsetting weaknesses with strengths of other systems, combination can produce higher quality than does any component system.one approach to system combination uses confusion networks (rosti et al, 2008; <papid> W08-0329 </papid>karakos etal., 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>in the most common form, skeleton sentence is chosen from among the one-bestsystem outputs.
</nextsent>
<nextsent>this skeleton determines the ordering of the final combined sentence.
</nextsent>
<nextsent>the remaining outputs are aligned with the skeleton, producing list of alternatives for each word in the skeleton, which comprises confusion network.
</nextsent>
<nextsent>a decoder chooses from the original skeleton wordand its alternatives to produce final output sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4098">
<title id=" W09-0408.xml">machine translation system combination with flexible word ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many systems for machine translation, with different underlying approaches, are of competitivequality.
</prevsent>
<prevsent>nonetheless these approaches and systems have different strengths and weaknesses.
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
by offsetting weaknesses with strengths of other systems, combination can produce higher quality than does any component system.one approach to system combination uses confusion networks (rosti et al, 2008; <papid> W08-0329 </papid>karakos etal., 2008).<papid> P08-2021 </papid></citsent>
<aftsection>
<nextsent>in the most common form, skeleton sentence is chosen from among the one-bestsystem outputs.
</nextsent>
<nextsent>this skeleton determines the ordering of the final combined sentence.
</nextsent>
<nextsent>the remaining outputs are aligned with the skeleton, producing list of alternatives for each word in the skeleton, which comprises confusion network.
</nextsent>
<nextsent>a decoder chooses from the original skeleton wordand its alternatives to produce final output sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4099">
<title id=" W09-0408.xml">machine translation system combination with flexible word ordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a decoder chooses from the original skeleton wordand its alternatives to produce final output sentence.
</prevsent>
<prevsent>while there are number of variations on this theme, our approach differs fundamentally in that the effective skeleton changes on per-phrase basis.
</prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
our system is an enhancement of our previous work (jayaraman and lavie, 2005).<papid> P05-3026 </papid></citsent>
<aftsection>
<nextsent>a hypothesis uses words from systems in order, switching between systems at phrase boundaries.
</nextsent>
<nextsent>alignment sand synchronization method merge meaning equivalent output from different systems.
</nextsent>
<nextsent>hypotheses are scored based on system confidence, alignment support, and language model.we contribute few enhancements to this process.
</nextsent>
<nextsent>first, we introduce an alignment-sensitivemethod for synchronizing available hypothesis extensions across systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4100">
<title id=" W09-0408.xml">machine translation system combination with flexible word ordering </title>
<section> system.  </section>
<citcontext>
<prevsection>
<prevsent>finally, hypothesis is complete when the end of sentence marker is appended.
</prevsent>
<prevsent>2.1 alignment.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
sentences from different systems are aligned in pairs using modified version of the meteor(banerjee and lavie, 2005) <papid> W05-0909 </papid>matcher.</citsent>
<aftsection>
<nextsent>this identifies alignments in three phases: exact matches up to case, wordnet (fellbaum, 1998) morphology matches, and shared wordnet synsets.
</nextsent>
<nextsent>these sources of alignments are quite precise and unable to pick up on looser matches such as mentioned?
</nextsent>
<nextsent>and said?
</nextsent>
<nextsent>that legitimately appear in output from different systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4102">
<title id=" W09-0408.xml">machine translation system combination with flexible word ordering </title>
<section> tuning.  </section>
<citcontext>
<prevsection>
<prevsent>this process terminates with complete hypotheses or an empty beam.
</prevsent>
<prevsent>given the 502 sentences made available for tuning by wmt 2009, we selected feature weights for scoring, set of systems to combine, confidence in each selected system, and the type and distance of synchronization.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
of these, only feature weights can be trained, for which we used minimum error rate training with version 1.04 of ibm-style bleu (papineni et al, 2002) <papid> P02-1040 </papid>in case-insensitive mode.</citsent>
<aftsection>
<nextsent>we treated the remaining parameters as model selection problem, using 402 randomly sampled sentences for training and 100 sentences for evaluation.
</nextsent>
<nextsent>this is clearly small sample on whichto evaluate, so we performed two folds of cross validation to obtain average scores over 200 untrained sentences.
</nextsent>
<nextsent>we chose to do only two folds due to limited computational time and desire to test many models.
</nextsent>
<nextsent>we scored systems and our own output using case-insensitive ibm-style bleu 1.04 (papineni et al, 2002), <papid> P02-1040 </papid>meteor 0.6 (lavie and agarwal, 2007) <papid> W07-0734 </papid>with all modules, and ter 5 (snover etal., 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4104">
<title id=" W09-0408.xml">machine translation system combination with flexible word ordering </title>
<section> tuning.  </section>
<citcontext>
<prevsection>
<prevsent>this is clearly small sample on whichto evaluate, so we performed two folds of cross validation to obtain average scores over 200 untrained sentences.
</prevsent>
<prevsent>we chose to do only two folds due to limited computational time and desire to test many models.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
we scored systems and our own output using case-insensitive ibm-style bleu 1.04 (papineni et al, 2002), <papid> P02-1040 </papid>meteor 0.6 (lavie and agarwal, 2007) <papid> W07-0734 </papid>with all modules, and ter 5 (snover etal., 2006).</citsent>
<aftsection>
<nextsent>for each source language, we ex 58 in sync bleu mete ter systems and confidences cz length 8 .236 .507 59.1 google .46 cu-bojar .27 uedin .27 cz align 5 .226 .499 57.8 google .50 cu-bojar .25 uedin .25 cz align 7 .211 .508 65.9 cu-bojar .60 google .20 uedin .20 cz .231 .504 57.8 google de length 7 .255 .531 54.2 google .40 uka .30 stuttgart .15 umd .15 de length 6 .260 .532 55.2 google .50 systran .25 umd .25 de align 9 .256 .533 55.5 google .40 uka .30 stuttgart .15 umd .15 de align 6 .200 .514 54.2 google .31 uedin .22 systran .18 umd .16 uka .14 de .244 .523 57.5 google es align 8 .297 .560 52.7 google .75 uedin .25 es length 5 .289 .548 52.1 google .50 talp-upc .17 uedin .17 rwth .17 es .297 .558 52.7 google fr align 6 .329 .574 49.9 google .70 lium1 .30 fr align 8 .314 .596 48.6 google .50 lium1 .30 limsi1 .20 fr length 8 .323 .570 48.5 google .50 lium1 .25 limsi1 .25 fr .324 .576 48.7 google hu length 5 .162 .403 69.2 umd .50 morpho .40 uedin .10 hu length 8 .158 .407 69.5 umd .50 morpho .40 uedin .10 hu align 7 .153 .392 68.0 umd .33 morpho .33 uedin .33 hu .141 .391 66.1 umd xx length 5 .326 .584 49.6 google-fr .61 google-es .39 xx align 4 .328 .580 49.5 google-fr .80 google-es .20 xx align 5 .324 .576 48.6 google-fr .61 google-es .39 xx align 7 .319 .587 51.1 google-fr .50 google-es .50 xx .324 .576 48.7 google-frtable 1: combination models used for submission to wmt 2009.
</nextsent>
<nextsent>for each language, we list our primary combination, contrastive combinations, and high-scoring system for comparison in italic.
</nextsent>
<nextsent>all translations are into english.
</nextsent>
<nextsent>the xx source language combines translations from different languages,in our case french and spanish.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4105">
<title id=" W09-1215.xml">parsing syntactic and semantic dependencies for multiple languages with a pipeline approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for data-driven syntactic dependency parsing, many approaches are based on supervised learning using treebank or annotated datasets.
</prevsent>
<prevsent>currently, graph-based and transition-based algorithms are two dominating approaches that are employed by many researchers, especially in previous conll shared tasks.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
graph-based algorithms (eisner, 1996; <papid> C96-1058 </papid>mcdonald et al, 2005) <papid> P05-1012 </papid>assume series of dependency tree candidates for sentence and the goal is to find the dependency tree with highest score.</citsent>
<aftsection>
<nextsent>transition-based algorithms (yamada and matsumoto, 2003; nivre et al, 2004) <papid> W04-2407 </papid>utilize transition histories learned from dependencies within sentences to predict next state transition and build the optimal transition sequence.</nextsent>
<nextsent>although different strategies were considered, two approaches yielded comparable results at previous tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4106">
<title id=" W09-1215.xml">parsing syntactic and semantic dependencies for multiple languages with a pipeline approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for data-driven syntactic dependency parsing, many approaches are based on supervised learning using treebank or annotated datasets.
</prevsent>
<prevsent>currently, graph-based and transition-based algorithms are two dominating approaches that are employed by many researchers, especially in previous conll shared tasks.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
graph-based algorithms (eisner, 1996; <papid> C96-1058 </papid>mcdonald et al, 2005) <papid> P05-1012 </papid>assume series of dependency tree candidates for sentence and the goal is to find the dependency tree with highest score.</citsent>
<aftsection>
<nextsent>transition-based algorithms (yamada and matsumoto, 2003; nivre et al, 2004) <papid> W04-2407 </papid>utilize transition histories learned from dependencies within sentences to predict next state transition and build the optimal transition sequence.</nextsent>
<nextsent>although different strategies were considered, two approaches yielded comparable results at previous tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4107">
<title id=" W09-1215.xml">parsing syntactic and semantic dependencies for multiple languages with a pipeline approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, graph-based and transition-based algorithms are two dominating approaches that are employed by many researchers, especially in previous conll shared tasks.
</prevsent>
<prevsent>graph-based algorithms (eisner, 1996; <papid> C96-1058 </papid>mcdonald et al, 2005) <papid> P05-1012 </papid>assume series of dependency tree candidates for sentence and the goal is to find the dependency tree with highest score.</prevsent>
</prevsection>
<citsent citstr=" W04-2407 ">
transition-based algorithms (yamada and matsumoto, 2003; nivre et al, 2004) <papid> W04-2407 </papid>utilize transition histories learned from dependencies within sentences to predict next state transition and build the optimal transition sequence.</citsent>
<aftsection>
<nextsent>although different strategies were considered, two approaches yielded comparable results at previous tasks.
</nextsent>
<nextsent>semantic role labeling contains two problems: identification and labeling.
</nextsent>
<nextsent>identification is binary classification problem, and the goal is to identify annotated units in sentence; while labeling is multi-class classification problem, which is to assign arguments with appropriate semantic roles.
</nextsent>
<nextsent>hacioglu (2004) <papid> C04-1186 </papid>utilized predicate-argument structure and map dependency relations to semantic roles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4108">
<title id=" W09-1215.xml">parsing syntactic and semantic dependencies for multiple languages with a pipeline approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic role labeling contains two problems: identification and labeling.
</prevsent>
<prevsent>identification is binary classification problem, and the goal is to identify annotated units in sentence; while labeling is multi-class classification problem, which is to assign arguments with appropriate semantic roles.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
hacioglu (2004) <papid> C04-1186 </papid>utilized predicate-argument structure and map dependency relations to semantic roles.</citsent>
<aftsection>
<nextsent>liu et al (2005) <papid> W05-0627 </papid>combined two problems into classification one, avoiding some annotated units being excluded due to some incorrect identification results.</nextsent>
<nextsent>in addition, various features are also selected to improve accuracy of srl.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4109">
<title id=" W09-1215.xml">parsing syntactic and semantic dependencies for multiple languages with a pipeline approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>identification is binary classification problem, and the goal is to identify annotated units in sentence; while labeling is multi-class classification problem, which is to assign arguments with appropriate semantic roles.
</prevsent>
<prevsent>hacioglu (2004) <papid> C04-1186 </papid>utilized predicate-argument structure and map dependency relations to semantic roles.</prevsent>
</prevsection>
<citsent citstr=" W05-0627 ">
liu et al (2005) <papid> W05-0627 </papid>combined two problems into classification one, avoiding some annotated units being excluded due to some incorrect identification results.</citsent>
<aftsection>
<nextsent>in addition, various features are also selected to improve accuracy of srl.
</nextsent>
<nextsent>in this paper, we propose pipe lined approach for conll-09 shared task on joint learning of syntactic and semantic dependencies, and describe our system that can handle multiple languages.
</nextsent>
<nextsent>in the system, we handle syntactic dependency parsing with transition-based approach.
</nextsent>
<nextsent>for srl, we utilize maximum entropy model to identify predicate senses and classify arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4111">
<title id=" W09-1215.xml">parsing syntactic and semantic dependencies for multiple languages with a pipeline approach </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>for different languages, some features mentioned above are invalid and should be removed, and some extended features could improve the performance of the classifier.
</prevsent>
<prevsent>in our system we mainly focus on chinese, therefore, word and voice should be removed when processing chinese dataset.
</prevsent>
</prevsection>
<citsent citstr=" J08-2004 ">
we also adopt some features proposed by (xue, 2008): ? <papid> J08-2004 </papid>pos_path_ba, pos_path_sb, pos_ path_lb: ba and bei are functional words that impact the order of arguments.</citsent>
<aftsection>
<nextsent>in propbank, ba words have the pos tag ba, and bei words have two pos tags: sb (short bei) and lb (long bei).
</nextsent>
<nextsent>our experiments are based on pc with intel core 2 duo 2.1g cpu and 2g memory.
</nextsent>
<nextsent>training and evaluation data (taul?
</nextsent>
<nextsent>et al, 2008; xue et al, 2008; haji?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4112">
<title id=" W09-0402.xml">syntax oriented evaluation measures for machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the new measures are the pos bleu score, i.e. the bleu score calculated on pos tags instead of words, as well as the posp, theposr and the posf score: precision, recall and measure calculated on pos n-grams.
</prevsent>
<prevsent>in addition to the metrics based only on pos tags, we investigated wpf score, i.e. an f-measure which takes into account both word and pos n-grams.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
the correlations on the document level were computed on the english, french, spanish and german texts generated by various translation systems in the framework of the first (koehn and monz, 2006), <papid> W06-3114 </papid>second (callison-burch et al, 2007) and third shared translation task (callison-burchet al, 2008).</citsent>
<aftsection>
<nextsent>preliminary experiments were carried out on the data from the first (2006) andthe second task (2007) ? spear mans rank correlation coefficients between the adequacy and fluency scores and the posbleu, posp, posr and posf scores were calculated.
</nextsent>
<nextsent>the posbleu andthe posf score were shown to be the most promising, so that these metrics were submitted to the official shared evaluation task 2008.
</nextsent>
<nextsent>the results of this evaluation showed that these metrics also correlate well on the document level with another human score, i.e. the sentence ranking.
</nextsent>
<nextsent>however,on the sentence level the results were less promising.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4113">
<title id=" W09-0402.xml">syntax oriented evaluation measures for machine translation output </title>
<section> syntactic-oriented evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>the possible reason for this is the main draw back of the metrics based on pure pos tags, i.e. neglecting the lexical aspect.
</prevsent>
<prevsent>therefore we also introduced wpf score which takes into account both word n-grams and pos n-grams.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we investigated the following metrics oriented on the syntactic structure of translation output: ? posbleu the standard bleu score (papineni et al, 2002) <papid> P02-1040 </papid>calculated on pos tags instead of words; ? posppos n-gram precision: percentage of pos ngrams in the hypothesis which have counterpart in the reference; ? posrrecall measure based on pos n-grams: percentage of pos n-grams in the reference which are also present in the hypothesis; ? posfpos n-gram based f-measure: takes into account all pos n-grams which have counter 29part, both in the reference and in the hypoth esis.</citsent>
<aftsection>
<nextsent>wpff-measure based both on word and pos grams: takes into account all word n-gramsand all pos n-grams which have counterpart both in the corresponding reference and hypothesis.
</nextsent>
<nextsent>the prerequisite for all metrics is availability of an appropriate pos tagger for the target language.
</nextsent>
<nextsent>it should be noted that the pos tags cannot be only basic but must have all details (e.g. verb tenses, cases, number, gender, etc.).
</nextsent>
<nextsent>the n-gram scores as well as the posbleu score are based on four grams (i.e. the value of maximal is 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4114">
<title id=" W09-0402.xml">syntax oriented evaluation measures for machine translation output </title>
<section> correlations between the new metrics.  </section>
<citcontext>
<prevsection>
<prevsent>correlation coefficients between human scores and three well-known automatic measures bleu, meteor and ter were calculated as well, in order to see how the new metrics perform in comparison with widely used metrics.
</prevsent>
<prevsent>the scores were calculated for outputs of translation from spanish, french and german into english and vice versa.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
english and german pos tags were produced using the tnt tagger (brants, 2000), <papid> A00-1031 </papid>spanish texts were annotated using the free ling analyser (carreras et al, 2004), and french texts using the treetagger1.</citsent>
<aftsection>
<nextsent>in this way, all references and hypotheses were provided with detailed pos tags.
</nextsent>
<nextsent>experiments on 2006 and 2007 test datathe preliminary experiments with the new evaluation metrics were performed on the data from the first two shared tasks in order to investigate spearman correlation coefficients ? between pos based evaluation measures and the human scores adequacy and fluency.
</nextsent>
<nextsent>the metrics described in section 2 (except the wpf score) were calculated for all translation outputs.
</nextsent>
<nextsent>for each new metric, the ? coefficient with the adequacy and with the fluency score on the document level were calculated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4115">
<title id=" W09-0505.xml">annotating spoken dialogs from speech segments to dialog acts and frame semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in spoken dialog systems (sds) most used models of slu are based on the identification of slots (enthis work was partially funded by the european commission projects luna (contract 33549) and adamach (contract 022593).tities) within one or more frames (frame-slot se mantics) that is defined by the application.
</prevsent>
<prevsent>while this model is simple and clearly insufficient tocope with interpretation and reasoning, it has supported the first generation of spoken dialog systems.
</prevsent>
</prevsection>
<citsent citstr=" W04-3218 ">
such dialog systems are thus limited by the ability to parse semantic features such as predicates and to perform logical computation in the context of specific dialog act (bechet et al, 2004).<papid> W04-3218 </papid></citsent>
<aftsection>
<nextsent>this limitation is reflected in the type ofhuman-machine interactions which are mostly directed at querying the user for specific slots (e.g. what is the departure city??)
</nextsent>
<nextsent>or implementing simple dialog acts (e.g. confirmation).
</nextsent>
<nextsent>we believe that an important step in overcoming such limitation relies on the study of models of human-humandialogs at different levels of representation: lexical, syntactic, semantic and discourse.in this paper, we present our results in addressing the above issues in the context of the luna research project for next-generation spoken dialog interfaces (de mori et al, 2008).
</nextsent>
<nextsent>we propose models for different levels of annotation of theluna spoken dialog corpus, including attribute value, predicate argument structures and dialog acts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4116">
<title id=" W09-0505.xml">annotating spoken dialogs from speech segments to dialog acts and frame semantics </title>
<section> annotation model.  </section>
<citcontext>
<prevsection>
<prevsent>the attribute-value annotation uses predefined domain ontology to specify concepts and their relations.
</prevsent>
<prevsent>dialog acts are used to annotate intention in an utterance and can be useful to find relations between different utterances as the next section will show.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
for predicate structure annotation, we followed the framenet model (baker et al., 1998) (<papid> P98-1013 </papid>see section 2.2).</citsent>
<aftsection>
<nextsent>2.1 dialog act annotation.
</nextsent>
<nextsent>dialog act annotation is the task of identifying the function or goal of given utterance (sinclairand coulthard, 1975): thus, it provides complementary information to the identification of domain concepts in the utterance, and domain independent dialog act scheme can be applied.
</nextsent>
<nextsent>for our corpus, we used dialog act taxonomy which follows initiatives such as damsl (core and allen, 1997), trains (traum, 1996) anddit++ (bunt, 2005).
</nextsent>
<nextsent>although the level of granu larity and coverage varies across such taxonomies, careful analysis leads to identifying three main groups of dialog acts: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZE4117">
<title id=" W09-0505.xml">annotating spoken dialogs from speech segments to dialog acts and frame semantics </title>
<section> feedback/grounding acts,used to elicit and.  </section>
<citcontext>
<prevsection>
<prevsent>rather than aspiring to the full discriminative power of possible conversational situations, we have opted for simple taxonomy that would cover the vast majority 35 of utterances and at the same time would be able to generalize them.
</prevsent>
<prevsent>its small number of classes is meant to allow supervised classification method to achieve reasonable performance with limiteddata.
</prevsent>
</prevsection>
<citsent citstr=" W08-0109 ">
the taxonomy is currently used by the statistical dialogue manager in the adamach eu project (varges et al, 2008); <papid> W08-0109 </papid>the limited number of classes allows to reduce the number of hypothesized current dialogue acts, thus reducing the dialogue state space.</citsent>
<aftsection>
<nextsent>dialog act annotation was performed manually by linguist on speech transcriptions previously segmented into turns as mentioned above.
</nextsent>
<nextsent>the annotation unit for dialog acts, is the utterance; how ever, utterances are complex semantic entities that do not necessarily correspond to turns.
</nextsent>
<nextsent>hence, asegmentation of the dialog transcription into utterances was performed by the annotator before dialog act labeling.
</nextsent>
<nextsent>both utterance segmentation and dialog act labeling were performed through the mmax tool (muller and strube, 2003).the annotator proceeded according to the following guidelines: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>