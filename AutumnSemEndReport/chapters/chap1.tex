\chapter{Introduction}
\section{Automatic Text Summarization}
Automatic summarization is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document. As the problem of information overload has grown, and as the quantity of data has increased, so has interest in automatic summarization. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax. Automatic data summarization is a very important area within machine learning and data mining. Summarization technologies are used today, in a large number of sectors in industry today. An example of the use of summarization technology is search engines such as Google. Other examples include document summarization, image collection summarization and video summarization. The main idea of summarization is to find a representative subset of the data, which contains the information of the entire set. Document summarization, tries to automatically create a representative summary or abstract of the entire document, by finding the most informative sentences. Similarly, in image summarization the system finds the most representative and important (or salient) images. Similarly, in consumer videos one would want to remove the boring or repetitive scenes, and extract out a much shorter and concise version of the video. This is also important, say for surveillance videos, where one might want to extract out only important events in the recorded video, since most of the events are uninteresting with nothing going on.
\pagebreak

\subsection{Extraction-based Summarization}

In this summarization task, the automatic system extracts objects from the entire collection, without modifying the objects themselves. Examples of this include keyphrase extraction, where the goal is to select individual words or phrases to "tag" a document, and document summarization, where the goal is to select whole sentences (without modifying them) to create a short paragraph summary. Similarly, in image collection summarization, the system extracts images from the collection without modifying the images themselves.

\subsection{Abstraction-based Summarization}
Extraction techniques merely copy the information deemed most important by the system to the summary (for example, key clauses, sentences or paragraphs), while abstraction involves paraphrasing sections of the source document. In general, abstraction can condense a text more strongly than extraction, but the programs that can do this are harder to develop as they require the use of natural language generation technology, which itself is a growing field.

While some work has been done in abstractive summarization (creating an abstract synopsis like that of a human), the majority of summarization systems are extractive (selecting a subset of sentences to place in a summary).

% \begin{figure}
% \centering
% \includegraphics[height=4cm]{figures/example.jpg}
% \caption[Chemistry cat.]{This is chemistry cat. Here he serves to demonstrate a figure in a LaTeX document, complete with caption. Notice his suave bow tie, but also that he has forgotten to label his solutions.}
% \end{figure}
\section{Citation Analysis}
Previous work has analyzed citation and collaboration networks (Teufel, Siddharthan, \& Tidhar, 2006; Newman, 2001) and scientific article summarization (Teufel \& Moens, 2002). Bradshaw (2002, 2003) benefited from citations to determine the content of articles and introduce “Reference Directed Indexing” to improve the results of a search engine. Nanba, Abekawa, Okumura, and Saito (2004) and Nanba et al. (2000) analyzed citation sentences and automatically categorize citations into three groups using 160 pre-defined phrase-based
rules. This categorization was then used to build a tool to help researchers analyze citations and write scientific summaries. Nanba and Okumura (1999) also discussed the same citation categorization to support a system for writing a survey. Nanba and Okumura (1999) and
Nanba et al. (2000) reported that co-citation implies similarity by showing that the textual similarity of co-cited papers is proportional to the proximity of their citations in the citing article.

Previous work has shown the importance of the citation sentences in understanding
scientific contributions. Elkiss et al. (2008) performed a large-scale study on citations and
their importance. They conducted several experiments on a set of 2, 497 articles from the
free PubMed Central (PMC) repository2 and 66 from ACM digital library. Results from this
experiment confirmed that the average cosine between sentences in the set of citations to an
article is consistently higher than that of its abstract. They also reported that this number
is much greater than the average cosine between citation sentences and a randomly chosen
document, as well as between citation sentences and the abstract. Finally, they concluded
that the content of citing sentences has much greater uniformity than the content of the
corresponding abstract, implying that citations are more focused and contain additional
information that does not appear in abstracts.

Nakov and Hearst (2012) performed a detailed manual study of citations in the area
of molecular interactions and found that the set of citations to a given target paper cover
most information found in the abstract of that article, as well as 20\% more concepts, mainly
related to experimental procedures.
Kupiec, Pedersen, and Chen (1995) used the abstracts of scientific articles as a target
summary. They used 188 Engineering Information summaries that are mostly indicative
in nature. Kan, Klavans, and McKeown (2002) used annotated bibliographies to cover
certain aspects of summarization and suggest guidelines that summaries should also include
metadata and critical document features as well as the prominent content-based features.
Siddharthan and Teufel (2007) described a new reference task and show high human
agreement as well as an improvement in the performance of argumentative zoning (Teufel,
2005). In argumentative zoning—a rhetorical classification task—seven classes (Own, Other,
Background, Textual, Aim, Basis, and Contrast) are used to label sentences according to
their role in the author’s argument.
The problem of automatic related work summarization is addressed by Hoang and Kan
(2010). In their work, Hoang and Kan used a set of keywords representing a hierarchy of
paper topics and assigned a score to each input sentence to construct an extractive summary.
Athar (2011) addressed the problem of identifying positive and negative sentiment polarity
in citations to scientific papers. Similarly, Athar and Teufel (2012) used context-enriched
citations to classify scientific sentiment towards a target paper.