it is also notable the study reported in (lin and hovy, 2003b) discussing the usefulness and limitations of automatic sentence extraction for summarization, which emphasizes the need of accurate tools for sentence extraction, as an integral part of automatic summarization systems. 
meta-evaluation of similarity metrics the question of how to know which similarity metric is best to evaluate automatic summaries/translations has been addressed by ‚Ä¢ comparing the quality of automatic items with the quality of manual references (culy and riehemann, 2003; lin and hovy, 2003b). 
for evaluation, we are using the rouge evaluation toolkit1, which is a method based on ngram statistics, found to be highly correlated with human evaluations (lin and hovy, 2003a). 
it is also notable the study reported in (lin and hovy, 2003b) discussing the usefulness and limitations of automatic sentence extraction for text summarization, 23 single document metaù summarization algorithm summarization algo. 
bleu (papineni et al, 2001) and rouge (lin and hovy, 2003a) are the standard similarity metrics used in machine translation and text summarisation. 
