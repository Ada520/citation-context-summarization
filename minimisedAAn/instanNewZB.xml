<paper>
<cited id="ZB0">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we develop technique for integrating pre trained probability models into the maxent framework, and show that this approach can improve on an hmm-based state-of-the-art system for the sentence-boundary detection task.
</prevsent>
<prevsent>an even more substantial improvement is obtained by combining the posterior probabilities of the two systems.
</prevsent>
</prevsection>
<citsent citstr=" A94-1013 ">
sentence boundary detection is problem that has received limited attention in the text-based computational linguistics community (schmid, 2000; palmer and hearst, 1994; <papid> A94-1013 </papid>reynar and ratnaparkhi,1997), <papid> A97-1004 </papid>but which has recently acquired renewed importance through an effort by the darpa ears program (darpa information processing technology office, 2003) to improve automatic speech transcription technology.</citsent>
<aftsection>
<nextsent>since standard speech recognizers output an unstructured stream of words, improving transcription means not only that word accuracy must be improved, but also that commonly used structural features such as sentence boundaries need to be recognized.
</nextsent>
<nextsent>the task is thus fundamentally based on both acoustic and textual (via automatic word recognition) information.
</nextsent>
<nextsent>from computational linguistics point of view, sentence units are crucial and assumed in most of the further processing steps that one would want to apply to such output: tagging and parsing, information extraction, and summarization, among others.
</nextsent>
<nextsent>sentence segmentation from speech is difficultproblem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we develop technique for integrating pre trained probability models into the maxent framework, and show that this approach can improve on an hmm-based state-of-the-art system for the sentence-boundary detection task.
</prevsent>
<prevsent>an even more substantial improvement is obtained by combining the posterior probabilities of the two systems.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
sentence boundary detection is problem that has received limited attention in the text-based computational linguistics community (schmid, 2000; palmer and hearst, 1994; <papid> A94-1013 </papid>reynar and ratnaparkhi,1997), <papid> A97-1004 </papid>but which has recently acquired renewed importance through an effort by the darpa ears program (darpa information processing technology office, 2003) to improve automatic speech transcription technology.</citsent>
<aftsection>
<nextsent>since standard speech recognizers output an unstructured stream of words, improving transcription means not only that word accuracy must be improved, but also that commonly used structural features such as sentence boundaries need to be recognized.
</nextsent>
<nextsent>the task is thus fundamentally based on both acoustic and textual (via automatic word recognition) information.
</nextsent>
<nextsent>from computational linguistics point of view, sentence units are crucial and assumed in most of the further processing steps that one would want to apply to such output: tagging and parsing, information extraction, and summarization, among others.
</nextsent>
<nextsent>sentence segmentation from speech is difficultproblem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB6">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> features and knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, the word identities themselves (from automatic recognition or human transcripts) constitute primary knowledge source for the sentence segmentation task.
</prevsent>
<prevsent>we also make use of various automatic taggers that map the word sequence to other representations.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
thetnt tagger (brants, 2000) <papid> A00-1031 </papid>is used to obtain part-of speech (pos) tags.</citsent>
<aftsection>
<nextsent>a tbl chunker trained on wall street journal corpus (ngai and florian, 2001) <papid> N01-1006 </papid>maps each word to an associated chunk tag, encoding chunk type and relative word position (beginning of an np, inside vp, etc.).</nextsent>
<nextsent>the tagged versions ofthe word stream are provided to allow generalizations based on syntactic structure and to smooth out possibly undertrained word-based probability esti1this is the same as simple per-event classification accuracy, except that the denominator counts only the marked?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB7">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> features and knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>we also make use of various automatic taggers that map the word sequence to other representations.
</prevsent>
<prevsent>thetnt tagger (brants, 2000) <papid> A00-1031 </papid>is used to obtain part-of speech (pos) tags.</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
a tbl chunker trained on wall street journal corpus (ngai and florian, 2001) <papid> N01-1006 </papid>maps each word to an associated chunk tag, encoding chunk type and relative word position (beginning of an np, inside vp, etc.).</citsent>
<aftsection>
<nextsent>the tagged versions ofthe word stream are provided to allow generalizations based on syntactic structure and to smooth out possibly undertrained word-based probability esti1this is the same as simple per-event classification accuracy, except that the denominator counts only the marked?
</nextsent>
<nextsent>events, thereby yielding error rates that are much higher than if one uses all potential boundary locations.
</nextsent>
<nextsent>mates.
</nextsent>
<nextsent>for the same reasons we also generate word class labels that are automatically induced from bigram word distributions (brown et al, 1992).<papid> J92-4003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB8">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> features and knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>events, thereby yielding error rates that are much higher than if one uses all potential boundary locations.
</prevsent>
<prevsent>mates.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
for the same reasons we also generate word class labels that are automatically induced from bigram word distributions (brown et al, 1992).<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>to model the prosodic structure of sentence boundaries, we extract several hundred features around each word boundary.
</nextsent>
<nextsent>these are based on the acoustic alignments produced by speech recognizer (or forced alignments of the true words when given).
</nextsent>
<nextsent>the features capture duration, pitch, and energy patterns associated with the word boundaries.
</nextsent>
<nextsent>informative features include the pause duration at the boundary, the difference in pitch before and after the boundary, and so on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB12">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> the models.  </section>
<citcontext>
<prevsection>
<prevsent>this mismatch between training and use of the model as classifier would not arise if the model directly estimated the posterior boundary label probabilities (e jw;f ).
</prevsent>
<prevsent>a second problem with hmms is that the underlying n-gram sequence model does not cope well with multiple representations (features) ofthe word sequence (words, pos, etc.) short of building joint model of all variables.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
this type of situation is well-suited to maximum entropy formulation (berger et al, 1996), <papid> J96-1002 </papid>which allows conditioning features to apply simultaneously, and therefore gives greater freedom in choosing representations.</citsent>
<aftsection>
<nextsent>another desirable characteristic of maxent mode lsis that they do not split the data recursively to condition their probability estimates, which makes them more robust than decision trees when training data is limited.
</nextsent>
<nextsent>4.2.1 model formulation and training we built posterior probability model for sentence boundary classification in the maxent framework.
</nextsent>
<nextsent>such model takes the familiar exponential form4 (ejw;f ) = 1  (w;f ) p  g (e;w;f ) (3) where  (w;f ) is the normalization term:  (w;f ) = e 0 p  g (e 0 ;w;f ) (4) the functions k (e;w;f ) are indicator functions corresponding to (complex) features defined over 4we omit the index from here since the current?
</nextsent>
<nextsent>event is meant in all cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB14">
<title id=" W04-3209.xml">comparing and combining generative and posterior probability models some advances in sentence boundary detection in speech </title>
<section> the models.  </section>
<citcontext>
<prevsection>
<prevsent>in that respect, the maxent model resembles the conditional probability model at the individual hmm states.
</prevsent>
<prevsent>the hmm as whole, however, through the forward-backward procedure,propagates evidence from all parts of the observation sequence to any given decision point.
</prevsent>
</prevsection>
<citsent citstr=" W02-1002 ">
variants such as the conditional markov model (cmm) combine sequence modeling with posterior probability (e.g., maxent) modeling, but it has been shown thatcmms are still structurally inferior to hmms be cause they only propagate evidence forward in time, not backwards (klein and manning, 2002).<papid> W02-1002 </papid></citsent>
<aftsection>
<nextsent>5.1 experimental setup.
</nextsent>
<nextsent>experiments comparing the two modeling approaches were conducted on two corpora: broadcast news (bn) and conversational telephone speech (cts).
</nextsent>
<nextsent>bn and cts differ in genre and speakingstyle.
</nextsent>
<nextsent>these differences are reflected in the frequency of su boundaries: about 14% of inter-word boundaries are sus in cts, compared to roughly 8% in bn.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB18">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the precision, recall and average parsing time for the penn treebank (section 23) were 87.85%, 86.85%, and 360 ms, respectively.
</prevsent>
<prevsent>we investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (hpsg) parsing for the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
we first applied beam thresholding techniques developed for cfg parsing to hpsg parsing, including local thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>and iterative parsing (tsuruoka and tsujii, 2005<papid> W05-1514 </papid>b).</citsent>
<aftsection>
<nextsent>next, we applied parsing techniques developed for deep parsing, including quick check (malouf et al, 2000), large constituent inhibition (kaplan et al, 2004) <papid> N04-1013 </papid>and hybrid parsing with cfg chunk parser (daum et al, 2003; <papid> E03-1052 </papid>frank et al, 2003; <papid> P03-1014 </papid>frank, 2004).<papid> C04-1185 </papid>the experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the penn treebank.</nextsent>
<nextsent>unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB19">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the precision, recall and average parsing time for the penn treebank (section 23) were 87.85%, 86.85%, and 360 ms, respectively.
</prevsent>
<prevsent>we investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (hpsg) parsing for the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" W05-1514 ">
we first applied beam thresholding techniques developed for cfg parsing to hpsg parsing, including local thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>and iterative parsing (tsuruoka and tsujii, 2005<papid> W05-1514 </papid>b).</citsent>
<aftsection>
<nextsent>next, we applied parsing techniques developed for deep parsing, including quick check (malouf et al, 2000), large constituent inhibition (kaplan et al, 2004) <papid> N04-1013 </papid>and hybrid parsing with cfg chunk parser (daum et al, 2003; <papid> E03-1052 </papid>frank et al, 2003; <papid> P03-1014 </papid>frank, 2004).<papid> C04-1185 </papid>the experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the penn treebank.</nextsent>
<nextsent>unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB21">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (hpsg) parsing for the penn treebank.
</prevsent>
<prevsent>we first applied beam thresholding techniques developed for cfg parsing to hpsg parsing, including local thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>and iterative parsing (tsuruoka and tsujii, 2005<papid> W05-1514 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
next, we applied parsing techniques developed for deep parsing, including quick check (malouf et al, 2000), large constituent inhibition (kaplan et al, 2004) <papid> N04-1013 </papid>and hybrid parsing with cfg chunk parser (daum et al, 2003; <papid> E03-1052 </papid>frank et al, 2003; <papid> P03-1014 </papid>frank, 2004).<papid> C04-1185 </papid>the experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the penn treebank.</citsent>
<aftsection>
<nextsent>unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.
</nextsent>
<nextsent>although they provide precise linguistic structures of sentences, their processing is considered expensive because of the detailed descriptions.
</nextsent>
<nextsent>since efficiency is of particular concern in practical applications, number of studies have focused on improving the parsing efficiency of unification based grammars (oepen et al, 2002).
</nextsent>
<nextsent>although significant improvements inefficiency have been made, parsing speed is still not high enough for practical applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB23">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (hpsg) parsing for the penn treebank.
</prevsent>
<prevsent>we first applied beam thresholding techniques developed for cfg parsing to hpsg parsing, including local thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>and iterative parsing (tsuruoka and tsujii, 2005<papid> W05-1514 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" E03-1052 ">
next, we applied parsing techniques developed for deep parsing, including quick check (malouf et al, 2000), large constituent inhibition (kaplan et al, 2004) <papid> N04-1013 </papid>and hybrid parsing with cfg chunk parser (daum et al, 2003; <papid> E03-1052 </papid>frank et al, 2003; <papid> P03-1014 </papid>frank, 2004).<papid> C04-1185 </papid>the experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the penn treebank.</citsent>
<aftsection>
<nextsent>unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.
</nextsent>
<nextsent>although they provide precise linguistic structures of sentences, their processing is considered expensive because of the detailed descriptions.
</nextsent>
<nextsent>since efficiency is of particular concern in practical applications, number of studies have focused on improving the parsing efficiency of unification based grammars (oepen et al, 2002).
</nextsent>
<nextsent>although significant improvements inefficiency have been made, parsing speed is still not high enough for practical applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB25">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (hpsg) parsing for the penn treebank.
</prevsent>
<prevsent>we first applied beam thresholding techniques developed for cfg parsing to hpsg parsing, including local thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>and iterative parsing (tsuruoka and tsujii, 2005<papid> W05-1514 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P03-1014 ">
next, we applied parsing techniques developed for deep parsing, including quick check (malouf et al, 2000), large constituent inhibition (kaplan et al, 2004) <papid> N04-1013 </papid>and hybrid parsing with cfg chunk parser (daum et al, 2003; <papid> E03-1052 </papid>frank et al, 2003; <papid> P03-1014 </papid>frank, 2004).<papid> C04-1185 </papid>the experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the penn treebank.</citsent>
<aftsection>
<nextsent>unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.
</nextsent>
<nextsent>although they provide precise linguistic structures of sentences, their processing is considered expensive because of the detailed descriptions.
</nextsent>
<nextsent>since efficiency is of particular concern in practical applications, number of studies have focused on improving the parsing efficiency of unification based grammars (oepen et al, 2002).
</nextsent>
<nextsent>although significant improvements inefficiency have been made, parsing speed is still not high enough for practical applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB26">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigated the performance efficacy of beam search parsing and deep parsing techniques in probabilistic head-driven phrase structure grammar (hpsg) parsing for the penn treebank.
</prevsent>
<prevsent>we first applied beam thresholding techniques developed for cfg parsing to hpsg parsing, including local thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>and iterative parsing (tsuruoka and tsujii, 2005<papid> W05-1514 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" C04-1185 ">
next, we applied parsing techniques developed for deep parsing, including quick check (malouf et al, 2000), large constituent inhibition (kaplan et al, 2004) <papid> N04-1013 </papid>and hybrid parsing with cfg chunk parser (daum et al, 2003; <papid> E03-1052 </papid>frank et al, 2003; <papid> P03-1014 </papid>frank, 2004).<papid> C04-1185 </papid>the experiments showed how each technique contributes to the final output of parsing in terms of precision, recall, and speed for the penn treebank.</citsent>
<aftsection>
<nextsent>unification-based grammars have been extensively studied in terms of linguistic formulation and computation efficiency.
</nextsent>
<nextsent>although they provide precise linguistic structures of sentences, their processing is considered expensive because of the detailed descriptions.
</nextsent>
<nextsent>since efficiency is of particular concern in practical applications, number of studies have focused on improving the parsing efficiency of unification based grammars (oepen et al, 2002).
</nextsent>
<nextsent>although significant improvements inefficiency have been made, parsing speed is still not high enough for practical applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB30">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since efficiency is of particular concern in practical applications, number of studies have focused on improving the parsing efficiency of unification based grammars (oepen et al, 2002).
</prevsent>
<prevsent>although significant improvements inefficiency have been made, parsing speed is still not high enough for practical applications.
</prevsent>
</prevsection>
<citsent citstr=" P05-1011 ">
the recent introduction of probabilistic models of wide-coverage unification-based grammars (malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyaoand tsujii, 2005) <papid> P05-1011 </papid>has opened up the novel possibility of increasing parsing speed by guiding the search path using probabilities.</citsent>
<aftsection>
<nextsent>that is, since we often require only the most probable parse result, we can compute partial parse results that are likely to contribute to the final parse result.
</nextsent>
<nextsent>this approach has been extensively studied in the field of probabilistic 103 cfg (pcfg) parsing, such as viterbi parsing and beam thresholding.
</nextsent>
<nextsent>while many methods of probabilistic parsing for unification-based grammars have been developed,their strategy is to first perform exhaustive parsing without using probabilities and then select the highest probability parse.
</nextsent>
<nextsent>the behavior of their algorithms is like that of the viterbi algorithm forpcfg parsing, so the correct parse with the highest probability is guaranteed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB31">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the behavior of their algorithms is like that of the viterbi algorithm forpcfg parsing, so the correct parse with the highest probability is guaranteed.
</prevsent>
<prevsent>the interesting pointof this approach is that, once the exhaustive parsing is completed, the probabilities of non-local dependencies, which cannot be computed during parsing, are computed after making packed parse forest.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
probabilistic models where probabilities are assigned to the cfg backbone of the unification-based grammar have been developed (kasper et al, 1996; briscoe and carroll, 1993; <papid> J93-1002 </papid>kiefer et al, 2002), <papid> C02-1075 </papid>and the most probable parse is found by pcfg parsing.this model is based on pcfg and not probabilistic unification-based grammar parsing.</citsent>
<aftsection>
<nextsent>geman and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>proposed dynamic programming algorithm for finding the most probable parse in packed parse forest generated by unification-based grammars without expanding the forest.</nextsent>
<nextsent>however, the efficiency of this algorithm is inherently limited by the inefficiency of exhaustive parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB32">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the behavior of their algorithms is like that of the viterbi algorithm forpcfg parsing, so the correct parse with the highest probability is guaranteed.
</prevsent>
<prevsent>the interesting pointof this approach is that, once the exhaustive parsing is completed, the probabilities of non-local dependencies, which cannot be computed during parsing, are computed after making packed parse forest.
</prevsent>
</prevsection>
<citsent citstr=" C02-1075 ">
probabilistic models where probabilities are assigned to the cfg backbone of the unification-based grammar have been developed (kasper et al, 1996; briscoe and carroll, 1993; <papid> J93-1002 </papid>kiefer et al, 2002), <papid> C02-1075 </papid>and the most probable parse is found by pcfg parsing.this model is based on pcfg and not probabilistic unification-based grammar parsing.</citsent>
<aftsection>
<nextsent>geman and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>proposed dynamic programming algorithm for finding the most probable parse in packed parse forest generated by unification-based grammars without expanding the forest.</nextsent>
<nextsent>however, the efficiency of this algorithm is inherently limited by the inefficiency of exhaustive parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB33">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the interesting pointof this approach is that, once the exhaustive parsing is completed, the probabilities of non-local dependencies, which cannot be computed during parsing, are computed after making packed parse forest.
</prevsent>
<prevsent>probabilistic models where probabilities are assigned to the cfg backbone of the unification-based grammar have been developed (kasper et al, 1996; briscoe and carroll, 1993; <papid> J93-1002 </papid>kiefer et al, 2002), <papid> C02-1075 </papid>and the most probable parse is found by pcfg parsing.this model is based on pcfg and not probabilistic unification-based grammar parsing.</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
geman and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>proposed dynamic programming algorithm for finding the most probable parse in packed parse forest generated by unification-based grammars without expanding the forest.</citsent>
<aftsection>
<nextsent>however, the efficiency of this algorithm is inherently limited by the inefficiency of exhaustive parsing.
</nextsent>
<nextsent>in this paper we describe the performance of beam thresholding, including iterative parsing, in probabilistic hpsg parsing for large-scale corpora, the penn treebank.
</nextsent>
<nextsent>we show how techniques developed for efficient deep parsing can improve the efficiency of probabilistic parsing.
</nextsent>
<nextsent>these techniques were evaluated in experiments on the penn treebank (marcuset al, 1994) with the wide-coverage hpsg parser developed by miyao et al (miyao et al, 2005; miyao and tsujii, 2005).<papid> P05-1011 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB38">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>the sign of the larger constituent is obtained by repeatedly applying schemata to lexi cal/phrasal signs.
</prevsent>
<prevsent>finally, the parse result is output as phrasal sign that dominates the sentence.given set of words and set of feature structures, an hpsg is formulated as tuple, = l,r?, where = {l = w,f ?|w ? w, ? f} is set of lexical entries, and is set of schemata, i.e., ? is partial function: ? ? . given sentence, an hpsg computes set of phrasal signs, i.e., feature structures, as result of parsing.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
previous studies (abney, 1997; <papid> J97-4005 </papid>johnson et al,1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>miyao et al, 2003; malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005) <papid> P05-1011 </papid>defined probabilistic model of unification-based grammars as log-linear model or maximum entropy model (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the probability of parse result assigned to given sentence = w1, . . .
</nextsent>
<nextsent>, wn?
</nextsent>
<nextsent>is p(t |w) = 1zw exp ( ? ifi(t ) ) zw = ? ? exp ( ? ifi(t ?) ) , where is model parameter, and fi is feature function that represents characteristic of parse treet . intuitively, the probability is defined as the normalized product of the weights exp(i) when characteristic corresponding to fi appears in parse resultt . model parameters are estimated using numer 104 ical optimization methods (malouf, 2002) <papid> W02-2018 </papid>so as to maximize the log-likelihood of the training data.however, the above model cannot be easily estimated because the estimation requires the computation of p(t |w) for all parse candidates assigned to sentence w. because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences.to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</nextsent>
<nextsent>they assumed that features are functions on nodes in packed parse forest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB39">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>the sign of the larger constituent is obtained by repeatedly applying schemata to lexi cal/phrasal signs.
</prevsent>
<prevsent>finally, the parse result is output as phrasal sign that dominates the sentence.given set of words and set of feature structures, an hpsg is formulated as tuple, = l,r?, where = {l = w,f ?|w ? w, ? f} is set of lexical entries, and is set of schemata, i.e., ? is partial function: ? ? . given sentence, an hpsg computes set of phrasal signs, i.e., feature structures, as result of parsing.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
previous studies (abney, 1997; <papid> J97-4005 </papid>johnson et al,1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>miyao et al, 2003; malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005) <papid> P05-1011 </papid>defined probabilistic model of unification-based grammars as log-linear model or maximum entropy model (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the probability of parse result assigned to given sentence = w1, . . .
</nextsent>
<nextsent>, wn?
</nextsent>
<nextsent>is p(t |w) = 1zw exp ( ? ifi(t ) ) zw = ? ? exp ( ? ifi(t ?) ) , where is model parameter, and fi is feature function that represents characteristic of parse treet . intuitively, the probability is defined as the normalized product of the weights exp(i) when characteristic corresponding to fi appears in parse resultt . model parameters are estimated using numer 104 ical optimization methods (malouf, 2002) <papid> W02-2018 </papid>so as to maximize the log-likelihood of the training data.however, the above model cannot be easily estimated because the estimation requires the computation of p(t |w) for all parse candidates assigned to sentence w. because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences.to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</nextsent>
<nextsent>they assumed that features are functions on nodes in packed parse forest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB40">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>the sign of the larger constituent is obtained by repeatedly applying schemata to lexi cal/phrasal signs.
</prevsent>
<prevsent>finally, the parse result is output as phrasal sign that dominates the sentence.given set of words and set of feature structures, an hpsg is formulated as tuple, = l,r?, where = {l = w,f ?|w ? w, ? f} is set of lexical entries, and is set of schemata, i.e., ? is partial function: ? ? . given sentence, an hpsg computes set of phrasal signs, i.e., feature structures, as result of parsing.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
previous studies (abney, 1997; <papid> J97-4005 </papid>johnson et al,1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>miyao et al, 2003; malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005) <papid> P05-1011 </papid>defined probabilistic model of unification-based grammars as log-linear model or maximum entropy model (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the probability of parse result assigned to given sentence = w1, . . .
</nextsent>
<nextsent>, wn?
</nextsent>
<nextsent>is p(t |w) = 1zw exp ( ? ifi(t ) ) zw = ? ? exp ( ? ifi(t ?) ) , where is model parameter, and fi is feature function that represents characteristic of parse treet . intuitively, the probability is defined as the normalized product of the weights exp(i) when characteristic corresponding to fi appears in parse resultt . model parameters are estimated using numer 104 ical optimization methods (malouf, 2002) <papid> W02-2018 </papid>so as to maximize the log-likelihood of the training data.however, the above model cannot be easily estimated because the estimation requires the computation of p(t |w) for all parse candidates assigned to sentence w. because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences.to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</nextsent>
<nextsent>they assumed that features are functions on nodes in packed parse forest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB44">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>the sign of the larger constituent is obtained by repeatedly applying schemata to lexi cal/phrasal signs.
</prevsent>
<prevsent>finally, the parse result is output as phrasal sign that dominates the sentence.given set of words and set of feature structures, an hpsg is formulated as tuple, = l,r?, where = {l = w,f ?|w ? w, ? f} is set of lexical entries, and is set of schemata, i.e., ? is partial function: ? ? . given sentence, an hpsg computes set of phrasal signs, i.e., feature structures, as result of parsing.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
previous studies (abney, 1997; <papid> J97-4005 </papid>johnson et al,1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>miyao et al, 2003; malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005) <papid> P05-1011 </papid>defined probabilistic model of unification-based grammars as log-linear model or maximum entropy model (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the probability of parse result assigned to given sentence = w1, . . .
</nextsent>
<nextsent>, wn?
</nextsent>
<nextsent>is p(t |w) = 1zw exp ( ? ifi(t ) ) zw = ? ? exp ( ? ifi(t ?) ) , where is model parameter, and fi is feature function that represents characteristic of parse treet . intuitively, the probability is defined as the normalized product of the weights exp(i) when characteristic corresponding to fi appears in parse resultt . model parameters are estimated using numer 104 ical optimization methods (malouf, 2002) <papid> W02-2018 </papid>so as to maximize the log-likelihood of the training data.however, the above model cannot be easily estimated because the estimation requires the computation of p(t |w) for all parse candidates assigned to sentence w. because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences.to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</nextsent>
<nextsent>they assumed that features are functions on nodes in packed parse forest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB45">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>the probability of parse result assigned to given sentence = w1, . . .
</prevsent>
<prevsent>, wn?
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
is p(t |w) = 1zw exp ( ? ifi(t ) ) zw = ? ? exp ( ? ifi(t ?) ) , where is model parameter, and fi is feature function that represents characteristic of parse treet . intuitively, the probability is defined as the normalized product of the weights exp(i) when characteristic corresponding to fi appears in parse resultt . model parameters are estimated using numer 104 ical optimization methods (malouf, 2002) <papid> W02-2018 </papid>so as to maximize the log-likelihood of the training data.however, the above model cannot be easily estimated because the estimation requires the computation of p(t |w) for all parse candidates assigned to sentence w. because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences.to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</citsent>
<aftsection>
<nextsent>they assumed that features are functions on nodes in packed parse forest.
</nextsent>
<nextsent>that is, parse tree is represented by set of nodes, i.e., = {c}, and the parse forest is represented by an and/or graph of the nodes.
</nextsent>
<nextsent>from this assumption, we can redefine the probability as p(t |w) = 1zw exp ( ? ct ? ifi(c) ) zw = ? ? exp ( ? ct ? ?
</nextsent>
<nextsent>i ifi(c) ) . packed parse forest has structure similar to chart of cfg parsing, and corresponds to an edge in the chart.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB48">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>this assumption restricts the possibility of feature functions that represent non-local dependencies expressed in parse result.
</prevsent>
<prevsent>since unification-based grammars can express semantic relations, such as predicate-argument relations, in their structure, the assumption unjustifiably restricts the flexibility of probabilistic modeling.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
however, previous research (miyao et al, 2003; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al, 2004) <papid> N04-1013 </papid>showed that predicate-argument relations can be represented under the assumption of feature locality.</citsent>
<aftsection>
<nextsent>we thus assumed the locality of feature functions and exploited it for the efficient search of probable parse results.
</nextsent>
<nextsent>parsing many of the techniques for improving the parsing efficiency of deep linguistic analysis have been developed in the framework of lexicalized grammars such as lexical functional grammar (lfg) (bresnan, 1982), lexicalized tree adjoining grammar (ltag) (shabes et al, 1988), hpsg (pollard and sag, 1994)or combinatory categorial grammar (ccg) (steedman, 2000).
</nextsent>
<nextsent>most of them were developed forex haustive parsing, i.e., producing all parse results that are given by the grammar (matsumoto et al, 1983; maxwell and kaplan, 1993; <papid> J93-4001 </papid>van noord, 1997; kiefer et al, 1999; <papid> P99-1061 </papid>malouf et al, 2000; torisawa et al, 2000; oepen et al, 2002; penn and munteanu, 2003).<papid> P03-1026 </papid></nextsent>
<nextsent>the strategy of exhaustive parsing has been widely used in grammar development and in parameter training for probabilistic models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB50">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> techniques for efficient deep.  </section>
<citcontext>
<prevsection>
<prevsent>we thus assumed the locality of feature functions and exploited it for the efficient search of probable parse results.
</prevsent>
<prevsent>parsing many of the techniques for improving the parsing efficiency of deep linguistic analysis have been developed in the framework of lexicalized grammars such as lexical functional grammar (lfg) (bresnan, 1982), lexicalized tree adjoining grammar (ltag) (shabes et al, 1988), hpsg (pollard and sag, 1994)or combinatory categorial grammar (ccg) (steedman, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
most of them were developed forex haustive parsing, i.e., producing all parse results that are given by the grammar (matsumoto et al, 1983; maxwell and kaplan, 1993; <papid> J93-4001 </papid>van noord, 1997; kiefer et al, 1999; <papid> P99-1061 </papid>malouf et al, 2000; torisawa et al, 2000; oepen et al, 2002; penn and munteanu, 2003).<papid> P03-1026 </papid></citsent>
<aftsection>
<nextsent>the strategy of exhaustive parsing has been widely used in grammar development and in parameter training for probabilistic models.
</nextsent>
<nextsent>we tested three of these techniques.
</nextsent>
<nextsent>quick check quick check filters out non-unifiable feature structures (malouf et al, 2000).
</nextsent>
<nextsent>suppose we have two non-unifiable feature structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB51">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> techniques for efficient deep.  </section>
<citcontext>
<prevsection>
<prevsent>we thus assumed the locality of feature functions and exploited it for the efficient search of probable parse results.
</prevsent>
<prevsent>parsing many of the techniques for improving the parsing efficiency of deep linguistic analysis have been developed in the framework of lexicalized grammars such as lexical functional grammar (lfg) (bresnan, 1982), lexicalized tree adjoining grammar (ltag) (shabes et al, 1988), hpsg (pollard and sag, 1994)or combinatory categorial grammar (ccg) (steedman, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P99-1061 ">
most of them were developed forex haustive parsing, i.e., producing all parse results that are given by the grammar (matsumoto et al, 1983; maxwell and kaplan, 1993; <papid> J93-4001 </papid>van noord, 1997; kiefer et al, 1999; <papid> P99-1061 </papid>malouf et al, 2000; torisawa et al, 2000; oepen et al, 2002; penn and munteanu, 2003).<papid> P03-1026 </papid></citsent>
<aftsection>
<nextsent>the strategy of exhaustive parsing has been widely used in grammar development and in parameter training for probabilistic models.
</nextsent>
<nextsent>we tested three of these techniques.
</nextsent>
<nextsent>quick check quick check filters out non-unifiable feature structures (malouf et al, 2000).
</nextsent>
<nextsent>suppose we have two non-unifiable feature structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB52">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> techniques for efficient deep.  </section>
<citcontext>
<prevsection>
<prevsent>we thus assumed the locality of feature functions and exploited it for the efficient search of probable parse results.
</prevsent>
<prevsent>parsing many of the techniques for improving the parsing efficiency of deep linguistic analysis have been developed in the framework of lexicalized grammars such as lexical functional grammar (lfg) (bresnan, 1982), lexicalized tree adjoining grammar (ltag) (shabes et al, 1988), hpsg (pollard and sag, 1994)or combinatory categorial grammar (ccg) (steedman, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P03-1026 ">
most of them were developed forex haustive parsing, i.e., producing all parse results that are given by the grammar (matsumoto et al, 1983; maxwell and kaplan, 1993; <papid> J93-4001 </papid>van noord, 1997; kiefer et al, 1999; <papid> P99-1061 </papid>malouf et al, 2000; torisawa et al, 2000; oepen et al, 2002; penn and munteanu, 2003).<papid> P03-1026 </papid></citsent>
<aftsection>
<nextsent>the strategy of exhaustive parsing has been widely used in grammar development and in parameter training for probabilistic models.
</nextsent>
<nextsent>we tested three of these techniques.
</nextsent>
<nextsent>quick check quick check filters out non-unifiable feature structures (malouf et al, 2000).
</nextsent>
<nextsent>suppose we have two non-unifiable feature structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB62">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> beam thresholding for hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>parsing 4.1 simple beam thresholding.
</prevsent>
<prevsent>many algorithms for improving the efficiency of pcfg parsing have been extensively investigated.
</prevsent>
</prevsection>
<citsent citstr=" J00-1003 ">
they include grammar compilation (tomita, 1986; nederhof, 2000), <papid> J00-1003 </papid>the viterbi algorithm, controlling search strategies without fom such as left-corner parsing (rosenkrantz and lewis ii, 1970) or head corner parsing (kay, 1989; van noord, 1997), and with fom such as the beam search, the best-first search or a* search (chitrao and grishman, 1990;caraballo and charniak, 1998; <papid> J98-2004 </papid>collins, 1999; ratnaparkhi, 1999; charniak, 2000; <papid> A00-2018 </papid>roark, 2001; <papid> J01-2004 </papid>klein and manning, 2003).<papid> N03-1016 </papid></citsent>
<aftsection>
<nextsent>the beam search and best first search algorithms significantly reduce the time required for finding the best parse at the cost of losing the guarantee of finding the correct parse.the cyk algorithm, which is essentially bottom up parser, is natural choice for non-probabilistichpsg parsers.
</nextsent>
<nextsent>many of the constraints are expressed as lexical entries in hpsg, and bottom-up parsers can use those constraints to reduce the search space in the early stages of parsing.for pcfg, extending the cyk algorithm to out put the viterbi parse is straightforward (ney, 1991;jurafsky and martin, 2000).
</nextsent>
<nextsent>the parser can efficiently calculate the viterbi parse by taking the maximum of the probabilities of the same nonterminal symbol in each cell.
</nextsent>
<nextsent>with the probabilistic model defined in section 2, we can also define the viterbi search for unification-based grammars (geman and johnson, 2002).<papid> P02-1036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB63">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> beam thresholding for hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>parsing 4.1 simple beam thresholding.
</prevsent>
<prevsent>many algorithms for improving the efficiency of pcfg parsing have been extensively investigated.
</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
they include grammar compilation (tomita, 1986; nederhof, 2000), <papid> J00-1003 </papid>the viterbi algorithm, controlling search strategies without fom such as left-corner parsing (rosenkrantz and lewis ii, 1970) or head corner parsing (kay, 1989; van noord, 1997), and with fom such as the beam search, the best-first search or a* search (chitrao and grishman, 1990;caraballo and charniak, 1998; <papid> J98-2004 </papid>collins, 1999; ratnaparkhi, 1999; charniak, 2000; <papid> A00-2018 </papid>roark, 2001; <papid> J01-2004 </papid>klein and manning, 2003).<papid> N03-1016 </papid></citsent>
<aftsection>
<nextsent>the beam search and best first search algorithms significantly reduce the time required for finding the best parse at the cost of losing the guarantee of finding the correct parse.the cyk algorithm, which is essentially bottom up parser, is natural choice for non-probabilistichpsg parsers.
</nextsent>
<nextsent>many of the constraints are expressed as lexical entries in hpsg, and bottom-up parsers can use those constraints to reduce the search space in the early stages of parsing.for pcfg, extending the cyk algorithm to out put the viterbi parse is straightforward (ney, 1991;jurafsky and martin, 2000).
</nextsent>
<nextsent>the parser can efficiently calculate the viterbi parse by taking the maximum of the probabilities of the same nonterminal symbol in each cell.
</nextsent>
<nextsent>with the probabilistic model defined in section 2, we can also define the viterbi search for unification-based grammars (geman and johnson, 2002).<papid> P02-1036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB64">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> beam thresholding for hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>parsing 4.1 simple beam thresholding.
</prevsent>
<prevsent>many algorithms for improving the efficiency of pcfg parsing have been extensively investigated.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
they include grammar compilation (tomita, 1986; nederhof, 2000), <papid> J00-1003 </papid>the viterbi algorithm, controlling search strategies without fom such as left-corner parsing (rosenkrantz and lewis ii, 1970) or head corner parsing (kay, 1989; van noord, 1997), and with fom such as the beam search, the best-first search or a* search (chitrao and grishman, 1990;caraballo and charniak, 1998; <papid> J98-2004 </papid>collins, 1999; ratnaparkhi, 1999; charniak, 2000; <papid> A00-2018 </papid>roark, 2001; <papid> J01-2004 </papid>klein and manning, 2003).<papid> N03-1016 </papid></citsent>
<aftsection>
<nextsent>the beam search and best first search algorithms significantly reduce the time required for finding the best parse at the cost of losing the guarantee of finding the correct parse.the cyk algorithm, which is essentially bottom up parser, is natural choice for non-probabilistichpsg parsers.
</nextsent>
<nextsent>many of the constraints are expressed as lexical entries in hpsg, and bottom-up parsers can use those constraints to reduce the search space in the early stages of parsing.for pcfg, extending the cyk algorithm to out put the viterbi parse is straightforward (ney, 1991;jurafsky and martin, 2000).
</nextsent>
<nextsent>the parser can efficiently calculate the viterbi parse by taking the maximum of the probabilities of the same nonterminal symbol in each cell.
</nextsent>
<nextsent>with the probabilistic model defined in section 2, we can also define the viterbi search for unification-based grammars (geman and johnson, 2002).<papid> P02-1036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB65">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> beam thresholding for hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>parsing 4.1 simple beam thresholding.
</prevsent>
<prevsent>many algorithms for improving the efficiency of pcfg parsing have been extensively investigated.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
they include grammar compilation (tomita, 1986; nederhof, 2000), <papid> J00-1003 </papid>the viterbi algorithm, controlling search strategies without fom such as left-corner parsing (rosenkrantz and lewis ii, 1970) or head corner parsing (kay, 1989; van noord, 1997), and with fom such as the beam search, the best-first search or a* search (chitrao and grishman, 1990;caraballo and charniak, 1998; <papid> J98-2004 </papid>collins, 1999; ratnaparkhi, 1999; charniak, 2000; <papid> A00-2018 </papid>roark, 2001; <papid> J01-2004 </papid>klein and manning, 2003).<papid> N03-1016 </papid></citsent>
<aftsection>
<nextsent>the beam search and best first search algorithms significantly reduce the time required for finding the best parse at the cost of losing the guarantee of finding the correct parse.the cyk algorithm, which is essentially bottom up parser, is natural choice for non-probabilistichpsg parsers.
</nextsent>
<nextsent>many of the constraints are expressed as lexical entries in hpsg, and bottom-up parsers can use those constraints to reduce the search space in the early stages of parsing.for pcfg, extending the cyk algorithm to out put the viterbi parse is straightforward (ney, 1991;jurafsky and martin, 2000).
</nextsent>
<nextsent>the parser can efficiently calculate the viterbi parse by taking the maximum of the probabilities of the same nonterminal symbol in each cell.
</nextsent>
<nextsent>with the probabilistic model defined in section 2, we can also define the viterbi search for unification-based grammars (geman and johnson, 2002).<papid> P02-1036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB66">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> beam thresholding for hpsg.  </section>
<citcontext>
<prevsection>
<prevsent>parsing 4.1 simple beam thresholding.
</prevsent>
<prevsent>many algorithms for improving the efficiency of pcfg parsing have been extensively investigated.
</prevsent>
</prevsection>
<citsent citstr=" N03-1016 ">
they include grammar compilation (tomita, 1986; nederhof, 2000), <papid> J00-1003 </papid>the viterbi algorithm, controlling search strategies without fom such as left-corner parsing (rosenkrantz and lewis ii, 1970) or head corner parsing (kay, 1989; van noord, 1997), and with fom such as the beam search, the best-first search or a* search (chitrao and grishman, 1990;caraballo and charniak, 1998; <papid> J98-2004 </papid>collins, 1999; ratnaparkhi, 1999; charniak, 2000; <papid> A00-2018 </papid>roark, 2001; <papid> J01-2004 </papid>klein and manning, 2003).<papid> N03-1016 </papid></citsent>
<aftsection>
<nextsent>the beam search and best first search algorithms significantly reduce the time required for finding the best parse at the cost of losing the guarantee of finding the correct parse.the cyk algorithm, which is essentially bottom up parser, is natural choice for non-probabilistichpsg parsers.
</nextsent>
<nextsent>many of the constraints are expressed as lexical entries in hpsg, and bottom-up parsers can use those constraints to reduce the search space in the early stages of parsing.for pcfg, extending the cyk algorithm to out put the viterbi parse is straightforward (ney, 1991;jurafsky and martin, 2000).
</nextsent>
<nextsent>the parser can efficiently calculate the viterbi parse by taking the maximum of the probabilities of the same nonterminal symbol in each cell.
</nextsent>
<nextsent>with the probabilistic model defined in section 2, we can also define the viterbi search for unification-based grammars (geman and johnson, 2002).<papid> P02-1036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB75">
<title id=" W05-1511.xml">efficacy of beam thresholding unification filtering and hybrid parsing in probabilistic hpsg parsing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>a predicate-argument relation is defined as tuple??,wh, a, wa?, where ? is the predicate type (e.g., adjective, in transitive verb), wh is the head word of the predicate, is the argument label (modarg, arg1,..., arg4), and wa is the head word of the argument.
</prevsent>
<prevsent>precision/recall is the ratio of tuples correctly identified by the parser.
</prevsent>
</prevsection>
<citsent citstr=" P03-1046 ">
this evaluation scheme wasthe same as used in previous evaluations of lexicalized grammars (hockenmaier, 2003; <papid> P03-1046 </papid>clark and curran, 2004; <papid> P04-1014 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>the experiments were conducted on an amd opteron server with 2.4-ghz cpu.
</nextsent>
<nextsent>section 22 of the treebank was usedas the development set, and performance was evaluated using sentences of less than 40 words in section23 (2,164 sentences, 20.3 words/sentence).
</nextsent>
<nextsent>the performance of each parsing technique was analyzed using the sentences in section 24 of less than 15 words(305 sentences) and less than 40 words (1145 sen tences).
</nextsent>
<nextsent>table 2 shows the parsing performance using all 110
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB80">
<title id=" W06-0701.xml">dimensionality reduction aids term cooccurrence based multi document summarization </title>
<section> svd in summarisation.  </section>
<citcontext>
<prevsection>
<prevsent>their solution is to assign each sentence an svd-based score using: scsv di = ? ?
</prevsent>
<prevsent>n? i=1 v(i, k)2 ? ?(k)2 ,where v(i, k) is the kth element of the ith sentence vector and ?(k) is the corresponding singular value.
</prevsent>
</prevsection>
<citsent citstr=" W05-0905 ">
murray et al (2005<papid> W05-0905 </papid>a) address the same concerns but retain the gong and liu framework.</citsent>
<aftsection>
<nextsent>rather than extracting the best sentence for each topic,the best sentences are extracted, with determined by the corresponding singular values from 2 matrix s. thus, dimensionality reduction is no longer tied to summary length and more than one sentence per topic can be chosen.
</nextsent>
<nextsent>a similar approach in duc 2005 using term co-occurrence models and svd was presented by jagarlamudi et al (2005).
</nextsent>
<nextsent>their system performs svd over term ? sentence matrix and combinesa relevance measurement based on this representation with relevance based on term co-occurrence model by weighted linear combination.
</nextsent>
<nextsent>3.2 sentence selection in embra.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB82">
<title id=" W06-0701.xml">dimensionality reduction aids term cooccurrence based multi document summarization </title>
<section> svd in summarisation.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 sentence selection in embra.
</prevsent>
<prevsent>the embra system developed for duc 2005 attempts to derive more robust representations of sentences by building large semantic space using svd on very large corpus.
</prevsent>
</prevsection>
<citsent citstr=" P05-1018 ">
while researcher shave used such large semantic spaces to aid in automatically judging the coherence of documents (foltz et al, 1998; barzilay and lapata, 2005), <papid> P05-1018 </papid>toour knowledge this is novel technique in sum marisation.</citsent>
<aftsection>
<nextsent>using concatenation of aquaint and duc 2005 data (100+ million words), we utilised the infomap tool4 to build semantic model based on singular value decomposition (svd).
</nextsent>
<nextsent>the decomposition and projection of the matrix to lower dimensionality space results in semantic model based on underlying term relations.
</nextsent>
<nextsent>in the current experiments, we set dimension of the reduced representation to 100.
</nextsent>
<nextsent>this is reduction of 90% from the full dimensionality of 1000 content-bearing terms in the original ds matrix.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB84">
<title id=" W06-0701.xml">dimensionality reduction aids term cooccurrence based multi document summarization </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we also use the statistical combined part of-speech (pos) tagger and sentence boundary disambiguation module from lt ttt (mikheev, 5http://www-nlpir.nist.gov/projects/ duc/duc2005/tasks.html 3 1997).
</prevsent>
<prevsent>using these tools, we produce an xml markup with sentence and word elements.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
further linguistic markup is added using the morpha lem matiser (minnen et al, 2000) <papid> W00-1427 </papid>and the c&c; named entity tagger (curran and clark, 2003) <papid> W03-0424 </papid>trained on the data from muc-7.</citsent>
<aftsection>
<nextsent>4.2 methods.
</nextsent>
<nextsent>the different system configurations (ds, ds+svd, tf.idf) were evaluated against the human upper bound and baseline using rouge-2 and rouge-su4.
</nextsent>
<nextsent>rouge estimates the coverage of appropriate concepts (lin and hovy, 2003) <papid> N03-1020 </papid>in summary by comparing it several human-created reference summaries.</nextsent>
<nextsent>rouge-2 does so by computing precision and recall based on macro-averaged bigram overlap.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB85">
<title id=" W06-0701.xml">dimensionality reduction aids term cooccurrence based multi document summarization </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we also use the statistical combined part of-speech (pos) tagger and sentence boundary disambiguation module from lt ttt (mikheev, 5http://www-nlpir.nist.gov/projects/ duc/duc2005/tasks.html 3 1997).
</prevsent>
<prevsent>using these tools, we produce an xml markup with sentence and word elements.
</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
further linguistic markup is added using the morpha lem matiser (minnen et al, 2000) <papid> W00-1427 </papid>and the c&c; named entity tagger (curran and clark, 2003) <papid> W03-0424 </papid>trained on the data from muc-7.</citsent>
<aftsection>
<nextsent>4.2 methods.
</nextsent>
<nextsent>the different system configurations (ds, ds+svd, tf.idf) were evaluated against the human upper bound and baseline using rouge-2 and rouge-su4.
</nextsent>
<nextsent>rouge estimates the coverage of appropriate concepts (lin and hovy, 2003) <papid> N03-1020 </papid>in summary by comparing it several human-created reference summaries.</nextsent>
<nextsent>rouge-2 does so by computing precision and recall based on macro-averaged bigram overlap.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB86">
<title id=" W06-0701.xml">dimensionality reduction aids term cooccurrence based multi document summarization </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 methods.
</prevsent>
<prevsent>the different system configurations (ds, ds+svd, tf.idf) were evaluated against the human upper bound and baseline using rouge-2 and rouge-su4.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
rouge estimates the coverage of appropriate concepts (lin and hovy, 2003) <papid> N03-1020 </papid>in summary by comparing it several human-created reference summaries.</citsent>
<aftsection>
<nextsent>rouge-2 does so by computing precision and recall based on macro-averaged bigram overlap.
</nextsent>
<nextsent>rouge-su4 allows bigrams to be composed of non-contiguous words, with as many as four words intervening.
</nextsent>
<nextsent>we use the same configuration as the official duc 2005 evaluation,6 which is based on word stems (rather than full forms) and uses jackknifing (k1 cross-evaluation) so that human gold-standard and automatic system summaries can be compared.
</nextsent>
<nextsent>the independent variable in the experiment isthe model of sentence semantics used by the sentence selection algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB89">
<title id=" W06-0701.xml">dimensionality reduction aids term cooccurrence based multi document summarization </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>this will be explored by running the experiment described in this paper number of times using corpora of different sizes (e.g. 0.5m, 1m, 10m and 100m words).
</prevsent>
<prevsent>unlike official duc evaluations, which rely onhuman judgements of readability and informative ness, our experiments rely solely on rouge gram evaluation metrics.
</prevsent>
</prevsection>
<citsent citstr=" N06-1047 ">
it has been shown in duc 2005 and in work by murray et al (2005<papid> W05-0905 </papid>b), murray et al (2006) <papid> N06-1047 </papid>that rouge does not always correlate well with human evaluations, though there is more stability when examining the correlations of macro averaged scores.</citsent>
<aftsection>
<nextsent>rouge suffers from lack ofpower to discriminate between systems whose performance is judged to differ by human annotators.
</nextsent>
<nextsent>thus, it is likely that future human evaluations would be more informative.
</nextsent>
<nextsent>another way that the evaluation issue might be addressed is by using an annotated sentence extraction corpus.
</nextsent>
<nextsent>this could proceed by comparing gold standard alignments between abstract and full document sentences with predicted alignments using correlation analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB90">
<title id=" W05-1304.xml">a machine learning approach to acronym generation </title>
<section> acronym generation as sequence.  </section>
<citcontext>
<prevsection>
<prevsent>!  #   ff  fi
</prevsent>
<prevsent>$fl    (3) if we have the training data containing large number of definition-acronym pairs where the definition is annotated with the labels for actions, we can estimate the parameters of this probabilistic mod eland the best action sequence can be efficiently computed by using viterbi decoding algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in this paper we adopt maximum entropy model(berger et al, 1996) <papid> J96-1002 </papid>to estimate the local probabilities fi </citsent>
<aftsection>
<nextsent>ffifl   since it can incorporate diverse types of features with reasonable computational cost.
</nextsent>
<nextsent>this modeling, as whole, is called maximum entropy markov modeling (memm).
</nextsent>
<nextsent>26 lower lower lower lower lower hyphen upper skip skip skip upper skip skip skip skip upper skip skip skip lower upper actions mm mm aa r nn gg aa ii t r ff uu c dd acronym definition figure 1: acronym generation as sequence labeling problem.
</nextsent>
<nextsent>the definition is duck interferon gamma?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB91">
<title id=" W05-1304.xml">a machine learning approach to acronym generation </title>
<section> acronym generation as sequence.  </section>
<citcontext>
<prevsection>
<prevsent>each letter in the acronym is generated from letter in the definition following the action for the letter.
</prevsent>
<prevsent>regularization is important in maximum entropy modeling to avoid over fitting to the training data.
</prevsent>
</prevsection>
<citsent citstr=" W03-1018 ">
for this purpose, we use the maximum entropy modeling with inequality constraints (kazama andtsujii, 2003).<papid> W03-1018 </papid></citsent>
<aftsection>
<nextsent>the model gives equally good performance as the maximum entropy modeling with gaussian priors (chen and rosenfeld, 1999), and the size of the resulting model is much smaller than that of gaussian priors because most of the parameters become zero.
</nextsent>
<nextsent>this characteristic enables us to easily handle the model data and carry out quick decoding, which is convenient when we repetitively perform experiments.
</nextsent>
<nextsent>this modeling has one parameter to tune, which is called width factor.
</nextsent>
<nextsent>we set this parameter to be 1.0 throughout the experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB92">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in machine translation, intuitively, the informative content words should be emphasized more for better adequacy of the translation quality.
</prevsent>
<prevsent>however, the standard statistical translation approach does not take account how informative and thereby, how important word is, in its translation model.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
one reason is the difficulty to measure how informative word is. another problem is to integrate it naturally into the existing statistical machine translation framework, which typically is built on word alignment models, like the well-known ibm alignment models (brown et al 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in recent years there has been strong tendency to incorporate phrasal translation into statistical machine translation.
</nextsent>
<nextsent>it directly translates an n-gram from the source language into an gram in the target language.
</nextsent>
<nextsent>the advantages are obvious: it has built-in local context modeling, and provides reliable local word reordering.
</nextsent>
<nextsent>it has multi-word translations, and models words conditional fertility given local context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB93">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it captures idiomatic phrase translations and can be easily enriched with bilingual dictionaries.
</prevsent>
<prevsent>in addition, it can compensate for the segmentation errors made during preprocessing, i.e. word segmentation errors of chinese.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the advantage of using phrase-based translation in statistical framework has been shown in many studies such as (koehn et al  2003; <papid> N03-1017 </papid>vogel et al  2003; zens et al . 2002; marcu and wong, 2002).<papid> W02-1018 </papid></citsent>
<aftsection>
<nextsent>however, the phrase translation pairs are typically extracted from parallel corpus based on the viterbi alignment of some word alignment models.
</nextsent>
<nextsent>the leads to the question what probability should be assigned to those phrase translations.
</nextsent>
<nextsent>different approaches have been suggested as using relative frequencies (zens et al  2002), calculate probabilities based on statistical word-to-word dictionary (vogel et al  2003) or use linear interpolation of these scores (koehn et al  2003).<papid> N03-1017 </papid></nextsent>
<nextsent>in this paper we investigate different approach with takes the information content of words better into account.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB94">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it captures idiomatic phrase translations and can be easily enriched with bilingual dictionaries.
</prevsent>
<prevsent>in addition, it can compensate for the segmentation errors made during preprocessing, i.e. word segmentation errors of chinese.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
the advantage of using phrase-based translation in statistical framework has been shown in many studies such as (koehn et al  2003; <papid> N03-1017 </papid>vogel et al  2003; zens et al . 2002; marcu and wong, 2002).<papid> W02-1018 </papid></citsent>
<aftsection>
<nextsent>however, the phrase translation pairs are typically extracted from parallel corpus based on the viterbi alignment of some word alignment models.
</nextsent>
<nextsent>the leads to the question what probability should be assigned to those phrase translations.
</nextsent>
<nextsent>different approaches have been suggested as using relative frequencies (zens et al  2002), calculate probabilities based on statistical word-to-word dictionary (vogel et al  2003) or use linear interpolation of these scores (koehn et al  2003).<papid> N03-1017 </papid></nextsent>
<nextsent>in this paper we investigate different approach with takes the information content of words better into account.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB97">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> phrase-based machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the phrase-based statistical translation systems use not only word-to-word translation, extracted from bilingual data, but also phrase-to phrase translations.
</prevsent>
<prevsent>different types of extraction approaches have been described in the literature: syntax-based, word-alignment-based, and genuine phrase alignment models.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the syntax-based approach has the advantage to model the grammar structures using models of more or less structural richness, such as the syntax-based alignment model in (yamada and knight, 2001) <papid> P01-1067 </papid>or the bilingual bracketing in (wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>popular word-alignment-based approaches usually relyon initial word alignments from the ibm and hmm alignment models (och and ney, 2000), <papid> P00-1056 </papid>from which the phrase pairs are then extracted.</nextsent>
<nextsent>(marcu and wong 2002) <papid> W02-1018 </papid>and (zhang et al  2003) do not relyon word alignment but model directly the phrase alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB98">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> phrase-based machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the phrase-based statistical translation systems use not only word-to-word translation, extracted from bilingual data, but also phrase-to phrase translations.
</prevsent>
<prevsent>different types of extraction approaches have been described in the literature: syntax-based, word-alignment-based, and genuine phrase alignment models.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the syntax-based approach has the advantage to model the grammar structures using models of more or less structural richness, such as the syntax-based alignment model in (yamada and knight, 2001) <papid> P01-1067 </papid>or the bilingual bracketing in (wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>popular word-alignment-based approaches usually relyon initial word alignments from the ibm and hmm alignment models (och and ney, 2000), <papid> P00-1056 </papid>from which the phrase pairs are then extracted.</nextsent>
<nextsent>(marcu and wong 2002) <papid> W02-1018 </papid>and (zhang et al  2003) do not relyon word alignment but model directly the phrase alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB99">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> phrase-based machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>different types of extraction approaches have been described in the literature: syntax-based, word-alignment-based, and genuine phrase alignment models.
</prevsent>
<prevsent>the syntax-based approach has the advantage to model the grammar structures using models of more or less structural richness, such as the syntax-based alignment model in (yamada and knight, 2001) <papid> P01-1067 </papid>or the bilingual bracketing in (wu, 1997).<papid> J97-3002 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
popular word-alignment-based approaches usually relyon initial word alignments from the ibm and hmm alignment models (och and ney, 2000), <papid> P00-1056 </papid>from which the phrase pairs are then extracted.</citsent>
<aftsection>
<nextsent>(marcu and wong 2002) <papid> W02-1018 </papid>and (zhang et al  2003) do not relyon word alignment but model directly the phrase alignment.</nextsent>
<nextsent>because all statistical machine translation systems search for globally optimal translation using the language and translation model, translation probability has to be assigned to each phrase translation pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB102">
<title id=" W04-3227.xml">phrase pair rescoring with term weighting for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>second, large monolingual english corpus was used to filter out the new word forms.
</prevsent>
<prevsent>if they did not appear in the corpus, the new entries were not added to the transducer (vogel, 2004).
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
bibr extracts sub-tree mappings from bilingual bracketing alignments (wu, 1997); <papid> J97-3002 </papid>hmm extracts partial path mappings from the viterbi path in the hidden markov model alignments (vogel et. al., 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>isa is an integrated segmentation and alignment for phrases (zhang et.al, 2003), which is an extension of (marcu and wong, 2002).<papid> W02-1018 </papid></nextsent>
<nextsent>ldc bibr hmm isa )(kn 425k 137k 349k 263k )/( srctgt llavg 1.80 1.11 1.09 1.20 table-1 statistics of transducers table-1 shows some statistics of the four transducers extracted for the translation task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB105">
<title id=" W06-1008.xml">a fast and accurate method for detecting english japanese parallel texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is pair of texts which is written in different languages and is translation of each other.
</prevsent>
<prevsent>a compilation of parallel texts offered in aserviceable form is called parallel corpus?.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
parallel corpora are very valuable resources in various fields of multilingual natural language processing such as statistical machine translation (brown et al., 1990), <papid> J90-2002 </papid>cross-lingual ir (chen and nie, 2000), <papid> A00-1004 </papid>and construction of dictionary (nagao, 1996).however, it is generally difficult to obtain parallel corpora of enough quantity and quality.</citsent>
<aftsection>
<nextsent>there have only been few varieties of parallel corpora.in addition, their languages have been biased toward english french and their contents toward official documents of governmental institutions or software manuals.
</nextsent>
<nextsent>therefore, it is often difficult to find parallel corpus that meets the needs of specific researches.
</nextsent>
<nextsent>to solve this problem, approaches to collect parallel texts from the web have been proposed.
</nextsent>
<nextsent>in the web space, all sorts of languages are used though english is dominating, and the content of the texts seems to be as diverse as all activities of the human-beings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB106">
<title id=" W06-1008.xml">a fast and accurate method for detecting english japanese parallel texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is pair of texts which is written in different languages and is translation of each other.
</prevsent>
<prevsent>a compilation of parallel texts offered in aserviceable form is called parallel corpus?.
</prevsent>
</prevsection>
<citsent citstr=" A00-1004 ">
parallel corpora are very valuable resources in various fields of multilingual natural language processing such as statistical machine translation (brown et al., 1990), <papid> J90-2002 </papid>cross-lingual ir (chen and nie, 2000), <papid> A00-1004 </papid>and construction of dictionary (nagao, 1996).however, it is generally difficult to obtain parallel corpora of enough quantity and quality.</citsent>
<aftsection>
<nextsent>there have only been few varieties of parallel corpora.in addition, their languages have been biased toward english french and their contents toward official documents of governmental institutions or software manuals.
</nextsent>
<nextsent>therefore, it is often difficult to find parallel corpus that meets the needs of specific researches.
</nextsent>
<nextsent>to solve this problem, approaches to collect parallel texts from the web have been proposed.
</nextsent>
<nextsent>in the web space, all sorts of languages are used though english is dominating, and the content of the texts seems to be as diverse as all activities of the human-beings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB107">
<title id=" W06-1008.xml">a fast and accurate method for detecting english japanese parallel texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>if we simply make dicision for all pairs in collection of texts, the calculation takes ?(n2) comparisons of text pairs where is the number of documents in the collection.
</prevsent>
<prevsent>in fact, most researches utilize properties peculiar to certain parallel web pages to reduce the number of candidate pairs in advance.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
resnik and smith focused on thefact that page pair tends to be mutual translation when their url strings meet certain condition, and examined only page pairs which satisfy it (resnik and smith, 2003).<papid> J03-3002 </papid></citsent>
<aftsection>
<nextsent>a url string sometimes contains substring which indicates the language in which the page is written.
</nextsent>
<nextsent>for example, webpage written in japanese sometimes have substring such as j, jp, jpn, n, euc or sjis in its url.
</nextsent>
<nextsent>they regard pair of pages as candidate when their urls match completely after removing such language-specific sub strings and, only for these candidates, did they make detailed comparison with bilingual dictionary.
</nextsent>
<nextsent>they were successful in collecting 2190 parallel pairs from 8294 candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB108">
<title id=" W06-0131.xml">pocnlw template for chinese word segmentation </title>
<section> the basic word segmentation stage.  </section>
<citcontext>
<prevsection>
<prevsent>in the first stage, the basic word segmentation is accomplished.
</prevsent>
<prevsent>the key issue in this stage is the ambiguity problem, which is mainly caused by the fact that chinese character can occur in different word internal positions in different words (xue, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W03-1723 ">
a lot of machine learning techniques have been applied to resolve this problem, the n-gram language model is one of the most popular ones among them (fu and luke, 2003; <papid> W03-1723 </papid>li et al, 2005).<papid> I05-3022 </papid></citsent>
<aftsection>
<nextsent>as such, we also employed gram model in this stage.
</nextsent>
<nextsent>when sentence is inputted, it is first segmented into sequence of individual characters (e.g. ascii strings, basic chinese characters, punitions, numerals and so on), marked as c1,n. according to the systems dictionary, several word sequences w1,m will be constructed as candidates.
</nextsent>
<nextsent>the function of the n-gram model is to find out the best word sequence w* corresponds to c1,n, which has the maximum integrated probability, i.e., trigramforwwwp bigramforwwp cwpw i iii m ii nm m m ? ?
</nextsent>
<nextsent>= 1 21 1 1 ,1,1 * ),|(maxarg )|(maxarg )|(maxarg ,1 ,1 ,1 177 the maximum likelihood method was used to estimate the word n-gram probabilities used in our model, and the linear interpolation method (jelinek and mercer, 1980) was applied to smooth these estimated probabilities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB109">
<title id=" W06-0131.xml">pocnlw template for chinese word segmentation </title>
<section> the basic word segmentation stage.  </section>
<citcontext>
<prevsection>
<prevsent>in the first stage, the basic word segmentation is accomplished.
</prevsent>
<prevsent>the key issue in this stage is the ambiguity problem, which is mainly caused by the fact that chinese character can occur in different word internal positions in different words (xue, 2003).
</prevsent>
</prevsection>
<citsent citstr=" I05-3022 ">
a lot of machine learning techniques have been applied to resolve this problem, the n-gram language model is one of the most popular ones among them (fu and luke, 2003; <papid> W03-1723 </papid>li et al, 2005).<papid> I05-3022 </papid></citsent>
<aftsection>
<nextsent>as such, we also employed gram model in this stage.
</nextsent>
<nextsent>when sentence is inputted, it is first segmented into sequence of individual characters (e.g. ascii strings, basic chinese characters, punitions, numerals and so on), marked as c1,n. according to the systems dictionary, several word sequences w1,m will be constructed as candidates.
</nextsent>
<nextsent>the function of the n-gram model is to find out the best word sequence w* corresponds to c1,n, which has the maximum integrated probability, i.e., trigramforwwwp bigramforwwp cwpw i iii m ii nm m m ? ?
</nextsent>
<nextsent>= 1 21 1 1 ,1,1 * ),|(maxarg )|(maxarg )|(maxarg ,1 ,1 ,1 177 the maximum likelihood method was used to estimate the word n-gram probabilities used in our model, and the linear interpolation method (jelinek and mercer, 1980) was applied to smooth these estimated probabilities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB110">
<title id=" W06-0131.xml">pocnlw template for chinese word segmentation </title>
<section> the oov word identification stage.  </section>
<citcontext>
<prevsection>
<prevsent>the n-gram method is based on the exiting grams in the model, so it is good at judging the connecting relationship among known words, but does not have the ability to deal with unknown words in substance.
</prevsent>
<prevsent>therefore, another oov word identification model is required.
</prevsent>
</prevsection>
<citsent citstr=" W00-1207 ">
oov words are regarded as words that do not exist in systems machine-readable dictionary, and more detailed definition can be found in (wu and jiang, 2000).<papid> W00-1207 </papid></citsent>
<aftsection>
<nextsent>in general, chinese word can be created through compounding or abbrevi ating of most of existing characters and words.
</nextsent>
<nextsent>thus, the key to solve the oov word identification lies on whether the new word creation mechanisms in chinese language can be extracted.
</nextsent>
<nextsent>therefore, poc-nlw language tagging template is introduced to explore such information on the character-level within words.
</nextsent>
<nextsent>3.1 the poc-nlw template.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB114">
<title id=" W06-0131.xml">pocnlw template for chinese word segmentation </title>
<section> the oov word identification stage.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 the hmm tagger.
</prevsent>
<prevsent>form the description of poc-nlw template, it can be found that the word segmentation could be implemented as poc-nlw tagging, which is similar to the so-called part-of-speech (pos) tagging problem.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
in pos tagging, hidden markov model (hmm) was applied as one of the most significant methods, as described in detail in (brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>the hmm method can achieve high accuracy in tagging with low processing costs, so it was adopted in our model.
</nextsent>
<nextsent>according to the definition of poc-nlw template, the state set of hmm corresponds to the wl-pn tag set, and the symbol set is composed of all characters.
</nextsent>
<nextsent>however, the initial state probability matrix and the state transition probability matrix are not composed of all of the tags in the state set.
</nextsent>
<nextsent>to express more clearly, we define two subset of the state set: ? begin tag set (bts): this set is consisted of tag which can occur in the begging position in word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB115">
<title id=" W04-3101.xml">a resource for constructing customized test suites for molecular biology entity identification systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in hirschman and manis taxonomy of evaluation techniques, our methodology is referred to as feature-based, in that it is based on the principle of classifying the inputs to the system in terms of some set of features that are relevant to the application of interest.
</prevsent>
<prevsent>it is designed to provide the developer or user with detailed information about the performance of her ei system.
</prevsent>
</prevsection>
<citsent citstr=" W02-0302 ">
we apply it to five molecular biology ei and information extraction systems: abgene (tanabe and wilbur 2002<papid> W02-0302 </papid>a, tanabe and wilbur 2002<papid> W02-0302 </papid>b); kex/proper (fukuda et al  1997); yapex (franzn et al  2002); the stochastic pos tagging-based system described in cohen et al  (in submission); and the entity identification component of ono et al information extraction system (ono et al  2001), and show how it gives detailed useful information about each that is not apparent from the standard metrics and that is not documented in the cited publications.</citsent>
<aftsection>
<nextsent>(since we are not interested in punishing system developers for graciously making their work available by pointing out their flaws, we do not refer to the various systems by name in the remainder of this paper.)
</nextsent>
<nextsent>software testing techniques can be grouped into structured (beizer 1990), heuristic (kaner et al  2002), and random categories.
</nextsent>
<nextsent>testing an ei system by running it on corpus of texts and calculating precision, recall, and f-score for the results falls into the category of random testing.
</nextsent>
<nextsent>random testing is powerful technique, in that it is successful in finding bugs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB119">
<title id=" W04-3101.xml">a resource for constructing customized test suites for molecular biology entity identification systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, if the raw data file contains the sentence acox2 polymorphisms may be correlated with an increased risk of larynx cancer, then the gold standard file will contain the corresponding sentence  gp acox2 /gp  polymorphisms may be correlated with an increased risk of larynx cancer.
</prevsent>
<prevsent>not all users will necessarily agree on what counts as the right?
</prevsent>
</prevsection>
<citsent citstr=" C02-1110 ">
gold standard see olsson et al  (2002) <papid> C02-1110 </papid>and the bio creative site for some of the issues.</citsent>
<aftsection>
<nextsent>users can enforce their own notions of correctness by using our data as input to their own generation code, or by post-processing the output of our applications.
</nextsent>
<nextsent>id: 136 name_vs_symbol: length: 3 case: contains_a_numeral: contains_arabic_numeral: arabic_numeral_position: contains_roman_numeral:  several typographic features omitted  contains_punctuation: 1 contains_hyphen: 1 contains_forward_slash:  several punctuation-related features omitted  contains_function_word: function_word_position: contains_past_participle: 1 past_participle_position: contains_present_participle: present_participle_position: source_authority: hgnc id: 2681  approved gene name  field original_form_in_source: death-associated protein 6 data: death-associated protein 6 figure 1 representative entry from the entity data file.
</nextsent>
<nextsent>a number of null-valued features are omitted for brevity see the full entry at the supplemental web site.
</nextsent>
<nextsent>the data field (last line of the figure) is what is output by the generation software.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB121">
<title id=" W06-0303.xml">a system for summarizing and visualizing arguments in subjective documents toward supporting decisionmaking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for process (1) in section 1, existing search engines can be used to search the web for documents related to specific topic.
</prevsent>
<prevsent>however, not all retrieved documents include subjective descriptions for the topic.
</prevsent>
</prevsection>
<citsent citstr=" C04-1200 ">
a solution to this problem is to automatically identify diaries and blogs (nanno et al, 2004),which usually include opinionated subjective de scriptions.for process (2), existing methods aim to distinguish between subjective and objective descriptions in texts (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2004; <papid> P04-1035 </papid>riloff and wiebe, 2003).<papid> W03-1014 </papid></citsent>
<aftsection>
<nextsent>for process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (dave et al, 2003; beineke et al, 2004; <papid> P04-1034 </papid>hu and liu, 2004; pang and lee, 2004) <papid> P04-1035 </papid>or multipoint scale categories (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2005).<papid> P05-1015 </papid>for process (4), which is the subject of this paper, ku et al (2005) selected documents that include large number of positive or negative sentences about target topic, and used their headlines as summary of the topic.</nextsent>
<nextsent>this is the application of an existing extraction-based summarization method to subjective descriptions.hu and liu (2004) summarized customer reviews of product such as digital camera.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB123">
<title id=" W06-0303.xml">a system for summarizing and visualizing arguments in subjective documents toward supporting decisionmaking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for process (1) in section 1, existing search engines can be used to search the web for documents related to specific topic.
</prevsent>
<prevsent>however, not all retrieved documents include subjective descriptions for the topic.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
a solution to this problem is to automatically identify diaries and blogs (nanno et al, 2004),which usually include opinionated subjective de scriptions.for process (2), existing methods aim to distinguish between subjective and objective descriptions in texts (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2004; <papid> P04-1035 </papid>riloff and wiebe, 2003).<papid> W03-1014 </papid></citsent>
<aftsection>
<nextsent>for process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (dave et al, 2003; beineke et al, 2004; <papid> P04-1034 </papid>hu and liu, 2004; pang and lee, 2004) <papid> P04-1035 </papid>or multipoint scale categories (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2005).<papid> P05-1015 </papid>for process (4), which is the subject of this paper, ku et al (2005) selected documents that include large number of positive or negative sentences about target topic, and used their headlines as summary of the topic.</nextsent>
<nextsent>this is the application of an existing extraction-based summarization method to subjective descriptions.hu and liu (2004) summarized customer reviews of product such as digital camera.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB124">
<title id=" W06-0303.xml">a system for summarizing and visualizing arguments in subjective documents toward supporting decisionmaking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for process (1) in section 1, existing search engines can be used to search the web for documents related to specific topic.
</prevsent>
<prevsent>however, not all retrieved documents include subjective descriptions for the topic.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
a solution to this problem is to automatically identify diaries and blogs (nanno et al, 2004),which usually include opinionated subjective de scriptions.for process (2), existing methods aim to distinguish between subjective and objective descriptions in texts (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2004; <papid> P04-1035 </papid>riloff and wiebe, 2003).<papid> W03-1014 </papid></citsent>
<aftsection>
<nextsent>for process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (dave et al, 2003; beineke et al, 2004; <papid> P04-1034 </papid>hu and liu, 2004; pang and lee, 2004) <papid> P04-1035 </papid>or multipoint scale categories (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2005).<papid> P05-1015 </papid>for process (4), which is the subject of this paper, ku et al (2005) selected documents that include large number of positive or negative sentences about target topic, and used their headlines as summary of the topic.</nextsent>
<nextsent>this is the application of an existing extraction-based summarization method to subjective descriptions.hu and liu (2004) summarized customer reviews of product such as digital camera.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB125">
<title id=" W06-0303.xml">a system for summarizing and visualizing arguments in subjective documents toward supporting decisionmaking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, not all retrieved documents include subjective descriptions for the topic.
</prevsent>
<prevsent>a solution to this problem is to automatically identify diaries and blogs (nanno et al, 2004),which usually include opinionated subjective de scriptions.for process (2), existing methods aim to distinguish between subjective and objective descriptions in texts (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2004; <papid> P04-1035 </papid>riloff and wiebe, 2003).<papid> W03-1014 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1034 ">
for process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (dave et al, 2003; beineke et al, 2004; <papid> P04-1034 </papid>hu and liu, 2004; pang and lee, 2004) <papid> P04-1035 </papid>or multipoint scale categories (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2005).<papid> P05-1015 </papid>for process (4), which is the subject of this paper, ku et al (2005) selected documents that include large number of positive or negative sentences about target topic, and used their headlines as summary of the topic.</citsent>
<aftsection>
<nextsent>this is the application of an existing extraction-based summarization method to subjective descriptions.hu and liu (2004) summarized customer reviews of product such as digital camera.
</nextsent>
<nextsent>their summarization method extracts nouns and noun phrases as features of the target product, (e.g., picture?
</nextsent>
<nextsent>for digital camera), and lists positive and negative reviews on feature-by-feature basis.
</nextsent>
<nextsent>the extracted features are sorted according to the frequency with which each feature appears in the reviews.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB129">
<title id=" W06-0303.xml">a system for summarizing and visualizing arguments in subjective documents toward supporting decisionmaking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, not all retrieved documents include subjective descriptions for the topic.
</prevsent>
<prevsent>a solution to this problem is to automatically identify diaries and blogs (nanno et al, 2004),which usually include opinionated subjective de scriptions.for process (2), existing methods aim to distinguish between subjective and objective descriptions in texts (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2004; <papid> P04-1035 </papid>riloff and wiebe, 2003).<papid> W03-1014 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1015 ">
for process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (dave et al, 2003; beineke et al, 2004; <papid> P04-1034 </papid>hu and liu, 2004; pang and lee, 2004) <papid> P04-1035 </papid>or multipoint scale categories (kim and hovy, 2004; <papid> C04-1200 </papid>pang and lee, 2005).<papid> P05-1015 </papid>for process (4), which is the subject of this paper, ku et al (2005) selected documents that include large number of positive or negative sentences about target topic, and used their headlines as summary of the topic.</citsent>
<aftsection>
<nextsent>this is the application of an existing extraction-based summarization method to subjective descriptions.hu and liu (2004) summarized customer reviews of product such as digital camera.
</nextsent>
<nextsent>their summarization method extracts nouns and noun phrases as features of the target product, (e.g., picture?
</nextsent>
<nextsent>for digital camera), and lists positive and negative reviews on feature-by-feature basis.
</nextsent>
<nextsent>the extracted features are sorted according to the frequency with which each feature appears in the reviews.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB130">
<title id=" W06-1311.xml">semantic tagging for resolution of indirect anaphora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are many problems in developing such studies.
</prevsent>
<prevsent>first, bridging is not regular class, it seldom contains cases of associative and indirect anaphora (defined in the sequence);lexical resources such as wordnet are not available for every language, and even when available such resources have proven to be insufficient forthe problem.
</prevsent>
</prevsection>
<citsent citstr=" J05-3004 ">
in fact, different sources of lexical knowledge have been evaluated for anaphora resolution (poesio et al, 2002; markert and nissim, 2005; <papid> J05-3004 </papid>bunescu, 2003).</citsent>
<aftsection>
<nextsent>at last, corpus studies of bridging anaphora usually report results on reduced number of examples, because this kind of data is scarce.
</nextsent>
<nextsent>usually bridging anaphora considers two types: associative anaphors are nps that have an antecedent that is necessary to their interpretation (the relation between theanaphor and its antecedent is different from iden tity); and indirect anaphor are those that have an identity relation with their antecedents but theanaphor and its antecedent have different head nouns.
</nextsent>
<nextsent>in both associative and indirect anaphora, the semantic relation holding between the anaphora nd its antecedent play an essential role for resolution.
</nextsent>
<nextsent>however, here we present an evaluation of the semantic tagging provided by the portuguese parser pala vras (bick, 2000) (http://visl.sdu.dk/visl/pt/parsing/automatic) as lexical resource for indirect anaphora resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB131">
<title id=" W06-1311.xml">semantic tagging for resolution of indirect anaphora </title>
<section> final remarks.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, establishing relationship between os profess ores 78 [the teachers], with the semantic tags and hprof,and os politicos [the politicians], with the semantic tags and hprof, when the correct antecedent was os docentes [the docents], with the semantic tags hh (group of humans) and hprof.
</prevsent>
<prevsent>previous work on nominal anaphor resolution hasused lexical knowledge in different ways.
</prevsent>
</prevsection>
<citsent citstr=" W97-1301 ">
(poe sio et al, 1997) <papid> W97-1301 </papid>presented results concerning the resolution of bridging definitions, using the wordnet (fellbaum, 1998), where bridging dds enclose our indirect and associative anaphora.</citsent>
<aftsection>
<nextsent>poe sio et al reported 35% of recall for synonymy, 56% for hypernymy and 38% for meronymy.(schulte im walde, 1997) evaluated the bridging cases presented in (poesio et al, 1997), <papid> W97-1301 </papid>on the basis of lexical acquisition from the british national corpus.</nextsent>
<nextsent>she reported recall of 33% for synonymy, 15% for hypernymy and 18% formeronymy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB133">
<title id=" W06-1311.xml">semantic tagging for resolution of indirect anaphora </title>
<section> final remarks.  </section>
<citcontext>
<prevsection>
<prevsent>she reported recall of 33% for synonymy, 15% for hypernymy and 18% formeronymy.
</prevsent>
<prevsent>(poesio et al, 2002) considering syntactic patterns for lexical knowledge acquisition, obtained better results for resolving meronymy (66% of recall).
</prevsent>
</prevsection>
<citsent citstr=" W04-0706 ">
(gasperin and vieira, 2004)<papid> W04-0706 </papid>tested the use of word similarity lists on resolving indirect anaphora, reporting 33% of recall.</citsent>
<aftsection>
<nextsent>(markert and nissim, 2005) <papid> J05-3004 </papid>presented two ways(wordnet and web) of obtaining lexical knowledge for antecedent selection in co referent dds (direct and indirect anaphora).</nextsent>
<nextsent>markert and nissim achieved 71% of recall using web-based method and 65% of recall using wordnet-basedmethod.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB135">
<title id=" W05-0312.xml">annotating discourse connectives in the chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of the chinese discourse treebank(cdtb) project is to add layer of discourse annotation to the penn chinese treebank (xue et al, to appear), the bulk of which has also been annotated with predicate-argument structures.
</prevsent>
<prevsent>this project is focused on discourse connectives, which include explicit connectives such as subordinate and coordinate conjunctions, discourse adverbials, as well as implicit discourse connectives that are infer able from neighboring sentences.
</prevsent>
</prevsection>
<citsent citstr=" W98-0315 ">
like the penn english discourse treebank (miltsakaki et al, 2004a; miltsakaki et al, 2004b), the cdtb project adopts the general idea presented in (webber and joshi, 1998; <papid> W98-0315 </papid>webber et al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>where discourse connectives are considered to be predicates that take abstract objects such as propositions,events and situations as their arguments.</citsent>
<aftsection>
<nextsent>this approach departs from the previous approaches to discourse analysis such as the rhetorical structure theory (mann and thompson, 1988; carlson et al,2003) in that it does not start from predefined inventory of abstract discourse relations.
</nextsent>
<nextsent>instead, all discourse relations are lexically grounded and anchored by discourse connective.
</nextsent>
<nextsent>the discourse relations so defined can be structural or anaphoric.
</nextsent>
<nextsent>structural discourse relations, generally anchored by subordinate and coordinate conjunctions, hold locally between two adjacent units of discourse (suchas clauses).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB136">
<title id=" W05-0312.xml">annotating discourse connectives in the chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of the chinese discourse treebank(cdtb) project is to add layer of discourse annotation to the penn chinese treebank (xue et al, to appear), the bulk of which has also been annotated with predicate-argument structures.
</prevsent>
<prevsent>this project is focused on discourse connectives, which include explicit connectives such as subordinate and coordinate conjunctions, discourse adverbials, as well as implicit discourse connectives that are infer able from neighboring sentences.
</prevsent>
</prevsection>
<citsent citstr=" P99-1006 ">
like the penn english discourse treebank (miltsakaki et al, 2004a; miltsakaki et al, 2004b), the cdtb project adopts the general idea presented in (webber and joshi, 1998; <papid> W98-0315 </papid>webber et al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>where discourse connectives are considered to be predicates that take abstract objects such as propositions,events and situations as their arguments.</citsent>
<aftsection>
<nextsent>this approach departs from the previous approaches to discourse analysis such as the rhetorical structure theory (mann and thompson, 1988; carlson et al,2003) in that it does not start from predefined inventory of abstract discourse relations.
</nextsent>
<nextsent>instead, all discourse relations are lexically grounded and anchored by discourse connective.
</nextsent>
<nextsent>the discourse relations so defined can be structural or anaphoric.
</nextsent>
<nextsent>structural discourse relations, generally anchored by subordinate and coordinate conjunctions, hold locally between two adjacent units of discourse (suchas clauses).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB137">
<title id=" W05-0312.xml">annotating discourse connectives in the chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of the chinese discourse treebank(cdtb) project is to add layer of discourse annotation to the penn chinese treebank (xue et al, to appear), the bulk of which has also been annotated with predicate-argument structures.
</prevsent>
<prevsent>this project is focused on discourse connectives, which include explicit connectives such as subordinate and coordinate conjunctions, discourse adverbials, as well as implicit discourse connectives that are infer able from neighboring sentences.
</prevsent>
</prevsection>
<citsent citstr=" J03-4002 ">
like the penn english discourse treebank (miltsakaki et al, 2004a; miltsakaki et al, 2004b), the cdtb project adopts the general idea presented in (webber and joshi, 1998; <papid> W98-0315 </papid>webber et al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>where discourse connectives are considered to be predicates that take abstract objects such as propositions,events and situations as their arguments.</citsent>
<aftsection>
<nextsent>this approach departs from the previous approaches to discourse analysis such as the rhetorical structure theory (mann and thompson, 1988; carlson et al,2003) in that it does not start from predefined inventory of abstract discourse relations.
</nextsent>
<nextsent>instead, all discourse relations are lexically grounded and anchored by discourse connective.
</nextsent>
<nextsent>the discourse relations so defined can be structural or anaphoric.
</nextsent>
<nextsent>structural discourse relations, generally anchored by subordinate and coordinate conjunctions, hold locally between two adjacent units of discourse (suchas clauses).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB138">
<title id=" W05-0312.xml">annotating discourse connectives in the chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast, anaphoric discourse relations are generally anchored by discourse adverbials and only one argument can be identified structurally in the local context while the other can only be de 84 rived anaphoric ally in the previous discourse.
</prevsent>
<prevsent>an advantage of this approach to discourse analysis is that discourse relations can be built up incrementally in bottom-up manner and this advantage is magnified in large-scale annotation projects where inter annotator agreement is crucial and has been verified in the construction of the penn english discourse treebank (miltsakaki et al, 2004a).
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
this approach closely parallels the annotation of the the verbs in the english and chinese prop banks (palmer et al, 2005; <papid> J05-1004 </papid>xue and palmer, 2003), <papid> W03-1707 </papid>where verbs are the anchors of predicate-argument structures.</citsent>
<aftsection>
<nextsent>the difference is that the extents of the arguments to discourse connectives are far less certain, while the arity of the predcates is fixed for the discourse connectives.
</nextsent>
<nextsent>this paper outlines the issues that arise from the annotation of chinese discourse connectives, with an initial focus on explicit discourse connectives.
</nextsent>
<nextsent>section 2 gives an overview of the different kinds of discourse connectives that we plan to annotate for the cdtb project.
</nextsent>
<nextsent>section 3 surveys the distribution of the discourse connectives and section 4 describes the kinds of discourse units that can be arguments to the discourse connectives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB139">
<title id=" W05-0312.xml">annotating discourse connectives in the chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast, anaphoric discourse relations are generally anchored by discourse adverbials and only one argument can be identified structurally in the local context while the other can only be de 84 rived anaphoric ally in the previous discourse.
</prevsent>
<prevsent>an advantage of this approach to discourse analysis is that discourse relations can be built up incrementally in bottom-up manner and this advantage is magnified in large-scale annotation projects where inter annotator agreement is crucial and has been verified in the construction of the penn english discourse treebank (miltsakaki et al, 2004a).
</prevsent>
</prevsection>
<citsent citstr=" W03-1707 ">
this approach closely parallels the annotation of the the verbs in the english and chinese prop banks (palmer et al, 2005; <papid> J05-1004 </papid>xue and palmer, 2003), <papid> W03-1707 </papid>where verbs are the anchors of predicate-argument structures.</citsent>
<aftsection>
<nextsent>the difference is that the extents of the arguments to discourse connectives are far less certain, while the arity of the predcates is fixed for the discourse connectives.
</nextsent>
<nextsent>this paper outlines the issues that arise from the annotation of chinese discourse connectives, with an initial focus on explicit discourse connectives.
</nextsent>
<nextsent>section 2 gives an overview of the different kinds of discourse connectives that we plan to annotate for the cdtb project.
</nextsent>
<nextsent>section 3 surveys the distribution of the discourse connectives and section 4 describes the kinds of discourse units that can be arguments to the discourse connectives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB140">
<title id=" W04-3211.xml">mixing weak learners in semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also present new features which result in 1.1%gain in classification accuracy and describe technique that results in 97% reduction in the feature space with no significant degradation inaccuracy.
</prevsent>
<prevsent>shallow semantic parsing is the process of finding sentence constituents that play semantic role relative to target predicate and then labeling those constituents according to their respective roles.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
specifying an events agent, patient, location, time of occurrence, etc, can be useful for nlp tasks such as information extraction (c.f., surdeanu et al, 2003),<papid> P03-1002 </papid>dialog understanding, question answering, text summarization, and machine translation.</citsent>
<aftsection>
<nextsent>example 1 depicts semantic parse.
</nextsent>
<nextsent>(1) [agent she] [p bought] [patient the vase] [locative in egypt] we expand on previous semantic parsing work (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2003;surdeanu et al, 2003) <papid> P03-1002 </papid>by presenting novel algorithm worthy of further exploration, describing technique to drastically reduce feature space size, and presenting statistically significant new features.</nextsent>
<nextsent>the accuracy of the final system is 88.3% on the classification task using the propbank (kingsbury et al, 2002) corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB141">
<title id=" W04-3211.xml">mixing weak learners in semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>specifying an events agent, patient, location, time of occurrence, etc, can be useful for nlp tasks such as information extraction (c.f., surdeanu et al, 2003),<papid> P03-1002 </papid>dialog understanding, question answering, text summarization, and machine translation.</prevsent>
<prevsent>example 1 depicts semantic parse.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
(1) [agent she] [p bought] [patient the vase] [locative in egypt] we expand on previous semantic parsing work (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2003;surdeanu et al, 2003) <papid> P03-1002 </papid>by presenting novel algorithm worthy of further exploration, describing technique to drastically reduce feature space size, and presenting statistically significant new features.</citsent>
<aftsection>
<nextsent>the accuracy of the final system is 88.3% on the classification task using the propbank (kingsbury et al, 2002) corpus.
</nextsent>
<nextsent>this is just 0.6% off the best accuracy reported in the literature.the classification algorithm used here is variant of random forests (rfs) (breiman, 2001).this was motivated by breimans empirical studies of numerous datasets showing that rfs often have lower generalize error than ada boost (fre und and schapire, 1997), are less sensitive to noisein the training data, and learn well from weak inputs, while taking much less time to train.
</nextsent>
<nextsent>rfs are also simpler to understand and implement than svms, leading to, among other things, easier interpretation of feature importance and interactions(c.f., breiman, 2004), easier multi-class classification (requiring only single training session versus one for each class), and easier problem-specific customization (e.g., by introducing prior knowledge).the algorithm described here is considerably different from those in (breiman, 2001).
</nextsent>
<nextsent>it was significantly revised to better handle high dimensional categorical inputs and as result provides much better accuracy on the shallow semantic parsing problem.the experiments reported here focus on the classification task ? given parsed constituent known to play semantic role relative to given predicate, decide which role is the appropriate one to assign to that constituent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB149">
<title id=" W04-3211.xml">mixing weak learners in semantic parsing </title>
<section> the data.  </section>
<citcontext>
<prevsection>
<prevsent>the classifiers were trained on data derived from the propbank corpus (kingsbury et al, 2002).
</prevsent>
<prevsent>thesame observations and features are used as described by (pradhan et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
they acquired the original data from the july 15, 2002 release of propbank, which the university of pennsylvania created by manually labeling the constituents np vp she bought np pp the vase in egypt arg0 predicate arg1 argm-loc figure 1: syntactic parse of the sentence in (2) of the penn treebank gold-standard parses (marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>predicate usages (at present, strictlyverbs) are hand annotated with 22 possible semantic roles plus the null role to indicate grammatical constituents that are not arguments of the predicate.
</nextsent>
<nextsent>the argument labels can have different meanings depending on their target predicate, but the annotation method attempted to assign consistent meanings to labels, especially when associated with similar verbs.
</nextsent>
<nextsent>there are seven core roles or arguments,labeled arg0-5 and arg9.
</nextsent>
<nextsent>arg0 usually corresponds to the semantic agent and arg1 to the entity most affected by the action.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB154">
<title id=" W04-3211.xml">mixing weak learners in semantic parsing </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments all focus strictly on the classification task ? given syntactic constituent known to be an argument of given predicate, decide which argument role is the appropriate one to assign to the constituent.
</prevsent>
<prevsent>4.1 experiment 1: baseline feature set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
the first experiment compares the random forest classifier to three other classifiers, statistical bayesian approach with backoff (gildea and palmer, 2002), <papid> P02-1031 </papid>decision tree classifier (surdeanu et al, 2003),<papid> P03-1002 </papid> and support vector machine (svm)(pradhan et al, 2003).</citsent>
<aftsection>
<nextsent>the baseline feature set utilized in this experiment is described in figure 2 (see (gildea and jurafsky, 2002) <papid> J02-3001 </papid>for details).</nextsent>
<nextsent>surdeanu et al omit the sub-categorization feature, but add binary-valued feature that indicates the governing category of noun-phrase argument constituents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB212">
<title id=" W05-1308.xml">intex a syntactic role driven protein protein interaction extractor for biomedical text </title>
<section> interaction extractor: finally, extracting.  </section>
<citcontext>
<prevsection>
<prevsent>2 related work.
</prevsent>
<prevsent>information extraction is the extraction of salient facts about pre-specified types of events, entities (bunescu, ge et al  2003) or relationships from free text.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
information extraction from free-text utilizes shallow-parsing techniques (daelemans, buchholz et al  1999), parts-of-speech tag ging(brill 1992), <papid> A92-1021 </papid>noun and verb phrase chunking (mikheev and finch 1997), <papid> A97-1054 </papid>verb subject and object relationships (daelemans, buchholz et al  1999), and learned (califf and mooney 1998; craven and kumlein 1999; seymore, mccallum et al  1999) or hand-build patterns to automate the creation of specialized databases.</citsent>
<aftsection>
<nextsent>manual pattern engineering approaches employ shallow parsing with patterns to extract the interactions.
</nextsent>
<nextsent>in the (ono, hishigaki et al  2001) system, 55 sentences are first tagged using dictionary based protein name identifier and then processed by module which extracts interactions directly from complex and compound sentences using regular expressions based on part of speech tags.
</nextsent>
<nextsent>the suiseki system of blaschke (blaschke, andrade et al  1999) also uses regular expressions, with probabilities that reflect the experimental accuracy of each pattern to extract interactions into predefined frame structures.
</nextsent>
<nextsent>genies (friedman, kra et al  2001) utilizes grammar based nlp engine for information extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB213">
<title id=" W05-1308.xml">intex a syntactic role driven protein protein interaction extractor for biomedical text </title>
<section> interaction extractor: finally, extracting.  </section>
<citcontext>
<prevsection>
<prevsent>2 related work.
</prevsent>
<prevsent>information extraction is the extraction of salient facts about pre-specified types of events, entities (bunescu, ge et al  2003) or relationships from free text.
</prevsent>
</prevsection>
<citsent citstr=" A97-1054 ">
information extraction from free-text utilizes shallow-parsing techniques (daelemans, buchholz et al  1999), parts-of-speech tag ging(brill 1992), <papid> A92-1021 </papid>noun and verb phrase chunking (mikheev and finch 1997), <papid> A97-1054 </papid>verb subject and object relationships (daelemans, buchholz et al  1999), and learned (califf and mooney 1998; craven and kumlein 1999; seymore, mccallum et al  1999) or hand-build patterns to automate the creation of specialized databases.</citsent>
<aftsection>
<nextsent>manual pattern engineering approaches employ shallow parsing with patterns to extract the interactions.
</nextsent>
<nextsent>in the (ono, hishigaki et al  2001) system, 55 sentences are first tagged using dictionary based protein name identifier and then processed by module which extracts interactions directly from complex and compound sentences using regular expressions based on part of speech tags.
</nextsent>
<nextsent>the suiseki system of blaschke (blaschke, andrade et al  1999) also uses regular expressions, with probabilities that reflect the experimental accuracy of each pattern to extract interactions into predefined frame structures.
</nextsent>
<nextsent>genies (friedman, kra et al  2001) utilizes grammar based nlp engine for information extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB214">
<title id=" W04-3235.xml">error measures and bayes decision rules revisited with applications to pos tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advantage of the pos tagging task is that it will be easier to handle from the mathematical point of view and will result in closed form solutions for the decision rules.
</prevsent>
<prevsent>from this point-of-view, the pos tagging task serves as good opportunity to illustrate the key concepts of the statistical approach to nlp.
</prevsent>
</prevsection>
<citsent citstr=" E85-1023 ">
related work: for the task of pos tagging, statistical approaches were proposed already in the 60s and 70s (stolz et al, 1965; bahl and mercer, 1976), before they started to find widespread use in the 80s (beale, 1985; <papid> E85-1023 </papid>derose, 1989; church, 1989).</citsent>
<aftsection>
<nextsent>to the best of our knowledge, the standard?
</nextsent>
<nextsent>version of the bayes decision rule, which minimizes the number of string errors, is used in virtually all approaches to pos tagging and other nlp tasks.
</nextsent>
<nextsent>there are only two research groups that do not take this type of decision rule for granted: (merialdo, 1994): <papid> J94-2001 </papid>in the context of pos tagging, the author introduces method that he calls maximum likelihood tagging.</nextsent>
<nextsent>the spirit of this method is similar to that of this work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB215">
<title id=" W04-3235.xml">error measures and bayes decision rules revisited with applications to pos tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to the best of our knowledge, the standard?
</prevsent>
<prevsent>version of the bayes decision rule, which minimizes the number of string errors, is used in virtually all approaches to pos tagging and other nlp tasks.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
there are only two research groups that do not take this type of decision rule for granted: (merialdo, 1994): <papid> J94-2001 </papid>in the context of pos tagging, the author introduces method that he calls maximum likelihood tagging.</citsent>
<aftsection>
<nextsent>the spirit of this method is similar to that of this work.
</nextsent>
<nextsent>however, this method is mentioned as an aside and its implications for the bayes decision rule and the statistical approach are not addressed.
</nextsent>
<nextsent>part of this work goes back to (bahl et al, 1974) who considered problem in coding theory.
</nextsent>
<nextsent>(goel and byrne, 2003): the error measure considered by the authors is the word error rate in speech recognition, i.e. the edit distance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB217">
<title id=" W04-3235.xml">error measures and bayes decision rules revisited with applications to pos tagging </title>
<section> the modelling approaches to pos.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 direct model: maximum entropy.
</prevsent>
<prevsent>we replace the true but unknown posterior distribution pr(gn1 |wn1 ) by model-based probability distribution p(gn1 |wn1 ): pr(gn1 |wn1 ) ? p(gn1 |wn1 ) and apply the chain rule: p(gn1 |wn1 ) = ? n=1 p(gn|gn11 , wn1 ) = ? n=1 p(gn|gn1n2 , wn+2n2) as for the generative model, we have made specific assumptions: there is second-order dependence for the tags gn1 , and the dependence on the words wn1 is limited to window wn+2n2 around position n. the resulting model is still rather complex and requires further specifications.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the typical procedure is to resort to log-linear modelling, which is also referred to as maximum entropy modelling (ratnaparkhi, 1996; <papid> W96-0213 </papid>berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>3.2.1 string error for the minimum string error, we obtain the decision rule: wn1 ? gn1 = argmax gn1 { p(gn1 |wn1 ) } since this is still second-order model, we can use dynamic programming to compute the most likely pos string.
</nextsent>
<nextsent>3.2.2 symbol error for the minimum symbol error, the marginal (and posterior) probability pm(g|wn1 ) has to be computed: pm(g|wn1 ) = ? gn1 : gm=g pr(gn1 |wn1 ) = ? gn1 : gm=g ? p(gn|gn1n2 , wn+2n2) which, due to the specific structure of the model p(gn|gn1n2 , wn+2n2), can be calculated efficiently using only forward algorithm (without backward?
</nextsent>
<nextsent>part).
</nextsent>
<nextsent>thus we obtain the decision rule for minimum symbol error at positions = 1, ..., : (wn1 ,m) ? gm = argmaxg { pm(g|wn1 ) } as in the case of the generative model, the computational effort is to compute the posterior probability pm(g|wn1 ) rather than to find the most probable tag at position m.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB218">
<title id=" W04-3235.xml">error measures and bayes decision rules revisited with applications to pos tagging </title>
<section> the modelling approaches to pos.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 direct model: maximum entropy.
</prevsent>
<prevsent>we replace the true but unknown posterior distribution pr(gn1 |wn1 ) by model-based probability distribution p(gn1 |wn1 ): pr(gn1 |wn1 ) ? p(gn1 |wn1 ) and apply the chain rule: p(gn1 |wn1 ) = ? n=1 p(gn|gn11 , wn1 ) = ? n=1 p(gn|gn1n2 , wn+2n2) as for the generative model, we have made specific assumptions: there is second-order dependence for the tags gn1 , and the dependence on the words wn1 is limited to window wn+2n2 around position n. the resulting model is still rather complex and requires further specifications.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the typical procedure is to resort to log-linear modelling, which is also referred to as maximum entropy modelling (ratnaparkhi, 1996; <papid> W96-0213 </papid>berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>3.2.1 string error for the minimum string error, we obtain the decision rule: wn1 ? gn1 = argmax gn1 { p(gn1 |wn1 ) } since this is still second-order model, we can use dynamic programming to compute the most likely pos string.
</nextsent>
<nextsent>3.2.2 symbol error for the minimum symbol error, the marginal (and posterior) probability pm(g|wn1 ) has to be computed: pm(g|wn1 ) = ? gn1 : gm=g pr(gn1 |wn1 ) = ? gn1 : gm=g ? p(gn|gn1n2 , wn+2n2) which, due to the specific structure of the model p(gn|gn1n2 , wn+2n2), can be calculated efficiently using only forward algorithm (without backward?
</nextsent>
<nextsent>part).
</nextsent>
<nextsent>thus we obtain the decision rule for minimum symbol error at positions = 1, ..., : (wn1 ,m) ? gm = argmaxg { pm(g|wn1 ) } as in the case of the generative model, the computational effort is to compute the posterior probability pm(g|wn1 ) rather than to find the most probable tag at position m.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB232">
<title id=" W05-1009.xml">morphology vs syntax in adjective class acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper fits into broader effort addressing the automatic acquisition of semantic classes for catalan adjectives.
</prevsent>
<prevsent>so far, no established standard of such semantic classes is available in theoretical or empirical linguistic research.
</prevsent>
</prevsection>
<citsent citstr=" C04-1161 ">
our aim is to reach aclassification that is empirically adequate and theoretically sound, and we use computational techniques as means to explore large amounts of data which would be impossible to explore by hand to help us define and characterise the classification.in previous research (boleda et al, 2004),<papid> C04-1161 </papid>we developed three-way classification according to generally accepted adjective properties (see section 2), and applied cluster analysis to further examine the classes.</citsent>
<aftsection>
<nextsent>while the cluster analysis confirmed our classification to large extent, it was clear that one of the classes needed further exploration.
</nextsent>
<nextsent>also, we used only syntactic features modelled as pairs of pos-bigrams; we explored neither other syntactic features nor the role of morphological evidence for the classification.
</nextsent>
<nextsent>in this paper we apply supervised classification technique, decision trees, for exploratory data analysis.
</nextsent>
<nextsent>our aim is to explore the linguistic features and description levels that are relevant for the semantic classification, focusing on morphology and syntax.we check how far we get with morphological information, and whether syntax is helpful to overcome the ceiling reached with morphology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB234">
<title id=" W05-1009.xml">morphology vs syntax in adjective class acquisition </title>
<section> classification and gold standard.  </section>
<citcontext>
<prevsection>
<prevsent>+ al, and is an object meaning.
</prevsent>
<prevsent>in this case, the judge should assign the adjective to two classes, primary basic, secondary object.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
compositional meanings are thus those corresponding to active morphological processes, and can be predicted from the meaning ofthe noun and the derivation with the suffix (be it de nominal, deverbal or participial).the judges had an acceptable 0.74 mean ? agreement (carletta, 1996) <papid> J96-2004 </papid>for the assignment of the primary class, but meaningless 0.21 for the secondary class (they did not even agree on which lemmatawere polysemous).</citsent>
<aftsection>
<nextsent>as reaction to the low agreement about polysemy, we incorporated polysemy information from catalan dictionary (dlc, 1993).
</nextsent>
<nextsent>this information was incorporated only in addition to the gathered gold standard: in many cases the dictionary only lists the compositional sense.
</nextsent>
<nextsent>we added it as second reading if our judges considered the non compositional one as most frequent.one of the authors of the paper classified there maining 100 lemmata according to the same criteria.for our experiment, we use the complete gold standard containing 186 lemmata (87 basic, 46 event, and 53 object adjectives).
</nextsent>
<nextsent>there is an obvious relationship between the derivational type of an adjective (whether it is denom inal, deverbal, or not derived) and the semantic clas task was quite high.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB236">
<title id=" W05-1009.xml">morphology vs syntax in adjective class acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>contrary to expectation, however, deverbal adjectives that occur predicatively are classified asbasic.
</prevsent>
<prevsent>this result confirms the suspicion that frequent predicative use is associated with participial, but not with other kinds of deverbal adjectives, as stated in section 4.4.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
in recent years much research (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde and brew, 2002; korhonen et al, 2003) <papid> P03-1009 </papid>has aimed at exploiting the syntax-semantics interface for classification tasks, mostly based on verbs.</citsent>
<aftsection>
<nextsent>in particular, merlo and stevenson (2001) <papid> J01-3003 </papid>present classification experiment which bears similarities to ours.</nextsent>
<nextsent>they use decision trees to classify in transitive english verbs into three semantic classes: unergatives, unaccusatives, and object-drop.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB237">
<title id=" W05-1009.xml">morphology vs syntax in adjective class acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>contrary to expectation, however, deverbal adjectives that occur predicatively are classified asbasic.
</prevsent>
<prevsent>this result confirms the suspicion that frequent predicative use is associated with participial, but not with other kinds of deverbal adjectives, as stated in section 4.4.
</prevsent>
</prevsection>
<citsent citstr=" P03-1009 ">
in recent years much research (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde and brew, 2002; korhonen et al, 2003) <papid> P03-1009 </papid>has aimed at exploiting the syntax-semantics interface for classification tasks, mostly based on verbs.</citsent>
<aftsection>
<nextsent>in particular, merlo and stevenson (2001) <papid> J01-3003 </papid>present classification experiment which bears similarities to ours.</nextsent>
<nextsent>they use decision trees to classify in transitive english verbs into three semantic classes: unergatives, unaccusatives, and object-drop.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB239">
<title id=" W05-1009.xml">morphology vs syntax in adjective class acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>merlo and stevenson identify linguistic features referring to verb argument structure (crucially involving thematic relations), and classify the verbs into the three classes with an accuracy of 69.8%.
</prevsent>
<prevsent>they compare their results with random baseline of 33%.there has been much less research in lexical acquisition for adjectives.
</prevsent>
</prevsection>
<citsent citstr=" P93-1023 ">
early efforts include hatzivassiloglou and mckeown (1993), <papid> P93-1023 </papid>cluster analysis directed to the automatic identification of adjectives belonging to the same scale (such as cold-tempered hot).</citsent>
<aftsection>
<nextsent>more recently, bohnet et al (2002) used bootstrapping to assign german adjectives to func tional?
</nextsent>
<nextsent>classes (of more traditional sort, based ona german descriptive grammar).
</nextsent>
<nextsent>they relied on ordering restrictions and coordination data which can be adapted to catalan.
</nextsent>
<nextsent>as for romance languages, the only related work we are aware of is carvalho and ranchod (2003),who developed finite-state approach to disambiguating homo graph adjectives and nouns in portuguese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB240">
<title id=" W05-0907.xml">evaluating duc 2004 tasks with the qarla framework </title>
<section> selection of similarity metrics.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we analyse the characteristics of the selected metrics.
</prevsent>
<prevsent>3.1 similarity metrics.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
for this work, we have considered the following similarity metrics: rouge based metrics (r): rouge (lin andhovy, 2003) <papid> N03-1020 </papid>estimates the quality of an automatic summary on the basis of the n-gram coverage related to set of human summaries (models).</citsent>
<aftsection>
<nextsent>although rouge is an evaluation metric, we can adapt it to behave as similarity metric between pairs of summaries ifwe consider only one model in the computation.
</nextsent>
<nextsent>there are different kinds of rouge metrics such as rouge-w, rouge-l, rouge 1, rouge-2, rouge-3, rouge-4, etc.
</nextsent>
<nextsent>(lin,2004<papid> W04-1013 </papid>b).</nextsent>
<nextsent>each of these metrics has been applied over summaries with three preprocessing options: with stemming and stop word removal (type c); only with stop words removal (type b); or without any kind of preprocessing (type a).all these combinations give 24 similarity metrics based on rouge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB241">
<title id=" W05-0907.xml">evaluating duc 2004 tasks with the qarla framework </title>
<section> selection of similarity metrics.  </section>
<citcontext>
<prevsection>
<prevsent>although rouge is an evaluation metric, we can adapt it to behave as similarity metric between pairs of summaries ifwe consider only one model in the computation.
</prevsent>
<prevsent>there are different kinds of rouge metrics such as rouge-w, rouge-l, rouge 1, rouge-2, rouge-3, rouge-4, etc.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
(lin,2004<papid> W04-1013 </papid>b).</citsent>
<aftsection>
<nextsent>each of these metrics has been applied over summaries with three preprocessing options: with stemming and stop word removal (type c); only with stop words removal (type b); or without any kind of preprocessing (type a).all these combinations give 24 similarity metrics based on rouge.
</nextsent>
<nextsent>inverted rouge based metrics (rpre): rouge metrics are recall oriented.
</nextsent>
<nextsent>if we reverse the direction of the similarity computation, we obtain precision oriented metrics (i.e. rpre(a, b) = r(b, a)).
</nextsent>
<nextsent>in this way, we generate another 24 metrics based on inverted rouge.truncatedvectmodel (tvmn): this family of metrics compares the distribution of the most relevant terms from original documents in the summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB243">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>large-scale production of annotated resources is often labour intensive, and thus calls for automatic labelling to streamline the process.
</prevsent>
<prevsent>the task is essentially done in two phases, namely recognising the constituents bearing some semantic relationship to the target verb in sentence, and then labelling them with the corresponding semantic roles.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
in their seminal proposal, gildea and jurafsky (2002) <papid> J02-3001 </papid>approached the task using various features such as headword, phrase type, and parse tree path.</citsent>
<aftsection>
<nextsent>while such features have remained the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing.
</nextsent>
<nextsent>the parse information is deemed important for the performance of role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>gildea and hockenmaier, 2003).<papid> W03-1008 </papid></nextsent>
<nextsent>more precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB244">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in their seminal proposal, gildea and jurafsky (2002) <papid> J02-3001 </papid>approached the task using various features such as headword, phrase type, and parse tree path.</prevsent>
<prevsent>while such features have remained the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing.</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
the parse information is deemed important for the performance of role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>gildea and hockenmaier, 2003).<papid> W03-1008 </papid></citsent>
<aftsection>
<nextsent>more precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data.
</nextsent>
<nextsent>its limited function in training, for instance, is reflected in the low coverage reported (e.g. you and chen, 2004).<papid> W04-1116 </papid></nextsent>
<nextsent>as full parses are not always accessible, many thus resort to shallow syntactic information from simple chunking, even though results often turn out to be less satisfactory than with full parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB245">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in their seminal proposal, gildea and jurafsky (2002) <papid> J02-3001 </papid>approached the task using various features such as headword, phrase type, and parse tree path.</prevsent>
<prevsent>while such features have remained the basic and essential features in subsequent research, parsed sentences are nevertheless required, for extracting the path features during training and providing the argument boundaries during testing.</prevsent>
</prevsection>
<citsent citstr=" W03-1008 ">
the parse information is deemed important for the performance of role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>gildea and hockenmaier, 2003).<papid> W03-1008 </papid></citsent>
<aftsection>
<nextsent>more precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data.
</nextsent>
<nextsent>its limited function in training, for instance, is reflected in the low coverage reported (e.g. you and chen, 2004).<papid> W04-1116 </papid></nextsent>
<nextsent>as full parses are not always accessible, many thus resort to shallow syntactic information from simple chunking, even though results often turn out to be less satisfactory than with full parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB246">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parse information is deemed important for the performance of role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>gildea and hockenmaier, 2003).<papid> W03-1008 </papid></prevsent>
<prevsent>more precisely, parse information is rather more critical for the identification of boundaries of candidate constituents than for the extraction of training data.</prevsent>
</prevsection>
<citsent citstr=" W04-1116 ">
its limited function in training, for instance, is reflected in the low coverage reported (e.g. you and chen, 2004).<papid> W04-1116 </papid></citsent>
<aftsection>
<nextsent>as full parses are not always accessible, many thus resort to shallow syntactic information from simple chunking, even though results often turn out to be less satisfactory than with full parses.
</nextsent>
<nextsent>this limitation is even more pertinent for the application of semantic role labelling to languages which do not have sophisticated parsing resources.
</nextsent>
<nextsent>in the case of chinese, for example, there is con 1siderable variability in its syntax-semantics inter face; and when one comes to more nested and complex sentences such as those from news articles, it becomes more difficult to capture the sentence structures by typical examples.
</nextsent>
<nextsent>thus in the current study, we approach the problem in chinese in the absence of parse information, and attempt to identify the headwords in the relevant constituents in sentence to be tagged as first step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB250">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>results and future work will be discussed in section 6, followed by conclusions in section 7.
</prevsent>
<prevsent>the definition of semantic roles falls on continuum from abstract ones to very specific ones.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
gildea and jurafsky (2002), <papid> J02-3001 </papid>for instance, used set of roles defined according to the framenet model (baker et al, 1998), <papid> P98-1013 </papid>thus corresponding to the frame elements in individual frames under particular domain to which given verb belongs.</citsent>
<aftsection>
<nextsent>lexical entries (in fact not limited to verbs, in the case of framenet) falling under the same frame will share the same set of roles.
</nextsent>
<nextsent>gildea and palmer (2002) <papid> P02-1031 </papid>defined roles with respect to individual predicates in the propbank, without explicit nam ing.</nextsent>
<nextsent>to date propbank and framenet are the two main resources in english for training semantic role labelling systems, as in the conll-2004 shared task (carreras and mrquez, 2004) and senseval-3 (litkowski, 2004).<papid> W04-0803 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB253">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>lexical entries (in fact not limited to verbs, in the case of framenet) falling under the same frame will share the same set of roles.
</prevsent>
<prevsent>gildea and palmer (2002) <papid> P02-1031 </papid>defined roles with respect to individual predicates in the propbank, without explicit nam ing.</prevsent>
</prevsection>
<citsent citstr=" W04-0803 ">
to date propbank and framenet are the two main resources in english for training semantic role labelling systems, as in the conll-2004 shared task (carreras and mrquez, 2004) and senseval-3 (litkowski, 2004).<papid> W04-0803 </papid></citsent>
<aftsection>
<nextsent>the theoretical treatment of semantic roles is also varied in chinese.
</nextsent>
<nextsent>in practice, for example, the semantic roles in the sinica treebank mark not only verbal arguments but also modifier-head relations (you and chen, 2004).<papid> W04-1116 </papid></nextsent>
<nextsent>in our present study, we go for set of more abstract semantic roles similar to the thematic roles for english used in verbnet (kipper et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB258">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the labelling of constituent then depends on its likelihood to fill each possible role given the features and the target predicate t, as in the following, for example: ),,,,,|( tvoicepositiongovpthrp subsequent studies exploited variety of implementation of the learning component.
</prevsent>
<prevsent>trans formation-based approaches were also used (e.g. see carreras and mrquez (2004) for an overview of systems participating in the conll shared task).
</prevsent>
</prevsection>
<citsent citstr=" W04-3213 ">
swier and stevenson (2004) <papid> W04-3213 </papid>innovated with an unsupervised approach to the problem, using bootstrapping algorithm, and achieved 87% accuracy.</citsent>
<aftsection>
<nextsent>while the estimation of the probabilities could be relatively straightforward, the trick often lies in locating the candidate constituents to be labelled.
</nextsent>
<nextsent>a parser of some kind is needed.
</nextsent>
<nextsent>gildea and palmer (2002) <papid> P02-1031 </papid>compared the effects of full parsing and shallow chunking; and found that when constituent boundaries are known, both automatic parses and gold standard parses resulted in about 80% accuracy for subsequent automatic role tagging, but when boundaries are unknown, results with automatic parses dropped to 57% precision and 50% recall.</nextsent>
<nextsent>with chunking only, performance further degraded to below 30%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB261">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with chunking only, performance further degraded to below 30%.
</prevsent>
<prevsent>problems mostly arise from arguments which correspond to more than one chunk, and the misplacement of core arguments.
</prevsent>
</prevsection>
<citsent citstr=" N04-1032 ">
sun and jurafsky (2004) <papid> N04-1032 </papid>also reported drop in f-score with automatic syntactic parses compared to perfect parses for role labelling in chinese, despite the comparatively good results of their parser (i.e. the collins parser ported to chi nese).</citsent>
<aftsection>
<nextsent>the necessity of parse information is also reflected from recent evaluation exercises.
</nextsent>
<nextsent>for instance, most systems in senseval-3 used parser to obtain full syntactic parses for the sentences, whereas systems participating in the conll task were restricted to use only shallow 2syntactic information.
</nextsent>
<nextsent>results reported in the former tend to be higher.
</nextsent>
<nextsent>although the dataset may be factor affecting the labelling performance, it nevertheless reinforces the usefulness of full syntactic information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB264">
<title id=" W05-1001.xml">data homogeneity and semantic role tagging in chinese </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>many predicates may be unseen in the training data, but while the probability estimation could be generalized from near-synonyms as suggested by semantic lexicon, whether the similarity and subtle differences between near-synonyms with respect to the argument structure and the corresponding syntactic realisation could be distinguished would also be worth studying.
</prevsent>
<prevsent>related to this is the possibility of augmenting the feature set.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
xue and palmer (2004), <papid> W04-3212 </papid>for instance, looked into new features such as syntactic frame, lexicalized constituent type, etc., and found that enriching the feature set improved the labelling performance.</citsent>
<aftsection>
<nextsent>in particular, given the importance of data homogeneity as observed from the experimental results, and the challenges posed by the characteristic natu feature set with mo
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB265">
<title id=" W06-0117.xml">france telecom rd beijing word segmenter for sighan bakeoff 2006 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the system also has few postprocessors.
</prevsent>
<prevsent>the main post proces sors include combining the separated words and tbl component.
</prevsent>
</prevsection>
<citsent citstr=" W04-3236 ">
2.2.1 basic system the basic system is similar to (ng and low, 2004).<papid> W04-3236 </papid></citsent>
<aftsection>
<nextsent>we used the tsujii laboratory maximum entropy package v2.0 (http://www-tsujii.is.s.utokyo.ac.jp/~tsuruoka/maxent/) to train our models.
</nextsent>
<nextsent>for cityu closed track, the basic features are the same as (ng and low, 2004).<papid> W04-3236 </papid></nextsent>
<nextsent>for msra closed track, we used two sets of basic features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB270">
<title id=" W04-3105.xml">mining medline postulating a beneficial role for cur cumin longa in retinal diseases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, in reality the challenge is greater since there is no assurance that there indeed is needle in the haystack.
</prevsent>
<prevsent>consequently, the goal of text mining (also known as literature mining) systems and algorithms is to assist users find such needles, if these exist at all in the literature haystacks?
</prevsent>
</prevsection>
<citsent citstr=" P99-1001 ">
(hearst 1999).<papid> P99-1001 </papid></citsent>
<aftsection>
<nextsent>in general, as shown in figure 1, user may start with any type of topic (a), be it disease, pharmacological substance, or specific gene.
</nextsent>
<nextsent>as he navigates the literature and follows connections through appropriate intermediate topics (b1, b2 etc.), the user hopes to reach terminal topics (c1, c2 etc.) that are both relevant and novel, in the sense of shedding new information on topic (a).
</nextsent>
<nextsent>this text mining approach commonly referred to as open?
</nextsent>
<nextsent>discovery was pioneered by swanson in the mid80s.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB271">
<title id=" W04-3249.xml">unsupervised domain relevance estimation for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, domain detection allows number of useful simplifications in text processing applications, such as, for instance, in word sense disambiguation (wsd).in this paper we introduce domain relevance estimation (dre) fully unsupervised technique for domain detection.
</prevsent>
<prevsent>roughly speaking, dre can be viewed as text categorization (tc) problem (se bastiani, 2002), even if we do not approach the problem in the standard supervised setting requiring category labeled training data.
</prevsent>
</prevsection>
<citsent citstr=" C00-1066 ">
in fact, recently, unsupervised approaches to tc have received more and more attention in the literature (see for example (ko and seo, 2000).<papid> C00-1066 </papid></citsent>
<aftsection>
<nextsent>we assume pre-defined set of categories, each defined by means of list of related terms.
</nextsent>
<nextsent>we call such categories domains and we consider them as set of general topics (e.g. sport, medicine,politics) that cover the main disciplines and areas of human activity.
</nextsent>
<nextsent>for each domain, the listof related words is extracted from wordnet domains (magnini and cavaglia`, 2000), an extension of wordnet in which synsets are annotated with domain labels.
</nextsent>
<nextsent>we have identified about 40 domains (out of 200 present in wordnet domains) andwe will use them for experiments throughout the paper (see table 1).dre focuses on the problem of estimating degree of relatedness of certain text with respect to the domains in wordnet domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB272">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in practice, this assumption does not always hold, and so cache can sometimes do more harm than good.
</prevsent>
<prevsent>1.1 interactive translation context.
</prevsent>
</prevsection>
<citsent citstr=" W02-1020 ">
over the last few years, an interactive machine translation (imt) system (foster et al, 2002) <papid> W02-1020 </papid>has been developed which, as the translator is typing, suggests word and phrase completions that the usercan accept or ignore.</citsent>
<aftsection>
<nextsent>the system uses translation engine to propose the words or phrases which it judges the most probable to be immediately typed.
</nextsent>
<nextsent>this engine includes translation model (tm) anda language model (lm) used jointly to produce proposals that are appropriate translations of source words and plausible completions of the current text in the target language.
</nextsent>
<nextsent>the translator remains in control of the translation because what is typed by the user is taken as constraint to which the model must continually adapt its completions.
</nextsent>
<nextsent>experiments have shown that the use of this system cansave about 50% of the keystrokes needed for entering translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB273">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> current imt models.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 then puts the resultsin the context of our imt application.
</prevsent>
<prevsent>section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system.
</prevsent>
</prevsection>
<citsent citstr=" P00-1006 ">
the word-based translation model embedded within the imt system has been designed by foster (2000).<papid> P00-1006 </papid></citsent>
<aftsection>
<nextsent>it is maximum entropy/minimum divergence (memd) translation model (berger et al, 1996), <papid> J96-1002 </papid>which mimics the parameters of the ibm model 2 (brown et al, 1993) <papid> J93-2003 </papid>within log-linear setting.</nextsent>
<nextsent>the resulting model (named mdi2b) is of the following form, where is the current target text, the source sentence being translated, a particular word in and the next word to be predicted: p(w|h, s) = q(w|h) exp( ? ss sw + ab) z(h, s) (1) the distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB274">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> current imt models.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system.
</prevsent>
<prevsent>the word-based translation model embedded within the imt system has been designed by foster (2000).<papid> P00-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
it is maximum entropy/minimum divergence (memd) translation model (berger et al, 1996), <papid> J96-1002 </papid>which mimics the parameters of the ibm model 2 (brown et al, 1993) <papid> J93-2003 </papid>within log-linear setting.</citsent>
<aftsection>
<nextsent>the resulting model (named mdi2b) is of the following form, where is the current target text, the source sentence being translated, a particular word in and the next word to be predicted: p(w|h, s) = q(w|h) exp( ? ss sw + ab) z(h, s) (1) the distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study.
</nextsent>
<nextsent>the?
</nextsent>
<nextsent>coefficients are the familiar transferor lexical parameters, and the ? ones can be understood as their position dependent correction.
</nextsent>
<nextsent>z is normalizing factor, the sum of the numerator for every in the target vocabulary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB275">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> current imt models.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system.
</prevsent>
<prevsent>the word-based translation model embedded within the imt system has been designed by foster (2000).<papid> P00-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
it is maximum entropy/minimum divergence (memd) translation model (berger et al, 1996), <papid> J96-1002 </papid>which mimics the parameters of the ibm model 2 (brown et al, 1993) <papid> J93-2003 </papid>within log-linear setting.</citsent>
<aftsection>
<nextsent>the resulting model (named mdi2b) is of the following form, where is the current target text, the source sentence being translated, a particular word in and the next word to be predicted: p(w|h, s) = q(w|h) exp( ? ss sw + ab) z(h, s) (1) the distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study.
</nextsent>
<nextsent>the?
</nextsent>
<nextsent>coefficients are the familiar transferor lexical parameters, and the ? ones can be understood as their position dependent correction.
</nextsent>
<nextsent>z is normalizing factor, the sum of the numerator for every in the target vocabulary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB276">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> current imt models.  </section>
<citcontext>
<prevsection>
<prevsent>z is normalizing factor, the sum of the numerator for every in the target vocabulary.
</prevsent>
<prevsent>our baseline model used an interpolated trigram of the following form as the distribution: p(w|h) = 1(wi2wi1) ? ptri(wi|wi2wi1) + 2(wi2wi1) ? pbi(wi|wi1) + 3(wi2wi1) ? puni(wi) + 4(wi2wi1) ? 1|v |+1 where 1(wi2wi1) + 2(wi2wi1) + 3(wi2wi1) + 4(wi2wi1) = 1 and |v | + 1 is the size of the event space (including special unknown word).
</prevsent>
</prevsection>
<citsent citstr=" C88-1016 ">
as mentioned above, the mdi2b model is closely related to the ibm2 model (brown et al, 1988).<papid> C88-1016 </papid></citsent>
<aftsection>
<nextsent>it contains two classes of features: word pair feature sand positional features.
</nextsent>
<nextsent>the word pair feature functions are defined as follows: fst(w,h, s) = { 1 if ? and = 0 otherwise this function is on if the predicted word is and is in the current source sentence.
</nextsent>
<nextsent>each feature fst has corresponding weight st (for brevity, this is defined to be 0 in equation 1 if the pair s, is not included in the model).
</nextsent>
<nextsent>the positional feature functions are defined as follows: fa,b(w, i, s) = j?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB279">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it seems that with our base model, we add most of the good pairs, but also lot of bad ones.
</prevsent>
<prevsent>with the viterbi alignment and threshold value of 0.3, most of the pairs added are good ones,but we are probably missing number of other appropriate ones.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
this comes back to the task of word alignment, which is very difficult task for computers (mihalcea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>moreover, we would want to add in the cache only those words for which more than one translation is possible.
</nextsent>
<nextsent>for example, the pair (today, au jourdhui), though it is very useful pair for the base model, is unlikely to help when added to the cache.
</nextsent>
<nextsent>the reason is simple: they are two words that are always translations of one another, so the model will have no problem predicting them.
</nextsent>
<nextsent>this ideal of precision and recall and of useful pairs in the cache is obtained by our model with threshold of 0.3, viterbi alignment and cache size of 1000.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB280">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>better performance from the alignment would lead to pairs in the cache closer to this ideal.
</prevsent>
<prevsent>in this study we computed viterbi alignments from an ibm model 2, because it is very efficient to compute and also because for training mdi2b, we do use the ibm model 2.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we could consider also more advanced word alignment models (och and ney, 2000; <papid> P00-1056 </papid>lin and cherry, 2003; <papid> W03-0302 </papid>moore, 2001).<papid> W01-1411 </papid></citsent>
<aftsection>
<nextsent>to keep the alignment model simple, we could still use an ibm model 2, but with the compositionality constraint that has been shown to give better word alignment than the viterbi one (simard and langlais, 2003).<papid> W03-0304 </papid></nextsent>
<nextsent>feature weights we implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB281">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>better performance from the alignment would lead to pairs in the cache closer to this ideal.
</prevsent>
<prevsent>in this study we computed viterbi alignments from an ibm model 2, because it is very efficient to compute and also because for training mdi2b, we do use the ibm model 2.
</prevsent>
</prevsection>
<citsent citstr=" W03-0302 ">
we could consider also more advanced word alignment models (och and ney, 2000; <papid> P00-1056 </papid>lin and cherry, 2003; <papid> W03-0302 </papid>moore, 2001).<papid> W01-1411 </papid></citsent>
<aftsection>
<nextsent>to keep the alignment model simple, we could still use an ibm model 2, but with the compositionality constraint that has been shown to give better word alignment than the viterbi one (simard and langlais, 2003).<papid> W03-0304 </papid></nextsent>
<nextsent>feature weights we implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB282">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>better performance from the alignment would lead to pairs in the cache closer to this ideal.
</prevsent>
<prevsent>in this study we computed viterbi alignments from an ibm model 2, because it is very efficient to compute and also because for training mdi2b, we do use the ibm model 2.
</prevsent>
</prevsection>
<citsent citstr=" W01-1411 ">
we could consider also more advanced word alignment models (och and ney, 2000; <papid> P00-1056 </papid>lin and cherry, 2003; <papid> W03-0302 </papid>moore, 2001).<papid> W01-1411 </papid></citsent>
<aftsection>
<nextsent>to keep the alignment model simple, we could still use an ibm model 2, but with the compositionality constraint that has been shown to give better word alignment than the viterbi one (simard and langlais, 2003).<papid> W03-0304 </papid></nextsent>
<nextsent>feature weights we implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB283">
<title id=" W04-3225.xml">adaptive language and translation models for interactive machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>in this study we computed viterbi alignments from an ibm model 2, because it is very efficient to compute and also because for training mdi2b, we do use the ibm model 2.
</prevsent>
<prevsent>we could consider also more advanced word alignment models (och and ney, 2000; <papid> P00-1056 </papid>lin and cherry, 2003; <papid> W03-0302 </papid>moore, 2001).<papid> W01-1411 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0304 ">
to keep the alignment model simple, we could still use an ibm model 2, but with the compositionality constraint that has been shown to give better word alignment than the viterbi one (simard and langlais, 2003).<papid> W03-0304 </papid></citsent>
<aftsection>
<nextsent>feature weights we implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair.
</nextsent>
<nextsent>the second model suffered from poor data representation and our training algorithm wasnt able to estimate good cache feature weights.
</nextsent>
<nextsent>we think that creating classes of word pairs, such as it was done for positional alignment features, would lead to better results.
</nextsent>
<nextsent>it would enable the model to take into account the tendency that pair has to repeat itself in document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB284">
<title id=" W05-0601.xml">effective use of wordnet semantics via kernel based learning </title>
<section> term similarity based on general.  </section>
<citcontext>
<prevsection>
<prevsent>when small training material is available, few words can be effectively used and the resulting document similarity metrics may be inaccurate.
</prevsent>
<prevsent>semantic generalizations overcome data sparseness problems as contributions from different but semantically similar words are made available.methods for the induction of semantically inspired word clusters have been widely used in language modeling and lexical acquisition tasks (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J02-2003 ">
(clark and weir, 2002)).<papid> J02-2003 </papid></citsent>
<aftsection>
<nextsent>the resource employed in most works is wordnet (fellbaum, 1998) which contains three subhierarchies: for nouns, verbs and adjectives.
</nextsent>
<nextsent>each hierarchy represents lexicalized concepts (or senses) organized according to an is a-kind-of ? relation.
</nextsent>
<nextsent>a concept is described by set of words syn(s) called synset.
</nextsent>
<nextsent>the words ? syn(s) are synonyms according to the sense s.for example, the words line, argumentation, logical argument and line of reasoning describe synset which expresses the methodical process of logical reasoning (e.g. cant follow your line of reason ing?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB285">
<title id=" W05-0601.xml">effective use of wordnet semantics via kernel based learning </title>
<section> term similarity based on general.  </section>
<citcontext>
<prevsection>
<prevsent>for example, black and white are colors but are also chess pieces and this impacts on the similarity score that should be used in ir applications.
</prevsent>
<prevsent>methods to solve the above problems attempt to map priori the terms to specific generalizations levels, i.e. to cuts in the hierarchy (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J98-2002 ">
(li and abe, 1998; <papid> J98-2002 </papid>resnik, 1997)), <papid> W97-0209 </papid>anduse corpus statistics for weighting the resulting mappings.</citsent>
<aftsection>
<nextsent>for several tasks (e.g. in tc) this is unsatis factory: different contexts of the same corpus (e.g. documents) may require different generalizations of the same word as they independently impact on the document similarity.
</nextsent>
<nextsent>on the contrary, the conceptual density (cd)(agirre and rigau, 1996) <papid> C96-1005 </papid>is flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hier archy.</nextsent>
<nextsent>the cd defines metrics according to thetopological structure of wordnet and can be seemingly applied to two or more words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB286">
<title id=" W05-0601.xml">effective use of wordnet semantics via kernel based learning </title>
<section> term similarity based on general.  </section>
<citcontext>
<prevsection>
<prevsent>for example, black and white are colors but are also chess pieces and this impacts on the similarity score that should be used in ir applications.
</prevsent>
<prevsent>methods to solve the above problems attempt to map priori the terms to specific generalizations levels, i.e. to cuts in the hierarchy (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W97-0209 ">
(li and abe, 1998; <papid> J98-2002 </papid>resnik, 1997)), <papid> W97-0209 </papid>anduse corpus statistics for weighting the resulting mappings.</citsent>
<aftsection>
<nextsent>for several tasks (e.g. in tc) this is unsatis factory: different contexts of the same corpus (e.g. documents) may require different generalizations of the same word as they independently impact on the document similarity.
</nextsent>
<nextsent>on the contrary, the conceptual density (cd)(agirre and rigau, 1996) <papid> C96-1005 </papid>is flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hier archy.</nextsent>
<nextsent>the cd defines metrics according to thetopological structure of wordnet and can be seemingly applied to two or more words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB287">
<title id=" W05-0601.xml">effective use of wordnet semantics via kernel based learning </title>
<section> term similarity based on general.  </section>
<citcontext>
<prevsection>
<prevsent>(li and abe, 1998; <papid> J98-2002 </papid>resnik, 1997)), <papid> W97-0209 </papid>anduse corpus statistics for weighting the resulting mappings.</prevsent>
<prevsent>for several tasks (e.g. in tc) this is unsatis factory: different contexts of the same corpus (e.g. documents) may require different generalizations of the same word as they independently impact on the document similarity.</prevsent>
</prevsection>
<citsent citstr=" C96-1005 ">
on the contrary, the conceptual density (cd)(agirre and rigau, 1996) <papid> C96-1005 </papid>is flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hier archy.</citsent>
<aftsection>
<nextsent>the cd defines metrics according to thetopological structure of wordnet and can be seemingly applied to two or more words.
</nextsent>
<nextsent>the measure formalized hereafter adapt to word pairs more general definition given in (basili et al, 2004).
</nextsent>
<nextsent>we denote by s?
</nextsent>
<nextsent>the set of nodes of the hierarchy rooted in the synset s, i.e. {c ? s|c isa s}, where is the set of wn synsets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB290">
<title id=" W05-0205.xml">towards intelligent search assistance for inquiry based learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, current general web search engines are still unable to interactively improve research results.
</prevsent>
<prevsent>in nlp domain, there are considerable efforts on question answering systems that attempt to answer question by returning concise facts.
</prevsent>
</prevsection>
<citsent citstr=" C00-1043 ">
while some qa systems are promising (harabagiu, et al, 2000; <papid> C00-1043 </papid>ravichandran and hovy, 2002), <papid> P02-1006 </papid>they can only handle factual questions as in trec (voorhees, 2001), and the context for the whole task is largely not considered.</citsent>
<aftsection>
<nextsent>there are proposals on using context in search.
</nextsent>
<nextsent>huang et al(2001) proposed term suggestion method for interactive web search.
</nextsent>
<nextsent>more existing systems that utilize contextual information in search are reviewed by lawrence (2000).
</nextsent>
<nextsent>however, one problem is that context?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB291">
<title id=" W05-0205.xml">towards intelligent search assistance for inquiry based learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, current general web search engines are still unable to interactively improve research results.
</prevsent>
<prevsent>in nlp domain, there are considerable efforts on question answering systems that attempt to answer question by returning concise facts.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
while some qa systems are promising (harabagiu, et al, 2000; <papid> C00-1043 </papid>ravichandran and hovy, 2002), <papid> P02-1006 </papid>they can only handle factual questions as in trec (voorhees, 2001), and the context for the whole task is largely not considered.</citsent>
<aftsection>
<nextsent>there are proposals on using context in search.
</nextsent>
<nextsent>huang et al(2001) proposed term suggestion method for interactive web search.
</nextsent>
<nextsent>more existing systems that utilize contextual information in search are reviewed by lawrence (2000).
</nextsent>
<nextsent>however, one problem is that context?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB292">
<title id=" W05-0205.xml">towards intelligent search assistance for inquiry based learning </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the term weight is defined by: ??
</prevsent>
<prevsent>?+ ?+= 2)()(2 )()( )( )1(ln )1ln( i i i ic idftf idftf (5) these context feature vectors are calculated for later use in re-ranking search results.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
meanwhile, we use brill tagger (brill, 1995) <papid> J95-4004 </papid>to determine parts of speech (pos) of words in dq/sq.</citsent>
<aftsection>
<nextsent>heuristic rules (zhang and xuan, 2005) based on pos are used to extract noun phrases.
</nextsent>
<nextsent>noun phrases containing words with high term weight are considered as keyphrases.
</nextsent>
<nextsent>the key phrase weight is defined by: )( )()()( c jj j p pphrasewwhereww ?=?
</nextsent>
<nextsent>(6) 3.2 term suggestion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB293">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this identification task is called semantic role labeling (srl).
</prevsent>
<prevsent>the corresponding roles of the verb (predicate) are called predicate arguments, and the whole proposition is known as predicate argument structure (pas).
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
to develop an automatic srl system for the biomedical domain, it is necessary to train the system with an annotated corpus, called proposition bank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>this corpus contains annotations of semantic pass superimposed on the penn treebank (ptb) (marcus et al., 1993; <papid> J93-2004 </papid>marcus et al, 1994).<papid> H94-1020 </papid></nextsent>
<nextsent>however, the process of manually annotating the pass to construct proposition bank is quite time consuming.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB295">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the corresponding roles of the verb (predicate) are called predicate arguments, and the whole proposition is known as predicate argument structure (pas).
</prevsent>
<prevsent>to develop an automatic srl system for the biomedical domain, it is necessary to train the system with an annotated corpus, called proposition bank (palmer et al, 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
this corpus contains annotations of semantic pass superimposed on the penn treebank (ptb) (marcus et al., 1993; <papid> J93-2004 </papid>marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>however, the process of manually annotating the pass to construct proposition bank is quite time consuming.
</nextsent>
<nextsent>in addition, due to the complexity of proposition bank annotation, inconsistent annotation may occur frequently and further complicate 5the annotation task.
</nextsent>
<nextsent>inspite of the above difficulties, there are proposition banks in the newswire domain that are adequate for training srl systems (xue and palmer, 2004; <papid> W04-3212 </papid>palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>in addition, according to the conll-2005 shared task (carreras and mrquez, 2005), the performance of srl systems in general does not decline significantly when tagging out-of-domain corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB296">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the corresponding roles of the verb (predicate) are called predicate arguments, and the whole proposition is known as predicate argument structure (pas).
</prevsent>
<prevsent>to develop an automatic srl system for the biomedical domain, it is necessary to train the system with an annotated corpus, called proposition bank (palmer et al, 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
this corpus contains annotations of semantic pass superimposed on the penn treebank (ptb) (marcus et al., 1993; <papid> J93-2004 </papid>marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>however, the process of manually annotating the pass to construct proposition bank is quite time consuming.
</nextsent>
<nextsent>in addition, due to the complexity of proposition bank annotation, inconsistent annotation may occur frequently and further complicate 5the annotation task.
</nextsent>
<nextsent>inspite of the above difficulties, there are proposition banks in the newswire domain that are adequate for training srl systems (xue and palmer, 2004; <papid> W04-3212 </papid>palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>in addition, according to the conll-2005 shared task (carreras and mrquez, 2005), the performance of srl systems in general does not decline significantly when tagging out-of-domain corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB297">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the process of manually annotating the pass to construct proposition bank is quite time consuming.
</prevsent>
<prevsent>in addition, due to the complexity of proposition bank annotation, inconsistent annotation may occur frequently and further complicate 5the annotation task.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
inspite of the above difficulties, there are proposition banks in the newswire domain that are adequate for training srl systems (xue and palmer, 2004; <papid> W04-3212 </papid>palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>in addition, according to the conll-2005 shared task (carreras and mrquez, 2005), the performance of srl systems in general does not decline significantly when tagging out-of-domain corpora.
</nextsent>
<nextsent>for example, when srl systems trained on the wall street journal (wsj) corpus were used to tag the brown corpus, the performance only dropped by 15%, on average.
</nextsent>
<nextsent>in comparison to annotating from scratch, annotation efforts based on the results of an available srl system are much reduced.
</nextsent>
<nextsent>thus, we plan to use news wire srl system to tag biomedical corpus and then manually revise the tagging results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB300">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> the biomedical proposition bank -.  </section>
<citcontext>
<prevsection>
<prevsent>the text of the title and content is segmented into sentences, in which biological terms are annotated with their semantic classes.
</prevsent>
<prevsent>the genia corpus is also annotated with part-of-speech (pos) tags (tateisi and tsu jii, 2004), and co-references are added to part of the genia corpus by the medco project at the institute for info comm research, singapore (yang et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
the penn-style treebank for genia, created by tateisi et al (2005), <papid> I05-2038 </papid>currently contains 500 abstracts.</citsent>
<aftsection>
<nextsent>the annotation scheme of the genia treebank (gtb), which basically follows the penn treebank ii (ptb) scheme (bies et al, 1995), is encoded in xml.
</nextsent>
<nextsent>however, in contrast to the wsj corpus, genia lacks proposition bank.
</nextsent>
<nextsent>we therefore use its 500 abstracts with gtb as our corpus.
</nextsent>
<nextsent>to develop our biomedical proposition bank, bioprop, we add the proposition bank annotation on top of the gtb annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB302">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> annotation of bioprop.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 annotation process.
</prevsent>
<prevsent>after choosing 30 verbs as predicates, we adopted semi-automatic method to annotate bioprop.
</prevsent>
</prevsection>
<citsent citstr=" N03-4009 ">
the annotation process consists of the following steps: (1) identifying predicate candidates; (2) automatically annotating the biomedical semantic roles with our wsj srl system; (3) transforming the automatic tagging results into word freak (morton and lacivita, 2003) <papid> N03-4009 </papid>format; and (4) manually correcting the annotation results with the word freak annotation tool.</citsent>
<aftsection>
<nextsent>we now describe these steps in detail: verbs # in bioprop ratio(%) # in propbank ratio(%) induce 290 1.89 16 0.01 bind 252 1.64 0 0 activate 235 1.53 2 0 express 194 1.26 53 0.03 inhibit 184 1.20 6 0 increase 166 1.08 396 0.24 regulate 122 0.79 23 0.01 mediate 104 0.68 1 0 stimulate 93 0.61 11 0.01 associate 82 0.53 51 0.03 encode 79 0.51 0 0 affect 60 0.39 119 0.07 enhance 60 0.39 28 0.02 block 58 0.38 71 0.04 reduce 55 0.36 241 0.14 decrease 54 0.35 16 0.01 suppress 38 0.25 4 0 interact 36 0.23 0 0 alter 27 0.18 17 0.01 trans activate 24 0.16 0 0 modulate 22 0.14 1 0 phosphorylate 21 0.14 0 0 transform 21 0.14 22 0.01 differentiate 21 0.14 2 0 repress 17 0.11 1 0 prevent 15 0.10 92 0.05 promote 14 0.09 52 0.03 trigger 14 0.09 40 0.02 mutate 14 0.09 1 0 signal 10 0.07 31 0.02 table 3.
</nextsent>
<nextsent>the number and percentage of pass for each verb in bioprop and propbank 1.
</nextsent>
<nextsent>each word with vb pos tag in verb.
</nextsent>
<nextsent>phrase that matches any lexical variant of the 30 verbs is treated as predicate candidate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB303">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> effect of training corpora on srl.  </section>
<citcontext>
<prevsection>
<prevsent>it is an appositive of [several regions]; therefore, it should be annotated as part of arg1 in this case.
</prevsent>
<prevsent>systems to examine the possibility that bioprop can im prove the training of srl systems used for automatic tagging of biomedical texts, we compare the performance of systems trained on bio prop and propbank in different domains.
</prevsent>
</prevsection>
<citsent citstr=" W06-3308 ">
we construct new srl system (called biomedical semantic role labeler, biosmile) that is trained on bioprop and employs all the features used in our wsj srl system (tsai et al, 2006).<papid> W06-3308 </papid></citsent>
<aftsection>
<nextsent>as with pos tagging, chunking, and named entity recognition, srl can also be formulated as sentence tagging problem.
</nextsent>
<nextsent>a sentence can be represented by sequence of words, sequence of phrases, or parsing tree; the basic units of sentence in these representations are words, phrases, and constituents, respectively.
</nextsent>
<nextsent>hacioglu et al (2004) <papid> W04-2416 </papid>showed that tagging phrase-byphrase (p-by-p) is better than word-by-word (w by-w).</nextsent>
<nextsent>however, punyakanok et al (2004) <papid> C04-1197 </papid>showed that constituent-by-constituent (c-by-c) tagging is better than p-by-p.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB304">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> effect of training corpora on srl.  </section>
<citcontext>
<prevsection>
<prevsent>as with pos tagging, chunking, and named entity recognition, srl can also be formulated as sentence tagging problem.
</prevsent>
<prevsent>a sentence can be represented by sequence of words, sequence of phrases, or parsing tree; the basic units of sentence in these representations are words, phrases, and constituents, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
hacioglu et al (2004) <papid> W04-2416 </papid>showed that tagging phrase-byphrase (p-by-p) is better than word-by-word (w by-w).</citsent>
<aftsection>
<nextsent>however, punyakanok et al (2004) <papid> C04-1197 </papid>showed that constituent-by-constituent (c-by-c) tagging is better than p-by-p.</nextsent>
<nextsent>therefore, we use c-by-c tagging for srl in our biosmile.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB305">
<title id=" W06-0602.xml">a semiautomatic method for annotating a biomedical proposition bank </title>
<section> effect of training corpora on srl.  </section>
<citcontext>
<prevsection>
<prevsent>a sentence can be represented by sequence of words, sequence of phrases, or parsing tree; the basic units of sentence in these representations are words, phrases, and constituents, respectively.
</prevsent>
<prevsent>hacioglu et al (2004) <papid> W04-2416 </papid>showed that tagging phrase-byphrase (p-by-p) is better than word-by-word (w by-w).</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
however, punyakanok et al (2004) <papid> C04-1197 </papid>showed that constituent-by-constituent (c-by-c) tagging is better than p-by-p.</citsent>
<aftsection>
<nextsent>therefore, we use c-by-c tagging for srl in our biosmile.
</nextsent>
<nextsent>srl can be divided into two steps.
</nextsent>
<nextsent>first, we identify all the predicates.
</nextsent>
<nextsent>this can be easily accomplished by finding all instances of verbs of interest and checking their part-of-speech (pos) tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB306">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we propose an algorithm which ranks mwes by their compositionality relative to semantic field taxonomy based on the lancaster english semantic lexicon (piao et al , 2005a).
</prevsent>
<prevsent>the semantic information provided by the lexicon is used for measuring the semantic distance between mwe and its constituent words.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
the algorithm is evaluated both on 89 manually ranked mwes and on mccarthy et al (2003) <papid> W03-1810 </papid>manually ranked phrasal verbs.</citsent>
<aftsection>
<nextsent>we compared the output of our tool with human judgments using spear mans rank-order correlation coefficient.
</nextsent>
<nextsent>our evaluation shows that the automatic ranking of the majority of our test data (86.52%) has strong to moderate correlation with the manual ranking while wide discrepancy is found for small number of mwes.
</nextsent>
<nextsent>our algorithm also obtained correlation of 0.3544 with manual ranking on mccarthy et al test data, which is comparable or better than most of the measures they tested.
</nextsent>
<nextsent>this experiment demonstrates that semantic lexicon can assist in mwe compositionality measurement in addition to statistical algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB307">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this experiment demonstrates that semantic lexicon can assist in mwe compositionality measurement in addition to statistical algorithms.
</prevsent>
<prevsent>over the past few years, compositionality and decomposability of mwes have become important issues in nlp research.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
lin (1999) <papid> P99-1041 </papid>argues that non-compositional expressions need to be treated differently than other phrases in many statistical or corpus based nlp methods?.</citsent>
<aftsection>
<nextsent>com positionality means that the meaning of the whole can be strictly predicted from the meaning of the parts?
</nextsent>
<nextsent>(manning &amp; schtze, 2000).
</nextsent>
<nextsent>on the other hand, decomposability is metric of the degree to which the meaning of mwe can be assigned to its parts (nunberg, 1994; riehemann, 2001; sag et al , 2002).
</nextsent>
<nextsent>these two concepts are closely related.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB309">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, decomposability is metric of the degree to which the meaning of mwe can be assigned to its parts (nunberg, 1994; riehemann, 2001; sag et al , 2002).
</prevsent>
<prevsent>these two concepts are closely related.
</prevsent>
</prevsection>
<citsent citstr=" H05-1113 ">
venkatapathy and joshi (2005) <papid> H05-1113 </papid>suggest that an expression is likely to be relatively more compositional if it is decomposable?.</citsent>
<aftsection>
<nextsent>while there exist various definitions for mwes, they are generally defined as cohesive lexemes that cross word boundaries (sag et al , 2002; copestake et al , 2002; calzolari et al , 2002; baldwin et al , 2003), <papid> W03-1812 </papid>which include nominal compounds, phrasal verbs, idioms, collocations etc. compositionality is critical criterion cutting across different definitions forex tracting and classifying mwes.</nextsent>
<nextsent>while semantics of certain types of mwes are non-compositional, like idioms kick the bucket?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB311">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these two concepts are closely related.
</prevsent>
<prevsent>venkatapathy and joshi (2005) <papid> H05-1113 </papid>suggest that an expression is likely to be relatively more compositional if it is decomposable?.</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
while there exist various definitions for mwes, they are generally defined as cohesive lexemes that cross word boundaries (sag et al , 2002; copestake et al , 2002; calzolari et al , 2002; baldwin et al , 2003), <papid> W03-1812 </papid>which include nominal compounds, phrasal verbs, idioms, collocations etc. compositionality is critical criterion cutting across different definitions forex tracting and classifying mwes.</citsent>
<aftsection>
<nextsent>while semantics of certain types of mwes are non-compositional, like idioms kick the bucket?
</nextsent>
<nextsent>and hot dog?, some others can have highly compositional semantics like the expressions traffic light?
</nextsent>
<nextsent>and audio tape?.
</nextsent>
<nextsent>automatic measurement of mwe composi tionality can have number of applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB312">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and audio tape?.
</prevsent>
<prevsent>automatic measurement of mwe composi tionality can have number of applications.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
one of the often quoted applications is for machine translation (melamed, 1997; <papid> W97-0311 </papid>hwang &amp; sasaki, 2005), in which non-compositional mwes need special treatment.</citsent>
<aftsection>
<nextsent>for instance, the translation of highly compositional mwe can possibly be inferred from the translations of its constituent words, whereas it is impossible for non compositional mwes, for which we need to identify the translation equivalent for the mwes as whole.
</nextsent>
<nextsent>in this paper, we explore new method of automatically estimating the compositionality of mwes using lexical semantic information, sourced from the lancaster semantic lexicon (piao et al , 2005a) that is employed in the usas1 tagger (rayson et al , 2004).
</nextsent>
<nextsent>this is 1 ucrel semantic analysis system.
</nextsent>
<nextsent>2 large lexical resource which contains nearly 55,000 single-word entries and over 18,800 mwe entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB315">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one of the earliest studies in this area was reported by lin (1999) <papid> P99-1041 </papid>who assumes that non compositional phrases have significantly different mutual information value than the phrases that are similar to their literal meanings?</prevsent>
<prevsent>and proposed to identify non-compositional mwes in corpus based on distributional characteristics of mwes.</prevsent>
</prevsection>
<citsent citstr=" W03-1809 ">
bannard et al  (2003) <papid> W03-1809 </papid>tested techniques using statistical models to infer the meaning of verb-particle constructions (vpcs), focus 2 in this lexicon, many mwes are encoded as templates,.</citsent>
<aftsection>
<nextsent>such as driv*_* {np/p*/j*/r*} mad_jj, which represent variational forms of single mwe, for further details, see rayson et al , 2004.
</nextsent>
<nextsent>ing on prepositional particles.
</nextsent>
<nextsent>they tested four methods over four compositional classification tasks, reporting that, on all tasks, at least one of the four methods offers an improvement in precision over the baseline they used.
</nextsent>
<nextsent>mccarthy et al  (2003) <papid> W03-1810 </papid>suggested that compositional phrasal verbs should have similar neighbours as for their simplex verbs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB322">
<title id=" W06-1202.xml">measuring mwe compositionality using semantic annotation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a limitation of our approach is language dependency.
</prevsent>
<prevsent>in order to port our algorithm to languages other than english, one needs to build similar semantic lexicon in those languages.
</prevsent>
</prevsection>
<citsent citstr=" E06-2014 ">
however, similar semantic lexical resources are already under construction for some other languages, including finnish and russian (lfberg et al , 2005; sharoff et al , 2006), <papid> E06-2014 </papid>which will allow us to port our algorithm to those languages.</citsent>
<aftsection>
<nextsent>in this paper, we explored an algorithm based on semantic lexicon for automatically measuring the compositionality of mwes.
</nextsent>
<nextsent>in our evaluation, the output of this algorithm showed moderate correlation with manual ranking.
</nextsent>
<nextsent>we claim that semantic lexical resources provide another approach for automatically measuring mwe compositionality in addition to the existing statistical algorithms.
</nextsent>
<nextsent>although our results are not yet conclusive due to the moderate scale of the test data, our evaluation demonstrates the potential of lexicon-based approaches for the task of compositional analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB323">
<title id=" W05-0831.xml">novel reordering approaches in phrase based statistical machine translation </title>
<section> reordering in training.  </section>
<citcontext>
<prevsection>
<prevsent>we suggest the following consistent source sentence reordering and alignment monotonization approach inwhich we compute optimal, minimum-cost align ments.first, we estimate cost matrix for each sentence pair (fj1 , ei1).
</prevsent>
<prevsent>the elements of this matrix cij are the local costs of aligning source word fj to target word ei.
</prevsent>
</prevsection>
<citsent citstr=" C04-1032 ">
following (matusov et al, 2004), <papid> C04-1032 </papid>we compute these local costs by interpol ating state occupation probabilities from the source-to-target and target-to-source training of the hmm and ibm-4 models as trained by the giza++ toolkit (och et al, 2003).</citsent>
<aftsection>
<nextsent>forgiven alignment ? ? , we define the costs of this alignment c(a) as the sum of the local costs of all aligned word pairs: c(a) = ?
</nextsent>
<nextsent>(i,j)a cij (1) the goal is to find an alignment with the minimum costs which fulfills certain constraints.
</nextsent>
<nextsent>3.1 source sentence reordering.
</nextsent>
<nextsent>to reorder source sentence, we require the alignment to be function of source words a1: {1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB324">
<title id=" W05-0831.xml">novel reordering approaches in phrase based statistical machine translation </title>
<section> reordering in search.  </section>
<citcontext>
<prevsection>
<prevsent>note, that the local constraints define true subset of the permutations defined by the ibm constraints.
</prevsent>
<prevsent>4.5 itg constraints.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
another type of reordering can be obtained using inversion transduction grammars (itg) (wu, 1997).<papid> J97-3002 </papid>these constraints are inspired by bilingual bracket ing.</citsent>
<aftsection>
<nextsent>they proved to be quite useful for machine translation, e.g. see (bender et al, 2004).
</nextsent>
<nextsent>here,we interpret the input sentence as sequence of segments.
</nextsent>
<nextsent>in the beginning, each word is segment ofits own.
</nextsent>
<nextsent>longer segments are constructed by recursively combining two adjacent segments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB325">
<title id=" W05-0831.xml">novel reordering approaches in phrase based statistical machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the 500 sentence chinese and japanese test sets of the iwslt 2004 evaluation campaign were translated and automatically scored against 16 reference translations after the end of the campaign using the iwslt evaluation server.
</prevsent>
<prevsent>5.2 evaluation criteria.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for the automatic evaluation, we used the criteria from the iwslt evaluation campaign (akiba etal., 2004), namely word error rate (wer), position independent word error rate (per), and the bleu and nist scores (papineni et al, 2002; <papid> P02-1040 </papid>doddington, 2002).</citsent>
<aftsection>
<nextsent>the two scores measure accuracy, i. e. larger scores are better.
</nextsent>
<nextsent>the error rates and scores we recomputed with respect to multiple reference transla 171 40 42 44 46 48 50 52 54 56 58 60 1 2 3 4 5 6 7 8 9 reordering constraints window size inv-ibmibmitglocal 46 47 48 49 50 51 52 53 54 55 1 2 3 4 5 6 7 8 9 reordering constraints window size inv-ibmibmitglocal figure 3: word error rate [%] as function of the reordering window size for different reordering constraints: japanese-to-english (left) and chinese-to-english (right) translation.
</nextsent>
<nextsent>tions, when they were available.
</nextsent>
<nextsent>to indicate this, we will label the error rate acronyms with an m. both training and evaluation were performed using corpora and references in lowercase and without punctuation marks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB326">
<title id=" W06-1312.xml">an annotation scheme for citation function </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>our citation parser then applies regular patterns and finds citations and other occurrences of the names of cited authors (without date) in running text and marks them up.
</prevsent>
<prevsent>self-citations are detected by overlap of citing and cited authors.
</prevsent>
</prevsection>
<citsent citstr=" N06-1050 ">
the citation processor deve lopped in our group (ritchie et al , 2006) <papid> N06-1050 </papid>achieves high accuracy for this task (96% of citations recognized, provided the reference list was error-free).</citsent>
<aftsection>
<nextsent>on average, our papers contain 26.8 citation instances in running text4.
</nextsent>
<nextsent>in order to machine learn citation function, we arein the process of creating corpus of scientific articles with human annotated citations, according to the scheme discussed before.
</nextsent>
<nextsent>here we report preliminary results with that scheme, with three annotators who are developers of the scheme.in our experiment, the annotators independently annotated 26 conference articles with this scheme, on the basis of guidelines which were frozen once annotation started5.
</nextsent>
<nextsent>the data used for the experiment contained total of 120,000 running words and 548 citations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB327">
<title id=" W06-1312.xml">an annotation scheme for citation function </title>
<section> human annotation: results.  </section>
<citcontext>
<prevsection>
<prevsent>this is in concordance with earlier annotation experiments (moravcsik and murugesan, 1975; spiegel-rusing, 1977).
</prevsent>
<prevsent>we reached an inter-annotator agreement of k=.72 (n=12;n=548;k=3)7.
</prevsent>
</prevsection>
<citsent citstr=" E99-1015 ">
this is comparable to aggreement on other discourse annotation tasks such as dialogue act parsing and argumentative zoning (teufel et al ,1999).<papid> E99-1015 </papid></citsent>
<aftsection>
<nextsent>we consider the agreement quite good, considering the number of categories and the difficulties (e.g., non-local dependencies) of the task.
</nextsent>
<nextsent>the annotators are obviously still disagreeing onsome categories.
</nextsent>
<nextsent>we were wondering to what degree the fine granularity of the scheme is problem.
</nextsent>
<nextsent>when we collapsed the obvious similar categories (all categories into one category, and all coco categories into another) to give four top level categories (weak, positive, contrast, neutral), this only raised kappa to 0.76.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB328">
<title id=" W06-1312.xml">an annotation scheme for citation function </title>
<section> human annotation: results.  </section>
<citcontext>
<prevsection>
<prevsent>when we collapsed the obvious similar categories (all categories into one category, and all coco categories into another) to give four top level categories (weak, positive, contrast, neutral), this only raised kappa to 0.76.
</prevsent>
<prevsent>this 4as opposed to reference list items, which are fewer.5the development of the scheme was done with 40+ different articles.6spiegel-rusing found that out of 2309 citations she examined, 80% substantiated statements.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
7following carletta (1996), <papid> J96-2004 </papid>we measure agreement in kappa, which follows the formula = (a)p (e)1p (e) wherep(a) is observed, and p(e) expected agreement.</citsent>
<aftsection>
<nextsent>kappa ranges between -1 and 1.
</nextsent>
<nextsent>k=0 means agreement is only as expected by chance.
</nextsent>
<nextsent>generally, kappas of 0.8 are considered stable, and kappas of .69 as marginally stable, according to the strictest scheme applied in the field.
</nextsent>
<nextsent>84 neut puse cocogm psim weak cocoxy pmot pmodi pbas psup coco- cocor0 62.7% 15.8% 3.9% 3.8% 3.1% 2.9% 2.2% 1.6% 1.5% 1.1% 1.0% 0.8% figure 5: distribution of the categories weak coco- cocogm cocor0 cocoxy puse pbas pmodi pmot psim psup neut weak 5 3 coco- 1 3 cocogm 23 3 cocor0 4 cocoxy 1 puse 86 6 2 1 12 pbas 3 2 pmodi 3 pmot 13 4 psim 3 20 5 psup 1 2 1 neut 6 10 6 4 17 1 6 4 287 figure 6: confusion matrix between two annotators points to the fact that most of our annotators disagreed about whether to assign more informative category or neut, the neutral fall-back category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB329">
<title id=" W06-1312.xml">an annotation scheme for citation function </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>here, we report positive results in terms of inter annotator agreement.future work on the annotation scheme will concentrate on improving guidelines for currently suboptimalcategories, and on measuring intra-annotator agreement and inter-annotator agreement with naive annotators.
</prevsent>
<prevsent>we are also currently investigating how well our scheme will work on text from different discipline, namely chemistry.
</prevsent>
</prevsection>
<citsent citstr=" W06-1613 ">
work on applying machine learning techniques for automatic citation classification is currently underway (teufel et al , 2006); <papid> W06-1613 </papid>the agreement of one annotator and the system is currently k=.57, leaving plenty of room for improvement in comparison with the human annotation results presented here.</citsent>
<aftsection>
<nextsent>this work was funded by the epsrc projects citraz (gr/s27832/01, rhetorical citation maps and domain-independent argumentative zoning?)
</nextsent>
<nextsent>and sciborg (ep/c010035/1, extracting the science from scientific publications?).
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB330">
<title id=" W06-1110.xml">towards case based parsing are chunks reliable indicators for syntax trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>linguistic similarity has often been used as bias in machine learning approaches to computational linguistics problems.
</prevsent>
<prevsent>the success of applying memory-based learning to problems such as pos tagging, named-entity recognition, partial parsing, or word sense disambiguation (cf.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
(daelemans et al ., 1996; <papid> W96-0102 </papid>daelemans et al , 1999; mooney, 1996; <papid> W96-0208 </papid>tjong kim sang, 2002; veenstra et al , 2000))shows that the bias of this similarity-based approach is suitable for processing natural language problems.</citsent>
<aftsection>
<nextsent>in (kubler, 2004a; kubler, 2004b), we extended the application of memory-based learning to full scale parsing, problem which cannot easily be described as classification problem.
</nextsent>
<nextsent>in this approach, the most similar sentence is found in the training data, and the respective syntax tree is then adapted to the input sentence.
</nextsent>
<nextsent>the parser was developed for parsing german dialog data, and it is based on the observation that dialogs tend to be repetitive in their structure.
</nextsent>
<nextsent>thus, there is higher than normal probability of finding the same or very similar sentence in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB331">
<title id=" W06-1110.xml">towards case based parsing are chunks reliable indicators for syntax trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>linguistic similarity has often been used as bias in machine learning approaches to computational linguistics problems.
</prevsent>
<prevsent>the success of applying memory-based learning to problems such as pos tagging, named-entity recognition, partial parsing, or word sense disambiguation (cf.
</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
(daelemans et al ., 1996; <papid> W96-0102 </papid>daelemans et al , 1999; mooney, 1996; <papid> W96-0208 </papid>tjong kim sang, 2002; veenstra et al , 2000))shows that the bias of this similarity-based approach is suitable for processing natural language problems.</citsent>
<aftsection>
<nextsent>in (kubler, 2004a; kubler, 2004b), we extended the application of memory-based learning to full scale parsing, problem which cannot easily be described as classification problem.
</nextsent>
<nextsent>in this approach, the most similar sentence is found in the training data, and the respective syntax tree is then adapted to the input sentence.
</nextsent>
<nextsent>the parser was developed for parsing german dialog data, and it is based on the observation that dialogs tend to be repetitive in their structure.
</nextsent>
<nextsent>thus, there is higher than normal probability of finding the same or very similar sentence in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB332">
<title id=" W06-1110.xml">towards case based parsing are chunks reliable indicators for syntax trees </title>
<section> a memory-based parser </section>
<citcontext>
<prevsection>
<prevsent>functions) 71.72% labeled precision (incl.
</prevsent>
<prevsent>gramm.
</prevsent>
</prevsection>
<citsent citstr=" C02-1131 ">
functions) 75.79% f  73.70 table 1: results for the memory-based parser (kubler, 2004a; kubler, 2004b) and karopars (muller and ule, 2002; <papid> C02-1131 </papid>muller, 2005).</citsent>
<aftsection>
<nextsent>the evaluation of karopars is based on chunk annotations only.
</nextsent>
<nextsent>parser employs similar strategy to the one in data-oriented parsing (dop) (bod, 1998; scha et al ., 1999).
</nextsent>
<nextsent>both parsers use larger tree fragments than the standard trees.
</nextsent>
<nextsent>the two approaches differ mainly in two respects: 1) dop allows different tree fragments to be extracted from one tree, thus making different combinations of fragments available for the assembly of specific tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB335">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental results with the penn treebank corpus show that our chunk parser can give high-precision parsing outputs with very high speed (14msec/sentence).
</prevsent>
<prevsent>we also present parsing method for searching the best parse by considering the probabilities output by the maximum entropy classifiers, and show that the search method can further im prove the parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" E99-1016 ">
chunk parsing (tjong kim sang, 2001; brants,1999) <papid> E99-1016 </papid>is simple parsing strategy both in implementation and concept.</citsent>
<aftsection>
<nextsent>the parser first performs chunking by identifying base phrases, and convert the identified phrases to non-terminal symbols.
</nextsent>
<nextsent>the parser again performs chunking on the updated sequence and convert the newly recognized phrases into non-terminal symbols.
</nextsent>
<nextsent>the parser repeats this procedure until there are no phrases to be chunked.
</nextsent>
<nextsent>after finishing these chunking processes, we can reconstruct the complete parse tree of the sentence from the chunking results.although the conceptual simplicity of chunk parsing is appealing, satisfactory performance for practical use has not yet been achieved with this parsing strategy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB336">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parser repeats this procedure until there are no phrases to be chunked.
</prevsent>
<prevsent>after finishing these chunking processes, we can reconstruct the complete parse tree of the sentence from the chunking results.although the conceptual simplicity of chunk parsing is appealing, satisfactory performance for practical use has not yet been achieved with this parsing strategy.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
sang achieved an f-score of 80.49 on the penn treebank by using the iob tagging method for each level of chunking (tjong kim sang, 2001).however, there is very large gap between their performance and that of widely-used practical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999).the performance of chunk parsing is heavily dependent on the performance of phrase recognition in each level of chunking.</citsent>
<aftsection>
<nextsent>we show in this paper that the chunk parsing strategy is indeed appealing in thatit can give considerably better performance than previously reported by using different approach for phrase recognition and that it enables us to build very fast parser that gives high-precision outputs.
</nextsent>
<nextsent>this advantage could open up the possibility ofusing full parsers for large-scale information extraction from the web corpus and real-time information extraction where the system needs to analyze the documents provided by the users on run-time.
</nextsent>
<nextsent>this paper is organized as follows.
</nextsent>
<nextsent>section 2introduces the overall chunk parsing strategy employed in this work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB337">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> chunk parsing.  </section>
<citcontext>
<prevsection>
<prevsent>figures 1 to 4 show an example of chunk parsing.
</prevsent>
<prevsent>in the first iteration, the chunker identifies two base phrases, (np estimated volume) and (qp2.4 million), and replaces each phrase with its nonterminal symbol and head.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
the head word is identified by using the head-percolation table (magerman, 1995).<papid> P95-1037 </papid></citsent>
<aftsection>
<nextsent>in the second iteration, the chunker identifies (np light million ounces) and converts this phrase into np.
</nextsent>
<nextsent>this chunking procedure is repeated until the whole sentence is chunked at the fourth iteration, and the full parse tree is easily recovered from the chunking history.
</nextsent>
<nextsent>this parsing strategy converts the problem of full parsing into smaller and simpler problems, namely, chunking, where we only need to recognize flat structures (base phrases).
</nextsent>
<nextsent>sang used the iob tagging method proposed by ramshow(ramshaw and marcus, 1995) <papid> W95-0107 </papid>and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the penn treebank corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB338">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> chunk parsing.  </section>
<citcontext>
<prevsection>
<prevsent>this chunking procedure is repeated until the whole sentence is chunked at the fourth iteration, and the full parse tree is easily recovered from the chunking history.
</prevsent>
<prevsent>this parsing strategy converts the problem of full parsing into smaller and simpler problems, namely, chunking, where we only need to recognize flat structures (base phrases).
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
sang used the iob tagging method proposed by ramshow(ramshaw and marcus, 1995) <papid> W95-0107 </papid>and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the penn treebank corpus.</citsent>
<aftsection>
<nextsent>approach the performance of chunk parsing heavily depends on the performance of each level of chunking.
</nextsent>
<nextsent>the popular approach to this shallow parsing is to convert the problem into tagging task and use variety volume was ounces . np vbd np . vp figure 3: chunk parsing, the 3rd iteration.
</nextsent>
<nextsent>volume was . np vp . figure 4: chunk parsing, the 4th iteration.of machine learning techniques that have been developed for sequence labeling problems such as hidden markov models, sequential classification with svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>and conditional random fields (sha and pereira, 2003).<papid> N03-1028 </papid></nextsent>
<nextsent>one of our claims in this paper is that we should not convert the chunking problem into tagging task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB339">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> chunking with sliding-window.  </section>
<citcontext>
<prevsection>
<prevsent>approach the performance of chunk parsing heavily depends on the performance of each level of chunking.
</prevsent>
<prevsent>the popular approach to this shallow parsing is to convert the problem into tagging task and use variety volume was ounces . np vbd np . vp figure 3: chunk parsing, the 3rd iteration.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
volume was . np vp . figure 4: chunk parsing, the 4th iteration.of machine learning techniques that have been developed for sequence labeling problems such as hidden markov models, sequential classification with svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>and conditional random fields (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>one of our claims in this paper is that we should not convert the chunking problem into tagging task.
</nextsent>
<nextsent>instead, we use classical sliding-windowmethod for chunking, where we consider all sub sequences as phrase candidates and classify them with machine learning algorithm.
</nextsent>
<nextsent>suppose, for example, we are about to perform chunking on these quence in figure 4.
</nextsent>
<nextsent>np-volume vbd-was .-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB340">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> chunking with sliding-window.  </section>
<citcontext>
<prevsection>
<prevsent>approach the performance of chunk parsing heavily depends on the performance of each level of chunking.
</prevsent>
<prevsent>the popular approach to this shallow parsing is to convert the problem into tagging task and use variety volume was ounces . np vbd np . vp figure 3: chunk parsing, the 3rd iteration.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
volume was . np vp . figure 4: chunk parsing, the 4th iteration.of machine learning techniques that have been developed for sequence labeling problems such as hidden markov models, sequential classification with svms (kudo and matsumoto, 2001), <papid> N01-1025 </papid>and conditional random fields (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>one of our claims in this paper is that we should not convert the chunking problem into tagging task.
</nextsent>
<nextsent>instead, we use classical sliding-windowmethod for chunking, where we consider all sub sequences as phrase candidates and classify them with machine learning algorithm.
</nextsent>
<nextsent>suppose, for example, we are about to perform chunking on these quence in figure 4.
</nextsent>
<nextsent>np-volume vbd-was .-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB341">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> filtering with the cfg rule dictionary.  </section>
<citcontext>
<prevsection>
<prevsent>one is done by rule dictionary.
</prevsent>
<prevsent>the other is done by naive bayes classifier.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we use an idea that is similar to the method proposed by ratnaparkhi (ratnaparkhi, 1996) <papid> W96-0213 </papid>for part of-speech tagging.</citsent>
<aftsection>
<nextsent>they used tag dictionary, with which the tagger considers only the tag-word pairs that appear in the training sentences as the candidate tags.
</nextsent>
<nextsent>a similar method can be used for reducing the number of phrase candidates.
</nextsent>
<nextsent>we first construct rule dictionary consisting of all the cfg rules used in the training data.
</nextsent>
<nextsent>in both training and parsing, we filter out all the sub-sequences that do not match any of the entry in the dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB342">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> phrase recognition with maximum.  </section>
<citcontext>
<prevsection>
<prevsent>we set the threshold probability for filtering to be 0.0001 for the experiments reported in this paper.
</prevsent>
<prevsent>the naive bayes classifiers effectively reduced the number of candidates with little positive samples that were wrongly filtered out.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
entropy classifier for the candidates which are not filtered out in the above two phases, we perform classification with maximum entropy classifiers (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>we construct binary classifier for each type of phrases using the entire training set.
</nextsent>
<nextsent>the training samples for maximum entropy consist of the phrase candidates that have not been filtered out by the cfg rule dictionary and the naive bayes classifier.
</nextsent>
<nextsent>one of the merits of using maximum entropy classifier is that we can obtain probability from the classifier in each decision.
</nextsent>
<nextsent>the probability of each decision represents how likely the candidate is correct chunk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB343">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> phrase recognition with maximum.  </section>
<citcontext>
<prevsection>
<prevsent>we accept chunk only when the probability is larger than the predefined threshold.
</prevsent>
<prevsent>with this thresholding scheme, we can control the trade-off between precision and recall by changing the threshold value.
</prevsent>
</prevsection>
<citsent citstr=" W03-1018 ">
regularization is important in maximum entropy modeling to avoid over fitting to the training data.for this purpose, we use the maximum entropy modeling with inequality constraints (kazama and tsu jii, 2003).<papid> W03-1018 </papid></citsent>
<aftsection>
<nextsent>this modeling has one parameter totune as in gaussian prior modeling.
</nextsent>
<nextsent>the parameter is called the width factor.
</nextsent>
<nextsent>we set this parameter to be 1.0 throughout the experiments.
</nextsent>
<nextsent>for numerical optimization, we used the limited-memory variable-metric (lmvm) algorithm (benson and more?, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB344">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> searching the best parse.  </section>
<citcontext>
<prevsection>
<prevsent>we generate alternative hypotheses in each levelof chunking, and search the best parse indepth first manner.
</prevsent>
<prevsent>7.3 iterative parsing.
</prevsent>
</prevsection>
<citsent citstr=" W05-1511 ">
we also tried an iterative parsing strategy, which was successfully used in probabilistic hpsg parsing (ninomiya et al, 2005).<papid> W05-1511 </papid></citsent>
<aftsection>
<nextsent>the parsing strategy is simple.
</nextsent>
<nextsent>the parser starts with very low margin and tries to find successful parse.
</nextsent>
<nextsent>if the parser cannot find successful parse, then it increases the margin by certain step and tries to parse with the wider margin.
</nextsent>
<nextsent>137
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB345">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>8.2 comparison with previous work.
</prevsent>
<prevsent>table 6 summarizes our parsing performance on section 23 together with the results of previous studies.
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
in order to make the results directly comparable, we produced pos tags as the input of our parsers by using pos tagger (tsuruoka and tsujii, 2005) <papid> H05-1059 </papid>which was trained on sections 0-18 in the wsj corpus.</citsent>
<aftsection>
<nextsent>the table also shows the performance achieved 138 65 70 75 80 85 90 0 50 100 150 200 250 300 350 400 450 500f sc or time (sec) chunk parser collins parser figure 6: time vs f-score on section 23.
</nextsent>
<nextsent>the axis represents the time required to parse the entire section.
</nextsent>
<nextsent>the time required for making hash table in collins parser is excluded.
</nextsent>
<nextsent>lr lp f-score ratnaparkhi (1997) <papid> W97-0301 </papid>86.3 87.5 86.9 collins (1999) 88.1 88.3 88.2 charniak (2000) <papid> A00-2018 </papid>89.6 89.5 89.5 kudo (2005) 89.3 89.6 89.4 sang (2001) 78.7 82.3 80.5 deterministic (tagger-poss) 81.2 86.5 83.8 deterministic (gold-poss) 82.6 87.7 85.1 search (tagger-poss) 83.2 87.1 85.1 search (gold-poss) 84.6 88.5 86.5 iterative search (tagger-poss) 85.0 86.8 85.9 iterative search (gold-poss) 86.2 88.0 87.1table 6: comparison with other work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB346">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the axis represents the time required to parse the entire section.
</prevsent>
<prevsent>the time required for making hash table in collins parser is excluded.
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
lr lp f-score ratnaparkhi (1997) <papid> W97-0301 </papid>86.3 87.5 86.9 collins (1999) 88.1 88.3 88.2 charniak (2000) <papid> A00-2018 </papid>89.6 89.5 89.5 kudo (2005) 89.3 89.6 89.4 sang (2001) 78.7 82.3 80.5 deterministic (tagger-poss) 81.2 86.5 83.8 deterministic (gold-poss) 82.6 87.7 85.1 search (tagger-poss) 83.2 87.1 85.1 search (gold-poss) 84.6 88.5 86.5 iterative search (tagger-poss) 85.0 86.8 85.9 iterative search (gold-poss) 86.2 88.0 87.1table 6: comparison with other work.</citsent>
<aftsection>
<nextsent>parsing performance on section 23 (all sentences).with the iterative parsing method presented in section 7.3.
</nextsent>
<nextsent>our chunk parser achieved an f-score of 83.8 with the deterministic parsing methods using the pos-tagger tags.
</nextsent>
<nextsent>this f-score is better than that achieved by the previous study on chunk parsing by3.3 points (tjong kim sang, 2001).
</nextsent>
<nextsent>the search algorithms gave an additional 1.3 point improvement.finally, the iterative parsing method achieved an score of 85.9.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB348">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>additional feature sets for the maximum entropy classifiers could improve the performance.
</prevsent>
<prevsent>thebottom-up parsing strategy allows us to use information about sub-trees that have already been constructed.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
we thus do not need to restrict ourselves to use only head-information of the partial parses.since many researchers have reported that information on partial parse trees plays an important role for achieving high performance (bod, 1992; collins and duffy, 2002; <papid> P02-1034 </papid>kudo et al, 2005), <papid> P05-1024 </papid>we expect that additional features will improve the performance of chunk parsing.</citsent>
<aftsection>
<nextsent>also, the methods for searching the best parse presented in sections 7.2 and 7.3 have much room for improvement.
</nextsent>
<nextsent>the search method does not have the device to avoid repetitive computations on the same nonterminal sequence in parsing.
</nextsent>
<nextsent>a chart-like structure which effectively stores the partial parse results could enable the parser to explore broader search space and produce better parses.our chunk parser exhibited considerable improvement in parsing accuracy over the previous study on chunk parsing.
</nextsent>
<nextsent>however, the reason is not completely clear.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB349">
<title id=" W05-1514.xml">chunk parsing revisited </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>additional feature sets for the maximum entropy classifiers could improve the performance.
</prevsent>
<prevsent>thebottom-up parsing strategy allows us to use information about sub-trees that have already been constructed.
</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
we thus do not need to restrict ourselves to use only head-information of the partial parses.since many researchers have reported that information on partial parse trees plays an important role for achieving high performance (bod, 1992; collins and duffy, 2002; <papid> P02-1034 </papid>kudo et al, 2005), <papid> P05-1024 </papid>we expect that additional features will improve the performance of chunk parsing.</citsent>
<aftsection>
<nextsent>also, the methods for searching the best parse presented in sections 7.2 and 7.3 have much room for improvement.
</nextsent>
<nextsent>the search method does not have the device to avoid repetitive computations on the same nonterminal sequence in parsing.
</nextsent>
<nextsent>a chart-like structure which effectively stores the partial parse results could enable the parser to explore broader search space and produce better parses.our chunk parser exhibited considerable improvement in parsing accuracy over the previous study on chunk parsing.
</nextsent>
<nextsent>however, the reason is not completely clear.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB350">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental results on the msr paraphrase corpus show that, even in the absence of any thesaurus to accommodate lexical variation between the paraphrases, an un interpolated average precision of at least 76% is obtainable from the bracketing itgs structure matching bias alone.
</prevsent>
<prevsent>this is consistent with experimental results on the pascal recognising textual entailment challenge corpus, which show surpisingly strong results for number of the task subsets.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the inversion transduction grammar or itg formalism,which historically was developed in the context of translation and alignment, hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments (wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>the itg hypothesis has been more extensively studied across different languages, but newly available paraphrase datasets provide intriguing opportu1the author would like to thank the hongkong research grants council (rgc) for supporting this research in part through grants rgc6083/99e, rgc6256/00e, anddag03/04.eg09, and marine carpuat and yihai shen for invaluable assistance in preparing the datasets and stoplist.
</nextsent>
<nextsent>nities for meaningful analysis of the itg hypothesis in monolingual setting.the strong inductive bias imposed by the itg hypothesis has been repeatedly shown empirically to yield both efficiency and accuracy gains for numerous language acquisition tasks, across variety of language pairs and tasks.
</nextsent>
<nextsent>for example, zens and ney (2003) <papid> P03-1019 </papid>show thatitg constraints yield significantly better alignment coverage than the constraints used in ibm statistical machine translation models on both german-english (verb mobil corpus) and french-english (canadian hansardscorpus).</nextsent>
<nextsent>zhang and gildea (2004) <papid> C04-1060 </papid>find that unsupervised alignment using bracketing itgs produces significantly lower chinese-english alignment error rates than syntactically supervised tree-to-string model (yamada and knight, 2001).<papid> P01-1067 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB351">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the itg hypothesis has been more extensively studied across different languages, but newly available paraphrase datasets provide intriguing opportu1the author would like to thank the hongkong research grants council (rgc) for supporting this research in part through grants rgc6083/99e, rgc6256/00e, anddag03/04.eg09, and marine carpuat and yihai shen for invaluable assistance in preparing the datasets and stoplist.
</prevsent>
<prevsent>nities for meaningful analysis of the itg hypothesis in monolingual setting.the strong inductive bias imposed by the itg hypothesis has been repeatedly shown empirically to yield both efficiency and accuracy gains for numerous language acquisition tasks, across variety of language pairs and tasks.
</prevsent>
</prevsection>
<citsent citstr=" P03-1019 ">
for example, zens and ney (2003) <papid> P03-1019 </papid>show thatitg constraints yield significantly better alignment coverage than the constraints used in ibm statistical machine translation models on both german-english (verb mobil corpus) and french-english (canadian hansardscorpus).</citsent>
<aftsection>
<nextsent>zhang and gildea (2004) <papid> C04-1060 </papid>find that unsupervised alignment using bracketing itgs produces significantly lower chinese-english alignment error rates than syntactically supervised tree-to-string model (yamada and knight, 2001).<papid> P01-1067 </papid></nextsent>
<nextsent>with regard to translation rather than alignment accuracy, zens et al  (2004) <papid> C04-1030 </papid>show that decoding under itg constraints yields significantly lower word error rates and bleu scores than the ibm constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB352">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nities for meaningful analysis of the itg hypothesis in monolingual setting.the strong inductive bias imposed by the itg hypothesis has been repeatedly shown empirically to yield both efficiency and accuracy gains for numerous language acquisition tasks, across variety of language pairs and tasks.
</prevsent>
<prevsent>for example, zens and ney (2003) <papid> P03-1019 </papid>show thatitg constraints yield significantly better alignment coverage than the constraints used in ibm statistical machine translation models on both german-english (verb mobil corpus) and french-english (canadian hansardscorpus).</prevsent>
</prevsection>
<citsent citstr=" C04-1060 ">
zhang and gildea (2004) <papid> C04-1060 </papid>find that unsupervised alignment using bracketing itgs produces significantly lower chinese-english alignment error rates than syntactically supervised tree-to-string model (yamada and knight, 2001).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>with regard to translation rather than alignment accuracy, zens et al  (2004) <papid> C04-1030 </papid>show that decoding under itg constraints yields significantly lower word error rates and bleu scores than the ibm constraints.</nextsent>
<nextsent>we are conducting series of investigations motivated by the following observation: the empirically demonstrated suitability of itg paraphrasing constraints across languages should hold, if anything, even more strongly in the monolingual case.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB353">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nities for meaningful analysis of the itg hypothesis in monolingual setting.the strong inductive bias imposed by the itg hypothesis has been repeatedly shown empirically to yield both efficiency and accuracy gains for numerous language acquisition tasks, across variety of language pairs and tasks.
</prevsent>
<prevsent>for example, zens and ney (2003) <papid> P03-1019 </papid>show thatitg constraints yield significantly better alignment coverage than the constraints used in ibm statistical machine translation models on both german-english (verb mobil corpus) and french-english (canadian hansardscorpus).</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
zhang and gildea (2004) <papid> C04-1060 </papid>find that unsupervised alignment using bracketing itgs produces significantly lower chinese-english alignment error rates than syntactically supervised tree-to-string model (yamada and knight, 2001).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>with regard to translation rather than alignment accuracy, zens et al  (2004) <papid> C04-1030 </papid>show that decoding under itg constraints yields significantly lower word error rates and bleu scores than the ibm constraints.</nextsent>
<nextsent>we are conducting series of investigations motivated by the following observation: the empirically demonstrated suitability of itg paraphrasing constraints across languages should hold, if anything, even more strongly in the monolingual case.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB354">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, zens and ney (2003) <papid> P03-1019 </papid>show thatitg constraints yield significantly better alignment coverage than the constraints used in ibm statistical machine translation models on both german-english (verb mobil corpus) and french-english (canadian hansardscorpus).</prevsent>
<prevsent>zhang and gildea (2004) <papid> C04-1060 </papid>find that unsupervised alignment using bracketing itgs produces significantly lower chinese-english alignment error rates than syntactically supervised tree-to-string model (yamada and knight, 2001).<papid> P01-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1030 ">
with regard to translation rather than alignment accuracy, zens et al  (2004) <papid> C04-1030 </papid>show that decoding under itg constraints yields significantly lower word error rates and bleu scores than the ibm constraints.</citsent>
<aftsection>
<nextsent>we are conducting series of investigations motivated by the following observation: the empirically demonstrated suitability of itg paraphrasing constraints across languages should hold, if anything, even more strongly in the monolingual case.
</nextsent>
<nextsent>the monolingual case allows in some sense closer testing of various implications of theitg hypothesis, without irrelevant dimensions of variation arising from other cross-lingual phenomena.
</nextsent>
<nextsent>asymmetric textual entailment recognition (rte)datasets, in particular the pascal recognising textual entailment challenge corpus (dagan et al , 2005), providetestbeds that abstract over many tasks, including information retrieval, comparable documents, reading comprehension, question answering, information extraction, machine translation, and paraphrase acquisition.
</nextsent>
<nextsent>at the same time, the emergence of paraphrasing datasets presents an opportunity for complementary experiments on the task of recognizing symmetric bidirectional entailment rather than asymmetric directional entailment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB355">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>asymmetric textual entailment recognition (rte)datasets, in particular the pascal recognising textual entailment challenge corpus (dagan et al , 2005), providetestbeds that abstract over many tasks, including information retrieval, comparable documents, reading comprehension, question answering, information extraction, machine translation, and paraphrase acquisition.
</prevsent>
<prevsent>at the same time, the emergence of paraphrasing datasets presents an opportunity for complementary experiments on the task of recognizing symmetric bidirectional entailment rather than asymmetric directional entailment.
</prevsent>
</prevsection>
<citsent citstr=" W04-3219 ">
in particular, for this study we employ the msr paraphrase corpus (quirk et al , 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>25
</nextsent>
<nextsent>formally, itgs can be defined as the restricted subset of syntax-directed transduction grammars or sdtgs lewis and stearns (1968) where all of the rules are either of straight or inverted orientation.
</nextsent>
<nextsent>ordinary sdtgs allow any permutation of the symbols on the right-hand side to be specified when translating from the input language to the output language.
</nextsent>
<nextsent>in contrast, itgs only allow two outof the possible permutations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB358">
<title id=" W05-1205.xml">recognizing paraphrases and textual entailment using inversion transduction grammars </title>
<section> inversion transduction grammars.  </section>
<citcontext>
<prevsection>
<prevsent>a ? ,  ? e1/f1 . . .
</prevsent>
<prevsent>a ? ei/fj the simplest class of itgs, bracketing itgs, are particularly interesting in applications like paraphrasing, because they impose itg constraints in language independent fashion, and in the simplest case do not require any language-specific linguistic grammar or training.
</prevsent>
</prevsection>
<citsent citstr=" P95-1033 ">
in bracketing itgs, the grammar uses only single, undifferentiated non-terminal (wu, 1995).<papid> P95-1033 </papid></citsent>
<aftsection>
<nextsent>the key modeling property of bracketing itgs that is most relevant to paraphrase recognition is that they assign strong preference to candidate paraphrase pairs in which nested constituent subtrees can be recursively aligned with minimum of constituent boundary violations.
</nextsent>
<nextsent>unlike language-specific linguistic approaches, however, the shape of the trees are driven in unsupervised fashion by the data.
</nextsent>
<nextsent>one way to view this is that the trees are hidden explanatory variables.
</nextsent>
<nextsent>this not only provides significantly higher robustness than more highly constrained manually constructed grammars, but also makes the model widely applicable across languages in economical fashion without large investment in manually constructed resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB362">
<title id=" W06-0901.xml">the stages of event extraction </title>
<section> event coreference: determining which event.  </section>
<citcontext>
<prevsection>
<prevsent>since we are interested only in performance on event extraction, we follow the methodology of the ace diagnostic tasks and use the ground truth entity, timex2, and value annotations both for training and testing.
</prevsent>
<prevsent>additionally, each document is tokenized and split into sentences using simple algorithm adapted from (grefenstette, 1994, p. 149).
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
these sentences are parsed using the august 2005 release of the charniak parser (charniak, 2000)<papid> A00-2018 </papid>4.</citsent>
<aftsection>
<nextsent>the parses are converted into dependency relations using method similar to (collins, 1999; jijkoun and de rijke, 2004).<papid> P04-1040 </papid></nextsent>
<nextsent>the syntactic annotations thus provide access both to constituency and dependency information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB363">
<title id=" W06-0901.xml">the stages of event extraction </title>
<section> event coreference: determining which event.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, each document is tokenized and split into sentences using simple algorithm adapted from (grefenstette, 1994, p. 149).
</prevsent>
<prevsent>these sentences are parsed using the august 2005 release of the charniak parser (charniak, 2000)<papid> A00-2018 </papid>4.</prevsent>
</prevsection>
<citsent citstr=" P04-1040 ">
the parses are converted into dependency relations using method similar to (collins, 1999; jijkoun and de rijke, 2004).<papid> P04-1040 </papid></citsent>
<aftsection>
<nextsent>the syntactic annotations thus provide access both to constituency and dependency information.
</nextsent>
<nextsent>note that with respect to these two sources of syntactic information, we use the word head ambiguously torefer both to the head of constituent (i.e., the distinguished word within the constituent from which the constituent inherits its category features) and to the head of dependency relation (i.e., the word on which the dependent in the relation depends).
</nextsent>
<nextsent>since parses and entity/timex/value annotations are produced independently, we need strategy for matching (entity/timex/value) mentions to parses.given mention, we first try to find single constituent whose offsets exactly match the extent of the mention.
</nextsent>
<nextsent>in the training and development data, there is an exact-match constituent for 89.2% of the entity mentions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB364">
<title id=" W06-0901.xml">the stages of event extraction </title>
<section> event coreference.  </section>
<citcontext>
<prevsection>
<prevsent>accuracy megam 0.750 timbl 0.759 baseline 0.738 majority (in training) 0.749 table 7: modality accuracy megam 0.955 timbl 0.955 baseline 0.950 majority (in training) 0.967 table 8: polarity
</prevsent>
<prevsent>7.1 task structure.
</prevsent>
</prevsection>
<citsent citstr=" N04-1001 ">
for event coreference, we follow the approach to entity coreference detailed in (florian et al,2004).<papid> N04-1001 </papid></citsent>
<aftsection>
<nextsent>this approach uses mention-pair coreference model with probabilistic decoding.
</nextsent>
<nextsent>each event mention in document is paired with every other event mention, and classifier assigns to each pair of mentions the probability that the paired mentions corefer.
</nextsent>
<nextsent>these probabilities are used in left-to-right entity linking algorithm inwhich each mention is compared with all already established events (i.e., event mention clusters) to determine whether it should be added to an existing event or start new one.
</nextsent>
<nextsent>since the classifier needs to output probabilities for this approach, wedo not use timbl, but only train maximum entropy classifier with megam.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB365">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> proposal.  </section>
<citcontext>
<prevsection>
<prevsent>in this case, however, both phrases appear to be compositional.
</prevsent>
<prevsent>words cannot be substituted between the two phrases be cause they are composed in different ways.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
recently, there has been much interest in finding words which are distributionally similar e.g., lin (1998), <papid> P98-2127 </papid>lee (1999), <papid> P99-1004 </papid>curran and moens (2002), <papid> W02-0908 </papid>weeds (2003) and geffet and dagan (2004).</citsent>
<aftsection>
<nextsent>two words are said to be distributionally similar if they appear in similar contexts.
</nextsent>
<nextsent>for example, the two words apple and pear are likely to be seen as the objects of the verbs eat and peel, and this adds to their distributional similarity.
</nextsent>
<nextsent>the distributional hypothesis (harris, 1968) proposes connection between distributional similarity and semantic similarity, which is the basis for large body of workon automatic thesaurus construction using distributional similarity methods (curran and moens, 2002; <papid> W02-0908 </papid>weeds, 2003; geffet and dagan, 2004).our proposal is that just as words have distributional similarity which can be used, with at least some success, to estimate semantic similarity, so do larger units of expression.</nextsent>
<nextsent>we propose that the unit of interest is sub-parse, i.e., fragment (connected subgraph) of parse tree, which can range in size from single word to the parse for the entire sen 8 my mobile needs phone charging my mobile phone low is battery figure 1: parse trees for my mobile phone needs charging?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB367">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> proposal.  </section>
<citcontext>
<prevsection>
<prevsent>in this case, however, both phrases appear to be compositional.
</prevsent>
<prevsent>words cannot be substituted between the two phrases be cause they are composed in different ways.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
recently, there has been much interest in finding words which are distributionally similar e.g., lin (1998), <papid> P98-2127 </papid>lee (1999), <papid> P99-1004 </papid>curran and moens (2002), <papid> W02-0908 </papid>weeds (2003) and geffet and dagan (2004).</citsent>
<aftsection>
<nextsent>two words are said to be distributionally similar if they appear in similar contexts.
</nextsent>
<nextsent>for example, the two words apple and pear are likely to be seen as the objects of the verbs eat and peel, and this adds to their distributional similarity.
</nextsent>
<nextsent>the distributional hypothesis (harris, 1968) proposes connection between distributional similarity and semantic similarity, which is the basis for large body of workon automatic thesaurus construction using distributional similarity methods (curran and moens, 2002; <papid> W02-0908 </papid>weeds, 2003; geffet and dagan, 2004).our proposal is that just as words have distributional similarity which can be used, with at least some success, to estimate semantic similarity, so do larger units of expression.</nextsent>
<nextsent>we propose that the unit of interest is sub-parse, i.e., fragment (connected subgraph) of parse tree, which can range in size from single word to the parse for the entire sen 8 my mobile needs phone charging my mobile phone low is battery figure 1: parse trees for my mobile phone needs charging?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB368">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> proposal.  </section>
<citcontext>
<prevsection>
<prevsent>in this case, however, both phrases appear to be compositional.
</prevsent>
<prevsent>words cannot be substituted between the two phrases be cause they are composed in different ways.
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
recently, there has been much interest in finding words which are distributionally similar e.g., lin (1998), <papid> P98-2127 </papid>lee (1999), <papid> P99-1004 </papid>curran and moens (2002), <papid> W02-0908 </papid>weeds (2003) and geffet and dagan (2004).</citsent>
<aftsection>
<nextsent>two words are said to be distributionally similar if they appear in similar contexts.
</nextsent>
<nextsent>for example, the two words apple and pear are likely to be seen as the objects of the verbs eat and peel, and this adds to their distributional similarity.
</nextsent>
<nextsent>the distributional hypothesis (harris, 1968) proposes connection between distributional similarity and semantic similarity, which is the basis for large body of workon automatic thesaurus construction using distributional similarity methods (curran and moens, 2002; <papid> W02-0908 </papid>weeds, 2003; geffet and dagan, 2004).our proposal is that just as words have distributional similarity which can be used, with at least some success, to estimate semantic similarity, so do larger units of expression.</nextsent>
<nextsent>we propose that the unit of interest is sub-parse, i.e., fragment (connected subgraph) of parse tree, which can range in size from single word to the parse for the entire sen 8 my mobile needs phone charging my mobile phone low is battery figure 1: parse trees for my mobile phone needs charging?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB370">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> proposal.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity between two such vectors or descriptions can then be found using standard distributional similarity measure (see weeds (2003)).
</prevsent>
<prevsent>the use of distributional evidence for larger units than words is not new.
</prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
szpektor et al (2004) <papid> W04-3206 </papid>automatically identify anchors in web corpus data.</citsent>
<aftsection>
<nextsent>anchors are lexical elements that describe the context of sentence and if words are found to occur with the same set of anchors, they are assumed to be paraphrases.
</nextsent>
<nextsent>for example, the anchor set {mozart,1756} is known anchor set for verbs with the meaning born in?.
</nextsent>
<nextsent>however, this use of distributional evidence requires both anchors, or contexts, to occur simultaneously with the target word.
</nextsent>
<nextsent>this differs from the standard notion of distributional similarity which involves finding similarity between cooccurrence vectors, where there is no requirement for two features or contexts to occur simulultaneously.our work with distributional similarity is generalisation of the approach taken by lin and pantel(2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB372">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> empirical evidence.  </section>
<citcontext>
<prevsection>
<prevsent>further, we do not make any restrictions as to the number or types of the grammatical relation contexts associated with tree.
</prevsent>
<prevsent>practically demonstrating our proposal requires source of paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
we first looked at the msr paraphrase corpus (dolan et al, 2004) <papid> C04-1051 </papid>since it contains large number of sentences close enough in meaning to be considered paraphrases.</citsent>
<aftsection>
<nextsent>however, inspection of the data revealed that the lexical overlap between the pairs of paraphrasing sentences in this corpus is very high.
</nextsent>
<nextsent>the average word overlap (i.e.,the proportion of exactly identical word forms) calculated over the sentences paired by humans in the training set is 0.70, and the lowest overlap4 for such sentences is 0.3.
</nextsent>
<nextsent>this high word overlap makes this poor source of examples for us, since we wish to study similarity between phrases which do not share semantically similar words.
</nextsent>
<nextsent>4a possible reason for this is that candidate sentences were first identified automatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB374">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> empirical evidence.  </section>
<citcontext>
<prevsection>
<prevsent>when the sub-parse is only aword, the process is simplified to finding grammatical relations containing that word.the raw feature file is then converted into cooccurrence vector by counting the occurrences ofeach feature type.
</prevsent>
<prevsent>table 1 shows the number of feature types and tokens extracted for each phrase.
</prevsent>
</prevsection>
<citsent citstr=" W03-1011 ">
this shows that we have extracted reasonable number of features for each phrase, since distributional similarity techniques have been shown to work well for words which occur more than 100 times in given corpus (lin, 1998; <papid> P98-2127 </papid>weeds and weir, 2003).<papid> W03-1011 </papid>we then computed the distributional similarity between each co-occurrence vector using the ?-skewdivergence measure (lee, 1999).<papid> P99-1004 </papid></citsent>
<aftsection>
<nextsent>the ?-skew divergence measure is an approximation to the kullbackleibler (kl) divergence me assure between two distributions and q: d(p||q) = ? p(x)log p(x) q(x) 5we currently retain all of the distinctions between grammatical relations output by rasp.
</nextsent>
<nextsent>10 the ?-skew divergence measure is designed to be used when unreliable maximum likelihood estimates(mle) of probabilities would result in the kl divergence being equal to ?.
</nextsent>
<nextsent>it is defined as: dist?(q, r) = d(r||?.q + (1?
</nextsent>
<nextsent>?).r) where 0 ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB378">
<title id=" W05-1202.xml">the distributional similarity of sub parses </title>
<section> empirical evidence.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, smaller distance indicates greater similarity.
</prevsent>
<prevsent>the reason for choosing this measure is that it can be used to compute the distance between anytwo co-occurrence vectors independent of any information about other words.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
this is in contrast to many other measures, e.g., lin (1998), <papid> P98-2127 </papid>which use theco-occurrences of features with other words to compute weighting function such as mutual information (mi) (church and hanks, 1989).<papid> P89-1010 </papid></citsent>
<aftsection>
<nextsent>since we only have corpus data for the target phrases, it is not possible for us to use such measure.
</nextsent>
<nextsent>however, the ?-skew divergence measure has been shown (weeds, 2003) to perform comparably with measures which use mi, particularly for lower frequency target words.
</nextsent>
<nextsent>4.3 results.
</nextsent>
<nextsent>the results, in terms of ?-skew divergence scores between pairs of phrases, are shown in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB379">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe these differences,an algorithm for detecting them, and finally some experimental results.
</prevsent>
<prevsent>these results have implications for automating discourse annotation based on syntactic annotation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the overall goal of the penn discourse treebank(pdtb) is to annotate the million word wsj corpus in the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>witha layer of discourse annotations.</citsent>
<aftsection>
<nextsent>a preliminary report on this project was presented at the 2004 work shop on frontiers in corpus annotation (miltsakaki et al, 2004<papid> W04-2703 </papid>a), where we described our annotation of discourse connectives (both explicit and implicit) along with their (clausal) arguments.further work done since then includes the annotation of attribution: that is, who has expressed each argument to discourse connective (the writer or some other speaker or author) and who has expressed the discourse relation itself.</nextsent>
<nextsent>these ascrip tions need not be the same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB380">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these results have implications for automating discourse annotation based on syntactic annotation.
</prevsent>
<prevsent>the overall goal of the penn discourse treebank(pdtb) is to annotate the million word wsj corpus in the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>witha layer of discourse annotations.</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
a preliminary report on this project was presented at the 2004 work shop on frontiers in corpus annotation (miltsakaki et al, 2004<papid> W04-2703 </papid>a), where we described our annotation of discourse connectives (both explicit and implicit) along with their (clausal) arguments.further work done since then includes the annotation of attribution: that is, who has expressed each argument to discourse connective (the writer or some other speaker or author) and who has expressed the discourse relation itself.</citsent>
<aftsection>
<nextsent>these ascrip tions need not be the same.
</nextsent>
<nextsent>of particular interest is the fact that attribution may or may not play role in the relation established by connective.
</nextsent>
<nextsent>this may lead to lack of congruence between arguments at the syntactic and the discourse levels.
</nextsent>
<nextsent>the issue of congruence is of interest both from the perspective of annotation (where it means that, even within asingle sentence, one cannot merely transfer the annotation of syntactic arguments of subordinate or coordinate conjunction to its discourse arguments),and from the perspective of inferences that these annotations will support in future applications of the pdtb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB381">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> overview of the pdtb.  </section>
<citcontext>
<prevsection>
<prevsent>in sections 4 and 5, we describe mismatches that arise between the discourse arguments of connective and the syntactic annotation as provided by the penn treebank (ptb), in the cases where all the arguments of the connective are in the same sentence.
</prevsent>
<prevsent>in section 6, we will discuss some implications of these issues for the theory and practice of discourse annotation and their relevance even at the level of sentence-bound annotation.
</prevsent>
</prevsection>
<citsent citstr=" W98-0315 ">
the pdtb builds on the dltag approach to discourse structure (webber and joshi, 1998; <papid> W98-0315 </papid>web beret al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>in which connectives are discourse-level predicates which project predicate-argument structure on par with verbs at 29 the sentence level.</citsent>
<aftsection>
<nextsent>initial work on the pdtb hasbeen described in miltsakaki et al (2004<papid> W04-2703 </papid>a), miltsakaki et al (2004<papid> W04-2703 </papid>b), prasad et al (2004).<papid> W04-0212 </papid>the key contribution of the pdtb design framework is its bottom-up approach to discourse structure: instead of appealing to an abstract (and arbi trary) set of discourse relations whose identification may confound multiple sources of discourse meaning, we start with the annotation of discourse connectives and their arguments, thus exposing clearly defined level of discourse representation.the pdtb annotates as explicit discourse connectives all subordinating conjunctions, coordinating conjunctions and discourse adverbials.</nextsent>
<nextsent>these predicates establish relations between two abstract objects such as events, states and propositions (asher, 1993).1 we use conn to denote the connective, and arg1 and arg2 to denote the textual spans from which the abstract object arguments are computed.2 in (1), the subordinating conjunction since establishes temporal relation between the event of the earthquake hitting and state where no music is played by certain woman.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB382">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> overview of the pdtb.  </section>
<citcontext>
<prevsection>
<prevsent>in sections 4 and 5, we describe mismatches that arise between the discourse arguments of connective and the syntactic annotation as provided by the penn treebank (ptb), in the cases where all the arguments of the connective are in the same sentence.
</prevsent>
<prevsent>in section 6, we will discuss some implications of these issues for the theory and practice of discourse annotation and their relevance even at the level of sentence-bound annotation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1006 ">
the pdtb builds on the dltag approach to discourse structure (webber and joshi, 1998; <papid> W98-0315 </papid>web beret al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>in which connectives are discourse-level predicates which project predicate-argument structure on par with verbs at 29 the sentence level.</citsent>
<aftsection>
<nextsent>initial work on the pdtb hasbeen described in miltsakaki et al (2004<papid> W04-2703 </papid>a), miltsakaki et al (2004<papid> W04-2703 </papid>b), prasad et al (2004).<papid> W04-0212 </papid>the key contribution of the pdtb design framework is its bottom-up approach to discourse structure: instead of appealing to an abstract (and arbi trary) set of discourse relations whose identification may confound multiple sources of discourse meaning, we start with the annotation of discourse connectives and their arguments, thus exposing clearly defined level of discourse representation.the pdtb annotates as explicit discourse connectives all subordinating conjunctions, coordinating conjunctions and discourse adverbials.</nextsent>
<nextsent>these predicates establish relations between two abstract objects such as events, states and propositions (asher, 1993).1 we use conn to denote the connective, and arg1 and arg2 to denote the textual spans from which the abstract object arguments are computed.2 in (1), the subordinating conjunction since establishes temporal relation between the event of the earthquake hitting and state where no music is played by certain woman.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB383">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> overview of the pdtb.  </section>
<citcontext>
<prevsection>
<prevsent>in sections 4 and 5, we describe mismatches that arise between the discourse arguments of connective and the syntactic annotation as provided by the penn treebank (ptb), in the cases where all the arguments of the connective are in the same sentence.
</prevsent>
<prevsent>in section 6, we will discuss some implications of these issues for the theory and practice of discourse annotation and their relevance even at the level of sentence-bound annotation.
</prevsent>
</prevsection>
<citsent citstr=" J03-4002 ">
the pdtb builds on the dltag approach to discourse structure (webber and joshi, 1998; <papid> W98-0315 </papid>web beret al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>in which connectives are discourse-level predicates which project predicate-argument structure on par with verbs at 29 the sentence level.</citsent>
<aftsection>
<nextsent>initial work on the pdtb hasbeen described in miltsakaki et al (2004<papid> W04-2703 </papid>a), miltsakaki et al (2004<papid> W04-2703 </papid>b), prasad et al (2004).<papid> W04-0212 </papid>the key contribution of the pdtb design framework is its bottom-up approach to discourse structure: instead of appealing to an abstract (and arbi trary) set of discourse relations whose identification may confound multiple sources of discourse meaning, we start with the annotation of discourse connectives and their arguments, thus exposing clearly defined level of discourse representation.the pdtb annotates as explicit discourse connectives all subordinating conjunctions, coordinating conjunctions and discourse adverbials.</nextsent>
<nextsent>these predicates establish relations between two abstract objects such as events, states and propositions (asher, 1993).1 we use conn to denote the connective, and arg1 and arg2 to denote the textual spans from which the abstract object arguments are computed.2 in (1), the subordinating conjunction since establishes temporal relation between the event of the earthquake hitting and state where no music is played by certain woman.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB386">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> overview of the pdtb.  </section>
<citcontext>
<prevsection>
<prevsent>in section 6, we will discuss some implications of these issues for the theory and practice of discourse annotation and their relevance even at the level of sentence-bound annotation.
</prevsent>
<prevsent>the pdtb builds on the dltag approach to discourse structure (webber and joshi, 1998; <papid> W98-0315 </papid>web beret al, 1999; <papid> P99-1006 </papid>webber et al, 2003) <papid> J03-4002 </papid>in which connectives are discourse-level predicates which project predicate-argument structure on par with verbs at 29 the sentence level.</prevsent>
</prevsection>
<citsent citstr=" W04-0212 ">
initial work on the pdtb hasbeen described in miltsakaki et al (2004<papid> W04-2703 </papid>a), miltsakaki et al (2004<papid> W04-2703 </papid>b), prasad et al (2004).<papid> W04-0212 </papid>the key contribution of the pdtb design framework is its bottom-up approach to discourse structure: instead of appealing to an abstract (and arbi trary) set of discourse relations whose identification may confound multiple sources of discourse meaning, we start with the annotation of discourse connectives and their arguments, thus exposing clearly defined level of discourse representation.the pdtb annotates as explicit discourse connectives all subordinating conjunctions, coordinating conjunctions and discourse adverbials.</citsent>
<aftsection>
<nextsent>these predicates establish relations between two abstract objects such as events, states and propositions (asher, 1993).1 we use conn to denote the connective, and arg1 and arg2 to denote the textual spans from which the abstract object arguments are computed.2 in (1), the subordinating conjunction since establishes temporal relation between the event of the earthquake hitting and state where no music is played by certain woman.
</nextsent>
<nextsent>in all the examples in this paper, as in (1), arg1 is italicized, arg2 is in boldface, and conn is underlined.
</nextsent>
<nextsent>(1) she hasnt played any music since the earthquake hit.
</nextsent>
<nextsent>what counts as legal argument?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB387">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> annotation of attribution.  </section>
<citcontext>
<prevsection>
<prevsent>(4) the $6 billion that some 40 companies are looking to raise in the year ending march 21 compares with only $2.7 billion raise on the capital market in the previous year.
</prevsent>
<prevsent>implicit - in contrast in fiscal 1984, before mr. gandhi came into power, only $810 million was raised.when complete, the pdtb will contain approximately 35k annotations: 15k annotations of the 100 explicit connectives identified in the corpus and 20k annotations of implicit connectives.3
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
wiebe and her colleagues have pointed out the importance of ascribing beliefs and assertions expressed in text to the agent(s) holding or making them (riloff and wiebe, 2003; <papid> W03-1014 </papid>wiebe et al, 2004;<papid> J04-3002 </papid>wiebe et al, 2005).</citsent>
<aftsection>
<nextsent>they have also gone considerable way towards specifying how such subjective material should be annotated (wiebe, 2002).
</nextsent>
<nextsent>since we take discourse connectives to convey semanticpredicate-argument relations between abstract objects, one can distinguish variety of cases depending on the attribution of the discourse relation or its 3the annotation guidelines for the pdtb are available at http://www.cis.upenn.edu/pdtb.
</nextsent>
<nextsent>30 arguments; that is, whether the relation or arguments are ascribed to the author of the text or someone other than the author.case 1: the relation and both arguments are attributed to the same source.
</nextsent>
<nextsent>in (5), the concessive relation between arg1 and arg2, anchored on the connective even though is attributed to the speaker dick mayer, because he is quoted as having said it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB388">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> annotation of attribution.  </section>
<citcontext>
<prevsection>
<prevsent>(4) the $6 billion that some 40 companies are looking to raise in the year ending march 21 compares with only $2.7 billion raise on the capital market in the previous year.
</prevsent>
<prevsent>implicit - in contrast in fiscal 1984, before mr. gandhi came into power, only $810 million was raised.when complete, the pdtb will contain approximately 35k annotations: 15k annotations of the 100 explicit connectives identified in the corpus and 20k annotations of implicit connectives.3
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
wiebe and her colleagues have pointed out the importance of ascribing beliefs and assertions expressed in text to the agent(s) holding or making them (riloff and wiebe, 2003; <papid> W03-1014 </papid>wiebe et al, 2004;<papid> J04-3002 </papid>wiebe et al, 2005).</citsent>
<aftsection>
<nextsent>they have also gone considerable way towards specifying how such subjective material should be annotated (wiebe, 2002).
</nextsent>
<nextsent>since we take discourse connectives to convey semanticpredicate-argument relations between abstract objects, one can distinguish variety of cases depending on the attribution of the discourse relation or its 3the annotation guidelines for the pdtb are available at http://www.cis.upenn.edu/pdtb.
</nextsent>
<nextsent>30 arguments; that is, whether the relation or arguments are ascribed to the author of the text or someone other than the author.case 1: the relation and both arguments are attributed to the same source.
</nextsent>
<nextsent>in (5), the concessive relation between arg1 and arg2, anchored on the connective even though is attributed to the speaker dick mayer, because he is quoted as having said it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB389">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> arguments of subordinating.  </section>
<citcontext>
<prevsection>
<prevsent>but although as discourse connective denies the expectation that the supply of dialysis products will be discontinued when the distribution arrangement ends.
</prevsent>
<prevsent>it does not convey the expectation that delmed will not say such things.
</prevsent>
</prevsection>
<citsent citstr=" J00-3005 ">
on the other hand, in (13), the contrast established by while is between the opinions of two entities i.e., advocates and their opponents.44this distinction is hard to capture in an rst-based parsing framework (marcu, 2000).<papid> J00-3005 </papid></citsent>
<aftsection>
<nextsent>according to the rst-based annotation scheme (carlson et al, 2003) although delmed said?
</nextsent>
<nextsent>and while opponents argued?
</nextsent>
<nextsent>are elementary discourse units (12) the current distribution arrangement ends in march1990, although delmed said it will continue to provide some supplies of the peritoneal dialysis products to national medical, the spokeswoman said.
</nextsent>
<nextsent>(13) advocates said the 90-cent-an-hour rise, to $4.25 an hour by april 1991, is too small for the working poor, while opponents argued that the increase will still hurt small business and cost many thousands of jobs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB390">
<title id=" W05-0305.xml">attribution and the nonalignment of syntactic and discourse arguments of connectives </title>
<section> repeat while parent(x.  </section>
<citcontext>
<prevsection>
<prevsent>5k instances).
</prevsent>
<prevsent>sections 02-24 finally we evaluated the algorithm on the output of statistical parser.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
the parser implementation in (bikel, 2002) was used in this experiment and it was run in mode which emulated the collins (1997) <papid> P97-1003 </papid>parser.</citsent>
<aftsection>
<nextsent>the parser was trained on sections 02-21 and sections 22-24 were used as test data, where 35 the parser was run and the tree subtraction algorithm was run on its output.
</nextsent>
<nextsent>the results are summarized in table 5.
</nextsent>
<nextsent>argument exact extra material omitted material arg1 65.5% 25.2% 9.3% arg2 84.7% 0% 15.3% table 5: tree subtraction on the output of statistical parser (approx.
</nextsent>
<nextsent>600 instances).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB391">
<title id=" W06-0902.xml">local semantics in the interpretation of temporal expressions </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>we have developed the representation described here on the basis of the set of 265 examples provided in the timex2 guidelines (ferro et al,2005), and this set of annotated examples is available to the community.6 the approach described here is implemented in dante, text processing system which produces normalised values forall timexs found in document.
</prevsent>
<prevsent>the recognition component of the system, which constructs the intermediate representations described here, is implemented via just over 200 rules written in thejape language:7 time expressions are thus recognised using finite state patterns, but we then apply syntactic check, using the conn exor parser, to ensure that we have identified the full extent of each temporal expression, appropriately extending the extent when this is not the case.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
6see www.clt.mq.edu.au/timex.7jape is provided as part of the gate tools (cunning ham et al, 2002).<papid> P02-1022 </papid></citsent>
<aftsection>
<nextsent>we are currently testing this representation and its means of derivation against the data from the 2004 tern competition.
</nextsent>
<nextsent>our results are broadly.
</nextsent>
<nextsent>comparable to those achieved by other systems (for example, chronos or tempex), though they can not be compared directly since the reported evaluations at the tern competition use data which are not public and therefore not available to us.
</nextsent>
<nextsent>we acknowledge the support of the defence science and technology organisation in carrying out the work described here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB392">
<title id=" W05-0303.xml">a unified representation for morphological syntactic semantic and referential annotations </title>
<section> referential relations.  </section>
<citcontext>
<prevsection>
<prevsent>we define referential relations as cover-term for all contextually dependent reference relations.
</prevsent>
<prevsent>the inventory of such relations adopted for syn-ra is inspired by the annotation scheme first developed in the mate project (davies et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W99-0309 ">
however, it takes acautious approach in that it only adopts those referential relations from mate for which the developers of mate report sufficiently high level of inter annotator agreement (poesio et al, 1999).<papid> W99-0309 </papid></citsent>
<aftsection>
<nextsent>syn-ra currently uses the following subset of relations: coreferential, anaphoric, cataphoric, bound, split antecedent, instance, and expletive.
</nextsent>
<nextsent>the potential markables are definite nps, personal pronouns, relative, reflexive, and reciprocal pronouns, demonstrative, indefinite and possessive pronouns.
</nextsent>
<nextsent>there is second research effort under way at the european media laboratory heidelberg, which also annotates german text corpora and dialog data with referential relations.
</nextsent>
<nextsent>since their corpora are not publicly available, it is difficult to verify their inventory of referential relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB393">
<title id=" W05-0303.xml">a unified representation for morphological syntactic semantic and referential annotations </title>
<section> automatic extraction of markables and.  </section>
<citcontext>
<prevsection>
<prevsent>however, the possessive pronoun ihre and the subject pronoun sie of the subordinate clause, can be and, in fact, are anaphor ically related, since they are not co-arguments of the same verb.
</prevsent>
<prevsent>this can be directly inferred from the treebank annotation, specifically from the sentence structure and the grammatical function information 16encoded on the edge labels.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
most published computational algorithms of anaphora resolution, including (hobbs, 1978; lappin and leass, 1994; <papid> J94-4002 </papid>ingria and stallard, 1989), <papid> P89-1032 </papid>relyon such binding-constraint filters to minimize the set of potential antecedents for pronouns and reflexives.as already pointed out, the sample sentence contains four markables: one possessive pronoun ihre, two occurrences of the pronoun sie and one complex np ihre schulkameradin cassie bernall.</citsent>
<aftsection>
<nextsent>the latter np is good example of syn-ras longest-matchprinciple for identifying markables.
</nextsent>
<nextsent>in case of complex nps, the entire np counts as mark able, butso do its sub constituents ? in the case at hand, particularly the possessive pronoun ihre.
</nextsent>
<nextsent>all of this information can be directly derived from the treebank account.
</nextsent>
<nextsent>compared to other annotation efforts for german where markables have to be chosen manually (mller and strube, 2003), manual annotation in the syn-ra project can, thus, be restricted to the selection of the appropriate referential relations between referentially dependent expressions and their nominal antecedents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB394">
<title id=" W05-0303.xml">a unified representation for morphological syntactic semantic and referential annotations </title>
<section> automatic extraction of markables and.  </section>
<citcontext>
<prevsection>
<prevsent>however, the possessive pronoun ihre and the subject pronoun sie of the subordinate clause, can be and, in fact, are anaphor ically related, since they are not co-arguments of the same verb.
</prevsent>
<prevsent>this can be directly inferred from the treebank annotation, specifically from the sentence structure and the grammatical function information 16encoded on the edge labels.
</prevsent>
</prevsection>
<citsent citstr=" P89-1032 ">
most published computational algorithms of anaphora resolution, including (hobbs, 1978; lappin and leass, 1994; <papid> J94-4002 </papid>ingria and stallard, 1989), <papid> P89-1032 </papid>relyon such binding-constraint filters to minimize the set of potential antecedents for pronouns and reflexives.as already pointed out, the sample sentence contains four markables: one possessive pronoun ihre, two occurrences of the pronoun sie and one complex np ihre schulkameradin cassie bernall.</citsent>
<aftsection>
<nextsent>the latter np is good example of syn-ras longest-matchprinciple for identifying markables.
</nextsent>
<nextsent>in case of complex nps, the entire np counts as mark able, butso do its sub constituents ? in the case at hand, particularly the possessive pronoun ihre.
</nextsent>
<nextsent>all of this information can be directly derived from the treebank account.
</nextsent>
<nextsent>compared to other annotation efforts for german where markables have to be chosen manually (mller and strube, 2003), manual annotation in the syn-ra project can, thus, be restricted to the selection of the appropriate referential relations between referentially dependent expressions and their nominal antecedents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB395">
<title id=" W05-0806.xml">augmenting a small parallel text with morphosyntactic language </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>this probability can be factor ised into the translation model probability (fj1 |ei1) which describes the correspondence between the words in the source andthe target sequence, and the language model probability (ej1 ) which describes well-formedness of the produced target sequence.
</prevsent>
<prevsent>these two probabilities can be modelled independently of each other.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for detailed descriptions of smt models see for example (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003).<papid> J03-1002 </papid>translation probabilities are learnt from bilingual parallel text corpus and language model probabilities are learnt from monolingual text in the target language.</citsent>
<aftsection>
<nextsent>usually, the performance of translation system strongly depends on the size of the available training corpus.
</nextsent>
<nextsent>however, acquisition ofa large high-quality bilingual parallel text for the desired domain and language pair requires lot of time and effort, and, for many language pairs, is even notpossible.
</nextsent>
<nextsent>besides, small corpora have certain advantages - the acquisition does not require too much effort and also manual creation and correction are possible.
</nextsent>
<nextsent>therefore there is an increasing number of publications dealing with limited amounts of bilingual data (al-onaizan et al, 2000; nieen and ney, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB396">
<title id=" W05-0806.xml">augmenting a small parallel text with morphosyntactic language </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>this probability can be factor ised into the translation model probability (fj1 |ei1) which describes the correspondence between the words in the source andthe target sequence, and the language model probability (ej1 ) which describes well-formedness of the produced target sequence.
</prevsent>
<prevsent>these two probabilities can be modelled independently of each other.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for detailed descriptions of smt models see for example (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003).<papid> J03-1002 </papid>translation probabilities are learnt from bilingual parallel text corpus and language model probabilities are learnt from monolingual text in the target language.</citsent>
<aftsection>
<nextsent>usually, the performance of translation system strongly depends on the size of the available training corpus.
</nextsent>
<nextsent>however, acquisition ofa large high-quality bilingual parallel text for the desired domain and language pair requires lot of time and effort, and, for many language pairs, is even notpossible.
</nextsent>
<nextsent>besides, small corpora have certain advantages - the acquisition does not require too much effort and also manual creation and correction are possible.
</nextsent>
<nextsent>therefore there is an increasing number of publications dealing with limited amounts of bilingual data (al-onaizan et al, 2000; nieen and ney, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB398">
<title id=" W05-0806.xml">augmenting a small parallel text with morphosyntactic language </title>
<section> language resources.  </section>
<citcontext>
<prevsection>
<prevsent>for each word, this tool provides its base form and sequence of morpho-syntactic tags.
</prevsent>
<prevsent>for the serbian corpus, to our knowlegde there is no available tool for automatic annotation of thislanguage.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
therefore, the base forms have been introduced manually and the pos tags have been provided partly manually and partly automatically using statistical maximum-entropy based pos tagger similar to the one described in (ratnaparkhi, 1996).<papid> W96-0213 </papid>first, the 200 sentences of the reduced training corpus have been annotated completely manually.</citsent>
<aftsection>
<nextsent>thenthe first 500 sentences of the rest of the training corpus have been tagged automatically and the errors have been manually corrected.
</nextsent>
<nextsent>afterwards, the pos tagger has been trained on the extended corpus (700sentences), the next 500 sentences of the rest are annotated, and the procedure has been repeated until the annotation has been finished for the complete corpus.
</nextsent>
<nextsent>42 table 1: statistics of the serbian-english assimil corpus serbian english training: original base forms original no article full corpus sentences 2632 2632 (2.6k) running words + punct.
</nextsent>
<nextsent>22227 24808 23308 average sentence length 8.4 9.5 8.8 vocabulary size 4546 2605 2645 2642 singletons 2728 1253 1211 reduced corpus sentences 200 200 (200) running words + punct.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB399">
<title id=" W05-0806.xml">augmenting a small parallel text with morphosyntactic language </title>
<section> translation experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>for the serbian to english translation systems, three versions of the serbian corpus have been used: original (baseline), base forms only (sr base) and base forms with additional treatment of the verbs (sr base+v-pos).
</prevsent>
<prevsent>for the translation into serbian, the systems were trained on two versions of the english corpus: original (baseline) and without articles (en no-article).
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the baseline translation system is the alignment templates system with scaling factors (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>word alignments are produced using giza++ toolkit without symmetrisation (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>preprocessing of the source data hasbeen done before the training of the system, therefore modifications of the training and search procedure were not necessary for the translation of the transformed source language corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB402">
<title id=" W05-0806.xml">augmenting a small parallel text with morphosyntactic language </title>
<section> translation experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>as for the external test set, results for this text are reported only for the full corpus systems, since for the reduced corpus the error rates are higher but the effects of using phrases and morpho-syntactic information are basically the same.
</prevsent>
<prevsent>4.2 translation results.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the evaluation metrics used in our experiments are wer (word error rate), per (positionindependent word error rate) and bleu (bilin gual evaluation understudy) (papineni et al, 2002).<papid> P02-1040 </papid>since bleu is an accuracy measure, we use 1 bleu as an error measure.</citsent>
<aftsection>
<nextsent>4.2.1 translation from serbian into english error rates for the translation from serbian into english are shown in table 3 and some examples are shown in table 6.
</nextsent>
<nextsent>it can be seen that there is significant decrease in all error rates when the full forms are replaced with their base forms.
</nextsent>
<nextsent>since the redundant information contained in the inflection is removed, the system can better capture the relevant information and is capable of producing correct or approximatively correct translations even for unseen full forms of the words (marked by unknown ? in the baseline result example).
</nextsent>
<nextsent>the treatment of the verbs yields some additional improvements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB403">
<title id=" W05-1307.xml">using biomedical literature mining to consolidate the set of known human protein protein interactions </title>
<section> assembling existing protein interaction.  </section>
<citcontext>
<prevsection>
<prevsent>in both training and testing the crf protein-name tagger, the corresponding medline abstracts were processed as follows.
</prevsent>
<prevsent>text was tokenized usingwhite-space as delimiters and treating all punctuation marks as separate tokens.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the text was segmented into sentences, and part-of-speech tags were assigned to each token using brills tagger (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>for each token in each sentence, vector of binary features was generated using the feature templates employed by the maximum entropy approach described in (bunescu et al, 2005).
</nextsent>
<nextsent>generally, these features make use of the words occurring before and after the current position in the text, their pos tags and capitalization patterns.
</nextsent>
<nextsent>each feature occurring in the training data is associated with parameter in the crf model.
</nextsent>
<nextsent>we used the crf implementation from (mccallum, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB404">
<title id=" W05-0628.xml">semantic role labeling as sequential tagging </title>
<section> goals and system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the top-most syntactic constituents falling inside these regions are selected as tokens.
</prevsent>
<prevsent>note that this strategy is independent of the input syntactic annotation explored, provided it contains clause boundaries.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
it happens that, in the case of full parses, this node selection strategy is equivalent to the pruning process defined by xue and palmer (2004)<papid> W04-3212 </papid>which selects sibling nodes along the path of ancestors from the verb predicate to the root of thetree2.</citsent>
<aftsection>
<nextsent>due to this pruning stage, the upper-bound recall figures are 95.67% for ppupc and 90.32% for fpcha.
</nextsent>
<nextsent>these values give f1 performance upper bounds of 97.79 and 94.91, respectively, assuming perfect predictors (100% precision).
</nextsent>
<nextsent>the nodes selected are labeled with b-i-o tags depending if they are at the beginning, inside, or outside of verb argument.
</nextsent>
<nextsent>there is total of 37 argument types, which amount to 37*2+1=75 labels.regarding the learning algorithm, we used generalized ada boost with real-valued weak classifiers, which constructs an ensemble of decision trees offixed depth (schapire and singer, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB408">
<title id=" W05-0628.xml">semantic role labeling as sequential tagging </title>
<section> goals and system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>parser.
</prevsent>
<prevsent>we did not contribute with significantly original features.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
instead,we borrowed most of them from the existing literature (gildea and jurafsky, 2002; <papid> J02-3001 </papid>carreras et al, 2004; <papid> W04-2415 </papid>xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>broadly speaking, we considered features belonging to four categories3: (1) on the verb predicate: ? form; lemma; pos tag; chunk type and type of verb phrase in which verb is included: single-word ormulti-word; verb voice: active, passive, copulative, in fini tive, or progressive; binary flag indicating if the verb is start/end of clause.?
</nextsent>
<nextsent>subcategorization, i.e., the phrase structure rule expanding the verb parent node.
</nextsent>
<nextsent>(2) on the focus constituent: ? type; head: extracted using common head-word rules; if the first element is pp chunk, then the head of the first np is extracted; ? first and last words and pos tags of the constituent.
</nextsent>
<nextsent>pos sequence: if it is less than 5 tags long; 2/3/4-grams of the pos sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB409">
<title id=" W05-0628.xml">semantic role labeling as sequential tagging </title>
<section> goals and system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>parser.
</prevsent>
<prevsent>we did not contribute with significantly original features.
</prevsent>
</prevsection>
<citsent citstr=" W04-2415 ">
instead,we borrowed most of them from the existing literature (gildea and jurafsky, 2002; <papid> J02-3001 </papid>carreras et al, 2004; <papid> W04-2415 </papid>xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>broadly speaking, we considered features belonging to four categories3: (1) on the verb predicate: ? form; lemma; pos tag; chunk type and type of verb phrase in which verb is included: single-word ormulti-word; verb voice: active, passive, copulative, in fini tive, or progressive; binary flag indicating if the verb is start/end of clause.?
</nextsent>
<nextsent>subcategorization, i.e., the phrase structure rule expanding the verb parent node.
</nextsent>
<nextsent>(2) on the focus constituent: ? type; head: extracted using common head-word rules; if the first element is pp chunk, then the head of the first np is extracted; ? first and last words and pos tags of the constituent.
</nextsent>
<nextsent>pos sequence: if it is less than 5 tags long; 2/3/4-grams of the pos sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB416">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this problem is often referred to as semi-supervised learning.
</prevsent>
<prevsent>it significantly reduces the effort needed to develop training set.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
it has shown promise in improving the performance of many tasks such as name tagging (miller et al, 2004), <papid> N04-1043 </papid>semantic class extraction (lin et al, 2003), chunking (ando and zhang, 2005), <papid> P05-1001 </papid>coreference resolution (bean and riloff, 2004) <papid> N04-1038 </papid>and text classification (blum and mitchell, 1998).</citsent>
<aftsection>
<nextsent>however, it is not clear, when semi-supervised learning is applied to improve learner, how the system should effectively select unlabeled data, and how the size and relevance of data impact the performance.
</nextsent>
<nextsent>in this paper we apply two semi-supervised learning algorithms to improve state-of-the-art name tagger.
</nextsent>
<nextsent>we run the baseline name tagger on large unlabeled corpus (bootstrapping) and the test set (self-training), and automatically generate high-confidence machine-labeled sentences as additional training data?.
</nextsent>
<nextsent>we then iteratively retrain the model on the increased training data?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB417">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this problem is often referred to as semi-supervised learning.
</prevsent>
<prevsent>it significantly reduces the effort needed to develop training set.
</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
it has shown promise in improving the performance of many tasks such as name tagging (miller et al, 2004), <papid> N04-1043 </papid>semantic class extraction (lin et al, 2003), chunking (ando and zhang, 2005), <papid> P05-1001 </papid>coreference resolution (bean and riloff, 2004) <papid> N04-1038 </papid>and text classification (blum and mitchell, 1998).</citsent>
<aftsection>
<nextsent>however, it is not clear, when semi-supervised learning is applied to improve learner, how the system should effectively select unlabeled data, and how the size and relevance of data impact the performance.
</nextsent>
<nextsent>in this paper we apply two semi-supervised learning algorithms to improve state-of-the-art name tagger.
</nextsent>
<nextsent>we run the baseline name tagger on large unlabeled corpus (bootstrapping) and the test set (self-training), and automatically generate high-confidence machine-labeled sentences as additional training data?.
</nextsent>
<nextsent>we then iteratively retrain the model on the increased training data?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB418">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this problem is often referred to as semi-supervised learning.
</prevsent>
<prevsent>it significantly reduces the effort needed to develop training set.
</prevsent>
</prevsection>
<citsent citstr=" N04-1038 ">
it has shown promise in improving the performance of many tasks such as name tagging (miller et al, 2004), <papid> N04-1043 </papid>semantic class extraction (lin et al, 2003), chunking (ando and zhang, 2005), <papid> P05-1001 </papid>coreference resolution (bean and riloff, 2004) <papid> N04-1038 </papid>and text classification (blum and mitchell, 1998).</citsent>
<aftsection>
<nextsent>however, it is not clear, when semi-supervised learning is applied to improve learner, how the system should effectively select unlabeled data, and how the size and relevance of data impact the performance.
</nextsent>
<nextsent>in this paper we apply two semi-supervised learning algorithms to improve state-of-the-art name tagger.
</nextsent>
<nextsent>we run the baseline name tagger on large unlabeled corpus (bootstrapping) and the test set (self-training), and automatically generate high-confidence machine-labeled sentences as additional training data?.
</nextsent>
<nextsent>we then iteratively retrain the model on the increased training data?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB419">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then we tried to select relevant documents from the unlabeled data in advance, and got clear further improvements.
</prevsent>
<prevsent>we also obtained significant improvement by self-training (boot strapping on the test data) without any additional unlabeled data.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
therefore, in contrast to the claim in (banko and brill, 2001), <papid> P01-1005 </papid>we concluded that, for some applications, effective use of large unlabeled corpora demands good data selection measures.</citsent>
<aftsection>
<nextsent>we propose and quantify some effective measures to select documents and sentences in this paper.
</nextsent>
<nextsent>the rest of this paper is structured as follows.
</nextsent>
<nextsent>section 2 briefly describes the efforts made by previous researchers to use semi-supervised learning as well as the work of (banko and brill, 2001).<papid> P01-1005 </papid></nextsent>
<nextsent>section 3 presents our baseline name tag ger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB422">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>section 7 presents our conclusions and directions for future work.
</prevsent>
<prevsent>this work presented here extends substantial body of previous work (blum and mitchell, 1998; riloff and jones, 1999; ando and zhang, 2005) <papid> P05-1001 </papid>48that all focus on reducing annotation requirements.</prevsent>
</prevsection>
<citsent citstr=" C96-2157 ">
for the specific task of named entity annotation, some researchers have emphasized the creation of taggers from minimal seed sets (strzalkowski and wang, 1996; <papid> C96-2157 </papid>collins and singer, 1999; <papid> W99-0613 </papid>lin et al, 2003) while another line of inquiry (which we are pursuing) has sought to improve on high-performance baseline taggers (miller et al, 2004).<papid> N04-1043 </papid></citsent>
<aftsection>
<nextsent>banko and brill (2001) <papid> P01-1005 </papid>suggested that the development of very large training corpora may be most effective for progress in empirical natural language processing.</nextsent>
<nextsent>their experiments show logarithmic trend in performance as corpus size increases without performance reaching an upper bound.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB423">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>section 7 presents our conclusions and directions for future work.
</prevsent>
<prevsent>this work presented here extends substantial body of previous work (blum and mitchell, 1998; riloff and jones, 1999; ando and zhang, 2005) <papid> P05-1001 </papid>48that all focus on reducing annotation requirements.</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
for the specific task of named entity annotation, some researchers have emphasized the creation of taggers from minimal seed sets (strzalkowski and wang, 1996; <papid> C96-2157 </papid>collins and singer, 1999; <papid> W99-0613 </papid>lin et al, 2003) while another line of inquiry (which we are pursuing) has sought to improve on high-performance baseline taggers (miller et al, 2004).<papid> N04-1043 </papid></citsent>
<aftsection>
<nextsent>banko and brill (2001) <papid> P01-1005 </papid>suggested that the development of very large training corpora may be most effective for progress in empirical natural language processing.</nextsent>
<nextsent>their experiments show logarithmic trend in performance as corpus size increases without performance reaching an upper bound.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB427">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>banko and brill (2001) <papid> P01-1005 </papid>suggested that the development of very large training corpora may be most effective for progress in empirical natural language processing.</prevsent>
<prevsent>their experiments show logarithmic trend in performance as corpus size increases without performance reaching an upper bound.</prevsent>
</prevsection>
<citsent citstr=" P02-1030 ">
recent work has replicated their work on thesaurus extraction (curran and moens, 2002) <papid> P02-1030 </papid>and is-a relation extraction (ravichandran et al, 2004), showing that collecting data over very large corpus significantly improves system per formance.</citsent>
<aftsection>
<nextsent>however, (curran, 2002) <papid> W02-1029 </papid>and (curran and osborne, 2002) <papid> W02-2008 </papid>claimed that the choice of statistical model is more important than relying upon large corpora.</nextsent>
<nextsent>the performance of name taggers has been limited in part by the amount of labeled training data available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB428">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>their experiments show logarithmic trend in performance as corpus size increases without performance reaching an upper bound.
</prevsent>
<prevsent>recent work has replicated their work on thesaurus extraction (curran and moens, 2002) <papid> P02-1030 </papid>and is-a relation extraction (ravichandran et al, 2004), showing that collecting data over very large corpus significantly improves system per formance.</prevsent>
</prevsection>
<citsent citstr=" W02-1029 ">
however, (curran, 2002) <papid> W02-1029 </papid>and (curran and osborne, 2002) <papid> W02-2008 </papid>claimed that the choice of statistical model is more important than relying upon large corpora.</citsent>
<aftsection>
<nextsent>the performance of name taggers has been limited in part by the amount of labeled training data available.
</nextsent>
<nextsent>how can an unlabeled corpus help to address this problem?
</nextsent>
<nextsent>based on its original training (on the labeled corpus), there will be some tags (in the unlabeled corpus) that the tagger will be very sure about.
</nextsent>
<nextsent>for example, there will be contexts that were always followed by person name (e.g.,  capt. ) in the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB429">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>their experiments show logarithmic trend in performance as corpus size increases without performance reaching an upper bound.
</prevsent>
<prevsent>recent work has replicated their work on thesaurus extraction (curran and moens, 2002) <papid> P02-1030 </papid>and is-a relation extraction (ravichandran et al, 2004), showing that collecting data over very large corpus significantly improves system per formance.</prevsent>
</prevsection>
<citsent citstr=" W02-2008 ">
however, (curran, 2002) <papid> W02-1029 </papid>and (curran and osborne, 2002) <papid> W02-2008 </papid>claimed that the choice of statistical model is more important than relying upon large corpora.</citsent>
<aftsection>
<nextsent>the performance of name taggers has been limited in part by the amount of labeled training data available.
</nextsent>
<nextsent>how can an unlabeled corpus help to address this problem?
</nextsent>
<nextsent>based on its original training (on the labeled corpus), there will be some tags (in the unlabeled corpus) that the tagger will be very sure about.
</nextsent>
<nextsent>for example, there will be contexts that were always followed by person name (e.g.,  capt. ) in the training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB430">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> baseline multi-lingual name tagger.  </section>
<citcontext>
<prevsection>
<prevsent>this process is performed repeatedly to bootstrap ourselves to higher performance.
</prevsent>
<prevsent>this approach can be used with any supervised-learning tagger that can produce some reliable measure of confidence in its decisions.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
our baseline name tagger is based on an hmm that generally follows the nymble model (bikel et al 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>then it uses best-first search to generate nbest hypotheses, and also computes the margin ? the difference between the log probabilities of the top two hypotheses.
</nextsent>
<nextsent>this is used as rough measure of confidence in our name tagging.1 in processing chinese, to take advantage of name structures, we do name structure parsing using an extended hmm which includes larger number of states (14).
</nextsent>
<nextsent>this new hmm can handle name prefixes and suffixes, and transliterated foreign names separately.
</nextsent>
<nextsent>we also augmented the hmm model with set of post-processing rules to correct some omissions and systematic errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB431">
<title id=" W06-0206.xml">data selection in semi supervised learning for name tagging </title>
<section> two semi-supervised learning meth-.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 bootstrapping.
</prevsent>
<prevsent>we divided the large unlabeled corpus into segments based on news sources and dates in order to: 1) create segments of manageable size; 2) separately evaluate the contribution of each segment (using labeled development test set) and reject those which do not help; and 3) apply the latest updated best model to each subsequent 1 we have also used this metric in the context of rescoring of.
</prevsent>
</prevsection>
<citsent citstr=" P05-1051 ">
name hypotheses (ji and grishman, 2005); <papid> P05-1051 </papid>scheffer et al (2001) used similar metric for active learning of name tags.</citsent>
<aftsection>
<nextsent>49 segment.
</nextsent>
<nextsent>the procedure can be formalized as follows.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>select related set relatedc from large cor-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB434">
<title id=" W04-3210.xml">automatic paragraph identification a study across languages and domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>written texts are usually broken up into sentences and paragraphs.
</prevsent>
<prevsent>sentence splitting is necessarypre-processing step for number of natural language processing (nlp) tasks including part-of speech tagging and parsing.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
since sentence-final punctuation can be ambiguous (e.g., period can also be used in an abbreviation as well as to mark the end of sentence), the task is not trivial and has consequently attracted lot of attention (e.g., rey nar and ratnaparkhi (1997)).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>in contrast, there has been virtually no previous research on inferring paragraph boundaries automatically.
</nextsent>
<nextsent>one reason for this is that paragraph boundaries are usually marked unambiguously by new line and extra white space.however, number of applications could benefit from paragraph detection mechanism.
</nextsent>
<nextsent>text to-text generation applications such as single- andmultidocument summarisation as well as text simplification usually take naturally occurring texts as input and transform them into new texts satisfying specific constraints (e.g., length, style, language).the output texts do not always preserve the structure and editing conventions of the original text.in summarisation, for example, sentences are typically extracted verbatim and concatenated to forma summary.
</nextsent>
<nextsent>insertion of paragraph breaks could im prove the readability of the summaries by indicating topic shifts and providing visual targets to the reader (stark, 1988).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB435">
<title id=" W04-3210.xml">automatic paragraph identification a study across languages and domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>further more, sometimes the output of speech recogniser needs to be processed automatically by applications such as information extraction or summarisation.
</prevsent>
<prevsent>most of these applications (e.g., christensen et al, (2004)) port techniques developed for written texts to spoken texts and therefore require input that is punctuated and broken into paragraphs.
</prevsent>
</prevsection>
<citsent citstr=" A00-1012 ">
while there has been some research on finding sentence boundaries in spoken text (stevenson and gaizauskas, 2000), <papid> A00-1012 </papid>there has been little research on determining paragraph boundaries.1if paragraph boundaries were mainly an aesthetic device for visually breaking up long texts into smaller chunks, as has previously been suggested (see long acre (1979)), paragraph boundaries could be easily inserted by splitting text into several equal-size segments.</citsent>
<aftsection>
<nextsent>psycho-linguistic research, however, indicates that paragraph boundaries are not purely aesthetic.
</nextsent>
<nextsent>for example, stark (1988) 1there has been research on using phonetic cues to segment speech into acoustic paragraphs?
</nextsent>
<nextsent>(hauptmann and smith, 1995).
</nextsent>
<nextsent>however, these do not necessarily correspond to writtenparagraphs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB436">
<title id=" W04-3210.xml">automatic paragraph identification a study across languages and domains </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>previous work has focused extensively on the task of automatic text segmentation whose primary goalis to divide individual texts into sub-topics.
</prevsent>
<prevsent>despite their differences, most methods are unsupervised and typically relyon the distribution of wordsin given text to provide cues for topic segmentation.2 hearsts (1997) text tiling algorithm, forex ample, determines sub-topic boundaries on the basisof term overlap in adjacent text blocks.
</prevsent>
</prevsection>
<citsent citstr=" P01-1064 ">
in more recent work, utiyama and isahara (2001) <papid> P01-1064 </papid>combine statistical segmentation model with graph search algorithm to find the segmentation with the maximum probability.</citsent>
<aftsection>
<nextsent>beeferman et al (1999) use supervised learning methods to infer boundaries between texts.
</nextsent>
<nextsent>they employ language models to detect topic shifts and combine them with cue word features.
</nextsent>
<nextsent>2due to lack of space we do not describe previous work in text segmentation here in detail; we refer the reader to utiyama and isahara (2001) <papid> P01-1064 </papid>and pevzener and hearst (2002) for comprehensive overview.</nextsent>
<nextsent>our work differs from these previous approaches in that paragraphs do not always correspond to subtopics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB439">
<title id=" W04-3210.xml">automatic paragraph identification a study across languages and domains </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>we measured distance in terms of the number of intervening sentences (ds) as well as in terms of the number of intervening words (dw).
</prevsent>
<prevsent>if paragraph breaks were driven purely by aesthetics one would expect this feature to be among the most successful ones.6 sentence length (length): this feature encodes the number of words in the current sentence.
</prevsent>
</prevsection>
<citsent citstr=" W03-1009 ">
average sentence length is known to vary with text position (genzel and charniak, 2003) <papid> W03-1009 </papid>and it is possible that it also varies with paragraph position.</citsent>
<aftsection>
<nextsent>relative position (pos): the relative position of asentence in the text is calculated by dividing the current sentence number by the number of sentences in the text.
</nextsent>
<nextsent>the motivation for this feature is that paragraph length may vary with text position.
</nextsent>
<nextsent>for example, it is possible that paragraphs at the beginning and end of text are shorter than paragraphs in the middle and hence paragraph break is more likely at the two former text positions.
</nextsent>
<nextsent>quotes (quotep, quotec, quotei): these features encode whether the previous or current sentence contain quotation (quotep and quotec, respectively) and whether the current sentence continues quotation that started in preceding sentence (quotei).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB443">
<title id=" W04-3210.xml">automatic paragraph identification a study across languages and domains </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>we additionally experimented with character level n-gram models.
</prevsent>
<prevsent>such models are defined overa relatively small vocabulary and can be easily constructed for any language without pre-processing.
</prevsent>
</prevsection>
<citsent citstr=" E03-1053 ">
character level n-gram models have been applied to the problem of authorship attribution and obtained state-of-the art results (peng et al, 2003).<papid> E03-1053 </papid>if some characters are more often attested in paragraph starting sentences (e.g., a? or t?), then we expect these sentences to have higher probability compared to non-paragraph starting ones.</citsent>
<aftsection>
<nextsent>again, we used the cmu toolkit for building the character level n-gram models.
</nextsent>
<nextsent>we experimented with models whose length varied from 2 to 8 and estimated the probability assigned to sentence according to the character level model (cmp).
</nextsent>
<nextsent>3.2.3 syntactic features for the english data we also used several features encoding syntactic complexity.
</nextsent>
<nextsent>genzel and charniak (2003) <papid> W03-1009 </papid>suggested that the syntactic complexity of sentences varies with their position in paragraph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB447">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally,we propose new figure-of-merit for best first parsing with confidence-rated inferences.
</prevsent>
<prevsent>our implementation is freely available at: http://cs.nyu.edu/turian/ software/parser/
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
discriminative machine learning methods have improved accuracy on many nlp tasks, such as pos tagging (toutanova et al, 2003), <papid> N03-1033 </papid>machine translation (och &amp; ney, 2002), <papid> P02-1038 </papid>and relation extraction (zhao &amp; grishman, 2005).<papid> P05-1052 </papid></citsent>
<aftsection>
<nextsent>there are strong reasons to believe the same would be true of parsing.
</nextsent>
<nextsent>however, only limited advances have been made thus far, perhaps due to various limitations of extant discriminative parsers.
</nextsent>
<nextsent>in this paper, we present some innovations aimed at reducing or eliminating some of these limitations, specifically for the task of constituent pars ing:?
</nextsent>
<nextsent>we show how constituent parsing can be performed using standard classification techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB449">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally,we propose new figure-of-merit for best first parsing with confidence-rated inferences.
</prevsent>
<prevsent>our implementation is freely available at: http://cs.nyu.edu/turian/ software/parser/
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
discriminative machine learning methods have improved accuracy on many nlp tasks, such as pos tagging (toutanova et al, 2003), <papid> N03-1033 </papid>machine translation (och &amp; ney, 2002), <papid> P02-1038 </papid>and relation extraction (zhao &amp; grishman, 2005).<papid> P05-1052 </papid></citsent>
<aftsection>
<nextsent>there are strong reasons to believe the same would be true of parsing.
</nextsent>
<nextsent>however, only limited advances have been made thus far, perhaps due to various limitations of extant discriminative parsers.
</nextsent>
<nextsent>in this paper, we present some innovations aimed at reducing or eliminating some of these limitations, specifically for the task of constituent pars ing:?
</nextsent>
<nextsent>we show how constituent parsing can be performed using standard classification techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB450">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally,we propose new figure-of-merit for best first parsing with confidence-rated inferences.
</prevsent>
<prevsent>our implementation is freely available at: http://cs.nyu.edu/turian/ software/parser/
</prevsent>
</prevsection>
<citsent citstr=" P05-1052 ">
discriminative machine learning methods have improved accuracy on many nlp tasks, such as pos tagging (toutanova et al, 2003), <papid> N03-1033 </papid>machine translation (och &amp; ney, 2002), <papid> P02-1038 </papid>and relation extraction (zhao &amp; grishman, 2005).<papid> P05-1052 </papid></citsent>
<aftsection>
<nextsent>there are strong reasons to believe the same would be true of parsing.
</nextsent>
<nextsent>however, only limited advances have been made thus far, perhaps due to various limitations of extant discriminative parsers.
</nextsent>
<nextsent>in this paper, we present some innovations aimed at reducing or eliminating some of these limitations, specifically for the task of constituent pars ing:?
</nextsent>
<nextsent>we show how constituent parsing can be performed using standard classification techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB451">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> parsing by classification.  </section>
<citcontext>
<prevsection>
<prevsent>y = +1 ifi?
</prevsent>
<prevsent>is correct inference and 1 otherwise.
</prevsent>
</prevsection>
<citsent citstr=" W05-1513 ">
this approach differs from that of yamada and matsumoto (2003) and sagae and lavie (2005), <papid> W05-1513 </papid>who parallelize according to the pos tag of one of the child items.</citsent>
<aftsection>
<nextsent>2.1.1 generating training examples our method of generating training examples does not require working parser, and can be run prior to any training.
</nextsent>
<nextsent>it is similar to the method used in the literature by deterministic parsers (yamada &amp; matsumoto, 2003; sagae &amp; lavie, 2005) <papid> W05-1513 </papid>with one ex ception: depending upon the order constituents are inferred, there may be multiple bottom-up paths that lead to the same final parse, so to generate training examples we choose single random path that leadsto the gold-standard parse tree.1 the training examples correspond to all candidate inferences considered in every state along this path, nearly all of which are incorrect inferences (with = 1).</nextsent>
<nextsent>for instance, only 4.4% of candidate np-inferences are correct.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB454">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> parsing by classification.  </section>
<citcontext>
<prevsection>
<prevsent>is 0.
</prevsent>
<prevsent>in our experiments, we used  = 108.
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
although our example weights are un normalized, so far weve found no benefit from scaling  as collins and koo (2005) <papid> J05-1003 </papid>suggest.</citsent>
<aftsection>
<nextsent>all inferences that fall in particular leaf node are assigned the same confidence: if inference falls in leaf node in the tth decision tree, then qt(i) = tf . 2.1.3 calibrating the sub-classifiers an important concern is when to stop growing the decision tree.
</nextsent>
<nextsent>we propose the minimum reduction in loss (mrl) stopping criterion: during training, there is value at iteration which serves as threshold on the minimum reduction in loss for leaf splits.
</nextsent>
<nextsent>if there is no splitting feature for leaf that reduces loss by at least then is not split.
</nextsent>
<nextsent>formally, leaf will not be bisected during iteration if max???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB455">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> parsing by classification.  </section>
<citcontext>
<prevsection>
<prevsent>our scoring function and parsing algorithm have no such limitations.
</prevsent>
<prevsent>q can, in principle, use arbitrary information from the history to evaluate constituent inferences.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
although some of our feature types are based on prior work (collins, 1999; klein &amp; manning, 2003; <papid> P03-1054 </papid>bikel, 2004), <papid> J04-4004 </papid>wenote that our scoring function uses more history information than typical parsers.</citsent>
<aftsection>
<nextsent>all features check whether an item has someproperty; specifically, whether the items label/headtag/headword is certain value.
</nextsent>
<nextsent>these features perform binary tests on the state directly, unlike henderson (2003) <papid> N03-1014 </papid>which works with an intermediate representation of the history.</nextsent>
<nextsent>in our baseline setup, feature set ? contained five different feature types, described in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB456">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> parsing by classification.  </section>
<citcontext>
<prevsection>
<prevsent>our scoring function and parsing algorithm have no such limitations.
</prevsent>
<prevsent>q can, in principle, use arbitrary information from the history to evaluate constituent inferences.
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
although some of our feature types are based on prior work (collins, 1999; klein &amp; manning, 2003; <papid> P03-1054 </papid>bikel, 2004), <papid> J04-4004 </papid>wenote that our scoring function uses more history information than typical parsers.</citsent>
<aftsection>
<nextsent>all features check whether an item has someproperty; specifically, whether the items label/headtag/headword is certain value.
</nextsent>
<nextsent>these features perform binary tests on the state directly, unlike henderson (2003) <papid> N03-1014 </papid>which works with an intermediate representation of the history.</nextsent>
<nextsent>in our baseline setup, feature set ? contained five different feature types, described in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB457">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> parsing by classification.  </section>
<citcontext>
<prevsection>
<prevsent>although some of our feature types are based on prior work (collins, 1999; klein &amp; manning, 2003; <papid> P03-1054 </papid>bikel, 2004), <papid> J04-4004 </papid>wenote that our scoring function uses more history information than typical parsers.</prevsent>
<prevsent>all features check whether an item has someproperty; specifically, whether the items label/headtag/headword is certain value.</prevsent>
</prevsection>
<citsent citstr=" N03-1014 ">
these features perform binary tests on the state directly, unlike henderson (2003) <papid> N03-1014 </papid>which works with an intermediate representation of the history.</citsent>
<aftsection>
<nextsent>in our baseline setup, feature set ? contained five different feature types, described in table 1.
</nextsent>
<nextsent>table 2 feature item groups.
</nextsent>
<nextsent>all children ? all non-head children ? all non-leftmost children ? all non-rightmost children ? all children left of the head ? all children right of the head ? head-child and all children left of the head ? head-child and all children right of the head 2.2 aggregating confidences.
</nextsent>
<nextsent>to get the cumulative score of parse path p, we apply aggregatora over the confidences q(i) in equation 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB458">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>at this ??, there were total of 9297 decision tree splits in the parser (summed over all constituent classifiers), lfms = 87.16, lrcl = 86.32, and lprc = 88.02.
</prevsent>
<prevsent>3.2 beam width.
</prevsent>
</prevsection>
<citsent citstr=" W04-3203 ">
to determine the effect of the beam width on the accuracy, we evaluated the baseline on the development set using beam width of 1, i.e. parsing entirely greedily (wong &amp; wu, 1999; kalt, 2004;<papid> W04-3203 </papid>sagae &amp; lavie, 2005).<papid> W05-1513 </papid></citsent>
<aftsection>
<nextsent>table 4 compares the base 145 table 3 steps for preprocessing the data.
</nextsent>
<nextsent>starred steps are performed only on input with tree structure.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>* strip functional tags and trace indices, and remove traces.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB460">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>* convert prt to advp.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
(this convention was established by magerman (1995).)<papid> P95-1037 </papid></citsent>
<aftsection>
<nextsent>3.
</nextsent>
<nextsent>remove quotation marks (i.e. terminal items tagged ??
</nextsent>
<nextsent>or ??).
</nextsent>
<nextsent>(bikel, 2004).<papid> J04-4004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB463">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>* remove unary projections to self (i.e. duplicate items with the same span and label).
</prevsent>
<prevsent>7.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
pos tag the text using ratnaparkhi (1996)<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>8.
</nextsent>
<nextsent>lowercase headwords..
</nextsent>
<nextsent>9.
</nextsent>
<nextsent>replace any word observed fewer than 5 times in the (lower-cased) training sentences with unk..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB465">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>9.
</prevsent>
<prevsent>replace any word observed fewer than 5 times in the (lower-cased) training sentences with unk..
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
a as pointed out by an anonymous reviewer of collins (2003), <papid> J03-4003 </papid>removing outermost punctuation may discard useful information.</citsent>
<aftsection>
<nextsent>its also worth noting that collins and roark (2004) <papid> P04-1015 </papid>saw lfms improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.</nextsent>
<nextsent>figure 2 parseval scores of the baseline on the ? 15 words development set of the penn treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB466">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>replace any word observed fewer than 5 times in the (lower-cased) training sentences with unk..
</prevsent>
<prevsent>a as pointed out by an anonymous reviewer of collins (2003), <papid> J03-4003 </papid>removing outermost punctuation may discard useful information.</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
its also worth noting that collins and roark (2004) <papid> P04-1015 </papid>saw lfms improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.</citsent>
<aftsection>
<nextsent>figure 2 parseval scores of the baseline on the ? 15 words development set of the penn treebank.
</nextsent>
<nextsent>thetop x-axis shows accuracy as the minimum reduction in loss ??
</nextsent>
<nextsent>decreases.
</nextsent>
<nextsent>the bottom shows the corresponding number of decision tree splits in the parser, summed over all classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB467">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this was late-breaking result, and we used the full vocabulary condition as our final parser for parsing the test set.
</prevsent>
<prevsent>3.7 test set results.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
table 9 shows the results of our best parser on the ? 15 words test set, as well as the accuracy reported for recent discriminative parser (taskar et al,2004) <papid> W04-3201 </papid>and scores we obtained by training and testing the parsers of charniak (2000) <papid> A00-2018 </papid>and bikel (2004) <papid> J04-4004 </papid>on the same data.</citsent>
<aftsection>
<nextsent>bikel (2004) <papid> J04-4004 </papid>is clean room?</nextsent>
<nextsent>re implementation of the collins parser (collins, 1999) with comparable accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB468">
<title id=" W05-1515.xml">constituent parsing by classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this was late-breaking result, and we used the full vocabulary condition as our final parser for parsing the test set.
</prevsent>
<prevsent>3.7 test set results.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
table 9 shows the results of our best parser on the ? 15 words test set, as well as the accuracy reported for recent discriminative parser (taskar et al,2004) <papid> W04-3201 </papid>and scores we obtained by training and testing the parsers of charniak (2000) <papid> A00-2018 </papid>and bikel (2004) <papid> J04-4004 </papid>on the same data.</citsent>
<aftsection>
<nextsent>bikel (2004) <papid> J04-4004 </papid>is clean room?</nextsent>
<nextsent>re implementation of the collins parser (collins, 1999) with comparable accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB499">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>patterns are applied to text which has undergone various levels of linguistic analysis, such as phrase chunking (soder land, 1999) and full syntactic parsing (gaizauskaset al, 1996).
</prevsent>
<prevsent>the approaches use different definitions of what constitutes valid pattern.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
for example, the auto slog system (riloff, 1993) uses patterns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while yangarber et al (2000) <papid> C00-2136 </papid>use subject-verb object tuples derived from dependency parse.</citsent>
<aftsection>
<nextsent>an appropriate pattern language must encode enough information about the text to be able to accurately identify the items of interest.
</nextsent>
<nextsent>however, it should not contain so much information as to be complex and impractical to apply.several recent approaches to ie have used patterns based on dependency analysis of the input text (yangarber, 2003; <papid> P03-1044 </papid>sudo et al, 2001; <papid> H01-1009 </papid>sudo et al., 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005; <papid> H05-1091 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></nextsent>
<nextsent>these approaches have used variety of pattern models (schemes for representing ie patterns based on particular parts of the dependency tree).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB501">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the auto slog system (riloff, 1993) uses patterns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while yangarber et al (2000) <papid> C00-2136 </papid>use subject-verb object tuples derived from dependency parse.</prevsent>
<prevsent>an appropriate pattern language must encode enough information about the text to be able to accurately identify the items of interest.</prevsent>
</prevsection>
<citsent citstr=" P03-1044 ">
however, it should not contain so much information as to be complex and impractical to apply.several recent approaches to ie have used patterns based on dependency analysis of the input text (yangarber, 2003; <papid> P03-1044 </papid>sudo et al, 2001; <papid> H01-1009 </papid>sudo et al., 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005; <papid> H05-1091 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches have used variety of pattern models (schemes for representing ie patterns based on particular parts of the dependency tree).
</nextsent>
<nextsent>for example, yangarber (2003) <papid> P03-1044 </papid>uses just subject-verb-object tuples while sudo et al (2003) <papid> P03-1029 </papid>allow any subpart of the tree toact as an extraction pattern.</nextsent>
<nextsent>the set of patterns allowed by the first model is proper subset of the second and therefore captures less of the information contained in the dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB503">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the auto slog system (riloff, 1993) uses patterns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while yangarber et al (2000) <papid> C00-2136 </papid>use subject-verb object tuples derived from dependency parse.</prevsent>
<prevsent>an appropriate pattern language must encode enough information about the text to be able to accurately identify the items of interest.</prevsent>
</prevsection>
<citsent citstr=" H01-1009 ">
however, it should not contain so much information as to be complex and impractical to apply.several recent approaches to ie have used patterns based on dependency analysis of the input text (yangarber, 2003; <papid> P03-1044 </papid>sudo et al, 2001; <papid> H01-1009 </papid>sudo et al., 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005; <papid> H05-1091 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches have used variety of pattern models (schemes for representing ie patterns based on particular parts of the dependency tree).
</nextsent>
<nextsent>for example, yangarber (2003) <papid> P03-1044 </papid>uses just subject-verb-object tuples while sudo et al (2003) <papid> P03-1029 </papid>allow any subpart of the tree toact as an extraction pattern.</nextsent>
<nextsent>the set of patterns allowed by the first model is proper subset of the second and therefore captures less of the information contained in the dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB504">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the auto slog system (riloff, 1993) uses patterns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while yangarber et al (2000) <papid> C00-2136 </papid>use subject-verb object tuples derived from dependency parse.</prevsent>
<prevsent>an appropriate pattern language must encode enough information about the text to be able to accurately identify the items of interest.</prevsent>
</prevsection>
<citsent citstr=" P03-1029 ">
however, it should not contain so much information as to be complex and impractical to apply.several recent approaches to ie have used patterns based on dependency analysis of the input text (yangarber, 2003; <papid> P03-1044 </papid>sudo et al, 2001; <papid> H01-1009 </papid>sudo et al., 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005; <papid> H05-1091 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches have used variety of pattern models (schemes for representing ie patterns based on particular parts of the dependency tree).
</nextsent>
<nextsent>for example, yangarber (2003) <papid> P03-1044 </papid>uses just subject-verb-object tuples while sudo et al (2003) <papid> P03-1029 </papid>allow any subpart of the tree toact as an extraction pattern.</nextsent>
<nextsent>the set of patterns allowed by the first model is proper subset of the second and therefore captures less of the information contained in the dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB505">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the auto slog system (riloff, 1993) uses patterns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while yangarber et al (2000) <papid> C00-2136 </papid>use subject-verb object tuples derived from dependency parse.</prevsent>
<prevsent>an appropriate pattern language must encode enough information about the text to be able to accurately identify the items of interest.</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
however, it should not contain so much information as to be complex and impractical to apply.several recent approaches to ie have used patterns based on dependency analysis of the input text (yangarber, 2003; <papid> P03-1044 </papid>sudo et al, 2001; <papid> H01-1009 </papid>sudo et al., 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005; <papid> H05-1091 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches have used variety of pattern models (schemes for representing ie patterns based on particular parts of the dependency tree).
</nextsent>
<nextsent>for example, yangarber (2003) <papid> P03-1044 </papid>uses just subject-verb-object tuples while sudo et al (2003) <papid> P03-1029 </papid>allow any subpart of the tree toact as an extraction pattern.</nextsent>
<nextsent>the set of patterns allowed by the first model is proper subset of the second and therefore captures less of the information contained in the dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB506">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the auto slog system (riloff, 1993) uses patterns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while yangarber et al (2000) <papid> C00-2136 </papid>use subject-verb object tuples derived from dependency parse.</prevsent>
<prevsent>an appropriate pattern language must encode enough information about the text to be able to accurately identify the items of interest.</prevsent>
</prevsection>
<citsent citstr=" P05-1047 ">
however, it should not contain so much information as to be complex and impractical to apply.several recent approaches to ie have used patterns based on dependency analysis of the input text (yangarber, 2003; <papid> P03-1044 </papid>sudo et al, 2001; <papid> H01-1009 </papid>sudo et al., 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005; <papid> H05-1091 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches have used variety of pattern models (schemes for representing ie patterns based on particular parts of the dependency tree).
</nextsent>
<nextsent>for example, yangarber (2003) <papid> P03-1044 </papid>uses just subject-verb-object tuples while sudo et al (2003) <papid> P03-1029 </papid>allow any subpart of the tree toact as an extraction pattern.</nextsent>
<nextsent>the set of patterns allowed by the first model is proper subset of the second and therefore captures less of the information contained in the dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB530">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>there are 3911 instances of binary relations in all corpora.
</prevsent>
<prevsent>4.2 generating dependency patterns.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
three dependency parsers were used for these ex periments: minipar3 (lin, 1999), the machin ese syntax4 parser from conn exor oy (tapanainen and jarvinen, 1997) <papid> A97-1011 </papid>and the stanford5 parser (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>these three parsers represent cross-section of approaches to producing dependency analyses: minipar uses constituency grammar internally before converting the result to dependency tree, machin ese syntax uses functional dependency grammar, and the stanford parser is lexicalized probabilistic parser.
</nextsent>
<nextsent>before these parsers were applied to the various corpora the named entities participating in relations are replaced by token indicating their class.
</nextsent>
<nextsent>for example, in the muc6 corpus acme hired smith?
</nextsent>
<nextsent>would become organisation hired personin?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB531">
<title id=" W06-0202.xml">comparing information extraction pattern models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>there are 3911 instances of binary relations in all corpora.
</prevsent>
<prevsent>4.2 generating dependency patterns.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
three dependency parsers were used for these ex periments: minipar3 (lin, 1999), the machin ese syntax4 parser from conn exor oy (tapanainen and jarvinen, 1997) <papid> A97-1011 </papid>and the stanford5 parser (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>these three parsers represent cross-section of approaches to producing dependency analyses: minipar uses constituency grammar internally before converting the result to dependency tree, machin ese syntax uses functional dependency grammar, and the stanford parser is lexicalized probabilistic parser.
</nextsent>
<nextsent>before these parsers were applied to the various corpora the named entities participating in relations are replaced by token indicating their class.
</nextsent>
<nextsent>for example, in the muc6 corpus acme hired smith?
</nextsent>
<nextsent>would become organisation hired personin?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB538">
<title id=" W05-0624.xml">sparse bayesian classification of predicate arguments </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>of the node features, we here pay most attention to the parse tree path features.
</prevsent>
<prevsent>3.1 predicate features.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
we used the following predicate features, all of which first appeared in (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>178 ? predicate lemma.
</nextsent>
<nextsent>subcategorization frame.
</nextsent>
<nextsent>voice.
</nextsent>
<nextsent>3.2 node features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB542">
<title id=" W05-0624.xml">sparse bayesian classification of predicate arguments </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>dependency tree path.
</prevsent>
<prevsent>we believe that labeled dependency paths provide more information about grammatical functions (and, implicitly, semantic relationships) than the raw constituent structure.
</prevsent>
</prevsection>
<citsent citstr=" W04-0814 ">
since the grammatical functions are not directly available from the parse trees, we investigated two approximations of dependency arc labels: first, the poss of the head tokens; secondly, the pts of the head node and its immediate parent (such labels were used in (ahn et al, 2004)).<papid> W04-0814 </papid></citsent>
<aftsection>
<nextsent>shallow path.
</nextsent>
<nextsent>since the upc shallow parsers were expected to be more robust than the full parsers, we used shallow path feature.
</nextsent>
<nextsent>we first built parse tree using clause and chunk bracketing, and the shallow path feature was then constructed like the constituent tree path.
</nextsent>
<nextsent>subpaths.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB543">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> recent developments.  </section>
<citcontext>
<prevsection>
<prevsent>knight and marcu (2000) equate summarization with compression at sentence level to achieve grammaticality and information capture, and push step beyond sentence extraction.
</prevsent>
<prevsent>many systems use machine learning methods to learn from readily aligned corpora of scientific articles and their corresponding abstracts.
</prevsent>
</prevsection>
<citsent citstr=" N03-1037 ">
zhou and hovy (2003) <papid> N03-1037 </papid>show summarization system trained from automatically obtained text-summary alignments obeying the chronological occurrences of news events.</citsent>
<aftsection>
<nextsent>mds poses more challenges in assessing similarities and differences among the set ofdocuments.
</nextsent>
<nextsent>the simple idea of extract-and concatenate does not respond to problems arisen from coherence and cohesion.
</nextsent>
<nextsent>barzilay et al (1999) <papid> P99-1071 </papid>introduce combination of extracted similar phrases and reformulation through sentence generation.</nextsent>
<nextsent>lin and hovy (2002) apply collection of known single-document summarization techniques, cooperating positional and topical information, clustering, etc., and extend them to perform mds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB544">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> recent developments.  </section>
<citcontext>
<prevsection>
<prevsent>mds poses more challenges in assessing similarities and differences among the set ofdocuments.
</prevsent>
<prevsent>the simple idea of extract-and concatenate does not respond to problems arisen from coherence and cohesion.
</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
barzilay et al (1999) <papid> P99-1071 </papid>introduce combination of extracted similar phrases and reformulation through sentence generation.</citsent>
<aftsection>
<nextsent>lin and hovy (2002) apply collection of known single-document summarization techniques, cooperating positional and topical information, clustering, etc., and extend them to perform mds.
</nextsent>
<nextsent>while many have suggested that conventional mds systems can be applied to biography generation directly, mani (2001) illustrates that the added functionality of biographical mds comes at the expense of substantial increase in system complexity and is somewhat beyond the capabilities of present day mds systems.
</nextsent>
<nextsent>the discussion was based in part on the only known mds biography system (schiffman et al, 2001) <papid> P01-1059 </papid>that uses corpus statistics along with linguistic knowledge to select and merge description of people in news.</nextsent>
<nextsent>the focus of this work was on synthesizing succinct descriptions of people by merging appositives from semantic processing using wordnet (miller, 1995).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB545">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> recent developments.  </section>
<citcontext>
<prevsection>
<prevsent>lin and hovy (2002) apply collection of known single-document summarization techniques, cooperating positional and topical information, clustering, etc., and extend them to perform mds.
</prevsent>
<prevsent>while many have suggested that conventional mds systems can be applied to biography generation directly, mani (2001) illustrates that the added functionality of biographical mds comes at the expense of substantial increase in system complexity and is somewhat beyond the capabilities of present day mds systems.
</prevsent>
</prevsection>
<citsent citstr=" P01-1059 ">
the discussion was based in part on the only known mds biography system (schiffman et al, 2001) <papid> P01-1059 </papid>that uses corpus statistics along with linguistic knowledge to select and merge description of people in news.</citsent>
<aftsection>
<nextsent>the focus of this work was on synthesizing succinct descriptions of people by merging appositives from semantic processing using wordnet (miller, 1995).
</nextsent>
<nextsent>in order to extract information that is related to person from large set of news texts written not exclusively about this person, we need to identify attributes shared among biographies.
</nextsent>
<nextsent>biographies share certain standard components.
</nextsent>
<nextsent>we annotated corpus of 130 biographies of 12 people (activists, artists, leaders, politicians, scientists, terrorists, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB546">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> sentence classification.  </section>
<citcontext>
<prevsection>
<prevsent>table 1.
</prevsent>
<prevsent>performance of 10-class sentence classification, using nave bayes classifier.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
part-of-speech (pos) information (brill, 1995) <papid> J95-4004 </papid>and word stems (lovins, 1968) were used in some feature sets.we boot strapped 10395 more biography indicating words by recording the immediate hypernyms, using wordnet (fellbaum, 1998), of the words collected from the controlled biography corpus described in section 3.</citsent>
<aftsection>
<nextsent>these words are called expanded unigrams and their frequency scores are reduced to fraction of the original words frequency score.
</nextsent>
<nextsent>some sentences in the testing set were labeled with multiple biography classes due to the fact that the original corpus was annotated at clause level.
</nextsent>
<nextsent>since the classification was done at sentence level, we relaxed the matching/evaluating program allowing hit when any of the several classes was matched.
</nextsent>
<nextsent>this is shown in table 1 as the relaxed cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB547">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> biography extraction.  </section>
<citcontext>
<prevsection>
<prevsent>sentences classified as biography-worthy are merged with the name-filtered sentences with duplicates eliminated.
</prevsent>
<prevsent>5.2 sentence ranking.
</prevsent>
</prevsection>
<citsent citstr=" W00-0405 ">
an essential capability of multi-document summarizer is to combine text passages in useful manner for the reader (goldstein et al, 2000).<papid> W00-0405 </papid></citsent>
<aftsection>
<nextsent>this includes sentence ordering parameter (mani, 2001).
</nextsent>
<nextsent>each of the sentences selected by the name-filter and the biography classifier is either related to the person-in-question via some news event or referred to as part of this persons biographical profile, or both.
</nextsent>
<nextsent>we need mechanism that will select sentences that are of informative significance within the source document set.
</nextsent>
<nextsent>using inverse-term-frequency (itf), i.e. an estimation of information value, words with high information value (low itf) are distinguished from those with low value (high itf).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB549">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>here we will show the performance of the resulting summaries.
</prevsent>
<prevsent>6.2 coverage evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
an intrinsic evaluation of biography summary was recently conducted under the guidance of document understanding conference (duc2004) using the automatic summarization evaluation tool rouge (recall-oriented understudy for gisting evaluation) by lin and hovy (2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>50 trec english document clusters, each containing on average 10 news articles, were the input to the system.
</nextsent>
<nextsent>summary length was restricted to 665 bytes.
</nextsent>
<nextsent>brute force truncation was applied on longer summaries.
</nextsent>
<nextsent>the rouge-l metric is based on longest common sub sequence (lcs) overlap (saggion et al., 2002).<papid> C02-1073 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB550">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>summary length was restricted to 665 bytes.
</prevsent>
<prevsent>brute force truncation was applied on longer summaries.
</prevsent>
</prevsection>
<citsent citstr=" C02-1073 ">
the rouge-l metric is based on longest common sub sequence (lcs) overlap (saggion et al., 2002).<papid> C02-1073 </papid></citsent>
<aftsection>
<nextsent>figure 2 shows that our system (86) performs at an equivalent level with the best systems 9 and 10, that is, they both lie within our systems 95% upper confidence interval.
</nextsent>
<nextsent>the 2 class classification module was used in generating the answers.
</nextsent>
<nextsent>the figure also shows the performance data evaluated with lower and higher confidences set at 95%.
</nextsent>
<nextsent>the performance data are from official duc results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB552">
<title id=" W04-3256.xml">multi document biography summarization </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>while cosine similarity and unigram and bigram overlap demonstrate sufficient measure on content coverage, they are not sensitive on how information is sequenced in the text (saggion et al, 2002).<papid> C02-1073 </papid></prevsent>
<prevsent>in evaluating and analyzing mds results, metrics, such as rouge-l, that consider linguistic sequence are essential.</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
radev and mckeown (1998) <papid> J98-3005 </papid>point out when summarizing interesting news events from multiple sources, one can expect reports with contradictory and redundant information.</citsent>
<aftsection>
<nextsent>an intelligent summarizer should attain as much information as possible, combine it, and present it in the most concise form to the user.
</nextsent>
<nextsent>when we look at the different attributes in persons life reported in news articles, person is described by the job positions that he/she has held, by education institutions that he/she has attended, and etc. those data are confirmed biographical information and do not bear the necessary contradiction associated with evolving news stories.
</nextsent>
<nextsent>however, we do feel the need to address and resolve discrepancies if we were to create comprehensive and detailed 0.25 0.3 0.35 0.4 0.45 0.5 0.55 e h a c 9 10 11 12 13 86 15 16 17 18 19 20 5 22 23 24 25 26 27 28 29 30 31 rouge-l 95% ci lower 95% ci higher figure 2.
</nextsent>
<nextsent>official rouge performance results from duc2004.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB553">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it is only weak regularizer that cannot avoid over fitting in situations where the number of training examples is significantly smaller than the number of features.
</prevsent>
<prevsent>in such situations some features will occur zero times on the training set and receive negative infinity weights, causing the assignment of zero probabilities for inputs including those features.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
similar assignment of (negative) infinity weights happens to features that are pseudo minimal (or pseudo-maximal) on the training set (see johnson et al  (1999)), <papid> P99-1069 </papid>that is, features whose value on correct parses always is less (or greater) 1this research has been funded in part by contractmda904-03-c-0404 of the advanced research and development activity, novel intelligence from massive data program.</citsent>
<aftsection>
<nextsent>than or equal to their value on all other parses.
</nextsent>
<nextsent>also, if large features sets are generated automatically from conjunctions of simple feature tests, many features will be redundant.
</nextsent>
<nextsent>besides over fitting, large feature sets also create the problem of increased time and space complexity.
</nextsent>
<nextsent>common techniques to deal with these problems are regularization and feature selection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB555">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since this discontinuity makes optimization hard numerical problem, standard gradient-based techniques for estimation cannot be applied directly.
</prevsent>
<prevsent>tibshirani (1996) presents specialized optimization algorithm for `1 regularization for linear least-squares regression called the lasso algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W03-1018 ">
goodman (2003) and kazama and tsujii(2003) <papid> W03-1018 </papid>employ standard iterative scaling and conjugate gradient techniques, however, for regularization simplified one-sided exponential prior is employed which is non-zero only for non-negative parameter values.</citsent>
<aftsection>
<nextsent>in these approaches the full feature space is considered in estimation, so saving sin computational complexity are gained only in applications of the resulting sparse models.
</nextsent>
<nextsent>perkins et al  (2003) presented an approach that combines`1 based regularization with incremental feature selection.
</nextsent>
<nextsent>their basic idea is to start with model in which almost all weights are zero, and iteratively decide, by comparing regularized feature gradients, which weight should be adjusted away from zeroin order to decrease the regularized objective function by the maximum amount.
</nextsent>
<nextsent>the `1 regularizer is thus used directly for incremental feature selection, which on the one hand makes feature selection fast, and on the other hand avoids numerical problems for zero-valued weights since only non-zero weights are included in the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB556">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>after adding ? 1 features to the model ina grafting step, the model is optimized with respect to all parameters corresponding to currently included features.
</prevsent>
<prevsent>this optimization is done by calling gradient-based general purpose optimization routine for the regularized objective function.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
we use conjugate gradient routine for this purpose (minka, 2001; malouf, 2002)<papid> W02-2018 </papid>2.</citsent>
<aftsection>
<nextsent>the gradient of our criterion with respect to parameter is: c(?)
</nextsent>
<nextsent>i = 1 m?
</nextsent>
<nextsent>k=1 l(?)
</nextsent>
<nextsent>i + ? sign(i) 2note that despite gradient feature testing, the parameters for some features can be driven to zero in conjugate gradient optimization of the `1-regularized objective function.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB557">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>6 experiments.
</prevsent>
<prevsent>6.1 train and test data.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in the experiments presented in this paper, we evaluate `2, `1, and `0 regularization on the task of stochastic parsing with maximum-entropy models for our experiments, we used stochastic parsing system for lfg that we trained on section 02-21of the upenn wall street journal treebank (mar cus et al , 1993) <papid> J93-2004 </papid>by discriminative estimation of conditional maximum-entropy model from partially labeled data (see riezler et al  (2002)).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>for estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see kaplan et al  (2004)).<papid> N04-1013 </papid></nextsent>
<nextsent>for the setup of discriminative estimation from partially labeled data, we found that restriction of the training data to sentences with relatively low ambiguity rate was possible at no loss inaccuracy compared to training from all sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB558">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>6 experiments.
</prevsent>
<prevsent>6.1 train and test data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
in the experiments presented in this paper, we evaluate `2, `1, and `0 regularization on the task of stochastic parsing with maximum-entropy models for our experiments, we used stochastic parsing system for lfg that we trained on section 02-21of the upenn wall street journal treebank (mar cus et al , 1993) <papid> J93-2004 </papid>by discriminative estimation of conditional maximum-entropy model from partially labeled data (see riezler et al  (2002)).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>for estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see kaplan et al  (2004)).<papid> N04-1013 </papid></nextsent>
<nextsent>for the setup of discriminative estimation from partially labeled data, we found that restriction of the training data to sentences with relatively low ambiguity rate was possible at no loss inaccuracy compared to training from all sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB559">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>6.1 train and test data.
</prevsent>
<prevsent>in the experiments presented in this paper, we evaluate `2, `1, and `0 regularization on the task of stochastic parsing with maximum-entropy models for our experiments, we used stochastic parsing system for lfg that we trained on section 02-21of the upenn wall street journal treebank (mar cus et al , 1993) <papid> J93-2004 </papid>by discriminative estimation of conditional maximum-entropy model from partially labeled data (see riezler et al  (2002)).<papid> P02-1035 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
for estimation and best-parse searching, efficient dynamic programming techniques over features forests are employed (see kaplan et al  (2004)).<papid> N04-1013 </papid></citsent>
<aftsection>
<nextsent>for the setup of discriminative estimation from partially labeled data, we found that restriction of the training data to sentences with relatively low ambiguity rate was possible at no loss inaccuracy compared to training from all sentences.
</nextsent>
<nextsent>furthermore, data were restricted to sentences of which discriminative learner can possibly take advantage, i.e. sentences where the set of parses assigned to the labeled string is proper subset of the parses assigned to the unlabeled string.
</nextsent>
<nextsent>together with restriction to examples that could be parsed by the full grammar anddid not have to use backoff mechanism of fragment parses, this resulted in training set of 10,000 examples with at most 100 parses.
</nextsent>
<nextsent>evaluation was done on the parc 700 dependency bank3, which is an lfg annotation of 700 examples randomly extracted from section 23 of the upenn wsj tree bank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB560">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the reason why the matrix of non-zeroes is less sparse in our case is that most of our feature templates are instantiated to linguistically motivated cases, and only few feature templates encode all possible conjunctions of simple feature tests.
</prevsent>
<prevsent>redundant features are introduced mostly by the latter templates, whereas the former features are generalizations over possible combinations of grammar constants.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
we conjecture that feature sets like this are typical for natural language applications.efficient feature detection is achieved by combination of hashing and dynamic programming on the packed representation of c- and f-structures(maxwell and kaplan, 1993).<papid> J93-4001 </papid></citsent>
<aftsection>
<nextsent>features can be described as local and non-local, depending on the sizeof the graph that has to be traversed in their computation.
</nextsent>
<nextsent>for each local template one of the parameters is selected as key for hashing.
</nextsent>
<nextsent>non-local features are treated as two (or more) local sub-features.
</nextsent>
<nextsent>packed structures are traversed depth-first, visiting each node only once.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB564">
<title id=" W04-3223.xml">incremental feature selection and l1 regularization for relaxed maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea of adding n-best features in each selection step also has been investigated earlier in the likelihood-based framework (see for example mccallum (2003)).
</prevsent>
<prevsent>how ever, the possible improvements in computational complexity and generalization performance due ton-best selection were not addressed explicitly.
</prevsent>
</prevsection>
<citsent citstr=" W03-1020 ">
further improvements of efficiency of grafting are possible by applying zhou et al (2003) <papid> W03-1020 </papid>technique of restricting feature selection in each step to the top ranked features from previous stages.in sum, we presented an application of `1 regularization to likelihood maximization for log-linear models that has simple interpretation as bounded constraint relaxation in terms of maximum entropy estimation.</citsent>
<aftsection>
<nextsent>the presented n-best grafting method does not require specialized algorithms or simplifications of the prior, but allows for an efficient, mathematically well-defined combination of feature selection and regularization.
</nextsent>
<nextsent>in an experimental evaluation, we showed n-best grafting to outperform `0,1-best `1, `2 regularization and standard incremental feature selection in terms of computational efficiency and generalization performance.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB565">
<title id=" W04-3247.xml">lexpagerank prestige in multi document text summarization </title>
<section> sentence centrality and centroid-based.  </section>
<citcontext>
<prevsection>
<prevsent>a common way of assessing word centrality is to lookat the centroid.
</prevsent>
<prevsent>the centro id of cluster is pseudo document which consists of words that have fre quency*idf scores above predefined threshold.
</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
in centroid-based summarization (radev et al, 2000),<papid> W00-0403 </papid>the sentences that contain more words from the centro id of the cluster are considered as central.</citsent>
<aftsection>
<nextsent>formally, the centro id score of sentence is the co sine of the angle between the centro id vector of the whole cluster and the individual centro id of the sentence.
</nextsent>
<nextsent>this is measure of how close the sentence isto the centro id of the cluster.
</nextsent>
<nextsent>centroid-based summarization has given promising results in the past (radev et al, 2001).
</nextsent>
<nextsent>in this section, we propose new method to measure sentence centrality based on prestige in social networks, which has also inspired many ideas in the computer networks and information retrieval.a cluster of documents can be viewed as network of sentences that are related to each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB566">
<title id=" W04-3247.xml">lexpagerank prestige in multi document text summarization </title>
<section> experiments on duc 2004 data.  </section>
<citcontext>
<prevsection>
<prevsent>rouge is recall based metric for fixed-length summaries which is based on n-gram co-occurence.
</prevsent>
<prevsent>it reports separate scores for 1, 2, 3, and 4-gram, and also for longest common sub sequence co-occurences.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
among these different scores, unigram-based rouge score (rouge-1) has been shown to agree with human 1http://www.isi.edu/cyl/rouge judgements most (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>we show three of the rouge metrics in our experiment results: rouge-1 (unigram-based), rouge-2 (bigram-based), and rouge-w (based on longest common sub sequence weighted by the length).
</nextsent>
<nextsent>there are 8 different human judges for duc 2004 task 2, and 4 for duc 2004 task 4.
</nextsent>
<nextsent>however, subset of exactly 4 different human judges produced model summaries for any given cluster.
</nextsent>
<nextsent>rouge requires limit on the length of the summaries to be able to make fair evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB567">
<title id=" W04-3247.xml">lexpagerank prestige in multi document text summarization </title>
<section> experiments on duc 2004 data.  </section>
<citcontext>
<prevsection>
<prevsent>length is not real feature score, but cutoff value that ignores the sentences shorter than the given threshold.
</prevsent>
<prevsent>several re rankers are implemented in mead.
</prevsent>
</prevsection>
<citsent citstr=" W00-1009 ">
we observed the best results with maximal marginal relevance (mmr) (carbonell and goldstein, 1998) reranker and the default reranker of the system based on cross-sentence informational subsumption (csis) (radev, 2000).<papid> W00-1009 </papid></citsent>
<aftsection>
<nextsent>all of our experiments shown in section 4.3 use csis reranker.a mead policy is combination of three com ponents: (a) the command lines for all features, (b) 2http://www.summarization.com feature lexpagerank lexpagerank.pl 0.2 centro id 1 position 1 length cutoff 9 lexpagerank 1 mmr-reranker-word.pl 0.5 mead-cosine enidf figure 4: sample mead policy.
</nextsent>
<nextsent>the formula for converting the feature vector to scalar, and (c) the command line for the reranker.
</nextsent>
<nextsent>a sample policy might be the one shown in figure 4.this example indicates the three default mead features (centroid, position, lengthcutoff), and our new lexpagerank feature used in our experiments.our lexpagerank implementation requires the co sine similarity threshold,  in the example, as an argument.
</nextsent>
<nextsent>each number next to feature name shows the relative weight of that feature (except for length cutoff where the number 9 indicates the threshold for selecting sentence based on the number of the words in the sentence).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB568">
<title id=" W04-2706.xml">deep syntactic annotation tectogrammatical representation and beyond </title>
<section> the extensions.  </section>
<citcontext>
<prevsection>
<prevsent>syntax.the above-mentioned development of formal frameworks toward an inclusion of valency in some way or an other has found its reflection in the annotation scenarios that aimed at going beyond the shallow structure of sentences.
</prevsent>
<prevsent>an important support for annotation conceived in this way can be found in schemes that are based on an investigation of the subcategorization of lexical units that function as heads of complex structures, see.
</prevsent>
</prevsection>
<citsent citstr=" H01-1010 ">
fillmoresframenet, the propbank as further stage of the development of the penn treebank (palmer et al, 2001) <papid> H01-1010 </papid>and levins verb classes (levin, 1993) on which the lcs database (dorr, 2001) is based.</citsent>
<aftsection>
<nextsent>there are other systems working with some kind of deep syntactic?
</nextsent>
<nextsent>annotation, e.g. the broadly conceived italian project carried out in pisa (n. calzolari, a. zampolli) or the taiwanese project marvs; another related framework is presented by the german project negra, basically surface oriented, with which the newly produced sub corpus tiger contains more information on lexical semantics.
</nextsent>
<nextsent>most work that has already been carried out concerns subcategorization frames (valency) of verbs but this restriction is not nec essary: not only verbs but also nouns or adjectives and adverbs may have their frames?
</nextsent>
<nextsent>or grids?.one of the first complex projects aimed at deep (underlying) syntactic annotation of large corpus is the already mentioned prague dependency treebank (hajic?, 1998); it is designed as complex annotation of czech texts (taken from the czech national corpus); the under lying syntactic dependency relations (called functors) are captured in the tectogrammatical tree structures (tgts); see (hajicova?, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB569">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is mary that john looks at b. * it is not sarah, john looks at mary.
</prevsent>
<prevsent>it is not sarah, it is mary that john looks atmore generally, the anaphoric potential (that is, the discourse status of the entities being talked about) of the preceding discourse, its structure, the presence of an embedding verb or of given subordinating or coordinating conjunction are all factors which may restrict the use of paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" C92-2092 ">
to preserve completeness, it is therefore important that generator be able to produce paraphrases in systematic fashion.on the other hand, it is also well known that surface realisation (the task of producing the set of sentences associated by grammar with given semantic representation) is np complete [brew, 1992].<papid> C92-2092 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present tag based surface realiserwhich supports both the generation and the selection of grammatical paraphrases (section 2 and 3).
</nextsent>
<nextsent>to deal with the resulting combinatorics, we introduce number of new optimisations (section 4).
</nextsent>
<nextsent>we then show how one of these optimisations can be used to support the selection of contextually appropriate paraphrases (section 5).
</nextsent>
<nextsent>finally, we relate our approach to similar proposals and show that it compares favourably in terms of efficiency (section 6 and 7).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB572">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> the grammar.  </section>
<citcontext>
<prevsection>
<prevsent>the adjunction at some node with top features tx and bottom features bx , of an auxiliary tree with root top features and foot bottom features entails the unification of tx with and of bx with . ? the substitution at some node with top features tx of tree with root top features entails the unification of tx with t. ? at the end of derivation, the top and bottom features of all nodes in the derived tree are unified.
</prevsent>
<prevsent>1for more details on ftag see [vijay-shanker and joshi, 1988].
</prevsent>
</prevsection>
<citsent citstr=" E03-1030 ">
2leaf nodes where substitution can take place are graphically distinguished by down arrow.in the ftag used by the surface realisation algorithm, linguistic expressions are associated with semantic representations as advocated in [gardent and kallmeyer, 2003].<papid> E03-1030 </papid></citsent>
<aftsection>
<nextsent>these mantic representations used are flat semantic representation sin the sense of [copestake et al , 2001] <papid> P01-1019 </papid>and the semantic parameters (that is, the semantic indices representing the missing arguments of the semantic functors) are represented by unification variables.</nextsent>
<nextsent>further, each elementary tree is associated with semantic representation of the type just described and the appropriate nodes of the elementary trees are decorated with semantic indices or parameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB573">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> the grammar.  </section>
<citcontext>
<prevsection>
<prevsent>1for more details on ftag see [vijay-shanker and joshi, 1988].
</prevsent>
<prevsent>2leaf nodes where substitution can take place are graphically distinguished by down arrow.in the ftag used by the surface realisation algorithm, linguistic expressions are associated with semantic representations as advocated in [gardent and kallmeyer, 2003].<papid> E03-1030 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
these mantic representations used are flat semantic representation sin the sense of [copestake et al , 2001] <papid> P01-1019 </papid>and the semantic parameters (that is, the semantic indices representing the missing arguments of the semantic functors) are represented by unification variables.</citsent>
<aftsection>
<nextsent>further, each elementary tree is associated with semantic representation of the type just described and the appropriate nodes of the elementary trees are decorated with semantic indices or parameters.
</nextsent>
<nextsent>more precisely, the substitution nodes of the tree associated with semantic functor will be associated with semantic parameters whilst root nodes and certain adjunction nodes will be labelled with semantic indices.
</nextsent>
<nextsent>as trees are combined, semantic parameters and semantic indices are unified by the ftag unification mechanism thus specifying which semantic index provides the value for which semantic parameter.
</nextsent>
<nextsent>generally, the idea is that the association between tree nodes and unification variables encodes the syntax/seman tics interface: it specifies which node in the tree provides the value for which semantic parameter in the semantic representation of semantic functor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB574">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> the basic algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>as result, it captures most grammatical paraphrases that is, paraphrases due to diverging argument realisations or to different meaning preserving alternation (e.g., active/passive or clefted/non clefted sentence).
</prevsent>
<prevsent>the basic surface realisation algorithm used is summarised in figure 1 (appendix).
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
it is bottom up, tabular algorithm [kay, 1996] <papid> P96-1027 </papid>optimised for tags.</citsent>
<aftsection>
<nextsent>its workings can be illustrated by the following example.
</nextsent>
<nextsent>suppose that the input semantics is the following : {camp(s,j),john(j),in(s,l),paris(l)}then the algorithm proceeds as follows.
</nextsent>
<nextsent>in first step (lexical selection), the elementary trees whose semantics sub sumes3 part of the input semantics are retrieved and added to the agenda.
</nextsent>
<nextsent>in our simple example, the selected trees are the trees for jean, campe, dans and paris.the second step (the substitution phase) consists in systematically exploring the possibility of combining two treesby substitution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB581">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> optimisations.  </section>
<citcontext>
<prevsection>
<prevsent>in the above example for instance, (3c) will be computed but neither (3a) nor (3b).
</prevsent>
<prevsent>4.2 avoiding spurious derivations.
</prevsent>
</prevsection>
<citsent citstr=" P91-1011 ">
categorical grammars often allow so called spurious derivations in that one and the same syntactic structure can be derived in several different ways [hepple, 1991].<papid> P91-1011 </papid></citsent>
<aftsection>
<nextsent>tags also induce spurious derivations due to the fact that substitutions and adjunct ions on different nodes of the same tree can be carried out in different relative orders all of which result in one and the same structure.
</nextsent>
<nextsent>thus for instance, given the trees np(marie), np(jean), s(np?, v(aime), np?)
</nextsent>
<nextsent>and the semantic aime(j,m),jean(j), marie(m), two derivations are possibles, one where np(jean) is first substituted in s(np?, v(aime), np?)
</nextsent>
<nextsent>before the tree for np(marie) is ; and the other where np(marie) is first substituted before np(jean) is added.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB582">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> paraphrase selection.  </section>
<citcontext>
<prevsection>
<prevsent>intuitively, selection constraint supports the selection, forgiven semantic index, of the variant(s) obeying the syntactico-semantic constraint set by the selection constraint for that index.
</prevsent>
<prevsent>formally, these constraints are imposed during the polarity filtering phase as follows.
</prevsent>
</prevsection>
<citsent citstr=" C00-1065 ">
the syntactic properties supported by the selection constraints are automatically associated during grammar compilation to the elementary trees of the grammar by means of so-called hyper tags [kinyon, 2000].<papid> C00-1065 </papid></citsent>
<aftsection>
<nextsent>this is made possible by the fact that the tag used is derived from meta grammar [crabbe?
</nextsent>
<nextsent>and duchier, 2004] that is, from highly factor ised way of representing the linguistic concepts encoded in the tag trees.
</nextsent>
<nextsent>roughly, the meta grammar formalism is used (i) to define abstractions over these concept sand (ii) to combine these abstractions so as to produce the elementary trees of tag.
</nextsent>
<nextsent>during the meta grammar compilation process, so-called hyper tag is built for each tree which records the abstractions used to produce that tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB583">
<title id=" W05-1605.xml">generating and selecting grammatical paraphrases </title>
<section> implementation and experimentation.  </section>
<citcontext>
<prevsection>
<prevsent>in what follows, we discuss the effect of polarity filtering and of paraphrase selection in that system.
</prevsent>
<prevsent>6.1 the effect of polarity filtering.
</prevsent>
</prevsection>
<citsent citstr=" P02-1003 ">
to get an estimate of how our realiser compares with existing published results, we revisited the test cases discussed in [carroll et al , 1999] and [koller and striegnitz, 2002] <papid> P02-1003 </papid>by producing similar sentences in french namely (7a) and (7b).(7) a. le directeur de ce bureau auditionne un nouveau consultant dallemagne (the manager in that office interviews new consultant from germany)b. le directeur organise un nouveau seminaire dequipe hebdomadaire special (the manager organises an unusual additional weekly departmental conference).</citsent>
<aftsection>
<nextsent>the grammar used contains 2063 trees.
</nextsent>
<nextsent>in this grammar, the verb organiser is associated with 107 trees and adjectives with 8 trees.
</nextsent>
<nextsent>for the purpose of efficiency testing, we furthermore treated the pp dequipe as an adjective.
</nextsent>
<nextsent>as result,there are 107 ? 8 (856) combinations of lexical items covering the input semantics for example (7a) while for example (7b), this number is 107?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB589">
<title id=" W05-0310.xml">semantically rich human aided machine annotation </title>
<section> the lay of the land in annotation.  </section>
<citcontext>
<prevsection>
<prevsent>numerous projects have striven to achieve text annotation via simpler task, like translation, sometimes assuming that one language has already been tagged (e.g., pianta and bentivogli 2003, and references therein).
</prevsent>
<prevsent>but results of such efforts are either of low quality, light semantic depth, or remain to be reported.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
of significant interest is the porting of annotations across languages: for example, yarowsky et al 2001 <papid> H01-1035 </papid>present method for automatic tagging of english and the projection of the tags to other languages; however, these tags do not include semantics.</citsent>
<aftsection>
<nextsent>post-editing of automatic annotation has been pursued in various projects (e.g., brants 2000, and marcus et al 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>the latter group did an experiment early on in which they found that manual tagging took about twice as long as correcting [automated tagging], with about twice the inter annotator disagreement rate and an error rate that was about 50% higher?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB590">
<title id=" W05-0310.xml">semantically rich human aided machine annotation </title>
<section> the lay of the land in annotation.  </section>
<citcontext>
<prevsection>
<prevsent>but results of such efforts are either of low quality, light semantic depth, or remain to be reported.
</prevsent>
<prevsent>of significant interest is the porting of annotations across languages: for example, yarowsky et al 2001 <papid> H01-1035 </papid>present method for automatic tagging of english and the projection of the tags to other languages; however, these tags do not include semantics.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
post-editing of automatic annotation has been pursued in various projects (e.g., brants 2000, and marcus et al 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the latter group did an experiment early on in which they found that manual tagging took about twice as long as correcting [automated tagging], with about twice the inter annotator disagreement rate and an error rate that was about 50% higher?
</nextsent>
<nextsent>(marcus et al 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>this conclusion supports the pursuit of automated tagging methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB596">
<title id=" W05-0310.xml">semantically rich human aided machine annotation </title>
<section> the lay of the land in annotation.  </section>
<citcontext>
<prevsection>
<prevsent>we, by contrast, use professionals to check and correct tmrs and thus reduce to practically zero the training time, the need for multiple annotators (pro vided the size of typical annotation task is commensurate with those in current projects), and costly correction of errors.
</prevsent>
<prevsent>among past projects that have addressed semantic annotation are the following: 1.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
gildea and jurafsky (2002) <papid> J02-3001 </papid>created stochastic system that labels case roles of predicates with either abstract (e.g., agent, theme) or domain specific (e.g., message, topic) roles.</citsent>
<aftsection>
<nextsent>the system 69 trained on 50,000 words of hand-annotated text (produced by the framenet project).
</nextsent>
<nextsent>when tasked to segment constituents and identify their semantic roles (with fillers being undisambiguated textual strings) the system scored in the 60s in precision and recall.
</nextsent>
<nextsent>limitations of the system include its reliance on hand-annotated data, and its reliance on prior knowledge of the predicate frame type (i.e., it lacks the capacity to disambiguate productively).
</nextsent>
<nextsent>semantics in this project is limited to case-roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB597">
<title id=" W05-0310.xml">semantically rich human aided machine annotation </title>
<section> porting to other languages.  </section>
<citcontext>
<prevsection>
<prevsent>we do not intend to trivialize the fact that creating new lexicon is lot of work.
</prevsent>
<prevsent>it is, however, compelling to consider that new lexicon of the same quality of our on tosem english one could be created with little more work than would be required to build typical translation dictionary.
</prevsent>
</prevsection>
<citsent citstr=" W04-0904 ">
in fact, we recently carried out an experiment on porting the english lexicon to polish and found that a) much of it could be done semi-automatically and b) the manual work for second language is considerably less than for the first language (for further discussion, see mcshane et al 2004).<papid> W04-0904 </papid></citsent>
<aftsection>
<nextsent>to sum up, the ontosem ontology and the dekade environment are equally suited to any language, and the ontosem english lexicon and analyzer can be configured to new languages with much less work required than for their initial development.
</nextsent>
<nextsent>in short, semantic-rich tagging through tmr creation could be realistic option for languages other than english.
</nextsent>
<nextsent>lack of inter annotator agreement presents significant problem in annotation efforts (see, e.g., marcus et al 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>with the ontosem semi automated approach, there is far less possibility of 73interannotator disagreement since people only correct the output of the analyzer, which is responsible for consistent and correct deployment of the large and complex static resources: if the knowledge bases are held constant, the analyzer will produce the same output every time, ensuring reproducibility of the annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB601">
<title id=" W05-0310.xml">semantically rich human aided machine annotation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>speed of gold standard tmr creation must also be evaluated, as well as the number of mistakes at each stage of analysis, and the effect that the correction of output at one stage has on the next stage.
</prevsent>
<prevsent>no methods or standards for such evaluation are readily available since no work of this type has ever been carried out.
</prevsent>
</prevsection>
<citsent citstr=" W04-0905 ">
in the face of the usual pressures of time and manpower, we have made the programmatic decision not to focus on all types of evaluation but, rather, to concentrate our evaluation metrics on the correctness of the automated output of the system, the extent to which manual correction is needed, and the depth and robustness of our knowledge resources (see nirenburg et al 2004 <papid> W04-0905 </papid>for our first evaluation effort).</citsent>
<aftsection>
<nextsent>we do not deny the ultimate desirability of additional aspects of evaluation in the future.
</nextsent>
<nextsent>the main source of variation among knowledge engineers within our approach lies not in review ing/editing annotations as such, but in building the knowledge sources that give rise to them.
</nextsent>
<nextsent>to take an actual example we encountered: one member of our group described the phrase weapon of mass destruction in the lexicon as biological-weapon or chemical-weapon, while another described it as weapon with the potential to kill very large number of people/animals.
</nextsent>
<nextsent>while both of these are correct, they focus on different salient aspects of the collocation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB602">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, large effort hasbeen invested in developing automatic or semiautomatic techniques for locating and annotating patterns and implicit information from the web, task known as web mining.
</prevsent>
<prevsent>in the particular case of web content mining, the aim is automatically mining data from textual web documents thatcan be represented with machine-readable semantic formalisms such as ontologies and semantic web languages.recently, there is an increasing interest in automatically extracting structured information from large corpora and, in particular, from the web(craven et al, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W98-1106 ">
because of the characteristics of the web, it is necessary to develop efficient algorithms able to learn from unannotated data (riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999; mann and yarowsky, 2005).<papid> P05-1060 </papid></citsent>
<aftsection>
<nextsent>new types of web content such as blogs and wikis, are also this work has been sponsored by mec, project number tin-2005-06885.source of textual information that contain an underlying structure from which specialist systems can benefit.
</nextsent>
<nextsent>consequently, rote extractors (brin, 1998; agichtein and gravano, 2000; ravichandran andhovy, 2002) <papid> P02-1006 </papid>have been identified as an appropriate method to look for textual contexts that happen to convey certain relation between two concepts.in this paper, we describe new procedure fores timating the precision of the patterns learnt by arote extractor, and how it compares to previous approaches.</nextsent>
<nextsent>the solution proposed opens new possibilities for improving the precision of the generated patterns, as described below.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB604">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, large effort hasbeen invested in developing automatic or semiautomatic techniques for locating and annotating patterns and implicit information from the web, task known as web mining.
</prevsent>
<prevsent>in the particular case of web content mining, the aim is automatically mining data from textual web documents thatcan be represented with machine-readable semantic formalisms such as ontologies and semantic web languages.recently, there is an increasing interest in automatically extracting structured information from large corpora and, in particular, from the web(craven et al, 1999).
</prevsent>
</prevsection>
<citsent citstr=" P05-1060 ">
because of the characteristics of the web, it is necessary to develop efficient algorithms able to learn from unannotated data (riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999; mann and yarowsky, 2005).<papid> P05-1060 </papid></citsent>
<aftsection>
<nextsent>new types of web content such as blogs and wikis, are also this work has been sponsored by mec, project number tin-2005-06885.source of textual information that contain an underlying structure from which specialist systems can benefit.
</nextsent>
<nextsent>consequently, rote extractors (brin, 1998; agichtein and gravano, 2000; ravichandran andhovy, 2002) <papid> P02-1006 </papid>have been identified as an appropriate method to look for textual contexts that happen to convey certain relation between two concepts.in this paper, we describe new procedure fores timating the precision of the patterns learnt by arote extractor, and how it compares to previous approaches.</nextsent>
<nextsent>the solution proposed opens new possibilities for improving the precision of the generated patterns, as described below.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB605">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because of the characteristics of the web, it is necessary to develop efficient algorithms able to learn from unannotated data (riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999; mann and yarowsky, 2005).<papid> P05-1060 </papid></prevsent>
<prevsent>new types of web content such as blogs and wikis, are also this work has been sponsored by mec, project number tin-2005-06885.source of textual information that contain an underlying structure from which specialist systems can benefit.</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
consequently, rote extractors (brin, 1998; agichtein and gravano, 2000; ravichandran andhovy, 2002) <papid> P02-1006 </papid>have been identified as an appropriate method to look for textual contexts that happen to convey certain relation between two concepts.in this paper, we describe new procedure fores timating the precision of the patterns learnt by arote extractor, and how it compares to previous approaches.</citsent>
<aftsection>
<nextsent>the solution proposed opens new possibilities for improving the precision of the generated patterns, as described below.
</nextsent>
<nextsent>this paper is structured as follows: section 2 describe related work; section 3 and 4 describe the proposed procedure and its evaluation, and section 5 presents the conclusions and future work.
</nextsent>
<nextsent>extracting information using machine learning algorithms has received much attention since the nineties, mainly motivated by the message understanding conferences.
</nextsent>
<nextsent>from the mid nineties, there are systems that learn extraction patterns from partially annotated and unannotated data (huffman, 1995; riloff, 1996; riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB608">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>extracting information using machine learning algorithms has received much attention since the nineties, mainly motivated by the message understanding conferences.
</prevsent>
<prevsent>from the mid nineties, there are systems that learn extraction patterns from partially annotated and unannotated data (huffman, 1995; riloff, 1996; riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999).</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
generalising textual patterns (both manually and automatically) for the identification of relations has been proposed since the early nineties(hearst, 1992), <papid> C92-2082 </papid>and it has been applied to extending ontologies with hyperonymy and holonymy relations (morin and jacquemin, 1999; kietz et al,2000; cimiano et al, 2004; berland and charniak, 1999).<papid> P99-1008 </papid></citsent>
<aftsection>
<nextsent>finkelstein-landau and morin (1999) <papid> P99-1050 </papid>learn patterns for company merging relations with exceedingly good accuracies.</nextsent>
<nextsent>recently, kernel 49methods are also becoming widely used for relation extraction (bunescu and mooney, 2005; <papid> H05-1091 </papid>zhao and grishman, 2005).<papid> P05-1052 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB609">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>extracting information using machine learning algorithms has received much attention since the nineties, mainly motivated by the message understanding conferences.
</prevsent>
<prevsent>from the mid nineties, there are systems that learn extraction patterns from partially annotated and unannotated data (huffman, 1995; riloff, 1996; riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999).</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
generalising textual patterns (both manually and automatically) for the identification of relations has been proposed since the early nineties(hearst, 1992), <papid> C92-2082 </papid>and it has been applied to extending ontologies with hyperonymy and holonymy relations (morin and jacquemin, 1999; kietz et al,2000; cimiano et al, 2004; berland and charniak, 1999).<papid> P99-1008 </papid></citsent>
<aftsection>
<nextsent>finkelstein-landau and morin (1999) <papid> P99-1050 </papid>learn patterns for company merging relations with exceedingly good accuracies.</nextsent>
<nextsent>recently, kernel 49methods are also becoming widely used for relation extraction (bunescu and mooney, 2005; <papid> H05-1091 </papid>zhao and grishman, 2005).<papid> P05-1052 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB610">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>from the mid nineties, there are systems that learn extraction patterns from partially annotated and unannotated data (huffman, 1995; riloff, 1996; riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>soderland, 1999).</prevsent>
<prevsent>generalising textual patterns (both manually and automatically) for the identification of relations has been proposed since the early nineties(hearst, 1992), <papid> C92-2082 </papid>and it has been applied to extending ontologies with hyperonymy and holonymy relations (morin and jacquemin, 1999; kietz et al,2000; cimiano et al, 2004; berland and charniak, 1999).<papid> P99-1008 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1050 ">
finkelstein-landau and morin (1999) <papid> P99-1050 </papid>learn patterns for company merging relations with exceedingly good accuracies.</citsent>
<aftsection>
<nextsent>recently, kernel 49methods are also becoming widely used for relation extraction (bunescu and mooney, 2005; <papid> H05-1091 </papid>zhao and grishman, 2005).<papid> P05-1052 </papid></nextsent>
<nextsent>concerning rote extractors from the web, they have the advantage that the training corpora can be collected easily and automatically, so they are useful in discovering many different relations from text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB611">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>generalising textual patterns (both manually and automatically) for the identification of relations has been proposed since the early nineties(hearst, 1992), <papid> C92-2082 </papid>and it has been applied to extending ontologies with hyperonymy and holonymy relations (morin and jacquemin, 1999; kietz et al,2000; cimiano et al, 2004; berland and charniak, 1999).<papid> P99-1008 </papid></prevsent>
<prevsent>finkelstein-landau and morin (1999) <papid> P99-1050 </papid>learn patterns for company merging relations with exceedingly good accuracies.</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
recently, kernel 49methods are also becoming widely used for relation extraction (bunescu and mooney, 2005; <papid> H05-1091 </papid>zhao and grishman, 2005).<papid> P05-1052 </papid></citsent>
<aftsection>
<nextsent>concerning rote extractors from the web, they have the advantage that the training corpora can be collected easily and automatically, so they are useful in discovering many different relations from text.
</nextsent>
<nextsent>several similar approaches have been proposed (brin, 1998; agichtein and gravano,2000; ravichandran and hovy, 2002), <papid> P02-1006 </papid>with various applications: question-answering (ravichan dran and hovy, 2002), <papid> P02-1006 </papid>multi-document named entity coreference (mann and yarowsky, 2003), <papid> W03-0405 </papid>and generating biographical information (mannand yarowsky, 2005).<papid> P05-1060 </papid></nextsent>
<nextsent>szpektor et al (2004) <papid> W04-3206 </papid>applies similar, with no seed lists, to extract automatically entailment relationships between verbs, and etzioni et al (2005) report very good results extracting named entities and relationships from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB612">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>generalising textual patterns (both manually and automatically) for the identification of relations has been proposed since the early nineties(hearst, 1992), <papid> C92-2082 </papid>and it has been applied to extending ontologies with hyperonymy and holonymy relations (morin and jacquemin, 1999; kietz et al,2000; cimiano et al, 2004; berland and charniak, 1999).<papid> P99-1008 </papid></prevsent>
<prevsent>finkelstein-landau and morin (1999) <papid> P99-1050 </papid>learn patterns for company merging relations with exceedingly good accuracies.</prevsent>
</prevsection>
<citsent citstr=" P05-1052 ">
recently, kernel 49methods are also becoming widely used for relation extraction (bunescu and mooney, 2005; <papid> H05-1091 </papid>zhao and grishman, 2005).<papid> P05-1052 </papid></citsent>
<aftsection>
<nextsent>concerning rote extractors from the web, they have the advantage that the training corpora can be collected easily and automatically, so they are useful in discovering many different relations from text.
</nextsent>
<nextsent>several similar approaches have been proposed (brin, 1998; agichtein and gravano,2000; ravichandran and hovy, 2002), <papid> P02-1006 </papid>with various applications: question-answering (ravichan dran and hovy, 2002), <papid> P02-1006 </papid>multi-document named entity coreference (mann and yarowsky, 2003), <papid> W03-0405 </papid>and generating biographical information (mannand yarowsky, 2005).<papid> P05-1060 </papid></nextsent>
<nextsent>szpektor et al (2004) <papid> W04-3206 </papid>applies similar, with no seed lists, to extract automatically entailment relationships between verbs, and etzioni et al (2005) report very good results extracting named entities and relationships from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB615">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>recently, kernel 49methods are also becoming widely used for relation extraction (bunescu and mooney, 2005; <papid> H05-1091 </papid>zhao and grishman, 2005).<papid> P05-1052 </papid></prevsent>
<prevsent>concerning rote extractors from the web, they have the advantage that the training corpora can be collected easily and automatically, so they are useful in discovering many different relations from text.</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
several similar approaches have been proposed (brin, 1998; agichtein and gravano,2000; ravichandran and hovy, 2002), <papid> P02-1006 </papid>with various applications: question-answering (ravichan dran and hovy, 2002), <papid> P02-1006 </papid>multi-document named entity coreference (mann and yarowsky, 2003), <papid> W03-0405 </papid>and generating biographical information (mannand yarowsky, 2005).<papid> P05-1060 </papid></citsent>
<aftsection>
<nextsent>szpektor et al (2004) <papid> W04-3206 </papid>applies similar, with no seed lists, to extract automatically entailment relationships between verbs, and etzioni et al (2005) report very good results extracting named entities and relationships from the web.</nextsent>
<nextsent>2.1 rote extractors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB617">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>concerning rote extractors from the web, they have the advantage that the training corpora can be collected easily and automatically, so they are useful in discovering many different relations from text.
</prevsent>
<prevsent>several similar approaches have been proposed (brin, 1998; agichtein and gravano,2000; ravichandran and hovy, 2002), <papid> P02-1006 </papid>with various applications: question-answering (ravichan dran and hovy, 2002), <papid> P02-1006 </papid>multi-document named entity coreference (mann and yarowsky, 2003), <papid> W03-0405 </papid>and generating biographical information (mannand yarowsky, 2005).<papid> P05-1060 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
szpektor et al (2004) <papid> W04-3206 </papid>applies similar, with no seed lists, to extract automatically entailment relationships between verbs, and etzioni et al (2005) report very good results extracting named entities and relationships from the web.</citsent>
<aftsection>
<nextsent>2.1 rote extractors.
</nextsent>
<nextsent>rote extractors (mann and yarowsky, 2005) <papid> P05-1060 </papid>estimate the probability of relation r(p, q) given the surrounding context a1pa2qa3.</nextsent>
<nextsent>this is calculated, with training corpus , as the number of times that two related elements r(x, y) from appear with that same contexta1xa2ya3, divided by the total number of times that appears in that context together with any other word: (r(p, q)|a1pa2qa3) = x,yr c(a1xa2ya3) x,z c(a1xa2za3) (1) is called the hook, and the target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB624">
<title id=" W06-0507.xml">towards largescale non taxonomic relation extraction estimating the precision of rote extractors </title>
<section> our proposal.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, given that many people can be born on the same year, but for every person there is just one birth year, the cardinality of the relation birth year is n:1; (d) the restrictions on the hook andthe target.
</prevsent>
<prevsent>these can be of the following three cat egories: unrestricted, if the pattern can extract any sequence of words as hook or target of the relation, entity, if the pattern can extract as hook or target only things of the same entity type as the wordsin the seed list (as annotated by the nerc mod ule), or pos, if the pattern can extract as hook or target any sequence of words whose sequence of pos labels was seen in the training corpus; and (e) sequence of queries that could be used to check, using the web, whether an extracted pair is correct or not.
</prevsent>
</prevsection>
<citsent citstr=" P06-2002 ">
we assume that the system has used the seed list to extract and generalise set of patterns for eachof the relations using training corpora (ravichan dran and hovy, 2002; <papid> P02-1006 </papid>alfonseca et al, 2006<papid> P06-2002 </papid>a).our procedure for calculating the patterns?</citsent>
<aftsection>
<nextsent>preci sions is as follows: 1.
</nextsent>
<nextsent>for every relation,.
</nextsent>
<nextsent>(a) for every hook, collect hook corpus from the web.
</nextsent>
<nextsent>51 relation name seed-list cardinality hook-type target-type web queries birth year birth-date.txt n:1 entity entity $1 was born in $2 death year death-date.txt n:1 entity entity $1 died in $2 birthplace birth-place.txt n:1 entity entity $1 was born in $2 country-capital country-capital.txt 1:1 entity entity $2 is the capital of $1 author-book author-book.txt n:n entity unrestricted $1 is the author of $2 director-film director-film.txt 1:n entity unrestricted $1 directed $2, $2 directed by $1 table 1: example rows in the input table for the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB634">
<title id=" W05-1608.xml">incremental generation of multimodal deixis referring to objects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>[lester et al, 1999] and [rickel and johnson, 1999] generate pointing gestures expressed by an agent which moves to the referent, and therefore, achieve unambiguous pointing.
</prevsent>
<prevsent>only [krahmer and vander sluis, 2003] integrate pointing and definite descriptions in more natural way and account for vague pointing.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
they distinguish three types ofpreciseness, i.e. precise, imprecise, or very imprecise pointing, and integrate pointing into the graph-based algorithm proposed by [krahmer et al, 2003].<papid> J03-1003 </papid></citsent>
<aftsection>
<nextsent>examining the generation of referring expressions realised as definite descriptions one has to mention, first of all, that the problem of selecting the minimal set (in the sense of gricesquantity maxim) of object properties needed for an unambiguous description of the referent has exponential computational complexity [reiter, 1990].<papid> P90-1013 </papid></nextsent>
<nextsent>each combination of properties has to be tested whether it is true only for the referent, and the shortest one of these combinations has to be chosen.especially for real-time applications in domains with high object density and objects with high number of properties this computation is intractable with brute-force methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB635">
<title id=" W05-1608.xml">incremental generation of multimodal deixis referring to objects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>only [krahmer and vander sluis, 2003] integrate pointing and definite descriptions in more natural way and account for vague pointing.
</prevsent>
<prevsent>they distinguish three types ofpreciseness, i.e. precise, imprecise, or very imprecise pointing, and integrate pointing into the graph-based algorithm proposed by [krahmer et al, 2003].<papid> J03-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" P90-1013 ">
examining the generation of referring expressions realised as definite descriptions one has to mention, first of all, that the problem of selecting the minimal set (in the sense of gricesquantity maxim) of object properties needed for an unambiguous description of the referent has exponential computational complexity [reiter, 1990].<papid> P90-1013 </papid></citsent>
<aftsection>
<nextsent>each combination of properties has to be tested whether it is true only for the referent, and the shortest one of these combinations has to be chosen.especially for real-time applications in domains with high object density and objects with high number of properties this computation is intractable with brute-force methods.
</nextsent>
<nextsent>several approaches have been proposed to deal with this problem, namely [dale, 1992; krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 1997;<papid> P97-1027 </papid>gardent, 2002].<papid> P02-1013 </papid></nextsent>
<nextsent>[dale and reiter, 1995] proposed an incremental algorithm which violates the quantity maxim in the strict sense, but achieves linear compute time and fits well with empirical findings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB637">
<title id=" W05-1608.xml">incremental generation of multimodal deixis referring to objects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>examining the generation of referring expressions realised as definite descriptions one has to mention, first of all, that the problem of selecting the minimal set (in the sense of gricesquantity maxim) of object properties needed for an unambiguous description of the referent has exponential computational complexity [reiter, 1990].<papid> P90-1013 </papid></prevsent>
<prevsent>each combination of properties has to be tested whether it is true only for the referent, and the shortest one of these combinations has to be chosen.especially for real-time applications in domains with high object density and objects with high number of properties this computation is intractable with brute-force methods.</prevsent>
</prevsection>
<citsent citstr=" P97-1027 ">
several approaches have been proposed to deal with this problem, namely [dale, 1992; krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 1997;<papid> P97-1027 </papid>gardent, 2002].<papid> P02-1013 </papid></citsent>
<aftsection>
<nextsent>[dale and reiter, 1995] proposed an incremental algorithm which violates the quantity maxim in the strict sense, but achieves linear compute time and fits well with empirical findings.
</nextsent>
<nextsent>3.1 the incremental algorithm by dale and reiter.
</nextsent>
<nextsent>to achieve linear compute time, [dale and reiter, 1995] propose fixed sequence of property evaluation and avoid backtracking.
</nextsent>
<nextsent>this approach leads to over-specification, but they can show that the generation results fit well with empirical findings if the sequence of properties is chosen accurately w.r.t. the specific domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB638">
<title id=" W05-1608.xml">incremental generation of multimodal deixis referring to objects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>examining the generation of referring expressions realised as definite descriptions one has to mention, first of all, that the problem of selecting the minimal set (in the sense of gricesquantity maxim) of object properties needed for an unambiguous description of the referent has exponential computational complexity [reiter, 1990].<papid> P90-1013 </papid></prevsent>
<prevsent>each combination of properties has to be tested whether it is true only for the referent, and the shortest one of these combinations has to be chosen.especially for real-time applications in domains with high object density and objects with high number of properties this computation is intractable with brute-force methods.</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
several approaches have been proposed to deal with this problem, namely [dale, 1992; krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 1997;<papid> P97-1027 </papid>gardent, 2002].<papid> P02-1013 </papid></citsent>
<aftsection>
<nextsent>[dale and reiter, 1995] proposed an incremental algorithm which violates the quantity maxim in the strict sense, but achieves linear compute time and fits well with empirical findings.
</nextsent>
<nextsent>3.1 the incremental algorithm by dale and reiter.
</nextsent>
<nextsent>to achieve linear compute time, [dale and reiter, 1995] propose fixed sequence of property evaluation and avoid backtracking.
</nextsent>
<nextsent>this approach leads to over-specification, but they can show that the generation results fit well with empirical findings if the sequence of properties is chosen accurately w.r.t. the specific domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB639">
<title id=" W05-0623.xml">a joint model for semantic role labeling </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we present semantic role labeling system submitted to the closed track of theconll-2005 shared task.
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
the system, introduced in (toutanova et al, 2005), <papid> P05-1073 </papid>implements joint model that captures dependencies among arguments of predicate using log-linear models in discriminative re-ranking framework.</citsent>
<aftsection>
<nextsent>we also describe experiments aimed at increasing the robustness of the system in the presence of syntactic parse errors.
</nextsent>
<nextsent>our final system achieves f1-measures of 76.68 and 78.45 on the development and the wsj portion of the test set, respectively.
</nextsent>
<nextsent>it is evident that there are strong statistical pattern sin the syntactic realization and ordering of the arguments of verbs; for instance, if an active predicate has an a0 argument it is very likely to come before an a1 argument.
</nextsent>
<nextsent>our model aims to capture such dependencies among the labels of nodes in syntactic parse tree.however, building such model is computationally expensive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB640">
<title id=" W05-0623.xml">a joint model for semantic role labeling </title>
<section> local models.  </section>
<citcontext>
<prevsection>
<prevsent>the identification model classifies each phrase as either an argument or non argument and our classification model labels each potential argument with specific argument label.
</prevsent>
<prevsent>the two models use the same features.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
previous research (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>carreras and ma`rquez, 2004)has identified many useful features for local identification and classification.</citsent>
<aftsection>
<nextsent>below we list the features and hand-picked conjunctions of features used in our local models.
</nextsent>
<nextsent>the ones denoted with asterisks(*) were not present in (toutanova et al, 2005).<papid> P05-1073 </papid></nextsent>
<nextsent>although most of these features have been described in previous work, some features, described in the next section, are ? to our knowledge ? novel.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB641">
<title id=" W05-0623.xml">a joint model for semantic role labeling </title>
<section> local models.  </section>
<citcontext>
<prevsection>
<prevsent>the identification model classifies each phrase as either an argument or non argument and our classification model labels each potential argument with specific argument label.
</prevsent>
<prevsent>the two models use the same features.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
previous research (gildea and jurafsky, 2002; <papid> J02-3001 </papid>pradhan et al, 2004; <papid> N04-1030 </papid>carreras and ma`rquez, 2004)has identified many useful features for local identification and classification.</citsent>
<aftsection>
<nextsent>below we list the features and hand-picked conjunctions of features used in our local models.
</nextsent>
<nextsent>the ones denoted with asterisks(*) were not present in (toutanova et al, 2005).<papid> P05-1073 </papid></nextsent>
<nextsent>although most of these features have been described in previous work, some features, described in the next section, are ? to our knowledge ? novel.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB654">
<title id=" W05-0623.xml">a joint model for semantic role labeling </title>
<section> increasing robustness to parser errors.  </section>
<citcontext>
<prevsection>
<prevsent>it is apparent that role labeling is very sensitive to the correctness of the given parse tree.
</prevsent>
<prevsent>if an argument does not correspond to constituent in parse tree, our model will not be able to consider the correct phrase.one way to address this problem is to utilize alternative parses.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
recent releases of the charniak parser (charniak, 2000) <papid> A00-2018 </papid>have included an option to provide the top parses of given sentence according to the probability model of the parser.</citsent>
<aftsection>
<nextsent>we use these alternative parses as follow: suppose t1, . . .
</nextsent>
<nextsent>, tk are trees for sentence with given probabilities (ti|s) by the parser.
</nextsent>
<nextsent>then for fixed predicate v, let li 175 precision recall f?=1 development 77.66% 75.72% 76.68 test wsj 79.54% 77.39% 78.45 test brown 70.24% 65.37% 67.71 test wsj+brown 78.34% 75.78% 77.04 test wsj precision recall f?=1 overall 79.54% 77.39% 78.45 a0 88.32% 88.30% 88.31 a1 78.61% 78.40% 78.51 a2 72.55% 68.11% 70.26 a3 73.08% 54.91% 62.71 a4 77.42% 70.59% 73.85 a5 100.00% 80.00% 88.89 am-adv 58.20% 51.19% 54.47 am-cau 63.93% 53.42% 58.21 am-dir 52.56% 48.24% 50.31 am-dis 76.56% 80.62% 78.54 am-ext 73.68% 43.75% 54.90 am-loc 61.52% 55.92% 58.59 am-mnr 58.33% 56.98% 57.65 am-mod 97.85% 99.09% 98.47 am-neg 97.41% 98.26% 97.84 am-pnc 49.50% 43.48% 46.30 am-prd 100.00% 20.00% 33.33 am-rec 0.00% 0.00% 0.00 am-tmp 74.85% 67.34% 70.90 r-a0 92.63% 89.73% 91.16 r-a1 81.53% 82.05% 81.79 r-a2 61.54% 50.00% 55.17 r-a3 0.00% 0.00% 0.00 r-a4 0.00% 0.00% 0.00 r-am-adv 0.00% 0.00% 0.00 r-am-cau 100.00% 50.00% 66.67 r-am-ext 0.00% 0.00% 0.00 r-am-loc 85.71% 57.14% 68.57 r-am-mnr 28.57% 33.33% 30.77 r-am-tmp 61.54% 76.92% 68.38 97.32% 97.32% 97.32 table 1: overall results (top) and detailed results on the wsj test (bottom) on the closed track of the conll shared task.
</nextsent>
<nextsent>denote the best joint labeling of tree ti, with score scoresrl(li|ti) according to our final joint model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB659">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>firstly, automatically identifying potential idioms and bringing them to the attention of lexicographer can be usedto improve coverage and reduce the time lexicog rapher must spend in searching for such examples.
</prevsent>
<prevsent>secondly and more ambitiously, the goal of such work is to enable computers to recognize idioms independently so that the inevitable lack of coverage in language resources does not impede their ability to respond intelligently to natural language input.in attempting first-pass at this task, the experiments described in this paper proceed as follows.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
we focus on particular class of idioms that can be extracted using lexico syntactic patterns (hearst, 1992), <papid> C92-2082 </papid>which are fixed patterns in text that suggest that the words occurring in them have some interesting relationship.</citsent>
<aftsection>
<nextsent>the patterns we focus on are occurrences of the form and/or b?, where and 48 are both nouns.
</nextsent>
<nextsent>examples include football and cricket?
</nextsent>
<nextsent>and hue and cry.?
</nextsent>
<nextsent>from this list, we extract those examples for which there is strong preference on the ordering of the participants.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB661">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the phrase france,germany, italy, and other european countries?
</prevsent>
<prevsent>suggests that france, germany and italy are part ofthe class of european countries.
</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
such hierarchical examples are quite sparse, and greater coverage was later attained by riloff and shepherd (1997)<papid> W97-0313 </papid>and roark and charniak (1998) <papid> P98-2182 </papid>in extracting relations not of hierarchy but of similarity, by finding conjunctions or co-ordinations such as cloves, cinammon, and nutmeg?</citsent>
<aftsection>
<nextsent>and cars and trucks.?
</nextsent>
<nextsent>this work was extended by caraballo (1999), <papid> P99-1016 </papid>who built classes of related words in this fashion and then reasoned that if hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class.</nextsent>
<nextsent>this technique can often mistakenly reason across an ambiguous middle-term, situation that was improved upon by cederberg and widdows (2003), <papid> W03-0415 </papid>by combiningpattern-based extraction with contextual filtering using latent semantic analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB662">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the phrase france,germany, italy, and other european countries?
</prevsent>
<prevsent>suggests that france, germany and italy are part ofthe class of european countries.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
such hierarchical examples are quite sparse, and greater coverage was later attained by riloff and shepherd (1997)<papid> W97-0313 </papid>and roark and charniak (1998) <papid> P98-2182 </papid>in extracting relations not of hierarchy but of similarity, by finding conjunctions or co-ordinations such as cloves, cinammon, and nutmeg?</citsent>
<aftsection>
<nextsent>and cars and trucks.?
</nextsent>
<nextsent>this work was extended by caraballo (1999), <papid> P99-1016 </papid>who built classes of related words in this fashion and then reasoned that if hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class.</nextsent>
<nextsent>this technique can often mistakenly reason across an ambiguous middle-term, situation that was improved upon by cederberg and widdows (2003), <papid> W03-0415 </papid>by combiningpattern-based extraction with contextual filtering using latent semantic analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB663">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>such hierarchical examples are quite sparse, and greater coverage was later attained by riloff and shepherd (1997)<papid> W97-0313 </papid>and roark and charniak (1998) <papid> P98-2182 </papid>in extracting relations not of hierarchy but of similarity, by finding conjunctions or co-ordinations such as cloves, cinammon, and nutmeg?</prevsent>
<prevsent>and cars and trucks.?</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
this work was extended by caraballo (1999), <papid> P99-1016 </papid>who built classes of related words in this fashion and then reasoned that if hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class.</citsent>
<aftsection>
<nextsent>this technique can often mistakenly reason across an ambiguous middle-term, situation that was improved upon by cederberg and widdows (2003), <papid> W03-0415 </papid>by combiningpattern-based extraction with contextual filtering using latent semantic analysis.</nextsent>
<nextsent>prior work in discovering non-compositional phrases has been carried out by lin (1999) <papid> P99-1041 </papid>and baldwin et al (2003), <papid> W03-1812 </papid>who also used lsato distinguish between compositional and non compositional verb-particle constructions and noun noun compounds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB664">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>and cars and trucks.?
</prevsent>
<prevsent>this work was extended by caraballo (1999), <papid> P99-1016 </papid>who built classes of related words in this fashion and then reasoned that if hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class.</prevsent>
</prevsection>
<citsent citstr=" W03-0415 ">
this technique can often mistakenly reason across an ambiguous middle-term, situation that was improved upon by cederberg and widdows (2003), <papid> W03-0415 </papid>by combiningpattern-based extraction with contextual filtering using latent semantic analysis.</citsent>
<aftsection>
<nextsent>prior work in discovering non-compositional phrases has been carried out by lin (1999) <papid> P99-1041 </papid>and baldwin et al (2003), <papid> W03-1812 </papid>who also used lsato distinguish between compositional and non compositional verb-particle constructions and noun noun compounds.</nextsent>
<nextsent>at the same time, work in analyzing idioms and asymmetry within linguistics has become more sophisticated, as discussed by benor and levy (2004),and many of the semantic factors underlying our results can be understood from sophisticated theoretical perspective.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB665">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>this work was extended by caraballo (1999), <papid> P99-1016 </papid>who built classes of related words in this fashion and then reasoned that if hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class.</prevsent>
<prevsent>this technique can often mistakenly reason across an ambiguous middle-term, situation that was improved upon by cederberg and widdows (2003), <papid> W03-0415 </papid>by combiningpattern-based extraction with contextual filtering using latent semantic analysis.</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
prior work in discovering non-compositional phrases has been carried out by lin (1999) <papid> P99-1041 </papid>and baldwin et al (2003), <papid> W03-1812 </papid>who also used lsato distinguish between compositional and non compositional verb-particle constructions and noun noun compounds.</citsent>
<aftsection>
<nextsent>at the same time, work in analyzing idioms and asymmetry within linguistics has become more sophisticated, as discussed by benor and levy (2004),and many of the semantic factors underlying our results can be understood from sophisticated theoretical perspective.
</nextsent>
<nextsent>other motivating and related themes of work forthis paper include collocation extraction and example based machine translation.
</nextsent>
<nextsent>in the work ofsmadja (1993) <papid> J93-1007 </papid>on extracting collocations, preference was given to constructions whose constituents appear in fixed order, similar (and more generally implemented) version of our assumption here that asymmetric constructions are more idiomatic than symmetric ones.</nextsent>
<nextsent>recent advances in example-based machine translation (ebmt) have emphasized the fact that examining patterns of language use can significantly improve idiomatic language generation (carl and way, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB666">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>this work was extended by caraballo (1999), <papid> P99-1016 </papid>who built classes of related words in this fashion and then reasoned that if hierarchical relationship could be extracted for any member of this class, it could be applied to all members of the class.</prevsent>
<prevsent>this technique can often mistakenly reason across an ambiguous middle-term, situation that was improved upon by cederberg and widdows (2003), <papid> W03-0415 </papid>by combiningpattern-based extraction with contextual filtering using latent semantic analysis.</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
prior work in discovering non-compositional phrases has been carried out by lin (1999) <papid> P99-1041 </papid>and baldwin et al (2003), <papid> W03-1812 </papid>who also used lsato distinguish between compositional and non compositional verb-particle constructions and noun noun compounds.</citsent>
<aftsection>
<nextsent>at the same time, work in analyzing idioms and asymmetry within linguistics has become more sophisticated, as discussed by benor and levy (2004),and many of the semantic factors underlying our results can be understood from sophisticated theoretical perspective.
</nextsent>
<nextsent>other motivating and related themes of work forthis paper include collocation extraction and example based machine translation.
</nextsent>
<nextsent>in the work ofsmadja (1993) <papid> J93-1007 </papid>on extracting collocations, preference was given to constructions whose constituents appear in fixed order, similar (and more generally implemented) version of our assumption here that asymmetric constructions are more idiomatic than symmetric ones.</nextsent>
<nextsent>recent advances in example-based machine translation (ebmt) have emphasized the fact that examining patterns of language use can significantly improve idiomatic language generation (carl and way, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB667">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>at the same time, work in analyzing idioms and asymmetry within linguistics has become more sophisticated, as discussed by benor and levy (2004),and many of the semantic factors underlying our results can be understood from sophisticated theoretical perspective.
</prevsent>
<prevsent>other motivating and related themes of work forthis paper include collocation extraction and example based machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
in the work ofsmadja (1993) <papid> J93-1007 </papid>on extracting collocations, preference was given to constructions whose constituents appear in fixed order, similar (and more generally implemented) version of our assumption here that asymmetric constructions are more idiomatic than symmetric ones.</citsent>
<aftsection>
<nextsent>recent advances in example-based machine translation (ebmt) have emphasized the fact that examining patterns of language use can significantly improve idiomatic language generation (carl and way, 2003).
</nextsent>
<nextsent>lexical acquisition and idiom extraction this section of the paper describes the techniques used to extract potentially idiomatic patterns from text, as deduced from previously successful experiments in lexical acquisition.
</nextsent>
<nextsent>49the main extraction technique is to use lexico syn tactic patterns of the form a, and/or c?
</nextsent>
<nextsent>to find nouns that are linked in some way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB668">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> the symmetric graph model as used for.  </section>
<citcontext>
<prevsection>
<prevsent>since the bnc is tagged for parts-of-speech, we know that the words highlighted in bold are nouns.since the phrase nutmeg, cinnamon, cloves or co riander?
</prevsent>
<prevsent>fits the pattern a, b, or d?, we create nodes for each of these nouns and create links between them all.
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
when applied to the whole of the bnc, these links can be aggregated to form graph with 99,454 nodes (nouns) and 587,475 links, as described by widdows and dorow (2002).<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>this graph was originally used for lexical acquisition, since clusters of words in the graph often map to recognized semantic classes with great accuracy (  80%, (widdows and dorow, 2002)).<papid> C02-1114 </papid></nextsent>
<nextsent>however, for the sake of smoothing over sparse data, these results made the assumption that the links between nodes were symmetric, rather than directed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB671">
<title id=" W05-1006.xml">automatic extraction of idioms using graph analysis and asymmetric lexico syntactic patterns </title>
<section> filtering using latent semantic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>some of the pairs extracted are examples of.
</prevsent>
<prevsent>general semantic patterns, others are examples of genuinely idiomatic phrases.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
even for semantically predictable phrases, the fact that the words occur in fixed patterns can be very useful for the purposes of disambiguation, as demonstrated by (yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>however, it 53would be useful to be able to tell which of the asymmetric patterns extracted by our experiments correspond to semantically regular phrases which happen to have conventional ordering preference, and which phrases correspond to genuine idioms.
</nextsent>
<nextsent>this final section demonstrates two techniques for performing this filtering task, which show promising results for improving our classification, though should not yet be considered as reliable.
</nextsent>
<nextsent>5.1 filtering using latent semantic analysis.
</nextsent>
<nextsent>latent semantic analysis or lsa (landauer and du mais, 1997) is by now tried and tested technique for determining semantic similarity between words by analyzing large corpus (widdows, 2004, ch 6).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB673">
<title id=" W05-1623.xml">reversibility and re usability of resources in nlg and natural language dialog systems </title>
<section> classification of reversibility types.  </section>
<citcontext>
<prevsection>
<prevsent>the user model, however, is not used for parsing, only for generation, hence the system is not reversible with respect to the user model.in table 1 the reversibility types of the different resources are put together.
</prevsent>
<prevsent>they form tuple (e, d, a, b, b, none) completely describing reversibility in conald.
</prevsent>
</prevsection>
<citsent citstr=" W98-1429 ">
resource type lexicon morphology grammar discourse memory domain model user model none table 1: reversibility of conald.the amalia system [gabrilovich et al, 1998] <papid> W98-1429 </papid>is typical example for prolog-based reversible nlg systems.</citsent>
<aftsection>
<nextsent>the system grammar is first inverted and then compiled into two different versions, one for parsing and one for generation.
</nextsent>
<nextsent>thus, we have type reversibility here.
</nextsent>
<nextsent>the parser parser uniform source algorithm uniform algorithm parser parser uniform source algorithm uniform algorithm generator generator generator generator parsing resource parsing resource parsing resource system resource system resource system resource generation resource generation resource generation resource system resource system resource system resource type data: static; algorithms: none type data: dynamic; algorithms: none type data: static; algorithms: dynamic type data: dynamic; algorithms: dynamic type data: static; algorithms: static type data: dynamic; algorithms: static figure 1: reversible dialog systems.
</nextsent>
<nextsent>parser parser uniform algorithm uniform source algorithm generator generator a b ba parsing resource parsing resource generation resource generation resource parsing resource generation resource legend uses resource is compiled into type data: none; algorithms: static type type resource program is compiled into program figure 2: not-so-reversible dialog systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB674">
<title id=" W05-0605.xml">word independent context pair classification model for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bottleneck is particularly serious when considering the domain dependency of word senses.
</prevsent>
<prevsent>to overcome the knowledge bottleneck, unsupervised or weakly supervised learning approaches have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
these include the bootstrapping approach (yarowsky 1995) <papid> P95-1026 </papid>and the context clustering approach (schtze 1998).</citsent>
<aftsection>
<nextsent>the above unsupervised or weakly supervised learning approaches are less subject to the knowledge bottleneck.
</nextsent>
<nextsent>for example, (yarowsky 1995) <papid> P95-1026 </papid>only requires sense number and few seeds for each sense of an ambiguous word (hereafter called keyword).</nextsent>
<nextsent>(schtze 1998) may only need minimal annotation to map the resulting context clusters onto external thesaurus for benchmarking and ap plication-related purposes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB678">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the verb relations we discover are similarity, strength, antonymy, enable ment, and temporal relations.
</prevsent>
<prevsent>identifying these relations over 29,165 verb pairs results in broad-coverage resource we call verbocean.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
our approach extends previously formulated ones that use surface patterns as indicators of semantic relations between nouns (hearst 1992; <papid> C92-2082 </papid>etzioni 2003; ravichandran and hovy 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>we extend these approaches in two ways: (i) our patterns indicate verb conjugation to increase their expressiveness and specificity and (ii) we use measure similar to mutual information to account for both the frequency of the verbs whose semantic relations are being discovered as well as for the frequency of the pattern.
</nextsent>
<nextsent>in this section, we describe application domains that can benefit from resource of verb semantics.
</nextsent>
<nextsent>we then introduce some existing resources and describe previous attempts at mining semantics from text.
</nextsent>
<nextsent>2.1 applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB679">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the verb relations we discover are similarity, strength, antonymy, enable ment, and temporal relations.
</prevsent>
<prevsent>identifying these relations over 29,165 verb pairs results in broad-coverage resource we call verbocean.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
our approach extends previously formulated ones that use surface patterns as indicators of semantic relations between nouns (hearst 1992; <papid> C92-2082 </papid>etzioni 2003; ravichandran and hovy 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>we extend these approaches in two ways: (i) our patterns indicate verb conjugation to increase their expressiveness and specificity and (ii) we use measure similar to mutual information to account for both the frequency of the verbs whose semantic relations are being discovered as well as for the frequency of the pattern.
</nextsent>
<nextsent>in this section, we describe application domains that can benefit from resource of verb semantics.
</nextsent>
<nextsent>we then introduce some existing resources and describe previous attempts at mining semantics from text.
</nextsent>
<nextsent>2.1 applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB681">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>in lexical selection of verbs in machine translation and in work on document classification, practitioners have argued for approaches that depend on wide-coverage resources indicating verb similarity and membership of verb in certain class.
</prevsent>
<prevsent>in work on translating verbs with many counterparts in the target language, palmer and wu (1995) discuss inherent limitations of approaches which do not examine verbs class membership, and put forth an approach based on verb similarity.
</prevsent>
</prevsection>
<citsent citstr=" P98-1112 ">
in document classification, klavans and kan (1998) <papid> P98-1112 </papid>demonstrate that document type is correlated with the presence of many verbs of certain evca class (levin 1993).</citsent>
<aftsection>
<nextsent>in discussing future work, klavans and kan point to extending coverage of the manually constructed evca resource as way of improving the performance of the system.
</nextsent>
<nextsent>a wide coverage repository of verb relations including verbs linked by the similarity relation will provide way to automatically extend the existing verb classes to cover more of the english lexicon.
</nextsent>
<nextsent>2.2 existing resources.
</nextsent>
<nextsent>some existing broad-coverage resources on verbs have focused on organizing verbs into classes or annotating their frames or thematic roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB682">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>evca (english verb classes and alternations) (levin 1993) organizes verbs by similarity and participation / nonparticipation in alternation patterns.
</prevsent>
<prevsent>it contains 3200 verbs classified into 191 classes.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
additional manually constructed resources include propbank (kingsbury et al 2002), framenet (baker et al 1998), <papid> P98-1013 </papid>verbnet (kipper et al 2000), and the resource on verb selectional restrictions developed by gomez (2001).<papid> N01-1012 </papid></citsent>
<aftsection>
<nextsent>our approach differs from the above in its focus.
</nextsent>
<nextsent>we relate verbs to each other rather than organize them into classes or identify their frames or thematic roles.
</nextsent>
<nextsent>wordnet does provide relations between verbs, but at coarser level.
</nextsent>
<nextsent>we provide finer-grained relations such as strength, enable ment and temporal information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB683">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>evca (english verb classes and alternations) (levin 1993) organizes verbs by similarity and participation / nonparticipation in alternation patterns.
</prevsent>
<prevsent>it contains 3200 verbs classified into 191 classes.
</prevsent>
</prevsection>
<citsent citstr=" N01-1012 ">
additional manually constructed resources include propbank (kingsbury et al 2002), framenet (baker et al 1998), <papid> P98-1013 </papid>verbnet (kipper et al 2000), and the resource on verb selectional restrictions developed by gomez (2001).<papid> N01-1012 </papid></citsent>
<aftsection>
<nextsent>our approach differs from the above in its focus.
</nextsent>
<nextsent>we relate verbs to each other rather than organize them into classes or identify their frames or thematic roles.
</nextsent>
<nextsent>wordnet does provide relations between verbs, but at coarser level.
</nextsent>
<nextsent>we provide finer-grained relations such as strength, enable ment and temporal information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB685">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>previous web mining work has rarely addressed extracting many different semantic relations from web-sized corpus.
</prevsent>
<prevsent>most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns.
</prevsent>
</prevsection>
<citsent citstr=" N04-1041 ">
hearst (1992) <papid> C92-2082 </papid>was the first followed by recent larger-scale and more fully automated efforts (pantel and ravichandran 2004; <papid> N04-1041 </papid>etzioni et al 2004; ravichandran and hovy 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>recently, moldovan et al (2004) <papid> W04-2609 </papid>present learning algorithm to detect 35 fine-grained noun phrase rela tions.</nextsent>
<nextsent>turney (2001) studied word relatedness and synonym extraction, while lin et al (2003) present an algorithm that queries the web using lexical patterns for distinguishing noun synonymy and antonymy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB688">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns.
</prevsent>
<prevsent>hearst (1992) <papid> C92-2082 </papid>was the first followed by recent larger-scale and more fully automated efforts (pantel and ravichandran 2004; <papid> N04-1041 </papid>etzioni et al 2004; ravichandran and hovy 2002).<papid> P02-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
recently, moldovan et al (2004) <papid> W04-2609 </papid>present learning algorithm to detect 35 fine-grained noun phrase rela tions.</citsent>
<aftsection>
<nextsent>turney (2001) studied word relatedness and synonym extraction, while lin et al (2003) present an algorithm that queries the web using lexical patterns for distinguishing noun synonymy and antonymy.
</nextsent>
<nextsent>our approach addresses verbs and provides for richer and finer-grained set of semantics.
</nextsent>
<nextsent>reliability of estimating bigram counts on the web via search engines has been investigated by keller and lapata (2003).<papid> J03-3005 </papid></nextsent>
<nextsent>semantic networks have also been extracted from dictionaries and other machine-readable re sources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB689">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>turney (2001) studied word relatedness and synonym extraction, while lin et al (2003) present an algorithm that queries the web using lexical patterns for distinguishing noun synonymy and antonymy.
</prevsent>
<prevsent>our approach addresses verbs and provides for richer and finer-grained set of semantics.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
reliability of estimating bigram counts on the web via search engines has been investigated by keller and lapata (2003).<papid> J03-3005 </papid></citsent>
<aftsection>
<nextsent>semantic networks have also been extracted from dictionaries and other machine-readable resources.
</nextsent>
<nextsent>mindnet (richardson et al 1998) <papid> P98-2180 </papid>extracts collection of triples of the type ducks have wings?</nextsent>
<nextsent>and duck capable-of flying?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB690">
<title id=" W04-3205.xml">verb ocean mining the web for fine grained semantic verb relations </title>
<section> relevant work.  </section>
<citcontext>
<prevsection>
<prevsent>reliability of estimating bigram counts on the web via search engines has been investigated by keller and lapata (2003).<papid> J03-3005 </papid></prevsent>
<prevsent>semantic networks have also been extracted from dictionaries and other machine-readable re sources.</prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
mindnet (richardson et al 1998) <papid> P98-2180 </papid>extracts collection of triples of the type ducks have wings?</citsent>
<aftsection>
<nextsent>and duck capable-of flying?.
</nextsent>
<nextsent>this resource, however, does not relate verbs to each other or provide verb semantics.
</nextsent>
<nextsent>in this section, we introduce and motivate the specific relations that we extract.
</nextsent>
<nextsent>whilst the natural language literature is rich in theories of semantics (barwise and perry 1985; schank and abelson 1977), large-coverage manually created semantic resources typically only organize verbs into flat or shallow hierarchy of classes (such as those described in section 2.2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB691">
<title id=" W05-0101.xml">teaching applied natural language processing triumphs and tribulations </title>
<section> choosing tools and readings.  </section>
<citcontext>
<prevsection>
<prevsent>java is attractive because many tools are written in it and the mims students were familiar with java ? they are required to use it fortwo of their required courses but still tend to struggle with it.
</prevsent>
<prevsent>i did not consider perl since python is amore principled language and is growing in acceptance and in tool availability.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
in the end decided to require the students to learn python because wanted to use nltk, the natural language toolkit (loper and bird, 2002).<papid> W02-0109 </papid></citsent>
<aftsection>
<nextsent>one goal of nltk is to remove the emphasis on programming to enable students to achieve results quickly; and this aligned with my primary goal.
</nextsent>
<nextsent>nltk seemed promising because it contained some well-written tutorials on n-grams, pos tagging and chunking, and contained text categorization modules.
</nextsent>
<nextsent>(i also wanted support for entity extraction, which nltk does not supply.)
</nextsent>
<nextsent>nltk is written in python, and so decided to try it and have the students learn new programming language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB692">
<title id=" W05-0101.xml">teaching applied natural language processing triumphs and tribulations </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>this assignment was challenging (especially because of some misleading text in the tagging tutorial, which has since been fixed) but the students learned great deal.
</prevsent>
<prevsent>as mentioned above, should have begun with preliminary assignment which got students familiar with python basics before attempting this assignment.for assignment 2, provided simple set of regular expression grammar rules for the shallow parser class, and asked the students to improve on these.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
after building the chunker, students were asked to 4choose verb and then analyze verb-argument structure (they were provided with two relevant papers (church and hanks, 1990; <papid> J90-1003 </papid>chklovski and pantel,2004)).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>as mentioned above, most of the mims students were not familiar with regular expressions, so should have done longer unit on this topic, at the expense of boring the cs students.
</nextsent>
<nextsent>the students learned great deal from working to improve the grammar rules, but the verb-argument analysis portion was not particularly successful, in part because the corpus analyzed was too small to yield many sentences forgiven verb and because we did not have code to automatically find regularities about the semantics of the arguments of the verbs.
</nextsent>
<nextsent>other causes of difficulty were the students?
</nextsent>
<nextsent>lack of linguistic background, and the fact that the chunking part took longer than expected, leaving students little time for the analysis portion of the as signment.assignments 3 and 4 are described in the following subsections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB693">
<title id=" W05-0101.xml">teaching applied natural language processing triumphs and tribulations </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>this assignment was challenging (especially because of some misleading text in the tagging tutorial, which has since been fixed) but the students learned great deal.
</prevsent>
<prevsent>as mentioned above, should have begun with preliminary assignment which got students familiar with python basics before attempting this assignment.for assignment 2, provided simple set of regular expression grammar rules for the shallow parser class, and asked the students to improve on these.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
after building the chunker, students were asked to 4choose verb and then analyze verb-argument structure (they were provided with two relevant papers (church and hanks, 1990; <papid> J90-1003 </papid>chklovski and pantel,2004)).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>as mentioned above, most of the mims students were not familiar with regular expressions, so should have done longer unit on this topic, at the expense of boring the cs students.
</nextsent>
<nextsent>the students learned great deal from working to improve the grammar rules, but the verb-argument analysis portion was not particularly successful, in part because the corpus analyzed was too small to yield many sentences forgiven verb and because we did not have code to automatically find regularities about the semantics of the arguments of the verbs.
</nextsent>
<nextsent>other causes of difficulty were the students?
</nextsent>
<nextsent>lack of linguistic background, and the fact that the chunking part took longer than expected, leaving students little time for the analysis portion of the as signment.assignments 3 and 4 are described in the following subsections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB694">
<title id=" W05-0101.xml">teaching applied natural language processing triumphs and tribulations </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed extended experimentation with the system and developed detailed tutorial on how to use the system; this tutorial should be of general use.4 for the categorization task, we used the twenty newsgroups?
</prevsent>
<prevsent>collection that was supplied with nltk.
</prevsent>
</prevsection>
<citsent citstr=" J97-2002 ">
unfortunately, it was not preprocessed into sentences, so also had to write some sentence splitting code (based on palmer and hearst (1997)) <papid> J97-2002 </papid>so students could make use of their tokenizer and tagger code.we selected one pair of news groups which contained very different content (rec.motorcycles vs. sci.space).</citsent>
<aftsection>
<nextsent>we called this the diverseset.
</nextsent>
<nextsent>we then created two groups of news groups with more homogeneous content (a) rec.autos, rec.motorcycles, rec.sport.baseball, rec.sport.hockey, and (b) sci.crypt, sci.electronics, sci.med.original, sci.space.
</nextsent>
<nextsent>the intention was to show the students that it is easier to automatically distinguish the heterogeneous groups than the homogeneous ones.
</nextsent>
<nextsent>we set up the code to allow students to adjust the size of their training and development sets, and to separate out reserved test set that would be used for comparing students?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB695">
<title id=" W05-0101.xml">teaching applied natural language processing triumphs and tribulations </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>those who tried other topics were often too ambitious and had trouble getting meaningful results.
</prevsent>
<prevsent>however, several of those students were trying ideas that they planned to apply to their capstone projects, and so it was highly valuable for them to get preview of what worked and what did not.one suggestion made was to create back-of the-book indexer, specifically for recipe book, and one team did good job with this project.
</prevsent>
</prevsection>
<citsent citstr=" N04-4030 ">
another was to improve on or apply an automatic hierarchy generation tool that we have developed in our research (stoica and hearst, 2004).<papid> N04-4030 </papid></citsent>
<aftsection>
<nextsent>students working on project to collect meta data for camera phone images successfully applied this tool to this problem.
</nextsent>
<nextsent>again, social networking analysis topics were popular but not particularly successful; nlp tools are not advanced enough yet to meet the needs of this intriguing topic area.
</nextsent>
<nextsent>not surprisingly, when students started with new (interesting) text collection, they were bogged down in the preprocessing stage before they could get much interesting work done.
</nextsent>
<nextsent>6.4 reflecting on assignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB696">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a challenge in learning the semantics of multiword expressions (mwes) is their varying degrees of compositionalitythe contribution of each component word to the overall semantics of the expression.
</prevsent>
<prevsent>mwes fall on range from fully compositional (i.e., each component contributes its meaning, as in frying pan) to non compositional or idiomatic (as in hit the roof ).
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
be cause of this variation, researchers have explored automatic methods for learning whether, or the degree to which, an mwe is compositional (e.g., lin, 1999; <papid> P99-1041 </papid>bannard et al, 2003; <papid> W03-1809 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>fazly et al, 2005).<papid> W05-1005 </papid>however, such work leaves unaddressed the basic issue of which of the possible meanings of component word is contributed when the mwe is(at least partly) compositional.</citsent>
<aftsection>
<nextsent>words are notoriously ambiguous, so that even if it can be determined that an mwe is compositional, its meaning is still unknown, since the actual semantic contribution of the components is yet to be determined.we address this problem in the domain of verb particle constructions (vpcs) in english, rich source of mwes.
</nextsent>
<nextsent>vpcs combine verb with any of finite set of particles, as in jump up, figure out, or give in.
</nextsent>
<nextsent>particles such as up, out, or in, with their literal meaning based in physical spatial relations, show variety of metaphorical and aspect ual meaning extensions, as exemplified here for the particle up: (1a) the sun just came up.
</nextsent>
<nextsent>[vertical spatial movement] (1b) she walked up to him.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB697">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a challenge in learning the semantics of multiword expressions (mwes) is their varying degrees of compositionalitythe contribution of each component word to the overall semantics of the expression.
</prevsent>
<prevsent>mwes fall on range from fully compositional (i.e., each component contributes its meaning, as in frying pan) to non compositional or idiomatic (as in hit the roof ).
</prevsent>
</prevsection>
<citsent citstr=" W03-1809 ">
be cause of this variation, researchers have explored automatic methods for learning whether, or the degree to which, an mwe is compositional (e.g., lin, 1999; <papid> P99-1041 </papid>bannard et al, 2003; <papid> W03-1809 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>fazly et al, 2005).<papid> W05-1005 </papid>however, such work leaves unaddressed the basic issue of which of the possible meanings of component word is contributed when the mwe is(at least partly) compositional.</citsent>
<aftsection>
<nextsent>words are notoriously ambiguous, so that even if it can be determined that an mwe is compositional, its meaning is still unknown, since the actual semantic contribution of the components is yet to be determined.we address this problem in the domain of verb particle constructions (vpcs) in english, rich source of mwes.
</nextsent>
<nextsent>vpcs combine verb with any of finite set of particles, as in jump up, figure out, or give in.
</nextsent>
<nextsent>particles such as up, out, or in, with their literal meaning based in physical spatial relations, show variety of metaphorical and aspect ual meaning extensions, as exemplified here for the particle up: (1a) the sun just came up.
</nextsent>
<nextsent>[vertical spatial movement] (1b) she walked up to him.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB699">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a challenge in learning the semantics of multiword expressions (mwes) is their varying degrees of compositionalitythe contribution of each component word to the overall semantics of the expression.
</prevsent>
<prevsent>mwes fall on range from fully compositional (i.e., each component contributes its meaning, as in frying pan) to non compositional or idiomatic (as in hit the roof ).
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
be cause of this variation, researchers have explored automatic methods for learning whether, or the degree to which, an mwe is compositional (e.g., lin, 1999; <papid> P99-1041 </papid>bannard et al, 2003; <papid> W03-1809 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>fazly et al, 2005).<papid> W05-1005 </papid>however, such work leaves unaddressed the basic issue of which of the possible meanings of component word is contributed when the mwe is(at least partly) compositional.</citsent>
<aftsection>
<nextsent>words are notoriously ambiguous, so that even if it can be determined that an mwe is compositional, its meaning is still unknown, since the actual semantic contribution of the components is yet to be determined.we address this problem in the domain of verb particle constructions (vpcs) in english, rich source of mwes.
</nextsent>
<nextsent>vpcs combine verb with any of finite set of particles, as in jump up, figure out, or give in.
</nextsent>
<nextsent>particles such as up, out, or in, with their literal meaning based in physical spatial relations, show variety of metaphorical and aspect ual meaning extensions, as exemplified here for the particle up: (1a) the sun just came up.
</nextsent>
<nextsent>[vertical spatial movement] (1b) she walked up to him.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB700">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a challenge in learning the semantics of multiword expressions (mwes) is their varying degrees of compositionalitythe contribution of each component word to the overall semantics of the expression.
</prevsent>
<prevsent>mwes fall on range from fully compositional (i.e., each component contributes its meaning, as in frying pan) to non compositional or idiomatic (as in hit the roof ).
</prevsent>
</prevsection>
<citsent citstr=" W05-1005 ">
be cause of this variation, researchers have explored automatic methods for learning whether, or the degree to which, an mwe is compositional (e.g., lin, 1999; <papid> P99-1041 </papid>bannard et al, 2003; <papid> W03-1809 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>fazly et al, 2005).<papid> W05-1005 </papid>however, such work leaves unaddressed the basic issue of which of the possible meanings of component word is contributed when the mwe is(at least partly) compositional.</citsent>
<aftsection>
<nextsent>words are notoriously ambiguous, so that even if it can be determined that an mwe is compositional, its meaning is still unknown, since the actual semantic contribution of the components is yet to be determined.we address this problem in the domain of verb particle constructions (vpcs) in english, rich source of mwes.
</nextsent>
<nextsent>vpcs combine verb with any of finite set of particles, as in jump up, figure out, or give in.
</nextsent>
<nextsent>particles such as up, out, or in, with their literal meaning based in physical spatial relations, show variety of metaphorical and aspect ual meaning extensions, as exemplified here for the particle up: (1a) the sun just came up.
</nextsent>
<nextsent>[vertical spatial movement] (1b) she walked up to him.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB704">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it is worth emphasizing that our feature space draws on general properties of vpcs, and is not specific to this particle.a vpc may be ambiguous, with its particle occurring in more than one sense; in contrast to (1a), come up may use up in goal-oriented sense as in 45 the deadline is coming up.
</prevsent>
<prevsent>while our long-term goal is token classification (disambiguation) of vpc in context, following other work on vpcs (e.g., bannard et al, 2003; <papid> W03-1809 </papid>mccarthy et al, 2003), <papid> W03-1810 </papid>we begin here with the task of type classification.given our use of features which capture the statistical behaviour relevant to vpc across corpus, we assume that the outcome of type classification yields the predominant sense of the particle in the vpc.</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
predominant sense identification is useful component of sense disambiguation of word tokens (mccarthy et al, 2004), <papid> P04-1036 </papid>and we presume our vpc type classification work will form the basis for later token disambiguation.</citsent>
<aftsection>
<nextsent>section 2 continues the paper with discussion of the features we developed for particle sense classification.
</nextsent>
<nextsent>section 3 first presents some brief cognitive linguistic background, followed by the sense classes of up used in our experiments.
</nextsent>
<nextsent>sections 4 and 5 discuss our experimental set-up and results, section 6 related work, and section 7 our conclusions.
</nextsent>
<nextsent>the following subsections describe the two sets of features we investigated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB705">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>vpcs are identified using simple heuristic based on part-of-speech tags, similar to one technique used by baldwin (2005).
</prevsent>
<prevsent>a use of verb is considered vpc if it occurs with particle (tagged avp) within six word window to the right.
</prevsent>
</prevsection>
<citsent citstr=" E03-1040 ">
over random sample of 113 vpcs thus extracted, we found 88% to be true vpcs, somewhat below the performance of baldwins (2005) best extraction method, indicating potential room for improve ment.the slot and particle features are calculated using modified version of the extract verb software provided by joanis and stevenson (2003), <papid> E03-1040 </papid>which runs over the bnc pre-processed using abneys (1991) cass chunker.</citsent>
<aftsection>
<nextsent>to compute the word co-occurrence features (wcfs), we first determine the relative frequency of all words which occur within five word window left and right of any of the target expressions in the training data.
</nextsent>
<nextsent>from this list we eliminate the most frequent 1% of words as stop list andthen use the next  most frequent words as feature words?.
</nextsent>
<nextsent>for each feature word?, we then calculate its relative frequency of occurrence with inthe same five word window of the target expres #vpcs in sense class sense class train verification test vert-up 24 33 27 goal-up 1 1 3 cmpl-up 20 23 22 refl-up 15 3 8 table 1: frequency of items in each sense class.
</nextsent>
<nextsent>#vpcs in sense class sense class train verification test vert-up 24 33 27 goal-up 21 24 25 cmpl-up refl-up 15 3 8 table 2: frequency of items in each class for the 3-way task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB708">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this vein, uchiyama et al (2005) tackle token classification of japanese compound verbs (similar to vpcs) as aspect ual, spatial, or adverbial.
</prevsent>
<prevsent>in the future, we aim to extend the scope of our work, to determine the meaning of particle in vpc token, along the lines of our sense classes here.
</prevsent>
</prevsection>
<citsent citstr=" J04-1003 ">
this will almost certainly require semantic classification of the verb token (la pata and brew, 2004), <papid> J04-1003 </papid>similar to our approach hereof using the semantic class of verb type as indicative of the meaning of particle type.particle semantics has clear relations to preposition semantics.</citsent>
<aftsection>
<nextsent>some research has focused on the sense disambiguation of specific prepositions(e.g., alam, 2004), while other work has classified preposition tokens according to their semantic role (ohara and wiebe, 2003).<papid> W03-0411 </papid></nextsent>
<nextsent>moreover, two large lexical resources of preposition senses are currently under construction, the preposition project (litkowski, 2005) and prepnet (saint dizier, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB709">
<title id=" W06-1207.xml">classifying particle semantics in english verb particle constructions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the future, we aim to extend the scope of our work, to determine the meaning of particle in vpc token, along the lines of our sense classes here.
</prevsent>
<prevsent>this will almost certainly require semantic classification of the verb token (la pata and brew, 2004), <papid> J04-1003 </papid>similar to our approach hereof using the semantic class of verb type as indicative of the meaning of particle type.particle semantics has clear relations to preposition semantics.</prevsent>
</prevsection>
<citsent citstr=" W03-0411 ">
some research has focused on the sense disambiguation of specific prepositions(e.g., alam, 2004), while other work has classified preposition tokens according to their semantic role (ohara and wiebe, 2003).<papid> W03-0411 </papid></citsent>
<aftsection>
<nextsent>moreover, two large lexical resources of preposition senses are currently under construction, the preposition project (litkowski, 2005) and prepnet (saint dizier, 2005).
</nextsent>
<nextsent>these resources were not suitable as the basis for our sense classes because they do not address the range of metaphorical extensions that preposition/particle can take on, but future work may enable larger scale studies of the type needed to adequately address vpc semantics.
</nextsent>
<nextsent>while progress has recently been made in techniques for assessing the compositionality of vpcs, work thus far has left unaddressed the problem of determining the particular meaning of the components.
</nextsent>
<nextsent>we focus here on the semantic contribution of the particlea part-of-speech whose semantic complexity and range of metaphorical meaning extensions has been largely overlooked in prior computational work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB710">
<title id=" W05-0204.xml">predicting learning in tutoring with the landscape model of memory </title>
<section> corpus of tutoring transcripts.  </section>
<citcontext>
<prevsection>
<prevsent>in the current work, the model is extended to cover corpus of transcripts of physics tutoring dialogs.
</prevsent>
<prevsent>in the next section we describe this corpus.
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
our corpus was taken from transcripts collected for the itspoke intelligent tutoring system project(litman and silliman, 2004).<papid> N04-3002 </papid></citsent>
<aftsection>
<nextsent>this project has collected tutoring dialogs with both human and computer tutors.
</nextsent>
<nextsent>in this paper, we describe results using the human tutor corpus.
</nextsent>
<nextsent>students being tutored are first given pre-test togauge their physics knowledge.
</nextsent>
<nextsent>after reading instructional materials about physics, they are given aqualitative physics problem and asked to write an essay describing its solution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB711">
<title id=" W06-1304.xml">interactive question answering and constraint relaxation in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their experiments focus on over constrained queries, whereas we also deal with un der constrained ones.
</prevsent>
<prevsent>moreover, we guide the user through the dialogue by making suggestions about query refinements, which serve similar role to the conditional responses of (kruijff-korbayova et al., 2002).
</prevsent>
</prevsection>
<citsent citstr=" P04-1010 ">
(hardy et al, 2004) <papid> P04-1010 </papid>describe dialogue system that uses an error-correcting database manager for matching caller-provided information to database entries.</citsent>
<aftsection>
<nextsent>this allows the system to select the most likely database entry, but, in contrast to our approach, does not modify constraints ata more abstract level.
</nextsent>
<nextsent>in contrast to all the approaches mentioned above, our language generator uses over generation and ranking techniques (langkilde, 2000; <papid> A00-2023 </papid>varges and mellish, 2001).<papid> N01-1001 </papid></nextsent>
<nextsent>this facilitates variation and alignment with the user utterance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB712">
<title id=" W06-1304.xml">interactive question answering and constraint relaxation in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(hardy et al, 2004) <papid> P04-1010 </papid>describe dialogue system that uses an error-correcting database manager for matching caller-provided information to database entries.</prevsent>
<prevsent>this allows the system to select the most likely database entry, but, in contrast to our approach, does not modify constraints ata more abstract level.</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
in contrast to all the approaches mentioned above, our language generator uses over generation and ranking techniques (langkilde, 2000; <papid> A00-2023 </papid>varges and mellish, 2001).<papid> N01-1001 </papid></citsent>
<aftsection>
<nextsent>this facilitates variation and alignment with the user utterance.
</nextsent>
<nextsent>a long-standing strand of research in nlp isin natural language access to databases (androutsopoulos et al, 1995).
</nextsent>
<nextsent>it mainly focused on mapping natural language input to database queries.
</nextsent>
<nextsent>our work can be seen as an extension of this workby embedding it into dialogue system and allowing the user to refine and relax queries, and to engage in clarification dialogs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB713">
<title id=" W06-1304.xml">interactive question answering and constraint relaxation in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(hardy et al, 2004) <papid> P04-1010 </papid>describe dialogue system that uses an error-correcting database manager for matching caller-provided information to database entries.</prevsent>
<prevsent>this allows the system to select the most likely database entry, but, in contrast to our approach, does not modify constraints ata more abstract level.</prevsent>
</prevsection>
<citsent citstr=" N01-1001 ">
in contrast to all the approaches mentioned above, our language generator uses over generation and ranking techniques (langkilde, 2000; <papid> A00-2023 </papid>varges and mellish, 2001).<papid> N01-1001 </papid></citsent>
<aftsection>
<nextsent>this facilitates variation and alignment with the user utterance.
</nextsent>
<nextsent>a long-standing strand of research in nlp isin natural language access to databases (androutsopoulos et al, 1995).
</nextsent>
<nextsent>it mainly focused on mapping natural language input to database queries.
</nextsent>
<nextsent>our work can be seen as an extension of this workby embedding it into dialogue system and allowing the user to refine and relax queries, and to engage in clarification dialogs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB715">
<title id=" W06-1304.xml">interactive question answering and constraint relaxation in spoken dialogue systems </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>our dialogue system employs the following architecture: the output of speech recognizer (nuance, using statistical language model) is analyzed by both general-purpose statistical dependency parser and (domain-specific) topic classifier.
</prevsent>
<prevsent>parse trees and topic labels are matched bythe dialogue move scripts?
</prevsent>
</prevsection>
<citsent citstr=" H05-2013 ">
of the dialogue manager (mirkovic and cavedon, 2005; weng et al,2005).<papid> H05-2013 </papid></citsent>
<aftsection>
<nextsent>the scripts serve to license the instantia tion of dialogue moves and their integration into the dialogue move tree.?
</nextsent>
<nextsent>the use of dialogue move scripts is motivated by the need to quickly tailor the system to new domains: only the scripts need to be adapted, not the underlying machinery implemented in java.
</nextsent>
<nextsent>the scripts define short sequences of dialog moves, for example command move (play song x?)
</nextsent>
<nextsent>may be followed either by disambiguation question or confirmation thatthe command will be executed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB716">
<title id=" W06-1304.xml">interactive question answering and constraint relaxation in spoken dialogue systems </title>
<section> generation.  </section>
<citcontext>
<prevsection>
<prevsent>from the in stantiated move nodes, the generator obtains the database query result including information about query modifications.
</prevsent>
<prevsent>the core of the generator is set of productions1 written in the java expert system shell (friedman-hill, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W05-1626 ">
we follow the bottom-up generation approach for production systems described in (varges, 2005) <papid> W05-1626 </papid>and perform mild over generation of candidate moves, followed by ranking.</citsent>
<aftsection>
<nextsent>the highest-ranked candidate is selected for output.productions map individual database constraints to phrases such as open for lunch?, within 3 miles?
</nextsent>
<nextsent>and formal dress code?, and recursively combine them into nps.
</nextsent>
<nextsent>this includes the use of coordination to produce restaurants with 5-star rating and formal dress code?,for example.
</nextsent>
<nextsent>the nps are integrated into sentence templates, several of which can be combined to form an output candidate turn.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB722">
<title id=" W06-1109.xml">study of some distance measures for language and encoding identification </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>beesleys method needed 6-64 of training data and 10-12 words of test data.
</prevsent>
<prevsent>it treats language and encoding pair as one entity.
</prevsent>
</prevsection>
<citsent citstr=" W97-0907 ">
adams and resnik (adams and resnik, 1997) <papid> W97-0907 </papid>describe client-server system using dunnings n-grams based algorithm (dunning, 1994) for variety of tradeoffs available to nlp applications like between the labelling accuracy and the sizeand completeness of language models.</citsent>
<aftsection>
<nextsent>their system dynamically adds language models.
</nextsent>
<nextsent>the system uses other tools to identify the text encoding.
</nextsent>
<nextsent>they use 5-grams with add-k smoothing.
</nextsent>
<nextsent>training size was 1-50 and test size above 50 characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB723">
<title id=" W06-1109.xml">study of some distance measures for language and encoding identification </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>which are characteristic of each language.
</prevsent>
<prevsent>this methods assumes unique words for each language.
</prevsent>
</prevsection>
<citsent citstr=" C96-2110 ">
one major problem with this method was that the test string might not contain any unique words.cavnars method, combined with some heuristics, was used by kikui (kikui, 1996) <papid> C96-2110 </papid>to identify languages as well as encodings for multilingualtext.</citsent>
<aftsection>
<nextsent>he relied on known mappings between languages and encodings and treated east asian languages differently from west european languages.
</nextsent>
<nextsent>kranig (muthusamy et al, 1994) and (simon, 2005) have reviewed and evaluated some of thewell known language identification methods.
</nextsent>
<nextsent>martins and silva (martins and silva, 2005) describea method similar to cavnars but which uses different similarity measure proposed by jiang andconrath (jiang and conrath, 1997).
</nextsent>
<nextsent>some heuristics are also employed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB724">
<title id=" W06-1309.xml">tracing actions helps in understanding interactions </title>
<section> a pragmatics-first view on dialogues </section>
<citcontext>
<prevsection>
<prevsent>rational dialogues that are based on gricesmaxims of conversation serve for jointly executing task in the domain of discourse (called the application domain) by following plan that could solve the task assigned to the participants of the dialogue.
</prevsent>
<prevsent>therefore, the interpretation of new contributions and their integration into dialogue is controlled by global factors (e.g. the assumption that all dialogue participants behave in cooperative manner and work effectively towards the completion of joint task) as well as by local factors(e.g. how does the new contribution serve in completing the current shared plan?).ony if these factors are represented in an effective and efficient formal language, dialogue systems can be implemented.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
examples of such models and their implementation are the information state-update approach (an implemented system is described in (larsson, 2002)), or ? more linguistically oriented ? approaches like the adjacency-pair models or intentional models such as grosz and sidners (see (grosz and sidner, 1986)).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>even if it has been noted often that discourse structure and task structure are not isomorphic,only few contributions to dialogue research focus on the question of how both structures interfere (see sect.
</nextsent>
<nextsent>2).
</nextsent>
<nextsent>in this paper, we emphasize that it is important to distinguish between the dialogue situation and the application situation: the former is modified whenever speech acts are performed, whereas the latter changes according to the effects of each action being executed.
</nextsent>
<nextsent>in this section, we will use maptask dialogue to show what the notions dialogue situation and application situation intend to mean.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB725">
<title id=" W06-1309.xml">tracing actions helps in understanding interactions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, allwood does not work out in detail how the pragmatics of the application domain can be formalized intractable way.
</prevsent>
<prevsent>(carletta, 1992) 61shows in corpus analysis that risk taking is elementary behavior of dialogue participants.
</prevsent>
</prevsection>
<citsent citstr=" C02-1067 ">
(bosand oka, 2002) <papid> C02-1067 </papid>uses first-order logic in drt environment to reason about the logical satisfiabil ity of new utterance given previous discourse.</citsent>
<aftsection>
<nextsent>for reasoning about action however, we think that first-order theorem prover or model builder isnot the ideal tool because it is too general.
</nextsent>
<nextsent>additionally, in dialogues about acting in an environment, the primary interest of semantic evaluation is not whether formula is true or false, but how goal or task can be solved.
</nextsent>
<nextsent>therefore,planning is more appropriate than proofing formulae.
</nextsent>
<nextsent>work on planning as part of dialogue understanding is reported in (zinn, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB726">
<title id=" W06-1309.xml">tracing actions helps in understanding interactions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, the presented discourse model is not computationally effective.
</prevsent>
<prevsent>(huber and ludwig, 2002; ludwig, 2004) present an interactive system which uses planning, (yates et al, 2003) and recently (lieberman and espinosa, 2006) reported on applying planning as vehicle for natural language interfaces, but none of the papers discusses how dialogue can be continued when failure in the application occurs.
</prevsent>
</prevsection>
<citsent citstr=" W02-0216 ">
in the witas system (see (lemon et al,2002)), <papid> W02-0216 </papid>activities are modelled by activity models, one for each type of activity the system can perform or analyse.</citsent>
<aftsection>
<nextsent>a similiar recipe-based approach is implemented in collagen (garland et al, 2003).
</nextsent>
<nextsent>as activities are hard-coded in the respective model, adaptation of the task and dialogue structure to the needs in current situation are harder to achieve than in our approach in which only goals are specified and activities are selected by planner depending on the current state.
</nextsent>
<nextsent>in addition, executing plans by verifying preconditions and effects of an activity that has been carried out recently lies the basis for framework of understanding the pragmatics of dialogue that is not implemented for particular application, but tries to be as generic as possible.
</nextsent>
<nextsent>a computational approach that aims at analyzing and generating rational ? i.e. goal-oriented ? dialogues in given domain must address the issues of organizing solution in the application domain as well as in the discourse domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB727">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these environments, keyboard input is inconvenient or sometimes impossible because of spatial limitation on mobile devices and instability in manipulating the devices.
</prevsent>
<prevsent>however, because of the low recognition rate in current speech recognition systems, the performance of speech applications such as speech-driven information retrieval (ir) and question answering (qa), and speech dialogue systems is very low.
</prevsent>
</prevsection>
<citsent citstr=" C02-1169 ">
the performance of the serially connected spoken qa system, based on the qa system from text input which has 76% performance and the output of the asr which operated at 30% wer, was only 7%(harabagiu et al, 2002).<papid> C02-1169 </papid></citsent>
<aftsection>
<nextsent>(harabagiu et al, 2002) <papid> C02-1169 </papid>exposes several fundamental flaws of this simple combination of an automatic speech recognition (asr) and qasystem, including the importance of named entity information, and the inadequacies of current speech recognition technology based on n-gram language models.</nextsent>
<nextsent>the major problem of speech-driven ir and qa is the decreasing of the performance due to the recognition errors in asr systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB729">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they evaluated the effectiveness of their systems through various error rates using 35 queries of trec.
</prevsent>
<prevsent>their researches show that the increasing word error rate (wer) quickly decreases the precision of ir.
</prevsent>
</prevsection>
<citsent citstr=" W02-1025 ">
another group investigated the performance of spoken queries in ntcir collections (fujii et al, 2002<papid> W02-1025 </papid>a).</citsent>
<aftsection>
<nextsent>they evaluated variety of speakers, and calculated the error rate with respect to query term, which is keyword used for the retrieval.
</nextsent>
<nextsent>they showed that the wer of the query terms was generally higher than that of the general words irrespective of the speakers.
</nextsent>
<nextsent>in other words, recognition of content words related to their and qa performance was more difficult than that of normal words.
</nextsent>
<nextsent>so, they introduced method to improve the precision of speech driven ir by suggesting new type of ir system tightly integrated with speech input interface (fujii et al, 2002<papid> W02-1025 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB735">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if the speech recognizer can be regarded as black-box, we can perform robust and flexible domain adaptation through the post error correction process.
</prevsent>
<prevsent>figure 1 shows the paradigm of this post error correction approach.
</prevsent>
</prevsection>
<citsent citstr=" P98-1107 ">
one approach in post error correction, which is straightforward and intuitive method to robustly handle many kinds of recognition errors, was rule-based approach (kaki et al, 1998).<papid> P98-1107 </papid></citsent>
<aftsection>
<nextsent>(kaki et al, 1998) <papid> P98-1107 </papid>collected many lexical error patterns that occurred in speech translation system in japanese.</nextsent>
<nextsent>they could correct any type of errors by matching the strings in the transcription with lexical error patterns in the database.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB737">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another approach has been based on statistical method utilizing the probabilistic information of words in spoken dialogue situation and the language models adapted to the application domain (ringger and allen,1996).
</prevsent>
<prevsent>(ringger and allen, 1996) applied the noisy channel model to the correction of the errors in speech recognition.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
they simplified statistical machine translation (mt) model called an ibm model (brown et al, 1990), <papid> J90-2002 </papid>and tried to construct general post-processor that can correct errors generated by any speech recognizer.</citsent>
<aftsection>
<nextsent>the model consists of two parts: channel model, which accounts for errors made by the asr, and the language model, which accounts for the likelihood of sequence of words being uttered.
</nextsent>
<nextsent>they trained the channel model and the language model both using some transcriptions from trains-95 dialogue system which is train traveling planning system (allen et al, 1996).<papid> P96-1009 </papid></nextsent>
<nextsent>here, the channel model has the distribution that an original word may be recognized as an erroneous word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB739">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they simplified statistical machine translation (mt) model called an ibm model (brown et al, 1990), <papid> J90-2002 </papid>and tried to construct general post-processor that can correct errors generated by any speech recognizer.</prevsent>
<prevsent>the model consists of two parts: channel model, which accounts for errors made by the asr, and the language model, which accounts for the likelihood of sequence of words being uttered.</prevsent>
</prevsection>
<citsent citstr=" P96-1009 ">
they trained the channel model and the language model both using some transcriptions from trains-95 dialogue system which is train traveling planning system (allen et al, 1996).<papid> P96-1009 </papid></citsent>
<aftsection>
<nextsent>here, the channel model has the distribution that an original word may be recognized as an erroneous word.
</nextsent>
<nextsent>they use the probability of mistakenly recognized words, the co-occurrenceinformation extracted from the words and their neighboring words, and the tagged word bi-grams, which are all lexical clues in error strings.
</nextsent>
<nextsent>such approaches based on lexical information of words have shown some successful results, but they still have major drawbacks; the performance of such systems depends on the size and the quality of speech recognition result, or on the database of collected error strings since they are directly dependent on lexical items.
</nextsent>
<nextsent>the error patterns constructed are available but not enough, be cause it is expensive to collect them; so in many cases, they fail to recover the original strings from the lexical specific error patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB741">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> noisy channel error correction model.  </section>
<citcontext>
<prevsection>
<prevsent>we prove the feasibility of our approach through some.
</prevsent>
<prevsent>experiments in section 5, and draw some conclusions in section 6.
</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
the noisy channel error correction framework has been applied to wide range of problems, such as spelling correction, statistical machine translation, and asr error correction (brill and moore, 2000; <papid> P00-1037 </papid>brown et al, 1990;<papid> J90-2002 </papid>ringger and allen, 1996).</citsent>
<aftsection>
<nextsent>the key idea of noisy channel model is that we can model some channel properties through estimating the posterior probabilities.
</nextsent>
<nextsent>the problem of asr error correction can be stated in this model as follows: for an input sentence, = o1, o2, . . .
</nextsent>
<nextsent>, on produced as the output sequence of asr, find the best word sequence,w? = w1, w2, . . .
</nextsent>
<nextsent>, wn, that maximizes the posterior probability (w |o).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB743">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> noisy channel error correction model.  </section>
<citcontext>
<prevsection>
<prevsent>rule and dropping the constant denominator, we can rewrite as: w?
</prevsent>
<prevsent>= arg max p (w |o) = arg max p (w )p (o|w ) (1)now, we have noisy channel model for asr error correction, with two components, the source model (w ) and the channel model (o|w ).
</prevsent>
</prevsection>
<citsent citstr=" P97-1064 ">
the probabilityp(w) is given by the language model and can be decomposed as: (w ) = ? p (wi|w1,i1) (2) figure 2: example of word-based channel model the distribution (w ) can be defined using n-grams, structured language model (chelba, 1997), <papid> P97-1064 </papid>or any other tool in the statistical language modeling.</citsent>
<aftsection>
<nextsent>next, the conditional probability, (o|w ) reflects the channel characteristics of the asr environment.
</nextsent>
<nextsent>if we assume that the output word sequence produced under asr are independent of one another, we have the following formula: (o|w ) = ? p (o1,i|w1,i) = ? p (oi|wi) (3) so, w?
</nextsent>
<nextsent>= arg max p (w )p (o|w ) = arg max ( ? p (wi|w1,i1) ? p (oi|wi))(4) however, this simple one-to-one model is not suitable to handling split or merged errors, which frequently appear in an asr output, because we assume that the out put word sequence are independent of one another.
</nextsent>
<nextsent>for example, 1figure 2 shows split or merged error problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB746">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> using syntactic and semantic.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 lexico-semantic pattern.
</prevsent>
<prevsent>a lexico-semantic pattern (lsp) is structure where linguistic entries and semantic types are used in combination to abstract certain sequences of the words in text.
</prevsent>
</prevsection>
<citsent citstr=" W01-1202 ">
it has been used in the area of natural language interface for database (nlidb) (jung et al, 2003) and trec qa system for the purpose of matching the user query with the appropriate answer types at syntax/semantic level (kim et al, 2001; <papid> W01-1202 </papid>lee et al, 2001).</citsent>
<aftsection>
<nextsent>in an lsp,linguistic entries consist of words, phrases and part-of speech (pos) tags, such as ymca,?
</nextsent>
<nextsent>young mens christian association,?
</nextsent>
<nextsent>and nnp.3 semantic types con 3part-of-speech tag denoting proper noun which is used in penn treebank (marcus et al, 1994).
</nextsent>
<nextsent>phrases lsp reading trainer fairytale trainer %hobby @position recreation coach table 1: example of template abstracted by lsp sist of common semantic classes and domain-specific (or user-defined) semantic classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB750">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> using syntactic and semantic.  </section>
<citcontext>
<prevsection>
<prevsent>query-to-lsp translation transforms given query intoa corresponding lsp, and the lsps enhance the coverage of extraction by information abstraction through many-to-one mapping between queries and an lsp.
</prevsent>
<prevsent>the words in query sentence are converted into the lsp through several steps.
</prevsent>
</prevsection>
<citsent citstr=" J02-1004 ">
first, morphological analysis is performed, which segments sentence of words into morphemes, and adds pos tags to the morphemes (lee et al,2002).<papid> J02-1004 </papid></citsent>
<aftsection>
<nextsent>ne recognition discovers all the possible semantic types for each word by consulting domain dictionary and an ontology dictionary.
</nextsent>
<nextsent>ne tagging selects semantic type for each word so that sentence can be mapped into suitable lsp sequence by searching several types in the semantic dictionaries (an et al, 2003).<papid> P03-2031 </papid></nextsent>
<nextsent>4.3 semantic-oriented error correction process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB751">
<title id=" W04-3009.xml">using higher level linguistic knowledge for speech recognition error correction in a spoken qa dialog </title>
<section> using syntactic and semantic.  </section>
<citcontext>
<prevsection>
<prevsent>first, morphological analysis is performed, which segments sentence of words into morphemes, and adds pos tags to the morphemes (lee et al,2002).<papid> J02-1004 </papid></prevsent>
<prevsent>ne recognition discovers all the possible semantic types for each word by consulting domain dictionary and an ontology dictionary.</prevsent>
</prevsection>
<citsent citstr=" P03-2031 ">
ne tagging selects semantic type for each word so that sentence can be mapped into suitable lsp sequence by searching several types in the semantic dictionaries (an et al, 2003).<papid> P03-2031 </papid></citsent>
<aftsection>
<nextsent>4.3 semantic-oriented error correction process.
</nextsent>
<nextsent>now, we will show the working mechanism of post error correction of speech recognition result using the domain knowledge of template database and domain-specific dictionary.
</nextsent>
<nextsent>figure 5 is schematic diagram of the post error correction process.the overall process is divided into two stages: syn tactic/semantic recovery and lexical recovery stage.
</nextsent>
<nextsent>in the semantic error detection stage, recognized query is converted into the corresponding lsp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB755">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in multi document summarization of news articles, it can be useful to know the relative order of events so as to merge and present information from multiple news sources correctly.
</prevsent>
<prevsent>in question answering, one would like to be able to ask when an event occurs, or what events occurred prior to particular event.
</prevsent>
</prevsection>
<citsent citstr=" J88-2006 ">
a wealth of prior research by (passoneau 1988), (webber 1988), (<papid> J88-2006 </papid>hwang and schubert 1992), (<papid> P92-1030 </papid>kamp and reyle 1993), (las carides and asher 1993), (hitzeman et al 1995), (<papid> E95-1035 </papid>kehler 2000) and others, has explored the different knowledge sources used in inferring the temporal ordering of events, including temporal adverbials, tense, aspect, rhetorical relations, pragmatic conventions, and background knowl edge.</citsent>
<aftsection>
<nextsent>for example, the narrative convention of events being described in the order in which they occur is followed in (1), but overridden by means of discourse relation, explanation in (2).
</nextsent>
<nextsent>(1) max stood up.
</nextsent>
<nextsent>john greeted him.
</nextsent>
<nextsent>(2) max fell.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB756">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in multi document summarization of news articles, it can be useful to know the relative order of events so as to merge and present information from multiple news sources correctly.
</prevsent>
<prevsent>in question answering, one would like to be able to ask when an event occurs, or what events occurred prior to particular event.
</prevsent>
</prevsection>
<citsent citstr=" P92-1030 ">
a wealth of prior research by (passoneau 1988), (webber 1988), (<papid> J88-2006 </papid>hwang and schubert 1992), (<papid> P92-1030 </papid>kamp and reyle 1993), (las carides and asher 1993), (hitzeman et al 1995), (<papid> E95-1035 </papid>kehler 2000) and others, has explored the different knowledge sources used in inferring the temporal ordering of events, including temporal adverbials, tense, aspect, rhetorical relations, pragmatic conventions, and background knowl edge.</citsent>
<aftsection>
<nextsent>for example, the narrative convention of events being described in the order in which they occur is followed in (1), but overridden by means of discourse relation, explanation in (2).
</nextsent>
<nextsent>(1) max stood up.
</nextsent>
<nextsent>john greeted him.
</nextsent>
<nextsent>(2) max fell.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB757">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in multi document summarization of news articles, it can be useful to know the relative order of events so as to merge and present information from multiple news sources correctly.
</prevsent>
<prevsent>in question answering, one would like to be able to ask when an event occurs, or what events occurred prior to particular event.
</prevsent>
</prevsection>
<citsent citstr=" E95-1035 ">
a wealth of prior research by (passoneau 1988), (webber 1988), (<papid> J88-2006 </papid>hwang and schubert 1992), (<papid> P92-1030 </papid>kamp and reyle 1993), (las carides and asher 1993), (hitzeman et al 1995), (<papid> E95-1035 </papid>kehler 2000) and others, has explored the different knowledge sources used in inferring the temporal ordering of events, including temporal adverbials, tense, aspect, rhetorical relations, pragmatic conventions, and background knowl edge.</citsent>
<aftsection>
<nextsent>for example, the narrative convention of events being described in the order in which they occur is followed in (1), but overridden by means of discourse relation, explanation in (2).
</nextsent>
<nextsent>(1) max stood up.
</nextsent>
<nextsent>john greeted him.
</nextsent>
<nextsent>(2) max fell.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB758">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) max fell.
</prevsent>
<prevsent>john pushed him.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
while there has been spurt of recent research addressing the event ordering problem, e.g., (mani and wilson 2000) (<papid> P00-1010 </papid>filatova and hovy 2001) (schilder and habel 2001) (li et al 2001) (mani et al 2003) (<papid> N03-2019 </papid>li et al 2004) (<papid> P04-1074 </papid>lapata and lascarides 2004) (<papid> N04-1020 </papid>boguraev and ando 2005) (mani et al 2006), <papid> P06-1095 </papid>that research relies on qualitative temporal relations.</citsent>
<aftsection>
<nextsent>qualitative relations (e.g., event before event b, or event during time t) are certainly of interest in developing timelines of events in news and other genres.
</nextsent>
<nextsent>however, metric constraints can also be potentially useful in this ordering problem.
</nextsent>
<nextsent>for example, in (3), it can be crucial to know whether the bomb landed few minutes to hours or several years before the hospitalization.
</nextsent>
<nextsent>while humans have strong intuitions about this from commonsense knowledge, machines dont.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB759">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) max fell.
</prevsent>
<prevsent>john pushed him.
</prevsent>
</prevsection>
<citsent citstr=" N03-2019 ">
while there has been spurt of recent research addressing the event ordering problem, e.g., (mani and wilson 2000) (<papid> P00-1010 </papid>filatova and hovy 2001) (schilder and habel 2001) (li et al 2001) (mani et al 2003) (<papid> N03-2019 </papid>li et al 2004) (<papid> P04-1074 </papid>lapata and lascarides 2004) (<papid> N04-1020 </papid>boguraev and ando 2005) (mani et al 2006), <papid> P06-1095 </papid>that research relies on qualitative temporal relations.</citsent>
<aftsection>
<nextsent>qualitative relations (e.g., event before event b, or event during time t) are certainly of interest in developing timelines of events in news and other genres.
</nextsent>
<nextsent>however, metric constraints can also be potentially useful in this ordering problem.
</nextsent>
<nextsent>for example, in (3), it can be crucial to know whether the bomb landed few minutes to hours or several years before the hospitalization.
</nextsent>
<nextsent>while humans have strong intuitions about this from commonsense knowledge, machines dont.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB760">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) max fell.
</prevsent>
<prevsent>john pushed him.
</prevsent>
</prevsection>
<citsent citstr=" P04-1074 ">
while there has been spurt of recent research addressing the event ordering problem, e.g., (mani and wilson 2000) (<papid> P00-1010 </papid>filatova and hovy 2001) (schilder and habel 2001) (li et al 2001) (mani et al 2003) (<papid> N03-2019 </papid>li et al 2004) (<papid> P04-1074 </papid>lapata and lascarides 2004) (<papid> N04-1020 </papid>boguraev and ando 2005) (mani et al 2006), <papid> P06-1095 </papid>that research relies on qualitative temporal relations.</citsent>
<aftsection>
<nextsent>qualitative relations (e.g., event before event b, or event during time t) are certainly of interest in developing timelines of events in news and other genres.
</nextsent>
<nextsent>however, metric constraints can also be potentially useful in this ordering problem.
</nextsent>
<nextsent>for example, in (3), it can be crucial to know whether the bomb landed few minutes to hours or several years before the hospitalization.
</nextsent>
<nextsent>while humans have strong intuitions about this from commonsense knowledge, machines dont.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB761">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) max fell.
</prevsent>
<prevsent>john pushed him.
</prevsent>
</prevsection>
<citsent citstr=" N04-1020 ">
while there has been spurt of recent research addressing the event ordering problem, e.g., (mani and wilson 2000) (<papid> P00-1010 </papid>filatova and hovy 2001) (schilder and habel 2001) (li et al 2001) (mani et al 2003) (<papid> N03-2019 </papid>li et al 2004) (<papid> P04-1074 </papid>lapata and lascarides 2004) (<papid> N04-1020 </papid>boguraev and ando 2005) (mani et al 2006), <papid> P06-1095 </papid>that research relies on qualitative temporal relations.</citsent>
<aftsection>
<nextsent>qualitative relations (e.g., event before event b, or event during time t) are certainly of interest in developing timelines of events in news and other genres.
</nextsent>
<nextsent>however, metric constraints can also be potentially useful in this ordering problem.
</nextsent>
<nextsent>for example, in (3), it can be crucial to know whether the bomb landed few minutes to hours or several years before the hospitalization.
</nextsent>
<nextsent>while humans have strong intuitions about this from commonsense knowledge, machines dont.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB762">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) max fell.
</prevsent>
<prevsent>john pushed him.
</prevsent>
</prevsection>
<citsent citstr=" P06-1095 ">
while there has been spurt of recent research addressing the event ordering problem, e.g., (mani and wilson 2000) (<papid> P00-1010 </papid>filatova and hovy 2001) (schilder and habel 2001) (li et al 2001) (mani et al 2003) (<papid> N03-2019 </papid>li et al 2004) (<papid> P04-1074 </papid>lapata and lascarides 2004) (<papid> N04-1020 </papid>boguraev and ando 2005) (mani et al 2006), <papid> P06-1095 </papid>that research relies on qualitative temporal relations.</citsent>
<aftsection>
<nextsent>qualitative relations (e.g., event before event b, or event during time t) are certainly of interest in developing timelines of events in news and other genres.
</nextsent>
<nextsent>however, metric constraints can also be potentially useful in this ordering problem.
</nextsent>
<nextsent>for example, in (3), it can be crucial to know whether the bomb landed few minutes to hours or several years before the hospitalization.
</nextsent>
<nextsent>while humans have strong intuitions about this from commonsense knowledge, machines dont.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB763">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>there were 1325 hits for this query in the bnc.
</prevsent>
<prevsent>(the public web interface to the bnc only shows 50 random results at time, so we had to iterate.)
</prevsent>
</prevsection>
<citsent citstr=" P05-3021 ">
the retrieved hits (sentences and fragments of sentences) were then processed with components from the tarsqi toolkit (verhagen et al 2005) <papid> P05-3021 </papid>to provide automatic timeml annotations.</citsent>
<aftsection>
<nextsent>the tlinks between events and times that were timex3 durations were then extracted.
</nextsent>
<nextsent>these links were then corrected and validated by hand and then added to the otc data to form an integrated corpus.
</nextsent>
<nextsent>an example from the bnc is shown in (9).
</nextsent>
<nextsent>(9) the  event storm /event   event lasted /event   timex3 val= p5d  five days /timex3 .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB764">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> 4 end, grow,  </section>
<citcontext>
<prevsection>
<prevsent>distribution of aggregated durations interestingly, 67 events in the data correspond to achievement?
</prevsent>
<prevsent>verbs, whose main characteristic is that they can have near-instantaneous duration (though of course they can be iterated or extended to have other durations).
</prevsent>
</prevsection>
<citsent citstr=" P97-1020 ">
we obtained list of achievement verbs from the lcs lexicon of (dorr and olsen 1997)<papid> P97-1020 </papid>3.</citsent>
<aftsection>
<nextsent>achievements can be marked as having durations of ptxs, i.e., an unspecified number of seconds.
</nextsent>
<nextsent>such values dont reinforce any of the observed values, instead extending the set of durations to include much smaller durations.
</nextsent>
<nextsent>as result, these hidden values are not shown in our data 6 estimating duration probabilities.
</nextsent>
<nextsent>given distribution of durations for events observed in corpora, one of the challenges is to arrive at an appropriate value forgiven event (or class of events).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB765">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> possible enhancements.  </section>
<citcontext>
<prevsection>
<prevsent>7.3 expanding the corpus sample.
</prevsent>
<prevsent>last but not least, we could expand substantially the search patterns and size of the corpus searched against.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
in particular, we could emulate the approach used in verb ocean (chklovski and pantel 2004).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>this resource consists of lexical relations mined from google searches.
</nextsent>
<nextsent>the mining uses set of lexical and syntactic patterns to test for pairs of verbs strongly associated on the web in particular semantic relation.
</nextsent>
<nextsent>for example, the system discovers that marriage happens before divorce, and that tie happens-before untie.
</nextsent>
<nextsent>such results are based on estimating the probability of the joint occurrence of the two verbs and the pattern.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB766">
<title id=" W06-0904.xml">a pilot study on acquiring metric temporal constraints for events </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in follow-on research, we will explore the enhancements described in section 7.
</prevsent>
<prevsent>however, this work is limited by the lack of evaluation, in terms of assessing how valid the durations inferred by our method are compared with human annotations.
</prevsent>
</prevsection>
<citsent citstr=" P06-1050 ">
in ongoing work, jerry hobbs and his colleagues (pan et al 2006) <papid> P06-1050 </papid>have developed an annotation scheme for humans to mark up event durations in documents.</citsent>
<aftsection>
<nextsent>once such enhancements are carried out, it will certainly be fruitful to compare the duration probabilities obtained with the ranges of durations provided in that corpus.
</nextsent>
<nextsent>in future, we will explore both regression and classification models for duration learning.
</nextsent>
<nextsent>in the latter case, we will investigate the use of constructive induction e.g., (bloedorn and michalski 1998).
</nextsent>
<nextsent>in particular, we will avail of operators to implement attribute abstraction that will cluster durations into coarse-grained classes, based on distributions of atomic durations observed in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB767">
<title id=" W05-0821.xml">improved language modeling for statistical machine translation </title>
<section> factored language models.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of this study was to use some of the language modeling techniques that have proved beneficial for asr in the past andto investigate whether they transfer to statistical machine translation.
</prevsent>
<prevsent>in particular, this includes language models that make use of morphological andpart-of-speech information, so-called factored language models.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
a factored language model (flm) (bilmes and kirchhoff, 2003) <papid> N03-2002 </papid>is based on representation of words as feature vectors and can utilize variety of additional information sources in addition to words,such as part-of-speech (pos) information, morphological information, or semantic features, in unified and principled framework.</citsent>
<aftsection>
<nextsent>assuming that each 125 word can be decomposed into features, i.e. ? f1:k , trigram model can be defined as p(f1:k1 , f1:k2 , ..., 1:kt ) ? ? t=3 p(f1:kt |f1:kt1 , f1:kt2 ) (3) each word is dependent not only on single stream of temporally preceding words, but also on additional parallel streams of features.
</nextsent>
<nextsent>this representation can be used to provide more robust probability estimates when particular word n-gram has notbeen observed in the training data but its corresponding feature combinations (e.g. stem or tag trigrams) has been observed.
</nextsent>
<nextsent>flms are therefore designed to exploit sparse training data more effectively.
</nextsent>
<nextsent>how ever, even when sufficient amount of training datais available, language model utilizing morphological and pos information may bias the system towards selecting more fluent translations, by boosting the score of hypotheses with e.g. frequent pos combinations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB768">
<title id=" W05-0821.xml">improved language modeling for statistical machine translation </title>
<section> factored language models.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to different choices for g, different discounting parameters can be selected at different levels in the backoff graph.
</prevsent>
<prevsent>one difficulty in training flms is the choice of the best combination of conditioning factors, backoff path(s) and smoothing options.
</prevsent>
</prevsection>
<citsent citstr=" C04-1022 ">
since the space of different combinations is too large to be searched exhaustively, we usea guided search procedure based on genetic algorithms (duh and kirchhoff, 2004), <papid> C04-1022 </papid>which optimizes the flm structure with respect to the desired crite rion.</citsent>
<aftsection>
<nextsent>in asr, this is usually the perplexity of the language model on held-out dataset; here, we use the bleu scores of the oracle 1-best hypotheses on the development set, as described below.
</nextsent>
<nextsent>flms have previously shown significant improvements in perplexity and word error rate on several asr tasks (e.g.
</nextsent>
<nextsent>(vergyri et al, 2004)).
</nextsent>
<nextsent>we used fairly simple baseline system trained using standard tools, i.e. giza++ (och and ney, 2000) for training word alignments and pharaoh (koehn, 2004) for phrase-based decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB769">
<title id=" W05-0821.xml">improved language modeling for statistical machine translation </title>
<section> language models.  </section>
<citcontext>
<prevsection>
<prevsent>the potential advantage of this model is that it models n-gramsup to length 4; since the bleu score is combination of n-gram precision scores up to length 4, the integration of 4-gram language model might yield better results.
</prevsent>
<prevsent>note that this can only be done in rescoring framework since the first-pass decoder can only use trigram language model.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
for the factored language models, feature-based word representation was obtained by tagging the text with rathnaparkis maximum-entropy tagger (rat naparkhi, 1996) <papid> W96-0213 </papid>and by stemming words using the porter stemmer (porter, 1980).</citsent>
<aftsection>
<nextsent>thus, the factored language models use two additional features perword.
</nextsent>
<nextsent>a word history of up to 2 was considered (3 gram flms).
</nextsent>
<nextsent>rather than optimizing the flms on the development set references, they were optimized to achieve low perplexity on the oracle 1-best hypotheses (the hypotheses with the best individual bleu scores) from the first decoding pass.
</nextsent>
<nextsent>this isdone to avoid optimizing the model on word combinations that might never be hypothesized by the first pass decoder, and tobias the model towards achieving high bleu score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB770">
<title id=" W05-0902.xml">on the subjectivity of human authored summaries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summary.
</prevsent>
<prevsent>the issue of subjectivity gains prominence as the compression ratio increases, i.e., the shorter the summary, the larger the number of correct?
</prevsent>
</prevsection>
<citsent citstr=" W03-0510 ">
summaries (lin andhovy, 2003<papid> W03-0510 </papid>b).</citsent>
<aftsection>
<nextsent>this is due to the fact that assimilation of seemingly important contents takes priority while discarding the redundant information.
</nextsent>
<nextsent>this is highly subjective aspect.
</nextsent>
<nextsent>although the subjectivity reflects individuals thoughts, there will also be some information commonly observed in different summaries of the same story.
</nextsent>
<nextsent>stated otherwise, words in summary may vary, phrases may vary, and often the grammatical structure may not be the same, but certain degree of information may be common across summaries.to what degree is information uniform across different summaries?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB772">
<title id=" W05-0902.xml">on the subjectivity of human authored summaries </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>there have been number of studies concerned with collating and analysing of human authored summaries, with the aim of producing and evaluating machine generated summaries.
</prevsent>
<prevsent>a phrase weighting process called the pyramid method?
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
was described in (nenkova and passonneau, 2004).<papid> N04-1019 </papid></citsent>
<aftsection>
<nextsent>they exploited the frequency of the same (similar) information that was in multiple summaries of the same story.
</nextsent>
<nextsent>it was referred to as summarisation content unit (scu).
</nextsent>
<nextsent>increasing stability of pyramid scores was observed as the pyramid grew larger.
</nextsent>
<nextsent>the authors concluded, however, that the initial creation of the pyramid was tedious task because large number of scus had to be hand annotated.in (van halteren and teufel, 2003), the cooccurrence of atomic information elements, called facto ids, was examined whilst analysing 50 different summaries of two stories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB776">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also describe markov parsing models, general framework for parser modeling and control, of which the parsers reported here are special case.
</prevsent>
<prevsent>a fundamental result of formal language theory is that the languages defined by context-free grammars are the same as those accepted by push-down automata.
</prevsent>
</prevsection>
<citsent citstr=" P99-1070 ">
this result was recently extended to the stochastic case (abney, et al, 1999).<papid> P99-1070 </papid></citsent>
<aftsection>
<nextsent>there are thus two main approaches to training statistical parser: inducing stochastic grammars and inducing stochastic automata.most recent work has employed grammar induction (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>examples of the automaton-induction approach are hermjakob (1997), which described deterministic parser, and ratnaparkhi (1998), which described stochastic parser.the deterministic parsers reported in this paper are greedy versions of stochastic parsers based on markov parsing models, described in section 3.3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB777">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a fundamental result of formal language theory is that the languages defined by context-free grammars are the same as those accepted by push-down automata.
</prevsent>
<prevsent>this result was recently extended to the stochastic case (abney, et al, 1999).<papid> P99-1070 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
there are thus two main approaches to training statistical parser: inducing stochastic grammars and inducing stochastic automata.most recent work has employed grammar induction (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>examples of the automaton-induction approach are hermjakob (1997), which described deterministic parser, and ratnaparkhi (1998), which described stochastic parser.the deterministic parsers reported in this paper are greedy versions of stochastic parsers based on markov parsing models, described in section 3.3.
</nextsent>
<nextsent>a greedy parser takes the single most probable action at every choice point.
</nextsent>
<nextsent>itthus does the minimum amount of search possible.
</nextsent>
<nextsent>there will always be tradeoff between speed on the one hand and accuracy and robustness on the other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB778">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>we find that they areal most as fast as current part-of-speech taggers, and they outperform basic un lexicalized pcfg parsers.
</prevsent>
<prevsent>while coverage is concern, it is quite high (over 99%) for some of our parsers.
</prevsent>
</prevsection>
<citsent citstr=" H92-1026 ">
markov parsing models are an example of the history-based parsing approach (black, et al., 1992).<papid> H92-1026 </papid></citsent>
<aftsection>
<nextsent>history-based parsing, broadly interpreted, includes most statistical parsers.markov parsing models take more automaton oriented (or control-oriented) view of what history means, compared to the more grammar oriented view of the original paper and most subsequent work.
</nextsent>
<nextsent>hermjakob (1997) described deterministic shift-reduce parser.
</nextsent>
<nextsent>the control is learned by hybrid of decision trees and decision lists.
</nextsent>
<nextsent>this work also used rich hand-crafted semantic ontology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB779">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>left-corner parsing is discussed in manning and carpenter (1997) and roark (2001).for search, roark used beam search with non backtracking top down automata, rather than the more usual chart-based search.
</prevsent>
<prevsent>magerman (1994) used parsing model based on decision tree techniques.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
numerous papers (manning and carpenter, 1997; johnson, 1998; <papid> J98-4004 </papid>charniak et al, 1998; <papid> W98-1115 </papid>roark, 2001) report that treebank binarization is advantageous.</citsent>
<aftsection>
<nextsent>3.1 general concepts.
</nextsent>
<nextsent>our approach to automaton induction is to view parsing as control problem.
</nextsent>
<nextsent>the parsing automaton is discrete dynamical system which we want to learn to control.
</nextsent>
<nextsent>at any given time, parser is in some state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB780">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>left-corner parsing is discussed in manning and carpenter (1997) and roark (2001).for search, roark used beam search with non backtracking top down automata, rather than the more usual chart-based search.
</prevsent>
<prevsent>magerman (1994) used parsing model based on decision tree techniques.
</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
numerous papers (manning and carpenter, 1997; johnson, 1998; <papid> J98-4004 </papid>charniak et al, 1998; <papid> W98-1115 </papid>roark, 2001) report that treebank binarization is advantageous.</citsent>
<aftsection>
<nextsent>3.1 general concepts.
</nextsent>
<nextsent>our approach to automaton induction is to view parsing as control problem.
</nextsent>
<nextsent>the parsing automaton is discrete dynamical system which we want to learn to control.
</nextsent>
<nextsent>at any given time, parser is in some state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB782">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> description of parsers.  </section>
<citcontext>
<prevsection>
<prevsent>our goal was not to directly compare the strategies, but simply to find theone that worked best in our system.
</prevsent>
<prevsent>direct comparison would be difficult, in particular because the choice of state representation has big influence on performance; and there is no obvious way of choosing the best state representation for particular parsing strategy.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the input sentences were pre-tagged using the maxpost tagger (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>all parsers here are un lexicalized, so they use pre terminals (part-of-speech tags) as their inputsymbols.
</nextsent>
<nextsent>each parser has an input (or looka head) buffer, organized as fifo queue.
</nextsent>
<nextsent>each parser also has stack.
</nextsent>
<nextsent>stack items are labeled with either pre terminal symbol or nonterminal (a syntactic category).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB783">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the different parsing strategies provide different opportunities for conditioning oncontext.
</prevsent>
<prevsent>this is very rich topic which unfortunately we cant explore further here.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
all experiments were done on the standard penn treebank wall st. journal task (marcus et al, 1993), <papid> J93-2004 </papid>for comparison with other work.</citsent>
<aftsection>
<nextsent>we used sections 2-21 for training, section 0 for development testing, and section 23 for final testing.
</nextsent>
<nextsent>all preliminary experiments used the development set for testing.
</nextsent>
<nextsent>we evaluated performance of each parser with several treebank transforms.
</nextsent>
<nextsent>results are in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB785">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the jvm version was 1.4.2, and the jvmwas warmed up before testing for speed.
</prevsent>
<prevsent>no additional effort was spent on speed optimization.clearly, these speeds are quite fast.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
a fast contemporary tagger, tnt (brants, 2000), <papid> A00-1031 </papid>which is implemented in c, tags between 30,000 and 60,000 words per second running on pentium 500 mhz cpu..</citsent>
<aftsection>
<nextsent>our lc parser is slightly slower than our sr and td parsers because lc inherently makes more decisions per sentence than the others do.
</nextsent>
<nextsent>speeds for the low-accuracy td runs are high due to the fact that the parser stops early when it encounters failure.
</nextsent>
<nextsent>comparing these speeds with other statistical parsers is somewhat problematic.
</nextsent>
<nextsent>differences in cpu speeds and implementation languages obscure the comparison.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB787">
<title id=" W04-3203.xml">induction of greedy controllers for deterministic treebank parsers </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>as noted, markov parsing model can be used to guide search.
</prevsent>
<prevsent>we plan to add beam search to explore the speed-accuracy tradeoff.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
improvements in the state representation are possible, particularly along the lines of linguistically-motivated treebank transformations, as in klein and manning (2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>adding lexical component to the model is another extension we intend to investigate.
</nextsent>
<nextsent>deterministic un lexicalized statistical parsers have surprisingly good accuracy and coverage, considering their speed and simplicity.
</nextsent>
<nextsent>thebest parsers reported here have almost complete coverage, outperform basic pcfgs, and are roughly as fast as taggers.
</nextsent>
<nextsent>we described an approach to statistical parsing based on induction of stochastic automata.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB788">
<title id=" W05-0402.xml">feature engineering and postprocessing for temporal expression recognition using conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one approach of integrating such list is using them to generate features, but the availability of such list also opens up other possibilities in feature design that we present in later sections.
</prevsent>
<prevsent>the second aspect concerns the tagging scheme.as in most ner experiments, the task of recognizing timexes is reduced to tagging.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
commonly used tagging schemes are inside-outside (io) and begincontinue-end-unique-negative (bceun) (borth wicket al, 1998).<papid> W98-1118 </papid></citsent>
<aftsection>
<nextsent>the io tagging scheme, which we use as baseline, assigns the tag to token if it is part of timex and otherwise.
</nextsent>
<nextsent>the richer bceunscheme assigns the five tags b, c, e, u, and to tokens depending on whether the token is single-token timex (u), non-timex (n), appears at the beginning (b), at the end (e) or inside timex boundary (c).
</nextsent>
<nextsent>inthis paper, we compare the io, bceun and an extended form of the bceun tagging scheme.
</nextsent>
<nextsent>the extended scheme adds two tags, pre and post, tothe bceun scheme, which correspond to tokens appearing to the left and to the right of timex.in contrast, our post-processing experiments investigate the application of the list of core timexesfor filtering the output of machine learner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB789">
<title id=" W05-0402.xml">feature engineering and postprocessing for temporal expression recognition using conditional random fields </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>, xn} is the observation sequence, = {y1, . . .
</prevsent>
<prevsent>, yt } is the label sequences, fk and are the feature functions and their weights respectively.an important property of these models is that probabilities are computed based on set of feature functions, i.e., fk (usually binary valued), which are defined on both the observation and label sequences . these feature functions describe different aspect of the data and may overlap, providing flexible way of describing the task.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
crfs have been shown to perform well in number of natural language processing applications, such as pos tagging (lafferty et al, 2001), shallow parsing or np chunking (sha and pereira, 2003), <papid> N03-1028 </papid>and named entity recognition (mccallum and li, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>in this paper, crfs are applied to the recognition of timexes; in our experiments we used the minor third implementation of crfs (cohen, 2004).
</nextsent>
<nextsent>the success of applying crfs depends on the quality of the set of features used and the tagging scheme chosen.
</nextsent>
<nextsent>below, we discuss these two aspects in greater detail.
</nextsent>
<nextsent>3.1 feature sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB790">
<title id=" W05-0402.xml">feature engineering and postprocessing for temporal expression recognition using conditional random fields </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>, xn} is the observation sequence, = {y1, . . .
</prevsent>
<prevsent>, yt } is the label sequences, fk and are the feature functions and their weights respectively.an important property of these models is that probabilities are computed based on set of feature functions, i.e., fk (usually binary valued), which are defined on both the observation and label sequences . these feature functions describe different aspect of the data and may overlap, providing flexible way of describing the task.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
crfs have been shown to perform well in number of natural language processing applications, such as pos tagging (lafferty et al, 2001), shallow parsing or np chunking (sha and pereira, 2003), <papid> N03-1028 </papid>and named entity recognition (mccallum and li, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>in this paper, crfs are applied to the recognition of timexes; in our experiments we used the minor third implementation of crfs (cohen, 2004).
</nextsent>
<nextsent>the success of applying crfs depends on the quality of the set of features used and the tagging scheme chosen.
</nextsent>
<nextsent>below, we discuss these two aspects in greater detail.
</nextsent>
<nextsent>3.1 feature sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB791">
<title id=" W05-0402.xml">feature engineering and postprocessing for temporal expression recognition using conditional random fields </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>these features constitute the basic feature set.
</prevsent>
<prevsent>another important feature is the list of core timexes.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the list is obtained by first extracting the phrases with -tmp function tags from the penn tree bank, and taking the words in these phrases (marcuset al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the resulting list is filtered for stopwords.
</nextsent>
<nextsent>among others, the list of core timexes consists of the names of days of the week and months, temporal units day,?
</nextsent>
<nextsent>month,?
</nextsent>
<nextsent>year,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB792">
<title id=" W05-0402.xml">feature engineering and postprocessing for temporal expression recognition using conditional random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the method is particularly sensitive to the criterion (the quality of the list in the current experiment) used for post-processing.
</prevsent>
<prevsent>a large number of publications deals with extraction of temporal expressions; the task is often treated as part of more involved task combining recognition and normalization of timexes.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
as result, many timex interpretation systems are mixture of both rule-based and machine learning approaches (mani and wilson, 2000).<papid> P00-1010 </papid></citsent>
<aftsection>
<nextsent>this is partly due to the fact that timex recognition is more amenable to data-drivenmethods whereas normalization is best handled using primarily rule-based methods.
</nextsent>
<nextsent>we focused on machine learning methods for the timex recognition task only.
</nextsent>
<nextsent>see (katz et al, 2005) for an overview of methods used for addressing the tern 2004 task.
</nextsent>
<nextsent>in many machine learning-based named-entity recognition tasks dictionaries are used for improving results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB793">
<title id=" W05-1201.xml">classification of semantic relations by humans and machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recognising semantic relations between sentences then becomes two-stepprocedure: first, the words and phrases in there spective sentences need to be aligned, after which the relations between the pairs of aligned words and phrases should be labeled in terms of semantic rela tions.various alignment algorithms have been developed for data-driven approaches to machine translation (e.g.
</prevsent>
<prevsent>(och and ney, 2000)).
</prevsent>
</prevsection>
<citsent citstr=" C96-1078 ">
initially work focused on word-based alignment, but more and more work is also addressing alignment at the higher levels (substrings, syntactic phrases or trees), e.g.,(meyers et al, 1996), <papid> C96-1078 </papid>gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>for our purposes, an additional advantage of aligning syntactic structures is that it keeps the alignment feasible (as the number of arbitrary sub strings that may be aligned grows exponentially to the number of words 1 in the sentence).
</nextsent>
<nextsent>here, following (herrera et al, 2005) and (barzilay, 2003), we will align sentences at the level of dependency structures.
</nextsent>
<nextsent>in addition, we will label the alignments in terms of five basic semantic relations to be defined below.
</nextsent>
<nextsent>we will perform this task both manually and automatically, so that we can address both of the issues raised above.section 2 describes monolingual parallel corpus consisting of two dutch translations, and formalizes the alignment-classification task to be performed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB795">
<title id=" W05-1201.xml">classification of semantic relations by humans and machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recognising semantic relations between sentences then becomes two-stepprocedure: first, the words and phrases in there spective sentences need to be aligned, after which the relations between the pairs of aligned words and phrases should be labeled in terms of semantic rela tions.various alignment algorithms have been developed for data-driven approaches to machine translation (e.g.
</prevsent>
<prevsent>(och and ney, 2000)).
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
initially work focused on word-based alignment, but more and more work is also addressing alignment at the higher levels (substrings, syntactic phrases or trees), e.g.,(meyers et al, 1996), <papid> C96-1078 </papid>gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>for our purposes, an additional advantage of aligning syntactic structures is that it keeps the alignment feasible (as the number of arbitrary sub strings that may be aligned grows exponentially to the number of words 1 in the sentence).
</nextsent>
<nextsent>here, following (herrera et al, 2005) and (barzilay, 2003), we will align sentences at the level of dependency structures.
</nextsent>
<nextsent>in addition, we will label the alignments in terms of five basic semantic relations to be defined below.
</nextsent>
<nextsent>we will perform this task both manually and automatically, so that we can address both of the issues raised above.section 2 describes monolingual parallel corpus consisting of two dutch translations, and formalizes the alignment-classification task to be performed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB797">
<title id=" W06-0508.xml">a hybrid approach for extracting semantic relations from texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>interesting work has been done on the unsupervised automatic detection of relations from small number of seed patterns.
</prevsent>
<prevsent>these are used as starting point to bootstrap the pattern learning process, by means of semantic similarity measures (yangarber, 2000; stevenson, 2004).
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
most of the approaches for relation extraction relyon the mapping of syntactic dependencies, such as svo, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (miller et al 2000), <papid> A00-2030 </papid>or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (gamallo et al, 2002).</citsent>
<aftsection>
<nextsent>in corpus-based approaches, many variations are found concerning the machine learning techniques used to produce classifiers to judge relation as relevant or non-relevant.
</nextsent>
<nextsent>(roth and yih, 2002), <papid> C02-1151 </papid>e.g., use probabilistic classifiers with constraints induced between relations and entities, such as selectional restrictions.</nextsent>
<nextsent>based on instances represented by pair of entities and their position in shallow parse tree, (zelenko et al, 2003) use support vector machines and voted perceptron algorithms with specialized kernel model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB798">
<title id=" W06-0508.xml">a hybrid approach for extracting semantic relations from texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of the approaches for relation extraction relyon the mapping of syntactic dependencies, such as svo, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (miller et al 2000), <papid> A00-2030 </papid>or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (gamallo et al, 2002).</prevsent>
<prevsent>in corpus-based approaches, many variations are found concerning the machine learning techniques used to produce classifiers to judge relation as relevant or non-relevant.</prevsent>
</prevsection>
<citsent citstr=" C02-1151 ">
(roth and yih, 2002), <papid> C02-1151 </papid>e.g., use probabilistic classifiers with constraints induced between relations and entities, such as selectional restrictions.</citsent>
<aftsection>
<nextsent>based on instances represented by pair of entities and their position in shallow parse tree, (zelenko et al, 2003) use support vector machines and voted perceptron algorithms with specialized kernel model.
</nextsent>
<nextsent>also using kernel methods and support vector machines, (zhao and grishman, 2005) <papid> P05-1052 </papid>combine clues from different levels of syntactic information and applies composite kernels to integrate the individual kernels.</nextsent>
<nextsent>similarly to our proposal, the framework presented by (iria and ciravegna, 2005) aims at the automation of semantic annotations according to ontologies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB799">
<title id=" W06-0508.xml">a hybrid approach for extracting semantic relations from texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(roth and yih, 2002), <papid> C02-1151 </papid>e.g., use probabilistic classifiers with constraints induced between relations and entities, such as selectional restrictions.</prevsent>
<prevsent>based on instances represented by pair of entities and their position in shallow parse tree, (zelenko et al, 2003) use support vector machines and voted perceptron algorithms with specialized kernel model.</prevsent>
</prevsection>
<citsent citstr=" P05-1052 ">
also using kernel methods and support vector machines, (zhao and grishman, 2005) <papid> P05-1052 </papid>combine clues from different levels of syntactic information and applies composite kernels to integrate the individual kernels.</citsent>
<aftsection>
<nextsent>similarly to our proposal, the framework presented by (iria and ciravegna, 2005) aims at the automation of semantic annotations according to ontologies.
</nextsent>
<nextsent>several supervised algorithms can be used on the training data represented through canonical graph-based data model.
</nextsent>
<nextsent>the framework includes shallow linguistic processing step, in which corpora are analyzed and representation is produced according to the data model, and classification step, where classifiers run on the datasets produced by the linguistic processing step.
</nextsent>
<nextsent>several relation extraction approaches have been proposed focusing on the task of ontology learning (reinberger and spyns, 2004; schutz and buitelaar, 2005; ciaramita et al, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB800">
<title id=" W06-0508.xml">a hybrid approach for extracting semantic relations from texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>given newsletter text, the first step of the relation extraction approach is to process the natural language text in order to identify linguistic triples, that is, sets of three elements with syntactic relationship, which can indicate potentially relevant semantic relations.
</prevsent>
<prevsent>in our architecture, 2 http://news.kmi.open.ac.uk/kmiplanet/ 3 http://kmi.open.ac.uk/projects/akt/ref-onto/ this is accomplished by the linguistic component module, and adaptation of the linguistic component designed in aqualog (lopez et al, 2005), question answering system.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
the linguistic component uses the infrastructure and the following resources from gate (cunningham et al, 2002): <papid> P02-1022 </papid>tokenizer, sentence splitter, part-of-speech tagger, morphological analyzer and vp chunker.</citsent>
<aftsection>
<nextsent>on the top of these resources, which produce syntactic annotations for the input text, the linguistic component uses grammar to identify linguistic triples.
</nextsent>
<nextsent>this grammar was implemented in jape (cunningham et al, 2000), which allows the definition of patterns to recognize regular expressions using the annotations provided by gate.
</nextsent>
<nextsent>the main type of construction aimed to be identified by our grammar involves verbal expression as indicative of potential relation and two noun phrases as terms linked by that relation.
</nextsent>
<nextsent>however, our patterns also account for other types of constructions, including, e.g., the use of comma to implicitly indicate relation, as in sentence (1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB801">
<title id=" W06-0508.xml">a hybrid approach for extracting semantic relations from texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>examples of linguistic triples for the newsletter in figure 2 jape patterns are based on shallow syntactic information only, and therefore they are not able to capture certain potentially relevant triples.
</prevsent>
<prevsent>to overcome this limitation, we employ parser as complementary resource to produce linguistic triples.
</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
we use minipar (lin, 1993), <papid> P93-1016 </papid>which produces functional relations for the components in sentence, including subject and object relations with respect to verb.</citsent>
<aftsection>
<nextsent>this allows capturing some implicit relations, such as indirect objects and long distance dependence relations.
</nextsent>
<nextsent>mini pars representation is converted into triple format and therefore the intermediate representation provided by both gate and minipar consists of triples of the type:  noun_phrase, verbal_expression, noun_phrase .
</nextsent>
<nextsent>given linguistic triple, the next step is to verify whether the verbal expression in that triple conveys relevant semantic relationship between entities (given by the terms) potentially belonging to an ontology.
</nextsent>
<nextsent>this is the most important phase of our approach and is represented by series of modules in our architecture in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB802">
<title id=" W06-0508.xml">a hybrid approach for extracting semantic relations from texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>string similarity metrics simply try to capture minor variations on the strings representing terms/relations, they do not account for the meaning of those strings.
</prevsent>
<prevsent>the ambiguity arising when more than one possible relation exists for pair of entities is problem neglected in most of the current work on relation extraction.
</prevsent>
</prevsection>
<citsent citstr=" P05-3014 ">
in our architecture, when the rss finds more than one possible relation, we choose one relation by using the word sense disambiguation (wsd) system sense learner (mi halcea and csomai, 2005).<papid> P05-3014 </papid></citsent>
<aftsection>
<nextsent>sense learner is supervised wsd system to disambiguate all open class words in any given text, after being trained on small dataset, according to global models for word categories.
</nextsent>
<nextsent>the current distribution includes two default models for verbs, which were trained on corpus containing 200,000 content words of journalistic texts tagged with their wordnet senses.
</nextsent>
<nextsent>since sense leaner requires sense tagged corpus in order to be trained to specific domains and there is not such corpus for our domain, we use one of the default training models.
</nextsent>
<nextsent>this is contextual model that relies on the first word before and after the verb, and its pos tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB803">
<title id=" W05-0401.xml">a novel machine learning approach for the identification of named entity relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the investigation for chinese information extraction is one of the topics of the project collate dedicated to building up the german competence center for language technology.
</prevsent>
<prevsent>after accomplishing the task concerning named entity (ne) identification, we go on studying identification issues for named entity relations (ners).
</prevsent>
</prevsection>
<citsent citstr=" W03-1708 ">
as an initial step, we define 14 different ners based on six identified nes in sports domain based chinese named entity recognition system (yao et al, 2003).<papid> W03-1708 </papid></citsent>
<aftsection>
<nextsent>in order to learn ners, we annotate the output texts from this system with xml.
</nextsent>
<nextsent>meanwhile, the ner annotation is performed by an interactive mode.
</nextsent>
<nextsent>the goal of the learning is to capture valuable information from ner and non-ner patterns, which is implicated in different features and helps us identify ners and non-ners.
</nextsent>
<nextsent>generally speaking, because not all features we pre define are important for each ner or non-ner, we should distinguish them by reasonable measure mode.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB804">
<title id=" W05-0401.xml">a novel machine learning approach for the identification of named entity relations </title>
<section> positive and negative case-based.  </section>
<citcontext>
<prevsection>
<prevsent>relation features, by which we can effectively identify different ners, are defined for capturing critical information of the chinese language.
</prevsent>
<prevsent>according to the features, we can define ner / non 2ner patterns.
</prevsent>
</prevsection>
<citsent citstr=" W96-0211 ">
the following essential factors motivate our definition for relation features: ? the relation features should be selected from multiple linguistic levels, i.e., morphology, grammar and semantics (cardie, 1996); ? <papid> W96-0211 </papid>they can help us to identify ners using positive and negative case-based machine learning as their information do not only deal with ners but also with non-ners; and ? they should embody the crucial information of chinese language processing (dang et al, 2002), <papid> C02-1143 </papid>such as word order, the context of words, and particles etc. there are total of 13 relation features shown in table 2, which are empirically defined according to the above motivations.</citsent>
<aftsection>
<nextsent>it should be explained that in order to distinguish feature names from element names of the ner / non-ner patterns, we add capital letter f? in the ending of feature names.
</nextsent>
<nextsent>in addition, sentence group in the following definitions can contain one or multiple sentences.
</nextsent>
<nextsent>in other words, sentence group must end with stop, semicolon, colon, exclamation mark, or question mark.
</nextsent>
<nextsent>feature category explanation sgtf the type of sentence group in which there exists relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB805">
<title id=" W05-0401.xml">a novel machine learning approach for the identification of named entity relations </title>
<section> positive and negative case-based.  </section>
<citcontext>
<prevsection>
<prevsent>relation features, by which we can effectively identify different ners, are defined for capturing critical information of the chinese language.
</prevsent>
<prevsent>according to the features, we can define ner / non 2ner patterns.
</prevsent>
</prevsection>
<citsent citstr=" C02-1143 ">
the following essential factors motivate our definition for relation features: ? the relation features should be selected from multiple linguistic levels, i.e., morphology, grammar and semantics (cardie, 1996); ? <papid> W96-0211 </papid>they can help us to identify ners using positive and negative case-based machine learning as their information do not only deal with ners but also with non-ners; and ? they should embody the crucial information of chinese language processing (dang et al, 2002), <papid> C02-1143 </papid>such as word order, the context of words, and particles etc. there are total of 13 relation features shown in table 2, which are empirically defined according to the above motivations.</citsent>
<aftsection>
<nextsent>it should be explained that in order to distinguish feature names from element names of the ner / non-ner patterns, we add capital letter f? in the ending of feature names.
</nextsent>
<nextsent>in addition, sentence group in the following definitions can contain one or multiple sentences.
</nextsent>
<nextsent>in other words, sentence group must end with stop, semicolon, colon, exclamation mark, or question mark.
</nextsent>
<nextsent>feature category explanation sgtf the type of sentence group in which there exists relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB806">
<title id=" W05-0401.xml">a novel machine learning approach for the identification of named entity relations </title>
<section> experimental results and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the total average measure is enhanced from 63.61% to 70.46% as whole.
</prevsent>
<prevsent>relation type average recall average precision average f-measure loc_cpc 100 91.67 95.65 tm_cp 100 87.50 93.33 ps_id 100 84.62 91.67 ps_tm 100 72.73 84.21 cp_loc 88.89 69.70 78.13 id_tm 90.91 66.67 76.93 cp_ti 83.33 71.43 76.92 ps_cp 60 75 66.67 tm_cpc 100 42.50 59.65 ht_vt 71.43 38.46 50 wt_lt 80 30.77 44.45 ps_cpc 33.33 66.67 44.44 cp_da 0 0 0 dt_dt 0 0 0 total ave. 71.99 56.98 63.61 table 3: identification performance for 14 ners only by positive case-based learning relation type average recall average precision average f-measure loc_cpc 100 91.67 95.65 tm_cp 100 87.50 93.33 cp_ti 100 75 85.71 ps_cpc 100 68.75 81.48 id_tm 90.91 68.19 77.93 ps_id 72.22 81.67 76.65 cp_loc 88.89 66.67 76.19 ps_tm 80 65 71.72 cp_da 100 50 66.67 dt_dt 66.67 66.67 66.67 ps_cp 60 75 66.67 wt_lt 60 37.50 46.15 ht_vt 42.86 30 35.30 tm_cpc 37.50 31.25 34.09 total ave. 78.50 63.92 70.46 table 4: identification performance for 14 ners by pncbl finally, we have to acknowledge that it is difficult to compare the performance of our method to others because the experimental conditions and corpus domains of other ner identification efforts are quite different from ours.
</prevsent>
</prevsection>
<citsent citstr=" W00-1210 ">
nevertheless, we would like to use the performance of chinese ner identification using memory-based learning (mbl) (zhang and zhou, 2000) <papid> W00-1210 </papid>for comparison with our approach in table 5.</citsent>
<aftsection>
<nextsent>in the table, we select similar ners in our domain to correspond to the three types of the relations (employee-of, product-of, and location-of).
</nextsent>
<nextsent>from the table we can deduce that the 7 identification performance of relations for pncbl is roughly comparable to that of the mbl.
</nextsent>
<nextsent>method relation type recall precision f-measure employee-of 75.60 92.30 83.12 product-of 56.20 87.10 68.32 mbl&i; location-of 67.20 75.60 71.15 ps_tm ps_cp ps_id 80 60 72.22 65 75 81.67 71.72 66.67 76.65 id_tm tm_cp 90.91 100 68.19 87.50 77.93 93.33 pncbl&i; cp_loc ps_cpc tm_cpc 88.89 100 37.50 66.67 68.75 31.25 76.19 81.48 34.09 table 5: performances for relation identification (pncbl&i; vs. mbl&i;)
</nextsent>
<nextsent>in this paper, we propose novel machine learning and identification approach pncbl&amp;i.; this approach exhibits the following advantages: (i) the defined negative cases are used to improve the ner identification performance as compared to only using positive cases; (ii) all of the tasks, building of ner and non-ner patterns, feature selection, feature weighting and identification threshold determination, are automatically completed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB807">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it can be used to perform morphological nor-.
</prevsent>
<prevsent>mal ization (i.e., stemming (porter, 1980)).
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
us classify unknown words, thereby enhancing the utility of cluster-based features for applications such as information extraction (miller et al., 2004; <papid> N04-1043 </papid>freitag, 2004).<papid> W04-3234 </papid></citsent>
<aftsection>
<nextsent>there is considerable literature on the problem of morphology induction in general, and unsupervised (or lightly supervised) induction in particular.
</nextsent>
<nextsent>much of the work attempts to exploit orthographic regularities alone, seeking affix ation patterns (or sig natures) that permit compressive representation of the corpus.
</nextsent>
<nextsent>several researchers propose algorithms based on the minimum description length (mdl)principle, achieving reasonable success in discovering regular morphological patterns (brent et al, 1995; goldsmith, 2000; creutz and lagus, 2002;<papid> W02-0603 </papid>argamon et al, 2004).<papid> C04-1152 </papid></nextsent>
<nextsent>mdl has information theoretic underpinnings, and an information theoretic objective function achieves similar success (snoveret al, 2002).<papid> W02-0602 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB808">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it can be used to perform morphological nor-.
</prevsent>
<prevsent>mal ization (i.e., stemming (porter, 1980)).
</prevsent>
</prevsection>
<citsent citstr=" W04-3234 ">
us classify unknown words, thereby enhancing the utility of cluster-based features for applications such as information extraction (miller et al., 2004; <papid> N04-1043 </papid>freitag, 2004).<papid> W04-3234 </papid></citsent>
<aftsection>
<nextsent>there is considerable literature on the problem of morphology induction in general, and unsupervised (or lightly supervised) induction in particular.
</nextsent>
<nextsent>much of the work attempts to exploit orthographic regularities alone, seeking affix ation patterns (or sig natures) that permit compressive representation of the corpus.
</nextsent>
<nextsent>several researchers propose algorithms based on the minimum description length (mdl)principle, achieving reasonable success in discovering regular morphological patterns (brent et al, 1995; goldsmith, 2000; creutz and lagus, 2002;<papid> W02-0603 </papid>argamon et al, 2004).<papid> C04-1152 </papid></nextsent>
<nextsent>mdl has information theoretic underpinnings, and an information theoretic objective function achieves similar success (snoveret al, 2002).<papid> W02-0602 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB809">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is considerable literature on the problem of morphology induction in general, and unsupervised (or lightly supervised) induction in particular.
</prevsent>
<prevsent>much of the work attempts to exploit orthographic regularities alone, seeking affix ation patterns (or sig natures) that permit compressive representation of the corpus.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
several researchers propose algorithms based on the minimum description length (mdl)principle, achieving reasonable success in discovering regular morphological patterns (brent et al, 1995; goldsmith, 2000; creutz and lagus, 2002;<papid> W02-0603 </papid>argamon et al, 2004).<papid> C04-1152 </papid></citsent>
<aftsection>
<nextsent>mdl has information theoretic underpinnings, and an information theoretic objective function achieves similar success (snoveret al, 2002).<papid> W02-0602 </papid></nextsent>
<nextsent>note that none of these approaches attempts to account for the syntactic dimension of af fixation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB810">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is considerable literature on the problem of morphology induction in general, and unsupervised (or lightly supervised) induction in particular.
</prevsent>
<prevsent>much of the work attempts to exploit orthographic regularities alone, seeking affix ation patterns (or sig natures) that permit compressive representation of the corpus.
</prevsent>
</prevsection>
<citsent citstr=" C04-1152 ">
several researchers propose algorithms based on the minimum description length (mdl)principle, achieving reasonable success in discovering regular morphological patterns (brent et al, 1995; goldsmith, 2000; creutz and lagus, 2002;<papid> W02-0603 </papid>argamon et al, 2004).<papid> C04-1152 </papid></citsent>
<aftsection>
<nextsent>mdl has information theoretic underpinnings, and an information theoretic objective function achieves similar success (snoveret al, 2002).<papid> W02-0602 </papid></nextsent>
<nextsent>note that none of these approaches attempts to account for the syntactic dimension of af fixation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB811">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much of the work attempts to exploit orthographic regularities alone, seeking affix ation patterns (or sig natures) that permit compressive representation of the corpus.
</prevsent>
<prevsent>several researchers propose algorithms based on the minimum description length (mdl)principle, achieving reasonable success in discovering regular morphological patterns (brent et al, 1995; goldsmith, 2000; creutz and lagus, 2002;<papid> W02-0603 </papid>argamon et al, 2004).<papid> C04-1152 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-0602 ">
mdl has information theoretic underpinnings, and an information theoretic objective function achieves similar success (snoveret al, 2002).<papid> W02-0602 </papid></citsent>
<aftsection>
<nextsent>note that none of these approaches attempts to account for the syntactic dimension of af fixation.
</nextsent>
<nextsent>and all must adopt strategies to cope with avery large search space (the power set of the vocab 128 ulary, in the limit).
</nextsent>
<nextsent>such strategies form common theme in these papers.our approach implicitly employs term cooccurrence statistics in the form of statistically derived term clusters.
</nextsent>
<nextsent>a number of researchers use such statistics directly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB812">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a common technique is to cast word as distribution over other words that occur within some limited window across the corpus.
</prevsent>
<prevsent>this definition of co-occurrence yields semantic distance measure which tends to draw together inflectional variants of word.
</prevsent>
</prevsection>
<citsent citstr=" W02-0606 ">
combined with heuristics such as string edit distance, it can be used to find reliable conflation sets (xu and croft,1998; baroni et al, 2002).<papid> W02-0606 </papid></citsent>
<aftsection>
<nextsent>a somewhat tighter definition of co-occurrence, which nevertheless yields semantic distance measure, serves as the basis ofa method that captures irregular inflectional transformations in yarowsky and wicentowski (2001).1 schone and jurafsky (2001) <papid> N01-1024 </papid>employ distributions over adjacent words (yielding syntactic distance metric) to improve the precision of their conflation sets.in contrast with these approaches, ours is predicated on strictly local notion of co-occurrence.</nextsent>
<nextsent>it is well known that clustering terms from corpus in english or related language, using distance measure based on local co-occurrence, yields clusters that correspond roughly to part of speech categories (schutze, 1995; clark, 2000).<papid> W00-0717 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB813">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this definition of co-occurrence yields semantic distance measure which tends to draw together inflectional variants of word.
</prevsent>
<prevsent>combined with heuristics such as string edit distance, it can be used to find reliable conflation sets (xu and croft,1998; baroni et al, 2002).<papid> W02-0606 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
a somewhat tighter definition of co-occurrence, which nevertheless yields semantic distance measure, serves as the basis ofa method that captures irregular inflectional transformations in yarowsky and wicentowski (2001).1 schone and jurafsky (2001) <papid> N01-1024 </papid>employ distributions over adjacent words (yielding syntactic distance metric) to improve the precision of their conflation sets.in contrast with these approaches, ours is predicated on strictly local notion of co-occurrence.</citsent>
<aftsection>
<nextsent>it is well known that clustering terms from corpus in english or related language, using distance measure based on local co-occurrence, yields clusters that correspond roughly to part of speech categories (schutze, 1995; clark, 2000).<papid> W00-0717 </papid></nextsent>
<nextsent>the heart of our idea is to search for affix transformation rules mapping terms in one cluster to those in another.the search for such rules has previously been conducted in the context of supervised part-of-speech tagging (mikheev, 1997), <papid> J97-3003 </papid>but not to our knowledge using word clusters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB815">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combined with heuristics such as string edit distance, it can be used to find reliable conflation sets (xu and croft,1998; baroni et al, 2002).<papid> W02-0606 </papid></prevsent>
<prevsent>a somewhat tighter definition of co-occurrence, which nevertheless yields semantic distance measure, serves as the basis ofa method that captures irregular inflectional transformations in yarowsky and wicentowski (2001).1 schone and jurafsky (2001) <papid> N01-1024 </papid>employ distributions over adjacent words (yielding syntactic distance metric) to improve the precision of their conflation sets.in contrast with these approaches, ours is predicated on strictly local notion of co-occurrence.</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
it is well known that clustering terms from corpus in english or related language, using distance measure based on local co-occurrence, yields clusters that correspond roughly to part of speech categories (schutze, 1995; clark, 2000).<papid> W00-0717 </papid></citsent>
<aftsection>
<nextsent>the heart of our idea is to search for affix transformation rules mapping terms in one cluster to those in another.the search for such rules has previously been conducted in the context of supervised part-of-speech tagging (mikheev, 1997), <papid> J97-3003 </papid>but not to our knowledge using word clusters.</nextsent>
<nextsent>basing the search for affix patterns on syntactic partition of the vocabulary, albeit noisy one, greatly reduces the size of the space of possible conflation sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB817">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a somewhat tighter definition of co-occurrence, which nevertheless yields semantic distance measure, serves as the basis ofa method that captures irregular inflectional transformations in yarowsky and wicentowski (2001).1 schone and jurafsky (2001) <papid> N01-1024 </papid>employ distributions over adjacent words (yielding syntactic distance metric) to improve the precision of their conflation sets.in contrast with these approaches, ours is predicated on strictly local notion of co-occurrence.</prevsent>
<prevsent>it is well known that clustering terms from corpus in english or related language, using distance measure based on local co-occurrence, yields clusters that correspond roughly to part of speech categories (schutze, 1995; clark, 2000).<papid> W00-0717 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
the heart of our idea is to search for affix transformation rules mapping terms in one cluster to those in another.the search for such rules has previously been conducted in the context of supervised part-of-speech tagging (mikheev, 1997), <papid> J97-3003 </papid>but not to our knowledge using word clusters.</citsent>
<aftsection>
<nextsent>basing the search for affix patterns on syntactic partition of the vocabulary, albeit noisy one, greatly reduces the size of the space of possible conflation sets.
</nextsent>
<nextsent>furthermore, the resulting rules can be assigned syntactic interpretation.
</nextsent>
<nextsent>a prerequisite of our method is clustering ofterms in the corpus vocabulary into rough syntactic groups.
</nextsent>
<nextsent>to achieve this, we first collect cooccurrence statistics for each word, measuring the1note that this method presupposes the availability of several resources in addition to corpus, including list of canonical inflectional suffixes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB818">
<title id=" W05-0617.xml">morphology induction from term clusters </title>
<section> clustering.  </section>
<citcontext>
<prevsection>
<prevsent>frequency of words found immediately adjacent toit in the corpus, treating left occurrences as distinct from right occurrences.
</prevsent>
<prevsent>this co-occurrencedatabase serves as input to information theoretic co clustering (dhillon et al, 2003), which seeks partition of the vocabulary that maximizes the mutual information between term categories and their contexts.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
this approach to term clustering is closely related to others from the literature (brown et al, 1992; <papid> J92-4003 </papid>clark, 2000).<papid> W00-0717 </papid>2recall that the mutual information between random variables   and</citsent>
<aftsection>
<nextsent>can be written:   ffflfi  ffi  (1) here,  and
</nextsent>
<nextsent>correspond to term and context clusters, respectively, each event  and  the observation of some term and contextual term in the corpus.
</nextsent>
<nextsent>we perform an approximate maximization of ! us ing simulated annealing procedure in which each random trial move takes word  or context  out of the cluster to which it is tentatively assigned and places it into another.
</nextsent>
<nextsent>we performed this procedure on the wall street journal (wsj) portion of the north american news corpus, forming 200 clusters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB825">
<title id=" W05-0820.xml">shared task statistical machine translation between european languages </title>
<section> goals.  </section>
<citcontext>
<prevsection>
<prevsent>we were satisfied to learn that many entries are by graduate students working on their own.
</prevsent>
<prevsent>promote and create free resources: academic research thrives on freely available resources.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the field of statistical machine translation has been blessed with long tradition of freely available software tools ? such as giza++ (och and ney, 2003) ? <papid> J03-1002 </papid>and parallel corpora ? such as the canadian hansards2.</citsent>
<aftsection>
<nextsent>following this lead, we made word alignments and language model available for this competition in addition to our previously published resources (europarl and pharaoh).
</nextsent>
<nextsent>the competition created resources as well.
</nextsent>
<nextsent>most teams agreed to share system output and their model files.
</nextsent>
<nextsent>you can download them from the competition web site3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB827">
<title id=" W05-0820.xml">shared task statistical machine translation between european languages </title>
<section> rules of engagement.  </section>
<citcontext>
<prevsection>
<prevsent>how well does this setup match the state of the art?
</prevsent>
<prevsent>the mit system using the pharaoh decoder (koehn, 2004a) proved to be very competitive in last years nist evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
however, the field is moving fast, and number of steps help to improve upon the provided baseline setup, e.g., larger language models trained on general text (up to billion words have been used), better reo dering models (e.g., suggested by tillman (2004) and och et al (2004)), <papid> N04-1021 </papid>better language-specific preprocessing (koehn and knight, 2003) <papid> E03-1076 </papid>and restructuring (collins et al, 2005), <papid> P05-1066 </papid>additional feature functions such as word class language models, and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to optimize parameters.some of these steps (e.g., improved reordering models) go beyond the current capabilities ofpharaoh.</citsent>
<aftsection>
<nextsent>however, we are hopeful that freely available software continues to match or at least follow closely the state of the art.
</nextsent>
<nextsent>we announced the shared task on march 3, and provided all the resources mentioned above (also adevelopment test corpus to track the quality of systems being developed).
</nextsent>
<nextsent>the test schedule called for the translation of 2000 sentence for each of the four language pairs in the week between april 310.
</nextsent>
<nextsent>we allowed late submissions up to april 17.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB828">
<title id=" W05-0820.xml">shared task statistical machine translation between european languages </title>
<section> rules of engagement.  </section>
<citcontext>
<prevsection>
<prevsent>how well does this setup match the state of the art?
</prevsent>
<prevsent>the mit system using the pharaoh decoder (koehn, 2004a) proved to be very competitive in last years nist evaluation.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
however, the field is moving fast, and number of steps help to improve upon the provided baseline setup, e.g., larger language models trained on general text (up to billion words have been used), better reo dering models (e.g., suggested by tillman (2004) and och et al (2004)), <papid> N04-1021 </papid>better language-specific preprocessing (koehn and knight, 2003) <papid> E03-1076 </papid>and restructuring (collins et al, 2005), <papid> P05-1066 </papid>additional feature functions such as word class language models, and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to optimize parameters.some of these steps (e.g., improved reordering models) go beyond the current capabilities ofpharaoh.</citsent>
<aftsection>
<nextsent>however, we are hopeful that freely available software continues to match or at least follow closely the state of the art.
</nextsent>
<nextsent>we announced the shared task on march 3, and provided all the resources mentioned above (also adevelopment test corpus to track the quality of systems being developed).
</nextsent>
<nextsent>the test schedule called for the translation of 2000 sentence for each of the four language pairs in the week between april 310.
</nextsent>
<nextsent>we allowed late submissions up to april 17.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB829">
<title id=" W05-0820.xml">shared task statistical machine translation between european languages </title>
<section> rules of engagement.  </section>
<citcontext>
<prevsection>
<prevsent>how well does this setup match the state of the art?
</prevsent>
<prevsent>the mit system using the pharaoh decoder (koehn, 2004a) proved to be very competitive in last years nist evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
however, the field is moving fast, and number of steps help to improve upon the provided baseline setup, e.g., larger language models trained on general text (up to billion words have been used), better reo dering models (e.g., suggested by tillman (2004) and och et al (2004)), <papid> N04-1021 </papid>better language-specific preprocessing (koehn and knight, 2003) <papid> E03-1076 </papid>and restructuring (collins et al, 2005), <papid> P05-1066 </papid>additional feature functions such as word class language models, and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to optimize parameters.some of these steps (e.g., improved reordering models) go beyond the current capabilities ofpharaoh.</citsent>
<aftsection>
<nextsent>however, we are hopeful that freely available software continues to match or at least follow closely the state of the art.
</nextsent>
<nextsent>we announced the shared task on march 3, and provided all the resources mentioned above (also adevelopment test corpus to track the quality of systems being developed).
</nextsent>
<nextsent>the test schedule called for the translation of 2000 sentence for each of the four language pairs in the week between april 310.
</nextsent>
<nextsent>we allowed late submissions up to april 17.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB830">
<title id=" W05-0820.xml">shared task statistical machine translation between european languages </title>
<section> rules of engagement.  </section>
<citcontext>
<prevsection>
<prevsent>how well does this setup match the state of the art?
</prevsent>
<prevsent>the mit system using the pharaoh decoder (koehn, 2004a) proved to be very competitive in last years nist evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
however, the field is moving fast, and number of steps help to improve upon the provided baseline setup, e.g., larger language models trained on general text (up to billion words have been used), better reo dering models (e.g., suggested by tillman (2004) and och et al (2004)), <papid> N04-1021 </papid>better language-specific preprocessing (koehn and knight, 2003) <papid> E03-1076 </papid>and restructuring (collins et al, 2005), <papid> P05-1066 </papid>additional feature functions such as word class language models, and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to optimize parameters.some of these steps (e.g., improved reordering models) go beyond the current capabilities ofpharaoh.</citsent>
<aftsection>
<nextsent>however, we are hopeful that freely available software continues to match or at least follow closely the state of the art.
</nextsent>
<nextsent>we announced the shared task on march 3, and provided all the resources mentioned above (also adevelopment test corpus to track the quality of systems being developed).
</nextsent>
<nextsent>the test schedule called for the translation of 2000 sentence for each of the four language pairs in the week between april 310.
</nextsent>
<nextsent>we allowed late submissions up to april 17.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB831">
<title id=" W05-0820.xml">shared task statistical machine translation between european languages </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>eleven teams from eight institutions in europe and north america participated, see figure 2 for complete list.
</prevsent>
<prevsent>the figure also indicates, if team usedthe pharaoh decoder (eight teams), the provided language model (seven teams) and the provided word alignment (four did, three of those with additional preprocessing or additional data).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
translation performance was measured using the bleu score (papineni et al, 2002), <papid> P02-1040 </papid>which measures n-gram overlap with reference translation.</citsent>
<aftsection>
<nextsent>in our case, we only used single reference translation, since the test set was taken from held-out portion of the europarl corpus.
</nextsent>
<nextsent>on the other hand we used arelatively large number of test sentences to guarantee that the bleu results are stable despite the fact that we used only one reference translation for each sentence.
</nextsent>
<nextsent>shared tasks like this one, of course, bring out the competitive spirit of participants and can draw criticisms about being horse race.
</nextsent>
<nextsent>from an outside perspective, however, it is far more interesting to learn which methods and ideas proved to be successful, than who won the competition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB832">
<title id=" W05-1628.xml">searching for grammaticality propagating dependencies in the viterbi algorithm </title>
<section> narrowing the search space: description.  </section>
<citcontext>
<prevsection>
<prevsent>however, n-grams alone often result in sentences that,whilst near-grammatical, are often just gibberish.
</prevsent>
<prevsent>when combined with (word) content selection model, we narrow the search space even further to those sentences that appear to make sense.
</prevsent>
</prevsection>
<citsent citstr=" W03-1202 ">
accordingly, approaches such as witbrock and mittal [1999] and wan et al [2003] <papid> W03-1202 </papid>have investigated models that improve the choice of words in the sentence.</citsent>
<aftsection>
<nextsent>witbrock and mittals content model chooses words that make good headlines, whilst that of wan et al attempts to ensure that, given short document like news article, only words from sentences of the same sub topic are combined to form new sentences.
</nextsent>
<nextsent>in this paper, we narrow the search space to those sequences that conserve dependency structures from within the input text.our algorithm extension essentially passes along the long distance context of dependency head information of the preceding word sequence, in order to influence the choice of thenext word appended to the sentence.
</nextsent>
<nextsent>this dependency structure is constructed statistically by an o(n) algorithm, which is folded into the viterbi algorithm.
</nextsent>
<nextsent>thus, the extension isin an o(n4) algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB833">
<title id=" W05-1628.xml">searching for grammaticality propagating dependencies in the viterbi algorithm </title>
<section> narrowing the search space: description.  </section>
<citcontext>
<prevsection>
<prevsent>competing paths through the search space are ranked taking into account the proposed dependency structures of the partially generated word sequences.
</prevsent>
<prevsent>sentences with probable dependency structures are ranked higher.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
to model the probability of dependency relation, we use the statistical dependency models inspired by those described in collins [1996].<papid> P96-1025 </papid></citsent>
<aftsection>
<nextsent>generation we assume that the reader is familiar with the viterbi algorithm.
</nextsent>
<nextsent>the interested reader is referred to manning and schutze [1999] for more complete description.
</nextsent>
<nextsent>here, we summarise our re-implementation (described in [wan et al,2003]) <papid> W03-1202 </papid>of the viterbi algorithm for summary sentence generation, as first introduced by witbrock and mittal [1999].</nextsent>
<nextsent>in this work, we begin with hidden markov model (hmm) where the nodes (ie, states) of the graph are uniquely labelled with words from relevant vocabulary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB835">
<title id=" W05-1628.xml">searching for grammaticality propagating dependencies in the viterbi algorithm </title>
<section> using the viterbi algorithm for sentence.  </section>
<citcontext>
<prevsection>
<prevsent>in this work, we begin with hidden markov model (hmm) where the nodes (ie, states) of the graph are uniquely labelled with words from relevant vocabulary.
</prevsent>
<prevsent>to obtain suitable subset of the vocabulary, words are taken from set of related sentences, such as those that might occur in news article (as is the case for the original work by witbrock andmittal).
</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
in this work, we use the clusters of event related sentences from the information fusion work by barzilay et al [1999].<papid> P99-1071 </papid></citsent>
<aftsection>
<nextsent>the edges between nodes in the hmm are typically weighted using bigram probabilities extracted from related corpus.
</nextsent>
<nextsent>the three probabilities of the unmodified viterbi algorithm are defined as follows:transition probability (using the maximum likelihood estimate to model bigram probabilities)1: ptrngram (wi+1|wi) = count(wi, wi+1) count(wi) emission probability: (for the purposes of testing the new transition probability function described in section 4, this is set to 1 in this paper): pem(w) = 1 path probability is defined recursively as: ppath(w0, . . .
</nextsent>
<nextsent>, wi+1) = ptrngram (wi+1|wi)?
</nextsent>
<nextsent>pem(w)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB836">
<title id=" W05-1628.xml">searching for grammaticality propagating dependencies in the viterbi algorithm </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in recent years, there has been steady stream of research in statistical text generation.
</prevsent>
<prevsent>we focus here on work which generates sentences from some sentential semantic representation via statistical method.
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
for examples of related statistical sentence generators see langkilde and knight [1998]<papid> W98-1426 </papid>and bangalore and rambow [2000].<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>these approaches begin with representation of sentence semantics that closely resembles that of dependency tree.
</nextsent>
<nextsent>this semantic representation is turned into word lattice.
</nextsent>
<nextsent>by ranking all traversalsof this lattice using an n-gram model, the best surface realisation of the semantic representation is chosen.
</nextsent>
<nextsent>the system then searches for the best path through this lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB837">
<title id=" W05-1628.xml">searching for grammaticality propagating dependencies in the viterbi algorithm </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in recent years, there has been steady stream of research in statistical text generation.
</prevsent>
<prevsent>we focus here on work which generates sentences from some sentential semantic representation via statistical method.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
for examples of related statistical sentence generators see langkilde and knight [1998]<papid> W98-1426 </papid>and bangalore and rambow [2000].<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>these approaches begin with representation of sentence semantics that closely resembles that of dependency tree.
</nextsent>
<nextsent>this semantic representation is turned into word lattice.
</nextsent>
<nextsent>by ranking all traversalsof this lattice using an n-gram model, the best surface realisation of the semantic representation is chosen.
</nextsent>
<nextsent>the system then searches for the best path through this lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB840">
<title id=" W06-1101.xml">linguistic distances </title>
<section> pronunciation.  </section>
<citcontext>
<prevsection>
<prevsent>there has been great deal of attention in psycho linguistics to the the problem of word recognition, and several models appeal explicitly to the degree of phonetic similarity among the words?
</prevsent>
<prevsent>(luce and pisoni, 1998, p. 1), butmost of these models employ relatively simple notions of sequence similarity and/or, e.g., the idea that distance may be ope rationalized by the number or replacements needed to derive one word from another ignoring the problem of similarity among words of different lengths (vitevitch andluce, 1999).
</prevsent>
</prevsection>
<citsent citstr=" E95-1009 ">
perhaps more sophisticated computational models of pronunciation distance could play role in these models in the future.kessler (1995) <papid> E95-1009 </papid>showed how to employ edit distance to ope rationalize pronunciation difference in order to investigate dialectology more precisely, an idea which, particular, heeringa (2004) pursue dat great length.</citsent>
<aftsection>
<nextsent>kondrak (2002) created variant of the dynamic programming algorithm usedto compute edit distance which he used to identify cognates in historical linguistics.
</nextsent>
<nextsent>mcmahon&amp; mcmahon (2005) include investigations of pronunciation similarity in their recent book on phylogenetic techniques in historical linguistics.
</nextsent>
<nextsent>several of the contributions to this volume build on these earlier efforts or are relevant to them.
</nextsent>
<nextsent>kondrak and sherif (this volume) continue the investigation into techniques for identifying cog nates, now comparing several techniques which rely solely on parameters set by the researcher to machine learning techniques which automatically optimize those parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB841">
<title id=" W06-1101.xml">linguistic distances </title>
<section> semantics.  </section>
<citcontext>
<prevsection>
<prevsent>of words.
</prevsent>
<prevsent>such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the british 3 linguist j.r. firth: you shall know word by the company it keeps.?
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
(firth, 1957, p. 11) context similarity has been used as means of extracting collocations from corpora, e.g. by church &hanks; (1990) <papid> J90-1003 </papid>and by dunning (1993), <papid> J93-1003 </papid>of identifying word senses, e.g. by yarowski (1995) and by schutze (1998), of clustering verb classes, e.g. by schulte im walde (2003), and of inducing selectional restrictions of verbs, e.g. by resnik (1993), by abe &amp; li (1996), by rooth et al (1999) <papid> P99-1014 </papid>and by wagner (2004).a third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses.</citsent>
<aftsection>
<nextsent>this type of approach has led totwo highly valued semantic resources: the princeton wordnet (fellbaum, 1998) and the berkeley framenet (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
<nextsent>while originally developed for english, both approaches have been successfully generalized to other languages.the three approaches to word meaning discussed above try to capture different aspects of the notion of semantic similarity, all of which are highly relevant for current and future research in computational linguistics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB842">
<title id=" W06-1101.xml">linguistic distances </title>
<section> semantics.  </section>
<citcontext>
<prevsection>
<prevsent>of words.
</prevsent>
<prevsent>such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the british 3 linguist j.r. firth: you shall know word by the company it keeps.?
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
(firth, 1957, p. 11) context similarity has been used as means of extracting collocations from corpora, e.g. by church &hanks; (1990) <papid> J90-1003 </papid>and by dunning (1993), <papid> J93-1003 </papid>of identifying word senses, e.g. by yarowski (1995) and by schutze (1998), of clustering verb classes, e.g. by schulte im walde (2003), and of inducing selectional restrictions of verbs, e.g. by resnik (1993), by abe &amp; li (1996), by rooth et al (1999) <papid> P99-1014 </papid>and by wagner (2004).a third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses.</citsent>
<aftsection>
<nextsent>this type of approach has led totwo highly valued semantic resources: the princeton wordnet (fellbaum, 1998) and the berkeley framenet (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
<nextsent>while originally developed for english, both approaches have been successfully generalized to other languages.the three approaches to word meaning discussed above try to capture different aspects of the notion of semantic similarity, all of which are highly relevant for current and future research in computational linguistics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB843">
<title id=" W06-1101.xml">linguistic distances </title>
<section> semantics.  </section>
<citcontext>
<prevsection>
<prevsent>of words.
</prevsent>
<prevsent>such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the british 3 linguist j.r. firth: you shall know word by the company it keeps.?
</prevsent>
</prevsection>
<citsent citstr=" P99-1014 ">
(firth, 1957, p. 11) context similarity has been used as means of extracting collocations from corpora, e.g. by church &hanks; (1990) <papid> J90-1003 </papid>and by dunning (1993), <papid> J93-1003 </papid>of identifying word senses, e.g. by yarowski (1995) and by schutze (1998), of clustering verb classes, e.g. by schulte im walde (2003), and of inducing selectional restrictions of verbs, e.g. by resnik (1993), by abe &amp; li (1996), by rooth et al (1999) <papid> P99-1014 </papid>and by wagner (2004).a third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses.</citsent>
<aftsection>
<nextsent>this type of approach has led totwo highly valued semantic resources: the princeton wordnet (fellbaum, 1998) and the berkeley framenet (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
<nextsent>while originally developed for english, both approaches have been successfully generalized to other languages.the three approaches to word meaning discussed above try to capture different aspects of the notion of semantic similarity, all of which are highly relevant for current and future research in computational linguistics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB844">
<title id=" W06-1101.xml">linguistic distances </title>
<section> semantics.  </section>
<citcontext>
<prevsection>
<prevsent>such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the british 3 linguist j.r. firth: you shall know word by the company it keeps.?
</prevsent>
<prevsent>(firth, 1957, p. 11) context similarity has been used as means of extracting collocations from corpora, e.g. by church &hanks; (1990) <papid> J90-1003 </papid>and by dunning (1993), <papid> J93-1003 </papid>of identifying word senses, e.g. by yarowski (1995) and by schutze (1998), of clustering verb classes, e.g. by schulte im walde (2003), and of inducing selectional restrictions of verbs, e.g. by resnik (1993), by abe &amp; li (1996), by rooth et al (1999) <papid> P99-1014 </papid>and by wagner (2004).a third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
this type of approach has led totwo highly valued semantic resources: the princeton wordnet (fellbaum, 1998) and the berkeley framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>while originally developed for english, both approaches have been successfully generalized to other languages.the three approaches to word meaning discussed above try to capture different aspects of the notion of semantic similarity, all of which are highly relevant for current and future research in computational linguistics.
</nextsent>
<nextsent>in fact, the five papers that discuss issues of semantic similarity in the present volume build on insights from these three frameworks or address open research questions posed by these frameworks.
</nextsent>
<nextsent>zesch and gurevych (this volume) discuss how measures of semantic similarity and more generally: semantic relatedness can be obtained by similarity judgments of informants who are presented with word pairs and who, for each pair, are asked torate the degree of semantic relatedness on predefined scale.
</nextsent>
<nextsent>such similarity judgments can provide important empirical evidence for taxonomic models of word meanings such as wordnets, which thus far rely mostly on expert knowledge of lexicographers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB845">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many other problems similar to text processing can also benefit from base np chunking, for example, finding genes in dna and phoneme information extraction.
</prevsent>
<prevsent>the initial work on base np chunking is focused on the grammar-based method.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
ramshaw and marcus (1995) <papid> W95-0107 </papid>introduced transformation based learning method which considered chunking as kind of tagging problem.</citsent>
<aftsection>
<nextsent>their work inspired many others to study the applications of learning methods to noun phrase chunking.
</nextsent>
<nextsent>(cardie and pierce, 1998, <papid> P98-1034 </papid>1999) applied scoring method to select new rules and naive heuristic for matching rules to evaluate the results  accu racy.</nextsent>
<nextsent>conll-2000 proposed shared task (tjong and buchholz, 2000), <papid> W00-0726 </papid>which aimed at dividing text in syntactically correlated parts of words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB847">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ramshaw and marcus (1995) <papid> W95-0107 </papid>introduced transformation based learning method which considered chunking as kind of tagging problem.</prevsent>
<prevsent>their work inspired many others to study the applications of learning methods to noun phrase chunking.</prevsent>
</prevsection>
<citsent citstr=" P98-1034 ">
(cardie and pierce, 1998, <papid> P98-1034 </papid>1999) applied scoring method to select new rules and naive heuristic for matching rules to evaluate the results  accu racy.</citsent>
<aftsection>
<nextsent>conll-2000 proposed shared task (tjong and buchholz, 2000), <papid> W00-0726 </papid>which aimed at dividing text in syntactically correlated parts of words.</nextsent>
<nextsent>the eleven systems for the conll-2000 shared task used wide variety of machine learning methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB848">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their work inspired many others to study the applications of learning methods to noun phrase chunking.
</prevsent>
<prevsent>(cardie and pierce, 1998, <papid> P98-1034 </papid>1999) applied scoring method to select new rules and naive heuristic for matching rules to evaluate the results  accu racy.</prevsent>
</prevsection>
<citsent citstr=" W00-0726 ">
conll-2000 proposed shared task (tjong and buchholz, 2000), <papid> W00-0726 </papid>which aimed at dividing text in syntactically correlated parts of words.</citsent>
<aftsection>
<nextsent>the eleven systems for the conll-2000 shared task used wide variety of machine learning methods.
</nextsent>
<nextsent>the best system in this workshop is on the basis of support vector machines used by (kudo and matsumoto, 2000).
</nextsent>
<nextsent>recently, some new statistical techniques, such as crf (lafferty et al 2001) and structural learning methods (ando and zhang, 2005) <papid> P05-1001 </papid>have been applied on the base np chunking.</nextsent>
<nextsent>(fei and fernando, 2003) considered chunking as sequence labeling task and achieved good performance by an improved training methods of crf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB849">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the eleven systems for the conll-2000 shared task used wide variety of machine learning methods.
</prevsent>
<prevsent>the best system in this workshop is on the basis of support vector machines used by (kudo and matsumoto, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
recently, some new statistical techniques, such as crf (lafferty et al 2001) and structural learning methods (ando and zhang, 2005) <papid> P05-1001 </papid>have been applied on the base np chunking.</citsent>
<aftsection>
<nextsent>(fei and fernando, 2003) considered chunking as sequence labeling task and achieved good performance by an improved training methods of crf.
</nextsent>
<nextsent>(ando and zhang, 2005) <papid> P05-1001 </papid>presented novel semi supervised learning method on chunking and produced performances higher than the previous best results.</nextsent>
<nextsent>the research on chinese base np chunking is, however, still at its developing stage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB853">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers apply similar methods of english base np chunking to chinese.
</prevsent>
<prevsent>zhao and huang (1998) made strict definition of chinese base np and put forward quasi-dependency model to analysis the structure of chinese base nps.
</prevsent>
</prevsection>
<citsent citstr=" W02-1818 ">
there are some other methods to deal with chinese phrase (no only base np) chunking, such as hmm (heng li et al, 2003), maximum entropy (zhou yaqian et al, 2003), memory-based learning (zhang and zhou, 2002) <papid> W02-1818 </papid>etc. 87 however, according to our experiments over 30,000 chinese words, the best results of chinese base np chunking are about 5% less than that of english chunking (although we should admit the chunking outcomes vary among different sizes of corpus and relyon the details of ex periments).</citsent>
<aftsection>
<nextsent>the differences between chinese nps and english nps are summarized as following points: first, the flexible structure of chinese noun phrase often results in the ambiguities during the recognition procedure.
</nextsent>
<nextsent>for example, many english base nps begin with the determinative, while the margin of chinese base nps is more uncertain.
</nextsent>
<nextsent>second, the base nps begins with more than two noun-modifiers, such as ??
</nextsent>
<nextsent>(high)/jj ?(new)/jj ??(technology)/nn?, the noun-modifiers ??/jj ? can not be completely recognized.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB856">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> task description.  </section>
<citcontext>
<prevsection>
<prevsent>by transforming the training data into the form with iob tags, we can view the base np chunking problem as multi-class classification problem.
</prevsent>
<prevsent>as svms are binary classifiers, we use the pairwise method to convert the multi-class problem into set of binary class problem, thus the i/o/b classifier is reduced into 3 kinds of binary classifier ? i/o classifier, o/b classifier, b/i classifier.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
in our experiments, we choose tinysvm 1 together with yamcha 2 (kudo and matsumoto, 2001) <papid> N01-1025 </papid>as the one of the baseline systems for our chunker.</citsent>
<aftsection>
<nextsent>in order to construct the feature sets for training svms, all information available in the surrounding contexts, including tokens, pos tags and iob tags.
</nextsent>
<nextsent>the tool yamcha makes it possible to add new features on your own.
</nextsent>
<nextsent>therefore, in the training stage, we also add two new features according to the words.
</nextsent>
<nextsent>first, we give special tags to the noun words, especially the proper noun, as we find in the experiment the proper nouns sometimes bring on errors, such as base 1 http://chasen.org/~taku/software/tinysvm/ 2 http://chasen.org/~taku/software/yamcha 88np ???(sichuan)/nr ??(basin)/nn?, containing the proper noun ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB857">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> task description.  </section>
<citcontext>
<prevsection>
<prevsent>more information analyses will be provided in section 4.
</prevsent>
<prevsent>an 2.3 conditional random fields.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
lafferty et al( 2001) present the conditional random fields for building probabilistic models to segment and label sequence data, which was used effectively for base np chunking (sha &amp; pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>lafferty et al (2001) point out that each of the random variable label sequences conditioned on the random observation sequence x. the joint distribution over the label sequence given has the form 1 1 1 ( | , ) exp( ( , )) ( ) ( , ) ( , , , ) j n i p x y z f x y x ? ?
</nextsent>
<nextsent>= = = ? where 1( , , ,j i )f y i?
</nextsent>
<nextsent>is either transition feature function ( 1, , ,i is y i?
</nextsent>
<nextsent>) or state feature function 1( , , , )i it y i?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB862">
<title id=" W06-0112.xml">a hybrid approach to chinese base noun phrase chunking </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>however, we find crf products some errors on identifying long-range base np, while svm performs well in this aspect and the errors of svm and crf are of different types.
</prevsent>
<prevsent>in this case, we develop combination approach to improve the results.
</prevsent>
</prevsection>
<citsent citstr=" C00-2124 ">
?(tjong et al, 2000) <papid> C00-2124 </papid>pointed out that the performance of machine learning can be improved by combining the output of different systems, so they combined the results of different classifiers 3 http://www.chasen.org/~taku/software/crf++/ 89and obtained good performance.</citsent>
<aftsection>
<nextsent>their combination system generated different classifiers by using different data labels and applied respective voting weights accordingly.
</nextsent>
<nextsent>(kudo and matsumoto 2001) <papid> N01-1025 </papid>designed voting arrangement by applying cross validation and vc-bound and leave-one-out bound for the voting weights.</nextsent>
<nextsent>the voting systems improve the accuracy, the choices of weights and the balance between different weights is based on experiences, which does not concern the inside features of the classification, without the guarantee of persuasive theoretical supports.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB864">
<title id=" W06-0606.xml">annotation compatibility working group report </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is likely that inconsistencies and errors (often induced by task-specific biases) can be identified and adjusted in the merging process; inferences may be drawn from how the component annotation systems interact; complex annotation in single framework may be easier for system to process than several annotations in different frameworks; and merged framework will help guide further annotation research (pustojevsky, et. al. 2005).
</prevsent>
<prevsent>another reason to merge is that merged resource in language may be similar to an existing resource in language b. thus merging resources may present opportunities for constructing nearly parallel resources, which in turn could prove useful for multilingual application.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
merging propbank (kingsbury, and palmer 2002) and nombank (meyers, et. al. 2004) <papid> W04-2705 </papid>would yield predicate argument structure for nouns and verbs, carrying more similar information to the praque dependency treebank tectogrammatical structure (hajicova and ceplova, 2000) than either component.</citsent>
<aftsection>
<nextsent>this report and an expanded online version http://nlp.cs.nyu.edu/wiki/corpuswg/annotation compatibility both describe how to find correspondences between annotation frameworks.
</nextsent>
<nextsent>this information can be used to combine various annotation resources in different ways, according to ones research goals, and, perhaps, could lead to some standards for combining annotation.
</nextsent>
<nextsent>this report will outline some of our initial findings in this effort with an eye towards maintaining and updating the online version in the future.
</nextsent>
<nextsent>we hope this is step towards making it easier for systems to use multiple annotation resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB865">
<title id=" W06-0606.xml">annotation compatibility working group report </title>
<section> part of speech and phrasal categories.  </section>
<citcontext>
<prevsection>
<prevsent>if another token give was tagged vb in brown, vb would be converted to verb.anysubc{infin,n3pres} (n3pres = not-3rd person and present tense).
</prevsent>
<prevsent>this allows systems to acquire the maximum information from corpora, tagged by different research groups.
</prevsent>
</prevsection>
<citsent citstr=" W04-1107 ">
ckip chinese-treebank (cctb) and penn chinese treebank (pctb) are two important resources for treebank-derived chinese nlp tasks (ckip, 1995; xia et al , 2000; xu et al , 2002; li et al , 2004).<papid> W04-1107 </papid></citsent>
<aftsection>
<nextsent>cctb is developed in traditional chinese (big5-encoded) at the academia sinica, taiwan (chen et al , 1999; chen et al , 2003).
</nextsent>
<nextsent>cctb uses the information based case grammar (icg) framework to express both syntactic and semantic descriptions.
</nextsent>
<nextsent>the present version cctb3 (version 3) provides 61,087 chinese sentences, 361,834 words and 6 files that are bracketed and post-edited by humans based on 5-million-word tagged sinica corpus (ckip, 1995).
</nextsent>
<nextsent>ckip pos tagging is hierarchical system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB866">
<title id=" W06-0606.xml">annotation compatibility working group report </title>
<section> differences between frameworks.  </section>
<citcontext>
<prevsection>
<prevsent>from markables.
</prevsent>
<prevsent>links can be used to annotate any form of semantic relations (indeed, the same notion was used in the timeml annotation of temporal relations).
</prevsent>
</prevsection>
<citsent citstr=" W05-0311 ">
a structured link, an innovation of mate, can represent ambiguity (poesio &amp; artstein, 2005).<papid> W05-0311 </papid></citsent>
<aftsection>
<nextsent>in (4), for example, the antecedent of the pronoun realized by mark able ne03 in utterance 3.3 could be either engine e2 or the boxcar at elmira; with the mate scheme, coders can mark their uncertainty.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>[in file markable.xml] 3.3: hook  coref:de id=ne01? engine e2 /coref:de  to  coref:de id=ne02?  the boxcar at ? elmira  /coref:de  5.1: and send  coref:de id=ne03?  it /coref:de  to  coref:de id=ne04?  corning /coref:de  [in separate file ? e.g., link.xml]  coref:link href=  markable.xml#id(ne03)  type=ident?   coref:anchor href= markable.xml#id(ne01)?
</nextsent>
<nextsent>/   coref:anchor href= markable.xml#id(ne02)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB867">
<title id=" W05-0103.xml">language and computers creating an introduction for a general undergraduate audience </title>
<section> course overview.  </section>
<citcontext>
<prevsection>
<prevsent>aids (spelling and grammar correc tion) ? machine translation (2 weeks) ? dialogue systems (2 weeks) ? computer-aided language learning ? social context of language technology use in contrast to the courses of which we are aware that offer computational linguistics to undergraduates, our language and computers is supposed to be accessible without prerequisites to students from every major (a requirement for gec courses).
</prevsent>
<prevsent>for example, we cannot assume any linguistic background or language awareness.
</prevsent>
</prevsection>
<citsent citstr=" W02-0105 ">
like lillian lees cornell course (lee, 2002), <papid> W02-0105 </papid>the course cannot presume programming ability.</citsent>
<aftsection>
<nextsent>but the gec regulations additionally prohibit us from requiring anything beyond high school level abilities in algebraic manipulation.
</nextsent>
<nextsent>we initially hoped that this meant that wewould be able to relyon the kind of math knowledge that we ourselves acquired in secondary school, but soon found that this was not realistic.
</nextsent>
<nextsent>the sample questions from lees course seem to us to be designed for students who actively enjoy math.
</nextsent>
<nextsent>our goal is different: we want to exercise and extend the math skills of the general student population, ensuring that the course is as accessible to the well-motivated dance major as it is to the geekier people with whom we are somewhat more familiar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB868">
<title id=" W04-3012.xml">context sensing using speech and common sense </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>these results are explained in terms of our experimental setup.
</prevsent>
<prevsent>high-level linguistic knowledge has been shown to have the potential of improving the state of the artin automatic speech recognition (asr).
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
such know ledge can be integrated in the asr component (gao, 2003; gao et al, 2003; stolcke et al, 2000; <papid> J00-3003 </papid>sarikaya et al, 2003; taylor et al, 2000).</citsent>
<aftsection>
<nextsent>alternatively, it may be included in the processing pipeline at alater stage, namely at the interface between the automatic speech recognizer and the spoken language understanding component (gurevych et al, 2003<papid> W03-0903 </papid>a; gurevych and porzel, 2003).</nextsent>
<nextsent>in any of these cases, it is necessary to provide systematic account of domain and world knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB869">
<title id=" W04-3012.xml">context sensing using speech and common sense </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>high-level linguistic knowledge has been shown to have the potential of improving the state of the artin automatic speech recognition (asr).
</prevsent>
<prevsent>such know ledge can be integrated in the asr component (gao, 2003; gao et al, 2003; stolcke et al, 2000; <papid> J00-3003 </papid>sarikaya et al, 2003; taylor et al, 2000).</prevsent>
</prevsection>
<citsent citstr=" W03-0903 ">
alternatively, it may be included in the processing pipeline at alater stage, namely at the interface between the automatic speech recognizer and the spoken language understanding component (gurevych et al, 2003<papid> W03-0903 </papid>a; gurevych and porzel, 2003).</citsent>
<aftsection>
<nextsent>in any of these cases, it is necessary to provide systematic account of domain and world knowledge.
</nextsent>
<nextsent>these types of knowledge have largely been ignored so far in asr research.
</nextsent>
<nextsent>the reason for this state of affairs lies in the fact that the manual construction of appropriate knowledge sources for broad domains is extremely costly.
</nextsent>
<nextsent>also, easy domain portability is an important requirement for any asr system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB873">
<title id=" W04-3012.xml">context sensing using speech and common sense </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the reason for this state of affairs lies in the fact that the manual construction of appropriate knowledge sources for broad domains is extremely costly.
</prevsent>
<prevsent>also, easy domain portability is an important requirement for any asr system.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the emergence of wide coverage linguistic knowledge bases for multiple languages, such as wordnet (fell baum, 1998), framenet (baker et al, 1998; <papid> P98-1013 </papid>baker et al., 2003), propbank (palmer et al, 2003; xue et al, 2004) is likely to change this situation.</citsent>
<aftsection>
<nextsent>domain recognition, which is the central topic ofthis paper, can be thought of as high-level semantic tagging of utterances.
</nextsent>
<nextsent>we expect significant improvements in the performance of the asr component of the system if information about the current domain of discourse is available.
</nextsent>
<nextsent>an obvious intuition behind this expectation is that knowing the current domain of discourse narrows down the search space of the speech recognizer.
</nextsent>
<nextsent>it also allows to rule out incoherent speech recognition hypotheses as well as those which do not fit in given domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB886">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, n-gram models are expensive to apply: in order to select the most likely realisation according to an n-gram model, all alternative realisations have to be generated and the probability of each realisation according to the model has to be calculated.
</prevsent>
<prevsent>this can get very expensive (even if packed representations of the set of alternatives are used), especially when the system accepts incompletely specified input, be cause the number of alternatives can be vast.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
in halogen, langkilde [2000] <papid> A00-2023 </papid>deals with trillions of alternatives, and the generator used in the experiments reported in this paper hasup to 1040 alternative realisations (see section 4.3 for empirical evidence of the relative inefficiency of n-gram genera tion).</citsent>
<aftsection>
<nextsent>furthermore, n-gram models have built-in bias towards shorter strings.
</nextsent>
<nextsent>this is because they calculate the likelihood of string of words as the joint probability of the words, or, more precisely, as the product of the probabilities of each word given the n?
</nextsent>
<nextsent>1 preceding words.
</nextsent>
<nextsent>the likelihood of any string will therefore generally be lower than that of any of its sub strings (see section 4.3 for empirical evidence of this bias).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB888">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>in fergus, bangalore et al used an xtag grammar to generate word lattice representation 1controlled generation of text (cogent) http://www.
</prevsent>
<prevsent>itri.brighton.ac.uk/projects/cogent.
</prevsent>
</prevsection>
<citsent citstr=" P00-1059 ">
of small number of alternative realisations, and 3-gram model to select the best [bangalore and rambow, 2000<papid> P00-1059 </papid>b].humphreys et al [2001] <papid> W01-0812 </papid>reused pcfg trained for nl parsing to build syntactic generation trees from candidate syntactic nodes.recently, habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint probability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings.</citsent>
<aftsection>
<nextsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.
</nextsent>
<nextsent>some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</nextsent>
<nextsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB892">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>in fergus, bangalore et al used an xtag grammar to generate word lattice representation 1controlled generation of text (cogent) http://www.
</prevsent>
<prevsent>itri.brighton.ac.uk/projects/cogent.
</prevsent>
</prevsection>
<citsent citstr=" W01-0812 ">
of small number of alternative realisations, and 3-gram model to select the best [bangalore and rambow, 2000<papid> P00-1059 </papid>b].humphreys et al [2001] <papid> W01-0812 </papid>reused pcfg trained for nl parsing to build syntactic generation trees from candidate syntactic nodes.recently, habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint probability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings.</citsent>
<aftsection>
<nextsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.
</nextsent>
<nextsent>some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</nextsent>
<nextsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB893">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>of small number of alternative realisations, and 3-gram model to select the best [bangalore and rambow, 2000<papid> P00-1059 </papid>b].humphreys et al [2001] <papid> W01-0812 </papid>reused pcfg trained for nl parsing to build syntactic generation trees from candidate syntactic nodes.recently, habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint probability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings.</prevsent>
<prevsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.</prevsent>
</prevsection>
<citsent citstr=" P99-1018 ">
some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</citsent>
<aftsection>
<nextsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></nextsent>
<nextsent>the likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summari sation construed as term selection and ordering [witbrock and mittal, 1999], grammar-free stochastic surface realisation [oh and rudnicky, 2000], <papid> W00-0306 </papid>and surface realisation construed as attribute selection and lexical choice [ratnaparkhi, 2000].<papid> A00-2026 </papid>some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB894">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>of small number of alternative realisations, and 3-gram model to select the best [bangalore and rambow, 2000<papid> P00-1059 </papid>b].humphreys et al [2001] <papid> W01-0812 </papid>reused pcfg trained for nl parsing to build syntactic generation trees from candidate syntactic nodes.recently, habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint probability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings.</prevsent>
<prevsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.</prevsent>
</prevsection>
<citsent citstr=" P00-1012 ">
some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</citsent>
<aftsection>
<nextsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></nextsent>
<nextsent>the likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summari sation construed as term selection and ordering [witbrock and mittal, 1999], grammar-free stochastic surface realisation [oh and rudnicky, 2000], <papid> W00-0306 </papid>and surface realisation construed as attribute selection and lexical choice [ratnaparkhi, 2000].<papid> A00-2026 </papid>some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB895">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>of small number of alternative realisations, and 3-gram model to select the best [bangalore and rambow, 2000<papid> P00-1059 </papid>b].humphreys et al [2001] <papid> W01-0812 </papid>reused pcfg trained for nl parsing to build syntactic generation trees from candidate syntactic nodes.recently, habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint probability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings.</prevsent>
<prevsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.</prevsent>
</prevsection>
<citsent citstr=" W00-0306 ">
some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</citsent>
<aftsection>
<nextsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></nextsent>
<nextsent>the likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summari sation construed as term selection and ordering [witbrock and mittal, 1999], grammar-free stochastic surface realisation [oh and rudnicky, 2000], <papid> W00-0306 </papid>and surface realisation construed as attribute selection and lexical choice [ratnaparkhi, 2000].<papid> A00-2026 </papid>some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB897">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>of small number of alternative realisations, and 3-gram model to select the best [bangalore and rambow, 2000<papid> P00-1059 </papid>b].humphreys et al [2001] <papid> W01-0812 </papid>reused pcfg trained for nl parsing to build syntactic generation trees from candidate syntactic nodes.recently, habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint probability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings.</prevsent>
<prevsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.</prevsent>
</prevsection>
<citsent citstr=" A00-2003 ">
some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</citsent>
<aftsection>
<nextsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></nextsent>
<nextsent>the likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summari sation construed as term selection and ordering [witbrock and mittal, 1999], grammar-free stochastic surface realisation [oh and rudnicky, 2000], <papid> W00-0306 </papid>and surface realisation construed as attribute selection and lexical choice [ratnaparkhi, 2000].<papid> A00-2026 </papid>some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB902">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>velldal et al [2004] compared the performance ofa 4-gram model trained on the bnc2 with maximum entropy model reused from parsing application and trained on the small, domain-specific logon corpus, finding that the domain-specific me model performs better on the logon corpus, but combined model performs best.
</prevsent>
<prevsent>some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</prevsent>
</prevsection>
<citsent citstr=" N01-1001 ">
in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></citsent>
<aftsection>
<nextsent>the likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summari sation construed as term selection and ordering [witbrock and mittal, 1999], grammar-free stochastic surface realisation [oh and rudnicky, 2000], <papid> W00-0306 </papid>and surface realisation construed as attribute selection and lexical choice [ratnaparkhi, 2000].<papid> A00-2026 </papid>some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.</nextsent>
<nextsent>some other research has focussed on machine learning methods, e.g. walker et al [2001] look at using boosting algorithm to train sentence plan ranker on corpus of labelled examples,and marciniak &amp; strube [2004] construe the entire generation process as sequence of classification problems, solved by corpus-trained feature-vector classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB905">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> generate-and-select nlg.  </section>
<citcontext>
<prevsection>
<prevsent>some statistical nlg research has looked at sub problems of language generation, such as ordering of np premodifiers [shaw and hatzivassiloglou, 1999; <papid> P99-1018 </papid>malouf, 2000], <papid> P00-1012 </papid>attribute selection in content planning [oh and rudnicky, 2000], <papid> W00-0306 </papid>np type determination [poesio et al, 1999], pronominal isation [strube and wolters, 2000], <papid> A00-2003 </papid>and lexical choice [bangalore and rambow, 2000<papid> P00-1059 </papid>a].</prevsent>
<prevsent>in hybrid symbolic-statistical approaches, white [2004] prunes edges in chart realisation using n-gram models, and varges uses quantitative methods for determining the weights on instance features in instance-based generation [varges and mellish, 2001].<papid> N01-1001 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
the likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summari sation construed as term selection and ordering [witbrock and mittal, 1999], grammar-free stochastic surface realisation [oh and rudnicky, 2000], <papid> W00-0306 </papid>and surface realisation construed as attribute selection and lexical choice [ratnaparkhi, 2000].<papid> A00-2026 </papid>some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.</citsent>
<aftsection>
<nextsent>some other research has focussed on machine learning methods, e.g. walker et al [2001] look at using boosting algorithm to train sentence plan ranker on corpus of labelled examples,and marciniak &amp; strube [2004] construe the entire generation process as sequence of classification problems, solved by corpus-trained feature-vector classifiers.
</nextsent>
<nextsent>generate-and-select nlg has been applied either to all of surface realisation, or to small sub problem in deep or surface realisation (not to the entire generation process); it is either very expensive or not guaranteed to find the optimal solution; and the models it has used are either shallow and unstructured, or require manual corpus annotation.
</nextsent>
<nextsent>treebank-training of generators is method for modelling likelihoods of realisations in generation.
</nextsent>
<nextsent>it is introduced in this section first in terms of the general idea behind it(which could be implemented with various formalisms, training methods and generation algorithms), and then in sec 2british national corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB907">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> evaluation on weather forecast generation.  </section>
<citcontext>
<prevsection>
<prevsent>a clear example is time expressions.
</prevsent>
<prevsent>a forecast can contain up to five different time expressions, which have to observe the correct chronological order.
</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
it is not appropriate to reward the mere presence (regardless of place in the string) of, say, by midnight (which is what some evaluation metrics are specifically designed to do, e.g. [bangalore et al, 2000]).<papid> W00-1401 </papid></citsent>
<aftsection>
<nextsent>se scoring has tendency to reward proximity to the intended place (although not in very straightforward way), and bleu is increasingly strict about place with increasing n. these score gives an intuitive, initial impression of how much the three methods have learned in comparison to the baseline: it is easy to conceptual ise how different one string is from another if you know there are two insert and delete operations between them (not so easy with the bleu scores).however, by far the more complete picture (and the most appropriate to this evaluation task) is given by bleu.
</nextsent>
<nextsent>it shows that the 2-gram generator does better than the other two, butnot by very large margin.
</nextsent>
<nextsent>the margin is important considering the far greater expense of n-gram generation.
</nextsent>
<nextsent>the following table shows the total amount of time it took to test the training and test sets with the different methods in one (controlled) run.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB908">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> discussion and further research.  </section>
<citcontext>
<prevsection>
<prevsent>tives can vary greatly in length, this preference is positively harmful (see following section for discussion of methods to counteract this bias).
</prevsent>
<prevsent>the n-gram models bias towards shorter strings is an example of general case: whenever the likelihood of larger unit that can vary in length (e.g. sentence) is modelled in terms of the joint probability of length-invariant smaller units, larger units that are composed of fewer smaller units are more likely.the possibility of counteracting this bias has been investigated.
</prevsent>
</prevsection>
<citsent citstr=" E91-1004 ">
in parsing, magerman &amp; marcus [1991] <papid> E91-1004 </papid>and briscoe &amp; carroll [1993] <papid> J93-1002 </papid>used the geometric mean of probabilities instead of the product of probabilities.</citsent>
<aftsection>
<nextsent>in later work, briscoe&amp; carroll [1992] use normalisation approach, the equivalent of which for n-gram selection would be to pad?
</nextsent>
<nextsent>shorter alternatives with extra dummy?
</nextsent>
<nextsent>words up to the length of the longest alternative, and to use the geometric mean ofthe probabilities assigned by the n-gram model to the non dummy words as the probability of any dummy word.
</nextsent>
<nextsent>ithas been observed that such methods turn principled probabilistic model into an ad hoc scoring function [manning and schuetze, 1999, p. 443].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB909">
<title id=" W05-1601.xml">statistical generation three methods compared and evaluated </title>
<section> discussion and further research.  </section>
<citcontext>
<prevsection>
<prevsent>tives can vary greatly in length, this preference is positively harmful (see following section for discussion of methods to counteract this bias).
</prevsent>
<prevsent>the n-gram models bias towards shorter strings is an example of general case: whenever the likelihood of larger unit that can vary in length (e.g. sentence) is modelled in terms of the joint probability of length-invariant smaller units, larger units that are composed of fewer smaller units are more likely.the possibility of counteracting this bias has been investigated.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
in parsing, magerman &amp; marcus [1991] <papid> E91-1004 </papid>and briscoe &amp; carroll [1993] <papid> J93-1002 </papid>used the geometric mean of probabilities instead of the product of probabilities.</citsent>
<aftsection>
<nextsent>in later work, briscoe&amp; carroll [1992] use normalisation approach, the equivalent of which for n-gram selection would be to pad?
</nextsent>
<nextsent>shorter alternatives with extra dummy?
</nextsent>
<nextsent>words up to the length of the longest alternative, and to use the geometric mean ofthe probabilities assigned by the n-gram model to the non dummy words as the probability of any dummy word.
</nextsent>
<nextsent>ithas been observed that such methods turn principled probabilistic model into an ad hoc scoring function [manning and schuetze, 1999, p. 443].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB910">
<title id=" W05-1519.xml">exploring features for identifying edited regions in dis fluent sentences </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we focus our attention on exploring feature spaces and selecting good features and start with analyzing the distributions of the edited regions and their components in the targeted corpus.
</prevsent>
<prevsent>we explore new feature spaces of part of-speech (pos) hierarchy and relaxed for rough copy in the experiments.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
these steps result in an improvement of 43.98% percent relative error reduction in f-score over an earlier best result in edited detection when punctuation is included in both training and testing data [charniak and johnson 2001], <papid> N01-1016 </papid>and 20.44% percent relative error reduction in f-score over the latest best result where punctuation is excluded from the training and testing data [johnson and charniak 2004].<papid> P04-1005 </papid></citsent>
<aftsection>
<nextsent>repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such dis fluent phenomena.
</nextsent>
<nextsent>processing speech repairs properly poses challenge to spoken dialog systems.
</nextsent>
<nextsent>early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [young and matessa 1991, bear et al  1992, <papid> P92-1008 </papid>heeman &amp; allen 1994].<papid> P94-1041 </papid></nextsent>
<nextsent>because of the availability of the switchboard corpus [godfrey et al  1992] and other conversational telephone speech (cts) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing dis fluent sentences [charniak and johnson 2001, <papid> N01-1016 </papid>johnson and charniak 2004, <papid> P04-1005 </papid>ostendorf et al  2004, liu et al  2005].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB915">
<title id=" W05-1519.xml">exploring features for identifying edited regions in dis fluent sentences </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we focus our attention on exploring feature spaces and selecting good features and start with analyzing the distributions of the edited regions and their components in the targeted corpus.
</prevsent>
<prevsent>we explore new feature spaces of part of-speech (pos) hierarchy and relaxed for rough copy in the experiments.
</prevsent>
</prevsection>
<citsent citstr=" P04-1005 ">
these steps result in an improvement of 43.98% percent relative error reduction in f-score over an earlier best result in edited detection when punctuation is included in both training and testing data [charniak and johnson 2001], <papid> N01-1016 </papid>and 20.44% percent relative error reduction in f-score over the latest best result where punctuation is excluded from the training and testing data [johnson and charniak 2004].<papid> P04-1005 </papid></citsent>
<aftsection>
<nextsent>repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such dis fluent phenomena.
</nextsent>
<nextsent>processing speech repairs properly poses challenge to spoken dialog systems.
</nextsent>
<nextsent>early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [young and matessa 1991, bear et al  1992, <papid> P92-1008 </papid>heeman &amp; allen 1994].<papid> P94-1041 </papid></nextsent>
<nextsent>because of the availability of the switchboard corpus [godfrey et al  1992] and other conversational telephone speech (cts) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing dis fluent sentences [charniak and johnson 2001, <papid> N01-1016 </papid>johnson and charniak 2004, <papid> P04-1005 </papid>ostendorf et al  2004, liu et al  2005].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB917">
<title id=" W05-1519.xml">exploring features for identifying edited regions in dis fluent sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such dis fluent phenomena.
</prevsent>
<prevsent>processing speech repairs properly poses challenge to spoken dialog systems.
</prevsent>
</prevsection>
<citsent citstr=" P92-1008 ">
early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [young and matessa 1991, bear et al  1992, <papid> P92-1008 </papid>heeman &amp; allen 1994].<papid> P94-1041 </papid></citsent>
<aftsection>
<nextsent>because of the availability of the switchboard corpus [godfrey et al  1992] and other conversational telephone speech (cts) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing dis fluent sentences [charniak and johnson 2001, <papid> N01-1016 </papid>johnson and charniak 2004, <papid> P04-1005 </papid>ostendorf et al  2004, liu et al  2005].</nextsent>
<nextsent>in this paper we describe our effort towards the task of edited region identification with the intention of parsing dis fluent sentences in the switchboard corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB918">
<title id=" W05-1519.xml">exploring features for identifying edited regions in dis fluent sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such dis fluent phenomena.
</prevsent>
<prevsent>processing speech repairs properly poses challenge to spoken dialog systems.
</prevsent>
</prevsection>
<citsent citstr=" P94-1041 ">
early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [young and matessa 1991, bear et al  1992, <papid> P92-1008 </papid>heeman &amp; allen 1994].<papid> P94-1041 </papid></citsent>
<aftsection>
<nextsent>because of the availability of the switchboard corpus [godfrey et al  1992] and other conversational telephone speech (cts) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing dis fluent sentences [charniak and johnson 2001, <papid> N01-1016 </papid>johnson and charniak 2004, <papid> P04-1005 </papid>ostendorf et al  2004, liu et al  2005].</nextsent>
<nextsent>in this paper we describe our effort towards the task of edited region identification with the intention of parsing dis fluent sentences in the switchboard corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB922">
<title id=" W05-1519.xml">exploring features for identifying edited regions in dis fluent sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because of the availability of the switchboard corpus [godfrey et al  1992] and other conversational telephone speech (cts) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing dis fluent sentences [charniak and johnson 2001, <papid> N01-1016 </papid>johnson and charniak 2004, <papid> P04-1005 </papid>ostendorf et al  2004, liu et al  2005].</prevsent>
<prevsent>in this paper we describe our effort towards the task of edited region identification with the intention of parsing dis fluent sentences in the switchboard corpus.</prevsent>
</prevsection>
<citsent citstr=" H05-1030 ">
a clear benefit of having accurate edited regions for parsing has been demonstrated by concurrent effort on parsing conversational speech [kahn et al 2005].<papid> H05-1030 </papid></citsent>
<aftsection>
<nextsent>since different machine learning methods provide similar performances on many nlp tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions.
</nextsent>
<nextsent>we start by analyzing the distributions of the edited regions and their components in the targeted corpus.
</nextsent>
<nextsent>we then design several feature spaces to cover the dis fluent regions in the training data.
</nextsent>
<nextsent>in addition, we also explore new feature spaces of part-of-speech hierarchy and extend candidate pools in the experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB930">
<title id=" W05-1519.xml">exploring features for identifying edited regions in dis fluent sentences </title>
<section> repair distributions in switchboard.  </section>
<citcontext>
<prevsection>
<prevsent>switchboard has over one million words, with telephone conversations on prescribed topics [godfrey et al  1992].
</prevsent>
<prevsent>it is full of dis fluent utterances, and [shriberg 1994, shriberg 1996] gives thorough analysis and categorization of them.
</prevsent>
</prevsection>
<citsent citstr=" W02-1007 ">
[engel et al  2002] <papid> W02-1007 </papid>also showed detailed distributions of the interregnum, including interjections and parentheticals.</citsent>
<aftsection>
<nextsent>since the majority of the disfluencies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions.
</nextsent>
<nextsent>for the reparandum and repair types, we include their distributions with and without punctuation.
</nextsent>
<nextsent>we include the distributions with punctuation is to match with the baseline system reported in [charniak and johnson 2001], <papid> N01-1016 </papid>where punctuation is included to identify the edited regions.</nextsent>
<nextsent>resent research showed that certain punctuation/prosody marks can be produced when speech signals are available [liu et al  2003].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB981">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents there sults of the parallel propbank ii project, which adds these richer layers of semantic annotation to the first 100k of the chinese treebank and its english translation.
</prevsent>
<prevsent>our preliminary analysis supports the hypothesis that this additional annotation reconciles many of the surface differences between the two languages.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
there is pressing need for consensus on task oriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>enabled the development of statistical syntactic parsers (collins, 1999; charniak, 2001).<papid> P01-1017 </papid></citsent>
<aftsection>
<nextsent>we believe that shallow semantics expressed as dependency structure, i.e., predicate-argumentstructure, for verbs, participial modifiers, and nom inalizations provides feasible level of annotation that would be of great benefit.
</nextsent>
<nextsent>this annotation, coupled with word senses, minimal co-reference links, this work is funded by the nsf via grant eia02-05448 .event identifiers, and discourse and temporal relations, could provide the foundation for major advance in our ability to automatically extract salient relationships from text.
</nextsent>
<nextsent>this will in turn facilitate breakthroughs in message understanding, machine translation, fact retrieval, and information retrieval.
</nextsent>
<nextsent>the proposition bank project is major step towards providing this type of annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB982">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents there sults of the parallel propbank ii project, which adds these richer layers of semantic annotation to the first 100k of the chinese treebank and its english translation.
</prevsent>
<prevsent>our preliminary analysis supports the hypothesis that this additional annotation reconciles many of the surface differences between the two languages.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
there is pressing need for consensus on task oriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>enabled the development of statistical syntactic parsers (collins, 1999; charniak, 2001).<papid> P01-1017 </papid></citsent>
<aftsection>
<nextsent>we believe that shallow semantics expressed as dependency structure, i.e., predicate-argumentstructure, for verbs, participial modifiers, and nom inalizations provides feasible level of annotation that would be of great benefit.
</nextsent>
<nextsent>this annotation, coupled with word senses, minimal co-reference links, this work is funded by the nsf via grant eia02-05448 .event identifiers, and discourse and temporal relations, could provide the foundation for major advance in our ability to automatically extract salient relationships from text.
</nextsent>
<nextsent>this will in turn facilitate breakthroughs in message understanding, machine translation, fact retrieval, and information retrieval.
</nextsent>
<nextsent>the proposition bank project is major step towards providing this type of annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB983">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this will in turn facilitate breakthroughs in message understanding, machine translation, fact retrieval, and information retrieval.
</prevsent>
<prevsent>the proposition bank project is major step towards providing this type of annotation.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
it takes practical approach to semantic representation, adding alayer of predicate argument information, or semantic roles, to the syntactic structures of the penn tree bank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>the frame files that provide guidance to the annotators constitute rich english lexicon with explicit ties between syntactic realizations and coarse-grained senses, framesets.
</nextsent>
<nextsent>propbank frame sets are distinguished primarily by syntactic criteria such as differences in subcategorization frames, and can be seen as the top level of an hierarchy of sense distinctions.
</nextsent>
<nextsent>groupings of fine-grained wordnet senses, such as those developed for senseval2 (palmer et al, to appear)provide an intermediate level, where groups are distinguished by either syntactic or semantic criteria.
</nextsent>
<nextsent>wordnet senses constitute the bottom level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB984">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>groupings of fine-grained wordnet senses, such as those developed for senseval2 (palmer et al, to appear)provide an intermediate level, where groups are distinguished by either syntactic or semantic criteria.
</prevsent>
<prevsent>wordnet senses constitute the bottom level.
</prevsent>
</prevsection>
<citsent citstr=" W04-2807 ">
the propbank frame set distinctions, which can be made consistently by humans and systems (over 90% accuracy for both), are surprisingly compatible with the groupings; 95% of the groups map directly onto single propbank frame set sense (palmer et al, 2004).<papid> W04-2807 </papid></citsent>
<aftsection>
<nextsent>the semantic annotation provided by propbank is only first approximation at capturing the full richness of semantic representation.
</nextsent>
<nextsent>additional annotation of nominalizations and other noun pred 61icates has already begun at nyu.
</nextsent>
<nextsent>this paper describes the results of propbank ii, project to provide richer semantic annotation to structures that have already been prop banked, specifically, eventuality id.s, coreference, coarse-grained sense tags, and discourse connectives.
</nextsent>
<nextsent>of special interest to the machine translation community is our finding, presented in this paper, that propbank ii annotation reconciles many of the surface differences of the two languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB987">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> propbank i.  </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the results of propbank ii, project to provide richer semantic annotation to structures that have already been prop banked, specifically, eventuality id.s, coreference, coarse-grained sense tags, and discourse connectives.
</prevsent>
<prevsent>of special interest to the machine translation community is our finding, presented in this paper, that propbank ii annotation reconciles many of the surface differences of the two languages.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
propbank (palmer et al, 2005) <papid> J05-1004 </papid>is an annotation of the wall street journal portion of the penn treebank ii (marcus et al, 1994) <papid> H94-1020 </papid>with predicate-argument?</citsent>
<aftsection>
<nextsent>structures, using sense tags for highly polysemous words and semantic role labels for each argument.an important goal is to provide consistent semantic role labels across different syntactic realizations of the same verb, as in the window in [arg0 john] broke [arg1 the window] and [arg1 the window] broke.
</nextsent>
<nextsent>propbank can provide frequency counts for (statistical) analysis or generation components in machine translation system, but provides only shallow semantic analysis in that the annotation is close to the syntactic structure and each verb is its own predicate.
</nextsent>
<nextsent>in propbank, semantic roles are defined on averb-by-verb basis.
</nextsent>
<nextsent>an individual verbs semantic arguments are simply numbered, beginning with 0.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB988">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> propbank i.  </section>
<citcontext>
<prevsection>
<prevsent>verbs can take any of set of general,adjunct-like arguments (argms), such as loc (lo cation), tmp (time), dis (discourse connectives), prp (purpose) or dir (direction).
</prevsent>
<prevsent>neg ations (neg) and modals (mod) are also marked.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
there are several other annotation projects, framenet (baker et al, 1998), <papid> P98-1013 </papid>salsa (ellsworth etal., 2004), and the prague tectogrammatics (haji cova and kucerova, 2002), that share similar goals.</citsent>
<aftsection>
<nextsent>berkeley.s framenet project, (baker et al, 1998; <papid> P98-1013 </papid>fillmore and atkins, 1998; johnson et al, 2002) is committed to producing rich semantic frames onwhich the annotation is based, but it is less concerned with annotating complete texts, concentrating instead on annotating set of examples for each predicator (including verbs, nouns and adjectives), and attempting to describe the network of relations among the semantic frames.</nextsent>
<nextsent>for instance, the buyer of buy event and the seller of sell event would both be arg0.s (agents) in propbank, while in framenet one is the buyer and the other is the seller.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB990">
<title id=" W05-0309.xml">a parallel proposition bank ii for chinese and english </title>
<section> propbank i.  </section>
<citcontext>
<prevsection>
<prevsent>the salsa project (ellsworth et al, 2004) in germany is producing german lexicon based on the framenet semantic frames and annotating alarge german newswire corpus.
</prevsent>
<prevsent>propbank style annotation is being used for verbs which do not yet have framenet frames defined.
</prevsent>
</prevsection>
<citsent citstr=" W03-1707 ">
the propbank annotation philosophy has been extended to the penn chinese proposition bank(xue and palmer, 2003).<papid> W03-1707 </papid></citsent>
<aftsection>
<nextsent>the chinese propbank annotation is performed on smaller (250k words) andyet growing corpus annotated with syntactic structures (xue et al, to appear).
</nextsent>
<nextsent>the same syntactic alternations that form the basis for the english propbank annotation also exist in robust quantities in chinese, even though it may not be the case that the same exact verbs (meaning verbs that are close translations of one another) have the exact same range of syntactic realization for chinese and english.
</nextsent>
<nextsent>for example, in (1), ?#c/new year???/ reception?
</nextsent>
<nextsent>plays the same role in (a) and (b), which is the event or activity held, even though it occurs indifferent syntactic positions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB994">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that corpora that are carefully annotated with respect to structural and linguistic characteristic sand that are distributed in standard formats are more widely used than corpora that are not.
</prevsent>
<prevsent>these findings have implications for the design of the next generation of biomedical corpora.
</prevsent>
</prevsection>
<citsent citstr=" W02-0312 ">
a small number of datasets for evaluating the performance of biomedical language processing (blp) systems on small number of task types have been made publicly available by their creators (blaschkeet al 19991, craven and kumlein 19992, pustejovsky et al 2002<papid> W02-0312 </papid>3, franzen et al 20024, collie ret al 1999<papid> E99-1043 </papid>5, tanabe et al 20056).</citsent>
<aftsection>
<nextsent>from biological perspective, number of these corpora (pdg,genia, meds tract, yapex, genetag) are exceptionally well curated.
</nextsent>
<nextsent>from the perspective of sys 1we refer to this corpus as the protein design group (pdg) corpus.
</nextsent>
<nextsent>2we refer to this as the university of wisconsin corpus.
</nextsent>
<nextsent>3the meds tract corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB995">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that corpora that are carefully annotated with respect to structural and linguistic characteristic sand that are distributed in standard formats are more widely used than corpora that are not.
</prevsent>
<prevsent>these findings have implications for the design of the next generation of biomedical corpora.
</prevsent>
</prevsection>
<citsent citstr=" E99-1043 ">
a small number of datasets for evaluating the performance of biomedical language processing (blp) systems on small number of task types have been made publicly available by their creators (blaschkeet al 19991, craven and kumlein 19992, pustejovsky et al 2002<papid> W02-0312 </papid>3, franzen et al 20024, collie ret al 1999<papid> E99-1043 </papid>5, tanabe et al 20056).</citsent>
<aftsection>
<nextsent>from biological perspective, number of these corpora (pdg,genia, meds tract, yapex, genetag) are exceptionally well curated.
</nextsent>
<nextsent>from the perspective of sys 1we refer to this corpus as the protein design group (pdg) corpus.
</nextsent>
<nextsent>2we refer to this as the university of wisconsin corpus.
</nextsent>
<nextsent>3the meds tract corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB996">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>we examine these corpora with respect to number of design features and other characteristics, and look for features that characterize widely usedand infrequently usedcorpora.our findings have implications for how the next generation of biomedical corpora should be constructed, and for how the existing corpora can be modified to make them more widely useful.
</prevsent>
<prevsent>table 1 lists the publicly available biomedical corpora of which we are aware.
</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
we omit discussion here of the corpus currently in production by the university of pennsylvania and the childrens hospital of philadelphia (kulick et al 2004), <papid> W04-3111 </papid>since it is not yet available in finished form.</citsent>
<aftsection>
<nextsent>we also omit text collections from our discussion.
</nextsent>
<nextsent>by text collection we mean textual datasets that may include meta data about documents, but do not contain mark-up of the document contents.
</nextsent>
<nextsent>so, the ohsumed text collec 38table 1: name, date, genre, and size for the six corpora.
</nextsent>
<nextsent>size is in words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB997">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>eight papers from coling 2004 (kimet al 2004) used it for evaluating entity identification tasks.
</prevsent>
<prevsent>yang et al (2002) adapted subset ofthe corpus for use in developing and testing coreference resolution system.
</prevsent>
</prevsection>
<citsent citstr=" W04-0508 ">
rinaldi et al (2004) <papid> W04-0508 </papid>used it to develop and test question-answering system.</citsent>
<aftsection>
<nextsent>locally, it has been used in teaching computational corpus linguistics for the past two years.
</nextsent>
<nextsent>we do not claim that it has not required extension for some of these task sour claim is that it is its annotation on these structural and linguistic levels, in combination with its format, that has made these extensions practical.
</nextsent>
<nextsent>4.1.1 formatting choices and formatting standardizationa basic desideratum for corpus is recoverabil ity: it should be possible to map from the annotation to the raw text.
</nextsent>
<nextsent>a related principle is that it should be easy for the corpus user to extract all annotation information from the corpus, e.g. for external storage and processing: in other words, the annotated corpus should allow the maximum flexibility forma nipulation by the user?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB998">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>  pos=nn?
</prevsent>
<prevsent>start=27 end=35
</prevsent>
</prevsection>
<citsent citstr=" N03-4009 ">
due to the availability of tools such as the university of pennsylvanias word freak (morton and lacivita 2003).<papid> N03-4009 </papid></citsent>
<aftsection>
<nextsent>crucially, this annotation should be based on character offsets, avoiding priori assumptions about tokenization.
</nextsent>
<nextsent>see smith et al (2005) <papid> W05-1305 </papid>for an approach to re factoring corpus to use character off sets.</nextsent>
<nextsent>4.1.2 guidelines the maxim of documentation suggests that annotation guidelines should be published.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB999">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>due to the availability of tools such as the university of pennsylvanias word freak (morton and lacivita 2003).<papid> N03-4009 </papid></prevsent>
<prevsent>crucially, this annotation should be based on character offsets, avoiding priori assumptions about tokenization.</prevsent>
</prevsection>
<citsent citstr=" W05-1305 ">
see smith et al (2005) <papid> W05-1305 </papid>for an approach to re factoring corpus to use character off sets.</citsent>
<aftsection>
<nextsent>4.1.2 guidelines the maxim of documentation suggests that annotation guidelines should be published.
</nextsent>
<nextsent>further, basic data on who did the annotations and on their level of agreement should be available.
</nextsent>
<nextsent>the currently available datasets mostly lack assessments ofinter-annotator agreement, utilize small or unspecified number of annotators, and do not provide published annotation guidelines.
</nextsent>
<nextsent>(we note the yang et al.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1000">
<title id=" W05-1306.xml">corpus design for biomedical natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a growing body of recent research makes 43 two points clear: full-text articles are different from abstracts, and full-text articles must be tapped if we are to build high-recall text data mining systems.corney et al (2004) looked directly at the effectiveness of information extraction from full-text articles versus abstracts.
</prevsent>
<prevsent>they found that recall fromfull-text articles was more than double that from abstracts.
</prevsent>
</prevsection>
<citsent citstr=" W02-0302 ">
analyzing the relative contributions of the abstracts and the full articles, they found that more than half of the interactions that they were able to extract were found in the full text and were absent in the abstract.tanabe and wilbur (2002) <papid> W02-0302 </papid>looked at the performance on full-text articles of an entity identification system that had originally been developed and tested using abstracts.</citsent>
<aftsection>
<nextsent>they found different false positive rates in the methods sections compared to other sections of full-text articles.
</nextsent>
<nextsent>this suggests that full-textarticles, unlike abstracts, will require parsing of document structure.
</nextsent>
<nextsent>they also noted range of problems related to the wider range of characters (includ ing, e.g., super scripts and greek letters) that occurs in full-text articles, as opposed to abstracts.
</nextsent>
<nextsent>schuemie et al (2004) examined set of 3902 full-text articles from nature genetics and biomed central, along with their abstracts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1002">
<title id=" W06-0125.xml">chinese word segmentation and named entity recognition based on a context dependent mutual information independence model </title>
<section> mutual information independence.  </section>
<citcontext>
<prevsection>
<prevsent>in this competition, the svm plus sigmoid classifier is used in chinese word segmentation while simple backoff approach as described in zhou et al  (2002) is used in named entity recognition.
</prevsent>
<prevsent>here, variant of the viterbi algorithm (viterbi 1967) in decoding the standard hidden markov model (hmm) (rabiner 1989) is implemented to find the most likely state sequence by replacing the state transition model and the output model of the standard hmm with the state transition model and the output model of the miim, respectively.
</prevsent>
</prevsection>
<citsent citstr=" C04-1004 ">
the above miim has been successfully applied in many applications, such as text chunking (zhou 2004), <papid> C04-1004 </papid>chinese word segmentation ( zhou 2005), english named entity recognition in the newswire domain (zhou et al  2002) and the biomedical domain (zhou et al  2004; zhou et al 2006).</citsent>
<aftsection>
<nextsent>for chinese word segmentation and named entity recognition by chunking, word or entity name is regarded as chunk of one or more word atoms and we have: ?  =  iii wpo , ; iw is the thi ? word atom in the sequence of word atoms nn wwww l211 = ; ip is the word formation pattern of the word atom iw . here ip measures the word formation power of the word atom iw and consists of: the percentage of iw occurring as whole word (round to 10%) the percentage of iw occurring at the beginning of other words (round to 10%) the percentage of iw occurring at the end of other words (round to 10%) the length of iw especially for named entity recognition, the percentages of word occurring in different entity types (round to 10%).
</nextsent>
<nextsent>is : the states are used to bracket and differentiate various types of words and optional entity types for named entity recognition.
</nextsent>
<nextsent>in this way, chinese word segmentation and named entity recognition can be regarded as bracketing and classification process.
</nextsent>
<nextsent>is is structural and consists of two parts: boundary category (b): it includes four values: {o, b, m, e}, where means that current word atom is whole word or entity name and b/m/e means that current word atom is at the beginning/in the middle/at the end of word or entity name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1003">
<title id=" W06-0503.xml">leila learning to extract information by linguistic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>different from previous approaches, our approach involves deep linguistic analysis, which helps it to achieve superior performance.
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" W97-1002 ">
there are numerous information extraction (ie) approaches, which differ in various features: ? arity of the target relation: some systems are designed to extract unary relations, i.e. sets of entities (finn and kushmerick, 2004; califf and mooney, 1997).<papid> W97-1002 </papid></citsent>
<aftsection>
<nextsent>in this paper we focus on the more general binary relations.
</nextsent>
<nextsent>type of the target relation: some systems are restricted to learning single relation, mostly the instanceof-relation (cimiano and volker, 2005b; buitelaar et al, 2004).
</nextsent>
<nextsent>in this paper, we are interested in extracting arbitrary relations (including instanceof).
</nextsent>
<nextsent>other systems are designed to discover new binary relations (maedche and staab, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1004">
<title id=" W06-0503.xml">leila learning to extract information by linguistic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>type of corpora: there exist systems that can extract information efficiently from formatted data, such as html-tables or structured text (graupmann, 2004; freitag and kushmerick, 2000).
</prevsent>
<prevsent>however, since large part of the web consists of natural language text, we consider inthis paper only systems that accept also unstructured corpora.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
initialization: as initial input, some systems require hand-tagged corpus (j. iria, 2005; soderland et al, 1995), other systems require text patterns (yangarber et al, 2000) <papid> C00-2136 </papid>or templates (xu and krieger, 2003) and again others require seed tuples (agichtein and gravano, 2000; ruiz-casado et al, 2005; mann and yarowsky, 2005) <papid> P05-1060 </papid>or tables of target concepts(cimiano and volker, 2005a).</citsent>
<aftsection>
<nextsent>since hand 18 labeled data and manual text patterns require huge human effort, we consider only systems that use seed pairs or tables of concepts.
</nextsent>
<nextsent>furthermore, there exist systems that use the whole web as corpus (etzioni et al, 2004) or that validate their output by the web (cimiano et al,2005).
</nextsent>
<nextsent>in order to study different extraction techniques in controlled environment, however, we restrict ourselves to systems that work on closed corpus for this paper.one school of extraction techniques concentrates on detecting the boundary of interesting entities in the text, (califf and mooney, 1997; <papid> W97-1002 </papid>finn and kushmerick, 2004; yangarber et al, 2002).<papid> C02-1154 </papid></nextsent>
<nextsent>this usually goes along with the restriction to unary target relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1005">
<title id=" W06-0503.xml">leila learning to extract information by linguistic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>type of corpora: there exist systems that can extract information efficiently from formatted data, such as html-tables or structured text (graupmann, 2004; freitag and kushmerick, 2000).
</prevsent>
<prevsent>however, since large part of the web consists of natural language text, we consider inthis paper only systems that accept also unstructured corpora.
</prevsent>
</prevsection>
<citsent citstr=" P05-1060 ">
initialization: as initial input, some systems require hand-tagged corpus (j. iria, 2005; soderland et al, 1995), other systems require text patterns (yangarber et al, 2000) <papid> C00-2136 </papid>or templates (xu and krieger, 2003) and again others require seed tuples (agichtein and gravano, 2000; ruiz-casado et al, 2005; mann and yarowsky, 2005) <papid> P05-1060 </papid>or tables of target concepts(cimiano and volker, 2005a).</citsent>
<aftsection>
<nextsent>since hand 18 labeled data and manual text patterns require huge human effort, we consider only systems that use seed pairs or tables of concepts.
</nextsent>
<nextsent>furthermore, there exist systems that use the whole web as corpus (etzioni et al, 2004) or that validate their output by the web (cimiano et al,2005).
</nextsent>
<nextsent>in order to study different extraction techniques in controlled environment, however, we restrict ourselves to systems that work on closed corpus for this paper.one school of extraction techniques concentrates on detecting the boundary of interesting entities in the text, (califf and mooney, 1997; <papid> W97-1002 </papid>finn and kushmerick, 2004; yangarber et al, 2002).<papid> C02-1154 </papid></nextsent>
<nextsent>this usually goes along with the restriction to unary target relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1007">
<title id=" W06-0503.xml">leila learning to extract information by linguistic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since hand 18 labeled data and manual text patterns require huge human effort, we consider only systems that use seed pairs or tables of concepts.
</prevsent>
<prevsent>furthermore, there exist systems that use the whole web as corpus (etzioni et al, 2004) or that validate their output by the web (cimiano et al,2005).
</prevsent>
</prevsection>
<citsent citstr=" C02-1154 ">
in order to study different extraction techniques in controlled environment, however, we restrict ourselves to systems that work on closed corpus for this paper.one school of extraction techniques concentrates on detecting the boundary of interesting entities in the text, (califf and mooney, 1997; <papid> W97-1002 </papid>finn and kushmerick, 2004; yangarber et al, 2002).<papid> C02-1154 </papid></citsent>
<aftsection>
<nextsent>this usually goes along with the restriction to unary target relations.
</nextsent>
<nextsent>other approaches make use of the context in which an entity appears(cimiano and volker, 2005a; buitelaar andra maka, 2005).
</nextsent>
<nextsent>this school is mostly restricted to the instanceof-relation.
</nextsent>
<nextsent>the only group that can learn arbitrary binary relations is the group of pattern matching systems (etzioni et al, 2004; agichtein and gravano, 2000; ravichandran and hovy, 2002; <papid> P02-1006 </papid>brin, 1999; soderland, 1999; xu et al., 2002; ruiz-casado et al, 2005; mann and yarowsky, 2005).<papid> P05-1060 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1008">
<title id=" W06-0503.xml">leila learning to extract information by linguistic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other approaches make use of the context in which an entity appears(cimiano and volker, 2005a; buitelaar andra maka, 2005).
</prevsent>
<prevsent>this school is mostly restricted to the instanceof-relation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
the only group that can learn arbitrary binary relations is the group of pattern matching systems (etzioni et al, 2004; agichtein and gravano, 2000; ravichandran and hovy, 2002; <papid> P02-1006 </papid>brin, 1999; soderland, 1999; xu et al., 2002; ruiz-casado et al, 2005; mann and yarowsky, 2005).<papid> P05-1060 </papid></citsent>
<aftsection>
<nextsent>surprisingly, none of these systems uses deep linguistic analysis of the corpus.
</nextsent>
<nextsent>consequently, most of them are extremely volatile to small variations in the patterns.
</nextsent>
<nextsent>for example, the simple subordinate clause in the following example (taken from (ravichandran andhovy, 2002)) <papid> P02-1006 </papid>can already prevent surface pattern matcher from discovering relation between london?</nextsent>
<nextsent>and the river thames?: london, which has one of the busiest airports in the world, lies on the banks of the river thames.?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1011">
<title id=" W06-0503.xml">leila learning to extract information by linguistic analysis </title>
<section> in the testing phase, the algorithm considers.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, high proportion of the incorrect assignments were friend,member, successor and predecessor, decreasing the precision of leila.
</prevsent>
<prevsent>thus, compared to the gold standard of humans, the performance of leila can be considered reasonably good.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the patterns found include the hearst patterns (hearst,1992) <papid> C92-2082 </papid>such as x?, but also more complex patterns like was known as y ?, [.</citsent>
<aftsection>
<nextsent>] as ?, [.
</nextsent>
<nextsent>] can be regarded as ? and is unusual among ?.
</nextsent>
<nextsent>some of these patterns could not have been found by primitive regular expression matching.to test whether thematic heterogeneity influences leila, we ran it on the wikigeneral corpus.
</nextsent>
<nextsent>finally, to try the limits of our system, we ran it on the google composers corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1012">
<title id=" W05-0627.xml">semantic role labeling system using maximum entropy classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this research was supported by national natural science foundation of china via grant 60435020last year, conll-2004 hold semantic role labeling shared task (carreras and ma`rquez, 2004) to test the participant systems?
</prevsent>
<prevsent>performance based on shallow syntactic parser results.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in 2005, srl shared task is continued (carreras and ma`rquez, 2005), because it is complex task and now it is far from desired performance.in our srl system, we select maximum entropy (berger et al, 1996) <papid> J96-1002 </papid>as classifier to implement the semantic role labeling system.</citsent>
<aftsection>
<nextsent>different from the best classifier reported in literatures (pradhan et al, 2005) ? support vector machines (svms) (vapnik, 1995), it is much easier for maximum entropy classifier to handle the multi-class classification problem without additional post-processing steps.
</nextsent>
<nextsent>the classifier is much faster than training svms classifiers.
</nextsent>
<nextsent>in addition, maximum entropy classifier can be tuned to minimize over-fitting by adjusting gaussian prior.
</nextsent>
<nextsent>xue and palmer (2004), <papid> W04-3212 </papid>xue and palmer (2005) and kwon et al (2004) <papid> C04-1179 </papid>have applied the maximum entropy classifier to semantic role labeling task successfully.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1013">
<title id=" W05-0627.xml">semantic role labeling system using maximum entropy classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the classifier is much faster than training svms classifiers.
</prevsent>
<prevsent>in addition, maximum entropy classifier can be tuned to minimize over-fitting by adjusting gaussian prior.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
xue and palmer (2004), <papid> W04-3212 </papid>xue and palmer (2005) and kwon et al (2004) <papid> C04-1179 </papid>have applied the maximum entropy classifier to semantic role labeling task successfully.</citsent>
<aftsection>
<nextsent>in the following sections, we will describe our system and report our results on development and test sets.
</nextsent>
<nextsent>2.1 constituent-by-constituent.
</nextsent>
<nextsent>we use syntactic constituent as the unit of labeling.
</nextsent>
<nextsent>however, it is impossible for each argument to findits matching constituent in all auto parsing trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1014">
<title id=" W05-0627.xml">semantic role labeling system using maximum entropy classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the classifier is much faster than training svms classifiers.
</prevsent>
<prevsent>in addition, maximum entropy classifier can be tuned to minimize over-fitting by adjusting gaussian prior.
</prevsent>
</prevsection>
<citsent citstr=" C04-1179 ">
xue and palmer (2004), <papid> W04-3212 </papid>xue and palmer (2005) and kwon et al (2004) <papid> C04-1179 </papid>have applied the maximum entropy classifier to semantic role labeling task successfully.</citsent>
<aftsection>
<nextsent>in the following sections, we will describe our system and report our results on development and test sets.
</nextsent>
<nextsent>2.1 constituent-by-constituent.
</nextsent>
<nextsent>we use syntactic constituent as the unit of labeling.
</nextsent>
<nextsent>however, it is impossible for each argument to findits matching constituent in all auto parsing trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1015">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments on the muc-4 test set show that these new ie patterns improved recall with only small precision loss.
</prevsent>
<prevsent>information extraction (ie) is the task of identifying event descriptions in natural language text and extracting information related to those events.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
many ie systems use extraction patterns or rules to identify the relevant information (soderland et al., 1995; riloff, 1996; califf and mooney, 1999; soderland, 1999; yangarber et al, 2000).<papid> C00-2136 </papid></citsent>
<aftsection>
<nextsent>most of these systems use annotated training data to learn pattern matching rules based on lexical, syntactic, and/or semantic information.
</nextsent>
<nextsent>the learned patterns are then used to locate relevant information in new texts.
</nextsent>
<nextsent>ie systems typically focus on information about events that are relevant to specific domain, such as terrorism (sundheim, 1992; <papid> M92-1001 </papid>soderland et al,1995; riloff, 1996; chieu et al, 2003), <papid> P03-1028 </papid>management succession (sundheim, 1995; <papid> M95-1002 </papid>yangarber et al, 2000), <papid> C00-2136 </papid>or job announcements (califf and mooney, 1999; freitag and mccallum, 2000).</nextsent>
<nextsent>supervised learning systems for ie depend on domain-specific training data, which consists of texts associated with the domain that have been manually annotated with event information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1016">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these systems use annotated training data to learn pattern matching rules based on lexical, syntactic, and/or semantic information.
</prevsent>
<prevsent>the learned patterns are then used to locate relevant information in new texts.
</prevsent>
</prevsection>
<citsent citstr=" M92-1001 ">
ie systems typically focus on information about events that are relevant to specific domain, such as terrorism (sundheim, 1992; <papid> M92-1001 </papid>soderland et al,1995; riloff, 1996; chieu et al, 2003), <papid> P03-1028 </papid>management succession (sundheim, 1995; <papid> M95-1002 </papid>yangarber et al, 2000), <papid> C00-2136 </papid>or job announcements (califf and mooney, 1999; freitag and mccallum, 2000).</citsent>
<aftsection>
<nextsent>supervised learning systems for ie depend on domain-specific training data, which consists of texts associated with the domain that have been manually annotated with event information.
</nextsent>
<nextsent>the need for domain-specific training data has several disadvantages.
</nextsent>
<nextsent>because of the manual labor involved in annotating corpus, and because new corpus must be annotated for each domain, most annotated ie corpora are relatively small.
</nextsent>
<nextsent>language is so expressive that it is practically impossible for the patterns learned from relatively small training set to cover all the different ways of describing events.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1017">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these systems use annotated training data to learn pattern matching rules based on lexical, syntactic, and/or semantic information.
</prevsent>
<prevsent>the learned patterns are then used to locate relevant information in new texts.
</prevsent>
</prevsection>
<citsent citstr=" P03-1028 ">
ie systems typically focus on information about events that are relevant to specific domain, such as terrorism (sundheim, 1992; <papid> M92-1001 </papid>soderland et al,1995; riloff, 1996; chieu et al, 2003), <papid> P03-1028 </papid>management succession (sundheim, 1995; <papid> M95-1002 </papid>yangarber et al, 2000), <papid> C00-2136 </papid>or job announcements (califf and mooney, 1999; freitag and mccallum, 2000).</citsent>
<aftsection>
<nextsent>supervised learning systems for ie depend on domain-specific training data, which consists of texts associated with the domain that have been manually annotated with event information.
</nextsent>
<nextsent>the need for domain-specific training data has several disadvantages.
</nextsent>
<nextsent>because of the manual labor involved in annotating corpus, and because new corpus must be annotated for each domain, most annotated ie corpora are relatively small.
</nextsent>
<nextsent>language is so expressive that it is practically impossible for the patterns learned from relatively small training set to cover all the different ways of describing events.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1018">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of these systems use annotated training data to learn pattern matching rules based on lexical, syntactic, and/or semantic information.
</prevsent>
<prevsent>the learned patterns are then used to locate relevant information in new texts.
</prevsent>
</prevsection>
<citsent citstr=" M95-1002 ">
ie systems typically focus on information about events that are relevant to specific domain, such as terrorism (sundheim, 1992; <papid> M92-1001 </papid>soderland et al,1995; riloff, 1996; chieu et al, 2003), <papid> P03-1028 </papid>management succession (sundheim, 1995; <papid> M95-1002 </papid>yangarber et al, 2000), <papid> C00-2136 </papid>or job announcements (califf and mooney, 1999; freitag and mccallum, 2000).</citsent>
<aftsection>
<nextsent>supervised learning systems for ie depend on domain-specific training data, which consists of texts associated with the domain that have been manually annotated with event information.
</nextsent>
<nextsent>the need for domain-specific training data has several disadvantages.
</nextsent>
<nextsent>because of the manual labor involved in annotating corpus, and because new corpus must be annotated for each domain, most annotated ie corpora are relatively small.
</nextsent>
<nextsent>language is so expressive that it is practically impossible for the patterns learned from relatively small training set to cover all the different ways of describing events.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1020">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>language is so expressive that it is practically impossible for the patterns learned from relatively small training set to cover all the different ways of describing events.
</prevsent>
<prevsent>consequently, the ie patterns learned from manually annotated training sets typically represent only subset of the ie patterns that could be useful for the task.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
many recent approaches in natural language processing (yarowsky, 1995; <papid> P95-1026 </papid>collins and singer, 1999; <papid> W99-0613 </papid>riloff and jones, 1999; nigam et al, 2000; wiebe and riloff, 2005) have recognized the need to use unannotated data to improve performance.</citsent>
<aftsection>
<nextsent>while the web provides vast repository of unannotated texts, it is non-trivial to identify texts that belong to particular domain.
</nextsent>
<nextsent>the difficulty is that web pages are not specifically annotated with tags categorizing their content.
</nextsent>
<nextsent>nevertheless, in this paper we look to the web as vast dynamic resource for domain-specific ie learning.
</nextsent>
<nextsent>our approach exploits an existing set of ie patterns that were learned from annotated training data to automatically identify new, domain-specific texts from 66the web.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1021">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>language is so expressive that it is practically impossible for the patterns learned from relatively small training set to cover all the different ways of describing events.
</prevsent>
<prevsent>consequently, the ie patterns learned from manually annotated training sets typically represent only subset of the ie patterns that could be useful for the task.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
many recent approaches in natural language processing (yarowsky, 1995; <papid> P95-1026 </papid>collins and singer, 1999; <papid> W99-0613 </papid>riloff and jones, 1999; nigam et al, 2000; wiebe and riloff, 2005) have recognized the need to use unannotated data to improve performance.</citsent>
<aftsection>
<nextsent>while the web provides vast repository of unannotated texts, it is non-trivial to identify texts that belong to particular domain.
</nextsent>
<nextsent>the difficulty is that web pages are not specifically annotated with tags categorizing their content.
</nextsent>
<nextsent>nevertheless, in this paper we look to the web as vast dynamic resource for domain-specific ie learning.
</nextsent>
<nextsent>our approach exploits an existing set of ie patterns that were learned from annotated training data to automatically identify new, domain-specific texts from 66the web.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1027">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>in this research, our goal is to automatically learn ie patterns from large, domain-independent text collection, such as the web.
</prevsent>
<prevsent>the billions of freely available documents on the world wide web and its ever-growing size make the web potential source of data for many corpus-based natural language processing tasks.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
indeed, many researchers have recently tapped the web as data-source for improving performance on nlp tasks (e.g., resnik (1999), <papid> P99-1068 </papid>ravichandran and hovy (2002),<papid> P02-1006 </papid>keller and lapata (2003)).<papid> J03-3005 </papid></citsent>
<aftsection>
<nextsent>despite these successes, numerous problems exist with collecting data from the web, such as web pages containing information that is not free text, including advertisements, embedded scripts, tables, captions, etc. also, the documents cover many genres, and it is not easy to identify documents of particular genre or domain.
</nextsent>
<nextsent>additionally, most of the documents are in html, and some amount of processing is required to extract the free text.
</nextsent>
<nextsent>in the following subsections we describe the process of collecting corpus of terrorism-related cnn news articles from the web.
</nextsent>
<nextsent>4.1 collecting domain-specific texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1029">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>in this research, our goal is to automatically learn ie patterns from large, domain-independent text collection, such as the web.
</prevsent>
<prevsent>the billions of freely available documents on the world wide web and its ever-growing size make the web potential source of data for many corpus-based natural language processing tasks.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
indeed, many researchers have recently tapped the web as data-source for improving performance on nlp tasks (e.g., resnik (1999), <papid> P99-1068 </papid>ravichandran and hovy (2002),<papid> P02-1006 </papid>keller and lapata (2003)).<papid> J03-3005 </papid></citsent>
<aftsection>
<nextsent>despite these successes, numerous problems exist with collecting data from the web, such as web pages containing information that is not free text, including advertisements, embedded scripts, tables, captions, etc. also, the documents cover many genres, and it is not easy to identify documents of particular genre or domain.
</nextsent>
<nextsent>additionally, most of the documents are in html, and some amount of processing is required to extract the free text.
</nextsent>
<nextsent>in the following subsections we describe the process of collecting corpus of terrorism-related cnn news articles from the web.
</nextsent>
<nextsent>4.1 collecting domain-specific texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1030">
<title id=" W06-0208.xml">learning domain specific information extraction patterns from the web </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>in this research, our goal is to automatically learn ie patterns from large, domain-independent text collection, such as the web.
</prevsent>
<prevsent>the billions of freely available documents on the world wide web and its ever-growing size make the web potential source of data for many corpus-based natural language processing tasks.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
indeed, many researchers have recently tapped the web as data-source for improving performance on nlp tasks (e.g., resnik (1999), <papid> P99-1068 </papid>ravichandran and hovy (2002),<papid> P02-1006 </papid>keller and lapata (2003)).<papid> J03-3005 </papid></citsent>
<aftsection>
<nextsent>despite these successes, numerous problems exist with collecting data from the web, such as web pages containing information that is not free text, including advertisements, embedded scripts, tables, captions, etc. also, the documents cover many genres, and it is not easy to identify documents of particular genre or domain.
</nextsent>
<nextsent>additionally, most of the documents are in html, and some amount of processing is required to extract the free text.
</nextsent>
<nextsent>in the following subsections we describe the process of collecting corpus of terrorism-related cnn news articles from the web.
</nextsent>
<nextsent>4.1 collecting domain-specific texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1041">
<title id=" W04-3202.xml">active learning and the total cost of annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, experiments using al assume model that is fixed ahead of time: the model used in al is the same one we are currently developing training material for.
</prevsent>
<prevsent>for many complex tasks, we are unlikely to have clear idea how best to model the task at the time of annotation; thus, in practice, we will need to reuse the labeled training material with other models.in this paper, we show that alcan be brittle: under variety of natural reuse scenarios (for example, allowing the later model to improve in quality, orelse reusing the labeled training material using different machine learning algorithm) performance of later models can be significantly undermined when training upon material created using al. the key to knowing how well one model will be able to use material selected by another is their relatedness ? yet there may be no means to determine this prior to annotation, leading to chicken-and-egg problem.our re usability results thus demonstrate that, additionally, other strategies must be adopted to ensure we reduce the total cost of annotation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1012 ">
in osborne and baldridge (2004), <papid> N04-1012 </papid>we showed that ensemble models can increase model performance and also produce annotation savings when incorporated into the al process.</citsent>
<aftsection>
<nextsent>an obvious next step is automating some decisions.
</nextsent>
<nextsent>here, we consider simple automation strategy that reduces annotation costs independently of aland examine its effect on reusability.
</nextsent>
<nextsent>we find that using both semi-automation and alwith high-quality models can eliminate the performance gap found in many reuse scenarios.
</nextsent>
<nextsent>however, for weak models, we show that semi-automationwith random sampling is more effective for improving re usability than using it with al ? demonstrating further cause for caution with al.finally, we show that under the standard assumption of reuse by the selecting model, using strategy which combines al, ensembling, and semi automated annotation, we are able to achieve our highest annotation savings to date on the complex task of parse selection for hpsg: an 80% reduction in annotation cost compared with labeling randomly selected data with our best single model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1042">
<title id=" W04-3202.xml">active learning and the total cost of annotation </title>
<section> parse selection for redwoods.  </section>
<citcontext>
<prevsection>
<prevsent>we find that using both semi-automation and alwith high-quality models can eliminate the performance gap found in many reuse scenarios.
</prevsent>
<prevsent>however, for weak models, we show that semi-automationwith random sampling is more effective for improving re usability than using it with al ? demonstrating further cause for caution with al.finally, we show that under the standard assumption of reuse by the selecting model, using strategy which combines al, ensembling, and semi automated annotation, we are able to achieve our highest annotation savings to date on the complex task of parse selection for hpsg: an 80% reduction in annotation cost compared with labeling randomly selected data with our best single model.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
we now briefly describe the redwoods treebankingenvironment (oepen et al, 2002), <papid> C02-2025 </papid>our parse selection models and their performance.</citsent>
<aftsection>
<nextsent>2.1 the redwoods treebank.
</nextsent>
<nextsent>the redwoods treebank project provides tools and annotated training material for creating parse selection models for the english resource grammar (erg, flickinger (2000)).
</nextsent>
<nextsent>the erg is hand-builtbroad-coverage hpsg grammar that provides an explicit grammar for the treebank.
</nextsent>
<nextsent>using this approach has the advantage that analyses for within-coverage sentences convey more information than just phrasestructure: they also contain derivations, semantic interpretations, and basic dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1043">
<title id=" W04-3202.xml">active learning and the total cost of annotation </title>
<section> parse selection for redwoods.  </section>
<citcontext>
<prevsection>
<prevsent>these sentences have 9.3 words and 58.0 parses on average.
</prevsent>
<prevsent>2.2 modeling parse selection.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
as is now standard for feature-based grammars, we mainly use log-linear models for parse selection (johnson et al, 1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>for log-linear models, the conditional probability of an analysis ti given sentence with set of analyses ? = {t . . .}
</nextsent>
<nextsent>is given as: (ti|s,mk) = exp( j=1 fj(ti)wj) z(s) (1) where fj(ti) returns the number of times feature occurs in analysis t, wj is weight from modelmk, and z(s) is normalization factor for the sentence.
</nextsent>
<nextsent>the parse with the highest probability is taken as the preferred parse for the model.
</nextsent>
<nextsent>we use the limited memory variable metric algorithm to determine the weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1050">
<title id=" W04-3202.xml">active learning and the total cost of annotation </title>
<section> active learning.  </section>
<citcontext>
<prevsection>
<prevsent>in practice, selecting data points for labeling such that models variance and/or bias is maximally minimized is computationally intractable, so approximations are typically used instead.
</prevsent>
<prevsent>one such approximation is uncertainty sampling.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
uncertainty sampling (also called tree entropy by hwa (2000)), <papid> W00-1306 </papid>measures the uncertainty of model over the set of parses of given sentence, based on the conditional 1this eyeball step is not always taken, but redwoods does not contain information about when this occurred, so we apply the cost for the step uniformly for all examples.</citsent>
<aftsection>
<nextsent>distribution it assigns to them.
</nextsent>
<nextsent>following hwa, we use the following measure to quantify uncertainty: fus(s, ?,mk) = ? ?
</nextsent>
<nextsent>t??
</nextsent>
<nextsent>p (t|s,mk) logp (t|s,mk) (5) ? denotes the set of analyses produced by the ergfor the sentence and mk is some model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1055">
<title id=" W04-3202.xml">active learning and the total cost of annotation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this is still true even if we do not allow ourselves to reuse those discriminants which were used to select the best parse from the n-best subset and the best parse was not actually present in that subset.
</prevsent>
<prevsent>there is large body of al work in the machine learning literature, but less so within natural language processing (nlp).
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
most work in nlp has primarily focused upon uncertainty sampling (hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002).<papid> P02-1016 </papid></citsent>
<aftsection>
<nextsent>hwa (2001) <papid> W01-0710 </papid>considered reuse of examples selected for one parser by an other with uncertainty sampling.</nextsent>
<nextsent>this performed better than sequential sampling but was only half as effective as self-selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1056">
<title id=" W04-3202.xml">active learning and the total cost of annotation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is large body of al work in the machine learning literature, but less so within natural language processing (nlp).
</prevsent>
<prevsent>most work in nlp has primarily focused upon uncertainty sampling (hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002).<papid> P02-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" W01-0710 ">
hwa (2001) <papid> W01-0710 </papid>considered reuse of examples selected for one parser by an other with uncertainty sampling.</citsent>
<aftsection>
<nextsent>this performed better than sequential sampling but was only half as effective as self-selection.
</nextsent>
<nextsent>here, we have considered reuse with respect to many models and theirco-relatedness.
</nextsent>
<nextsent>also, we compare reuse performance against against random sampling, which we showed previously to be much stronger baseline than sequential sampling for the redwoods corpus (osborne and baldridge, 2004).<papid> N04-1012 </papid></nextsent>
<nextsent>hwa et al (2003) showed that for parsers, al outperforms the closely related co-training, and that some of the labeling could be automated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1058">
<title id=" W05-0829.xml">competitive grouping in integrated phrase segmentation and alignment model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isa extracts phrase pairs from abi lingual corpus without requiring the pre calculated word alignment as many other phrase alignment models do.
</prevsent>
<prevsent>experiments conducted within the wpt-05 shared taskon statistical machine translation demonstrate the simplicity and effectiveness of this approach.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
in recent years, various phrase translation approaches (marcu and wong, 2002; <papid> W02-1018 </papid>och et al, 1999;<papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been shown to outperform word-to-word translation models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>many of these phrase alignment strategies relyon the pre-calculated word alignment and use different heuristics to extract the phrase pairs from the viterbi word alignment path.
</nextsent>
<nextsent>the integrated segmentation and alignment (isa) model (zhang et al, 2003) does not require such word alignment.
</nextsent>
<nextsent>isa segments the sentence into phrases and finds their alignment simultaneously.
</nextsent>
<nextsent>isa is simple andfast.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1059">
<title id=" W05-0829.xml">competitive grouping in integrated phrase segmentation and alignment model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isa extracts phrase pairs from abi lingual corpus without requiring the pre calculated word alignment as many other phrase alignment models do.
</prevsent>
<prevsent>experiments conducted within the wpt-05 shared taskon statistical machine translation demonstrate the simplicity and effectiveness of this approach.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
in recent years, various phrase translation approaches (marcu and wong, 2002; <papid> W02-1018 </papid>och et al, 1999;<papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been shown to outperform word-to-word translation models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>many of these phrase alignment strategies relyon the pre-calculated word alignment and use different heuristics to extract the phrase pairs from the viterbi word alignment path.
</nextsent>
<nextsent>the integrated segmentation and alignment (isa) model (zhang et al, 2003) does not require such word alignment.
</nextsent>
<nextsent>isa segments the sentence into phrases and finds their alignment simultaneously.
</nextsent>
<nextsent>isa is simple andfast.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1060">
<title id=" W05-0829.xml">competitive grouping in integrated phrase segmentation and alignment model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isa extracts phrase pairs from abi lingual corpus without requiring the pre calculated word alignment as many other phrase alignment models do.
</prevsent>
<prevsent>experiments conducted within the wpt-05 shared taskon statistical machine translation demonstrate the simplicity and effectiveness of this approach.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in recent years, various phrase translation approaches (marcu and wong, 2002; <papid> W02-1018 </papid>och et al, 1999;<papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been shown to outperform word-to-word translation models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>many of these phrase alignment strategies relyon the pre-calculated word alignment and use different heuristics to extract the phrase pairs from the viterbi word alignment path.
</nextsent>
<nextsent>the integrated segmentation and alignment (isa) model (zhang et al, 2003) does not require such word alignment.
</nextsent>
<nextsent>isa segments the sentence into phrases and finds their alignment simultaneously.
</nextsent>
<nextsent>isa is simple andfast.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1061">
<title id=" W05-0829.xml">competitive grouping in integrated phrase segmentation and alignment model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isa extracts phrase pairs from abi lingual corpus without requiring the pre calculated word alignment as many other phrase alignment models do.
</prevsent>
<prevsent>experiments conducted within the wpt-05 shared taskon statistical machine translation demonstrate the simplicity and effectiveness of this approach.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
in recent years, various phrase translation approaches (marcu and wong, 2002; <papid> W02-1018 </papid>och et al, 1999;<papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>have been shown to outperform word-to-word translation models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>many of these phrase alignment strategies relyon the pre-calculated word alignment and use different heuristics to extract the phrase pairs from the viterbi word alignment path.
</nextsent>
<nextsent>the integrated segmentation and alignment (isa) model (zhang et al, 2003) does not require such word alignment.
</nextsent>
<nextsent>isa segments the sentence into phrases and finds their alignment simultaneously.
</nextsent>
<nextsent>isa is simple andfast.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1062">
<title id=" W05-0829.xml">competitive grouping in integrated phrase segmentation and alignment model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isa is simple andfast.
</prevsent>
<prevsent>translation experiments have shown comparable performance to other phrase alignment strategies which require complicated statistical model training.
</prevsent>
</prevsection>
<citsent citstr=" P97-1063 ">
in this paper, we describe the key idea behind this model and connect it with the competitive linking algorithm (melamed, 1997) <papid> P97-1063 </papid>which was developed for word-to-word alignment.</citsent>
<aftsection>
<nextsent>test given bilingual corpus of language pair (foreign, source language) and (english, target language), if we know the word alignment for each sentence pair we can calculate the co-occurrence frequency for each source/target word pair type c(f, e) and the marginal frequency c(f) = c(f, e) andc(e) = c(f, e).
</nextsent>
<nextsent>we can apply various statistical tests (manning and schutze, 1999) to measure how likely is the association between ande, in other words how likely they are mutual translations.
</nextsent>
<nextsent>in the following sections, we will use 2statistics to measure the the mutual translation likelihood (church and hanks, 1990).<papid> J90-1003 </papid></nextsent>
<nextsent>segmentation and alignment the competitive linking algorithm (cla) (melamed, 1997) <papid> P97-1063 </papid>is greedy word alignment algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1064">
<title id=" W05-0829.xml">competitive grouping in integrated phrase segmentation and alignment model </title>
<section> translation likelihood as statistical.  </section>
<citcontext>
<prevsection>
<prevsent>test given bilingual corpus of language pair (foreign, source language) and (english, target language), if we know the word alignment for each sentence pair we can calculate the co-occurrence frequency for each source/target word pair type c(f, e) and the marginal frequency c(f) = c(f, e) andc(e) = c(f, e).
</prevsent>
<prevsent>we can apply various statistical tests (manning and schutze, 1999) to measure how likely is the association between ande, in other words how likely they are mutual translations.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
in the following sections, we will use 2statistics to measure the the mutual translation likelihood (church and hanks, 1990).<papid> J90-1003 </papid></citsent>
<aftsection>
<nextsent>segmentation and alignment the competitive linking algorithm (cla) (melamed, 1997) <papid> P97-1063 </papid>is greedy word alignment algorithm.</nextsent>
<nextsent>it was designed to overcome the problem of indirect associations using simple heuristic: whenever several word tokens fi in one half of the bilingual corpus co-occur with particular word token in the other half of the corpus, the word that is most likely to be es translation is the one for which the likelihood l(f, e) of translational equivalence is highest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1067">
<title id=" W04-3006.xml">error detection and recovery in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>entry.
</prevsent>
<prevsent>a novelty of our work is the introduction of speech synthesizer to simulate the user, which facilitates development and evaluation of our proposed strategy.we have found that the speak-and-spell strategy is quite effective in simulation mode, but it remains to be tested in real user dialogues.
</prevsent>
</prevsection>
<citsent citstr=" W03-0707 ">
spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources (eckert et al, 1997; gorin et al, 1997; dahlback et al, 1999; zue et al, 2000; walker et al, 2001; glass and seneff, 2003; <papid> W03-0707 </papid>pieraccini et al, 1997; quast et al, 2003; j. gustafson, 1999; polifroni and chung, 2002; denecke, 2002; <papid> C02-1147 </papid>seneff, 2002; zue and glass, 2000).</citsent>
<aftsection>
<nextsent>while the effectiveness of such systems ? this research was supported by an industrial consortium supporting the mit oxygen alliance.
</nextsent>
<nextsent>has improved significantly over the past several years, critical barrier to widespread deployment remains in the form of communication breakdown at strategic points in the dialogue, often when the user is trying to convey critical piece of information that the system repeatedly misunderstands.
</nextsent>
<nextsent>this paper focuses on the specific two-stage problem of error detection and subsequent recovery, in situation where the user is attempting to provide named entity which the system fails to understand.
</nextsent>
<nextsent>it is not straightforward process for the system even to notice that it has made mistake.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1068">
<title id=" W04-3006.xml">error detection and recovery in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>entry.
</prevsent>
<prevsent>a novelty of our work is the introduction of speech synthesizer to simulate the user, which facilitates development and evaluation of our proposed strategy.we have found that the speak-and-spell strategy is quite effective in simulation mode, but it remains to be tested in real user dialogues.
</prevsent>
</prevsection>
<citsent citstr=" C02-1147 ">
spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources (eckert et al, 1997; gorin et al, 1997; dahlback et al, 1999; zue et al, 2000; walker et al, 2001; glass and seneff, 2003; <papid> W03-0707 </papid>pieraccini et al, 1997; quast et al, 2003; j. gustafson, 1999; polifroni and chung, 2002; denecke, 2002; <papid> C02-1147 </papid>seneff, 2002; zue and glass, 2000).</citsent>
<aftsection>
<nextsent>while the effectiveness of such systems ? this research was supported by an industrial consortium supporting the mit oxygen alliance.
</nextsent>
<nextsent>has improved significantly over the past several years, critical barrier to widespread deployment remains in the form of communication breakdown at strategic points in the dialogue, often when the user is trying to convey critical piece of information that the system repeatedly misunderstands.
</nextsent>
<nextsent>this paper focuses on the specific two-stage problem of error detection and subsequent recovery, in situation where the user is attempting to provide named entity which the system fails to understand.
</nextsent>
<nextsent>it is not straightforward process for the system even to notice that it has made mistake.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1069">
<title id=" W04-3006.xml">error detection and recovery in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the remainder of the paper is organized as follows.
</prevsent>
<prevsent>section 2 motivates why we think this is an interesting and important problem.
</prevsent>
</prevsection>
<citsent citstr=" W00-0303 ">
in sections 3 and 4, we describe the error detection and recovery strategies that have been adopted in our mercury flight reservation system (sen eff, 2002; seneff and polifroni, 2000), <papid> W00-0303 </papid>and we provide an analysis of the degree to which error recovery was successful, specifically for the case of entering source or destination city name.</citsent>
<aftsection>
<nextsent>the approach used was to solicita keypad entry of the city in cases where the system detected communication breakdown.
</nextsent>
<nextsent>we have analyzeda set of 172 cases where keypad entry of city was solicited.
</nextsent>
<nextsent>one of the observations was that users were often not very receptive to the idea of switching into keypad mode to map the spelling of the city to numeric code.whether this is the result of cognitive overload, confusion, or some other reason is not clear, however, since we were unable to interview users to identify why they chose not to use the keypad.
</nextsent>
<nextsent>motivated by the apparent need for more intuitive error recovery strategy, we describe in sections 5 and6 set of experiments that explore an alternative approach whereby the user is instead asked to speak and spell the problematic city name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1071">
<title id=" W04-3006.xml">error detection and recovery in spoken dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the observations was that users were often not very receptive to the idea of switching into keypad mode to map the spelling of the city to numeric code.whether this is the result of cognitive overload, confusion, or some other reason is not clear, however, since we were unable to interview users to identify why they chose not to use the keypad.
</prevsent>
<prevsent>motivated by the apparent need for more intuitive error recovery strategy, we describe in sections 5 and6 set of experiments that explore an alternative approach whereby the user is instead asked to speak and spell the problematic city name.
</prevsent>
</prevsection>
<citsent citstr=" N03-1005 ">
we have recently developed the capability to utilize pronounced version of aword to greatly enhance the accuracy of letter recognition task, and have successfully integrated this technology into personal name enrollment task (seneff et al,2003; chung et al, 2003).<papid> N03-1005 </papid></citsent>
<aftsection>
<nextsent>our interest here was in evaluating whether similar technique would be useful for the error recovery problem.it is difficult, however, to develop and perfect an algorithm involving multiple recognition passes, that is only triggered sporadically in user conversations.
</nextsent>
<nextsent>hence, we discuss novel approach to system development based on simulating the completion of user dialogues beginning atthe point where the system had detected communication breakdown.
</nextsent>
<nextsent>in other words, we utilize speech synthesizer to produce speak-and-spell waveform that is solicited in lieu of the keypad entry in the mercury dialogues we have analyzed.
</nextsent>
<nextsent>dectalk1 acts as user continuing the conversation from the point where the original mercury system detected communication break down.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1082">
<title id=" W06-0138.xml">using partofspeech reranking to improve chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>traditionally,these two tasks were treated as separate and independent processing steps chained together in apipeline.
</prevsent>
<prevsent>in such pipeline systems, errors introduced at the early stage cannot be easily recovered in later steps, causing cascade of error sand eventually harm overall performance.
</prevsent>
</prevsection>
<citsent citstr=" H05-1094 ">
intuitively, correct segmentation of the input sentence is more likely to give rise to correct pos tagging sequence than an incorrect segmentation.hinging on this idea, one way to avoid error propagation in chaining subtasks such as segmentation and pos tagging is to exploit the learning transfer (sutton and mccallum, 2005) <papid> H05-1094 </papid>among subtasks, typically through joint inference.</citsent>
<aftsection>
<nextsent>sutton et al.
</nextsent>
<nextsent>(2004) presented dynamic conditional random fields (dcrf), generalization of the traditionallinear-chain crf that allow representation of interaction among labels.
</nextsent>
<nextsent>they used loopy belief propagation for inference approximation.
</nextsent>
<nextsent>their empirical results on the joint task of pos tagging and np-chunking suggested that dcrf gave superior performance over cascaded linear-chain crf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1083">
<title id=" W06-0138.xml">using partofspeech reranking to improve chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they used loopy belief propagation for inference approximation.
</prevsent>
<prevsent>their empirical results on the joint task of pos tagging and np-chunking suggested that dcrf gave superior performance over cascaded linear-chain crf.
</prevsent>
</prevsection>
<citsent citstr=" W04-3236 ">
ng and low (2004) <papid> W04-3236 </papid>and luo (2003) <papid> W03-1025 </papid>also trained single joint models over the chinese segmentation and pos tagging subtasks.</citsent>
<aftsection>
<nextsent>in their work, they brought the two subtasks together by treating it as single tagging problem, for which they trained maximum entropy classifier to assign combined word boundary and pos tag to each character.
</nextsent>
<nextsent>a major challenge, however, exists in doing joint inference for complex and large-scale nlp application.
</nextsent>
<nextsent>sutton and mccallum (sutton and mccallum, 2005) <papid> H05-1094 </papid>suggested that in many cases exact inference can be too expensive and thus formi dable.</nextsent>
<nextsent>they presented an alternative approach in which linear-chain crf is trained separately for each subtask at training time, but at decoding time they combined the learned weights from the crf cascade into single grid-shaped facto rial crf to perform joint decoding and make predictions for all subtasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1084">
<title id=" W06-0138.xml">using partofspeech reranking to improve chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they used loopy belief propagation for inference approximation.
</prevsent>
<prevsent>their empirical results on the joint task of pos tagging and np-chunking suggested that dcrf gave superior performance over cascaded linear-chain crf.
</prevsent>
</prevsection>
<citsent citstr=" W03-1025 ">
ng and low (2004) <papid> W04-3236 </papid>and luo (2003) <papid> W03-1025 </papid>also trained single joint models over the chinese segmentation and pos tagging subtasks.</citsent>
<aftsection>
<nextsent>in their work, they brought the two subtasks together by treating it as single tagging problem, for which they trained maximum entropy classifier to assign combined word boundary and pos tag to each character.
</nextsent>
<nextsent>a major challenge, however, exists in doing joint inference for complex and large-scale nlp application.
</nextsent>
<nextsent>sutton and mccallum (sutton and mccallum, 2005) <papid> H05-1094 </papid>suggested that in many cases exact inference can be too expensive and thus formi dable.</nextsent>
<nextsent>they presented an alternative approach in which linear-chain crf is trained separately for each subtask at training time, but at decoding time they combined the learned weights from the crf cascade into single grid-shaped facto rial crf to perform joint decoding and make predictions for all subtasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1087">
<title id=" W06-0138.xml">using partofspeech reranking to improve chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>butat decoding time, we experiment with an alternative approximation method to joint decoding, by taking the n-best hypotheses from the segmentation model and use the pos tagging model for reranking.
</prevsent>
<prevsent>we evaluated our system on the open tracks of sighan bakeoff 2006 dataset.
</prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
furthermore, to evaluate our reranking methods impact on the pos tagging task, we also performed 10-fold cross-validation tests on the 250k penn 205chinese treebank (ctb) (xue et al, 2002).<papid> C02-1145 </papid></citsent>
<aftsection>
<nextsent>results from both evaluations suggest that our simple reranking method is very effective.
</nextsent>
<nextsent>we achieveda consistent performance gain on both segmentation and pos tagging tasks over linearly-cascaded crf.
</nextsent>
<nextsent>our official f-scores on the 2006 bakeoff open tracks are 0.935 (upuc), 0.964 (cityu), 0.952 (msra) and 0.949 (ckip).
</nextsent>
<nextsent>given an observed chinese character sequencex = {c1, c2, ..., cn}, let and denote segmentation sequence and pos tagging sequence over x. our goal is to find segmentation sequence s?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1089">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments show promising results with respect to the ultimate goal, achieving much better scala bility than prior web-based methods.
</prevsent>
<prevsent>modeling semantic variability in language has drawn lot of attention in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P01-1052 ">
many applications like qa, ir, ie and machine translation (moldovan andrus, 2001; <papid> P01-1052 </papid>hermjakob et al, 2003; jacquemin, 1999) <papid> P99-1044 </papid>have to recognize that the same meaning can be expressed in the text in huge variety of surface forms.</citsent>
<aftsection>
<nextsent>substantial research has been dedicated to acquiring paraphrase patterns, which represent various forms in which certain meaning can be expressed.following (dagan and glickman, 2004) we observe that somewhat more general notion needed for applications is that of entailment relations (e.g.
</nextsent>
<nextsent>(moldovan andrus, 2001)).<papid> P01-1052 </papid></nextsent>
<nextsent>these are directional relations between two expressions, where the meaning of one can be entailed from the meaning of the other.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1090">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments show promising results with respect to the ultimate goal, achieving much better scala bility than prior web-based methods.
</prevsent>
<prevsent>modeling semantic variability in language has drawn lot of attention in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P99-1044 ">
many applications like qa, ir, ie and machine translation (moldovan andrus, 2001; <papid> P01-1052 </papid>hermjakob et al, 2003; jacquemin, 1999) <papid> P99-1044 </papid>have to recognize that the same meaning can be expressed in the text in huge variety of surface forms.</citsent>
<aftsection>
<nextsent>substantial research has been dedicated to acquiring paraphrase patterns, which represent various forms in which certain meaning can be expressed.following (dagan and glickman, 2004) we observe that somewhat more general notion needed for applications is that of entailment relations (e.g.
</nextsent>
<nextsent>(moldovan andrus, 2001)).<papid> P01-1052 </papid></nextsent>
<nextsent>these are directional relations between two expressions, where the meaning of one can be entailed from the meaning of the other.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1092">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> background and motivations.  </section>
<citcontext>
<prevsection>
<prevsent>the prominent approach for paraphrase learning searches sentences that share common sets of multiple anchors, assuming they describe roughly the same fact or event.
</prevsent>
<prevsent>to facilitate finding many matching sentences, highly redundant comparable corpora have been used.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
these include multiple translations of the same text (barzilay and mckeown, 2001) <papid> P01-1008 </papid>and corresponding articles from multiple news sources (shinyama et al, 2002; pang etal., 2003; <papid> N03-1024 </papid>barzilay and lee, 2003).<papid> N03-1003 </papid></citsent>
<aftsection>
<nextsent>while facilitating accuracy, we assume that comparable corpora cannot be sole resource due to their limited availability.
</nextsent>
<nextsent>avoiding comparable corpus, (glickman and dagan, 2003) developed statistical methods that match verb paraphrases within regular corpus.their limited scale results, obtaining several hundred verb paraphrases from 15 million word corpus, suggest that much larger corpora are required.
</nextsent>
<nextsent>naturally, the largest available corpus is the web.since exhaustive processing of the web is not feasible, (duclaye et al, 2002) and (ravichandran and hovy, 2002) <papid> P02-1006 </papid>attempted bootstrapping approaches, which resemble the mutual bootstrapping method for information extraction of (riloff and jones, 1999).</nextsent>
<nextsent>these methods start with provided known set of anchors for target meaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1093">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> background and motivations.  </section>
<citcontext>
<prevsection>
<prevsent>the prominent approach for paraphrase learning searches sentences that share common sets of multiple anchors, assuming they describe roughly the same fact or event.
</prevsent>
<prevsent>to facilitate finding many matching sentences, highly redundant comparable corpora have been used.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
these include multiple translations of the same text (barzilay and mckeown, 2001) <papid> P01-1008 </papid>and corresponding articles from multiple news sources (shinyama et al, 2002; pang etal., 2003; <papid> N03-1024 </papid>barzilay and lee, 2003).<papid> N03-1003 </papid></citsent>
<aftsection>
<nextsent>while facilitating accuracy, we assume that comparable corpora cannot be sole resource due to their limited availability.
</nextsent>
<nextsent>avoiding comparable corpus, (glickman and dagan, 2003) developed statistical methods that match verb paraphrases within regular corpus.their limited scale results, obtaining several hundred verb paraphrases from 15 million word corpus, suggest that much larger corpora are required.
</nextsent>
<nextsent>naturally, the largest available corpus is the web.since exhaustive processing of the web is not feasible, (duclaye et al, 2002) and (ravichandran and hovy, 2002) <papid> P02-1006 </papid>attempted bootstrapping approaches, which resemble the mutual bootstrapping method for information extraction of (riloff and jones, 1999).</nextsent>
<nextsent>these methods start with provided known set of anchors for target meaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1094">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> background and motivations.  </section>
<citcontext>
<prevsection>
<prevsent>the prominent approach for paraphrase learning searches sentences that share common sets of multiple anchors, assuming they describe roughly the same fact or event.
</prevsent>
<prevsent>to facilitate finding many matching sentences, highly redundant comparable corpora have been used.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
these include multiple translations of the same text (barzilay and mckeown, 2001) <papid> P01-1008 </papid>and corresponding articles from multiple news sources (shinyama et al, 2002; pang etal., 2003; <papid> N03-1024 </papid>barzilay and lee, 2003).<papid> N03-1003 </papid></citsent>
<aftsection>
<nextsent>while facilitating accuracy, we assume that comparable corpora cannot be sole resource due to their limited availability.
</nextsent>
<nextsent>avoiding comparable corpus, (glickman and dagan, 2003) developed statistical methods that match verb paraphrases within regular corpus.their limited scale results, obtaining several hundred verb paraphrases from 15 million word corpus, suggest that much larger corpora are required.
</nextsent>
<nextsent>naturally, the largest available corpus is the web.since exhaustive processing of the web is not feasible, (duclaye et al, 2002) and (ravichandran and hovy, 2002) <papid> P02-1006 </papid>attempted bootstrapping approaches, which resemble the mutual bootstrapping method for information extraction of (riloff and jones, 1999).</nextsent>
<nextsent>these methods start with provided known set of anchors for target meaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1095">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> background and motivations.  </section>
<citcontext>
<prevsection>
<prevsent>while facilitating accuracy, we assume that comparable corpora cannot be sole resource due to their limited availability.
</prevsent>
<prevsent>avoiding comparable corpus, (glickman and dagan, 2003) developed statistical methods that match verb paraphrases within regular corpus.their limited scale results, obtaining several hundred verb paraphrases from 15 million word corpus, suggest that much larger corpora are required.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
naturally, the largest available corpus is the web.since exhaustive processing of the web is not feasible, (duclaye et al, 2002) and (ravichandran and hovy, 2002) <papid> P02-1006 </papid>attempted bootstrapping approaches, which resemble the mutual bootstrapping method for information extraction of (riloff and jones, 1999).</citsent>
<aftsection>
<nextsent>these methods start with provided known set of anchors for target meaning.
</nextsent>
<nextsent>for example,the known anchor set {mozart, 1756} is given as in put in order to find paraphrases for the template xborn in y?.
</nextsent>
<nextsent>web searching is then used to find occurrences of the input anchor set, resulting in new templates that are supposed to specify the same relation as the original one (born in?).
</nextsent>
<nextsent>these new templates are then exploited to get new anchor sets, which are subsequently processed as the initial {mozart, 1756}.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1098">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> background and motivations.  </section>
<citcontext>
<prevsection>
<prevsent>interesting algorithms are presented in (pang et al, 2003; <papid> N03-1024 </papid>barzilay and lee,2003).<papid> N03-1003 </papid></prevsent>
<prevsent>they learn linear patterns within similar contexts represented as finite state automata.</prevsent>
</prevsection>
<citsent citstr=" A00-1039 ">
three classes of syntactic template learning approaches are presented in the literature: learning of predicate argument templates (yangarber et al, 2000), <papid> A00-1039 </papid>learning of syntactic chains (lin and pantel, 2001) and learning of sub-trees (sudo et al, 2003).<papid> P03-1029 </papid></citsent>
<aftsection>
<nextsent>the last approach is the most general with respect to the template form.
</nextsent>
<nextsent>however, its processing time increases exponentially with the size of the templates.
</nextsent>
<nextsent>as conclusion, state of the art approaches still learn templates of limited form and size, thus restricting generality of the learning process.
</nextsent>
<nextsent>motivated by prior experience, we identify two major goals for scaling web-based acquisition of entailment relations: (a) covering the broadest possible range of meanings, while requiring minimal input and (b) keeping template structures as general as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1099">
<title id=" W04-3206.xml">scaling web based acquisition of entailment relations </title>
<section> background and motivations.  </section>
<citcontext>
<prevsection>
<prevsent>interesting algorithms are presented in (pang et al, 2003; <papid> N03-1024 </papid>barzilay and lee,2003).<papid> N03-1003 </papid></prevsent>
<prevsent>they learn linear patterns within similar contexts represented as finite state automata.</prevsent>
</prevsection>
<citsent citstr=" P03-1029 ">
three classes of syntactic template learning approaches are presented in the literature: learning of predicate argument templates (yangarber et al, 2000), <papid> A00-1039 </papid>learning of syntactic chains (lin and pantel, 2001) and learning of sub-trees (sudo et al, 2003).<papid> P03-1029 </papid></citsent>
<aftsection>
<nextsent>the last approach is the most general with respect to the template form.
</nextsent>
<nextsent>however, its processing time increases exponentially with the size of the templates.
</nextsent>
<nextsent>as conclusion, state of the art approaches still learn templates of limited form and size, thus restricting generality of the learning process.
</nextsent>
<nextsent>motivated by prior experience, we identify two major goals for scaling web-based acquisition of entailment relations: (a) covering the broadest possible range of meanings, while requiring minimal input and (b) keeping template structures as general as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1100">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both of them are based on character tagging, but use different tag sets and different features.
</prevsent>
<prevsent>evaluation results show that our word segmentation system achieved 93.3% and 94.7% f-score in upuc and msra open tests, and our ner system got 70.84% and 81.32% f-score in ldc and msra open tests.
</prevsent>
</prevsection>
<citsent citstr=" I05-3025 ">
dealing with word segmentation as character tagging showed good results in last sighan bakeoff (j.k.low et al,2005).<papid> I05-3025 </papid></citsent>
<aftsection>
<nextsent>it is good at unknown word identification, but only using char acter-level features sometimes makes mistakes when identifying known words (t.nakagawa, 2004).<papid> C04-1067 </papid></nextsent>
<nextsent>researchers use word-level features (j.k.low et al,2005) <papid> I05-3025 </papid>to solve this problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1102">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation results show that our word segmentation system achieved 93.3% and 94.7% f-score in upuc and msra open tests, and our ner system got 70.84% and 81.32% f-score in ldc and msra open tests.
</prevsent>
<prevsent>dealing with word segmentation as character tagging showed good results in last sighan bakeoff (j.k.low et al,2005).<papid> I05-3025 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1067 ">
it is good at unknown word identification, but only using char acter-level features sometimes makes mistakes when identifying known words (t.nakagawa, 2004).<papid> C04-1067 </papid></citsent>
<aftsection>
<nextsent>researchers use word-level features (j.k.low et al,2005) <papid> I05-3025 </papid>to solve this problem.</nextsent>
<nextsent>based on this idea, we develop word segmentation system based on character-tagging, which also combine character-level and word-level fea tures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1104">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on this idea, we develop word segmentation system based on character-tagging, which also combine character-level and word-level features.
</prevsent>
<prevsent>in addition, character-based ner module and rule-based factoid identification module are developed for post-processing.
</prevsent>
</prevsection>
<citsent citstr=" W03-1026 ">
named entity recognition based on character tagging has shown better accuracy than word based methods (h.jing et al,2003).<papid> W03-1026 </papid></citsent>
<aftsection>
<nextsent>but the small window of text makes it difficult to recognize the named entities with many characters, such as organization names (h.jing et al,2003).<papid> W03-1026 </papid></nextsent>
<nextsent>considering about this, we developed ner system based on character-tagging, which combines word-level and character-level features together.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1108">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> character tagging for word.  </section>
<citcontext>
<prevsection>
<prevsent>)|(maxarg* stpt = (1) then we assume that the tagging of one character is independent of each other, and modify formula 1 as ? = = = = = i ii tttt nn tttt ctp ccctttpt n 1...
</prevsent>
<prevsent>2121 ...
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
* )|(maxarg )...|...(maxarg 21 21 (2) beam search (n=3) (ratnaparkhi,1996) <papid> W96-0213 </papid>is applied for tag sequence searching, but we only search the valid sequences to ensure the validity of searching result.</citsent>
<aftsection>
<nextsent>svm is selected as the basic classification model for tagging because of its robustness to over-fitting and high performance (sebastiani, 2002).
</nextsent>
<nextsent>to simplify the calculation, the output of svm is regarded as p(ti|ci).
</nextsent>
<nextsent>2.2 tag definition.
</nextsent>
<nextsent>four tags b, i, e, s?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1109">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> character tagging for word.  </section>
<citcontext>
<prevsection>
<prevsent>a character list, which contains all the characters in the lexicon introduced later, is used to identify them.
</prevsent>
<prevsent>besides of that, feature pu(c0) means whether c0 is in punctuation character list.
</prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
it is also binary feature and all the punctuations in the punctuation character list come from penn chinese tree bank 5.1 (n.xue et al,2002).<papid> C02-1145 </papid></citsent>
<aftsection>
<nextsent>in addition, we define some word-level features based on lexicon to enlarge the window size of text in the two tasks, which are: (c) wn (n=-1,0,1) feature wn (n=-1,0,1) mean the lexicon words in different positions (the word containing c0 and one word to its left and right) and they are also binary features.
</nextsent>
<nextsent>we select all the possible words in the lexicon that satisfy the requirements, not like only selecting the longest one in (j.k.low et al,2005).<papid> I05-3025 </papid></nextsent>
<nextsent>to create the lexicon, we use following steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1112">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> character tagging for word.  </section>
<citcontext>
<prevsection>
<prevsent>we select all the possible words in the lexicon that satisfy the requirements, not like only selecting the longest one in (j.k.low et al,2005).<papid> I05-3025 </papid></prevsent>
<prevsent>to create the lexicon, we use following steps.</prevsent>
</prevsection>
<citsent citstr=" I05-3017 ">
first, lexicon from nict (national institute of information and communications technology, japan) is used as the basic lexicon, which is extracted from peking university corpus of the second sighan bakeoff (t.emerson, 2005), <papid> I05-3017 </papid>penn chinese treebank 4.0 (n.xue et al,2002), <papid> C02-1145 </papid>chinese-to-english word list1 and part of nict corpus (k.uchimoto et al.,2004; <papid> W04-2208 </papid>y.j.zhang et al,2005).</citsent>
<aftsection>
<nextsent>then, all the words containing digits and letters are removed 1 http://projects.ldc.upenn.edu/chinese/ from this lexicon.
</nextsent>
<nextsent>at last, all the punctuations in penn chinese treebank 5.1 (n.xue et al,2002) <papid> C02-1145 </papid>and all the words in the training data of upuc and msra corp uses are added into the lexicon.</nextsent>
<nextsent>besides of above features, some extra features are defined only for ner task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1114">
<title id=" W06-0123.xml">chinese word segmentation and named entity recognition by character tagging </title>
<section> character tagging for word.  </section>
<citcontext>
<prevsection>
<prevsent>we select all the possible words in the lexicon that satisfy the requirements, not like only selecting the longest one in (j.k.low et al,2005).<papid> I05-3025 </papid></prevsent>
<prevsent>to create the lexicon, we use following steps.</prevsent>
</prevsection>
<citsent citstr=" W04-2208 ">
first, lexicon from nict (national institute of information and communications technology, japan) is used as the basic lexicon, which is extracted from peking university corpus of the second sighan bakeoff (t.emerson, 2005), <papid> I05-3017 </papid>penn chinese treebank 4.0 (n.xue et al,2002), <papid> C02-1145 </papid>chinese-to-english word list1 and part of nict corpus (k.uchimoto et al.,2004; <papid> W04-2208 </papid>y.j.zhang et al,2005).</citsent>
<aftsection>
<nextsent>then, all the words containing digits and letters are removed 1 http://projects.ldc.upenn.edu/chinese/ from this lexicon.
</nextsent>
<nextsent>at last, all the punctuations in penn chinese treebank 5.1 (n.xue et al,2002) <papid> C02-1145 </papid>and all the words in the training data of upuc and msra corp uses are added into the lexicon.</nextsent>
<nextsent>besides of above features, some extra features are defined only for ner task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1116">
<title id=" W05-0635.xml">semantic role labeling using complete syntactic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we introduce semantic role labeling system constructed on top of thefull syntactic analysis of text.
</prevsent>
<prevsent>the labeling problem is modeled using richset of lexical, syntactic, and semantic attributes and learned using one-versus-all ada boost classifiers.our results indicate that even simple approach that assumes that each semantic argument maps into exactly one syntactic phrase obtains encouraging performance,surpassing the best system that uses partial syntax by almost 6%.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
most current semantic role labeling (srl) approaches can be classified in one of two classes:approaches that take advantage of complete syntactic analysis of text, pioneered by (gildea and jurafsky, 2002), <papid> J02-3001 </papid>and approaches that use partial syntactic analysis, championed by the previous conll shared task evaluations (carreras and ma`rquez, 2004).however, to the authors?</citsent>
<aftsection>
<nextsent>knowledge, clear analysis of the benefits of using full syntactic analysis versus partial analysis is not yet available.
</nextsent>
<nextsent>on onehand, the additional information provided by complete syntax should intuitively be useful.
</nextsent>
<nextsent>but, on the other hand, the state-of-the-art of full parsing is known to be less robust and perform worse than the tools used for partial syntactic analysis, which would decrease the quality of the information provided.
</nextsent>
<nextsent>the work presented in this paper contribute sto this analysis by introducing model that is entirely based on the full syntactic analysis of text, generated by real-world parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1117">
<title id=" W05-0635.xml">semantic role labeling using complete syntactic analysis </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the work presented in this paper contribute sto this analysis by introducing model that is entirely based on the full syntactic analysis of text, generated by real-world parser.
</prevsent>
<prevsent>2.1 mapping arguments to syntactic.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
constituent sour approach maps each argument label to one syntactic constituent, using strategy similar to (sur deanu et al, 2003).<papid> P03-1002 </papid></citsent>
<aftsection>
<nextsent>using bottom-up approach, we map each argument to the first phrase that has the exact same boundaries and climb as high as possible in the syntactic tree across unary production chains.
</nextsent>
<nextsent>unfortunately, this one-to-one mapping between semantic arguments and syntactic constituents is not always possible.
</nextsent>
<nextsent>one semantic argument may be mapped to many syntactic constituents due to: (a)intrinsic differences between the syntactic and semantic representations, and (b) incorrect syntacticstructure.
</nextsent>
<nextsent>figure 1 illustrates each one of these sit uations: figure 1 (a) shows sentence where each semantic argument correctly maps to one syntactic constituent; figure 1 (b) illustrates the situation where one semantic argument correctly maps to two syntactic constituents; and figure 1 (c) shows one to-many mapping caused by an incorrect syntacticstructure: argument a0 maps to two phrases, the terminal by?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1121">
<title id=" W05-0635.xml">semantic role labeling using complete syntactic analysis </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>we trained one-vs-all classifiers for the top 24 most common arguments in training (includingr-a* and c-a*).
</prevsent>
<prevsent>for simplicity we do not label predicates.
</prevsent>
</prevsection>
<citsent citstr=" W04-2415 ">
following the strategy proposed by (carreras et al, 2004) <papid> W04-2415 </papid>we select training examples (both positive and negative) only from: (a) the first s* phrase that includes the predicate, or (b) from phrases that appear to the left of the predicate in the sentence.</citsent>
<aftsection>
<nextsent>more than 98% of the arguments fall into one of these classes.at prediction time the classifiers are combined using simple greedy technique that iteratively assigns to each predicate the argument classified with the highest confidence.
</nextsent>
<nextsent>for each predicate we consider as candidates all am attributes, but only numbered attributes indicated in the corresponding propbank frame.
</nextsent>
<nextsent>2.4 argument expansion heuristics.
</nextsent>
<nextsent>we address arguments that should map to more than one terminal phrase with the following postprocessing heuristic: if an argument is mapped to one terminal phrase, its boundaries are extended to the right to include all terminal phrases that are not already labeled as other arguments for the samepredicate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1123">
<title id=" W05-0635.xml">semantic role labeling using complete syntactic analysis </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 results and discussion.
</prevsent>
<prevsent>table 7 presents the results obtained by our system.
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
on the wsj data, our results surpass with almost 6% the results obtained by the best srl system that used partial syntax in the conll 2004 shared task evaluation (hacioglu et al, 2004).<papid> W04-2416 </papid></citsent>
<aftsection>
<nextsent>even though these numbers are not directly comparable (this years shared task offers more training data), we consider these results encouraging given the simplicity of our system (we essentially model only one-to-one 223 precision recall f?=1 development 79.14% 71.57% 75.17 test wsj 80.32% 72.95% 76.46 test brown 72.41% 59.67% 65.42 test wsj+brown 79.35% 71.17% 75.04 test wsj precision recall f?=1 overall 80.32% 72.95% 76.46 a0 87.09% 85.21% 86.14 a1 79.80% 72.23% 75.83 a2 74.74% 58.38% 65.55 a3 83.04% 53.76% 65.26 a4 77.42% 70.59% 73.85 a5 0.00% 0.00% 0.00 am-adv 57.82% 46.05% 51.27 am-cau 49.38% 54.79% 51.95 am-dir 62.96% 40.00% 48.92 am-dis 72.19% 76.25% 74.16 am-ext 60.87% 43.75% 50.91 am-loc 64.19% 52.34% 57.66 am-mnr 63.90% 44.77% 52.65 am-mod 98.09% 93.28% 95.63 am-neg 96.15% 97.83% 96.98 am-pnc 55.22% 32.17% 40.66 am-prd 0.00% 0.00% 0.00 am-rec 0.00% 0.00% 0.00 am-tmp 79.17% 73.41% 76.18 r-a0 84.85% 87.50% 86.15 r-a1 75.00% 71.15% 73.03 r-a2 60.00% 37.50% 46.15 r-a3 0.00% 0.00% 0.00 r-a4 0.00% 0.00% 0.00 r-am-adv 0.00% 0.00% 0.00 r-am-cau 0.00% 0.00% 0.00 r-am-ext 0.00% 0.00% 0.00 r-am-loc 68.00% 80.95% 73.91 r-am-mnr 30.00% 50.00% 37.50 r-am-tmp 60.81% 86.54% 71.43 0.00% 0.00% 0.00 table 7: overall results (top) and detailed results on the wsj test (bottom).mappings between semantic arguments and syntactic constituents).
</nextsent>
<nextsent>only 0.14% out of the 75.17% measure obtained on the development partition are attributed to the argument expansion heuristics introduced in section 2.4.
</nextsent>
<nextsent>this paper describes semantic role labeling system constructed on top of the complete syntactic analysis of text.
</nextsent>
<nextsent>we model semantic arguments that map into exactly one syntactic phrase (about 90% of all semantic arguments in the development set) using rich set of lexical, syntactic, and semanticattributes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1124">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>typical semantic arguments include agent, patient, instrument, etc. and also adjuncts such as locative, temporal, manner, cause, etc. last year, the conll-2004 shared task aimed at evaluating machine learning srl systems based only on partial syntactic information.
</prevsent>
<prevsent>in (carreras and ma`rquez, 2004) one may find detailed review of the task and also brief state-of-the-art on srl previous to 2004.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
ten systems contributed to thetask, which was evaluated using the propbank corpus (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>the best results were around 70 in f1 measure.
</nextsent>
<nextsent>though not directly comparable, these figures are substantially lower than the best results published up to date using full parsing as input information (f1 slightly over 79).
</nextsent>
<nextsent>in addition to the conll-2004 shared task, another evaluation exercise was conducted in the senseval-3 work shop (litkowski, 2004).<papid> W04-0803 </papid></nextsent>
<nextsent>eight systems relying on full parsing information were evaluated in that event using the framenet corpus (fillmore et al, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1126">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the best results were around 70 in f1 measure.
</prevsent>
<prevsent>though not directly comparable, these figures are substantially lower than the best results published up to date using full parsing as input information (f1 slightly over 79).
</prevsent>
</prevsection>
<citsent citstr=" W04-0803 ">
in addition to the conll-2004 shared task, another evaluation exercise was conducted in the senseval-3 work shop (litkowski, 2004).<papid> W04-0803 </papid></citsent>
<aftsection>
<nextsent>eight systems relying on full parsing information were evaluated in that event using the framenet corpus (fillmore et al, 2001).
</nextsent>
<nextsent>from the point of view of learning architectures and study of feature relevance, it is also worth mentioning the following recent works (punyakanok et al,2004; <papid> C04-1197 </papid>moschitti, 2004; <papid> P04-1043 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a).</nextsent>
<nextsent>following last years initiative, the conll-2005 shared task1 will concern again the recognition of semantic roles for the english language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1127">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the conll-2004 shared task, another evaluation exercise was conducted in the senseval-3 work shop (litkowski, 2004).<papid> W04-0803 </papid></prevsent>
<prevsent>eight systems relying on full parsing information were evaluated in that event using the framenet corpus (fillmore et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
from the point of view of learning architectures and study of feature relevance, it is also worth mentioning the following recent works (punyakanok et al,2004; <papid> C04-1197 </papid>moschitti, 2004; <papid> P04-1043 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a).</citsent>
<aftsection>
<nextsent>following last years initiative, the conll-2005 shared task1 will concern again the recognition of semantic roles for the english language.
</nextsent>
<nextsent>compared to the shared task of conll-2004, the novelties introduced in the 2005 edition are: ? aiming at evaluating the contribution of full parsing in srl, the complete syntactic trees given by two alternative parsers have been provided as input information for the task.
</nextsent>
<nextsent>therest of input information does not vary and corresponds to the levels of processing treated in the previous editions of the conll shared task, i.e., words, pos tags, base chunks, clauses, and named entities.?
</nextsent>
<nextsent>the training corpus has been substantially enlarged.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1128">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the conll-2004 shared task, another evaluation exercise was conducted in the senseval-3 work shop (litkowski, 2004).<papid> W04-0803 </papid></prevsent>
<prevsent>eight systems relying on full parsing information were evaluated in that event using the framenet corpus (fillmore et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
from the point of view of learning architectures and study of feature relevance, it is also worth mentioning the following recent works (punyakanok et al,2004; <papid> C04-1197 </papid>moschitti, 2004; <papid> P04-1043 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a).</citsent>
<aftsection>
<nextsent>following last years initiative, the conll-2005 shared task1 will concern again the recognition of semantic roles for the english language.
</nextsent>
<nextsent>compared to the shared task of conll-2004, the novelties introduced in the 2005 edition are: ? aiming at evaluating the contribution of full parsing in srl, the complete syntactic trees given by two alternative parsers have been provided as input information for the task.
</nextsent>
<nextsent>therest of input information does not vary and corresponds to the levels of processing treated in the previous editions of the conll shared task, i.e., words, pos tags, base chunks, clauses, and named entities.?
</nextsent>
<nextsent>the training corpus has been substantially enlarged.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1129">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the conll-2004 shared task, another evaluation exercise was conducted in the senseval-3 work shop (litkowski, 2004).<papid> W04-0803 </papid></prevsent>
<prevsent>eight systems relying on full parsing information were evaluated in that event using the framenet corpus (fillmore et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
from the point of view of learning architectures and study of feature relevance, it is also worth mentioning the following recent works (punyakanok et al,2004; <papid> C04-1197 </papid>moschitti, 2004; <papid> P04-1043 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a).</citsent>
<aftsection>
<nextsent>following last years initiative, the conll-2005 shared task1 will concern again the recognition of semantic roles for the english language.
</nextsent>
<nextsent>compared to the shared task of conll-2004, the novelties introduced in the 2005 edition are: ? aiming at evaluating the contribution of full parsing in srl, the complete syntactic trees given by two alternative parsers have been provided as input information for the task.
</nextsent>
<nextsent>therest of input information does not vary and corresponds to the levels of processing treated in the previous editions of the conll shared task, i.e., words, pos tags, base chunks, clauses, and named entities.?
</nextsent>
<nextsent>the training corpus has been substantially enlarged.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1130">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the conll-2004 shared task, another evaluation exercise was conducted in the senseval-3 work shop (litkowski, 2004).<papid> W04-0803 </papid></prevsent>
<prevsent>eight systems relying on full parsing information were evaluated in that event using the framenet corpus (fillmore et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" W05-0634 ">
from the point of view of learning architectures and study of feature relevance, it is also worth mentioning the following recent works (punyakanok et al,2004; <papid> C04-1197 </papid>moschitti, 2004; <papid> P04-1043 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a).</citsent>
<aftsection>
<nextsent>following last years initiative, the conll-2005 shared task1 will concern again the recognition of semantic roles for the english language.
</nextsent>
<nextsent>compared to the shared task of conll-2004, the novelties introduced in the 2005 edition are: ? aiming at evaluating the contribution of full parsing in srl, the complete syntactic trees given by two alternative parsers have been provided as input information for the task.
</nextsent>
<nextsent>therest of input information does not vary and corresponds to the levels of processing treated in the previous editions of the conll shared task, i.e., words, pos tags, base chunks, clauses, and named entities.?
</nextsent>
<nextsent>the training corpus has been substantially enlarged.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1132">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> task description.  </section>
<citcontext>
<prevsection>
<prevsent>according to the propbank frames, for attract (8th), the a0 annotates the at tractor, and the a1 the thing attracted; for intersperse (9th), a0 is the arranger, and a1 the entity interspersed.
</prevsent>
<prevsent>2.2 closed challenge setting.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the organization provided training, development and test sets derived from the standard sections ofthe penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and propbank (palmer et al, 2005) <papid> J05-1004 </papid>corpora.</citsent>
<aftsection>
<nextsent>in the closed challenge, systems have to be built strictly with information contained in the training sections of the treebank and propbank.
</nextsent>
<nextsent>since this collection contains the gold reference annotations of both syntactic and predicate-argument structures, the closed challenge allows: (1) to make use of any preprocessing system strictly developed within this setting, and (2) to learn from scratch any annotation that is contained in the data.
</nextsent>
<nextsent>to support the former,the organization provided the output of state-of-the art syntactic pre processors, described in section 3.the development set is used to tune the parameters of system.
</nextsent>
<nextsent>the gold reference annotations arealso available in this set, but only to evaluate the performance of different parametrizations of system, and select the optimal one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1138">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>predicts wsj full parses, with information of the lexical head for each syntactic constituent.
</prevsent>
<prevsent>the pos tags (required by the parser) have been computed with (gimenez and ma`rquez, 2003).
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
full parser of charniak (2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>jointly predicts pos tags and full parses.?
</nextsent>
<nextsent>named entities predicted with the maximum entropy based tagger of chieu and ng (2003).<papid> W03-0423 </papid>the tagger follows the conll-2003 task setting (tjong kim sang and de meulder, 2003),and thus is not developed with wsj data.</nextsent>
<nextsent>how ever, we allowed its use because there is no available named entity recognizer developed with wsj data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1139">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>full parser of charniak (2000).<papid> A00-2018 </papid></prevsent>
<prevsent>jointly predicts pos tags and full parses.?</prevsent>
</prevsection>
<citsent citstr=" W03-0423 ">
named entities predicted with the maximum entropy based tagger of chieu and ng (2003).<papid> W03-0423 </papid>the tagger follows the conll-2003 task setting (tjong kim sang and de meulder, 2003),and thus is not developed with wsj data.</citsent>
<aftsection>
<nextsent>how ever, we allowed its use because there is no available named entity recognizer developed with wsj data.
</nextsent>
<nextsent>the reported performance on the conll-2003 test is f1 = 88.31, with prec/rec.
</nextsent>
<nextsent>at 88.12/88.51.
</nextsent>
<nextsent>tables 2 and 3 summarize the performance of the syntactic processors on the development and test sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1142">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>see the ml-method?
</prevsent>
<prevsent>column of table 4 for summary of the following information.loglinear models and vector-based linear classifiers dominated over the rest.
</prevsent>
</prevsection>
<citsent citstr=" W05-0623 ">
probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</citsent>
<aftsection>
<nextsent>support vector machines (svm) were used by 6 teams.
</nextsent>
<nextsent>four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></nextsent>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1144">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>see the ml-method?
</prevsent>
<prevsent>column of table 4 for summary of the following information.loglinear models and vector-based linear classifiers dominated over the rest.
</prevsent>
</prevsection>
<citsent citstr=" W05-0632 ">
probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</citsent>
<aftsection>
<nextsent>support vector machines (svm) were used by 6 teams.
</nextsent>
<nextsent>four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></nextsent>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1145">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>see the ml-method?
</prevsent>
<prevsent>column of table 4 for summary of the following information.loglinear models and vector-based linear classifiers dominated over the rest.
</prevsent>
</prevsection>
<citsent citstr=" W05-0636 ">
probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</citsent>
<aftsection>
<nextsent>support vector machines (svm) were used by 6 teams.
</nextsent>
<nextsent>four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></nextsent>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1146">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>see the ml-method?
</prevsent>
<prevsent>column of table 4 for summary of the following information.loglinear models and vector-based linear classifiers dominated over the rest.
</prevsent>
</prevsection>
<citsent citstr=" W05-0638 ">
probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</citsent>
<aftsection>
<nextsent>support vector machines (svm) were used by 6 teams.
</nextsent>
<nextsent>four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></nextsent>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1148">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>see the ml-method?
</prevsent>
<prevsent>column of table 4 for summary of the following information.loglinear models and vector-based linear classifiers dominated over the rest.
</prevsent>
</prevsection>
<citsent citstr=" W05-0639 ">
probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</citsent>
<aftsection>
<nextsent>support vector machines (svm) were used by 6 teams.
</nextsent>
<nextsent>four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></nextsent>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1149">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</prevsent>
<prevsent>support vector machines (svm) were used by 6 teams.</prevsent>
</prevsection>
<citsent citstr=" W05-0629 ">
four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></citsent>
<aftsection>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).
</nextsent>
<nextsent>decision tree learning (dt) was also represented 156 devel.
</nextsent>
<nextsent>test wsj test brown p(%) r(%) f1 p(%) r(%) f1 p(%) r(%) f1 upc chunker 94.66 93.17 93.91 95.26 94.52 94.89 92.64 90.85 91.73 upc clauser 90.38 84.73 87.46 90.93 85.94 88.36 84.21 74.32 78.95 collins (1999) 85.02 83.55 84.28 85.63 85.20 85.41 82.68 81.33 82.00 charniak (2000) <papid> A00-2018 </papid>87.60 87.38 87.49 88.20 88.30 88.25 80.54 81.15 80.84 table 3: results of the syntactic parsers on the development, and wsj and brown test sets.</nextsent>
<nextsent>unlike in full parsing, the figures have been computed on strict evaluation basis with respect to punctuation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1153">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</prevsent>
<prevsent>support vector machines (svm) were used by 6 teams.</prevsent>
</prevsection>
<citsent citstr=" W05-0631 ">
four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></citsent>
<aftsection>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).
</nextsent>
<nextsent>decision tree learning (dt) was also represented 156 devel.
</nextsent>
<nextsent>test wsj test brown p(%) r(%) f1 p(%) r(%) f1 p(%) r(%) f1 upc chunker 94.66 93.17 93.91 95.26 94.52 94.89 92.64 90.85 91.73 upc clauser 90.38 84.73 87.46 90.93 85.94 88.36 84.21 74.32 78.95 collins (1999) 85.02 83.55 84.28 85.63 85.20 85.41 82.68 81.33 82.00 charniak (2000) <papid> A00-2018 </papid>87.60 87.38 87.49 88.20 88.30 88.25 80.54 81.15 80.84 table 3: results of the syntactic parsers on the development, and wsj and brown test sets.</nextsent>
<nextsent>unlike in full parsing, the figures have been computed on strict evaluation basis with respect to punctuation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1154">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>probably, this is due to the versatility of the approaches and the availability of very good software toolkits.in particular, 8 teams used the maximum entropy (me) statistical framework (che et al, 2005; haghighi et al, 2005; <papid> W05-0623 </papid>park and rim, 2005; <papid> W05-0632 </papid>tjong kim sang et al, 2005; sutton and mccallum, 2005; <papid> W05-0636 </papid>tsai et al, 2005; <papid> W05-0638 </papid>yi and palmer, 2005; <papid> W05-0639 </papid>venkatapathy et al, 2005).</prevsent>
<prevsent>support vector machines (svm) were used by 6 teams.</prevsent>
</prevsection>
<citsent citstr=" W05-0630 ">
four of them with the standard polynomial kernels (mitsumori et al, 2005; <papid> W05-0629 </papid>tjong kim sang et al, 2005; tsai et al, 2005; <papid> W05-0638 </papid>pradhan etal., 2005<papid> W05-0634 </papid>b), another one using gaussian kernels (oz gencil and mccracken, 2005), <papid> W05-0631 </papid>and last group using tree-based kernels specifically designed for the task(moschitti et al, 2005).<papid> W05-0630 </papid></citsent>
<aftsection>
<nextsent>another team used also related learning approach, snow, which is winnow based network of linear separators (punyakanok et al., 2005).
</nextsent>
<nextsent>decision tree learning (dt) was also represented 156 devel.
</nextsent>
<nextsent>test wsj test brown p(%) r(%) f1 p(%) r(%) f1 p(%) r(%) f1 upc chunker 94.66 93.17 93.91 95.26 94.52 94.89 92.64 90.85 91.73 upc clauser 90.38 84.73 87.46 90.93 85.94 88.36 84.21 74.32 78.95 collins (1999) 85.02 83.55 84.28 85.63 85.20 85.41 82.68 81.33 82.00 charniak (2000) <papid> A00-2018 </papid>87.60 87.38 87.49 88.20 88.30 88.25 80.54 81.15 80.84 table 3: results of the syntactic parsers on the development, and wsj and brown test sets.</nextsent>
<nextsent>unlike in full parsing, the figures have been computed on strict evaluation basis with respect to punctuation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1157">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>test wsj test brown p(%) r(%) f1 p(%) r(%) f1 p(%) r(%) f1 upc chunker 94.66 93.17 93.91 95.26 94.52 94.89 92.64 90.85 91.73 upc clauser 90.38 84.73 87.46 90.93 85.94 88.36 84.21 74.32 78.95 collins (1999) 85.02 83.55 84.28 85.63 85.20 85.41 82.68 81.33 82.00 charniak (2000) <papid> A00-2018 </papid>87.60 87.38 87.49 88.20 88.30 88.25 80.54 81.15 80.84 table 3: results of the syntactic parsers on the development, and wsj and brown test sets.</prevsent>
<prevsent>unlike in full parsing, the figures have been computed on strict evaluation basis with respect to punctuation.</prevsent>
</prevsection>
<citsent citstr=" W05-0633 ">
by ponzetto and strube (2005), <papid> W05-0633 </papid>who used c4.5.</citsent>
<aftsection>
<nextsent>ensembles of decision trees learned through the ada boost algorithm (ab) were applied by ma`rquez et al (2005) and surdeanu and turmo (2005).<papid> W05-0635 </papid></nextsent>
<nextsent>tjong kim sang et al (2005) applied, among others, memory-based learning (mbl).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1158">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>unlike in full parsing, the figures have been computed on strict evaluation basis with respect to punctuation.
</prevsent>
<prevsent>by ponzetto and strube (2005), <papid> W05-0633 </papid>who used c4.5.</prevsent>
</prevsection>
<citsent citstr=" W05-0635 ">
ensembles of decision trees learned through the ada boost algorithm (ab) were applied by ma`rquez et al (2005) and surdeanu and turmo (2005).<papid> W05-0635 </papid></citsent>
<aftsection>
<nextsent>tjong kim sang et al (2005) applied, among others, memory-based learning (mbl).
</nextsent>
<nextsent>regarding novel learning paradigms not applied in previous shared tasks, we find relevant vector machine (rvm), which is kernel based linear dis criminant inside the framework of sparse bayesian learning (johansson and nugues, 2005) <papid> W05-0624 </papid>and tree conditional random fields (t-crf) (cohn and blunsom, 2005), <papid> W05-0622 </papid>that extend the sequential crf model to tree structures.</nextsent>
<nextsent>finally, lin and smith (2005) <papid> W05-0626 </papid>presented proposal radically different from the rest, with very light learning components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1159">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>ensembles of decision trees learned through the ada boost algorithm (ab) were applied by ma`rquez et al (2005) and surdeanu and turmo (2005).<papid> W05-0635 </papid></prevsent>
<prevsent>tjong kim sang et al (2005) applied, among others, memory-based learning (mbl).</prevsent>
</prevsection>
<citsent citstr=" W05-0624 ">
regarding novel learning paradigms not applied in previous shared tasks, we find relevant vector machine (rvm), which is kernel based linear dis criminant inside the framework of sparse bayesian learning (johansson and nugues, 2005) <papid> W05-0624 </papid>and tree conditional random fields (t-crf) (cohn and blunsom, 2005), <papid> W05-0622 </papid>that extend the sequential crf model to tree structures.</citsent>
<aftsection>
<nextsent>finally, lin and smith (2005) <papid> W05-0626 </papid>presented proposal radically different from the rest, with very light learning components.</nextsent>
<nextsent>their approach (consensus in pattern matching, cpm) contains some elements of memory-based learning and ensemble classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1160">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>ensembles of decision trees learned through the ada boost algorithm (ab) were applied by ma`rquez et al (2005) and surdeanu and turmo (2005).<papid> W05-0635 </papid></prevsent>
<prevsent>tjong kim sang et al (2005) applied, among others, memory-based learning (mbl).</prevsent>
</prevsection>
<citsent citstr=" W05-0622 ">
regarding novel learning paradigms not applied in previous shared tasks, we find relevant vector machine (rvm), which is kernel based linear dis criminant inside the framework of sparse bayesian learning (johansson and nugues, 2005) <papid> W05-0624 </papid>and tree conditional random fields (t-crf) (cohn and blunsom, 2005), <papid> W05-0622 </papid>that extend the sequential crf model to tree structures.</citsent>
<aftsection>
<nextsent>finally, lin and smith (2005) <papid> W05-0626 </papid>presented proposal radically different from the rest, with very light learning components.</nextsent>
<nextsent>their approach (consensus in pattern matching, cpm) contains some elements of memory-based learning and ensemble classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1161">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>tjong kim sang et al (2005) applied, among others, memory-based learning (mbl).
</prevsent>
<prevsent>regarding novel learning paradigms not applied in previous shared tasks, we find relevant vector machine (rvm), which is kernel based linear dis criminant inside the framework of sparse bayesian learning (johansson and nugues, 2005) <papid> W05-0624 </papid>and tree conditional random fields (t-crf) (cohn and blunsom, 2005), <papid> W05-0622 </papid>that extend the sequential crf model to tree structures.</prevsent>
</prevsection>
<citsent citstr=" W05-0626 ">
finally, lin and smith (2005) <papid> W05-0626 </papid>presented proposal radically different from the rest, with very light learning components.</citsent>
<aftsection>
<nextsent>their approach (consensus in pattern matching, cpm) contains some elements of memory-based learning and ensemble classification.
</nextsent>
<nextsent>from the machine learning perspective, system combination is another interesting component observed in many of the proposals.
</nextsent>
<nextsent>this fact, which is difference from last year shared task, is explain edas an attempt of increasing the robustness and coverage of the systems, which are quite dependent on in put parsing errors.
</nextsent>
<nextsent>the different outputs to combine are obtained by varying input information, changing learning algorithm, or considering n-best solution lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1189">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>there ranking approach allows to define global complex features applying to complete candidate solutions to train the rankers.
</prevsent>
<prevsent>4.3 features.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
looking at the description of the different systems, it becomes clear that the general type of features used in this edition is strongly based on previous work on the srl task (gildea and jurafsky, 2002; <papid> J02-3001 </papid>surdeanu et al, 2003; <papid> P03-1002 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a; xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>with no exception, all systems have made intensive use of syntax to extract features.
</nextsent>
<nextsent>while most systems work only on the output of parsercharniaks being the most preferred?
</nextsent>
<nextsent>some systems depend on many syntactic parsers.
</nextsent>
<nextsent>in the latter situation, either system is combination of many individual systems (each working with differentparser), or system extracts features from many different parse trees while exploring the nodes of only one parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1190">
<title id=" W05-0620.xml">introduction to the conll2005 shared task semantic role labeling </title>
<section> a review of participant systems </section>
<citcontext>
<prevsection>
<prevsent>there ranking approach allows to define global complex features applying to complete candidate solutions to train the rankers.
</prevsent>
<prevsent>4.3 features.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
looking at the description of the different systems, it becomes clear that the general type of features used in this edition is strongly based on previous work on the srl task (gildea and jurafsky, 2002; <papid> J02-3001 </papid>surdeanu et al, 2003; <papid> P03-1002 </papid>pradhan et al, 2005<papid> W05-0634 </papid>a; xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>with no exception, all systems have made intensive use of syntax to extract features.
</nextsent>
<nextsent>while most systems work only on the output of parsercharniaks being the most preferred?
</nextsent>
<nextsent>some systems depend on many syntactic parsers.
</nextsent>
<nextsent>in the latter situation, either system is combination of many individual systems (each working with differentparser), or system extracts features from many different parse trees while exploring the nodes of only one parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1230">
<title id=" W06-1105.xml">comparison of similarity models for the relation discovery task </title>
<section> kiichiro toyoda toyota corp founder.  </section>
<citcontext>
<prevsection>
<prevsent>business newswire, which could be inserted into corporate intelligence database.
</prevsent>
<prevsent>in the biomedical domain, we may want to identify relationships between genes and proteins from biomedical publications, e.g. hirschman et al  (2004), to help scientists keep up-to-date on the literature.
</prevsent>
</prevsection>
<citsent citstr=" P04-1055 ">
or, we may want to identify disease and treatment relations in publications and textbooks, which can be used tohelp formalise medical knowledge and assist general practitioners in diagnosis, treatment and prognosis (rosario and hearst, 2004).<papid> P04-1055 </papid></citsent>
<aftsection>
<nextsent>another application scenario involves building networks of relationships from text collections that indicate the important entities in domain andcan be used to visualise interactions.
</nextsent>
<nextsent>the networks could provide an alternative to searching when interacting with document collection.
</nextsent>
<nextsent>this could prove beneficial, for example, in investigative journalism.
</nextsent>
<nextsent>it might also be used for social science research using techniques from social network analysis (marsden and lin, 1982).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1231">
<title id=" W06-1105.xml">comparison of similarity models for the relation discovery task </title>
<section> kiichiro toyoda toyota corp founder.  </section>
<citcontext>
<prevsection>
<prevsent>this could prove beneficial, for example, in investigative journalism.
</prevsent>
<prevsent>it might also be used for social science research using techniques from social network analysis (marsden and lin, 1982).
</prevsent>
</prevsection>
<citsent citstr=" W04-1017 ">
in previ 25 ous work, relations have been used for automatic text summarisation as conceptual representation of sentence content in sentence extraction framework (filatova and hatzivassiloglou, 2004).<papid> W04-1017 </papid></citsent>
<aftsection>
<nextsent>in the next section, we motivate and introduce the relation discovery task, which addresses some of the shortcomings of conventional approaches to relation extraction (i.e. supervised learning or rule engineering) by applying minimally supervisedmethods.1 critical part of the relation discovery task is grouping entity pairs by their relationtype.
</nextsent>
<nextsent>this is clustering task and requires robust conceptual representation of relation semantics and measure of similarity between relations.
</nextsent>
<nextsent>in previous work (hasegawa et al , 2004; <papid> P04-1053 </papid>chen et al ., 2005), the conceptual representation has been limited to term-by-document (txd) models of relation semantics.</nextsent>
<nextsent>the current work introduces term co-occurrence (txt) representation for the relation discovery task and shows that it performs significantly better than the txd representation.we also explore dimensionality reduction techniques, which show further improvement.section 3 presents parameter isation of similarity models for relation discovery.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1232">
<title id=" W06-1105.xml">comparison of similarity models for the relation discovery task </title>
<section> kiichiro toyoda toyota corp founder.  </section>
<citcontext>
<prevsection>
<prevsent>in the next section, we motivate and introduce the relation discovery task, which addresses some of the shortcomings of conventional approaches to relation extraction (i.e. supervised learning or rule engineering) by applying minimally supervisedmethods.1 critical part of the relation discovery task is grouping entity pairs by their relationtype.
</prevsent>
<prevsent>this is clustering task and requires robust conceptual representation of relation semantics and measure of similarity between relations.
</prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
in previous work (hasegawa et al , 2004; <papid> P04-1053 </papid>chen et al ., 2005), the conceptual representation has been limited to term-by-document (txd) models of relation semantics.</citsent>
<aftsection>
<nextsent>the current work introduces term co-occurrence (txt) representation for the relation discovery task and shows that it performs significantly better than the txd representation.we also explore dimensionality reduction techniques, which show further improvement.section 3 presents parameter isation of similarity models for relation discovery.
</nextsent>
<nextsent>for the purposes of the current work, this consists of the semantic representation for terms (i.e. how terms context is modelled), dimensionality reduction technique(e.g. singular value decomposition, latent dirich let al ocation), and the measure used to compute similarity.
</nextsent>
<nextsent>we also build on the evaluation paradigm for relation discovery with detailed, controlled experimental setup.
</nextsent>
<nextsent>section 4 describes the experiment design, which compares the various system configurations across six different subsets of the relation extraction data from the automatic content extraction (ace) evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1244">
<title id=" W06-1105.xml">comparison of similarity models for the relation discovery task </title>
<section> kiichiro toyoda toyota corp founder.  </section>
<citcontext>
<prevsection>
<prevsent>p2 ??
</prevsent>
<prevsent>q2 in the current work, we use cosine over term and svd representations of entity pair context.
</prevsent>
</prevsection>
<citsent citstr=" P97-1008 ">
however, it is not clear which similarity measure should be used for the probabilistic topic models.dagan et al  (1997) <papid> P97-1008 </papid>find that the symmetric information radius measure performs best on pseudo word sense disambiguation task, while lee (1999)<papid> P99-1004 </papid>find that the asymmetric skew divergence ? generalisation of kullback-leibler divergence ? performs best for improving probability estimates for unseen word co-occurrences.</citsent>
<aftsection>
<nextsent>in the current work, we compare kl divergence with two methods for deriving symmetric mea 3the hyper parameters ? and ? are dirichlet priors on the multinomial distributions for word features (?
</nextsent>
<nextsent>dir(?)) and topics (?
</nextsent>
<nextsent>dir(?)).
</nextsent>
<nextsent>the choice of the dirichlet is explained by its conjugacy to the multinomial distribution, meaning that if the parameter (e.g. ?, ?) for multinomialdistribution is endowed with dirichlet prior then the posterior will also be dirichlet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1245">
<title id=" W06-1105.xml">comparison of similarity models for the relation discovery task </title>
<section> kiichiro toyoda toyota corp founder.  </section>
<citcontext>
<prevsection>
<prevsent>p2 ??
</prevsent>
<prevsent>q2 in the current work, we use cosine over term and svd representations of entity pair context.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
however, it is not clear which similarity measure should be used for the probabilistic topic models.dagan et al  (1997) <papid> P97-1008 </papid>find that the symmetric information radius measure performs best on pseudo word sense disambiguation task, while lee (1999)<papid> P99-1004 </papid>find that the asymmetric skew divergence ? generalisation of kullback-leibler divergence ? performs best for improving probability estimates for unseen word co-occurrences.</citsent>
<aftsection>
<nextsent>in the current work, we compare kl divergence with two methods for deriving symmetric mea 3the hyper parameters ? and ? are dirichlet priors on the multinomial distributions for word features (?
</nextsent>
<nextsent>dir(?)) and topics (?
</nextsent>
<nextsent>dir(?)).
</nextsent>
<nextsent>the choice of the dirichlet is explained by its conjugacy to the multinomial distribution, meaning that if the parameter (e.g. ?, ?) for multinomialdistribution is endowed with dirichlet prior then the posterior will also be dirichlet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1250">
<title id=" W06-1105.xml">comparison of similarity models for the relation discovery task </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>as documents are explicitly modelled in the lda model, we input matrix with raw frequencies.
</prevsent>
<prevsent>in the txd, unreduced txt and svd models we use tf*idf term weighting.we use the same preprocessing when preparing the text for building the svd and probabilistic topic models as we use for processing the intervening context of entity pairs.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
this consisted of mx terminator (reynar and ratnaparkhi., 1997) <papid> A97-1004 </papid>for sentence boundary detection, the penn treebank 5following results reported by chen et al  (2005), who tried unsuccessfully to incorporate words from the surrounding context to represent relations semantics, we use only intervening words.</citsent>
<aftsection>
<nextsent>6http://infomap.stanford.edu/ 7http://psiexp.ss.uci.edu/research/ programs_data/toolbox.htm sed script8 for token isation, and the infomap stop word list.
</nextsent>
<nextsent>we also use an implementation of the porter algorithm (porter, 1980) for stemming.9 4.2 model selection.
</nextsent>
<nextsent>we used the ace 2004 relation data to perform model selection.
</nextsent>
<nextsent>firstly, dimensionality (d) needs to be optimised for svd and lda.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1254">
<title id=" W06-0124.xml">boosting for chinese named entity recognition </title>
<section> boosting.  </section>
<citcontext>
<prevsection>
<prevsent>adaboost.mh has shown its usefulness on standard machine learning tasks through extensive theoretical and empirical studies, where different standard machine learning methods have been used as the weak classifier (e.g., bauer and kohavi (1999), opitz and maclin (1999), schapire(2002)).
</prevsent>
<prevsent>it also performs well on number of natural language processing problems, including text categorization (e.g., schapire and singer (2000),sebastiani et al (2000)) and word sense disambiguation (e.g., escudero et al (2000)).
</prevsent>
</prevsection>
<citsent citstr=" W02-2035 ">
in particular, it has also been demonstrated that boosting can be used to build language-independent ner models that perform exceptionally well (wu et al (2002), <papid> W02-2035 </papid>wu et al (2004), <papid> C04-1058 </papid>carreras et al (2002)).<papid> W02-2004 </papid>the weak classifiers used in the boosting algorithm come from wide range of machine learning methods.</citsent>
<aftsection>
<nextsent>we have chosen to use simple classifier called decision stump in the algorithm.
</nextsent>
<nextsent>a decision stump is basically one-level decision tree where the split at the root level is based on specific attribute/value pair.
</nextsent>
<nextsent>for example, possible attribute/value pair could bew2 =?/.
</nextsent>
<nextsent>in order to implement the boosting/decision stumps, we used the publicly available software at&t; boostexter (schapire and singer, 2000), which implements boosting on top of decisionstumps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1255">
<title id=" W06-0124.xml">boosting for chinese named entity recognition </title>
<section> boosting.  </section>
<citcontext>
<prevsection>
<prevsent>adaboost.mh has shown its usefulness on standard machine learning tasks through extensive theoretical and empirical studies, where different standard machine learning methods have been used as the weak classifier (e.g., bauer and kohavi (1999), opitz and maclin (1999), schapire(2002)).
</prevsent>
<prevsent>it also performs well on number of natural language processing problems, including text categorization (e.g., schapire and singer (2000),sebastiani et al (2000)) and word sense disambiguation (e.g., escudero et al (2000)).
</prevsent>
</prevsection>
<citsent citstr=" C04-1058 ">
in particular, it has also been demonstrated that boosting can be used to build language-independent ner models that perform exceptionally well (wu et al (2002), <papid> W02-2035 </papid>wu et al (2004), <papid> C04-1058 </papid>carreras et al (2002)).<papid> W02-2004 </papid>the weak classifiers used in the boosting algorithm come from wide range of machine learning methods.</citsent>
<aftsection>
<nextsent>we have chosen to use simple classifier called decision stump in the algorithm.
</nextsent>
<nextsent>a decision stump is basically one-level decision tree where the split at the root level is based on specific attribute/value pair.
</nextsent>
<nextsent>for example, possible attribute/value pair could bew2 =?/.
</nextsent>
<nextsent>in order to implement the boosting/decision stumps, we used the publicly available software at&t; boostexter (schapire and singer, 2000), which implements boosting on top of decisionstumps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1256">
<title id=" W06-0124.xml">boosting for chinese named entity recognition </title>
<section> boosting.  </section>
<citcontext>
<prevsection>
<prevsent>adaboost.mh has shown its usefulness on standard machine learning tasks through extensive theoretical and empirical studies, where different standard machine learning methods have been used as the weak classifier (e.g., bauer and kohavi (1999), opitz and maclin (1999), schapire(2002)).
</prevsent>
<prevsent>it also performs well on number of natural language processing problems, including text categorization (e.g., schapire and singer (2000),sebastiani et al (2000)) and word sense disambiguation (e.g., escudero et al (2000)).
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
in particular, it has also been demonstrated that boosting can be used to build language-independent ner models that perform exceptionally well (wu et al (2002), <papid> W02-2035 </papid>wu et al (2004), <papid> C04-1058 </papid>carreras et al (2002)).<papid> W02-2004 </papid>the weak classifiers used in the boosting algorithm come from wide range of machine learning methods.</citsent>
<aftsection>
<nextsent>we have chosen to use simple classifier called decision stump in the algorithm.
</nextsent>
<nextsent>a decision stump is basically one-level decision tree where the split at the root level is based on specific attribute/value pair.
</nextsent>
<nextsent>for example, possible attribute/value pair could bew2 =?/.
</nextsent>
<nextsent>in order to implement the boosting/decision stumps, we used the publicly available software at&t; boostexter (schapire and singer, 2000), which implements boosting on top of decisionstumps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1257">
<title id=" W06-0124.xml">boosting for chinese named entity recognition </title>
<section> experiment details.  </section>
<citcontext>
<prevsection>
<prevsent>for example, possible attribute/value pair could bew2 =?/.
</prevsent>
<prevsent>in order to implement the boosting/decision stumps, we used the publicly available software at&t; boostexter (schapire and singer, 2000), which implements boosting on top of decisionstumps.
</prevsent>
</prevsection>
<citsent citstr=" W03-1709 ">
for preprocessing we used an off-the shelf chinese lexical analysis system, the open source ictclas (zhang et al, 2003), <papid> W03-1709 </papid>to segment and pos tag the training and test corpora.</citsent>
<aftsection>
<nextsent>151 3.1 data preprocessing.
</nextsent>
<nextsent>the training corpora provided by the sighanbakeoff organizers were in the conll two column format, with one chinese character per line and hand-annotated named entity chunks in the second column.
</nextsent>
<nextsent>in order to provide basic features for training the decision stumps, the training corpora were segmented and pos tagged by ictclas, which labels chinese words using set of 39 tags.
</nextsent>
<nextsent>this module employs hierarchical hidden markov model (hhmm) and provides word segmentation, pos tagging and unknown word recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1258">
<title id=" W04-3002.xml">hybrid statistical and structural semantic modeling for thai multistage spoken language understanding </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>to generate such semantic frame, words in the utterance are usually aligned to semantic tree by parsing algorithm such as probabilistic context free grammar or recursive network whose nodes represent semantic symbols of the words and arcs consist of transition probabilities.
</prevsent>
<prevsent>during parsing, these probabilities are summed up, and used to determine the most likely parsed tree.
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
many understanding engines have been successfully implemented based on this paradigm (seneff, 1992; <papid> J92-1004 </papid>potamianos et al, 2000; miller et al, 1994).<papid> P94-1004 </papid></citsent>
<aftsection>
<nextsent>a draw back of this method is, however, the requirement of large, fully annotated corpus, i.e. corpus with semantic tags on every word, to ensure training reliability.
</nextsent>
<nextsent>the second practice has been utilized in applications such as call classification (gorin et al, 1997).
</nextsent>
<nextsent>in this application, the understanding module aims to classify an input utterance to one of predefined user goals (if an utterance is supposed to have one goal) directly from the words contained in the utterance.
</nextsent>
<nextsent>this problem can be considered simple pattern classification task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1259">
<title id=" W04-3002.xml">hybrid statistical and structural semantic modeling for thai multistage spoken language understanding </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>to generate such semantic frame, words in the utterance are usually aligned to semantic tree by parsing algorithm such as probabilistic context free grammar or recursive network whose nodes represent semantic symbols of the words and arcs consist of transition probabilities.
</prevsent>
<prevsent>during parsing, these probabilities are summed up, and used to determine the most likely parsed tree.
</prevsent>
</prevsection>
<citsent citstr=" P94-1004 ">
many understanding engines have been successfully implemented based on this paradigm (seneff, 1992; <papid> J92-1004 </papid>potamianos et al, 2000; miller et al, 1994).<papid> P94-1004 </papid></citsent>
<aftsection>
<nextsent>a draw back of this method is, however, the requirement of large, fully annotated corpus, i.e. corpus with semantic tags on every word, to ensure training reliability.
</nextsent>
<nextsent>the second practice has been utilized in applications such as call classification (gorin et al, 1997).
</nextsent>
<nextsent>in this application, the understanding module aims to classify an input utterance to one of predefined user goals (if an utterance is supposed to have one goal) directly from the words contained in the utterance.
</nextsent>
<nextsent>this problem can be considered simple pattern classification task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1260">
<title id=" W04-2710.xml">annotating wordnet </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 tagger expertise.
</prevsent>
<prevsent>finally, there is the question of whether novice taggers with adequate training can attain the level of accuracy of experienced lexicographers and linguists.
</prevsent>
</prevsection>
<citsent citstr=" W97-0206 ">
fellbaum et al (1997) <papid> W97-0206 </papid>answer this in the negative.</citsent>
<aftsection>
<nextsent>their findings show novice tagger accuracy decreasing as the number of senses, or fineness of distinctions among the senses, increases.
</nextsent>
<nextsent>level of expertise likely influenced the slow pace of tagging reported for the kilo and reader projects, which employed novice taggers.
</nextsent>
<nextsent>during the tagging of the evaluation dataset for senseval-1, the highly experienced lexicographers who did the tagging reported the time spent absorbing new contexts dropped off rapidly after slow start-up period (krishnamurthy and nicholls, 2000).
</nextsent>
<nextsent>2.5 the present approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1261">
<title id=" W05-0904.xml">syntactic features for evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation has long been stumbling block in the development of machine translation systems, due tothe simple fact that there are many correct translations forgiven sentence.
</prevsent>
<prevsent>human evaluation of system output is costly in both time and money, leading to the rise of automatic evaluation metrics in recentyears.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the most commonly used automatic evaluation metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002), are based on the assumption that the closer machine translation is to professional human translation, the better it is?</citsent>
<aftsection>
<nextsent>(papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>for every hypothesis, bleu computes the fraction of n-grams which also appear in the reference sentences, as well as brevity penalty.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1264">
<title id=" W05-0904.xml">syntactic features for evaluation of machine translation </title>
<section> evaluating machine translation with.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 dependency-based metrics.
</prevsent>
<prevsent>dependency trees consist of trees of head-modifier relations with word at each node, rather than justat the leaves.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
dependency trees were found to correspond better across translation pairs than constituent trees by fox (2002), <papid> W02-1039 </papid>and form the basis of thema chine translation systems of alshawi et al (2000) <papid> J00-1004 </papid>27 reference: np pron vp np art hypothesis: np pron vp np pron figure 2: examples for the computation of stm and lin (2004).<papid> C04-1090 </papid></citsent>
<aftsection>
<nextsent>we derived dependency trees fromthe constituent trees by applying the deterministic headword extraction rules used by the parser of collins (1999).
</nextsent>
<nextsent>for the example of the reference syntax tree in figure 2, the whole tree with the root represents sentence; and the subtree npart represents noun phrase.
</nextsent>
<nextsent>then for every node in the syntax tree, we can determine its headword by its syntactic structure; from the subtree npart n, for example, the headword selection rules chose the headword of np to be word corresponding to thepos in the subtree, and the other child, which corresponds to art, is the modifier for the headword.the dependency tree then is kind of structure constituted by headwords and every subtree represents the modifier information for its root headword.
</nextsent>
<nextsent>for example, the dependency tree of the sentence have red penis shown as below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1265">
<title id=" W05-0904.xml">syntactic features for evaluation of machine translation </title>
<section> evaluating machine translation with.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 dependency-based metrics.
</prevsent>
<prevsent>dependency trees consist of trees of head-modifier relations with word at each node, rather than justat the leaves.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
dependency trees were found to correspond better across translation pairs than constituent trees by fox (2002), <papid> W02-1039 </papid>and form the basis of thema chine translation systems of alshawi et al (2000) <papid> J00-1004 </papid>27 reference: np pron vp np art hypothesis: np pron vp np pron figure 2: examples for the computation of stm and lin (2004).<papid> C04-1090 </papid></citsent>
<aftsection>
<nextsent>we derived dependency trees fromthe constituent trees by applying the deterministic headword extraction rules used by the parser of collins (1999).
</nextsent>
<nextsent>for the example of the reference syntax tree in figure 2, the whole tree with the root represents sentence; and the subtree npart represents noun phrase.
</nextsent>
<nextsent>then for every node in the syntax tree, we can determine its headword by its syntactic structure; from the subtree npart n, for example, the headword selection rules chose the headword of np to be word corresponding to thepos in the subtree, and the other child, which corresponds to art, is the modifier for the headword.the dependency tree then is kind of structure constituted by headwords and every subtree represents the modifier information for its root headword.
</nextsent>
<nextsent>for example, the dependency tree of the sentence have red penis shown as below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1266">
<title id=" W05-0904.xml">syntactic features for evaluation of machine translation </title>
<section> evaluating machine translation with.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 dependency-based metrics.
</prevsent>
<prevsent>dependency trees consist of trees of head-modifier relations with word at each node, rather than justat the leaves.
</prevsent>
</prevsection>
<citsent citstr=" C04-1090 ">
dependency trees were found to correspond better across translation pairs than constituent trees by fox (2002), <papid> W02-1039 </papid>and form the basis of thema chine translation systems of alshawi et al (2000) <papid> J00-1004 </papid>27 reference: np pron vp np art hypothesis: np pron vp np pron figure 2: examples for the computation of stm and lin (2004).<papid> C04-1090 </papid></citsent>
<aftsection>
<nextsent>we derived dependency trees fromthe constituent trees by applying the deterministic headword extraction rules used by the parser of collins (1999).
</nextsent>
<nextsent>for the example of the reference syntax tree in figure 2, the whole tree with the root represents sentence; and the subtree npart represents noun phrase.
</nextsent>
<nextsent>then for every node in the syntax tree, we can determine its headword by its syntactic structure; from the subtree npart n, for example, the headword selection rules chose the headword of np to be word corresponding to thepos in the subtree, and the other child, which corresponds to art, is the modifier for the headword.the dependency tree then is kind of structure constituted by headwords and every subtree represents the modifier information for its root headword.
</nextsent>
<nextsent>for example, the dependency tree of the sentence have red penis shown as below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1267">
<title id=" W05-0904.xml">syntactic features for evaluation of machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>and for each mt hypothesis, three reference translations are associated with it.
</prevsent>
<prevsent>28 input: dependency tree t, maximum length of the headword chain output: headword chains from length 1 to for = 1 to for every node in if == 1 add ns word to ns 1 word headword chains; else for every direct child of for every i-1 words headword chain hc of new chain = joint(ns word, hc); add new chain to the words headword chains of n; endfor endfor endif endfor endfor figure 3: algorithm for extracting the headword chains the human judgments, on scale of 1 to 5, were collected at the 2003 johns hopkins speech and language summer workshop, which tells the overall quality of the mt hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the translations were generated by the alignment template system of och (2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>this testing set is called jhu testing set in this paper.
</nextsent>
<nextsent>the other set of testing data is from mt evaluation workshop at acl05.
</nextsent>
<nextsent>three sets of human translations (e01, e03, e04) are selected as the references, and the outputs of seven mt systems (e9 e11 e12 e14 e15 e17 e22) are used for testing the performance of our syntactic metrics.
</nextsent>
<nextsent>each set of mt translations contains 929 english sentences, each of which is associated with human judgments for its fluency and adequacy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1268">
<title id=" W05-0904.xml">syntactic features for evaluation of machine translation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>31 hyp diplomats will be aboard the plane to return home . ref1 diplomats are to come back home aboard the fifth plane . ref2 diplomatic staff would go home in fifth plane . ref3 diplomatic staff will take the fifth plane home . table 7: an example hypothesis in the acl05-mte workshop which was assigned high score by hwcm (0.511) but low score by bleu (0.084).
</prevsent>
<prevsent>both human judges assigned high score (4).
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
indeed, in some recent work on re-ranking machine translation hypotheses (och et al, 2004), <papid> N04-1021 </papid>parser produced structures were not found to provide helpful information, as parser is likely to assign good looking structure to even lousy input hypothesis.however, there is an important distinction between the use of parsers in re-ranking and evaluation ? in the present work we are looking for similarities between pairs of parse trees rather than at features of single tree.</citsent>
<aftsection>
<nextsent>this means that the syntax-based evaluation measures can succeed even when the tree structure for poor hypothesis looks reasonable on its own, as long as it is sufficiently distinct from the structures used in the references.
</nextsent>
<nextsent>we speculate that by discriminatively training weights for the individual subtrees and headword chains used by the syntax-based metrics, further improvements in evaluation accuracy are possible.
</nextsent>
<nextsent>acknowledgments we are very grateful to alex kulesza for assistance with the jhu data.
</nextsent>
<nextsent>this work was partially supported by nsf itr iis-09325646 and nsf itr iis-0428020.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1269">
<title id=" W05-0611.xml">improving sequence segmentation learning by predicting trigrams </title>
<section> optimizing output sequences.  </section>
<citcontext>
<prevsection>
<prevsent>this well-known problem has triggered at least the following three main types of solutions.
</prevsent>
<prevsent>feedback loop each training or test example may represent not only the regular windowed input, butalso copy of previously made classifications, to allow the classifier to be more consistent with its previous decisions.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
direct feedback loops that copya predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by ratnaparkhi(1996) <papid> W96-0213 </papid>and the memory-based tagger (mbt) proposed by daelemans et al (1996).<papid> W96-0102 </papid></citsent>
<aftsection>
<nextsent>this solution assumes that processing is directed, e.g. from left to right.
</nextsent>
<nextsent>a noted problem of this approach is the label bias problem (lafferty et al, 2001), which is that afeedback-loop classifier may be driven to be consistent with its previous decision also in the case this decision was wrong; sequences of errors may result.stacking, boosting, and voting the partly incorrect concatenated output sequence of single classifier may serve as input to second-stage classifier in stacking architecture, common machine-learning optimization technique (wolpert, 1992).
</nextsent>
<nextsent>although less elegant than monolithic single-classifier architecture, this method is known to be capable of recognizing recurring errors of the first-stage classifier and correcting them (veenstra, 1998).
</nextsent>
<nextsent>boosting (freund and schapire, 1996) has been applied to optimize chunking systems (carreras et al, 2002), <papid> W02-2004 </papid>as well as voting over sets of different classifiers (florian et al, 2003).<papid> W03-0425 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1270">
<title id=" W05-0611.xml">improving sequence segmentation learning by predicting trigrams </title>
<section> optimizing output sequences.  </section>
<citcontext>
<prevsection>
<prevsent>this well-known problem has triggered at least the following three main types of solutions.
</prevsent>
<prevsent>feedback loop each training or test example may represent not only the regular windowed input, butalso copy of previously made classifications, to allow the classifier to be more consistent with its previous decisions.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
direct feedback loops that copya predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by ratnaparkhi(1996) <papid> W96-0213 </papid>and the memory-based tagger (mbt) proposed by daelemans et al (1996).<papid> W96-0102 </papid></citsent>
<aftsection>
<nextsent>this solution assumes that processing is directed, e.g. from left to right.
</nextsent>
<nextsent>a noted problem of this approach is the label bias problem (lafferty et al, 2001), which is that afeedback-loop classifier may be driven to be consistent with its previous decision also in the case this decision was wrong; sequences of errors may result.stacking, boosting, and voting the partly incorrect concatenated output sequence of single classifier may serve as input to second-stage classifier in stacking architecture, common machine-learning optimization technique (wolpert, 1992).
</nextsent>
<nextsent>although less elegant than monolithic single-classifier architecture, this method is known to be capable of recognizing recurring errors of the first-stage classifier and correcting them (veenstra, 1998).
</nextsent>
<nextsent>boosting (freund and schapire, 1996) has been applied to optimize chunking systems (carreras et al, 2002), <papid> W02-2004 </papid>as well as voting over sets of different classifiers (florian et al, 2003).<papid> W03-0425 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1271">
<title id=" W05-0611.xml">improving sequence segmentation learning by predicting trigrams </title>
<section> optimizing output sequences.  </section>
<citcontext>
<prevsection>
<prevsent>a noted problem of this approach is the label bias problem (lafferty et al, 2001), which is that afeedback-loop classifier may be driven to be consistent with its previous decision also in the case this decision was wrong; sequences of errors may result.stacking, boosting, and voting the partly incorrect concatenated output sequence of single classifier may serve as input to second-stage classifier in stacking architecture, common machine-learning optimization technique (wolpert, 1992).
</prevsent>
<prevsent>although less elegant than monolithic single-classifier architecture, this method is known to be capable of recognizing recurring errors of the first-stage classifier and correcting them (veenstra, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
boosting (freund and schapire, 1996) has been applied to optimize chunking systems (carreras et al, 2002), <papid> W02-2004 </papid>as well as voting over sets of different classifiers (florian et al, 2003).<papid> W03-0425 </papid></citsent>
<aftsection>
<nextsent>punyakanok and roth (2001) present two methods for combining the predictions of different classifiers according to constraints that ensure that the resulting output is made more coher ent.output sequence optimization rather than basing classifications only on model parameters estimated from co-occurrences between input and output symbols employed for maximizing the likelihood of point-wise single-label predictions at the output level, classifier output may be augmented by an optimization over the output sequence as whole using optimization techniques such as beam searching in the space of conditional markov models output (ratnaparkhi, 1996) <papid> W96-0213 </papid>or hidden markov models (skut and brants, 1998).</nextsent>
<nextsent>maximum-entropymarkov models (mccallum et al, 2000) and conditional random fields (lafferty et al, 2001) optimize the likelihood of segment ations of output symbol sequences through variations of viterbi search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1272">
<title id=" W05-0611.xml">improving sequence segmentation learning by predicting trigrams </title>
<section> optimizing output sequences.  </section>
<citcontext>
<prevsection>
<prevsent>a noted problem of this approach is the label bias problem (lafferty et al, 2001), which is that afeedback-loop classifier may be driven to be consistent with its previous decision also in the case this decision was wrong; sequences of errors may result.stacking, boosting, and voting the partly incorrect concatenated output sequence of single classifier may serve as input to second-stage classifier in stacking architecture, common machine-learning optimization technique (wolpert, 1992).
</prevsent>
<prevsent>although less elegant than monolithic single-classifier architecture, this method is known to be capable of recognizing recurring errors of the first-stage classifier and correcting them (veenstra, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
boosting (freund and schapire, 1996) has been applied to optimize chunking systems (carreras et al, 2002), <papid> W02-2004 </papid>as well as voting over sets of different classifiers (florian et al, 2003).<papid> W03-0425 </papid></citsent>
<aftsection>
<nextsent>punyakanok and roth (2001) present two methods for combining the predictions of different classifiers according to constraints that ensure that the resulting output is made more coher ent.output sequence optimization rather than basing classifications only on model parameters estimated from co-occurrences between input and output symbols employed for maximizing the likelihood of point-wise single-label predictions at the output level, classifier output may be augmented by an optimization over the output sequence as whole using optimization techniques such as beam searching in the space of conditional markov models output (ratnaparkhi, 1996) <papid> W96-0213 </papid>or hidden markov models (skut and brants, 1998).</nextsent>
<nextsent>maximum-entropymarkov models (mccallum et al, 2000) and conditional random fields (lafferty et al, 2001) optimize the likelihood of segment ations of output symbol sequences through variations of viterbi search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1274">
<title id=" W05-0611.xml">improving sequence segmentation learning by predicting trigrams </title>
<section> data and methodology.  </section>
<citcontext>
<prevsection>
<prevsent>chunk is the task of splitting sentences into non-overlapping syntactic phrases or constituents.
</prevsent>
<prevsent>the used dataset, extracted from the wsj penn treebank, contains 211,727 training examples and 47,377 test instances.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
the examples represent seven-word windows of words and their respective (predicted) part-of-speech tags, and each example is labeled with class using the iob type of segmentation coding as introduced by ramshaw and marcus (1995), <papid> W95-0107 </papid>marking whether the middle word is inside (i), outside (o), or at the beginning (b) of chunk.</citsent>
<aftsection>
<nextsent>words occuring less than ten times in the training material are attenuated (converted into more general string that retains some of the words surface form).
</nextsent>
<nextsent>generalization performance is measured by the f-score on correctly identified and labeled constituents in test data, using the evaluation method originally used in the shared task?
</nextsent>
<nextsent>sub event of the conll-2000 conference (tjong kimsang and buchholz, 2000) in which this particular training and test set were used.
</nextsent>
<nextsent>an example sentence with base phrases marked and labeled is the following: [he]np [reckons]v [the current account deficit]np [will narrow]v [to]pp [only $ 1.8 billion]np [in]pp [september]np . ner, named-entity recognition, is to recognize and type named entities in text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1276">
<title id=" W05-0611.xml">improving sequence segmentation learning by predicting trigrams </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>apparently, they both introduce complementary disagreements in overlapping trigrams, which the simple voting mechanism can convert to more correct predictions than the two methods do individually.further research should focus on deep quantitative and qualitative analysis of the different errors the different methods correct when compared to the baseline single-class classifier, as well as the errors they may introduce.
</prevsent>
<prevsent>alternatives to the 86 iob-style encoding should also be incorporated inthese experiments (tjong kim sang, 2000).
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
additionally, broader comparison with point-wise predictors (kashima and tsuboi, 2004) as well as viterbi-based probabilistic models (mccallum et al, 2000; lafferty et al, 2001; sha and pereira, 2003) <papid> N03-1028 </papid>in large-scale comparative studies is warranted.</citsent>
<aftsection>
<nextsent>also, the scope of the study may be broadened to all sequential language processing tasks, including tasks in which no segmentation takes place (e.g.part-of-speech tagging), and tasks at the morpho phonological level (e.g. grapheme-phoneme conversion and morphological analysis).
</nextsent>
<nextsent>acknowledgements the authors wish to thank sander canisius for discussions and suggestions.
</nextsent>
<nextsent>the work of the first author is funded by nwo, the netherlands organisation for scientific research; the second authors work is partially funded by the eu biomint project.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1277">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper discusses the issues involved in merging four of these efforts into unified linguistic structure: propbank, nombank, the discourse treebank and coreference annotation undertaken at the university of essex.
</prevsent>
<prevsent>we discuss resolving overlapping and conflicting annotation as well as how the various annotation schemes can reinforce each other to produce representation that is greater than the sum of its parts.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the creation of the penn treebank (marcus et al  1993) <papid> J93-2004 </papid>and the word sense-annotated semcor (fellbaum, 1997) have shown how even limited amounts of annotated data can result in major improvements in complex natural language understanding systems.</citsent>
<aftsection>
<nextsent>these annotated corpora have led to high-level improvements for parsing and word sense disambiguation (wsd), on the same scale as previously occurred for part of speech tagging by the annotation of the brown corpus and, more recently, the british national corpus (bnc) (burnard, 2000).
</nextsent>
<nextsent>however, the creation of semantically annotated corpora has lagged dramatically behind the creation of other linguistic resources: in part due to the perceived cost, in part due to an assumed lack of theoretical agreement on basic semantic judgments, in part, finally, due to the understandable unwillingness of research groups to get involved in such an undertaking.
</nextsent>
<nextsent>as result, the need for such resources has become urgent.
</nextsent>
<nextsent>many recent annotation efforts for english have focused on pieces of the larger problem of semantic annotation, rather than producing single unified representation like head-driven phrase structure grammar (pollard and sag 1994) or the prague dependency tectogramatical representation (hajicova &amp; kucerova, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1278">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as result, the need for such resources has become urgent.
</prevsent>
<prevsent>many recent annotation efforts for english have focused on pieces of the larger problem of semantic annotation, rather than producing single unified representation like head-driven phrase structure grammar (pollard and sag 1994) or the prague dependency tectogramatical representation (hajicova &amp; kucerova, 2002).
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
propbank (palmer et al  2005) <papid> J05-1004 </papid>annotates predicate argument structure anchored by verbs.</citsent>
<aftsection>
<nextsent>nombank (meyers, et. al., 2004<papid> W04-2705 </papid>a) annotates predicate argument structure anchored by nouns.</nextsent>
<nextsent>time bank (pustejovsky et al  2003) annotates the temporal features of propositions and the temporal relations between propositions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1279">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many recent annotation efforts for english have focused on pieces of the larger problem of semantic annotation, rather than producing single unified representation like head-driven phrase structure grammar (pollard and sag 1994) or the prague dependency tectogramatical representation (hajicova &amp; kucerova, 2002).
</prevsent>
<prevsent>propbank (palmer et al  2005) <papid> J05-1004 </papid>annotates predicate argument structure anchored by verbs.</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
nombank (meyers, et. al., 2004<papid> W04-2705 </papid>a) annotates predicate argument structure anchored by nouns.</citsent>
<aftsection>
<nextsent>time bank (pustejovsky et al  2003) annotates the temporal features of propositions and the temporal relations between propositions.
</nextsent>
<nextsent>the penn discourse treebank (miltsakaki et al  2004<papid> W04-2703 </papid>a/b) treats discourse connectives as predicates and the sentences being joined as arguments.</nextsent>
<nextsent>researchers at essex were responsible for the coreference markup scheme developed inmate (poesio et al  1999; <papid> W99-0309 </papid>poesio, 2004<papid> W04-2327 </papid>a) and have annotated corpora using this scheme including subset of the penn treebank (poesio and vieira, 1998), <papid> J98-2001 </papid>and the gnome corpus (poesio, 2004<papid> W04-2327 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1283">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nombank (meyers, et. al., 2004<papid> W04-2705 </papid>a) annotates predicate argument structure anchored by nouns.</prevsent>
<prevsent>time bank (pustejovsky et al  2003) annotates the temporal features of propositions and the temporal relations between propositions.</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
the penn discourse treebank (miltsakaki et al  2004<papid> W04-2703 </papid>a/b) treats discourse connectives as predicates and the sentences being joined as arguments.</citsent>
<aftsection>
<nextsent>researchers at essex were responsible for the coreference markup scheme developed inmate (poesio et al  1999; <papid> W99-0309 </papid>poesio, 2004<papid> W04-2327 </papid>a) and have annotated corpora using this scheme including subset of the penn treebank (poesio and vieira, 1998), <papid> J98-2001 </papid>and the gnome corpus (poesio, 2004<papid> W04-2327 </papid>a).</nextsent>
<nextsent>this paper discusses the issues involved in creating unified linguistic annotation (ula) by merging annotation of examples using the schemata from these efforts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1284">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>time bank (pustejovsky et al  2003) annotates the temporal features of propositions and the temporal relations between propositions.
</prevsent>
<prevsent>the penn discourse treebank (miltsakaki et al  2004<papid> W04-2703 </papid>a/b) treats discourse connectives as predicates and the sentences being joined as arguments.</prevsent>
</prevsection>
<citsent citstr=" W99-0309 ">
researchers at essex were responsible for the coreference markup scheme developed inmate (poesio et al  1999; <papid> W99-0309 </papid>poesio, 2004<papid> W04-2327 </papid>a) and have annotated corpora using this scheme including subset of the penn treebank (poesio and vieira, 1998), <papid> J98-2001 </papid>and the gnome corpus (poesio, 2004<papid> W04-2327 </papid>a).</citsent>
<aftsection>
<nextsent>this paper discusses the issues involved in creating unified linguistic annotation (ula) by merging annotation of examples using the schemata from these efforts.
</nextsent>
<nextsent>crucially, all individual annotations can be kept separate in order to make it easy to produce alternative annotations of specific type of semantic information without need to modify the annotation at the other levels.
</nextsent>
<nextsent>embarking on separate annotation efforts has the advantage of allowing researchers to focus on the difficult issues in each area of semantic annotation and the disadvantage of inducing certain amount of tunnel vision or task-centricity ? annotators working on narrow task tend to see all phenomena in light of the task they are working on, ignoring other factors.
</nextsent>
<nextsent>however, merging these annotation efforts allows these biases to be dealt with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1286">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>time bank (pustejovsky et al  2003) annotates the temporal features of propositions and the temporal relations between propositions.
</prevsent>
<prevsent>the penn discourse treebank (miltsakaki et al  2004<papid> W04-2703 </papid>a/b) treats discourse connectives as predicates and the sentences being joined as arguments.</prevsent>
</prevsection>
<citsent citstr=" W04-2327 ">
researchers at essex were responsible for the coreference markup scheme developed inmate (poesio et al  1999; <papid> W99-0309 </papid>poesio, 2004<papid> W04-2327 </papid>a) and have annotated corpora using this scheme including subset of the penn treebank (poesio and vieira, 1998), <papid> J98-2001 </papid>and the gnome corpus (poesio, 2004<papid> W04-2327 </papid>a).</citsent>
<aftsection>
<nextsent>this paper discusses the issues involved in creating unified linguistic annotation (ula) by merging annotation of examples using the schemata from these efforts.
</nextsent>
<nextsent>crucially, all individual annotations can be kept separate in order to make it easy to produce alternative annotations of specific type of semantic information without need to modify the annotation at the other levels.
</nextsent>
<nextsent>embarking on separate annotation efforts has the advantage of allowing researchers to focus on the difficult issues in each area of semantic annotation and the disadvantage of inducing certain amount of tunnel vision or task-centricity ? annotators working on narrow task tend to see all phenomena in light of the task they are working on, ignoring other factors.
</nextsent>
<nextsent>however, merging these annotation efforts allows these biases to be dealt with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1294">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>time bank (pustejovsky et al  2003) annotates the temporal features of propositions and the temporal relations between propositions.
</prevsent>
<prevsent>the penn discourse treebank (miltsakaki et al  2004<papid> W04-2703 </papid>a/b) treats discourse connectives as predicates and the sentences being joined as arguments.</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
researchers at essex were responsible for the coreference markup scheme developed inmate (poesio et al  1999; <papid> W99-0309 </papid>poesio, 2004<papid> W04-2327 </papid>a) and have annotated corpora using this scheme including subset of the penn treebank (poesio and vieira, 1998), <papid> J98-2001 </papid>and the gnome corpus (poesio, 2004<papid> W04-2327 </papid>a).</citsent>
<aftsection>
<nextsent>this paper discusses the issues involved in creating unified linguistic annotation (ula) by merging annotation of examples using the schemata from these efforts.
</nextsent>
<nextsent>crucially, all individual annotations can be kept separate in order to make it easy to produce alternative annotations of specific type of semantic information without need to modify the annotation at the other levels.
</nextsent>
<nextsent>embarking on separate annotation efforts has the advantage of allowing researchers to focus on the difficult issues in each area of semantic annotation and the disadvantage of inducing certain amount of tunnel vision or task-centricity ? annotators working on narrow task tend to see all phenomena in light of the task they are working on, ignoring other factors.
</nextsent>
<nextsent>however, merging these annotation efforts allows these biases to be dealt with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1305">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> the component annotation schemata.  </section>
<citcontext>
<prevsection>
<prevsent>the 1m word penn treebank ii wall street journal corpus has been successfully annotated with semantic argument structures for verbs and is now available via the penn linguistic data consortium as propbank (palmer, et. al., 2005).<papid> J05-1004 </papid></prevsent>
<prevsent>coarse-grained sense tags, based on groupings of wordnet senses, are being added, as well as links from the argument labels in the frames files to framenet frame elements.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
there are close parallels to other semantic role labeling projects, such as framenet (baker, et. al., 1998; <papid> P98-1013 </papid>fillmore &amp; atkins, 1998; fillmore &amp; baker, 2001), salsa (ellsworth, et.al, 2004), prague tectogrammatics (hajicova &amp; kucerova, 2002) and iamtc, (helmreich, et. al., 2004) <papid> W04-2709 </papid>nombank: the nyu nombank project can be considered part of the larger propbank effort and is designed to provide argument structure for instances of about 5000 common nouns in the penn treebank ii corpus (meyers, et. al., 2004<papid> W04-2705 </papid>a).</citsent>
<aftsection>
<nextsent>propbank argument types and related verb frames files are used to provide commonality of annotation.
</nextsent>
<nextsent>this enables the development of systems that can recognize regularizations of lexically and syntactically related sentence structures, whether they occur as verb phrases or noun phrases.
</nextsent>
<nextsent>for example, given an ie system tuned to hiring scenario (muc-6, 1995), nombank and propbank annotation facilitate generalization over patterns.
</nextsent>
<nextsent>propbank and nombank would both support single ie pattern stating that the object (arg1) of appoint is john and the subject (arg0) is ibm, allowing system to detect that ibm hired john from each of the following strings: ibm appointed john, john was appointed by ibm, ibm appointment of john, the appointment of john by ibm and john is the current ibm appointee.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1306">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> the component annotation schemata.  </section>
<citcontext>
<prevsection>
<prevsent>the 1m word penn treebank ii wall street journal corpus has been successfully annotated with semantic argument structures for verbs and is now available via the penn linguistic data consortium as propbank (palmer, et. al., 2005).<papid> J05-1004 </papid></prevsent>
<prevsent>coarse-grained sense tags, based on groupings of wordnet senses, are being added, as well as links from the argument labels in the frames files to framenet frame elements.</prevsent>
</prevsection>
<citsent citstr=" W04-2709 ">
there are close parallels to other semantic role labeling projects, such as framenet (baker, et. al., 1998; <papid> P98-1013 </papid>fillmore &amp; atkins, 1998; fillmore &amp; baker, 2001), salsa (ellsworth, et.al, 2004), prague tectogrammatics (hajicova &amp; kucerova, 2002) and iamtc, (helmreich, et. al., 2004) <papid> W04-2709 </papid>nombank: the nyu nombank project can be considered part of the larger propbank effort and is designed to provide argument structure for instances of about 5000 common nouns in the penn treebank ii corpus (meyers, et. al., 2004<papid> W04-2705 </papid>a).</citsent>
<aftsection>
<nextsent>propbank argument types and related verb frames files are used to provide commonality of annotation.
</nextsent>
<nextsent>this enables the development of systems that can recognize regularizations of lexically and syntactically related sentence structures, whether they occur as verb phrases or noun phrases.
</nextsent>
<nextsent>for example, given an ie system tuned to hiring scenario (muc-6, 1995), nombank and propbank annotation facilitate generalization over patterns.
</nextsent>
<nextsent>propbank and nombank would both support single ie pattern stating that the object (arg1) of appoint is john and the subject (arg0) is ibm, allowing system to detect that ibm hired john from each of the following strings: ibm appointed john, john was appointed by ibm, ibm appointment of john, the appointment of john by ibm and john is the current ibm appointee.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1340">
<title id=" W05-0302.xml">merging propbank nombank time bank penn discourse treebank and coreference </title>
<section> unifying linguistic annotations.  </section>
<citcontext>
<prevsection>
<prevsent>one possible representation format would be to convert each annotation into features and values to be added to larger feature structure.
</prevsent>
<prevsent>1 the resulting feature structure would combine stand alone and offset annotation ? it would include actual words and features from the text as well as special features that point to the actual text (character offsets) and, perhaps, syntactic trees (offsets along the lines of propbank/nombank).
</prevsent>
</prevsection>
<citsent citstr=" W01-1514 ">
alternative global annotation schemes include annotation graphs (cieri &amp; bird, 2001), <papid> W01-1514 </papid>and mate (carletta, et. al., 1999).</citsent>
<aftsection>
<nextsent>there are many areas in which the boundaries between these annotations have not been clearly defined, such as the treatment of support constructions and light verbs, as discussed below.
</nextsent>
<nextsent>determining the most suitable format for the merged representation should be top priority.
</nextsent>
<nextsent>there are many possible interactions between different types of annotation: aspect ual verbs have argument labels in propbank, but are also important roles for temporal relations.
</nextsent>
<nextsent>support 1 the feature structure has many advantages as target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1343">
<title id=" W06-1107.xml">evaluation of several phonetic similarity algorithms on the task of cognate identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we focus on few representatives of both approaches, and compare their performance on the specific task of cognate identification.
</prevsent>
<prevsent>cog nate identification is problem of finding, in distinct languages, words that can be traced back to common word in proto-language.
</prevsent>
</prevsection>
<citsent citstr=" W05-0606 ">
beyond historical linguistics, cognate identification has applications in other areas of computational linguistics (mackay and kondrak, 2005).<papid> W05-0606 </papid></citsent>
<aftsection>
<nextsent>because the likelihood that two words across different languages are cognates is highly correlated with their phonetic similarity, cog nate identification provides an objective test of the quality of phonetic similarity schemes.the remainder of this paper is organized as fol 43 lows.
</nextsent>
<nextsent>section 2 discusses the two manually designedschemes: the aline algorithm and linguistically motivated metric.
</nextsent>
<nextsent>section 3 discusses various learning approaches.
</nextsent>
<nextsent>in section 4, we describe dynamic bayesian nets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1344">
<title id=" W06-1107.xml">evaluation of several phonetic similarity algorithms on the task of cognate identification </title>
<section> two manually constructed schemes.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we first describe two different constructed schemes and then compare their properties.
</prevsent>
<prevsent>2.1 aline.
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
the aline algorithm (kondrak, 2000) <papid> A00-2038 </papid>assigns similarity score to pairs of phonetically-transcribedwords on the basis of the decomposition of phonemes into elementary phonetic features.</citsent>
<aftsection>
<nextsent>the algorithm was originally designed to identify and aligncognates in vocabularies of related languages.
</nextsent>
<nextsent>nevertheless, thanks to its grounding in universal phonetic principles, the algorithm can be used for estimating the similarity of any pair of words.
</nextsent>
<nextsent>the principal component of aline is function that calculates the similarity of two phonemes that are expressed in terms of about dozen multi-valued phonetic features (place, manner, voice, etc.).
</nextsent>
<nextsent>the phonetic features are assigned salience weights that express their relative importance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1346">
<title id=" W06-1107.xml">evaluation of several phonetic similarity algorithms on the task of cognate identification </title>
<section> learning algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm was evaluated on the task of matching surface pronunciations in the switchboard data to their canonical pronunciations in lexicon, yielding significant improvement inaccuracy over levenshtein distance.
</prevsent>
<prevsent>45 3.2 levenshtein with learned weights.
</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
mann and yarowsky (2001) <papid> N01-1020 </papid>applied the stochastic transducer of ristad and yianilos (1998) for inducing translation lexicons between two languages, but found that in some cases it offered no improvement over levenshtein distance.</citsent>
<aftsection>
<nextsent>in order to remedy this problem, they they proposed to filter the probabilities learned by em into few discrete cost classes, which are then used in the standard edit distancealgorithm.
</nextsent>
<nextsent>the llw approach yielded improvement over both regular levenshtein and the stochastic transducer.
</nextsent>
<nextsent>3.3 cordi.
</nextsent>
<nextsent>cordi (kondrak, 2002) <papid> C02-1016 </papid>is program for detecting recurrent sound correspondences in bilingualwordlists.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1347">
<title id=" W06-1107.xml">evaluation of several phonetic similarity algorithms on the task of cognate identification </title>
<section> learning algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>the llw approach yielded improvement over both regular levenshtein and the stochastic transducer.
</prevsent>
<prevsent>3.3 cordi.
</prevsent>
</prevsection>
<citsent citstr=" C02-1016 ">
cordi (kondrak, 2002) <papid> C02-1016 </papid>is program for detecting recurrent sound correspondences in bilingualwordlists.</citsent>
<aftsection>
<nextsent>the idea is to relate recurrent sound correspondences in word lists to translational equivalences in bitexts.
</nextsent>
<nextsent>a translation model is induced between phonemes in two word lists by combining the maximum similarity alignment with the competitive linking algorithm of melamed (2000).<papid> J00-2004 </papid></nextsent>
<nextsent>mela meds approach is based on the one-to-one assumption, which implies that every word in the bitext is aligned with at most one word on the other side of the bitext.in the context of the bilingual word lists, the correspondences determined under the one-to-one assumption are restricted to link single phonemes to single phonemes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1348">
<title id=" W06-1107.xml">evaluation of several phonetic similarity algorithms on the task of cognate identification </title>
<section> learning algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>cordi (kondrak, 2002) <papid> C02-1016 </papid>is program for detecting recurrent sound correspondences in bilingualwordlists.</prevsent>
<prevsent>the idea is to relate recurrent sound correspondences in word lists to translational equivalences in bitexts.</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
a translation model is induced between phonemes in two word lists by combining the maximum similarity alignment with the competitive linking algorithm of melamed (2000).<papid> J00-2004 </papid></citsent>
<aftsection>
<nextsent>mela meds approach is based on the one-to-one assumption, which implies that every word in the bitext is aligned with at most one word on the other side of the bitext.in the context of the bilingual word lists, the correspondences determined under the one-to-one assumption are restricted to link single phonemes to single phonemes.
</nextsent>
<nextsent>nevertheless, the method is powerful enough to determine valid correspondences in word lists in which the fraction of cognate pairs is well below 50%.
</nextsent>
<nextsent>the discovered phoneme correspondences can beused to compute correspondence-based similarity score between two words.
</nextsent>
<nextsent>each valid correspondence is counted as link and contributes aconstant positive score (no crossing links areal lowed).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1350">
<title id=" W06-1107.xml">evaluation of several phonetic similarity algorithms on the task of cognate identification </title>
<section> dynamic bayesian nets.  </section>
<citcontext>
<prevsection>
<prevsent>a bayesian net is directed acyclic graph in which each of the nodes represents random variable.
</prevsent>
<prevsent>the random variable can be either deterministic, in which case the node can only take on one value forgiven configuration of its parents, or stochastic, inwhich case the configuration of the parents determines the probability distribution of the node.
</prevsent>
</prevsection>
<citsent citstr=" P05-1042 ">
arcs in the net represent dependency relationships.filali and bilmes (2005) <papid> P05-1042 </papid>proposed to use dynamic bayesian nets (dbns) for computing word similarity.</citsent>
<aftsection>
<nextsent>a dbn is bayesian net where set of arcs and nodes are maintained for each point intime in dynamic process.
</nextsent>
<nextsent>this involves set of prologue frames denoting the beginning of the process, chunk frames which are repeated for the middle of the process, and epilogue frames to end the process.the conditional probability relationships are timeindependent.
</nextsent>
<nextsent>dbns can encode quite complex interdependencies between states.
</nextsent>
<nextsent>we tested four different dbn models on the taskof cognate identification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1361">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rescoring.
</prevsent>
<prevsent>we can use word graphs for rescoring with more sophisticated models, e.g. higher-order language models.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
discriminative training.the training of the model scaling factors as described in (och and ney, 2002) <papid> P02-1038 </papid>was done on -best lists.</citsent>
<aftsection>
<nextsent>using word graphs instead could further improve the results.
</nextsent>
<nextsent>also, the phrase translation probabilities could be trained dis crimatively, rather than only the scaling factors.
</nextsent>
<nextsent>confidence measures.
</nextsent>
<nextsent>word graphs can be used to derive confidence measures, such as the posterior probability (ueffing and ney, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1362">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state of the art.
</prevsent>
<prevsent>although there are these many applications, there are only few publications directly devoted to word graphs.
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
the only publication, weare aware of, is (ueffing et al, 2002).<papid> W02-1021 </papid></citsent>
<aftsection>
<nextsent>the shortcomings of (ueffing et al, 2002) <papid> W02-1021 </papid>are:?</nextsent>
<nextsent>they use single-word based models only.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1367">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wewill describe an algorithm with linear worst case complexity.
</prevsent>
<prevsent>apart from (ueffing et al, 2002), <papid> W02-1021 </papid>publications on weighted finite state transducer approaches to machine translation, e.g.</prevsent>
</prevsection>
<citsent citstr=" N01-1018 ">
(bangalore and riccardi, 2001; <papid> N01-1018 </papid>kumar and byrne, 2003), <papid> N03-1019 </papid>deal with wordgraphs.</citsent>
<aftsection>
<nextsent>but to our knowledge, there are no publications that give detailed analysis and evaluation of the quality of word graphs for machine translation.we will fill this gap and give systematic description and an assessment of the quality of word graphs for phrase-based machine translation.
</nextsent>
<nextsent>we will show that even for hard tasks with very large vocabulary and long sentences the graph error rate drops significantly.
</nextsent>
<nextsent>the remaining part is structured as follows: firstwe will give brief description of the translation system in section 2.
</nextsent>
<nextsent>in section 3, we will give definition of word graphs and describe the generation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1368">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wewill describe an algorithm with linear worst case complexity.
</prevsent>
<prevsent>apart from (ueffing et al, 2002), <papid> W02-1021 </papid>publications on weighted finite state transducer approaches to machine translation, e.g.</prevsent>
</prevsection>
<citsent citstr=" N03-1019 ">
(bangalore and riccardi, 2001; <papid> N01-1018 </papid>kumar and byrne, 2003), <papid> N03-1019 </papid>deal with wordgraphs.</citsent>
<aftsection>
<nextsent>but to our knowledge, there are no publications that give detailed analysis and evaluation of the quality of word graphs for machine translation.we will fill this gap and give systematic description and an assessment of the quality of word graphs for phrase-based machine translation.
</nextsent>
<nextsent>we will show that even for hard tasks with very large vocabulary and long sentences the graph error rate drops significantly.
</nextsent>
<nextsent>the remaining part is structured as follows: firstwe will give brief description of the translation system in section 2.
</nextsent>
<nextsent>in section 3, we will give definition of word graphs and describe the generation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1369">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> translation system.  </section>
<citcontext>
<prevsection>
<prevsent>here, the domain is news and therefore the vocabulary is very large and the sentences are with an average of 30 words quite long.
</prevsent>
<prevsent>in this section, we give brief description of the translation system.
</prevsent>
</prevsection>
<citsent citstr=" N04-1033 ">
we use phrase-based translation approach as described in (zens and ney, 2004).<papid> N04-1033 </papid>the posterior probability pr(ei1|fj1 ) is modeled directly using weighted log-linear combination of trigram language model and various translationmodels: phrase translation model and word based lexicon model.</citsent>
<aftsection>
<nextsent>these translation models areused for both directions: p(f |e) and p(e|f).
</nextsent>
<nextsent>additionally, we use word penalty and phrase penalty.with the exception of the language model, all models can be considered as within-phrase models as they depend only on single phrase pair, but not on the context outside of the phrase.
</nextsent>
<nextsent>the model scaling factors are optimized with respect to some evaluation criterion (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>we extended the monotone search algorithm from(zens and ney, 2004) <papid> N04-1033 </papid>such that reorderings are possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1370">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> translation system.  </section>
<citcontext>
<prevsection>
<prevsent>these translation models areused for both directions: p(f |e) and p(e|f).
</prevsent>
<prevsent>additionally, we use word penalty and phrase penalty.with the exception of the language model, all models can be considered as within-phrase models as they depend only on single phrase pair, but not on the context outside of the phrase.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the model scaling factors are optimized with respect to some evaluation criterion (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we extended the monotone search algorithm from(zens and ney, 2004) <papid> N04-1033 </papid>such that reorderings are possible.</nextsent>
<nextsent>in our case, we assume that local reorderings are sufficient.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1373">
<title id=" W05-0834.xml">word graphs for statistical machine translation </title>
<section> translation system.  </section>
<citcontext>
<prevsection>
<prevsent>these permutations are represented as reordering graph, similar to (zens et al, 2002).
</prevsent>
<prevsent>oncewe have this reordering graph, we perform monotone phrase-based translation of this graph.
</prevsent>
</prevsection>
<citsent citstr=" W05-0831 ">
more details of this reordering approach are described in (kanthak et al, 2005).<papid> W05-0831 </papid></citsent>
<aftsection>
<nextsent>3.1 definition.
</nextsent>
<nextsent>a word graph is directed acyclic graph = (v, e) with one designated root node n0 ? . the edges are labeled with words and optionally with scores.
</nextsent>
<nextsent>we will use (n, n?, w) to denote an edge from node 192 to node n?
</nextsent>
<nextsent>with word label w. each path through the word graph represents translation candidate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1388">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that discriminative techniques frequently achieve classification accuracy that is superior to generative techniques, over wide range of tasks.
</prevsent>
<prevsent>the empirical utility of models such as logistic regression and support vector machines (svms) in flat classification tasks like text categorization, word-sense disambiguation, and relevance routing has been repeatedly demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</citsent>
<aftsection>
<nextsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.
</nextsent>
<nextsent>in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</nextsent>
<nextsent>a discriminative modelis then used to choose between these candi dates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1389">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that discriminative techniques frequently achieve classification accuracy that is superior to generative techniques, over wide range of tasks.
</prevsent>
<prevsent>the empirical utility of models such as logistic regression and support vector machines (svms) in flat classification tasks like text categorization, word-sense disambiguation, and relevance routing has been repeatedly demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</citsent>
<aftsection>
<nextsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.
</nextsent>
<nextsent>in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</nextsent>
<nextsent>a discriminative modelis then used to choose between these candi dates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1391">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that discriminative techniques frequently achieve classification accuracy that is superior to generative techniques, over wide range of tasks.
</prevsent>
<prevsent>the empirical utility of models such as logistic regression and support vector machines (svms) in flat classification tasks like text categorization, word-sense disambiguation, and relevance routing has been repeatedly demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" P01-1042 ">
for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</citsent>
<aftsection>
<nextsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.
</nextsent>
<nextsent>in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</nextsent>
<nextsent>a discriminative modelis then used to choose between these candi dates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1393">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that discriminative techniques frequently achieve classification accuracy that is superior to generative techniques, over wide range of tasks.
</prevsent>
<prevsent>the empirical utility of models such as logistic regression and support vector machines (svms) in flat classification tasks like text categorization, word-sense disambiguation, and relevance routing has been repeatedly demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</citsent>
<aftsection>
<nextsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.
</nextsent>
<nextsent>in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</nextsent>
<nextsent>a discriminative modelis then used to choose between these candi dates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1394">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that discriminative techniques frequently achieve classification accuracy that is superior to generative techniques, over wide range of tasks.
</prevsent>
<prevsent>the empirical utility of models such as logistic regression and support vector machines (svms) in flat classification tasks like text categorization, word-sense disambiguation, and relevance routing has been repeatedly demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</citsent>
<aftsection>
<nextsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.
</nextsent>
<nextsent>in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</nextsent>
<nextsent>a discriminative modelis then used to choose between these candi dates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1395">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown that discriminative techniques frequently achieve classification accuracy that is superior to generative techniques, over wide range of tasks.
</prevsent>
<prevsent>the empirical utility of models such as logistic regression and support vector machines (svms) in flat classification tasks like text categorization, word-sense disambiguation, and relevance routing has been repeatedly demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</citsent>
<aftsection>
<nextsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.
</nextsent>
<nextsent>in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</nextsent>
<nextsent>a discriminative modelis then used to choose between these candi dates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1398">
<title id=" W04-3201.xml">max margin parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for sequence tasks like part-of-speech tagging or named-entity extraction, recent top-performing systems have also generally been based on discriminative sequence models, like conditional markov models (toutanova et al , 2003) <papid> N03-1033 </papid>or conditional random fields (lafferty et al , 2001).a number of recent papers have considered discriminative approaches for natural language parsing (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; johnson, 2001; <papid> P01-1042 </papid>geman and johnson,2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004; <papid> N04-1013 </papid>collins, 2004).</prevsent>
<prevsent>broadly speaking, these approaches fall into two categories, reranking and dynamic programming approaches.</prevsent>
</prevsection>
<citsent citstr=" W03-1012 ">
in reranking methods (johnson et al , 1999; <papid> P99-1069 </papid>collins, 2000; shen et al , 2003), <papid> W03-1012 </papid>an initial parser is used to generate number of candidate parses.</citsent>
<aftsection>
<nextsent>a discriminative modelis then used to choose between these candidates.
</nextsent>
<nextsent>in dynamic programming methods, alarge number of candidate parse trees are represented compactly in parse tree forest or chart.given sufficiently local?
</nextsent>
<nextsent>features, the decoding and parameter estimation problems can be solved using dynamic programming algorithms.for example, (johnson, 2001; <papid> P01-1042 </papid>geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; clark and curran, 2004; <papid> P04-1014 </papid>kaplan et al , 2004) <papid> N04-1013 </papid>describe approaches based on conditional log-linear (max imum entropy) models, where variants of theinside-outside algorithm can be used to efficiently calculate gradients of the log-likelihood function, despite the exponential number of trees represented by the parse forest.in this paper, we describe dynamic programming approach to discriminative parsing that is an alternative to maximum entropyestimation.</nextsent>
<nextsent>our method extends the max margin approach of taskar et al  (2003) to the case of context-free grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1406">
<title id=" W04-3201.xml">max margin parsing </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>we used the penn english treebank for all of our experiments.
</prevsent>
<prevsent>we report results here for each model and setting trained and tested on only the sentences of length ? 15 words.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
aside from the length restriction, we used the standard splits: sections 2-21 for training (9753 sen tences), 22 for development (603 sentences), and 23 for final testing (421 sentences).as baseline, we trained cnf transformation of the un lexicalized model of klein and manning (2003) <papid> P03-1054 </papid>on this data.</citsent>
<aftsection>
<nextsent>the resulting grammar had 3975 non-terminal symbols and contained two kinds of productions: binary nonterminal rewrites and tag-word rewrites.5 the scores for the binary rewrites were estimated using un smoothed relative frequency estimators.
</nextsent>
<nextsent>the tagging rewrites were estimated with smoothed model of (w|t), also using the model from klein and manning (2003).<papid> P03-1054 </papid></nextsent>
<nextsent>figure 3 shows the performance of this model (generative): 87.99 f1 on the test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1409">
<title id=" W05-0833.xml">hybrid example based smt the best of both worlds </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in so doing, it provides more complete evaluation of the main question at hand, namely whether an smt system outperforms an ebmt system on reasonably large training and test sets.
</prevsent>
<prevsent>we obtained the same training and test data used 183in (way and gough, 2005), and evaluated number of smt systems which use the pharaoh decoder1 against the marker-based ebmt system of (gough &amp; way, 2004b), for french english and englishfrench.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we provide results using range of automatic evaluation metrics: bleu (papineni et al, 2002), <papid> P02-1040 </papid>precision and recall (turian et al, 2003), and word- and sentence error rates.</citsent>
<aftsection>
<nextsent>(way and gough, 2005) observe that ebmt tends to outperform word-based smt model, and our experiments show that number of different phrase-based smt systems still tend to fall short of the quality obtained via ebmt for these evaluation metrics.
</nextsent>
<nextsent>however,when pharaoh is seeded with the datasets automatically induced by both giza++ and their ebmt system, better results are seen for french english than for the ebmt system per se.the remainder of the paper is constructed as follows.
</nextsent>
<nextsent>in section 2, we summarize the main ideas behind typical models of smt and ebmt, as well as the ebmt system of (gough &amp; way, 2004b) used inour experiments.
</nextsent>
<nextsent>in section 3, we revisit the experiments and results carried out by (way and gough, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1411">
<title id=" W05-0833.xml">hybrid example based smt the best of both worlds </title>
<section> example-based and statistical models of.  </section>
<citcontext>
<prevsection>
<prevsent>essentially, the translation model establishes the set of target language words (and more recently,phrases) which are most likely to be useful in translating the source string, while the language model tries to assemble these words (and phrases) in the most likely target word order.
</prevsent>
<prevsent>the language model is trained by determining all bigram and/or trigram frequency distributions occurring in the training data, while the translation model takes into account source and target word (and phrase) co-occurrencefrequencies, sentence lengths and the relative sentence positions of source and target words.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
until quite recently, smt models of translation were based on the simple word alignment models of (brown et al, 1990).<papid> J90-2002 </papid></citsent>
<aftsection>
<nextsent>nowadays, however, smt practitioners also get their systems to learn phrasal as well as lexical alignments (e.g.
</nextsent>
<nextsent>(koehn et al, 2003); (<papid> N03-1017 </papid>och, 2003)).<papid> P03-1021 </papid></nextsent>
<nextsent>unsurprisingly, the quality obtained by todays phrase-based smt systems is considerably better than that obtained by the poorer word-based models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1413">
<title id=" W05-0833.xml">hybrid example based smt the best of both worlds </title>
<section> example-based and statistical models of.  </section>
<citcontext>
<prevsection>
<prevsent>until quite recently, smt models of translation were based on the simple word alignment models of (brown et al, 1990).<papid> J90-2002 </papid></prevsent>
<prevsent>nowadays, however, smt practitioners also get their systems to learn phrasal as well as lexical alignments (e.g.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
(koehn et al, 2003); (<papid> N03-1017 </papid>och, 2003)).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>unsurprisingly, the quality obtained by todays phrase-based smt systems is considerably better than that obtained by the poorer word-based models.
</nextsent>
<nextsent>smt (way and gough, 2005) obtained large translation memory from sun microsystems containing 207,468englishfrench sentence pairs, of which 3,939 sentence pairs were randomly extracted as test set,with the remaining 203,529 sentences used as training data.
</nextsent>
<nextsent>the average sentence length for the english test set was 13.1 words and 15.2 words for the corresponding french test set.
</nextsent>
<nextsent>the ebmt system used was their marker-based system as described in section 2.1 above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1414">
<title id=" W05-0833.xml">hybrid example based smt the best of both worlds </title>
<section> example-based and statistical models of.  </section>
<citcontext>
<prevsection>
<prevsent>until quite recently, smt models of translation were based on the simple word alignment models of (brown et al, 1990).<papid> J90-2002 </papid></prevsent>
<prevsent>nowadays, however, smt practitioners also get their systems to learn phrasal as well as lexical alignments (e.g.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
(koehn et al, 2003); (<papid> N03-1017 </papid>och, 2003)).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>unsurprisingly, the quality obtained by todays phrase-based smt systems is considerably better than that obtained by the poorer word-based models.
</nextsent>
<nextsent>smt (way and gough, 2005) obtained large translation memory from sun microsystems containing 207,468englishfrench sentence pairs, of which 3,939 sentence pairs were randomly extracted as test set,with the remaining 203,529 sentences used as training data.
</nextsent>
<nextsent>the average sentence length for the english test set was 13.1 words and 15.2 words for the corresponding french test set.
</nextsent>
<nextsent>the ebmt system used was their marker-based system as described in section 2.1 above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1415">
<title id=" W05-0833.xml">hybrid example based smt the best of both worlds </title>
<section> comparing ebmt and word-based.  </section>
<citcontext>
<prevsection>
<prevsent>the average sentence length for the english test set was 13.1 words and 15.2 words for the corresponding french test set.
</prevsent>
<prevsent>the ebmt system used was their marker-based system as described in section 2.1 above.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in order to create the necessary smt language and translation models, they used: ? giza++ (och &amp; ney, 2003);<papid> J03-1002 </papid>2 ? the cmu-cambridge statistical toolkit;3 ? the isi rewrite decoder.4 translation was performed from english french and french english, and the resulting translations were evaluated using range of automatic metrics: bleu (papineni et al, 2002), <papid> P02-1040 </papid>precision and recall 2http://www.isi.edu/och/giza++.html 3http://mi.eng.cam.ac.uk/prc14/toolkit.html 4http://www.isi.edu/licensed-sw/rewrite-decoder/ 185 (turian et al, 2003), and word- and sentence errorrates.</citsent>
<aftsection>
<nextsent>in order to see whether the amount of training data affected the (relative) performance of the ebmt and smt systems, (way and gough, 2005) split the training data into three sets, of 50k (1.1m words), 100k (2.4m words) and 203k (4.8m words) sentence pairs (ts1ts3 in what follows).
</nextsent>
<nextsent>3.1 english french results.
</nextsent>
<nextsent>table 1: comparing the ebmt system of (gough &amp; way, 2004b) with word-based smt (wb-smt) system for englishfrench.
</nextsent>
<nextsent>bleu prec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1418">
<title id=" W05-0833.xml">hybrid example based smt the best of both worlds </title>
<section> comparing ebmt and word-based.  </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, however,apart from ser, all evaluation scores are higher using 100k sentence pairs as training data rather than the full 203k sentences.
</prevsent>
<prevsent>it is generally assumed that increasing the size of the training data for corpus based mt systems will improve the quality of the output translations.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
(way and gough, 2005) observe that while this dip in performance may be due to degree of over fitting, they intend to carry out some variance analysis on these results (e.g. performing bootstrap-resampling on the test set (koehn, 2004)), <papid> W04-3250 </papid>or re-test with different sample test sets in orderto investigate whether the same phenomenon is ob served.</citsent>
<aftsection>
<nextsent>with respect to ser, however, for both smt and ebmt, the figures improve as more training data is made available.
</nextsent>
<nextsent>however, the improvement is much more significant for ebmt (20.6%) than for smt (0.1%).
</nextsent>
<nextsent>while the wer scores are much the same,indicating that both systems are identifying reasonable target vocabulary that should appear in the out put translation, the vast differences in ser using ts3 indicate that system containing essentially no information about target syntax has very little hope of arranging these target words in the right order.on the contrary, even system containing some basic knowledge of how phrases fit together such as the marker-based ebmt system of (gough &amp; way,2004b) will generate translations of far higher quality.
</nextsent>
<nextsent>3.2 french english results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1423">
<title id=" W06-0703.xml">question preprocessing in a qa system on internet discussion groups </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, inappropriate phrases should be removed and different questions in one posting should be separated before question comparison.
</prevsent>
<prevsent>there is no research focusing on this topic.
</prevsent>
</prevsection>
<citsent citstr=" W02-1904 ">
faq finders (lai et al, 2002; <papid> W02-1904 </papid>lytinen and tomuro, 2002; burke, 1997) are closely related to this topic.</citsent>
<aftsection>
<nextsent>however, there are differences between them.
</nextsent>
<nextsent>first of all, questions in faq set are often written in perfect grammar without 16 garbage text.
</nextsent>
<nextsent>second, questions are often paired with answers separately.
</nextsent>
<nextsent>i.e. there is often one question in one qa pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1424">
<title id=" W06-0703.xml">question preprocessing in a qa system on internet discussion groups </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>i.e. there is often one question in one qa pair.
</prevsent>
<prevsent>there were some research groups who divided questions into segments.
</prevsent>
</prevsection>
<citsent citstr=" N04-1008 ">
soricut and brill (2004) <papid> N04-1008 </papid>chunked questions and used them as queries to search engines.</citsent>
<aftsection>
<nextsent>saquete et al (2004) <papid> P04-1072 </papid>focused on decomposition of complex question into several sub-questions.</nextsent>
<nextsent>in this paper, question segmentation is to identify different questions posed in one posting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1425">
<title id=" W06-0703.xml">question preprocessing in a qa system on internet discussion groups </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there were some research groups who divided questions into segments.
</prevsent>
<prevsent>soricut and brill (2004) <papid> N04-1008 </papid>chunked questions and used them as queries to search engines.</prevsent>
</prevsection>
<citsent citstr=" P04-1072 ">
saquete et al (2004) <papid> P04-1072 </papid>focused on decomposition of complex question into several sub-questions.</citsent>
<aftsection>
<nextsent>in this paper, question segmentation is to identify different questions posed in one posting.
</nextsent>
<nextsent>2.1 garbage texts.
</nextsent>
<nextsent>articles in discussion groups are colloquial.
</nextsent>
<nextsent>users often write articles as if they are talking to other users.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1426">
<title id=" W06-0703.xml">question preprocessing in a qa system on internet discussion groups </title>
<section> 22 2.54  </section>
<citcontext>
<prevsection>
<prevsent>weights of part-of-speeches before computing similarity, word segmentation is performed to identify words in chinese text.
</prevsent>
<prevsent>after that, part-of-speech tagger is used to obtain pos information of each word.
</prevsent>
</prevsection>
<citsent citstr=" P01-1037 ">
(4) merging questions with the same type the information of question type has been widely adopted in qa systems (zhang and lee, 2003; hovy et al, 2002; harabagiu et al., 2001).<papid> P01-1037 </papid></citsent>
<aftsection>
<nextsent>question type often refers to the possible type of its answer, such as person name, location name, or temporal expression.
</nextsent>
<nextsent>the question types used in this paper are person, location, reason, quantity, temporal, comparison, definition, method, selection, yesno, and other.
</nextsent>
<nextsent>rules to determine question types are created manually.
</nextsent>
<nextsent>this strategy tries to merge two question fragments of the same question type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1427">
<title id=" W05-0213.xml">situational language training for hotel receptionists </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the following sections we present the following: ? the thetis scenario and the technologies applied ? aspects of content adaptation ? the results of the users?
</prevsent>
<prevsent>evaluation ? the lessons we have learned both regarding the value of the technologies (including the linguistics technologies), and the peda 3 see www.exills.com 85gogical value of such an innovative approach to language learning 3 thetis : scenario and linguistic tech-.
</prevsent>
</prevsection>
<citsent citstr=" W04-1702 ">
nologies as the general technical architecture behind thetis has already been described in details in (segond and parmentier 2004) (<papid> W04-1702 </papid>brunet al. 2002) we just give an overview of the entire system and concentrate below on the description of the thetis scenario and on the linguistic technologies that have been integrated into the system.</citsent>
<aftsection>
<nextsent>thetis integrates virtual reality and linguistic technologies in web application in order to propose truly e-learning solution that can be used both synchronously and asynchronously.
</nextsent>
<nextsent>our motivations for applying these two components are the follow ing: ? virtual reality offers cognitive context and promotes interaction.
</nextsent>
<nextsent>linguistic technologies offer autonomy to the students by showing them concepts, giving them assistance to understand word meanings within particular contexts by presenting various examples, providing feedback on their skills (during chat sessions as well as through exercises or even free activities).
</nextsent>
<nextsent>the notion of scenario is central to thetis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1428">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this comparison is timely, and important, as decoders evolve to represent more complex search space decisions and are evaluated against innovative evaluation metrics of translation quality.
</prevsent>
<prevsent>state of the art statistical machine translation takes advantage of exponential models to incorporate alarge set of potentially overlapping features to select translations from set of potential candidates.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
as discussed in (och, 2003), <papid> P03-1021 </papid>the direct translation model represents the probability of target sentence english?</citsent>
<aftsection>
<nextsent>e = e1 . . .
</nextsent>
<nextsent>ei being the translation for source sentence french?
</nextsent>
<nextsent>f = f1 . . .
</nextsent>
<nextsent>fj through an exponential, or log-linear model p?(e|f) = exp( k=1 ? hk(e, f))?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1429">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>selecting translation from this model under the maximum posteriori (map) criteria yields transl?(f) = argmax p?(e|f) .
</prevsent>
<prevsent>(2)this decision rule is optimal under the zero one loss function, minimizing the sentence error rate (mangu et al, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
using the log-linear form to model p?(e|f) gives us the flexibility to introduce overlapping features that can represent global context while decoding (searching the space of candidate translations) and rescoring (ranking set of candidate translations before performing theargmax operation), albeit at the cost of the traditional source-channel generative model of translation proposed in (brown et al, 1993).<papid> J93-2003 </papid>a significant impact of this paradigm shift, however, has been the movement to leverage the flexibility of the exponential model to maximize performance with respect to automatic evaluation met 208rics.</citsent>
<aftsection>
<nextsent>each evaluation metric considers different aspects of translation quality, both at the sentence and corpus level, often achieving high correlation to human evaluation (doddington, 2002).
</nextsent>
<nextsent>it is clear that the decision rule stated in (1) does not reflect the choice of evaluation metric, and substantial workhas been done to correct this mismatch in criteria.
</nextsent>
<nextsent>approaches include integrating the metric into the decision rule, and learning ? to optimize the performance of the decision rule.
</nextsent>
<nextsent>in this paper we will compare and evaluate several aspects of these techniques, focusing on minimum error rate (mer) training (och, 2003) <papid> P03-1021 </papid>and minimum bayes risk (mbr) decision rules, within novel training environment that isolates the impact of each component of these methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1432">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> addressing evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>we now describe competing strategies to address the problem of modeling the evaluation metric within the decoding and rescoring process, and introduce our contribution towards training non-tractable error surfaces.
</prevsent>
<prevsent>the methods discussed below make useof gen(f), the approximation to the complete candidate translation space e, referred to as an n-best list.
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
details regarding n-best list generation from decoder output can be found in (ueffing et al, 2002).<papid> W02-1021 </papid></citsent>
<aftsection>
<nextsent>2.1 minimum error rate training.
</nextsent>
<nextsent>the predominant approach to reconciling the mismatch between the map decision rule and the evaluation metric has been to train the parameters ? of the exponential model to correlate the map choice with the maximum score as indicated by the evaluation metric on development set with known references (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>we differentiate between the decision rule transl?(f) = argmax egen(f) p?(e|f) (3a) and the training criterion ??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1436">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> addressing evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>this is due to the decision rule, rather than the training procedure, as we will see when we consider alternative decision rules.
</prevsent>
<prevsent>2.2 the minimum bayes risk decision rule.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
the minimum bayes risk decision rule as proposed by (mangu et al, 2000) for the word error rate metric in speech recognition, and (kumar and byrne, 2004) <papid> N04-1022 </papid>when applied to translation, changes the decision rule in (2) to select the translation that has the lowest expected loss e[loss(e, r)], which can be estimated by considering weighted loss between and the elements of the n-best list, the approximation to e, as described in (mangu et al, 2000).</citsent>
<aftsection>
<nextsent>the resulting decision rule is: transl?(f) = argmin egen(f) ? egen(f) loss(e, e?)p?(e ?|f) .
</nextsent>
<nextsent>(4)(kumar and byrne, 2004) <papid> N04-1022 </papid>explicitly consider selecting both and a, an alignment between the english and french sentences.</nextsent>
<nextsent>under phrase based translation model (koehn et al, 2003; <papid> N03-1017 </papid>marcu and wong, 2002), <papid> W02-1018 </papid>this distinction is important and will be discussed in more detail.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1440">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> addressing evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting decision rule is: transl?(f) = argmin egen(f) ? egen(f) loss(e, e?)p?(e ?|f) .
</prevsent>
<prevsent>(4)(kumar and byrne, 2004) <papid> N04-1022 </papid>explicitly consider selecting both and a, an alignment between the english and french sentences.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
under phrase based translation model (koehn et al, 2003; <papid> N03-1017 </papid>marcu and wong, 2002), <papid> W02-1018 </papid>this distinction is important and will be discussed in more detail.</citsent>
<aftsection>
<nextsent>the representation of the evaluation metric or the loss function is in the decision rule, rather than in the training criterion forthe exponential model.
</nextsent>
<nextsent>this criterion is hard to optimize for the same reason as the criterion in (3b): the objective function is not continuous in ?.
</nextsent>
<nextsent>tomake things worse, it is more expensive to evaluate the function at given ?, since the decision rule involves sum over all translations.
</nextsent>
<nextsent>2.3 mbr and the exponential model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1441">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> addressing evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting decision rule is: transl?(f) = argmin egen(f) ? egen(f) loss(e, e?)p?(e ?|f) .
</prevsent>
<prevsent>(4)(kumar and byrne, 2004) <papid> N04-1022 </papid>explicitly consider selecting both and a, an alignment between the english and french sentences.</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
under phrase based translation model (koehn et al, 2003; <papid> N03-1017 </papid>marcu and wong, 2002), <papid> W02-1018 </papid>this distinction is important and will be discussed in more detail.</citsent>
<aftsection>
<nextsent>the representation of the evaluation metric or the loss function is in the decision rule, rather than in the training criterion forthe exponential model.
</nextsent>
<nextsent>this criterion is hard to optimize for the same reason as the criterion in (3b): the objective function is not continuous in ?.
</nextsent>
<nextsent>tomake things worse, it is more expensive to evaluate the function at given ?, since the decision rule involves sum over all translations.
</nextsent>
<nextsent>2.3 mbr and the exponential model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1442">
<title id=" W05-0836.xml">training and evaluating error minimization decision rules for statistical machine translation </title>
<section> addressing evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>are not the optimal parameters for this training criterion.
</prevsent>
<prevsent>we can expect the error surface of the mbr training criterion to contain larger sections of similar altitude, since the decision rule emphasizes consensus.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the piece wise linearity observation made in (papineni et al, 2002) <papid> P02-1040 </papid>is no longer applicable since we cannot move the log operation into the expected value.</citsent>
<aftsection>
<nextsent>motivated by the challenges that the mbr training criterion presents, we present training method that is based on the assumption that the error surface is locally non-smooth but consists of local regions of similar loss values.
</nextsent>
<nextsent>we would like to focus the search within regions of the parameter space that result in low loss values, simulating the effect thatthe mer training process achieves when it determines the merged error boundaries across set of sentences.
</nextsent>
<nextsent>let score(?)
</nextsent>
<nextsent>be some function of loss(transl?(~f),~r) that is greater or equal zero, decreases monotonic ally with loss, and for which ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1448">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>suppose we have small amount of text data with syntactic annotations and fairly large corpus of parallel text, for which the other language (e.g., english) is not resource impoverished.
</prevsent>
<prevsent>how might we exploit english parsers to improve syntactic analysis tools for this language?
</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
one idea (yarowsky and ngai, 2001; <papid> N01-1026 </papid>hwa et al, 2002) <papid> P02-1050 </papid>is to project english analysis onto data, through?</citsent>
<aftsection>
<nextsent>word-aligned parallel text.
</nextsent>
<nextsent>to do this, we might use an english parser to analyze the english side of the parallel text and word-alignment algorithm to induce word correspondences.
</nextsent>
<nextsent>by positing coupling of english syntax with syntax, we can induce structure on the side of the parallel text that is in some sense isomorphic to the english parse.
</nextsent>
<nextsent>we might take the projection idea step farther.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1449">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>suppose we have small amount of text data with syntactic annotations and fairly large corpus of parallel text, for which the other language (e.g., english) is not resource impoverished.
</prevsent>
<prevsent>how might we exploit english parsers to improve syntactic analysis tools for this language?
</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
one idea (yarowsky and ngai, 2001; <papid> N01-1026 </papid>hwa et al, 2002) <papid> P02-1050 </papid>is to project english analysis onto data, through?</citsent>
<aftsection>
<nextsent>word-aligned parallel text.
</nextsent>
<nextsent>to do this, we might use an english parser to analyze the english side of the parallel text and word-alignment algorithm to induce word correspondences.
</nextsent>
<nextsent>by positing coupling of english syntax with syntax, we can induce structure on the side of the parallel text that is in some sense isomorphic to the english parse.
</nextsent>
<nextsent>we might take the projection idea step farther.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1450">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> bilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in 3 we describe parameter estimation for each of the factored models, including novel applications of log-linear models to english dependency parsing and korean morphological analysis.4 presents korean parsing results with various monolingual and bilingual algorithms, including our bilingual parsing algorithm.
</prevsent>
<prevsent>we close by reviewing prior work in areas related to this paper (5).
</prevsent>
</prevsection>
<citsent citstr=" N03-1021 ">
the joint model used by our bilingual parser is an instance of stochastic bilingual multi text grammar (2mtg), formally defined by melamed (2003).<papid> N03-1021 </papid></citsent>
<aftsection>
<nextsent>the 2 mtg formalism generates two strings such that each syntactic constituent including individual wordsin one side of the bitext corresponds either to constituent in the other side or to ?.
</nextsent>
<nextsent>melamed defines bilexicalized mtg (l2mtg), which is synchronous extension of bilexical grammars such as those described in eisner and satta (1999) <papid> P99-1059 </papid>and applies the latters algorithmic speed ups to l2mtg-parsing.our formalism is not precise fit to either unlexical ized mtg or l2mtg since we posit lexical dependency structure only in one of the languages (english).</nextsent>
<nextsent>the primary rationale for this is that we are dealing with only asmall quantity of labeled data in language and therefore do not expect to be able to accurately estimate its lexical affinities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1451">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> bilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the joint model used by our bilingual parser is an instance of stochastic bilingual multi text grammar (2mtg), formally defined by melamed (2003).<papid> N03-1021 </papid></prevsent>
<prevsent>the 2 mtg formalism generates two strings such that each syntactic constituent including individual wordsin one side of the bitext corresponds either to constituent in the other side or to ?.</prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
melamed defines bilexicalized mtg (l2mtg), which is synchronous extension of bilexical grammars such as those described in eisner and satta (1999) <papid> P99-1059 </papid>and applies the latters algorithmic speed ups to l2mtg-parsing.our formalism is not precise fit to either unlexical ized mtg or l2mtg since we posit lexical dependency structure only in one of the languages (english).</citsent>
<aftsection>
<nextsent>the primary rationale for this is that we are dealing with only asmall quantity of labeled data in language and therefore do not expect to be able to accurately estimate its lexical affinities.
</nextsent>
<nextsent>further, synchronous parsing is in practice computationally expensive, and eliminating lexicalization on one side reduces the run-time of the parser from o(n8) to o(n7).
</nextsent>
<nextsent>our parsing algorithm is simple transformation of mela meds r2d parser that eliminates head information in all korean parser items.the model event space for our stochastic halfbilexicalized?
</nextsent>
<nextsent>2-mtg consists of rewrite rules of the following two forms, with english above and below: ( x[h1] ? h1 h2 ) , ( x[h1] ? [h1]z[c1] bc )where upper-case symbols are nonterminals and lowercase symbols are words (potentially ?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1454">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>we trained the parser on sentences of 15 words orfewer in the wsj treebank sections 0121.5 99.49% dependency attachment accuracy was achieved on the training set, and 76.68% and 75.00% were achieved on sections 22 and 23, respectively.
</prevsent>
<prevsent>performance on the english side of our ktb test set was 71.82% (averaged across 5 folds, ? = 1.75).
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
this type of discriminative training has been applied to log-linear variants of hidden markov models (lafferty et al, 2001) and to lexical-functional grammar (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, ithas not been explored for context-free models (includ ing bilexical dependency models like ours).
</nextsent>
<nextsent>a review 4our split hags head automaton states correspond to the pos tags of the dependent words; this makes the head automaton deterministic and offers an additional speedup.
</nextsent>
<nextsent>5the parser does not model pos-tags; we assume they are known.
</nextsent>
<nextsent>headwords in the wsj corpus were obtained using r. hwas const2dep tool.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1455">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>we trained the parser on sentences of 15 words orfewer in the wsj treebank sections 0121.5 99.49% dependency attachment accuracy was achieved on the training set, and 76.68% and 75.00% were achieved on sections 22 and 23, respectively.
</prevsent>
<prevsent>performance on the english side of our ktb test set was 71.82% (averaged across 5 folds, ? = 1.75).
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
this type of discriminative training has been applied to log-linear variants of hidden markov models (lafferty et al, 2001) and to lexical-functional grammar (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, ithas not been explored for context-free models (includ ing bilexical dependency models like ours).
</nextsent>
<nextsent>a review 4our split hags head automaton states correspond to the pos tags of the dependent words; this makes the head automaton deterministic and offers an additional speedup.
</nextsent>
<nextsent>5the parser does not model pos-tags; we assume they are known.
</nextsent>
<nextsent>headwords in the wsj corpus were obtained using r. hwas const2dep tool.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1456">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>3.4 translation model.
</prevsent>
<prevsent>in our bilingual parser, the english and korean parses are mediated through word-to-word translational correspondence links.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
unlike the syntax models, the translation models were trained without the benefit of labeled data.we used the giza++ implementation of the ibm statistical translation models (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>to obtain reliable word translation estimates, we trained on bilingual corpus in addition to the ktb training set.
</nextsent>
<nextsent>the foreign broadcast information service dataset contains about 99,000 sentences of korean and72,000 of english translation.
</nextsent>
<nextsent>for our training, we extracted relatively small parallel corpus of about 19,000 high-confidence sentence pairs.
</nextsent>
<nextsent>as noted above, koreans productive agglutinativemorphology leads to sparse estimates of word frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1457">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>3.4 translation model.
</prevsent>
<prevsent>in our bilingual parser, the english and korean parses are mediated through word-to-word translational correspondence links.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
unlike the syntax models, the translation models were trained without the benefit of labeled data.we used the giza++ implementation of the ibm statistical translation models (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>to obtain reliable word translation estimates, we trained on bilingual corpus in addition to the ktb training set.
</nextsent>
<nextsent>the foreign broadcast information service dataset contains about 99,000 sentences of korean and72,000 of english translation.
</nextsent>
<nextsent>for our training, we extracted relatively small parallel corpus of about 19,000 high-confidence sentence pairs.
</nextsent>
<nextsent>as noted above, koreans productive agglutinativemorphology leads to sparse estimates of word frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1459">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>7
</prevsent>
<prevsent>having trained each part of the model, we bring them together in unified dynamic program to perform inference on the bilingual text as described in 2.
</prevsent>
</prevsection>
<citsent citstr=" P04-3032 ">
in order to experiment easily with different algorithms, we implemented all the morphological disambiguation and parsing models in this paper in dyna, new language for weighted dynamic programming (eisner et al, 2004).<papid> P04-3032 </papid></citsent>
<aftsection>
<nextsent>for parameter estimation, we used the complementary dynamite tool.
</nextsent>
<nextsent>just as cky parsing starts with words in its chart, the dynamic program chart for the bilingual parser is seeded with the links given in the hypothesized word alignment.
</nextsent>
<nextsent>all our current results are optimal under the model,but as we scale up to more complex data, we might introduce a?
</nextsent>
<nextsent>heuristics or, at the possible expense of optimality, beam search or pruning techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1464">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>improved english parsers such as collins?
</prevsent>
<prevsent>modelshavealso been implemented in dyna, the dynamic programming framework used here (eisner et al, 2004).<papid> P04-3032 </papid></prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
combining separately trained systems and then searching for an (ideally) optimal solution is standard practice in statistical continuous speech recognition (jelinek, 1998) and statistical machine translation (brown et al,1990).<papid> J90-2002 </papid></citsent>
<aftsection>
<nextsent>composition is even more of staple infinite state frameworks (knight and graehl, 1998).<papid> J98-4003 </papid></nextsent>
<nextsent>finally, factored models involving parses have been used to guide search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1465">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>modelshavealso been implemented in dyna, the dynamic programming framework used here (eisner et al, 2004).<papid> P04-3032 </papid></prevsent>
<prevsent>combining separately trained systems and then searching for an (ideally) optimal solution is standard practice in statistical continuous speech recognition (jelinek, 1998) and statistical machine translation (brown et al,1990).<papid> J90-2002 </papid></prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
composition is even more of staple infinite state frameworks (knight and graehl, 1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>finally, factored models involving parses have been used to guide search.
</nextsent>
<nextsent>charniak et al (2003) combine separately trained parse production probabilities with translation probabilities to prune parse forest hypothesized by the translation model.
</nextsent>
<nextsent>as discussed in 2, klein and manning (2002) guide their parsers search using combination of separate un lexicalized pcfg and lexical dependency models.
</nextsent>
<nextsent>the extent to which assumptions about similarity of syntax across languages are empirically valid has received attention in few pilot studies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1466">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>as discussed in 2, klein and manning (2002) guide their parsers search using combination of separate un lexicalized pcfg and lexical dependency models.
</prevsent>
<prevsent>the extent to which assumptions about similarity of syntax across languages are empirically valid has received attention in few pilot studies.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
fox (2002) <papid> W02-1039 </papid>has considered english and french, and hwa et al (2002) <papid> P02-1050 </papid>investigate chinese and english.</citsent>
<aftsection>
<nextsent>xia et al (2000) <papid> W00-1208 </papid>compare the rule templates of lexicalized tree adjoining grammars extracted from treebanks in english, chinese, and ko rean.</nextsent>
<nextsent>in the context of machine translation, dorr (1994)<papid> J94-4004 </papid>investigated divergences between two languages?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1468">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>the extent to which assumptions about similarity of syntax across languages are empirically valid has received attention in few pilot studies.
</prevsent>
<prevsent>fox (2002) <papid> W02-1039 </papid>has considered english and french, and hwa et al (2002) <papid> P02-1050 </papid>investigate chinese and english.</prevsent>
</prevsection>
<citsent citstr=" W00-1208 ">
xia et al (2000) <papid> W00-1208 </papid>compare the rule templates of lexicalized tree adjoining grammars extracted from treebanks in english, chinese, and ko rean.</citsent>
<aftsection>
<nextsent>in the context of machine translation, dorr (1994)<papid> J94-4004 </papid>investigated divergences between two languages?</nextsent>
<nextsent>struc tures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1469">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>fox (2002) <papid> W02-1039 </papid>has considered english and french, and hwa et al (2002) <papid> P02-1050 </papid>investigate chinese and english.</prevsent>
<prevsent>xia et al (2000) <papid> W00-1208 </papid>compare the rule templates of lexicalized tree adjoining grammars extracted from treebanks in english, chinese, and ko rean.</prevsent>
</prevsection>
<citsent citstr=" J94-4004 ">
in the context of machine translation, dorr (1994)<papid> J94-4004 </papid>investigated divergences between two languages?</citsent>
<aftsection>
<nextsent>structures.
</nextsent>
<nextsent>some proposals have sidestepped the empirical issueentirely.
</nextsent>
<nextsent>wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>used unsupervised learning on parallel text to induce syntactic analysis that was useful for their respective applications in phrasal translation extraction and speech translation,though not necessarily similar to what human annotator would select.</nextsent>
<nextsent>note point of divergence of thesitg from our bilingual parsing system: sitg only allows words, but not higher structures, to match null in the other language and thus requires that the trees in parallel sentences be isomorphic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1470">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>structures.
</prevsent>
<prevsent>some proposals have sidestepped the empirical issueentirely.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>used unsupervised learning on parallel text to induce syntactic analysis that was useful for their respective applications in phrasal translation extraction and speech translation,though not necessarily similar to what human annotator would select.</citsent>
<aftsection>
<nextsent>note point of divergence of thesitg from our bilingual parsing system: sitg only allows words, but not higher structures, to match null in the other language and thus requires that the trees in parallel sentences be isomorphic.
</nextsent>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>introduced tree-to-string alignment on japanese data, and gildea (2003) <papid> P03-1011 </papid>performed tree-to-tree alignment on the korean treebank, allowing for non-isomorphic structures; he applied this to word-to-word alignment.</nextsent>
<nextsent>finally, inspired by these intuitive notions of translational correspondence, cherry and lin (2003) <papid> P03-1012 </papid>include dependency features in word alignment model to improve non-syntactic baseline systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1471">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>structures.
</prevsent>
<prevsent>some proposals have sidestepped the empirical issueentirely.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>used unsupervised learning on parallel text to induce syntactic analysis that was useful for their respective applications in phrasal translation extraction and speech translation,though not necessarily similar to what human annotator would select.</citsent>
<aftsection>
<nextsent>note point of divergence of thesitg from our bilingual parsing system: sitg only allows words, but not higher structures, to match null in the other language and thus requires that the trees in parallel sentences be isomorphic.
</nextsent>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>introduced tree-to-string alignment on japanese data, and gildea (2003) <papid> P03-1011 </papid>performed tree-to-tree alignment on the korean treebank, allowing for non-isomorphic structures; he applied this to word-to-word alignment.</nextsent>
<nextsent>finally, inspired by these intuitive notions of translational correspondence, cherry and lin (2003) <papid> P03-1012 </papid>include dependency features in word alignment model to improve non-syntactic baseline systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1472">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>used unsupervised learning on parallel text to induce syntactic analysis that was useful for their respective applications in phrasal translation extraction and speech translation,though not necessarily similar to what human annotator would select.</prevsent>
<prevsent>note point of divergence of thesitg from our bilingual parsing system: sitg only allows words, but not higher structures, to match null in the other language and thus requires that the trees in parallel sentences be isomorphic.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
yamada and knight (2001) <papid> P01-1067 </papid>introduced tree-to-string alignment on japanese data, and gildea (2003) <papid> P03-1011 </papid>performed tree-to-tree alignment on the korean treebank, allowing for non-isomorphic structures; he applied this to word-to-word alignment.</citsent>
<aftsection>
<nextsent>finally, inspired by these intuitive notions of translational correspondence, cherry and lin (2003) <papid> P03-1012 </papid>include dependency features in word alignment model to improve non-syntactic baseline systems.</nextsent>
<nextsent>in more formal work, melamed (2003) <papid> N03-1021 </papid>proposes multi text grammars and algorithms for parsing them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1473">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>wu (1997) <papid> J97-3002 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>used unsupervised learning on parallel text to induce syntactic analysis that was useful for their respective applications in phrasal translation extraction and speech translation,though not necessarily similar to what human annotator would select.</prevsent>
<prevsent>note point of divergence of thesitg from our bilingual parsing system: sitg only allows words, but not higher structures, to match null in the other language and thus requires that the trees in parallel sentences be isomorphic.</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
yamada and knight (2001) <papid> P01-1067 </papid>introduced tree-to-string alignment on japanese data, and gildea (2003) <papid> P03-1011 </papid>performed tree-to-tree alignment on the korean treebank, allowing for non-isomorphic structures; he applied this to word-to-word alignment.</citsent>
<aftsection>
<nextsent>finally, inspired by these intuitive notions of translational correspondence, cherry and lin (2003) <papid> P03-1012 </papid>include dependency features in word alignment model to improve non-syntactic baseline systems.</nextsent>
<nextsent>in more formal work, melamed (2003) <papid> N03-1021 </papid>proposes multi text grammars and algorithms for parsing them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1474">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>note point of divergence of thesitg from our bilingual parsing system: sitg only allows words, but not higher structures, to match null in the other language and thus requires that the trees in parallel sentences be isomorphic.
</prevsent>
<prevsent>yamada and knight (2001) <papid> P01-1067 </papid>introduced tree-to-string alignment on japanese data, and gildea (2003) <papid> P03-1011 </papid>performed tree-to-tree alignment on the korean treebank, allowing for non-isomorphic structures; he applied this to word-to-word alignment.</prevsent>
</prevsection>
<citsent citstr=" P03-1012 ">
finally, inspired by these intuitive notions of translational correspondence, cherry and lin (2003) <papid> P03-1012 </papid>include dependency features in word alignment model to improve non-syntactic baseline systems.</citsent>
<aftsection>
<nextsent>in more formal work, melamed (2003) <papid> N03-1021 </papid>proposes multi text grammars and algorithms for parsing them.</nextsent>
<nextsent>shieber and schabes (1990) <papid> C90-3045 </papid>describe synchronous tree adjoining grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1476">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, inspired by these intuitive notions of translational correspondence, cherry and lin (2003) <papid> P03-1012 </papid>include dependency features in word alignment model to improve non-syntactic baseline systems.</prevsent>
<prevsent>in more formal work, melamed (2003) <papid> N03-1021 </papid>proposes multi text grammars and algorithms for parsing them.</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
shieber and schabes (1990) <papid> C90-3045 </papid>describe synchronous tree adjoining grammar.</citsent>
<aftsection>
<nextsent>while both of these formalisms require bilingual grammar rules, eisner (2003) <papid> P03-2041 </papid>describes an algorithm for learning tree substitution grammars from unaligned trees.</nextsent>
<nextsent>working on the penn korean treebank, sarkar and han (2002) made single training/test split and used91% of the sentences to train morphological disam biguator and lexicalized tree adjoining grammar (ltag) based parsing system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1477">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>in more formal work, melamed (2003) <papid> N03-1021 </papid>proposes multi text grammars and algorithms for parsing them.</prevsent>
<prevsent>shieber and schabes (1990) <papid> C90-3045 </papid>describe synchronous tree adjoining grammar.</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
while both of these formalisms require bilingual grammar rules, eisner (2003) <papid> P03-2041 </papid>describes an algorithm for learning tree substitution grammars from unaligned trees.</citsent>
<aftsection>
<nextsent>working on the penn korean treebank, sarkar and han (2002) made single training/test split and used91% of the sentences to train morphological disam biguator and lexicalized tree adjoining grammar (ltag) based parsing system.
</nextsent>
<nextsent>for monolingual approach to training parser with scarce resources, see (steedman et al, 2003), <papid> N03-1031 </papid>who apply co-training and corrected co-training to bootstrapping an english parser starting with 1000 parsed training sen truth [top [np ngyen.tay/nnc kong.pyeng/nnc cwung.tay/nnc] [vp [np ku/dan to/nnc] ken.sel/nnc] ./sfn] pcfg [top ngyen.tay/vv [s [np kong.pyeng/nnc cwung.tay/nnc] [vp [np ku/npn to/nnx] ken.sel/nnc] ./sfn]] bilingual [top [np ngyen.tay/vv kong.pyeng/nnc1 cwung.tay/nnc] [vp [np ku/npn to/nnx] ken.sel/nnc] ./sfn2] translation the regimental1 engineer company constructed that road .2 truth [top [np ku/dan sa.lam/nnc] [np ceng.chi/nnc kwun.kwan/nnc] ?/sfn] pcfg [top [vp [np ku/dan sa.lam/nnc ceng.chi/nnc] kwun.kwan/nnc] ?/sfn] bilingual [top [np ku/dan1 sa.lam/nnc] [np ceng.chi/nnc2 kwun.kwan/nnc3] ?/sfn4] translation he1 is political2 officer3 4 table 5: the gold-standard parse, pcfg parse, bilingual parse, and english translation for two selected test sentences.</nextsent>
<nextsent>giza-aligned words are co indexed with subscripts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1478">
<title id=" W04-3207.xml">bilingual parsing with factored estimation using english to parse korean </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>while both of these formalisms require bilingual grammar rules, eisner (2003) <papid> P03-2041 </papid>describes an algorithm for learning tree substitution grammars from unaligned trees.</prevsent>
<prevsent>working on the penn korean treebank, sarkar and han (2002) made single training/test split and used91% of the sentences to train morphological disam biguator and lexicalized tree adjoining grammar (ltag) based parsing system.</prevsent>
</prevsection>
<citsent citstr=" N03-1031 ">
for monolingual approach to training parser with scarce resources, see (steedman et al, 2003), <papid> N03-1031 </papid>who apply co-training and corrected co-training to bootstrapping an english parser starting with 1000 parsed training sen truth [top [np ngyen.tay/nnc kong.pyeng/nnc cwung.tay/nnc] [vp [np ku/dan to/nnc] ken.sel/nnc] ./sfn] pcfg [top ngyen.tay/vv [s [np kong.pyeng/nnc cwung.tay/nnc] [vp [np ku/npn to/nnx] ken.sel/nnc] ./sfn]] bilingual [top [np ngyen.tay/vv kong.pyeng/nnc1 cwung.tay/nnc] [vp [np ku/npn to/nnx] ken.sel/nnc] ./sfn2] translation the regimental1 engineer company constructed that road .2 truth [top [np ku/dan sa.lam/nnc] [np ceng.chi/nnc kwun.kwan/nnc] ?/sfn] pcfg [top [vp [np ku/dan sa.lam/nnc ceng.chi/nnc] kwun.kwan/nnc] ?/sfn] bilingual [top [np ku/dan1 sa.lam/nnc] [np ceng.chi/nnc2 kwun.kwan/nnc3] ?/sfn4] translation he1 is political2 officer3 4 table 5: the gold-standard parse, pcfg parse, bilingual parse, and english translation for two selected test sentences.</citsent>
<aftsection>
<nextsent>giza-aligned words are co indexed with subscripts.
</nextsent>
<nextsent>the bilingual parser recovers from erroneous morphological tagging in the first sentence and finds the proper np bracketing in the second.
</nextsent>
<nextsent>method training unlabeled unlabeled labeled labeled crossing sentences precision recall precision recall brackets pcfg training 32 57.03 (5.45) 78.45 (5.71) 51.13 (6.14) 70.26 (6.40) 0.71 (0.22) 64 54.96 (4.98) 76.91 (6.71) 46.94 (4.38) 65.69 (5.99) 0.72 (0.25) 128 52.60 (3.15) 73.20 (4.97) 43.46 (3.34) 60.48 (5.14) 0.82 (0.18) 512 50.82 (1.46) 70.98 (2.00) 39.47 (2.49) 55.12 (3.42) 0.87 (0.06) 1024 50.25 (0.82) 70.31 (1.32) 37.93 (1.45) 53.07 (2.16) 0.89 (0.04) pcfg test 32 43.63 (4.40) 45.96 (5.38) 31.67 (3.47) 33.36 (4.19) 1.27 (0.16) 64 45.90 (2.30) 46.68 (2.92) 34.29 (2.35) 34.91 (3.22) 1.18 (0.12) 128 48.07 (4.14) 48.47 (4.45) 36.39 (3.37) 36.68 (3.50) 1.15 (0.14) 512 50.88 (2.97) 51.89 (2.92) 38.10 (3.22) 38.82 (2.68) 1.10 (0.10) 1024 51.15 (2.17) 52.65 (1.74) 37.47 (1.89) 38.58 (1.64) 1.12 (0.08) sitg ? 30.65 (1.97) 45.22 (3.43) ? ?
</nextsent>
<nextsent>1.93 (0.17) flat sitg ? 41.78 (1.98) 33.59 (3.36) ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1479">
<title id=" W06-0128.xml">chinese word segmentation using various dictionaries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper shows the effectiveness of the external resources (bilingual dictionary and word list) for chinese word segmentations.
</prevsent>
<prevsent>most of the chinese word segment ations are used for monolingual processing.
</prevsent>
</prevsection>
<citsent citstr=" C92-1019 ">
in general, the word segmentation program utilizes the word entries, part-of-speech (pos) information (chen and liu, 1992) <papid> C92-1019 </papid>in monolingual dictionary, segmentation rules (palmer, 1997), <papid> P97-1041 </papid>and some statistical information (sproat, et al, 1994).<papid> P94-1010 </papid></citsent>
<aftsection>
<nextsent>for the tasks of machine translation (mt) (bian and chen, 1998) and cross-language information retrieval (clir) (bian and chen, 2000), another translation dictionary may be used to transfer the words of documents from the source languages to target languages.
</nextsent>
<nextsent>because of the inconsistencies resulting from the two types of dictionaries (segmentation dictionary and transfer dictionary), this approach has the problems that some segmented words cannot be found in the transfer dictionary.
</nextsent>
<nextsent>in this paper, we focus on the effectiveness of the chinese word segmentation using different dictionaries.
</nextsent>
<nextsent>four different dictionaries (or word lists) and two different testing collections (testing data) are used to evaluate the results of the chinese word segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1480">
<title id=" W06-0128.xml">chinese word segmentation using various dictionaries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper shows the effectiveness of the external resources (bilingual dictionary and word list) for chinese word segmentations.
</prevsent>
<prevsent>most of the chinese word segment ations are used for monolingual processing.
</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
in general, the word segmentation program utilizes the word entries, part-of-speech (pos) information (chen and liu, 1992) <papid> C92-1019 </papid>in monolingual dictionary, segmentation rules (palmer, 1997), <papid> P97-1041 </papid>and some statistical information (sproat, et al, 1994).<papid> P94-1010 </papid></citsent>
<aftsection>
<nextsent>for the tasks of machine translation (mt) (bian and chen, 1998) and cross-language information retrieval (clir) (bian and chen, 2000), another translation dictionary may be used to transfer the words of documents from the source languages to target languages.
</nextsent>
<nextsent>because of the inconsistencies resulting from the two types of dictionaries (segmentation dictionary and transfer dictionary), this approach has the problems that some segmented words cannot be found in the transfer dictionary.
</nextsent>
<nextsent>in this paper, we focus on the effectiveness of the chinese word segmentation using different dictionaries.
</nextsent>
<nextsent>four different dictionaries (or word lists) and two different testing collections (testing data) are used to evaluate the results of the chinese word segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1481">
<title id=" W06-0128.xml">chinese word segmentation using various dictionaries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper shows the effectiveness of the external resources (bilingual dictionary and word list) for chinese word segmentations.
</prevsent>
<prevsent>most of the chinese word segment ations are used for monolingual processing.
</prevsent>
</prevsection>
<citsent citstr=" P94-1010 ">
in general, the word segmentation program utilizes the word entries, part-of-speech (pos) information (chen and liu, 1992) <papid> C92-1019 </papid>in monolingual dictionary, segmentation rules (palmer, 1997), <papid> P97-1041 </papid>and some statistical information (sproat, et al, 1994).<papid> P94-1010 </papid></citsent>
<aftsection>
<nextsent>for the tasks of machine translation (mt) (bian and chen, 1998) and cross-language information retrieval (clir) (bian and chen, 2000), another translation dictionary may be used to transfer the words of documents from the source languages to target languages.
</nextsent>
<nextsent>because of the inconsistencies resulting from the two types of dictionaries (segmentation dictionary and transfer dictionary), this approach has the problems that some segmented words cannot be found in the transfer dictionary.
</nextsent>
<nextsent>in this paper, we focus on the effectiveness of the chinese word segmentation using different dictionaries.
</nextsent>
<nextsent>four different dictionaries (or word lists) and two different testing collections (testing data) are used to evaluate the results of the chinese word segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1482">
<title id=" W05-0511.xml">steps toward deep lexical acquisition </title>
<section> what steps we must take.  </section>
<citcontext>
<prevsection>
<prevsent>later qualitative ai frameworks of forbus (1984) and kuipers (1994) may be applied to mccloskey (1982)s intuitive physics and disessas (1993) p-prims.
</prevsent>
<prevsent>except for the work of hobbs, pustejovsky and their colleagues, few have mapped commonsense theories onto the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" J87-3004 ">
similar domain-general elements of naive math and causality are present in the workds of hobbs et al (1987), <papid> J87-3004 </papid>kennedy and mcnally (2002)s degree representations for grad able predicates, talmy (1988)s force dynamics, and the quantity spaces of kuipers(1994) and forbus (1984).</citsent>
<aftsection>
<nextsent>these disparate frameworks provide foundational elements for ut metal anguage.
</nextsent>
<nextsent>shortcuts on ut foundations will not work we must resist the urge to take shortcuts onthese foundations.
</nextsent>
<nextsent>simply creating slots for foundational phenomena will impede progress.
</nextsent>
<nextsent>pustejovsky (1995)s observations for co-compositionhave clearly illustrated how much flexibility our interpretation systems must have, e.g. in he enjoyed the beer/movie.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1484">
<title id=" W05-0511.xml">steps toward deep lexical acquisition </title>
<section> what we assumed wrong.  </section>
<citcontext>
<prevsection>
<prevsent>we cannot map parse trees onto sentence meanings.
</prevsent>
<prevsent>the possibility of putting meaning in your trees?
</prevsent>
</prevsection>
<citsent citstr=" W04-2424 ">
(palmer 2004) <papid> W04-2424 </papid>completely disappears.</citsent>
<aftsection>
<nextsent>we may still use the machine learning paradigm to parse, disambiguate and recognize speech.
</nextsent>
<nextsent>but these results are of little use to model theory, concept and lexical acquisition, because there is no output representation where suitable training set could be collected.
</nextsent>
<nextsent>the human conceptual apparatus is not that simple: the vad requires g(t ?)
</nextsent>
<nextsent>(which changes, as ? changes), and for that we need explanatory accounts of ut and g, and must recognize the diverse ways the tad may change state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1485">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, whether two events overlap or are in sequence often depends very much on their durations.
</prevsent>
<prevsent>temporal information processing has become more and more important in many natural language processing (nlp) applications, such as question answering (harabagiu and bejan, 2005; moldovan et. al., 2005; saur?
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
et. al., 2005), summarization (mani and schiffman, 2005), and information extraction (surdeanu et. al., 2003).<papid> P03-1002 </papid></citsent>
<aftsection>
<nextsent>temporal anchoring and event ordering are among the most important kinds of temporal information needed for nlp applications.
</nextsent>
<nextsent>although there has been much work on extracting and inferring such information from texts (hitzeman et al, 1995; <papid> E95-1035 </papid>mani and wilson, 2000; <papid> P00-1010 </papid>filatova and hovy, 2001; <papid> W01-1313 </papid>boguraev and ando, 2005), none of this work has exploited the implicit event duration information from the text.</nextsent>
<nextsent>consider the sentence from news article: george w. bush met with vladimir putin in moscow.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1486">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et. al., 2005), summarization (mani and schiffman, 2005), and information extraction (surdeanu et. al., 2003).<papid> P03-1002 </papid></prevsent>
<prevsent>temporal anchoring and event ordering are among the most important kinds of temporal information needed for nlp applications.</prevsent>
</prevsection>
<citsent citstr=" E95-1035 ">
although there has been much work on extracting and inferring such information from texts (hitzeman et al, 1995; <papid> E95-1035 </papid>mani and wilson, 2000; <papid> P00-1010 </papid>filatova and hovy, 2001; <papid> W01-1313 </papid>boguraev and ando, 2005), none of this work has exploited the implicit event duration information from the text.</citsent>
<aftsection>
<nextsent>consider the sentence from news article: george w. bush met with vladimir putin in moscow.
</nextsent>
<nextsent>how long was the meeting?
</nextsent>
<nextsent>our first reaction to this question might be that we have no idea.
</nextsent>
<nextsent>but in fact we do have an idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1487">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et. al., 2005), summarization (mani and schiffman, 2005), and information extraction (surdeanu et. al., 2003).<papid> P03-1002 </papid></prevsent>
<prevsent>temporal anchoring and event ordering are among the most important kinds of temporal information needed for nlp applications.</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
although there has been much work on extracting and inferring such information from texts (hitzeman et al, 1995; <papid> E95-1035 </papid>mani and wilson, 2000; <papid> P00-1010 </papid>filatova and hovy, 2001; <papid> W01-1313 </papid>boguraev and ando, 2005), none of this work has exploited the implicit event duration information from the text.</citsent>
<aftsection>
<nextsent>consider the sentence from news article: george w. bush met with vladimir putin in moscow.
</nextsent>
<nextsent>how long was the meeting?
</nextsent>
<nextsent>our first reaction to this question might be that we have no idea.
</nextsent>
<nextsent>but in fact we do have an idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1488">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>et. al., 2005), summarization (mani and schiffman, 2005), and information extraction (surdeanu et. al., 2003).<papid> P03-1002 </papid></prevsent>
<prevsent>temporal anchoring and event ordering are among the most important kinds of temporal information needed for nlp applications.</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
although there has been much work on extracting and inferring such information from texts (hitzeman et al, 1995; <papid> E95-1035 </papid>mani and wilson, 2000; <papid> P00-1010 </papid>filatova and hovy, 2001; <papid> W01-1313 </papid>boguraev and ando, 2005), none of this work has exploited the implicit event duration information from the text.</citsent>
<aftsection>
<nextsent>consider the sentence from news article: george w. bush met with vladimir putin in moscow.
</nextsent>
<nextsent>how long was the meeting?
</nextsent>
<nextsent>our first reaction to this question might be that we have no idea.
</nextsent>
<nextsent>but in fact we do have an idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1489">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if war started yesterday, we can be pretty sure it is still going on today.
</prevsent>
<prevsent>if hurricane started last year, we can be sure it is over by now.
</prevsent>
</prevsection>
<citsent citstr=" P06-1050 ">
to extract such implicit event duration information from texts automatically, we developed corpus annotated with typical durations of events (pan et al, 2006<papid> P06-1050 </papid>a) which currently contains all the 48 non-wall-street-journal (non-wsj) news articles (a total of 2132 event instances), as well as 10 wsj articles (156 event instances), from the time bank corpus annotated in timeml (pustejovky et al, 2003).</citsent>
<aftsection>
<nextsent>because the annotated corpus is still fairly small, we cannot hope to learn to make fine grained judgments of event durations that are currently annotated in the corpus, but as we show in greater detail in (pan et al, 2006<papid> P06-1050 </papid>b), it is possible to learn useful coarse-grained judgments that considerably outperform baseline and approach human performance.</nextsent>
<nextsent>this paper describes our work on extending timeml with annotations of typical durations of events, which can enrich the expressiveness of timeml, and provides nlp applications that exploit timeml with this additional implicit event duration information for their temporal information processing tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1501">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> annotating and learning typical du-.  </section>
<citcontext>
<prevsection>
<prevsent>when the articles were completely annotated by the three annotators, the results were analyzed and the differences were reconciled.
</prevsent>
<prevsent>differences in annotation could be due to the differences in interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into relatively small number of classes.
</prevsent>
</prevsection>
<citsent citstr=" J88-2003 ">
some of these correspond to aspect ual features of events, which have been intensively investigated (e.g., vendler, 1967; dowty, 1979; moens and steedman, 1988; <papid> J88-2003 </papid>passonneau, 1988).<papid> J88-2005 </papid></citsent>
<aftsection>
<nextsent>we then developed guidelines to cover those cases (see the next section).
</nextsent>
<nextsent>2.2 event classes.
</nextsent>
<nextsent>action vs. state: actions involve change, such as those described by words like  speaking ,  gave , and  skyrocketed .
</nextsent>
<nextsent>states involve things staying the same, such as being dead, being dry, and being at peace.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1502">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> annotating and learning typical du-.  </section>
<citcontext>
<prevsection>
<prevsent>when the articles were completely annotated by the three annotators, the results were analyzed and the differences were reconciled.
</prevsent>
<prevsent>differences in annotation could be due to the differences in interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into relatively small number of classes.
</prevsent>
</prevsection>
<citsent citstr=" J88-2005 ">
some of these correspond to aspect ual features of events, which have been intensively investigated (e.g., vendler, 1967; dowty, 1979; moens and steedman, 1988; <papid> J88-2003 </papid>passonneau, 1988).<papid> J88-2005 </papid></citsent>
<aftsection>
<nextsent>we then developed guidelines to cover those cases (see the next section).
</nextsent>
<nextsent>2.2 event classes.
</nextsent>
<nextsent>action vs. state: actions involve change, such as those described by words like  speaking ,  gave , and  skyrocketed .
</nextsent>
<nextsent>states involve things staying the same, such as being dead, being dry, and being at peace.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1503">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> annotating and learning typical du-.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 inter-annotator agreement.
</prevsent>
<prevsent>although the graphical output of the annotations enables us to visualize quickly the level of agreement among different annotators for each event, quantitative measurement of the agreement is needed.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the kappa statistic (krippendorff, 1980; carletta, 1996) <papid> J96-2004 </papid>has become the de facto standard to assess inter-annotator agreement.</citsent>
<aftsection>
<nextsent>it is computed as: )(1 )()( ep epap ? ?=?
</nextsent>
<nextsent>p(a) is the observed agreement among the annotators, and p(e) is the expected agreement, 40 figure 1: overlap of judgments of [10 minutes, 30 minutes] and [10 minutes, 2 hours].
</nextsent>
<nextsent>which is the probability that the annotators agree by chance.
</nextsent>
<nextsent>2.3.1 what should count as agreement?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1517">
<title id=" W06-0906.xml">extending timeml with typical durations of events </title>
<section> annotating and learning typical du-.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic relations.
</prevsent>
<prevsent>the information in the events syntactic environment is very important in deciding the durations of events.
</prevsent>
</prevsection>
<citsent citstr=" P97-1062 ">
forgiven event, both the head of its subject and the head of its object are extracted from the parse trees generated by the contex parser (hermjakob and mooney, 1997).<papid> P97-1062 </papid></citsent>
<aftsection>
<nextsent>similarly to the local context features, for both the subject head and the object head, their original form, lemma, and pos tags are extracted as features.
</nextsent>
<nextsent>wordnet hypernyms.
</nextsent>
<nextsent>events with the same hypernyms may have similar durations.
</nextsent>
<nextsent>but closely related events dont always have the same direct hypernyms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1530">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the word triple text-tekst-text ([tekst] in german, dutch and english) can be easily recognized as cognate; recognizing pfeffer-peper-pepper ([pfe][f@r] [pe:][p@r])-[pe][p@r*]), however, requires more knowledge about sound changes within the languages.
</prevsent>
<prevsent>the algorithms developed for machine translation search for similarities on the orthographic level, whereas some approaches to comparative and syn chronic linguistics put their focus on similarities of phonological sequences.
</prevsent>
</prevsection>
<citsent citstr=" J96-4002 ">
covington (1996), <papid> J96-4002 </papid>for instance, suggests different algorithms to align the phonetic representation of words of historical languages.</citsent>
<aftsection>
<nextsent>kondrak (2000) <papid> A00-2038 </papid>presents an algorithm to align phonetic sequences by computing the similarities of these words.nerbonne and heeringa (1997) <papid> W97-1102 </papid>use phonetic transcriptions to measure the phonetic distance between different dialects.</nextsent>
<nextsent>the abovementioned approaches presuppose either parallel texts of different languages for machine translation or manually compiled lists of transcribed cognates/words for analyzing syn chronic or dia chronic word pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1531">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithms developed for machine translation search for similarities on the orthographic level, whereas some approaches to comparative and syn chronic linguistics put their focus on similarities of phonological sequences.
</prevsent>
<prevsent>covington (1996), <papid> J96-4002 </papid>for instance, suggests different algorithms to align the phonetic representation of words of historical languages.</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
kondrak (2000) <papid> A00-2038 </papid>presents an algorithm to align phonetic sequences by computing the similarities of these words.nerbonne and heeringa (1997) <papid> W97-1102 </papid>use phonetic transcriptions to measure the phonetic distance between different dialects.</citsent>
<aftsection>
<nextsent>the abovementioned approaches presuppose either parallel texts of different languages for machine translation or manually compiled lists of transcribed cognates/words for analyzing syn chronic or dia chronic word pairs.
</nextsent>
<nextsent>unfortunately, transcribed bilingual data are scarce and it 33 is labor-intensive to collect these kind of corpora.
</nextsent>
<nextsent>thus, we aim at exploiting electronic pronunciation dictionaries to overcome the lack of data.
</nextsent>
<nextsent>in our approach, we automatically generate data as input to an unsupervised training regime andwith the aim of automatically learning similar structures from these data using expectation maximization (em) based clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1532">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithms developed for machine translation search for similarities on the orthographic level, whereas some approaches to comparative and syn chronic linguistics put their focus on similarities of phonological sequences.
</prevsent>
<prevsent>covington (1996), <papid> J96-4002 </papid>for instance, suggests different algorithms to align the phonetic representation of words of historical languages.</prevsent>
</prevsection>
<citsent citstr=" W97-1102 ">
kondrak (2000) <papid> A00-2038 </papid>presents an algorithm to align phonetic sequences by computing the similarities of these words.nerbonne and heeringa (1997) <papid> W97-1102 </papid>use phonetic transcriptions to measure the phonetic distance between different dialects.</citsent>
<aftsection>
<nextsent>the abovementioned approaches presuppose either parallel texts of different languages for machine translation or manually compiled lists of transcribed cognates/words for analyzing syn chronic or dia chronic word pairs.
</nextsent>
<nextsent>unfortunately, transcribed bilingual data are scarce and it 33 is labor-intensive to collect these kind of corpora.
</nextsent>
<nextsent>thus, we aim at exploiting electronic pronunciation dictionaries to overcome the lack of data.
</nextsent>
<nextsent>in our approach, we automatically generate data as input to an unsupervised training regime andwith the aim of automatically learning similar structures from these data using expectation maximization (em) based clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1533">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>in sections 7 and 8, we discuss our results and draw some final conclusions.
</prevsent>
<prevsent>some approaches to revealing sound correspondences require clean data whereas other methods can deal with noisy input.
</prevsent>
</prevsection>
<citsent citstr=" C02-2022 ">
cahill and tiberius (2002) <papid> C02-2022 </papid>use manually compiled cognate list of dutch,english and german cognates and extract cross linguistic phoneme correspondences.</citsent>
<aftsection>
<nextsent>the results1 contain the counts of certain german phoneme and their possible english and dutch counterparts.
</nextsent>
<nextsent>the method presented in kondrak (2003), however,can deal with noisy bilingual word lists.
</nextsent>
<nextsent>he generates sound correspondences of various algonquianlanguages.
</nextsent>
<nextsent>his algorithm considers them as possible candidates if their likelihood scores lie above certain minimum-strength threshold.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1535">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>the candidates are evaluated against manually compiled sound correspondences.
</prevsent>
<prevsent>the algorithm is able to judge 1http://www.itri.brighton.ac.uk/projects/metaphon/ whether bilingual phoneme pair is possible sound correspondence.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
another interesting generative model can be found in knight and graehl (1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>they train weighted finite-state transducers with the em algorithm which are applied to automaticallytransliterating japanese words - originated from english - back to english.
</nextsent>
<nextsent>in our approach, we aim at discovering similar correspondences between bilingual data represented in the classes.
</nextsent>
<nextsent>the classes canbe used to assess how likely bilingual sound correspondence is.
</nextsent>
<nextsent>in this section, we describe the resources used for our clustering algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1536">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> phonological clustering.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, we extract the onset pair [h] [h], the nucleus pair [au]-[ui] and the coda pair [s]-[s] from the german-dutch word pair [haus]-[huis].with the described method, we obtain from the remaining 21,212 german-dutch and 13,067 german english words, 59,819 german-dutch and 35,847 german-english onset, nucleus and coda pairs.
</prevsent>
<prevsent>in this section, we describe the unsupervised clustering method used for clustering of phonologicalunits.
</prevsent>
</prevsection>
<citsent citstr=" P00-1029 ">
three- and five-dimensional em-based clustering has been applied to monolingual phonological data (muller et al, 2000) <papid> P00-1029 </papid>and two-dimensional clustering to syntax (rooth et al, 1999).<papid> P99-1014 </papid></citsent>
<aftsection>
<nextsent>in our approach, we apply two-dimensional clustering to reveal classes of bilingual sound correspondences.
</nextsent>
<nextsent>the method is well-known but the application of probabilistic clustering to bilingual phonological data allows new view on bilingual phonological 35 processes.
</nextsent>
<nextsent>we choose em-based clustering as we need technique which provides probabilities to deal with noise in the training data.
</nextsent>
<nextsent>the two main parts of em-based clustering are (i) the induction of smooth probability model over the data, and (ii) the automatic discovery of class structure in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1537">
<title id=" W05-0805.xml">revealing phonological similarities between related languages from automatically generated parallel corpora </title>
<section> phonological clustering.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, we extract the onset pair [h] [h], the nucleus pair [au]-[ui] and the coda pair [s]-[s] from the german-dutch word pair [haus]-[huis].with the described method, we obtain from the remaining 21,212 german-dutch and 13,067 german english words, 59,819 german-dutch and 35,847 german-english onset, nucleus and coda pairs.
</prevsent>
<prevsent>in this section, we describe the unsupervised clustering method used for clustering of phonologicalunits.
</prevsent>
</prevsection>
<citsent citstr=" P99-1014 ">
three- and five-dimensional em-based clustering has been applied to monolingual phonological data (muller et al, 2000) <papid> P00-1029 </papid>and two-dimensional clustering to syntax (rooth et al, 1999).<papid> P99-1014 </papid></citsent>
<aftsection>
<nextsent>in our approach, we apply two-dimensional clustering to reveal classes of bilingual sound correspondences.
</nextsent>
<nextsent>the method is well-known but the application of probabilistic clustering to bilingual phonological data allows new view on bilingual phonological 35 processes.
</nextsent>
<nextsent>we choose em-based clustering as we need technique which provides probabilities to deal with noise in the training data.
</nextsent>
<nextsent>the two main parts of em-based clustering are (i) the induction of smooth probability model over the data, and (ii) the automatic discovery of class structure in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1542">
<title id=" W05-0633.xml">semantic role labeling using lexical statistical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate the performance on set of relatively cheap?
</prevsent>
<prevsent>features and report an f1 score of 68.13% on the overall test set.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
this paper presents system for the conll 2005 semantic role labeling shared task (carreras &ma;`rquez, 2005), which is based on the current release of the english propbank data (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>for the 2005 edition of the shared task are available both syntactic and semantic information.
</nextsent>
<nextsent>accordingly, we make use of both clausal, chunk and deep syntactic (tree structure) features, named entity information, as well as statistical representations for lexical item encoding.
</nextsent>
<nextsent>the set of features and their encoding reflect the necessity of limiting the complexity and dimensionality of the input space.
</nextsent>
<nextsent>they also provide the classifier with enough information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1543">
<title id=" W05-0633.xml">semantic role labeling using lexical statistical information </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>semantic arguments are mapped to the nodes in the parse trees, aset of hand-crafted shallow tree pruning rules are applied, probability distributions for feature representation are generated from training data1, and feature vectors are extracted.
</prevsent>
<prevsent>those are finally fed into the classifier for semantic role classification.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
2.1.1 tree node mapping of semantic arguments and named entities following gildea &amp; jurafsky (2002), (<papid> J02-3001 </papid>i) labels matching more than one constituent due to non branching nodes are taken as labels of higher constituents, (ii) in cases of labels with no corresponding parse constituent, these are assigned to the partial match given by the constituent spanning the shortest portion of the sentence beginning at the labels span left boundary and lying entirely within it.we drop the role or named entity label if such suit able constituent could not be found2.</citsent>
<aftsection>
<nextsent>1all other processing steps assume uniform treatment of both training and test data.
</nextsent>
<nextsent>2the percentage of roles for which no valid tree node couldbe found amounts to 3% for the training and 7% for the development set.
</nextsent>
<nextsent>these results are compatible with the performance of the employed parser (collins, 1999).
</nextsent>
<nextsent>213 2.1.2 tree pruning the tagged trees are further processed by applying the following pruning rules: ? all punctuation nodes are removed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1544">
<title id=" W05-0608.xml">domain kernels for text categorization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in section 3 we illustrate the svm approach to tc, and we define domain kernel that exploits domain models to estimate similarity among documents.
</prevsent>
<prevsent>in section 4 the performance of the domain kernel are compared with astandard bag-of-words feature representation, showing the improvements in the learning curves.
</prevsent>
</prevsection>
<citsent citstr=" W04-0856 ">
section5 describes the previous attempts to exploit semi supervised learning for tc, while section 6 concludes the paper and proposes some directions for future research.1the idea of exploiting domain kernel to help supervised classification framework, has been profitably used also inother nlp tasks such as word sense disambiguation (see forex ample (strapparava et al, 2004)).<papid> W04-0856 </papid></citsent>
<aftsection>
<nextsent>the simplest methodology to estimate the similarity among the topics of two texts is to represent them by means of vectors in the vector space model (vsm), and to exploit the cosine similarity.
</nextsent>
<nextsent>more formally, let = {t1, t2, . . .
</nextsent>
<nextsent>, tn} be corpus, let = {w1, w2, . . .
</nextsent>
<nextsent>, wk} be its vocabulary, let be the ? term-by-document matrix representing , such that ti,j is the frequency of word wi into the text tj . the vsm is k-dimensional space rk, in which the text tj ? is represented by means of the vector ~tj such that the ith component of ~tj is ti,j. the similarity among two texts in the vsm is estimated by computing the cosine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1545">
<title id=" W05-0706.xml">choosing an optimal architecture for segmentation and pos tagging of modern hebrew </title>
<section> task definition, corpora and related.  </section>
<citcontext>
<prevsection>
<prevsent>method by considering the context of the word.
</prevsent>
<prevsent>levinger (1992) adds short context filter that enforces grammatical constraints and rules out im possible analyses.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
segals (2000) system includes, in addition to somewhat different implementation of similar words?, two additional components: correction rules a` la brill (1995), <papid> J95-4004 </papid>and rudimentary deterministic syntactic parser.</citsent>
<aftsection>
<nextsent>using hmms for pos tagging and segmenting hebrew was previously discussed in (adler, 2001).
</nextsent>
<nextsent>the hmm in adlers work is trained on an untagged corpus, using the baum-welch algorithm (baum,1972).
</nextsent>
<nextsent>adler suggests various methods for performing both tagging and segmentation, most notable are(a) the usage of word-level tags, which uniquely determine the segmentation and the tag of each morpheme, and (b) the usage of two-dimensional markov model with morpheme-level tags.
</nextsent>
<nextsent>only the first method (word-level tags) was tested, resulting in an accuracy of 82%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1546">
<title id=" W05-0706.xml">choosing an optimal architecture for segmentation and pos tagging of modern hebrew </title>
<section> task definition, corpora and related.  </section>
<citcontext>
<prevsection>
<prevsent>only the first method (word-level tags) was tested, resulting in an accuracy of 82%.
</prevsent>
<prevsent>in the present paper, both word-level tagging and morpheme-level tagging are evaluated.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
moving on to arabic, lee et al (2003) <papid> P03-1051 </papid>describe aword segmentation system for arabic that uses an gram language model over morphemes.</citsent>
<aftsection>
<nextsent>they start with seed segmenter, based on language mod eland stem vocabulary derived from manually segmented corpus.
</nextsent>
<nextsent>the seed segmenter is improved it eratively by applying bootstrapping scheme to large unsegmented corpus.
</nextsent>
<nextsent>their system achieves accuracy of 97.1% (per word).
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>use support vector machines (svms) for the tasks of word segmentation and pos tagging (and also base phrase chunking).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1547">
<title id=" W05-0706.xml">choosing an optimal architecture for segmentation and pos tagging of modern hebrew </title>
<section> task definition, corpora and related.  </section>
<citcontext>
<prevsection>
<prevsent>the seed segmenter is improved it eratively by applying bootstrapping scheme to large unsegmented corpus.
</prevsent>
<prevsent>their system achieves accuracy of 97.1% (per word).
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
diab et al (2004) <papid> N04-4038 </papid>use support vector machines (svms) for the tasks of word segmentation and pos tagging (and also base phrase chunking).</citsent>
<aftsection>
<nextsent>for segmentation, they report precision of 99.09% andre call of 99.15%, when measuring morphemes that were correctly identified.
</nextsent>
<nextsent>for tagging, diab et al report accuracy of 95.49%, with tag set of 24 postags.
</nextsent>
<nextsent>tagging was applied to segmented words, using the gold?
</nextsent>
<nextsent>segmentation from the annotated corpus (mona diab, p.c.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1548">
<title id=" W05-0706.xml">choosing an optimal architecture for segmentation and pos tagging of modern hebrew </title>
<section> architectures for pos tagging semitic.  </section>
<citcontext>
<prevsection>
<prevsent>the actual probabilistic model used in this work for estimating (en1 , an1 ) is based on hidden markov models (hmms).
</prevsent>
<prevsent>hmms underly many successful pos taggers , e.g.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
(church, 1988; <papid> A88-1019 </papid>charniak et al, 1993).</citsent>
<aftsection>
<nextsent>for k-th order markov model (k = 1 or = 2), we rewrite (4) as: argmax en1 ,a 1 (en1 , n 1 ) ? argmax en1 ,a 1 n?
</nextsent>
<nextsent>i=1 (ai | aik, . . .
</nextsent>
<nextsent>, ai1)p (ei | ai) (5) for reasons of data sparseness, actual models we usework with = 2 for the morpheme level tokenization, and with = 1 for the word level tokenization.
</nextsent>
<nextsent>42 for these models, two kinds of probabilities need to be estimated: (ei | ai) (lexical model) and (ai |aik, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1550">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(cosy), fp6-004250-ipment that the robot maintains.
</prevsent>
<prevsent>this way we can dynamically use contextual information during the planning process.
</prevsent>
</prevsection>
<citsent citstr=" P02-1041 ">
the logical forms we operate on are all specified in asingle formalism, namely hybrid logic dependency semantics (hlds), meaning we have representational continuum between discourse-level and utterance-level representations [kruijff, 2001; baldridge and kruijff, 2002], <papid> P02-1041 </papid>and can guide utterance planning through content decisions made at higher levels.</citsent>
<aftsection>
<nextsent>the logical form we obtain from the utterance planner serves as input to separate openccg realizer [white and baldridge, 2003; white, 2004].
</nextsent>
<nextsent>the resulting approach is related to [stone and doran,1997; <papid> P97-1026 </papid>cassell et al, 2000].<papid> W00-1423 </papid></nextsent>
<nextsent>we adopt their idea of an utterance as description, generated from communicative goal, and also use an onto logically promiscuous?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1551">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the logical forms we operate on are all specified in asingle formalism, namely hybrid logic dependency semantics (hlds), meaning we have representational continuum between discourse-level and utterance-level representations [kruijff, 2001; baldridge and kruijff, 2002], <papid> P02-1041 </papid>and can guide utterance planning through content decisions made at higher levels.</prevsent>
<prevsent>the logical form we obtain from the utterance planner serves as input to separate openccg realizer [white and baldridge, 2003; white, 2004].</prevsent>
</prevsection>
<citsent citstr=" P97-1026 ">
the resulting approach is related to [stone and doran,1997; <papid> P97-1026 </papid>cassell et al, 2000].<papid> W00-1423 </papid></citsent>
<aftsection>
<nextsent>we adopt their idea of an utterance as description, generated from communicative goal, and also use an onto logically promiscuous?
</nextsent>
<nextsent>formalism for representing meaning [hobbs, 1985].<papid> P85-1008 </papid></nextsent>
<nextsent>we differ in that we separate out the realizer, though minimize the need for backtracking in the planner by allowing for multiple, alternative logical forms to be sent to the realizer, cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1552">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the logical forms we operate on are all specified in asingle formalism, namely hybrid logic dependency semantics (hlds), meaning we have representational continuum between discourse-level and utterance-level representations [kruijff, 2001; baldridge and kruijff, 2002], <papid> P02-1041 </papid>and can guide utterance planning through content decisions made at higher levels.</prevsent>
<prevsent>the logical form we obtain from the utterance planner serves as input to separate openccg realizer [white and baldridge, 2003; white, 2004].</prevsent>
</prevsection>
<citsent citstr=" W00-1423 ">
the resulting approach is related to [stone and doran,1997; <papid> P97-1026 </papid>cassell et al, 2000].<papid> W00-1423 </papid></citsent>
<aftsection>
<nextsent>we adopt their idea of an utterance as description, generated from communicative goal, and also use an onto logically promiscuous?
</nextsent>
<nextsent>formalism for representing meaning [hobbs, 1985].<papid> P85-1008 </papid></nextsent>
<nextsent>we differ in that we separate out the realizer, though minimize the need for backtracking in the planner by allowing for multiple, alternative logical forms to be sent to the realizer, cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1553">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting approach is related to [stone and doran,1997; <papid> P97-1026 </papid>cassell et al, 2000].<papid> W00-1423 </papid></prevsent>
<prevsent>we adopt their idea of an utterance as description, generated from communicative goal, and also use an onto logically promiscuous?</prevsent>
</prevsection>
<citsent citstr=" P85-1008 ">
formalism for representing meaning [hobbs, 1985].<papid> P85-1008 </papid></citsent>
<aftsection>
<nextsent>we differ in that we separate out the realizer, though minimize the need for backtracking in the planner by allowing for multiple, alternative logical forms to be sent to the realizer, cf.
</nextsent>
<nextsent>[foster and white, 2004].<papid> W04-0601 </papid></nextsent>
<nextsent>also, to establish contextual status of an entity, we can in principle use any type of model that the robot maintains of the environment, as long as we have an ontology on which we can establish common ground in interpretation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1554">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>formalism for representing meaning [hobbs, 1985].<papid> P85-1008 </papid></prevsent>
<prevsent>we differ in that we separate out the realizer, though minimize the need for backtracking in the planner by allowing for multiple, alternative logical forms to be sent to the realizer, cf.</prevsent>
</prevsection>
<citsent citstr=" W04-0601 ">
[foster and white, 2004].<papid> W04-0601 </papid></citsent>
<aftsection>
<nextsent>also, to establish contextual status of an entity, we can in principle use any type of model that the robot maintains of the environment, as long as we have an ontology on which we can establish common ground in interpretation.
</nextsent>
<nextsent>our approach places us squarely in the full generation camp, but there is continuum: using the approach to including canned text as proposed in [foster and white, 2004],<papid> W04-0601 </papid>we can freely position the actual planner between full generation and pre-baked generation.</nextsent>
<nextsent>we can use the flexibility of full generation where necessary, notably to achieve contextual appropriateness, but if desired we can use more direct methods to specify content.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1556">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach owes its perspective to systemic approaches, particularly kpml [bateman,1997].
</prevsent>
<prevsent>where we differ is in the creation of, and relation between, the resources we use in the parser, the realizer, and the utterance planner: we use one and the same grammar for both parsing and realization (though with different algo rithms), and we can derive the systemic network for utterance planning from this grammar (4) to ensure that we have single formulation of the robots linguistic knowledge, in the form of ccg grammar.
</prevsent>
</prevsection>
<citsent citstr=" P04-1011 ">
we also point out (4), how we can in principle train the planner, like e.g. [stent et al, 2004].<papid> P04-1011 </papid></citsent>
<aftsection>
<nextsent>overview in 2 we briefly discuss hlds, and the overall architecture in which we employ the utterance planner.
</nextsent>
<nextsent>3 presents the planner, focusing on the basic structure of the planning grammar, and context sensitivity.
</nextsent>
<nextsent>4 discusses how we can base the planning grammar on the specification of the grammar we employ for parsing and realization, and how we can in principle train the planning grammar given corpus of (analyzable) utterances.
</nextsent>
<nextsent>2.1 hybrid logic dependency semantics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1561">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>it also includes belief context.
</prevsent>
<prevsent>the belief context model captures global cross-modal fusion,achieved by fusing information across the different modalities at least at the level of token identification.
</prevsent>
</prevsection>
<citsent citstr=" W03-0903 ">
we establish common ground for interpretation across modalities by relating each layer to set of ontologies that model categories on which the events, states, and entities at that lay ercan be interpreted, following recent work in information fusion [wache et al, 2001] and dialogue systems [gurevych et al., 2003].<papid> W03-0903 </papid></citsent>
<aftsection>
<nextsent>there are different levels of granularity for the common ground we may be able to establish, due to the potential for hybridity across the different local representations used in the architecture.
</nextsent>
<nextsent>on the low end of the scale we have type identity, to type/token identity, to the high end where we have fully shared representations.
</nextsent>
<nextsent>the granularity of the common ground we are able to establish determines to what extend information can be fused.for the purposes of this paper we use the example implemented architecture, shown in figure 2.
</nextsent>
<nextsent>the goal of this instance is to enable robot to conduct simple dialogue about dynamic, visual scene.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1562">
<title id=" W05-1609.xml">context sensitive utterance planning for ccg </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in parallel to the speech dimension, figure 2: example implemented architecture we also have processes that interpret the visual scene.
</prevsent>
<prevsent>we use visual recognition and classification algorithm based on opencv 1 that produces representation of an object in terms of its type, physical properties, and position.
</prevsent>
</prevsection>
<citsent citstr=" W05-1607 ">
we interpret these representations on model of the visual scene, capturing proximal and projective spatial relations between objects [kelleher and kruijff, 2005<papid> W05-1607 </papid>b].</citsent>
<aftsection>
<nextsent>for production, the architecture in figure 2 includes only spoken language as an output modality.
</nextsent>
<nextsent>the dialogue planner constructs an hlds logical form that specifies the communication goal reflecting how the belief context could be updated with the information coming from the acoustic and visual dimensions.
</nextsent>
<nextsent>this logical form is taken by the utterance planner, which expands this logical form to full logical form that openccg can realize as well-formed string [white, 2004].
</nextsent>
<nextsent>finally, we use freetts2 for speech synthesis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1569">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> defining word alignment shared task.  </section>
<citcontext>
<prevsection>
<prevsent>assuming sentence aligned bilingual corpus in languages l1 and l2, the task of word alignment system is to indicate which word token in the corpus of language l1 corresponds to which word token in the corpus of language l2.
</prevsent>
<prevsent>this years shared task follows on the success ofthe previous word alignment evaluation that was organized during the hlt/naacl 2003 workshop on building and using parallel texts: data driven machine translation and beyond?
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
(mihalcea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>however, the current edition is distinct in that it has focus on languages with scarce resources.
</nextsent>
<nextsent>participating teams were provided with training and test data for three language pairs, accounting for different levels of data scarceness: (1) englishinuktitut (2 million words training data), (2) romanian english (1 million words), and (3) english hindi (60,000 words).
</nextsent>
<nextsent>similar to the previous word alignment evaluation and with the machine translation evaluation exercises organized by nist, two different subtasks were defined: (1) limited resources, where systems were allowed to use only the resources provided.
</nextsent>
<nextsent>(2) unlimited resources, where systems were allowed to useany resources in addition to those provided.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1571">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>three sets of training data were made available.
</prevsent>
<prevsent>all datasets were sentence-aligned, and pre-processed(i.e. tokenized and lower-cased), with identical preprocessing procedures used for training, trial, and test data.englishinuktitut.
</prevsent>
</prevsection>
<citsent citstr=" W03-0320 ">
a collection of sentence aligned englishinuktitut parallel texts from the legislative assembly of nunavut (martin et al, 2003).<papid> W03-0320 </papid></citsent>
<aftsection>
<nextsent>this collection consists of approximately 2 million inuktitut tokens (1.6 million words) and 4 million english tokens (3.4 million words).
</nextsent>
<nextsent>the inuktitut data was originally encoded in unicode representing sylla bics orthography (qaniujaaqpait), but was transliterated to an ascii encoding of the standardized roman orthography (qaliujaaqpait) for this evaluation.
</nextsent>
<nextsent>romanianenglish.
</nextsent>
<nextsent>a set of romanian english parallel texts, consisting of about 1 million romanian words, and about the same number of english words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1574">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>the hindi data was encoded in unicode devangari script, and used the utf8 encoding.
</prevsent>
<prevsent>the english?
</prevsent>
</prevsection>
<citsent citstr=" W05-0819 ">
hindi data were provided by niraj aswani and robert gaizauskas from university of sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>b).</citsent>
<aftsection>
<nextsent>2.2 trial data.
</nextsent>
<nextsent>three sets of trial data were made available at the same time training data became available.
</nextsent>
<nextsent>trial sets consisted of sentence aligned texts, provided together with manually determined word alignments.
</nextsent>
<nextsent>the main purpose of these data was to enable participants to better understand the format required for the word alignment result files.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1578">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>evaluations were performed with respect to four different measures.
</prevsent>
<prevsent>three of them ? precision, recall,and f-measure ? represent traditional measures in information retrieval, and were also frequently used in previous word alignment literature.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
the fourth measure was originally introduced by (och and ney, 2000), <papid> C00-2163 </papid>and proposes the notion of quality of word alignment.given an alignment   , and gold standard alignment</citsent>
<aftsection>
<nextsent>, each such alignment set eventually consisting of two sets   ,   , and
</nextsent>
<nextsent> corresponding to sure and probable alignments, the following measures are defined (where  is the alignment type, and can be set to either or p).
</nextsent>
<nextsent>(1)
</nextsent>
<nextsent>(2)            (3)   ffflfi
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1579">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0813 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1580">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0814 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1581">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0811 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1582">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0801 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1583">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0812 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1588">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0810 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1589">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0818 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1590">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>ffi
</prevsent>
<prevsent>(4) each word alignment submission was evaluated interms of the above measures.
</prevsent>
</prevsection>
<citsent citstr=" W05-0815 ">
given numerous (constructive) debates held during the previous word alignment evaluation, which questioned the informative ness of the null alignment evaluations, we decided 67 team system name description carnegie mellon university spa (brown et al, 2005) <papid> W05-0813 </papid>information sciences institute / usc isi (fraser and marcu, 2005) <papid> W05-0814 </papid>johns hopkins university jhu (schafer and drabek, 2005) <papid> W05-0811 </papid>microsoft research msr (moore, 2005) <papid> W05-0801 </papid>romanian academy institute of artificial intelligence treq-al, meba, cowal (tufis et al, 2005) university of maryland / umiacs umiacs (lopez and resnik, 2005) <papid> W05-0812 </papid>university of sheffield sheffield (aswani and gaizauskas, 2005<papid> W05-0819 </papid>a) university of montreal japa, nukti (langlais et al, 2005) <papid> W05-0810 </papid>university of sao paulo, university of alicante lihla (caseli et al, 2005) <papid> W05-0818 </papid>university jaume mar (vilar, 2005) <papid> W05-0815 </papid>table 1: teams participating in the word alignment shared task to evaluate only no-null alignments, and thus thenull alignments were removed from both submissions and gold standard data.</citsent>
<aftsection>
<nextsent>we conducted therefore 7 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, all of them measured on no-null alignments.
</nextsent>
<nextsent>ten teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the namesof the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>seven teams participated in the romanian english subtask, four teams participated in the english?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1591">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>system names are preceded by marker to indicate the system type: stands for limited resources, and stands for unlimited resources.
</prevsent>
<prevsent>while each participating system was unique, there were few unifying themes.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
several teams had approaches that relied (to varying degrees) on an ibm model of statistical machine translation (brown et al,1993), <papid> J93-2003 </papid>with different improvements brought by different teams, consisting of new sub models, improvements in the hmm model, model combination for optimal alignment, etc. se-veral teams used sym metrization metrics, as introduced in (och and ney, 2003) (<papid> J03-1002 </papid>union, intersection, refined), most of the times applied on the alignments produced for the two directions source target and target source, but also as way to combine different word alignment systems.</citsent>
<aftsection>
<nextsent>significant improvements with respect to baseline word alignment systems were observed when the vocabulary was reduced using simple stemming techniques, which seems to be particularly effective technique given the data sparseness problems associated with the relatively small amounts of training data.
</nextsent>
<nextsent>in the unlimited resources subtask, systems made use of bilingual dictionaries, human contributed word alignments, or syntactic constraints derived from dependency parse tree applied on the english side of the corpus.
</nextsent>
<nextsent>when only small amounts of parallel corpora were available (i.e. the english hindi subtask), the useof additional resources resulted in absolute improvements of up to 20% as compared to the case when the word alignment systems were based exclusively on the parallel texts.
</nextsent>
<nextsent>interestingly, this was not the case for the language pairs that had larger training corpora (i.e. romanian english, englishinuktitut), where the limited resources systems seemed to lead to comparable or sometime even better results than those that relied on unlimited resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1592">
<title id=" W05-0809.xml">word alignment for languages with scarce resources </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>system names are preceded by marker to indicate the system type: stands for limited resources, and stands for unlimited resources.
</prevsent>
<prevsent>while each participating system was unique, there were few unifying themes.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
several teams had approaches that relied (to varying degrees) on an ibm model of statistical machine translation (brown et al,1993), <papid> J93-2003 </papid>with different improvements brought by different teams, consisting of new sub models, improvements in the hmm model, model combination for optimal alignment, etc. se-veral teams used sym metrization metrics, as introduced in (och and ney, 2003) (<papid> J03-1002 </papid>union, intersection, refined), most of the times applied on the alignments produced for the two directions source target and target source, but also as way to combine different word alignment systems.</citsent>
<aftsection>
<nextsent>significant improvements with respect to baseline word alignment systems were observed when the vocabulary was reduced using simple stemming techniques, which seems to be particularly effective technique given the data sparseness problems associated with the relatively small amounts of training data.
</nextsent>
<nextsent>in the unlimited resources subtask, systems made use of bilingual dictionaries, human contributed word alignments, or syntactic constraints derived from dependency parse tree applied on the english side of the corpus.
</nextsent>
<nextsent>when only small amounts of parallel corpora were available (i.e. the english hindi subtask), the useof additional resources resulted in absolute improvements of up to 20% as compared to the case when the word alignment systems were based exclusively on the parallel texts.
</nextsent>
<nextsent>interestingly, this was not the case for the language pairs that had larger training corpora (i.e. romanian english, englishinuktitut), where the limited resources systems seemed to lead to comparable or sometime even better results than those that relied on unlimited resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1593">
<title id=" W06-0405.xml">coupling a linguistic formalism and a script language </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>this article presents novel syntactic parser architecture, in which linguistic formalism can be enriched with all sorts of constraints, included extra-linguistic ones, thanks to the seamless coupling of the formalism with programming language.
</prevsent>
</prevsection>
<citsent citstr=" C94-1104 ">
the utilization of constraints in natural language parsers (see blache and balfourier,2001 or tapanainen and jrvinen , 1994) <papid> C94-1104 </papid>is central to most systems today.</citsent>
<aftsection>
<nextsent>however, these constraints are often limited to purely linguistic features, such as linearity or dependency relations between categories within given syntactic tree.
</nextsent>
<nextsent>most linguistic formalisms have been created with the sole purpose of extracting linguistic information from bits and pieces of text.
</nextsent>
<nextsent>they usually use launch and forget strategy, where text is analyzed according to local constraints, displayed and then discarded to make room for the next block of text.
</nextsent>
<nextsent>these parsers take each sentence as an independent input, on which grammar rules are applied together with constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1594">
<title id=" W06-0405.xml">coupling a linguistic formalism and a script language </title>
<section> scripting.  </section>
<citcontext>
<prevsection>
<prevsent>the xpath language is used to query this document in order to retrieve salient information at parsing time, which is then translated into local linguistic features.
</prevsent>
<prevsent>however, only static information can be exploited, as these xml databases must be built beforehand.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
similar mechanisms have also been proposed in other architectures to help heterogeneous linguistic modules to communicate through common xml interface (see cunningham et al,2002, <papid> P02-1022 </papid>blache and gunot , 2003).</citsent>
<aftsection>
<nextsent>these architectures are very powerful as they connect together tools that only need to comply with common in put/output dtd.
</nextsent>
<nextsent>specialized java modules can then be written which are applied to intermediate representations to add their own touch of extra linguistic data.
</nextsent>
<nextsent>since, the intermediate representation is an xml document, the number of possible enrichments is almost limitless, as each module will only extract from this document the xml markup tags that it is designed to handle.
</nextsent>
<nextsent>however, since xml is by nature furiously verbose, the overall system might be very slow as it might spend large amount of time translating external xml representation into internal representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1595">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the number of books in narrative style that are available in digital form is rapidly increasing through projects such as project gutenberg and the million book project at carnegie mellonuniversity.
</prevsent>
<prevsent>access to these collections is becoming easier with directories such as the online books page at the university of pennsylvania.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
as text analysis and retrieval moves from retrieval of documents to retrieval of document passages, the ability to segment documents into smaller, coherent regions enables more precise retrieval of meaningful portions of text (hearst, 1994) <papid> P94-1002 </papid>and improved question answering.</citsent>
<aftsection>
<nextsent>segmentation also has application sin other areas of information access, including document navigation (choi, 2000), anaphora and ellipsis resolution, and text summarization (kozima, 1993).<papid> P93-1041 </papid>research projects on text segmentation have focused on broadcast news stories (beeferman et al, 1999), expository texts (hearst, 1994) <papid> P94-1002 </papid>and synthetic texts (li and yamanishi, 2000; <papid> W00-1305 </papid>brants et al, 2002).broadcast news stories contain cues that are indicative of new story, such as coming up?, or phrases that introduce reporter, which are not applicable to written text.</nextsent>
<nextsent>in expository texts and synthetic texts, there is repetition of terms within topical segment, so that the similarity of blocks?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1598">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>access to these collections is becoming easier with directories such as the online books page at the university of pennsylvania.
</prevsent>
<prevsent>as text analysis and retrieval moves from retrieval of documents to retrieval of document passages, the ability to segment documents into smaller, coherent regions enables more precise retrieval of meaningful portions of text (hearst, 1994) <papid> P94-1002 </papid>and improved question answering.</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
segmentation also has application sin other areas of information access, including document navigation (choi, 2000), anaphora and ellipsis resolution, and text summarization (kozima, 1993).<papid> P93-1041 </papid>research projects on text segmentation have focused on broadcast news stories (beeferman et al, 1999), expository texts (hearst, 1994) <papid> P94-1002 </papid>and synthetic texts (li and yamanishi, 2000; <papid> W00-1305 </papid>brants et al, 2002).broadcast news stories contain cues that are indicative of new story, such as coming up?, or phrases that introduce reporter, which are not applicable to written text.</citsent>
<aftsection>
<nextsent>in expository texts and synthetic texts, there is repetition of terms within topical segment, so that the similarity of blocks?
</nextsent>
<nextsent>of text is useful indicator of topic change.
</nextsent>
<nextsent>synthetic texts are created by concatenating stories, and exhibit stronger topic changes than the sub topic changes within document; consequently, algorithms based on the similarity of text blocks work well on these texts.
</nextsent>
<nextsent>in contrast to these earlier works, we present method for segmenting narrative documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1602">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>access to these collections is becoming easier with directories such as the online books page at the university of pennsylvania.
</prevsent>
<prevsent>as text analysis and retrieval moves from retrieval of documents to retrieval of document passages, the ability to segment documents into smaller, coherent regions enables more precise retrieval of meaningful portions of text (hearst, 1994) <papid> P94-1002 </papid>and improved question answering.</prevsent>
</prevsection>
<citsent citstr=" W00-1305 ">
segmentation also has application sin other areas of information access, including document navigation (choi, 2000), anaphora and ellipsis resolution, and text summarization (kozima, 1993).<papid> P93-1041 </papid>research projects on text segmentation have focused on broadcast news stories (beeferman et al, 1999), expository texts (hearst, 1994) <papid> P94-1002 </papid>and synthetic texts (li and yamanishi, 2000; <papid> W00-1305 </papid>brants et al, 2002).broadcast news stories contain cues that are indicative of new story, such as coming up?, or phrases that introduce reporter, which are not applicable to written text.</citsent>
<aftsection>
<nextsent>in expository texts and synthetic texts, there is repetition of terms within topical segment, so that the similarity of blocks?
</nextsent>
<nextsent>of text is useful indicator of topic change.
</nextsent>
<nextsent>synthetic texts are created by concatenating stories, and exhibit stronger topic changes than the sub topic changes within document; consequently, algorithms based on the similarity of text blocks work well on these texts.
</nextsent>
<nextsent>in contrast to these earlier works, we present method for segmenting narrative documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1605">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> previous approaches.  </section>
<citcontext>
<prevsection>
<prevsent>when the short range model outperforms the long range model, this indicates boundary.
</prevsent>
<prevsent>their method performed well on number of broadcast news datasets, including the cnn dataset from tdt 1997.
</prevsent>
</prevsection>
<citsent citstr=" P99-1046 ">
reynar (1999) <papid> P99-1046 </papid>describes maximum entropy model that combines hand selected features, includ ing: broadcast news domain cues, number of content word bigrams, number of named entities, number of content words that are wordnet synonyms in the left and right regions, percentage of content words in the right segment that are first uses, whether pronouns occur in the first five words, and whether word frequency based algorithm predicts boundary.</citsent>
<aftsection>
<nextsent>he found that for the hub-4 corpus, which is composed of transcribed broadcasts, that the combined feature model performed better than texttiling.mochizuki et al (1998) <papid> P98-2145 </papid>use combination of linguistic cues to segment japanese text.</nextsent>
<nextsent>although anumber of cues do not apply to english (e.g., topical markers), they also use anaphoric expressions and lexical chains as cues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1607">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> previous approaches.  </section>
<citcontext>
<prevsection>
<prevsent>their method performed well on number of broadcast news datasets, including the cnn dataset from tdt 1997.
</prevsent>
<prevsent>reynar (1999) <papid> P99-1046 </papid>describes maximum entropy model that combines hand selected features, includ ing: broadcast news domain cues, number of content word bigrams, number of named entities, number of content words that are wordnet synonyms in the left and right regions, percentage of content words in the right segment that are first uses, whether pronouns occur in the first five words, and whether word frequency based algorithm predicts boundary.</prevsent>
</prevsection>
<citsent citstr=" P98-2145 ">
he found that for the hub-4 corpus, which is composed of transcribed broadcasts, that the combined feature model performed better than texttiling.mochizuki et al (1998) <papid> P98-2145 </papid>use combination of linguistic cues to segment japanese text.</citsent>
<aftsection>
<nextsent>although anumber of cues do not apply to english (e.g., topical markers), they also use anaphoric expressions and lexical chains as cues.
</nextsent>
<nextsent>their study was small, but did indicate that lexical chains are useful cue in some domains.these studies indicate that combination of features can be useful for segmentation.
</nextsent>
<nextsent>however, mochizuki et al (1998) <papid> P98-2145 </papid>analyzed japanese texts, andrey nar (1999) <papid> P99-1046 </papid>and beeferman et al (1999) evaluated on broadcast news stories, which have many cues that narrative texts do not.</nextsent>
<nextsent>beeferman et al (1999) also evaluated on concatenated wall street journal articles, which have stronger topic changes than within document.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1614">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> feature-based segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>the text is preprocessed by tokenizing, removing stop words, and stemming using the inxight linguistix morphological analyzer.
</prevsent>
<prevsent>paragraphs are identified using formatting information.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
sentences are identified using the tnt tokenizer and parts of speech with the tntpart of speech tagger (brants, 2000) <papid> A00-1031 </papid>with the standard english wall street journal n-grams.</citsent>
<aftsection>
<nextsent>named entities are identified using finite state technology (beesley and karttunen, 2003) to identify various entities including: person, location, disease and organization.
</nextsent>
<nextsent>many of these preprocessing steps help provide salient features for use during segmentation.
</nextsent>
<nextsent>4.3 engineered features.
</nextsent>
<nextsent>segmenting narrative documents raises number of interesting challenges.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1615">
<title id=" W05-0405.xml">feature based segmentation of narrative documents </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also compute the sentence error probability, which estimates the probability that randomly chosen pair of sentences sentences apart is incorrectly classified.
</prevsent>
<prevsent>k and are chosen to be half the average length of section in the test data.
</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
window diff (pevzner and hearst, 2002) <papid> J02-1002 </papid>uses sliding window over the data and measures the difference between the number of hypothesized boundaries and the actual boundaries within the win dow.</citsent>
<aftsection>
<nextsent>this metric handles several criticisms of the word error probability metric.
</nextsent>
<nextsent>5.2 segmenting narrative books.
</nextsent>
<nextsent>table 2 shows the results of the svm-segmenter on bio hazard and demon in the freezer.
</nextsent>
<nextsent>a baseline performance for segmentation algorithms is whether the algorithm performs better than naive segmenting algorithms: choose no boundaries, choose all boundaries and choose randomly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1621">
<title id=" W05-1527.xml">supple a practical parser for natural language engineering applications </title>
<section> the supple parser.  </section>
<citcontext>
<prevsection>
<prevsent>1in previous published materials and in the current gate release the parser is referred to as buchart.
</prevsent>
<prevsent>this is name is now deprecated.mars (cf-psgs), written in prolog, that has number of characteristics making it well-suited for use in le applications.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
it is available both as language processing resource within the gate general architecture for text engineering (cunningham et al,2002) <papid> P02-1022 </papid>and as standalone program requiring various preprocessing steps to be applied to the input.</citsent>
<aftsection>
<nextsent>we will here list some of its key characteristics.firstly, the parser allows multiword units identified by earlier processing components, e.g. named entity recognisers (ners), gazette ers, etc, to be treated as non-decomposable units for syntactic processing.
</nextsent>
<nextsent>this is important as the identification of such items is an essential part of analyzing real text in many domains.
</nextsent>
<nextsent>the parser allows layered parsing process, witha number of separate grammars being applied in series, one on top of the other, with best parse?
</nextsent>
<nextsent>selection process between stages so that only subset of the constituents constructed at each stage is passed forward to the next.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1622">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> convergence of qa and summarization.  </section>
<citcontext>
<prevsection>
<prevsent>as the answer to the question what band did the music for the 1970s film saturday night fever???.
</prevsent>
<prevsent>for such well-specified information needs, question answering systems represent an improvement over traditional document retrieval systems because they do not require user to manually browse through ranked list of hits?.
</prevsent>
</prevsection>
<citsent citstr=" N03-1034 ">
since 1999, the nist-organized question answering tracks at trec (see, for example, voorhees 2003<papid> N03-1034 </papid>a) have served as focal point of research in the field, providing an annual forum for evaluating systems developed by teams from all over the world.</citsent>
<aftsection>
<nextsent>the model has been duplicated and elaborated on by clef in europe and ntcir in asia, both of which have also introduced cross-lingual elements.
</nextsent>
<nextsent>recently, research in question answering has shifted away from factoid questions to more complex information needs.
</nextsent>
<nextsent>this new direction can be characterized as move towards answers that canonly be arrived at through some form of reasoning and answers that require drawing information from multiple sources.
</nextsent>
<nextsent>indeed, there are many types of questions that would require integration of both capabilities: extracting raw information nuggets?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1625">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> definition questions: case study.  </section>
<citcontext>
<prevsection>
<prevsent>in many other fields in computational linguistics, the ability to conduct evaluations with quick turnaround has lead torapid progress in the state of the art.
</prevsent>
<prevsent>question an 44swering for definition questions appears to be missing this critical ingredient.to address this evaluation gap, we have recently developed pourpre, method for automatically evaluating definition questions based on idf weighted unigram co-occurrences (lin and demner fushman, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
this idea of employing n-gramco-occurrence statistics to score the output of computer system against one or more desired reference outputs has its roots in the bleu metric forma chine translation (papineni et al, 2002) <papid> P02-1040 </papid>and the rouge (lin and hovy, 2003) <papid> N03-1020 </papid>metric for summarization.</citsent>
<aftsection>
<nextsent>note that metrics for automatically evaluating definitions should be, like metrics for evaluating summaries, biased towards recall.
</nextsent>
<nextsent>fluency (i.e., precision) is not usually of concern because most systems employ extractive techniques to produce answers.
</nextsent>
<nextsent>our study reports good correlation between the automatically computed pourpre metric and official trec system ranks.
</nextsent>
<nextsent>this measure will hopefully spur progress in definition question answering systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1626">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> definition questions: case study.  </section>
<citcontext>
<prevsection>
<prevsent>in many other fields in computational linguistics, the ability to conduct evaluations with quick turnaround has lead torapid progress in the state of the art.
</prevsent>
<prevsent>question an 44swering for definition questions appears to be missing this critical ingredient.to address this evaluation gap, we have recently developed pourpre, method for automatically evaluating definition questions based on idf weighted unigram co-occurrences (lin and demner fushman, 2005).
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
this idea of employing n-gramco-occurrence statistics to score the output of computer system against one or more desired reference outputs has its roots in the bleu metric forma chine translation (papineni et al, 2002) <papid> P02-1040 </papid>and the rouge (lin and hovy, 2003) <papid> N03-1020 </papid>metric for summarization.</citsent>
<aftsection>
<nextsent>note that metrics for automatically evaluating definitions should be, like metrics for evaluating summaries, biased towards recall.
</nextsent>
<nextsent>fluency (i.e., precision) is not usually of concern because most systems employ extractive techniques to produce answers.
</nextsent>
<nextsent>our study reports good correlation between the automatically computed pourpre metric and official trec system ranks.
</nextsent>
<nextsent>this measure will hopefully spur progress in definition question answering systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1627">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> definition questions: case study.  </section>
<citcontext>
<prevsection>
<prevsent>this measure will hopefully spur progress in definition question answering systems.
</prevsent>
<prevsent>the development of automatic evaluation metrics based on n-gram co-occurrence for question answering is an example of successful knowledge transfer from summarization to question answering evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W04-3254 ">
we believe that there exist many more opportunities for future exploration; as an example,there are remarkable similarities between information nuggets in definition question answering and recently-proposed methods for assessing summaries based on fine-grained semantic units (teufel and van halteren, 2004; <papid> W04-3254 </papid>nenkova and passonneau, 2004).<papid> N04-1019 </papid>another promising direction of research in definition question answering involves applying the pyramid method (nenkova and passonneau, 2004) <papid> N04-1019 </papid>to better model the vital/okay nuggets distinction.</citsent>
<aftsection>
<nextsent>asit currently stands, the vital/okay dichotomy is troublesome because there is no way to ope rationalize such classification scheme within system; see hildebrandt et al (2004) <papid> N04-1007 </papid>for more discussion.</nextsent>
<nextsent>yet,the effects on score are significant: system that returns, for example, all the okay nuggets but none of the vital nuggets would receive score of zero.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1628">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> definition questions: case study.  </section>
<citcontext>
<prevsection>
<prevsent>this measure will hopefully spur progress in definition question answering systems.
</prevsent>
<prevsent>the development of automatic evaluation metrics based on n-gram co-occurrence for question answering is an example of successful knowledge transfer from summarization to question answering evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
we believe that there exist many more opportunities for future exploration; as an example,there are remarkable similarities between information nuggets in definition question answering and recently-proposed methods for assessing summaries based on fine-grained semantic units (teufel and van halteren, 2004; <papid> W04-3254 </papid>nenkova and passonneau, 2004).<papid> N04-1019 </papid>another promising direction of research in definition question answering involves applying the pyramid method (nenkova and passonneau, 2004) <papid> N04-1019 </papid>to better model the vital/okay nuggets distinction.</citsent>
<aftsection>
<nextsent>asit currently stands, the vital/okay dichotomy is troublesome because there is no way to ope rationalize such classification scheme within system; see hildebrandt et al (2004) <papid> N04-1007 </papid>for more discussion.</nextsent>
<nextsent>yet,the effects on score are significant: system that returns, for example, all the okay nuggets but none of the vital nuggets would receive score of zero.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1630">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> definition questions: case study.  </section>
<citcontext>
<prevsection>
<prevsent>the development of automatic evaluation metrics based on n-gram co-occurrence for question answering is an example of successful knowledge transfer from summarization to question answering evaluation.
</prevsent>
<prevsent>we believe that there exist many more opportunities for future exploration; as an example,there are remarkable similarities between information nuggets in definition question answering and recently-proposed methods for assessing summaries based on fine-grained semantic units (teufel and van halteren, 2004; <papid> W04-3254 </papid>nenkova and passonneau, 2004).<papid> N04-1019 </papid>another promising direction of research in definition question answering involves applying the pyramid method (nenkova and passonneau, 2004) <papid> N04-1019 </papid>to better model the vital/okay nuggets distinction.</prevsent>
</prevsection>
<citsent citstr=" N04-1007 ">
asit currently stands, the vital/okay dichotomy is troublesome because there is no way to ope rationalize such classification scheme within system; see hildebrandt et al (2004) <papid> N04-1007 </papid>for more discussion.</citsent>
<aftsection>
<nextsent>yet,the effects on score are significant: system that returns, for example, all the okay nuggets but none of the vital nuggets would receive score of zero.
</nextsent>
<nextsent>in truth, the vital/okay distinction is poor attempt at modeling the fact that some nuggets about target are more important than others this is exactly whatthe pyramid method is designed to capture.
</nextsent>
<nextsent>building pyramids?
</nextsent>
<nextsent>for definition questions is an avenue of research that we are currently pursuing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1632">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> putting the relevance in summarization.  </section>
<citcontext>
<prevsection>
<prevsent>as an example, the pyramid method (nenkova and passonneau, 2004), <papid> N04-1019 </papid>represents good first attempt at realistic model of human variations.</prevsent>
<prevsent>second, the view that variations in judgment are an inescapable part of extrinsic evaluations would lead one to conclude that low inter-annotator agreement isnt necessarily bad.</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
computational linguistics research generally attaches great value to high kappa measures (carletta, 1996), <papid> J96-2004 </papid>which indicate high human agreement on particular task.</citsent>
<aftsection>
<nextsent>low agreement is seen as barrier to conducting reproducible research and to drawing generalizable conclusions.
</nextsent>
<nextsent>however, this is not necessarily truelow agreement in information retrieval has not been handicap for advancing the state of the art.
</nextsent>
<nextsent>when dealing with notions such as relevance, low kappa values can most likely be attributed to the nature of the task itself.
</nextsent>
<nextsent>attempting to raise agreement by, for example, developing rigid assessment guidelines, may do more harm than good.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1633">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, it is unclear how exactly one would ope rationalize the evaluation of such capabilities.
</prevsent>
<prevsent>nevertheless, we believe that advanced reasoning capabilities based on detailed semantic analyses of text will receive much attention in the future.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the recent flurry of work on semantic analysis, based on resources such as framenet (baker et al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury et al, 2002), provide the substrate for reasoning engines.</citsent>
<aftsection>
<nextsent>developments inthe automatic construction, adaptation, and merging of ontologies will supply the knowledge necessary to draw inferences.
</nextsent>
<nextsent>in order to jump-start the knowledge acquisition process, we envision the development of domain-specific question answering systems, the lessons from which will be applied to systems that operate on broader domains.
</nextsent>
<nextsent>in terms of ope rationalizing evaluations for these advanced capabilities, the field has already made important first steps, e.g., the pascal recognising textual entailment challenge.what effect will these developments have on summarization research?
</nextsent>
<nextsent>we believe that future systems will employ more detailed linguistic analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1634">
<title id=" W05-0906.xml">evaluating summaries and answers two sides of the same coin </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>fluent, cohesive, and topical summaries cannot be generated solely using an extractive approach sentences are at the wrong level of granularity, source of problems ranging from dangling anaphoric references to verbose subordinate clauses.
</prevsent>
<prevsent>only through more detailed linguistic analysis can information from multiple documents be truly synthesized.
</prevsent>
</prevsection>
<citsent citstr=" W02-0404 ">
already, there are hybrid approaches to multi-document summarization that employ natural language generation techniques (mckeown et al, 1999; elson, 2004), and researchers have experimented with sentential operations to improve the discourse structure of summaries (otterbacher et al, 2002).<papid> W02-0404 </papid></citsent>
<aftsection>
<nextsent>the primary purpose of this paper was to identify similarities between multi-document summarization and complex question answering, pointing out potential synergistic opportunities in the area of system evaluation.
</nextsent>
<nextsent>we hope that this is merely small part of sustained dialogue between researchers from these two largely independent communities.
</nextsent>
<nextsent>answering complex questions and summarizing multiple documents are essentially opposite sides of the same coin, as they represent different approaches tothe common problem of addressing complex user information needs.
</nextsent>
<nextsent>we would like to thank donna harman and ellen voorhees for many insights about the intricacies of ir evaluation, bonnie dorr for introducing us toduc and bringing us into the summarization community, and kiri for her kind support.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1635">
<title id=" W05-0639.xml">the integration of syntactic parsing and semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate the task of semantic role labeling (srl): given verb in sentence, the goal is to locate the constituents which are arguments of the verb, and assign them appropriate semantic roles, such as, agent, patient, and theme.
</prevsent>
<prevsent>previous srl systems have explored the effects of using different lexical features, and experimented on different machine learning algorithms.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
(gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2005; punyakanok et al, 2004) <papid> C04-1197 </papid>however, these srl systems generally extract features from sentences processed by syntactic parser or other shallow parsing components, such as chunker and clause identifier.</citsent>
<aftsection>
<nextsent>as result, the performance of the srl systems relies heavily on those syntax-analysis tools.
</nextsent>
<nextsent>in order to improve the fundamental performance of an srl system, we trained parsers with training data containing not only syntactic constituent information but also semantic argument information.
</nextsent>
<nextsent>the new parsers generate more correct constituents than that trained on pure syntactic information.
</nextsent>
<nextsent>because the new parser generate different constituents than pure syntactic parser, we also explore the possibility of combining the output of several parsers with the help of voting post-processing component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1636">
<title id=" W05-0639.xml">the integration of syntactic parsing and semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate the task of semantic role labeling (srl): given verb in sentence, the goal is to locate the constituents which are arguments of the verb, and assign them appropriate semantic roles, such as, agent, patient, and theme.
</prevsent>
<prevsent>previous srl systems have explored the effects of using different lexical features, and experimented on different machine learning algorithms.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
(gildea and palmer, 2002; <papid> P02-1031 </papid>pradhan et al, 2005; punyakanok et al, 2004) <papid> C04-1197 </papid>however, these srl systems generally extract features from sentences processed by syntactic parser or other shallow parsing components, such as chunker and clause identifier.</citsent>
<aftsection>
<nextsent>as result, the performance of the srl systems relies heavily on those syntax-analysis tools.
</nextsent>
<nextsent>in order to improve the fundamental performance of an srl system, we trained parsers with training data containing not only syntactic constituent information but also semantic argument information.
</nextsent>
<nextsent>the new parsers generate more correct constituents than that trained on pure syntactic information.
</nextsent>
<nextsent>because the new parser generate different constituents than pure syntactic parser, we also explore the possibility of combining the output of several parsers with the help of voting post-processing component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1637">
<title id=" W05-0639.xml">the integration of syntactic parsing and semantic role labeling </title>
<section> semantic role labeling: the.  </section>
<citcontext>
<prevsection>
<prevsent>the argument identification and classification components are trained with sec 02 21 of the penn treebank corpus.
</prevsent>
<prevsent>2.1 parsing.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
previous srl systems usually use pure syntactic parser, such as (charniak, 2000; <papid> A00-2018 </papid>collins, 1999), to retrieve possible constituents.</citsent>
<aftsection>
<nextsent>once the boundary of constituent is defined, there is no way to chang eit in later phases.
</nextsent>
<nextsent>therefore the quality of the syntactic parser has major impact on the final per 237 formance of an srl system, and the percentage of correct constituents that is generated by the syntactic parser also defines the recall upper bound of ansrl system.
</nextsent>
<nextsent>in order to attack this problem, in addition to charniaks parser (charniak, 2000), <papid> A00-2018 </papid>our system combine two parser which are trained on both syntactic constituent information and semantic argument information.</nextsent>
<nextsent>(see section 3) 2.2 pruning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1639">
<title id=" W05-0639.xml">the integration of syntactic parsing and semantic role labeling </title>
<section> semantic role labeling: the.  </section>
<citcontext>
<prevsection>
<prevsent>(see section 3) 2.2 pruning.
</prevsent>
<prevsent>given parse tree, pruning component filters out the constituents which are unlikely to be semantic arguments in order to facilitate the training of the argument identification component.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
our system uses the heuristic rules introduced by (xue and palmer,2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>the heuristics first spot the verb and then extract all the sister nodes along the verb spine of the parse tree.
</nextsent>
<nextsent>we expand the coverage by also extracting all the immediate children of an s, advp, pp and np node.
</nextsent>
<nextsent>this stage generally prunes off about 80% of the constituents given by parser.
</nextsent>
<nextsent>for our newly trained parsers, we also extract constituents which have secondary constituent label indicating the constituent in question is an argument.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1641">
<title id=" W05-0639.xml">the integration of syntactic parsing and semantic role labeling </title>
<section> training parser with semantic.  </section>
<citcontext>
<prevsection>
<prevsent>instead of passively accepting candidate constituents from the upstream syntactic parser, an srl system needs to interact with the parser in order to obtain improved performance.
</prevsent>
<prevsent>this motivated our first attempt which is to integrate syntactic parsing and semantic parsing as single step, and hopefully as result we would be able to discard the srl pipeline.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
the idea is to augment the penn treebank (marcus et al, 1994) <papid> H94-1020 </papid>constituent labels with the semantic role labels from the propbank (palmer et al, 2005), <papid> J05-1004 </papid>and generate rich training corpus.</citsent>
<aftsection>
<nextsent>for example, if an np is also an ar 238 gument arg0 of verb in the given sentence, we change the constituent label np into np-arg0.
</nextsent>
<nextsent>a parser therefore is trained on this new corpus and should be able to serve as an srl system at the same time as predicting parse.
</nextsent>
<nextsent>however, this ideal approach is not feasible.
</nextsent>
<nextsent>given the fact that there are many different semantic role labels and the same constituent can be different arguments of different verbs in the same sentence, the number of constituent labels will soon grow outof control and make the parser training computationally infeasible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1642">
<title id=" W05-0639.xml">the integration of syntactic parsing and semantic role labeling </title>
<section> training parser with semantic.  </section>
<citcontext>
<prevsection>
<prevsent>instead of passively accepting candidate constituents from the upstream syntactic parser, an srl system needs to interact with the parser in order to obtain improved performance.
</prevsent>
<prevsent>this motivated our first attempt which is to integrate syntactic parsing and semantic parsing as single step, and hopefully as result we would be able to discard the srl pipeline.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
the idea is to augment the penn treebank (marcus et al, 1994) <papid> H94-1020 </papid>constituent labels with the semantic role labels from the propbank (palmer et al, 2005), <papid> J05-1004 </papid>and generate rich training corpus.</citsent>
<aftsection>
<nextsent>for example, if an np is also an ar 238 gument arg0 of verb in the given sentence, we change the constituent label np into np-arg0.
</nextsent>
<nextsent>a parser therefore is trained on this new corpus and should be able to serve as an srl system at the same time as predicting parse.
</nextsent>
<nextsent>however, this ideal approach is not feasible.
</nextsent>
<nextsent>given the fact that there are many different semantic role labels and the same constituent can be different arguments of different verbs in the same sentence, the number of constituent labels will soon grow outof control and make the parser training computationally infeasible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1643">
<title id=" W06-0140.xml">chinese named entity recognition with a multi phase model </title>
<section> chinese ner with multi-level models.  </section>
<citcontext>
<prevsection>
<prevsent>t k ttkk tossf osp 1 1 1 ),,,(exp 1 )|( ? where ),,,( 1 tossf ttk ? is an arbitrary feature function over its arguments, and is learned weight for each feature function.
</prevsent>
<prevsent>based on crfs model, we cast the segmentation problem as sequence tagging problem.
</prevsent>
</prevsection>
<citsent citstr=" C04-1081 ">
different from (peng et al, 2004), <papid> C04-1081 </papid>we represent the positions of hanzi (chinese character) with four different tags: for hanzi that starts word, for hanzi that continues the word, for hanzi that ends the word, for hanzi that occurs as single-character word.</citsent>
<aftsection>
<nextsent>the basic segmentation is process of labeling each hanzi with tag given the features derived from its surrounding context.
</nextsent>
<nextsent>the features used in our experiment can be broken into two categories: character features and word features.
</nextsent>
<nextsent>the character features are instan tia tions of the following templates, similar to those described in (ng and jin, 2004), <papid> W04-3236 </papid>refers to chinese hanzi.</nextsent>
<nextsent>(a) cn (n = 2,1,0,1,2 ) (b) cncn+1( = 2,1,0,1) (c) c1c1 (d) pu(c0 ) in addition to the character features, we came up with another type word context feature which was found very useful in our experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1644">
<title id=" W06-0140.xml">chinese named entity recognition with a multi phase model </title>
<section> chinese ner with multi-level models.  </section>
<citcontext>
<prevsection>
<prevsent>the basic segmentation is process of labeling each hanzi with tag given the features derived from its surrounding context.
</prevsent>
<prevsent>the features used in our experiment can be broken into two categories: character features and word features.
</prevsent>
</prevsection>
<citsent citstr=" W04-3236 ">
the character features are instan tia tions of the following templates, similar to those described in (ng and jin, 2004), <papid> W04-3236 </papid>refers to chinese hanzi.</citsent>
<aftsection>
<nextsent>(a) cn (n = 2,1,0,1,2 ) (b) cncn+1( = 2,1,0,1) (c) c1c1 (d) pu(c0 ) in addition to the character features, we came up with another type word context feature which was found very useful in our experiments.
</nextsent>
<nextsent>the feature captures the relationship between the hanzi and the word which contains the hanzi.
</nextsent>
<nextsent>for two-hanzi word, for example, the first hanzi ???
</nextsent>
<nextsent>within the word ????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1645">
<title id=" W05-0102.xml">teaching dialogue to interdisciplinary teams through tool kits </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and yet, itis clearly impracticable to have students in quarter long or semester-long course build dialogue system from scratch.
</prevsent>
<prevsent>for this reason, instructors ofthese courses have experimented with various options to allow students to view the code of working dialogue system, tweak code, or build their own application using dialogue system toolkit.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
some popular options include the nltk (loper and bird, 2002), <papid> W02-0109 </papid>cslu (cole, 1999), trindi (larsson and traum, 2000) and regulus (rayner et al, 2003) <papid> E03-2010 </papid>toolkits.</citsent>
<aftsection>
<nextsent>however, each of these options has turned out to have disadvantages.
</nextsent>
<nextsent>some of the tool kits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist.
</nextsent>
<nextsent>what is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to,and tweak ability of, the models of discourse for advanced students.in addition, as computational linguists become increasingly interested in the role of non-verbal behavior in discourse and dialogue, more of us would like to give our students exposure to models of the interaction between language and nonverbal behaviors such as eye gaze, head nods and hand gestures.however, the available dialogue system tool kits either have no graphical body or if they do have (part of) bodyas in the case of the cslu toolkitthetoolkit does not allow the implementation of alternative models of body language interaction.
</nextsent>
<nextsent>we feel, therefore, that there is need for toolkit that allows the beginning graduate student who may have some computer science or some linguistics background, but not bothto implement aworking embodied dialogue system, as way to experiment with models of discourse, dialogue, collaborative conversation and the interaction between verbal and nonverbal behavior in conversation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1646">
<title id=" W05-0102.xml">teaching dialogue to interdisciplinary teams through tool kits </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and yet, itis clearly impracticable to have students in quarter long or semester-long course build dialogue system from scratch.
</prevsent>
<prevsent>for this reason, instructors ofthese courses have experimented with various options to allow students to view the code of working dialogue system, tweak code, or build their own application using dialogue system toolkit.
</prevsent>
</prevsection>
<citsent citstr=" E03-2010 ">
some popular options include the nltk (loper and bird, 2002), <papid> W02-0109 </papid>cslu (cole, 1999), trindi (larsson and traum, 2000) and regulus (rayner et al, 2003) <papid> E03-2010 </papid>toolkits.</citsent>
<aftsection>
<nextsent>however, each of these options has turned out to have disadvantages.
</nextsent>
<nextsent>some of the tool kits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist.
</nextsent>
<nextsent>what is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to,and tweak ability of, the models of discourse for advanced students.in addition, as computational linguists become increasingly interested in the role of non-verbal behavior in discourse and dialogue, more of us would like to give our students exposure to models of the interaction between language and nonverbal behaviors such as eye gaze, head nods and hand gestures.however, the available dialogue system tool kits either have no graphical body or if they do have (part of) bodyas in the case of the cslu toolkitthetoolkit does not allow the implementation of alternative models of body language interaction.
</nextsent>
<nextsent>we feel, therefore, that there is need for toolkit that allows the beginning graduate student who may have some computer science or some linguistics background, but not bothto implement aworking embodied dialogue system, as way to experiment with models of discourse, dialogue, collaborative conversation and the interaction between verbal and nonverbal behavior in conversation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1649">
<title id=" W05-0102.xml">teaching dialogue to interdisciplinary teams through tool kits </title>
<section> framing the problem.  </section>
<citcontext>
<prevsection>
<prevsent>we have found this concretely in our work.
</prevsent>
<prevsent>what got linguists involved in the computational exploration of dialogue semantics at rutgers was not the special teaching resources stone created.
</prevsent>
</prevsection>
<citsent citstr=" P05-3001 ">
it was hooking students up with the systems that were being actively developed in ongoing research (devault et al, 2005).<papid> P05-3001 </papid></citsent>
<aftsection>
<nextsent>these research efforts made it practical to provide students with thevisualizations, task and context models, and interactive architecture they needed to explore substantive issues in dialogue semantics.
</nextsent>
<nextsent>whatever we do will have to closely connect teaching and our ongoing research.
</nextsent>
<nextsent>our experience teaching dialogue to interdisciplinary teams through tool kits has been humbling.
</nextsent>
<nextsent>we have new appreciation for the differences between coursework and research infrastructure supporting teaching may be harder, because students require broader spectrum of implementation, faster learning curve and the ability to explore mistaken ideas as well as promising ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1650">
<title id=" W04-3242.xml">random forests in language modeling </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>since our current rf models uses kn smoothing exclusively in lower order probabilities,3for the * -test, we used the standard sclites statistical system comparison program from nist with the option mapsswe?, which means the test is the matched pairs sentence segment word error test.
</prevsent>
<prevsent>it may not be adequate when we apply it to higher order  -gram models.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
one possible solution is to use rf models for lower order probabilities as well.higher order rfs will be grown based on lower order rfs which can be recursively grown.another interesting application of our new approach is parser based language models where rich syntactic information is available (chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001; xu et al., 2002).<papid> P02-1025 </papid></citsent>
<aftsection>
<nextsent>when we use rfs for those models,there are potentially many different syntactic questions at each node split.
</nextsent>
<nextsent>for example, there can be questions such as is there noun phrase or noun among the previous  exposed heads??, etc. such kinds of questions can be encoded and included in the history.
</nextsent>
<nextsent>since the length of the history could be very large, better smoothing method would bevery useful.
</nextsent>
<nextsent>composite questions in the form of pylons (bahl et al, 1989) can also be used.as we mentioned at the end of section 3.2, random samples of the training data can also be used for dt growing and has been proven to be useful for classification problems (amit and geman, 1997; breiman, 2001; ho, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1651">
<title id=" W04-3242.xml">random forests in language modeling </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>since our current rf models uses kn smoothing exclusively in lower order probabilities,3for the * -test, we used the standard sclites statistical system comparison program from nist with the option mapsswe?, which means the test is the matched pairs sentence segment word error test.
</prevsent>
<prevsent>it may not be adequate when we apply it to higher order  -gram models.
</prevsent>
</prevsection>
<citsent citstr=" P02-1025 ">
one possible solution is to use rf models for lower order probabilities as well.higher order rfs will be grown based on lower order rfs which can be recursively grown.another interesting application of our new approach is parser based language models where rich syntactic information is available (chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001; xu et al., 2002).<papid> P02-1025 </papid></citsent>
<aftsection>
<nextsent>when we use rfs for those models,there are potentially many different syntactic questions at each node split.
</nextsent>
<nextsent>for example, there can be questions such as is there noun phrase or noun among the previous  exposed heads??, etc. such kinds of questions can be encoded and included in the history.
</nextsent>
<nextsent>since the length of the history could be very large, better smoothing method would bevery useful.
</nextsent>
<nextsent>composite questions in the form of pylons (bahl et al, 1989) can also be used.as we mentioned at the end of section 3.2, random samples of the training data can also be used for dt growing and has been proven to be useful for classification problems (amit and geman, 1997; breiman, 2001; ho, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1652">
<title id=" W06-0706.xml">automating help desk responses a comparative study of information gathering approaches </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, prediction could yield replies that do not match particular query terms.
</prevsent>
<prevsent>observation o2 leads us to consider two levels of granularity: document and sentence.
</prevsent>
</prevsection>
<citsent citstr=" C04-1057 ">
that is,we can obtain document comprising complete answer on the basis of request (i.e., reuse an answer to previous request), or we can obtain individual sentences and then combine them to compose an answer, as is done in multi document summarization (filatova and hatzivassiloglou, 2004).<papid> C04-1057 </papid></citsent>
<aftsection>
<nextsent>the sentence-level granu a3: if you are able to see the internet then it sounds like it is working, you may want to get in touch with your it department to see if you need to make any changes to your settings to get it to work.
</nextsent>
<nextsent>try performing soft reset, by pressing the stylus pen in the small hole on the bottom left hand side of the ipaq and then release.
</nextsent>
<nextsent>a4: would recommend doing soft reset by pressing the stylus pen in the small hole on the left hand side of the ipaq and then release.
</nextsent>
<nextsent>then charge the unit overnight to make sure it has been long enough and then see what happens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1654">
<title id=" W06-0706.xml">automating help desk responses a comparative study of information gathering approaches </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>however, when there are not enough similar cases in the dataset (as is the case with the three datasets referred to above), answer prediction is not able to generalize from them, and therefore we can only rely on new request closely matching an old request or an old answer.
</prevsent>
<prevsent>the answer prediction method can address 29% of the requests.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
only about tenth of these 7we have also employed sequence-based measures using the rouge tool set (lin and hovy, 2003), <papid> N03-1020 </papid>with similar results to those obtained with the word-by-word measure.</citsent>
<aftsection>
<nextsent>are uniquely addressed by this method, but the generated responses are of fairly high quality, with an average precision and f-score of 0.82.
</nextsent>
<nextsent>notice the large standard deviation of these averages, suggesting somewhat inconsistent behaviour.
</nextsent>
<nextsent>this is due to the fact that this method gives good results only when complete template responses are found.
</nextsent>
<nextsent>in this case, any re-used response will have high similarity to the actual response.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1655">
<title id=" W06-0706.xml">automating help desk responses a comparative study of information gathering approaches </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>there trieval system eresponder (carmel et al, 2000) is similar to our answer retrieval method, where the system retrieves list of request-response pairs and presents ranked list of responses to theuser.
</prevsent>
<prevsent>our results show that due to the repetitions in the responses, multi-document summarization can be used to produce single (possibly partial) representative response.
</prevsent>
</prevsection>
<citsent citstr=" P00-1038 ">
this is recognized by berger and mittal (2000), <papid> P00-1038 </papid>who employ query-relevant summarization to generate re sponses.</citsent>
<aftsection>
<nextsent>however, their corpus consists of faq 46 request-response pairs ? significantly different corpus to ours in that it lacks repetition and redundancy, and where the responses are not personalized.
</nextsent>
<nextsent>lapalme and kosseim (2003) propose retrieval approach similar to our answer retrieval method, and question-answering approach, but applied to corpus of technical documents rather than request-response pairs.
</nextsent>
<nextsent>the methods presented in this paper combine different aspects of document retrieval, question-answering and multi document summarization, applied to corpus of repetitive request-response pairs.
</nextsent>
<nextsent>we have presented four basic methods and one hybrid method for addressing help-desk requests.the basic methods represent the four ways of combining level of granularity (sentence and document) with information-gathering technique (pre diction and retrieval).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1656">
<title id=" W06-0903.xml">automatic dating of documents and temporal text classification </title>
<section> background and assumptions.  </section>
<citcontext>
<prevsection>
<prevsent>temporal information extracted from the documents itself is also useful in dating the documents ? for example, if document contains many references to the year 2006, it is quite likely that the document was written in 2006 (or in the last few weeks of december 2005).
</prevsent>
<prevsent>these notions have been used implicitly by researchers and historians when validating the authenticity of documents, but have not been utilised much in automated systems.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
similar applications have so far been largely confined to authorship identification, such as (mosteller and wallace, 1964; fung, 2003) and the identification of association rules (yarowsky, 1994; <papid> P94-1013 </papid>silverstein et al, 1997).</citsent>
<aftsection>
<nextsent>temporal information is presently under utilised for automated document classification purposes, especially when it comes to guessing at the document creation date automatically.
</nextsent>
<nextsent>this work presents method of using periodical temporal-frequency information present in documents to create temporal-association rules that can be used for automatic document dating.
</nextsent>
<nextsent>past and ongoing related research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as timeml/timex (gaizauskas and setzer, 2002; pustejovsky et al, 2003; ferro et al, 2004), tdrl (aramburu and berlanga, 1998) and their associated evaluations such as the ace tern competition (sundheim et al 2004).
</nextsent>
<nextsent>temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al, 2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (bogu raev and ando, 2005; moldovan et al, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1657">
<title id=" W06-0903.xml">automatic dating of documents and temporal text classification </title>
<section> background and assumptions.  </section>
<citcontext>
<prevsection>
<prevsent>this work presents method of using periodical temporal-frequency information present in documents to create temporal-association rules that can be used for automatic document dating.
</prevsent>
<prevsent>past and ongoing related research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as timeml/timex (gaizauskas and setzer, 2002; pustejovsky et al, 2003; ferro et al, 2004), tdrl (aramburu and berlanga, 1998) and their associated evaluations such as the ace tern competition (sundheim et al 2004).
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al, 2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (bogu raev and ando, 2005; moldovan et al, 2005).</citsent>
<aftsection>
<nextsent>a growing body of related work related to the computational treatment of time in language has also been building up largely since 2000 (col ing 2000; acl 2001; lrec 2002; terqas 2002; tango 2003, dagstuhl 2005).
</nextsent>
<nextsent>there is also large body of work on time series analysis and temporal logic in physics, economics and mathematics, providing important techniques and general background information.
</nextsent>
<nextsent>in particular, this work uses techniques adapted from seasonal arima (auto-regressive integrated moving average) models (sarima).
</nextsent>
<nextsent>sarima models are class of seasonal, non stationary temporal models based on the arima process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1658">
<title id=" W06-0903.xml">automatic dating of documents and temporal text classification </title>
<section> background and assumptions.  </section>
<citcontext>
<prevsection>
<prevsent>this work presents method of using periodical temporal-frequency information present in documents to create temporal-association rules that can be used for automatic document dating.
</prevsent>
<prevsent>past and ongoing related research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as timeml/timex (gaizauskas and setzer, 2002; pustejovsky et al, 2003; ferro et al, 2004), tdrl (aramburu and berlanga, 1998) and their associated evaluations such as the ace tern competition (sundheim et al 2004).
</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al, 2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (bogu raev and ando, 2005; moldovan et al, 2005).</citsent>
<aftsection>
<nextsent>a growing body of related work related to the computational treatment of time in language has also been building up largely since 2000 (col ing 2000; acl 2001; lrec 2002; terqas 2002; tango 2003, dagstuhl 2005).
</nextsent>
<nextsent>there is also large body of work on time series analysis and temporal logic in physics, economics and mathematics, providing important techniques and general background information.
</nextsent>
<nextsent>in particular, this work uses techniques adapted from seasonal arima (auto-regressive integrated moving average) models (sarima).
</nextsent>
<nextsent>sarima models are class of seasonal, non stationary temporal models based on the arima process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1659">
<title id=" W06-0903.xml">automatic dating of documents and temporal text classification </title>
<section> background and assumptions.  </section>
<citcontext>
<prevsection>
<prevsent>this work presents method of using periodical temporal-frequency information present in documents to create temporal-association rules that can be used for automatic document dating.
</prevsent>
<prevsent>past and ongoing related research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as timeml/timex (gaizauskas and setzer, 2002; pustejovsky et al, 2003; ferro et al, 2004), tdrl (aramburu and berlanga, 1998) and their associated evaluations such as the ace tern competition (sundheim et al 2004).
</prevsent>
</prevsection>
<citsent citstr=" N03-2019 ">
temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al, 2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (bogu raev and ando, 2005; moldovan et al, 2005).</citsent>
<aftsection>
<nextsent>a growing body of related work related to the computational treatment of time in language has also been building up largely since 2000 (col ing 2000; acl 2001; lrec 2002; terqas 2002; tango 2003, dagstuhl 2005).
</nextsent>
<nextsent>there is also large body of work on time series analysis and temporal logic in physics, economics and mathematics, providing important techniques and general background information.
</nextsent>
<nextsent>in particular, this work uses techniques adapted from seasonal arima (auto-regressive integrated moving average) models (sarima).
</nextsent>
<nextsent>sarima models are class of seasonal, non stationary temporal models based on the arima process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1660">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the ability to categorize distinct word sequences as meaning the same thing?
</prevsent>
<prevsent>is vital to applications as diverse as search, summarization, dialog, and question answering.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
recent research has treated paraphrase acquisition and generation as machine learning problem (barzilay &amp; mckeown, 2001; <papid> P01-1008 </papid>lin &amp; pantel, 2002; shinyama et al 2002, barzilay &amp; lee, 2003, <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>we approach this problem as one of statistical machine translation (smt), within the noisy channel model of brown et al (1993).<papid> J93-2003 </papid></nextsent>
<nextsent>that is, we seek to identify the optimal paraphrase t* of sentence by finding: ( ){ } { })p()|p(maxarg |pmaxarg* tts stt t = = and being sentences in the same language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1661">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the ability to categorize distinct word sequences as meaning the same thing?
</prevsent>
<prevsent>is vital to applications as diverse as search, summarization, dialog, and question answering.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
recent research has treated paraphrase acquisition and generation as machine learning problem (barzilay &amp; mckeown, 2001; <papid> P01-1008 </papid>lin &amp; pantel, 2002; shinyama et al 2002, barzilay &amp; lee, 2003, <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>we approach this problem as one of statistical machine translation (smt), within the noisy channel model of brown et al (1993).<papid> J93-2003 </papid></nextsent>
<nextsent>that is, we seek to identify the optimal paraphrase t* of sentence by finding: ( ){ } { })p()|p(maxarg |pmaxarg* tts stt t = = and being sentences in the same language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1662">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the ability to categorize distinct word sequences as meaning the same thing?
</prevsent>
<prevsent>is vital to applications as diverse as search, summarization, dialog, and question answering.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
recent research has treated paraphrase acquisition and generation as machine learning problem (barzilay &amp; mckeown, 2001; <papid> P01-1008 </papid>lin &amp; pantel, 2002; shinyama et al 2002, barzilay &amp; lee, 2003, <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>we approach this problem as one of statistical machine translation (smt), within the noisy channel model of brown et al (1993).<papid> J93-2003 </papid></nextsent>
<nextsent>that is, we seek to identify the optimal paraphrase t* of sentence by finding: ( ){ } { })p()|p(maxarg |pmaxarg* tts stt t = = and being sentences in the same language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1663">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is vital to applications as diverse as search, summarization, dialog, and question answering.
</prevsent>
<prevsent>recent research has treated paraphrase acquisition and generation as machine learning problem (barzilay &amp; mckeown, 2001; <papid> P01-1008 </papid>lin &amp; pantel, 2002; shinyama et al 2002, barzilay &amp; lee, 2003, <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we approach this problem as one of statistical machine translation (smt), within the noisy channel model of brown et al (1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>that is, we seek to identify the optimal paraphrase t* of sentence by finding: ( ){ } { })p()|p(maxarg |pmaxarg* tts stt t = = and being sentences in the same language.
</nextsent>
<nextsent>we describe and evaluate an smt-based paraphrase generation system that utilizes monotone phrasal decoder to generate meaning-preserving paraphrases across multiple domains.
</nextsent>
<nextsent>by adopting at the outset paradigm geared toward generating sentences, this approach overcomes many problems encountered by task-specific approaches.
</nextsent>
<nextsent>in particular, we show that smt techniques can be extended to paraphrase given sufficient monolingual parallel data.1 we show that huge corpus of comparable and alignable sentence pairs can be culled from ready-made topical/temporal clusters of news articles gathered on daily basis from thousands of sources on the world wide web, thereby permitting the system to operate outside the narrow domains typical of existing systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1665">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we show that smt techniques can be extended to paraphrase given sufficient monolingual parallel data.1 we show that huge corpus of comparable and alignable sentence pairs can be culled from ready-made topical/temporal clusters of news articles gathered on daily basis from thousands of sources on the world wide web, thereby permitting the system to operate outside the narrow domains typical of existing systems.
</prevsent>
<prevsent>until recently, efforts in paraphrase were not strongly focused on generation and relied primarily on narrow data sources.
</prevsent>
</prevsection>
<citsent citstr=" W03-1608 ">
one data source has been multiple translations of classic literary works (bar zilay &amp; mckeown 2001; <papid> P01-1008 </papid>ibrahim 2002; ibrahim et al. 2003).<papid> W03-1608 </papid></citsent>
<aftsection>
<nextsent>pang et al (2003) <papid> N03-1024 </papid>obtain parallel monolingual texts from set of 100 multiply-translated news articles.</nextsent>
<nextsent>while translation-based approaches to obtaining data do address the problem of how to identify two strings as meaning the same thing, they are limited in scala bility owing to the difficulty (and expense) of obtaining large quantities of multiply-translated source documents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1671">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>mean levenshtein distance was 5.17; mean sentence length was 18.6 words.
</prevsent>
<prevsent>3.2 word alignment.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
to this corpus we applied the word alignment algorithms available in giza++ (och &amp; ney, 2000), <papid> P00-1056 </papid>freely available implementation of ibm models 1-5 (brown, 1993) and the hmm alignment (vogel et al 1996), <papid> C96-2141 </papid>along with various improvements and modifications motivated by experimentation by och &amp; ney (2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>in order to capture the many-to-many alignments that identify correspondences between idioms and other phrasal chunks, we align in the forward direction and again in the backward direction, heuristic ally re combining each unidirectional word alignment into single bidirectional alignment (och &amp; ney 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>figure 1 shows an example of monolingual alignment produced by giza++.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1672">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>mean levenshtein distance was 5.17; mean sentence length was 18.6 words.
</prevsent>
<prevsent>3.2 word alignment.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
to this corpus we applied the word alignment algorithms available in giza++ (och &amp; ney, 2000), <papid> P00-1056 </papid>freely available implementation of ibm models 1-5 (brown, 1993) and the hmm alignment (vogel et al 1996), <papid> C96-2141 </papid>along with various improvements and modifications motivated by experimentation by och &amp; ney (2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>in order to capture the many-to-many alignments that identify correspondences between idioms and other phrasal chunks, we align in the forward direction and again in the backward direction, heuristic ally re combining each unidirectional word alignment into single bidirectional alignment (och &amp; ney 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>figure 1 shows an example of monolingual alignment produced by giza++.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1676">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>differences were highlighted and the annotators were asked to review their choices on these differences.
</prevsent>
<prevsent>finally we combined the two annotations into single gold stan dard: if both annotators agreed that an alignment should be sure, then the alignment was marked as sure in the gold-standard; otherwise the alignment was marked as possible.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
to compute precision, recall, and alignment error rate (aer) for the twin datasets, we used exactly the formulae listed in och &amp; ney (2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>let be the set of alignments in the comparison, be the set of sure alignments in the gold standard, and be the union of the sure and possible alignments in the gold standard.
</nextsent>
<nextsent>then we have: || ||precision pa ? = || || recall sa ? = || ||aer sa sapa + ?+?
</nextsent>
<nextsent>= measured in terms of aer4, final interrater agreement between the two annotators on the 250 sentences was 93.1%.
</nextsent>
<nextsent>4 the formula for aer given here and in och &amp; ney (2003) <papid> J03-1002 </papid>is intended to compare an automatic alignment against gold standard alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1679">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>ab lation experiments, not described here, indicate that additional data will improve aer.
</prevsent>
<prevsent>3.3 identifying phrasal replacements.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
recent work in smt has shown that simple phrase-based mt systems can outperform more sophisticated word-based systems (e.g. koehn et al. 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>therefore, we adopt phrasal decoder patterned closely after that of vogel et al (2003).
</nextsent>
<nextsent>we view the source and target sentences and as word sequences s1..sm and t1..tn.
</nextsent>
<nextsent>a word alignment of and can be expressed as function from each of the source and target tokens to unique cept (brown et al 1993); <papid> J93-2003 </papid>isomorphically, cept represents an aligned subset of the source and target tokens.</nextsent>
<nextsent>then, forgiven sentence pair and word alignment, we define phrase pair as subset of the cepts in which both the source and target tokens are contiguous.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1682">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>collocations and other non-compositional phrases receive higher probability as whole than they would as independent single word replacements.
</prevsent>
<prevsent>one further simplification was made.
</prevsent>
</prevsection>
<citsent citstr=" P97-1037 ">
given that our domain is restricted to the generation of monolingual paraphrase, interesting output can be produced without tackling the difficult problem of inter-phrase reordering.7 therefore, along the lines of tillmann et al (1997), <papid> P97-1037 </papid>we relyon only monotone phrasal alignments, although we do allow in tra-phrasal reordering.</citsent>
<aftsection>
<nextsent>while this means certain common structural alternations (e.g., ac tive/passive) cannot be generated, we are still able to express broad range of phenomena: pings to be both unwieldy in practice and very often indicative of poor word alignment.
</nextsent>
<nextsent>7 even in the realm of mt, such an assumption can produce competitive results (vogel et al 2003).
</nextsent>
<nextsent>in addition, we were hesitant to incur the exponential increase in running time associated with those movement models in the tradition of brown el al (1993), especially since these offset models fail to capture important linguistic generalizations (e.g., phrasal coherence, headedness).
</nextsent>
<nextsent>synonymy: injured ? wounded ? phrasal replacements: bush administration ? white house ? intra-phrasal reorderings: margin of error ? error margin our channel model, then, is determined solely by the phrasal replacements involved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1692">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>should these facts be interpreted to mean that msa, with its more dramatic rewrites, is ultimately more ambitious than pr?
</prevsent>
<prevsent>we believe that the opposite is true.
</prevsent>
</prevsection>
<citsent citstr=" W01-1401 ">
a close look at msa suggests that it is similar in spirit to example-based machine translation techniques that relyon pairing entire sentences in source and target languages, with the translation step limited to local adjustments of the target sentence (e.g. sumita 2001).<papid> W01-1401 </papid></citsent>
<aftsection>
<nextsent>when an input sentence closely matches template, results can be stunning.
</nextsent>
<nextsent>however, msa achieves its richness of substitution at the cost of generality.
</nextsent>
<nextsent>inspection reveals that 15 of the 59 msa paraphrases, or 25.4%, are based on single high-frequency, do main-specific template (essentially running tally of deaths in the israeli-palestinian conflict).
</nextsent>
<nextsent>unless one is prepared to assume that similar templates can be found for most sentence types, scala bility and domain extensibility appear beyond the reach of msa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1693">
<title id=" W04-3219.xml">monolingual machine translation for paraphrase generation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>relying on edit distance to identify likely paraphrases has the unfortunate result of excluding interesting sentence pairs that are similar in meaning though different in form.
</prevsent>
<prevsent>for example: the cassini spacecraft, which is enroute to saturn, is about to make close pass of the ringed planet mysterious moon phoebe on its way to an extended mission at saturn, the cassini probe on friday makes its closest rendezvous with saturn dark moon phoebe.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
we are currently experimenting with data extracted from the first two sentences in each article, which by journalistic convention tend to summarize content (dolan et al 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>while noisier than the edit distance data, initial results suggest that these can be rich source of information about larger phrasal substitutions and syntactic reordering.
</nextsent>
<nextsent>although we have not attempted to address the issue of paraphrase identification here, we are currently exploring machine learning techniques, based in part on features of document structure and other linguistic features that should allow us to bootstrap initial alignments to develop more data.
</nextsent>
<nextsent>this will we hope, eventually allow us to address such issues as paraphrase identification for ir.
</nextsent>
<nextsent>to exploit richer datasets, we will also seek to address the monotone limitation of our decoder that further limits the complexity of our paraphrase output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1694">
<title id=" W06-0803.xml">extracting key phrases to disambiguate personal name queries in web search </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as measure of the strength of the relationship between two people aand b, these algorithms use the number of hits obtained for the query and b. however, this approach fails when or has namesakes because the number of hits in these cases includes the hits for the namesakes.
</prevsent>
<prevsent>to overcome this problem, we could include phrases in the query that uniquely identify and from their namesakes.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
person name disambiguation can be seen as special case of word sense disambiguation (wsd) (schutze, 1998; mccarthy et al, 2004) <papid> P04-1036 </papid>problem which has been studied extensively in natural language understanding.</citsent>
<aftsection>
<nextsent>however, there are several fundamental differences between wsd and person name disambiguation.
</nextsent>
<nextsent>wsd typically concentrates on disambiguating between 2-4 possible meanings of the word, all of which are apriori known.
</nextsent>
<nextsent>however, in person name disambiguation in web, the number of different namesakes can be much larger and unknown.
</nextsent>
<nextsent>from resource point of view, wsd utilizes sense tagged dictionaries such as wordnet, whereas no dictionary can provide information regarding different namesakes for particular name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1695">
<title id=" W06-0803.xml">extracting key phrases to disambiguate personal name queries in web search </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of person name disambiguation has been addressed in the domain of research paper citations (han et al, 2005), with various supervised methods proposed for its solution.
</prevsent>
<prevsent>however, citations have fixed format compared to free texton the web.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
fields such as co-authors, title, journal name, conference name, year of publication can be easily extracted from citation and provide vital information to the disambiguation process.research on multi-document person name resolution (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003; <papid> W03-0405 </papid>fleischman and hovy, 2004) <papid> W04-0701 </papid>focuses on the related problem of determining if 2http://flink.sematicweb.org/.</citsent>
<aftsection>
<nextsent>the system won the 1st place at the semantic web challenge in iswc2004.two instances with the same name and from different documents refer to the same individual.bagga and baldwin (1998) <papid> P98-1012 </papid>first perform within document coreference resolution to form coreference chains for each entity in each document.</nextsent>
<nextsent>they then use the text surrounding each reference chain to create summaries about each entity ineach document.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1696">
<title id=" W06-0803.xml">extracting key phrases to disambiguate personal name queries in web search </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of person name disambiguation has been addressed in the domain of research paper citations (han et al, 2005), with various supervised methods proposed for its solution.
</prevsent>
<prevsent>however, citations have fixed format compared to free texton the web.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
fields such as co-authors, title, journal name, conference name, year of publication can be easily extracted from citation and provide vital information to the disambiguation process.research on multi-document person name resolution (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003; <papid> W03-0405 </papid>fleischman and hovy, 2004) <papid> W04-0701 </papid>focuses on the related problem of determining if 2http://flink.sematicweb.org/.</citsent>
<aftsection>
<nextsent>the system won the 1st place at the semantic web challenge in iswc2004.two instances with the same name and from different documents refer to the same individual.bagga and baldwin (1998) <papid> P98-1012 </papid>first perform within document coreference resolution to form coreference chains for each entity in each document.</nextsent>
<nextsent>they then use the text surrounding each reference chain to create summaries about each entity ineach document.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1697">
<title id=" W06-0803.xml">extracting key phrases to disambiguate personal name queries in web search </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of person name disambiguation has been addressed in the domain of research paper citations (han et al, 2005), with various supervised methods proposed for its solution.
</prevsent>
<prevsent>however, citations have fixed format compared to free texton the web.
</prevsent>
</prevsection>
<citsent citstr=" W04-0701 ">
fields such as co-authors, title, journal name, conference name, year of publication can be easily extracted from citation and provide vital information to the disambiguation process.research on multi-document person name resolution (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003; <papid> W03-0405 </papid>fleischman and hovy, 2004) <papid> W04-0701 </papid>focuses on the related problem of determining if 2http://flink.sematicweb.org/.</citsent>
<aftsection>
<nextsent>the system won the 1st place at the semantic web challenge in iswc2004.two instances with the same name and from different documents refer to the same individual.bagga and baldwin (1998) <papid> P98-1012 </papid>first perform within document coreference resolution to form coreference chains for each entity in each document.</nextsent>
<nextsent>they then use the text surrounding each reference chain to create summaries about each entity ineach document.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1702">
<title id=" W05-0705.xml">modifying a natural language processing system for european languages to treat arabic in information processing and information retrieval applications </title>
<section> information retrieval application:.  </section>
<citcontext>
<prevsection>
<prevsent>an alternative but noisy approach (larkey et al 2002) is to reduce to unvoweled text throughout the nlp application.
</prevsent>
<prevsent>pean languages4, we had to decide how this feature would be handled in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" C96-1017 ">
solutions to this problem have been proposed, ranging from generation and storage of all agglutinated words forms (debili and zouari, 1985) to the compilation of valid sequences of proclitics, words and enclitics into finite-state machines (beesley, 1996).<papid> C96-1017 </papid></citsent>
<aftsection>
<nextsent>our system had already addressed the problem of compounds for german in the following way: if an in put word is not present in the dictionary, compound-searching module returns all complete sequences of dictionary words (a list of possible compound joining  fogemorphemes  is passed to this module) as valid decompositions of the input word.
</nextsent>
<nextsent>though theoretically this method could be used to treat arabic clitics, we decided against using this existing process for two reasons: 1.
</nextsent>
<nextsent>contrary to german, in which any noun.
</nextsent>
<nextsent>may theoretically be the first element of compound, arabic clitics belong to small closed set of articles, conjunctions, prepositions and pronouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1703">
<title id=" W05-0705.xml">modifying a natural language processing system for european languages to treat arabic in information processing and information retrieval applications </title>
<section> information retrieval application:.  </section>
<citcontext>
<prevsection>
<prevsent>all clitic possibilities are computed by using proclitics and enclitics dictionaries.
</prevsent>
<prevsent>a radical, computed by removing these clitics, is checked against the full form lexicon.
</prevsent>
</prevsection>
<citsent citstr=" W02-0506 ">
if it does not exist in the full form lexicon, re-write rules (such as those described in darwish (2002)) <papid> W02-0506 </papid>are applied, and the altered form is checked against the full form dictionary.</citsent>
<aftsection>
<nextsent>for example, consider the token ???? and the included clitics (?, ?), the computed radical ??
</nextsent>
<nextsent>does not exist in the full form lexicon but after applying one of the dozen re-write rules, the modified radical ??
</nextsent>
<nextsent>is found the dictionary and the input token is segmented into root and clitics as: ? + ??
</nextsent>
<nextsent>+ ? = ???? . ? the compatibility of the morpho-syntactic tags of the three components (proclitic, radical, enclitic) is then checked.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1704">
<title id=" W05-0705.xml">modifying a natural language processing system for european languages to treat arabic in information processing and information retrieval applications </title>
<section> information retrieval application:.  </section>
<citcontext>
<prevsection>
<prevsent>tified as such because it is found in the lexicon; the name ??&amp;(,h (lampard) is not in the lexicon and incorrectly stemmed as +??&amp;(, (plural of the noun ?(, (grater)); the name ??!??
</prevsent>
<prevsent>(eidur) is incorrectly tagged as verb; and + )&amp;??b (gudjohnsen), which is not in the dictionary and for which the clitic stemmer does not produce any solutions receives the default tags adjective, noun, proper noun and verb, to be decided by the part-of-speech tagger.
</prevsent>
</prevsection>
<citsent citstr=" W98-1002 ">
to improve this performance, we plan to enrich the arabic lexicon with more proper names, using either name recognition (maloney and niv, 1998) <papid> W98-1002 </papid>or back translation approach after name recognition in english texts (al-onaizan and knight, 2002).</citsent>
<aftsection>
<nextsent>processing steps: part-of-speech analysis for the succeeding steps involving part-of-speech tagging, named entity recognition, division into nominal and verbal chains, and dependency extraction no changes were necessary for treating arabic.
</nextsent>
<nextsent>after morphological analysis, as input to step 2a, part-of-speech tagging, we have the same type of word graph for arabic text as for european text: each node is annotated with the surface form, lemma and part-of-speech in the graph.
</nextsent>
<nextsent>if word is ambiguous, then more than one node appears in the graph for that word.
</nextsent>
<nextsent>our part-of-speech tagging involves using language model (bigrams and trigrams of grammatical tags) derived from hand tagged text to eliminate un attested or rare sub paths in the graph of words representing sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1705">
<title id=" W05-0705.xml">modifying a natural language processing system for european languages to treat arabic in information processing and information retrieval applications </title>
<section> information retrieval application:.  </section>
<citcontext>
<prevsection>
<prevsent>this minor problem was solved by storing the fully voweled forms of the entities (for application such as information retrieval as shown below) rather than the surface form.
</prevsent>
<prevsent>after named entity recognition, our methods of verbal and nominal chain recognition and dependency extraction did not require any modifications for arabic.
</prevsent>
</prevsection>
<citsent citstr=" P84-1108 ">
but since the sentence graphs, as mentioned above, are currently large, we have restricted the chains recognized to simple noun and verb chunks (abney, 1991) rather than the more complex chains (marsh, 1984) <papid> P84-1108 </papid>we recognize for european languages.</citsent>
<aftsection>
<nextsent>likewise, the only dependency relations that we extract for the moment are relations between nominal elements.
</nextsent>
<nextsent>we expect that the reduction in sentence graph once lemmas are all collected in the same word node will allow us to treat more complex dependency relations.
</nextsent>
<nextsent>the results of the nlp steps produce, for all languages we treat, set of normalized lemmas, set of named entities and set of nominal compounds (as well as other dependency relations for some languages).
</nextsent>
<nextsent>these results can be used for any natural language processing application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1706">
<title id=" W06-0605.xml">frontiers in linguistic annotation for lower density languages </title>
<section> linguistically annotated resources.  </section>
<citcontext>
<prevsection>
<prevsent>morphologically analyzed text (for non isolating languages; at issue here is particularly inflectional morphology, and to lesser degree of importance for most computational purposes, derivational morphology); also morphological tag schema appropriate to the particular language ? text marked for word boundaries (for those scripts which, like thai, do not mark most word boundaries)?
</prevsent>
<prevsent>pos tagged text, and pos tag schema appropriate to the particular language ? tree banked (syntactically annotated and parsed) text ? semantically tagged text (semantic roles) cf.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
propbank (palmer et al, 2005), <papid> J05-1004 </papid>or frames cf.</citsent>
<aftsection>
<nextsent>framenet1?
</nextsent>
<nextsent>electronic dictionaries and other lexical resources, such as wordnet2there are numerous dimensions for linguistically annotated resources, and range of research projects have attempted to identify the core properties of interest.
</nextsent>
<nextsent>while concepts such as the basic language resource kit (blark; (krauwer, 2003; mapelli and choukri, 2003)) have gained considerable currency in higher-density language resource creation projects, it is clear that the baseline requirements of such schemes are significantly more advanced than we can hope for for lower-density languages in the short to medium term.
</nextsent>
<nextsent>notably, the concept of reduced blark (blarkette?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1707">
<title id=" W06-0605.xml">frontiers in linguistic annotation for lower density languages </title>
<section> increasing available resources.  </section>
<citcontext>
<prevsection>
<prevsent>more importantly, there can be some checking for inter-annotator agreement (and revision taking into account such differences as are found).
</prevsent>
<prevsent>earlier work on corpus collection from the web (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
(resnik and smith, 2003)) <papid> J03-3002 </papid>gave some hope that reasonably large quantities of parallel text could be found on the web, so that bitext collection could be built for interesting language pairs(with one member of the pair usually being en glish) relatively cheaply.</citsent>
<aftsection>
<nextsent>subsequent experience with lower-density languages has not born that hope out; parallel text on the web seems relatively rare for most languages.
</nextsent>
<nextsent>it is unclear why this should be.
</nextsent>
<nextsent>certainly in countries like india, there are large amounts of news text in english andmany of the target languages (such as hindi).
</nextsent>
<nextsent>nevertheless, very little of that text seems to be genuinely parallel, although recent work (munteanu and marcu, 2005) <papid> J05-4003 </papid>indicates that true parallelism may not be required for some tasks, eg machine 10http://bowland-files.lancs.ac.uk/corplang/emille/ translation, in order to gain acceptable results.because bitext was so difficult to find for lower density languages, corpus creation efforts rely largely, if not exclusively, on contracting out textfor translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1708">
<title id=" W06-0605.xml">frontiers in linguistic annotation for lower density languages </title>
<section> increasing available resources.  </section>
<citcontext>
<prevsection>
<prevsent>it is unclear why this should be.
</prevsent>
<prevsent>certainly in countries like india, there are large amounts of news text in english andmany of the target languages (such as hindi).
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
nevertheless, very little of that text seems to be genuinely parallel, although recent work (munteanu and marcu, 2005) <papid> J05-4003 </papid>indicates that true parallelism may not be required for some tasks, eg machine 10http://bowland-files.lancs.ac.uk/corplang/emille/ translation, in order to gain acceptable results.because bitext was so difficult to find for lower density languages, corpus creation efforts rely largely, if not exclusively, on contracting out textfor translation.</citsent>
<aftsection>
<nextsent>in most cases, source text is harvested from news sites in the target language, andthen translated into english by commercial translation agencies, at rate usually in the neighborhood of us$0.25 per word.
</nextsent>
<nextsent>in theory, one could reduce this cost by dealing directly with translators, avoiding the middleman agencies.
</nextsent>
<nextsent>since many translators are in the third world, this might result inconsiderable cost savings.
</nextsent>
<nextsent>nevertheless,quality control issues loom large.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1709">
<title id=" W06-0605.xml">frontiers in linguistic annotation for lower density languages </title>
<section> increasing available resources.  </section>
<citcontext>
<prevsection>
<prevsent>13http://www.wikipedia.org 14http://www.mturk.com/mturk/ 15http://litgloss.buffalo.edu/ 16http://www.espgame.org/ 17http://wiktionary.org/ other researchers have experimented with the automatic creation of corpora using web data (ghani et al, 2001) some of these corpora have grown to reasonable sizes; (scannell, 2003; scan nell, 2006) has corpora derived from web crawling which are measured in tens of millions of words for variety of lower-density languages.
</prevsent>
<prevsent>however it should be noted that in these cases, the type of linguistic resource created is often not linguistically annotated, but rather lexicon or collection of primary texts in given language.finally, we may mention efforts to create certain kinds of resources by computer-directed elicitation.
</prevsent>
</prevsection>
<citsent citstr=" P98-2160 ">
examples of projects sharing this focus include boas (nirenburg and raskin, 1998), <papid> P98-2160 </papid>and the avenue project (probst et al, 2002), (lavie et al, 2003).</citsent>
<aftsection>
<nextsent>creating more annotated resources is the obvious way to approach the problem of the lack of resources for lower-density languages.
</nextsent>
<nextsent>a complementary approach is to improve the way the information in smaller resources is used, for example by developing machine translation systems that require less parallel text.
</nextsent>
<nextsent>how much reduction in the required amount of resources might be enough?
</nextsent>
<nextsent>an interesting experiment, which to our knowledge has never been tried, would be for linguist to attempt as test case what we hope that computers can do.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1710">
<title id=" W06-0609.xml">issues in synchronizing the english treebank and propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first task is to provide part-of-speech tag for every token.
</prevsent>
<prevsent>particularly relevant for propbank work, verbs in any form (active, passive, gerund, infinitive, etc.) are marked with verbal part of speech (vbp, vbn, vbg, vb, etc.).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
(marcus, et al 1993; <papid> J93-2004 </papid>santorini 1990) the syntactic annotation task consists of marking constituent boundaries, inserting empty categories (traces of movement, pro, pro), showing the relationships between constituents (argument/adjunct structures), and specifying particular subset of adverbial roles.</citsent>
<aftsection>
<nextsent>(marcus, et al. 1994; <papid> H94-1020 </papid>bies, et al 1995) constituent boundaries are shown through syntactic node labels in the trees.</nextsent>
<nextsent>in the simplest case, node will contain an entire constituent, complete with any associated arguments or modifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1711">
<title id=" W06-0609.xml">issues in synchronizing the english treebank and propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>particularly relevant for propbank work, verbs in any form (active, passive, gerund, infinitive, etc.) are marked with verbal part of speech (vbp, vbn, vbg, vb, etc.).
</prevsent>
<prevsent>(marcus, et al 1993; <papid> J93-2004 </papid>santorini 1990) the syntactic annotation task consists of marking constituent boundaries, inserting empty categories (traces of movement, pro, pro), showing the relationships between constituents (argument/adjunct structures), and specifying particular subset of adverbial roles.</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
(marcus, et al. 1994; <papid> H94-1020 </papid>bies, et al 1995) constituent boundaries are shown through syntactic node labels in the trees.</citsent>
<aftsection>
<nextsent>in the simplest case, node will contain an entire constituent, complete with any associated arguments or modifiers.
</nextsent>
<nextsent>however, in structures involving syntactic movement, sub-constituents may be displaced.
</nextsent>
<nextsent>in these cases, treebank annotation represents the original position with trace and shows the relationship as co-indexing.
</nextsent>
<nextsent>in (1) be low, for example, the direct object of entail is shown with the trace *t*, which is co indexed to the whnp node of the question word what.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1712">
<title id=" W06-0609.xml">issues in synchronizing the english treebank and propbank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>adjunct constituents are sister to the np that contains the head noun, child of the np that contains both: (np (np head) (pp adjunct)) 1.2 propbank.
</prevsent>
<prevsent>propbank is an annotation of predicate-argument structures on top of syntactically parsed, or tree banked, structures.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
(palmer, et al 2005; <papid> J05-1004 </papid>babko malaya, 2005).</citsent>
<aftsection>
<nextsent>more specifically, propbank annotation involves three tasks: argument labeling, annotation of modifiers, and creating co-reference chains for empty categories.
</nextsent>
<nextsent>the first goal is to provide consistent argument labels across different syntactic realizations of the same verb, as in (3) [arg0 john] broke [arg1 the window] [arg1 the window] broke.
</nextsent>
<nextsent>as this example shows, semantic arguments are tagged with numbered argument labels, such as arg0, arg1, arg2, where these labels are defined on verb by verb basis.
</nextsent>
<nextsent>the second task of the propbank annotation involves assigning functional tags to all modifiers of the verb, such as mnr (manner), loc (locative), tmp (temporal), dis (discourse con nectives), prp (purpose) or dir (direction) and others.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1713">
<title id=" W06-1104.xml">automatically creating datasets for measures of semantic relatedness </title>
<section> evaluating sr measures.  </section>
<citcontext>
<prevsection>
<prevsent>16 is presented.
</prevsent>
<prevsent>section 5 discusses the results, and finally we draw some conclusions in section 6.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
various approaches for computing semantic relatedness of words or concepts have been proposed, e.g. dictionary-based (lesk, 1986), ontology-based (wu and palmer, 1994; <papid> P94-1019 </papid>leacock and chodorow, 1998), information-based (resnik, 1995; jiang and conrath, 1997) or distributional (weeds and weir, 2005).<papid> J05-4002 </papid></citsent>
<aftsection>
<nextsent>the knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.
</nextsent>
<nextsent>according to budanitsky and hirst (2006), there are three prevalent approaches for evaluatingsr measures: mathematical analysis, application specific evaluation and comparison with human judgments.
</nextsent>
<nextsent>mathematical analysis can assess measure with respect to some formal properties, e.g.whether measure is metric (lin, 1998).4 how ever, mathematical analysis cannot tell us whether measure closely resembles human judgments or whether it performs best when used in certain application.the latter question is tackled by application specific evaluation, where measure is tested within the framework of certain application, e.g. word sense disambiguation (patwardhan et al., 2003) or malapropism detection (budanitskyand hirst, 2006).
</nextsent>
<nextsent>lebart and rajman (2000) argue for application-specific evaluation of similarity measures, because measures are always used for some task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1714">
<title id=" W06-1104.xml">automatically creating datasets for measures of semantic relatedness </title>
<section> evaluating sr measures.  </section>
<citcontext>
<prevsection>
<prevsent>16 is presented.
</prevsent>
<prevsent>section 5 discusses the results, and finally we draw some conclusions in section 6.
</prevsent>
</prevsection>
<citsent citstr=" J05-4002 ">
various approaches for computing semantic relatedness of words or concepts have been proposed, e.g. dictionary-based (lesk, 1986), ontology-based (wu and palmer, 1994; <papid> P94-1019 </papid>leacock and chodorow, 1998), information-based (resnik, 1995; jiang and conrath, 1997) or distributional (weeds and weir, 2005).<papid> J05-4002 </papid></citsent>
<aftsection>
<nextsent>the knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.
</nextsent>
<nextsent>according to budanitsky and hirst (2006), there are three prevalent approaches for evaluatingsr measures: mathematical analysis, application specific evaluation and comparison with human judgments.
</nextsent>
<nextsent>mathematical analysis can assess measure with respect to some formal properties, e.g.whether measure is metric (lin, 1998).4 how ever, mathematical analysis cannot tell us whether measure closely resembles human judgments or whether it performs best when used in certain application.the latter question is tackled by application specific evaluation, where measure is tested within the framework of certain application, e.g. word sense disambiguation (patwardhan et al., 2003) or malapropism detection (budanitskyand hirst, 2006).
</nextsent>
<nextsent>lebart and rajman (2000) argue for application-specific evaluation of similarity measures, because measures are always used for some task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1715">
<title id=" W06-1104.xml">automatically creating datasets for measures of semantic relatedness </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, manually selected word pairs are often biased towards highly related pairs (gurevych, 2006), because human annotators tendto select only highly related pairs connected by relations they are aware of.
</prevsent>
<prevsent>automatic corpus-based selection of word pairs is more objective, leading to balanced dataset with pairs connected by all kinds of lexical-semantic relations.
</prevsent>
</prevsection>
<citsent citstr=" W04-2607 ">
morris and hirst (2004) <papid> W04-2607 </papid>pointed out that many relations between words in text are non-classical (i.e. other than typical taxonomic relations like synonymy orhypernymy) and therefore not covered by semantic similarity.previous studies only considered semantic relatedness (or similarity) of words rather than con cepts.</citsent>
<aftsection>
<nextsent>however, polysemous or homonymouswords should be annotated on the level of concepts.
</nextsent>
<nextsent>if we assume that bank has two meanings (financial institution?
</nextsent>
<nextsent>vs. river bank?)5 and it is paired with money, the result is two sense quali 5wordnet lists 10 meanings.
</nextsent>
<nextsent>fied pairs (bankfinancial ? money) and (bankriver ? money).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1716">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one improvement incorporates syntactic knowledge.
</prevsent>
<prevsent>results on the workshop data show that alignment performance exceeds thatof state-of-the art system based on more complex models, resulting in over 5.5% absolute reduction in error on romanian-english.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the most widely used alignment model is ibm model 4(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in empirical evaluations it has outperformed the other ibm models and hidden markov model (hmm) (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>it was the basis for system that performed very well in comparison of several alignment systems (dejean et al, 2003; <papid> W03-0305 </papid>mihalcea and pedersen, 2003).<papid> W03-0301 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1717">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>results on the workshop data show that alignment performance exceeds thatof state-of-the art system based on more complex models, resulting in over 5.5% absolute reduction in error on romanian-english.
</prevsent>
<prevsent>the most widely used alignment model is ibm model 4(brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in empirical evaluations it has outperformed the other ibm models and hidden markov model (hmm) (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>it was the basis for system that performed very well in comparison of several alignment systems (dejean et al, 2003; <papid> W03-0305 </papid>mihalcea and pedersen, 2003).<papid> W03-0301 </papid></nextsent>
<nextsent>implementations are also freely available (al-onaizan et al, 1999; och and ney, 2003).<papid> J03-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1722">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the most widely used alignment model is ibm model 4(brown et al, 1993).<papid> J93-2003 </papid></prevsent>
<prevsent>in empirical evaluations it has outperformed the other ibm models and hidden markov model (hmm) (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0305 ">
it was the basis for system that performed very well in comparison of several alignment systems (dejean et al, 2003; <papid> W03-0305 </papid>mihalcea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>implementations are also freely available (al-onaizan et al, 1999; och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>the ibm model 4 search space cannot be efficiently enumerated; therefore it cannot be trained directly using expectation maximization (em).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1723">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the most widely used alignment model is ibm model 4(brown et al, 1993).<papid> J93-2003 </papid></prevsent>
<prevsent>in empirical evaluations it has outperformed the other ibm models and hidden markov model (hmm) (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
it was the basis for system that performed very well in comparison of several alignment systems (dejean et al, 2003; <papid> W03-0305 </papid>mihalcea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>implementations are also freely available (al-onaizan et al, 1999; och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>the ibm model 4 search space cannot be efficiently enumerated; therefore it cannot be trained directly using expectation maximization (em).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1740">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>we can decompose this by introducing the hidden alignment variable = am1 . each element of takes on value in the range [1,n].
</prevsent>
<prevsent>the value of ai determines link between the ith french word fi and the aith english word eai . this representation introduces 83 an asymmetry into the model because it constrains each french word to correspond to exactly one english word, while each english word is permitted to correspond to an arbitrary number of french words.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
although the resulting set of links may still be relatively accurate, we cansymmetrize by combining it with the set produced by applying the complementary model p(e|f) to the same data(och and ney, 2000<papid> P00-1056 </papid>b).</citsent>
<aftsection>
<nextsent>making few independence assumptions we arrive at the decomposition in equation 1.
</nextsent>
<nextsent>1 p(f,a|e) = ? i=1 d(ai|ai1) ? t( fi|eai) (1) we refer to d(ai|ai1) as the distortion model and t( fi|eai) as the translation model.
</nextsent>
<nextsent>conveniently, equation 1 is inthe form of an hmm, so we can apply standard algorithms for hmm parameter estimation and maximization.
</nextsent>
<nextsent>this approach was proposed in vogel et al (1996) <papid> C96-2141 </papid>and subsequently improved (och and ney, 2000<papid> P00-1056 </papid>a; toutanova et al, 2002).<papid> W02-1012 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1750">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>1 p(f,a|e) = ? i=1 d(ai|ai1) ? t( fi|eai) (1) we refer to d(ai|ai1) as the distortion model and t( fi|eai) as the translation model.
</prevsent>
<prevsent>conveniently, equation 1 is inthe form of an hmm, so we can apply standard algorithms for hmm parameter estimation and maximization.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
this approach was proposed in vogel et al (1996) <papid> C96-2141 </papid>and subsequently improved (och and ney, 2000<papid> P00-1056 </papid>a; toutanova et al, 2002).<papid> W02-1012 </papid></citsent>
<aftsection>
<nextsent>2.1 the tree distortion model.
</nextsent>
<nextsent>equation 1 is adequate in practice, but we can improve it.
</nextsent>
<nextsent>numerous parameterizations have been proposed for the distortion model.
</nextsent>
<nextsent>in our surface distortion model, it depends only on the distance ai ? ai1 and an automatically determined word class c(eai1) as shown in equation 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1761">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>1 p(f,a|e) = ? i=1 d(ai|ai1) ? t( fi|eai) (1) we refer to d(ai|ai1) as the distortion model and t( fi|eai) as the translation model.
</prevsent>
<prevsent>conveniently, equation 1 is inthe form of an hmm, so we can apply standard algorithms for hmm parameter estimation and maximization.
</prevsent>
</prevsection>
<citsent citstr=" W02-1012 ">
this approach was proposed in vogel et al (1996) <papid> C96-2141 </papid>and subsequently improved (och and ney, 2000<papid> P00-1056 </papid>a; toutanova et al, 2002).<papid> W02-1012 </papid></citsent>
<aftsection>
<nextsent>2.1 the tree distortion model.
</nextsent>
<nextsent>equation 1 is adequate in practice, but we can improve it.
</nextsent>
<nextsent>numerous parameterizations have been proposed for the distortion model.
</nextsent>
<nextsent>in our surface distortion model, it depends only on the distance ai ? ai1 and an automatically determined word class c(eai1) as shown in equation 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1772">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>in our surface distortion model, it depends only on the distance ai ? ai1 and an automatically determined word class c(eai1) as shown in equation 2.
</prevsent>
<prevsent>it is similar to (och and ney, 2000<papid> P00-1056 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
the word class c(eai1) is assigned using an unsupervised approach (och, 1999).<papid> E99-1010 </papid></citsent>
<aftsection>
<nextsent>d(ai|ai1) = p(ai|ai ai1,c(eai1)) (2)the surface distortion model can capture local movement but it cannot capture movement of structures or the behavior of long-distance dependencies across translations.
</nextsent>
<nextsent>the intuitive appeal of capturing richer information has inspired numerous alignment models (wu, 1995;yamada and knight, 2001; <papid> P01-1067 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></nextsent>
<nextsent>however, we would like to retain the simplicity and good performance of the hmm model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1773">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>the word class c(eai1) is assigned using an unsupervised approach (och, 1999).<papid> E99-1010 </papid></prevsent>
<prevsent>d(ai|ai1) = p(ai|ai ai1,c(eai1)) (2)the surface distortion model can capture local movement but it cannot capture movement of structures or the behavior of long-distance dependencies across translations.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the intuitive appeal of capturing richer information has inspired numerous alignment models (wu, 1995;yamada and knight, 2001; <papid> P01-1067 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>however, we would like to retain the simplicity and good performance of the hmm model.
</nextsent>
<nextsent>we introduce distortion model which depends on thetree distance ?(ei,ek) = (w,x,y) between each pair of english words ei and ek.
</nextsent>
<nextsent>given dependency parse of em1 , and represent the respective number of dependency links separating ei and ek from their closest common ancestor node in the parse tree.
</nextsent>
<nextsent>2 the final element = {1 1we ignore the sentence length probability p(m|n), which is not relevant to word alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1774">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>the word class c(eai1) is assigned using an unsupervised approach (och, 1999).<papid> E99-1010 </papid></prevsent>
<prevsent>d(ai|ai1) = p(ai|ai ai1,c(eai1)) (2)the surface distortion model can capture local movement but it cannot capture movement of structures or the behavior of long-distance dependencies across translations.</prevsent>
</prevsection>
<citsent citstr=" P03-1012 ">
the intuitive appeal of capturing richer information has inspired numerous alignment models (wu, 1995;yamada and knight, 2001; <papid> P01-1067 </papid>cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>however, we would like to retain the simplicity and good performance of the hmm model.
</nextsent>
<nextsent>we introduce distortion model which depends on thetree distance ?(ei,ek) = (w,x,y) between each pair of english words ei and ek.
</nextsent>
<nextsent>given dependency parse of em1 , and represent the respective number of dependency links separating ei and ek from their closest common ancestor node in the parse tree.
</nextsent>
<nextsent>2 the final element = {1 1we ignore the sentence length probability p(m|n), which is not relevant to word alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1776">
<title id=" W05-0812.xml">improved hmm alignment models for languages with scarce resources </title>
<section> hmms and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>since this method works well, we applyllr(ei, j) in single reestimation step shown in equation 5.
</prevsent>
<prevsent>t( |e) = llr( |e) 2 +n e? llr( |e?)2 +n ? |v | (5) in reestimation llr( |e) is computed from the expected counts of and produced by the em algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P04-1066 ">
this is similar to moore (2004); <papid> P04-1066 </papid>as in that work, |v | = 100,000, and 1, 2, and are estimated on development data.we can also use an improved initial estimate for distor tion.</citsent>
<aftsection>
<nextsent>consider simple distortion model p(ai|ai ai1).
</nextsent>
<nextsent>we expect this distribution to have maximum near p(ai|0) because we know that words tend to retain their locality across translation.
</nextsent>
<nextsent>rather than wait for this to occur, we use an initial estimate for the distortion model given in equation 6.
</nextsent>
<nextsent>84 corpus 1 2 ? symmetrization n1 11 12 1 english-inuktitut 14 1.0 1.75 -1.5 ? 54 1.0 1.75 -1.5 romanian-english 54 1.5 1.0 -2.5 refined (och and ney, 2000<papid> P00-1056 </papid>b) 54 1.5 1.0 -2.5 english-hindi 14 1.5 3.0 -2.5 ? 12 1.0 1.0 -1.0 table 1: training parameters for the workshop data (see section 2.2).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1806">
<title id=" W05-0307.xml">a framework for annotating information structure in discourse </title>
<section> corpus and tools.  </section>
<citcontext>
<prevsection>
<prevsent>the switchboard corpus (godfrey et al , 1992) consists of 2430 spontaneous phone conversations (av erage six minutes), between speakers of american english, for three million words.
</prevsent>
<prevsent>the corpus is distributed as stereo speech signals with an orthographic transcription per channel time-stamped at the word level.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
a third of this is syntactically parsed as part of the penn treebank (marcus et al , 1993) <papid> J93-2004 </papid>and has dialog act annotation (shriberg et al , 1998).</citsent>
<aftsection>
<nextsent>we used subset of this.
</nextsent>
<nextsent>in adherence with current standards, we converted all the existing annotations, and are producing the new discourse annotations incoherent multi-layered xml-conformant schema, using nxt technology (carletta et al , 2004).1 this allows us to search over and integrate information from the many layers of annotation, including the1beside the nxt tools, we also used the tiger switchboard filter (mengel and lezius, 2000) for the xml conversion.
</nextsent>
<nextsent>using existing markup we automatically selected and filtered nps to be annotated, excluding locative, directional,and adverbial nps and disfluencies, and adding possessive pronouns.
</nextsent>
<nextsent>see (nissim et al , 2004) for technical details.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1807">
<title id=" W05-0307.xml">a framework for annotating information structure in discourse </title>
<section> information status.  </section>
<citcontext>
<prevsection>
<prevsent>coreference is also marked up for relative pronouns: they receive subtype relative and are linked back to their head.the guidelines contain decision tree the annotators use to establish priority in case more than one class is appropriate forgiven entity.
</prevsent>
<prevsent>for example, if mediated/general entity is also old/identity the latter is to be preferred to the former.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
similar precedence relations hold among subtypes.to provide more robust and reliable clues in annotating bridging types (e.g. for distinguishing between poss and part), we provided replacement tests and referred to relations encoded in knowledge bases such as wordnet (fellbaum, 1998) (for part) and framenet (baker et al , 1998) (<papid> P98-1013 </papid>for situation).</citsent>
<aftsection>
<nextsent>3.2 validation of the scheme.
</nextsent>
<nextsent>three switchboard dialogues (for total of 1738markables) were marked up by two different annotators for assessing the validity of the scheme.
</nextsent>
<nextsent>we evaluated annotation reliability by using the kappa statistic (carletta, 1996).<papid> J96-2004 </papid></nextsent>
<nextsent>good quality annotation of discourse phenomena normally yields kappa (  ) of about .80.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1808">
<title id=" W05-0307.xml">a framework for annotating information structure in discourse </title>
<section> information status.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 validation of the scheme.
</prevsent>
<prevsent>three switchboard dialogues (for total of 1738markables) were marked up by two different annotators for assessing the validity of the scheme.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
we evaluated annotation reliability by using the kappa statistic (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>good quality annotation of discourse phenomena normally yields kappa (  ) of about .80.
</nextsent>
<nextsent>we assessed the validity of the scheme on the four-way classication into the three main categories (old, mediated and new) and the non applicable category.
</nextsent>
<nextsent>we also evaluated the annotation including the subtypes.
</nextsent>
<nextsent>all cases where at lea stone annotator assigned not-understood tag were excluded from the agreement evaluation (14 markables).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1809">
<title id=" W05-0307.xml">a framework for annotating information structure in discourse </title>
<section> information structure.  </section>
<citcontext>
<prevsection>
<prevsent>they dene this minimally as the most prominent in three word phrase.
</prevsent>
<prevsent>(hirschberg, 1993) got 80-98% accuracy using only text-based features.
</prevsent>
</prevsection>
<citsent citstr=" W04-2707 ">
however, her denition of contrast was not as thorough as ours.(hedberg and sosa, 2001) looked at marking of rat ied, unratied (old and new) and contrastive topics and foci (theme and rheme) with tobi pitch accents.(baumann et al , 2004) <papid> W04-2707 </papid>annotated simpler information structure and prosodic events in small german corpus.</citsent>
<aftsection>
<nextsent>structure much previous work, not corpus-based, draws direct correspondence between information structure, prosodic phrasing and pitch accent type.
</nextsent>
<nextsent>however in real speech there are many non-semantic inu ences on prosody, including phrase length, speaking rate and rhythm.
</nextsent>
<nextsent>information structure is rather astrong constraint on the realisation of prosodic structure (calhoun, 2004a).
</nextsent>
<nextsent>contrary to the assumption of tobi, this structure is metrical, highly structured and linguistically relevant both within and across prosodic phrases (ladd, 1996; truckenbrodt, 2002).one of our main aims is to test how such evidence can be reconciled with theories presented earlier about the relationship between information structure and prosody.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1810">
<title id=" W04-3238.xml">spelling correction as an iterative process that exploits the collective knowledge of web users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the former approaches were based on the impractical assumption that all possible syntactic uses of all words (i.e. part-of-speech) are known, and presented both recall and precision problems because many of the substitution errors are not syntactically anomalous and many unusual syntactic constructions do not contain errors.
</prevsent>
<prevsent>the latter approach had very limited success under the assumptions that each sentence contains at most one misspelled word, each misspelling is the result of single point change (insertion, deletion, substitution, or transposition), and the defect rate (the relative number of errors in the text) is known.
</prevsent>
</prevsection>
<citsent citstr=" W95-0104 ">
a different body of work (e.g. golding, 1995; <papid> W95-0104 </papid>golding and roth, 1996; mangu and brill, 1997) focused on resolving limited number of cognitive substitution errors, in the framework of context sensitive spelling correction (cssc).</citsent>
<aftsection>
<nextsent>although promising results were obtained (92-95% accu racy), the scope of this work was very limited as it only addressed known sets of commonly confused words, such as {peace, piece}).
</nextsent>
<nextsent>1.1 spell checking of search engine queries.
</nextsent>
<nextsent>the task of web-query spelling correction addressed in this work has many similarities to traditional spelling correction but also poses additional challenges.
</nextsent>
<nextsent>both the frequency and severity of spelling errors for search queries are significantly greater than in wordprocessing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1811">
<title id=" W05-0609.xml">discriminative training of clustering functions theory and experiments with entity identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>clustering approaches have been widely applied to natural language processing (nlp) problems.
</prevsent>
<prevsent>typically, natural language elements (words, phrases, sentences, etc.) are partitioned into non-overlapping classes, based on some distance (or similarity) metric defined between them, in order to provide some level of syntactic or semantic abstraction.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
a key example is that of class-based language models (brown et al, 1992; <papid> J92-4003 </papid>dagan et al, 1999)where clustering approaches are used in order to partition words, determined to be similar, into sets.</citsent>
<aftsection>
<nextsent>this enables estimating more robust statistics since these are computed over collections of similar?
</nextsent>
<nextsent>words.
</nextsent>
<nextsent>a large number of different metrics and algorithms have been experimented with these problems (dagan et al, 1999; lee, 1997; weeds et al, 2004).<papid> C04-1146 </papid></nextsent>
<nextsent>similarity between words wasalso used as metric in distributional clustering algorithm in (pantel and lin, 2002), and it shows that functionally similar words can be grouped together and even separated to smaller groups based on their senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1812">
<title id=" W05-0609.xml">discriminative training of clustering functions theory and experiments with entity identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this enables estimating more robust statistics since these are computed over collections of similar?
</prevsent>
<prevsent>words.
</prevsent>
</prevsection>
<citsent citstr=" C04-1146 ">
a large number of different metrics and algorithms have been experimented with these problems (dagan et al, 1999; lee, 1997; weeds et al, 2004).<papid> C04-1146 </papid></citsent>
<aftsection>
<nextsent>similarity between words wasalso used as metric in distributional clustering algorithm in (pantel and lin, 2002), and it shows that functionally similar words can be grouped together and even separated to smaller groups based on their senses.
</nextsent>
<nextsent>at higher level, (mann and yarowsky, 2003) <papid> W03-0405 </papid>disambiguated personal names by clustering peoples home pages usinga tfidf similarity, and several other researchers have applied clustering at the same level in the context of the entity identification problem (bilenko et al, 2003; mccallum and wellner, 2003; li et al, 2004).</nextsent>
<nextsent>similarly, approaches to coreference resolution (cardie and wagstaff, 1999) <papid> W99-0611 </papid>use clustering to identify groups of references to the same entity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1813">
<title id=" W05-0609.xml">discriminative training of clustering functions theory and experiments with entity identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a large number of different metrics and algorithms have been experimented with these problems (dagan et al, 1999; lee, 1997; weeds et al, 2004).<papid> C04-1146 </papid></prevsent>
<prevsent>similarity between words wasalso used as metric in distributional clustering algorithm in (pantel and lin, 2002), and it shows that functionally similar words can be grouped together and even separated to smaller groups based on their senses.</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
at higher level, (mann and yarowsky, 2003) <papid> W03-0405 </papid>disambiguated personal names by clustering peoples home pages usinga tfidf similarity, and several other researchers have applied clustering at the same level in the context of the entity identification problem (bilenko et al, 2003; mccallum and wellner, 2003; li et al, 2004).</citsent>
<aftsection>
<nextsent>similarly, approaches to coreference resolution (cardie and wagstaff, 1999) <papid> W99-0611 </papid>use clustering to identify groups of references to the same entity.</nextsent>
<nextsent>clustering is an optimization procedure that takes as input (1) collection of domain elements along with (2)a distance metric between them and (3) an algorithm selected to partition the data elements, with the goal of optimizing some form of clustering quality with respect to the given distance metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1814">
<title id=" W05-0609.xml">discriminative training of clustering functions theory and experiments with entity identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>similarity between words wasalso used as metric in distributional clustering algorithm in (pantel and lin, 2002), and it shows that functionally similar words can be grouped together and even separated to smaller groups based on their senses.
</prevsent>
<prevsent>at higher level, (mann and yarowsky, 2003) <papid> W03-0405 </papid>disambiguated personal names by clustering peoples home pages usinga tfidf similarity, and several other researchers have applied clustering at the same level in the context of the entity identification problem (bilenko et al, 2003; mccallum and wellner, 2003; li et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" W99-0611 ">
similarly, approaches to coreference resolution (cardie and wagstaff, 1999) <papid> W99-0611 </papid>use clustering to identify groups of references to the same entity.</citsent>
<aftsection>
<nextsent>clustering is an optimization procedure that takes as input (1) collection of domain elements along with (2)a distance metric between them and (3) an algorithm selected to partition the data elements, with the goal of optimizing some form of clustering quality with respect to the given distance metric.
</nextsent>
<nextsent>for example, the k-means clustering approach (hartigan and wong, 1979) seeks to maximize measure of tightness of the resulting clusters based on the euclidean distance.
</nextsent>
<nextsent>clustering is typically called an unsupervised method, since data elements areused without labels during the clustering process and labels are not used to provide feedback to the optimization process.
</nextsent>
<nextsent>e.g., labels are not taken into account when measuring the quality of the partition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1817">
<title id=" W05-0609.xml">discriminative training of clustering functions theory and experiments with entity identification </title>
<section> clustering in natural language tasks.  </section>
<citcontext>
<prevsection>
<prevsent>as expected, experimental evidence (cohen et al, 2003; cohen and richman, 2002;li et al, 2004) shows that domain-specific distance functions improve over fixed metric.
</prevsent>
<prevsent>this can be explained by the flexibility provided by adapting the metric to the domain as well as the contribution of supervision that guides the adaptation of the metric.
</prevsent>
</prevsection>
<citsent citstr=" W04-3244 ">
a few works (xing et al, 2002; bar-hillel et al, 2003; schultz and joachims, 2004; mochihashi et al, 2004) <papid> W04-3244 </papid>outside the nlp domain have also pursued this general direction, and some have tried to learn the metric with limited amount of supervision, no supervision or by incorporating other information sources such as constraints on the class memberships of the data elements.</citsent>
<aftsection>
<nextsent>in most of these cases, the algorithm practically used in clustering,(e.g. k-means), is not considered in the learning procedure, or only implicitly exploited by optimizing the same objective function.
</nextsent>
<nextsent>(bach and jordan, 2003; bilenko et al., 2004) indeed suggest to learn metric directly in clustering task but the learning procedure is specific for one clustering algorithm.
</nextsent>
<nextsent>to solve the limitations of existing approaches, we develop the supervised discriminative clustering framework (sdc), that can train distance function with respect to any chosen clustering algorithm in the context of given task, guided by supervision.
</nextsent>
<nextsent>a labeled dataset a supervised learner training stage:goal: h*=argmin errs(h,p) distance metric a clustering algorithm a+ unlabeled dataset s?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1818">
<title id=" W04-2902.xml">analysis and processing of lecture audio data preliminary investigations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the past decade, we have seen dramatic increase in the availability of on-line academic lecture material.
</prevsent>
<prevsent>these educational resources can potentially change theway people learn ? students with disabilities can enhance their educational experience, professionals cankeep up with recent advancements in their field, and people of all ages can satisfy their thirst for knowledge.
</prevsent>
</prevsection>
<citsent citstr=" H01-1064 ">
in contrast to many other communicative activities however,lecture processing has until recently enjoyed little benefit from the development of human language technology.although there has been significant research directed toward audio indexing and retrieval (bacchiani et al, 2001; <papid> H01-1064 </papid>foote, 1999; jourlin et al, 2000; makhoul et al, 2000;franz et al, 2003; renals et al, 2000), lecture transcription and analysis is relatively unexplored area in speech and natural language research.</citsent>
<aftsection>
<nextsent>the most substantial research on lectures has been performed as part of the spontaneous speech project in japan (furui, 2003), where researchers are processing variety of japanese monologues such as academic and simulated presentations, news commentaries, etc. there has also been some work reported on german lectures (hurst et al, 2002).
</nextsent>
<nextsent>one of the reasons for the minimal research in this area is due to the limited availability of relevant data.the only publicly available corpus of academic presentations in english is ted, which includes 48 hours of audio recordings of 188 presentations given at euro speech 93 (lamel et al, 1994).
</nextsent>
<nextsent>only 6 of the presenters were native english speakers however, and only 39 of the lectures have been transcribed.
</nextsent>
<nextsent>the corpus of spontaneous japanese currently contains over 2,500 transcribed presentations (kawahara et al, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1819">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>, for example, polystyrene garden-gnome.
</prevsent>
<prevsent>the productivity of compound nouns makes their treatment equally desirable and difficult.
</prevsent>
</prevsection>
<citsent citstr=" W03-1803 ">
they appear frequently: more than 1% of the words in the british national corpus (bnc: burnard (2000))participate in noun compounds (tanaka and baldwin, 2003).<papid> W03-1803 </papid></citsent>
<aftsection>
<nextsent>however, unestablished compounds are common: almost 70% of compounds identified in the bnc co-occur with frequency of only one (lapata and lascarides, 2003).<papid> E03-1073 </papid></nextsent>
<nextsent>analysis of the entire space of compound noun shas been hampered to some degree as the space defies some regular set of predicates to define the implicit semantics between modifier and its head.this semantic under specification led early analysis to be primarily of semantic nature, but more recent work has advanced into using syntax to predict the semantics, in the spirit of the study by levin (1993) on dia thesis alternations.in this work, we examine compound nominal is ations, subset of compound nouns where the head has morphologically related verb.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1820">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the productivity of compound nouns makes their treatment equally desirable and difficult.
</prevsent>
<prevsent>they appear frequently: more than 1% of the words in the british national corpus (bnc: burnard (2000))participate in noun compounds (tanaka and baldwin, 2003).<papid> W03-1803 </papid></prevsent>
</prevsection>
<citsent citstr=" E03-1073 ">
however, unestablished compounds are common: almost 70% of compounds identified in the bnc co-occur with frequency of only one (lapata and lascarides, 2003).<papid> E03-1073 </papid></citsent>
<aftsection>
<nextsent>analysis of the entire space of compound noun shas been hampered to some degree as the space defies some regular set of predicates to define the implicit semantics between modifier and its head.this semantic under specification led early analysis to be primarily of semantic nature, but more recent work has advanced into using syntax to predict the semantics, in the spirit of the study by levin (1993) on dia thesis alternations.in this work, we examine compound nominal is ations, subset of compound nouns where the head has morphologically related verb.
</nextsent>
<nextsent>for example, product replacement has an underlying verbal head replace, whereas garden-gnome hasno such form.
</nextsent>
<nextsent>while compound nouns in general have set of semantic relationships between the head and modifier that is potentially non-finite, compound nominalisations are better defined, inthat the modifier fills syntactic argument relation with respect to the head.
</nextsent>
<nextsent>for example, product might fill the direct object slot of the verb to replace for the compound above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1821">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 compound noun interpretation.
</prevsent>
<prevsent>compound nouns were seminally and thoroughly analysed by levi (1978), who hand constructs anineway set of semantic relations that she identifies as broadly defining the observed relationships between the compound head and modifier.
</prevsent>
</prevsection>
<citsent citstr=" P84-1109 ">
warren (1978) also inspects the syntax of compound nouns, to create somewhat different set of twelve conceptual categories.early attempts to automatically classify compound nouns have taken semantic approach:finin (1980) and isabelle (1984) <papid> P84-1109 </papid>use role nomi nals?</citsent>
<aftsection>
<nextsent>derived from the head of the compound to fill slot with the modifier.
</nextsent>
<nextsent>vanderwende (1994)<papid> C94-2125 </papid>uses rule based technique that scores compound on possible semantic interpretations, while jones (1995) implements graph based unification procedure over semantic feature structures for the head.</nextsent>
<nextsent>finally, rosario and hearst (2001) <papid> W01-0511 </papid>makeuse of domain specific lexical resource to classify according to neural networks and decision trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1822">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>warren (1978) also inspects the syntax of compound nouns, to create somewhat different set of twelve conceptual categories.early attempts to automatically classify compound nouns have taken semantic approach:finin (1980) and isabelle (1984) <papid> P84-1109 </papid>use role nomi nals?</prevsent>
<prevsent>derived from the head of the compound to fill slot with the modifier.</prevsent>
</prevsection>
<citsent citstr=" C94-2125 ">
vanderwende (1994)<papid> C94-2125 </papid>uses rule based technique that scores compound on possible semantic interpretations, while jones (1995) implements graph based unification procedure over semantic feature structures for the head.</citsent>
<aftsection>
<nextsent>finally, rosario and hearst (2001) <papid> W01-0511 </papid>makeuse of domain specific lexical resource to classify according to neural networks and decision trees.</nextsent>
<nextsent>syntactic classification, using paraphrasing,was first used by leonard (1984), who uses prioritised rule based approach across number of possible readings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1823">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>derived from the head of the compound to fill slot with the modifier.
</prevsent>
<prevsent>vanderwende (1994)<papid> C94-2125 </papid>uses rule based technique that scores compound on possible semantic interpretations, while jones (1995) implements graph based unification procedure over semantic feature structures for the head.</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
finally, rosario and hearst (2001) <papid> W01-0511 </papid>makeuse of domain specific lexical resource to classify according to neural networks and decision trees.</citsent>
<aftsection>
<nextsent>syntactic classification, using paraphrasing,was first used by leonard (1984), who uses prioritised rule based approach across number of possible readings.
</nextsent>
<nextsent>lauer (1995) employs corpus statistical model over similar paraphrase set based on prepositions.
</nextsent>
<nextsent>lapata (2002) <papid> J02-3004 </papid>and grover et al (2005) again use corpus statistical paraphrase based approach, but with verb?</nextsent>
<nextsent>argument relations for compound nominalisations?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1824">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic classification, using paraphrasing,was first used by leonard (1984), who uses prioritised rule based approach across number of possible readings.
</prevsent>
<prevsent>lauer (1995) employs corpus statistical model over similar paraphrase set based on prepositions.
</prevsent>
</prevsection>
<citsent citstr=" J02-3004 ">
lapata (2002) <papid> J02-3004 </papid>and grover et al (2005) again use corpus statistical paraphrase based approach, but with verb?</citsent>
<aftsection>
<nextsent>argument relations for compound nominalisations?
</nextsent>
<nextsent>attempting to define the relation as one of subject, direct object, or number of prepositional objects in the latter.
</nextsent>
<nextsent>2.2 webascorpus approaches.
</nextsent>
<nextsent>using the world wide web for corpus statistics is relatively recent phenomenon; we present afew notable examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1826">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>grefenstette (1998) analyses the plausibility of candidate translations in machine translation task through web statistics,and avoids some data sparseness within that context.
</prevsent>
<prevsent>zhu and rosenfeld (2001) train language model from large corpus, and use the web to estimate low density trigram frequencies.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
keller and lapata (2003) <papid> J03-3005 </papid>show that web counts can obviate data sparseness for syntactic predicate?</citsent>
<aftsection>
<nextsent>argument bigrams.
</nextsent>
<nextsent>they also observe that the noisiness of the web, while unexplored in detail,does not greatly reduce the reliability of their results.
</nextsent>
<nextsent>nakov and hearst (2005) <papid> W05-0603 </papid>demonstrate that web counts can aid in identifying the bracketing in higherarity noun compounds.</nextsent>
<nextsent>finally, lapata and keller (2005) evaluate the performance of web counts on wide range of natural language processing tasks, including compound noun bracketing and compound noun interpretation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1828">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>argument bigrams.
</prevsent>
<prevsent>they also observe that the noisiness of the web, while unexplored in detail,does not greatly reduce the reliability of their results.
</prevsent>
</prevsection>
<citsent citstr=" W05-0603 ">
nakov and hearst (2005) <papid> W05-0603 </papid>demonstrate that web counts can aid in identifying the bracketing in higherarity noun compounds.</citsent>
<aftsection>
<nextsent>finally, lapata and keller (2005) evaluate the performance of web counts on wide range of natural language processing tasks, including compound noun bracketing and compound noun interpretation.
</nextsent>
<nextsent>2.3 confidence intervals.
</nextsent>
<nextsent>maximum likelihood statistics are not robust when many sparse vectors are under consideration, i.e. naively choosing the largest number?
</nextsent>
<nextsent>may not be accurate in contexts when the relative value across samplings may be relevant, for example, in machine learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1829">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>to find verb argument frequencies, we parse this using rasp (briscoe and carroll, 2002), tag sequence grammar based statistical parser.
</prevsent>
<prevsent>we contrast the corpus statistics with ones collected from the 55web, using an implementation of freely available google scraper?
</prevsent>
</prevsection>
<citsent citstr=" N03-1013 ">
from cpan.1 forgiven compound nominal isation, we wish to determine all possible verbal forms of the head.we do so using the combination of the morphological component of celex (burnage, 1990), lexical database, nomlex (macleod et al, 1998), nominal isation database, and catvar (habash and dorr, 2003), <papid> N03-1013 </papid>an automatically constructed database of clusters of inflected words based on the porter stemmer (porter, 1997).</citsent>
<aftsection>
<nextsent>once the verbal forms have been identified, we construct canonical forms of the present partici ple (+ing) and the past participle (+ed), using themorph lemmatiser (minnen et al, 2001).
</nextsent>
<nextsent>we construct canonical forms of the plural head and plural modifier (+s) in the same manner.
</nextsent>
<nextsent>for evaluation, we have the twoway classified dataset used by lapata (2002), <papid> J02-3004 </papid>and three way classified dataset constructed from open text.</nextsent>
<nextsent>lapata automatically extracts candidates from the british national corpus, and hand curates set of 796 compound nominalisations which were interpreted as either subjective relation subj (e.g. wood appearance wood appears?), or (direct) objective relation obj (e.g. stress avoidance ?[so] avoids stress?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1831">
<title id=" W06-1208.xml">interpretation of compound nominalisations using corpus and web statistics </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>lapata automatically extracts candidates from the british national corpus, and hand curates set of 796 compound nominalisations which were interpreted as either subjective relation subj (e.g. wood appearance wood appears?), or (direct) objective relation obj (e.g. stress avoidance ?[so] avoids stress?.
</prevsent>
<prevsent>we automatically validated this dataset for consistency, removing: 1.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
items that did not occur in the same chunk, according to chunker based on fntbl 1.0 (ngai and florian, 2001), <papid> N01-1006 </papid>2.</citsent>
<aftsection>
<nextsent>items whose head did not have verbal form according to our lexical resources, and 3.
</nextsent>
<nextsent>items which consisted in part of proper nouns, to end up with 695 consistent compounds.
</nextsent>
<nextsent>we used the method of nicholson and baldwin (2005) to derive small dataset of 129 compound nominalisations, also from the bnc, which we instructed three unskilled annotators to identify each as one of subjective (sub), direct object (dob), or prepositional object (pob, e.g. sideshow ?[so] show [st] on the side?).
</nextsent>
<nextsent>the annotators identified nine prepositional relations: {about,against,for,from,in,into,on,to,with}.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1839">
<title id=" W04-3251.xml">instance based question answering a data driven approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present basic implementation of these concepts that achieves good performance on trec test data.
</prevsent>
<prevsent>ever since question answering (qa) emerged as an active research field, the community has slowly diversified question types, increased question complexity, and refined evaluation metrics - as reflected by the trec qa track (voorhees, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P00-1071 ">
starting from successful pipeline architectures (moldovan etal., 2000; <papid> P00-1071 </papid>hovy et al, 2000), qa systems have responded to changes in the nature of the qa task by incorporating knowledge resources (hermjakob et al., 2000; hovy et al, 2002), <papid> C02-1042 </papid>handling additional types of questions, employing complex reasoning mechanisms (moldovan et al, 2003; <papid> N03-1022 </papid>nyberg et al, 2003), tapping into external data sources such as the web, encyclopedias, databases (dumais et al, 2002; xu et al, 2003), and merging multiple agents and strategies into meta-systems (chu-carroll et al, 2003; burger et al, 2002).</citsent>
<aftsection>
<nextsent>in recent years, learning components have started to permeate question answering (clarke et al, 2003; ravichandran et al, 2003; <papid> N03-2029 </papid>echihabi andmarcu, 2003).<papid> P03-1003 </papid></nextsent>
<nextsent>although the field is still dominated by knowledge-intensive approaches, components such as question classification, answer extraction, and answer verification are beginning to be addressed through statistical methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1840">
<title id=" W04-3251.xml">instance based question answering a data driven approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present basic implementation of these concepts that achieves good performance on trec test data.
</prevsent>
<prevsent>ever since question answering (qa) emerged as an active research field, the community has slowly diversified question types, increased question complexity, and refined evaluation metrics - as reflected by the trec qa track (voorhees, 2003).
</prevsent>
</prevsection>
<citsent citstr=" C02-1042 ">
starting from successful pipeline architectures (moldovan etal., 2000; <papid> P00-1071 </papid>hovy et al, 2000), qa systems have responded to changes in the nature of the qa task by incorporating knowledge resources (hermjakob et al., 2000; hovy et al, 2002), <papid> C02-1042 </papid>handling additional types of questions, employing complex reasoning mechanisms (moldovan et al, 2003; <papid> N03-1022 </papid>nyberg et al, 2003), tapping into external data sources such as the web, encyclopedias, databases (dumais et al, 2002; xu et al, 2003), and merging multiple agents and strategies into meta-systems (chu-carroll et al, 2003; burger et al, 2002).</citsent>
<aftsection>
<nextsent>in recent years, learning components have started to permeate question answering (clarke et al, 2003; ravichandran et al, 2003; <papid> N03-2029 </papid>echihabi andmarcu, 2003).<papid> P03-1003 </papid></nextsent>
<nextsent>although the field is still dominated by knowledge-intensive approaches, components such as question classification, answer extraction, and answer verification are beginning to be addressed through statistical methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1841">
<title id=" W04-3251.xml">instance based question answering a data driven approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present basic implementation of these concepts that achieves good performance on trec test data.
</prevsent>
<prevsent>ever since question answering (qa) emerged as an active research field, the community has slowly diversified question types, increased question complexity, and refined evaluation metrics - as reflected by the trec qa track (voorhees, 2003).
</prevsent>
</prevsection>
<citsent citstr=" N03-1022 ">
starting from successful pipeline architectures (moldovan etal., 2000; <papid> P00-1071 </papid>hovy et al, 2000), qa systems have responded to changes in the nature of the qa task by incorporating knowledge resources (hermjakob et al., 2000; hovy et al, 2002), <papid> C02-1042 </papid>handling additional types of questions, employing complex reasoning mechanisms (moldovan et al, 2003; <papid> N03-1022 </papid>nyberg et al, 2003), tapping into external data sources such as the web, encyclopedias, databases (dumais et al, 2002; xu et al, 2003), and merging multiple agents and strategies into meta-systems (chu-carroll et al, 2003; burger et al, 2002).</citsent>
<aftsection>
<nextsent>in recent years, learning components have started to permeate question answering (clarke et al, 2003; ravichandran et al, 2003; <papid> N03-2029 </papid>echihabi andmarcu, 2003).<papid> P03-1003 </papid></nextsent>
<nextsent>although the field is still dominated by knowledge-intensive approaches, components such as question classification, answer extraction, and answer verification are beginning to be addressed through statistical methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1842">
<title id=" W04-3251.xml">instance based question answering a data driven approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ever since question answering (qa) emerged as an active research field, the community has slowly diversified question types, increased question complexity, and refined evaluation metrics - as reflected by the trec qa track (voorhees, 2003).
</prevsent>
<prevsent>starting from successful pipeline architectures (moldovan etal., 2000; <papid> P00-1071 </papid>hovy et al, 2000), qa systems have responded to changes in the nature of the qa task by incorporating knowledge resources (hermjakob et al., 2000; hovy et al, 2002), <papid> C02-1042 </papid>handling additional types of questions, employing complex reasoning mechanisms (moldovan et al, 2003; <papid> N03-1022 </papid>nyberg et al, 2003), tapping into external data sources such as the web, encyclopedias, databases (dumais et al, 2002; xu et al, 2003), and merging multiple agents and strategies into meta-systems (chu-carroll et al, 2003; burger et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" N03-2029 ">
in recent years, learning components have started to permeate question answering (clarke et al, 2003; ravichandran et al, 2003; <papid> N03-2029 </papid>echihabi andmarcu, 2003).<papid> P03-1003 </papid></citsent>
<aftsection>
<nextsent>although the field is still dominated by knowledge-intensive approaches, components such as question classification, answer extraction, and answer verification are beginning to be addressed through statistical methods.
</nextsent>
<nextsent>at the same time, research efforts in data acquisition promise to deliver increasingly larger question-answer datasets(girju et al, 2003; fleischman et al, 2003).<papid> P03-1001 </papid></nextsent>
<nextsent>more over, question answering is expanding to different languages (magnini et al, 2003) and domains other than news stories (zweigenbaum, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1843">
<title id=" W04-3251.xml">instance based question answering a data driven approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ever since question answering (qa) emerged as an active research field, the community has slowly diversified question types, increased question complexity, and refined evaluation metrics - as reflected by the trec qa track (voorhees, 2003).
</prevsent>
<prevsent>starting from successful pipeline architectures (moldovan etal., 2000; <papid> P00-1071 </papid>hovy et al, 2000), qa systems have responded to changes in the nature of the qa task by incorporating knowledge resources (hermjakob et al., 2000; hovy et al, 2002), <papid> C02-1042 </papid>handling additional types of questions, employing complex reasoning mechanisms (moldovan et al, 2003; <papid> N03-1022 </papid>nyberg et al, 2003), tapping into external data sources such as the web, encyclopedias, databases (dumais et al, 2002; xu et al, 2003), and merging multiple agents and strategies into meta-systems (chu-carroll et al, 2003; burger et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" P03-1003 ">
in recent years, learning components have started to permeate question answering (clarke et al, 2003; ravichandran et al, 2003; <papid> N03-2029 </papid>echihabi andmarcu, 2003).<papid> P03-1003 </papid></citsent>
<aftsection>
<nextsent>although the field is still dominated by knowledge-intensive approaches, components such as question classification, answer extraction, and answer verification are beginning to be addressed through statistical methods.
</nextsent>
<nextsent>at the same time, research efforts in data acquisition promise to deliver increasingly larger question-answer datasets(girju et al, 2003; fleischman et al, 2003).<papid> P03-1001 </papid></nextsent>
<nextsent>more over, question answering is expanding to different languages (magnini et al, 2003) and domains other than news stories (zweigenbaum, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1844">
<title id=" W04-3251.xml">instance based question answering a data driven approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, learning components have started to permeate question answering (clarke et al, 2003; ravichandran et al, 2003; <papid> N03-2029 </papid>echihabi andmarcu, 2003).<papid> P03-1003 </papid></prevsent>
<prevsent>although the field is still dominated by knowledge-intensive approaches, components such as question classification, answer extraction, and answer verification are beginning to be addressed through statistical methods.</prevsent>
</prevsection>
<citsent citstr=" P03-1001 ">
at the same time, research efforts in data acquisition promise to deliver increasingly larger question-answer datasets(girju et al, 2003; fleischman et al, 2003).<papid> P03-1001 </papid></citsent>
<aftsection>
<nextsent>more over, question answering is expanding to different languages (magnini et al, 2003) and domains other than news stories (zweigenbaum, 2003).
</nextsent>
<nextsent>these trends suggest the need for principled, statistically based, easily re-trainable, language independent qa systems that take full advantage of large amounts of training data.we propose an instance-based, data-driven approach to question answering.
</nextsent>
<nextsent>instead of classifying questions according to limited, predefined ontologies, we allow training data to shape the strategies for answering new questions.
</nextsent>
<nextsent>answer models, query content models, and extraction models are also learned directly from training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1850">
<title id=" W06-0201.xml">development of an automatic trend exploration system using the must data collection </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the best scores are described using bold fonts.
</prevsent>
<prevsent>for each evaluation score.we used five evaluation scores.
</prevsent>
</prevsection>
<citsent citstr=" I05-2043 ">
mrr is the average of the score where 1/r is given as the score when the rank of the first correct output is (murata et al, 2005<papid> I05-2043 </papid>b).</citsent>
<aftsection>
<nextsent>tp1 is the average of the precision in the first output.
</nextsent>
<nextsent>tp5 is the average of the precision where the system includes correct output in the first five outputs.
</nextsent>
<nextsent>rp is the average of the r-precision and ap is the average of the average precision.
</nextsent>
<nextsent>(here, the average means that the evaluation score is calculated for each domain dataset and the summation of these scores divided by the number of the domain datasets is the average.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1854">
<title id=" W06-0402.xml">control strategies for parsing with freer word order languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes two contributions to thearea of parsing over freer word-order (fwo) languages, i.e., languages that do not readily admit asemantically transparent context-free analysis, because of looser connection between grammatical function assignment and linear constituent order than one finds in english.
</prevsent>
<prevsent>this is particularly ripe area for constraint-based methods be cause such large number of linguistic partial knowledge sources must be brought to bear on fwo parsing in order to restrict its search space to size comparable to that of standard cfg-based parsing.the first addresses the indexation of tabled sub strings in generalized chart parsers for fwo languages.
</prevsent>
</prevsection>
<citsent citstr=" P83-1021 ">
while chart parsing can famously be cast as deduction (pereira and warren, 1983), <papid> P83-1021 </papid>what chart parsing really is is an algebraic closure over the rules of phrase structure grammar, which is most naturally expressed inside constraint solver such as chr (morawietz, 2000).<papid> C00-1080 </papid></citsent>
<aftsection>
<nextsent>ideally, we would like to use standard chart parsers for fwo languages, but because of the constituent ordering constraints that are implicit in the right-hand-sides (rhss) of cfg rules, this is not possible without effectively converting fwo grammar into cfg by expanding its rule system exponentially into all possible rhs orders (barton et al, 1987).
</nextsent>
<nextsent>fwo grammar rules generally cannot be used as they stand in chart parser because tabled sub strings record non-terminal category derived over contiguous subspan of the input string from word to word j. fwo languages have many phrasal categories that are not contiguous substrings.
</nextsent>
<nextsent>johnson (1985), <papid> P85-1015 </papid>reape (1991) and others have suggested using bit vectors to index chart edges as an alternative to substring spans in the case of parsing over fwo languages, but that is really only half of the story.</nextsent>
<nextsent>we still need control strategy to tell us where we should be searching for some constituent at any point in derivation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1855">
<title id=" W06-0402.xml">control strategies for parsing with freer word order languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes two contributions to thearea of parsing over freer word-order (fwo) languages, i.e., languages that do not readily admit asemantically transparent context-free analysis, because of looser connection between grammatical function assignment and linear constituent order than one finds in english.
</prevsent>
<prevsent>this is particularly ripe area for constraint-based methods be cause such large number of linguistic partial knowledge sources must be brought to bear on fwo parsing in order to restrict its search space to size comparable to that of standard cfg-based parsing.the first addresses the indexation of tabled sub strings in generalized chart parsers for fwo languages.
</prevsent>
</prevsection>
<citsent citstr=" C00-1080 ">
while chart parsing can famously be cast as deduction (pereira and warren, 1983), <papid> P83-1021 </papid>what chart parsing really is is an algebraic closure over the rules of phrase structure grammar, which is most naturally expressed inside constraint solver such as chr (morawietz, 2000).<papid> C00-1080 </papid></citsent>
<aftsection>
<nextsent>ideally, we would like to use standard chart parsers for fwo languages, but because of the constituent ordering constraints that are implicit in the right-hand-sides (rhss) of cfg rules, this is not possible without effectively converting fwo grammar into cfg by expanding its rule system exponentially into all possible rhs orders (barton et al, 1987).
</nextsent>
<nextsent>fwo grammar rules generally cannot be used as they stand in chart parser because tabled sub strings record non-terminal category derived over contiguous subspan of the input string from word to word j. fwo languages have many phrasal categories that are not contiguous substrings.
</nextsent>
<nextsent>johnson (1985), <papid> P85-1015 </papid>reape (1991) and others have suggested using bit vectors to index chart edges as an alternative to substring spans in the case of parsing over fwo languages, but that is really only half of the story.</nextsent>
<nextsent>we still need control strategy to tell us where we should be searching for some constituent at any point in derivation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1856">
<title id=" W06-0402.xml">control strategies for parsing with freer word order languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ideally, we would like to use standard chart parsers for fwo languages, but because of the constituent ordering constraints that are implicit in the right-hand-sides (rhss) of cfg rules, this is not possible without effectively converting fwo grammar into cfg by expanding its rule system exponentially into all possible rhs orders (barton et al, 1987).
</prevsent>
<prevsent>fwo grammar rules generally cannot be used as they stand in chart parser because tabled sub strings record non-terminal category derived over contiguous subspan of the input string from word to word j. fwo languages have many phrasal categories that are not contiguous substrings.
</prevsent>
</prevsection>
<citsent citstr=" P85-1015 ">
johnson (1985), <papid> P85-1015 </papid>reape (1991) and others have suggested using bit vectors to index chart edges as an alternative to substring spans in the case of parsing over fwo languages, but that is really only half of the story.</citsent>
<aftsection>
<nextsent>we still need control strategy to tell us where we should be searching for some constituent at any point in derivation.
</nextsent>
<nextsent>this paper provides such control strategy, using this data structure, for doing search more effectively with fwo grammar.
</nextsent>
<nextsent>the second contribution addresses another source of constraints on the search space: the length of the input.
</nextsent>
<nextsent>while this number is not aconstant across parses, it is constant within single parse, and there are functions that can be pre computed for fixed grammar which relate tight upper and lower bounds on the length of the in put to both the height of parse tree and other variables (defined below) whose values bound therecursion of the fixed phrase structure rule system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1857">
<title id=" W06-0136.xml">ngram based twostep algorithm for word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to overcome the data sparseness problem of bigram data, unigram is used for the smoothing.
</prevsent>
<prevsent>word segmentation has been one of the very important problems in the chinese language processing.
</prevsent>
</prevsection>
<citsent citstr=" W02-1208 ">
it is necessary in the information retrieval system for the korean language (kang and woo, 2001; lee et al 2002).<papid> W02-1208 </papid></citsent>
<aftsection>
<nextsent>though korean words are separated by white spaces, many web users often do not set space in sentence when they write query at the search engine.
</nextsent>
<nextsent>another necessity of automatic word segmentation is the index term extraction from sentence that includes word spacing errors.
</nextsent>
<nextsent>the motivation of this research is to investigate practical word segmentation system for the korean language.
</nextsent>
<nextsent>while we develop the system, we found that ngram-based algorithm was exactly applicable to the chinese word segmentation and we have participated the bakeoff (kang and lim, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1858">
<title id=" W06-0136.xml">ngram based twostep algorithm for word segmentation </title>
<section> word segmentation algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>we investigated two step algorithm of determining space tags in each character position of sentence using by context dependent n-gram features.
</prevsent>
<prevsent>it is based on the assumption that space tags depend on the left and right context of characters together with the space tags that it accompanies.
</prevsent>
</prevsection>
<citsent citstr=" I05-3024 ">
let tici be current  space tag, character  pair in sentence.4 ? ti-2ci-2 ti-1ci-1 tici ti+1ci+1 ti+2ci+2 ? in our previous work of (lim and kang, 2005), <papid> I05-3024 </papid>n-gram features (a) and (b) are used.</citsent>
<aftsection>
<nextsent>these features are used to determine the space tag ti.
</nextsent>
<nextsent>in this work, core n-gram feature is c3t2 classes of trigram features ci-2ti-1ci-1tici, ci-1ticiti+1ci+1.
</nextsent>
<nextsent>in addition, simple character trigram with no space tag ticici+1ci+2?
</nextsent>
<nextsent>is added.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1859">
<title id=" W05-0604.xml">new experiments in distributional representations of synonymy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>harris articulated the expectation that words with similar meanings would be used in similar contexts (harris, 1968), and recent empirical work involving large corpora has borne this out.
</prevsent>
<prevsent>in particular, by associating each word with distribution over the words observed in its context, we can distinguish synonyms from non-synonymswith fair reliability.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
this capability may be exploited to generate corpus-based thesauri automatically (lin, 1998), <papid> P98-2127 </papid>or used in any other application of text that might benefit from measure of lexical semantic similarity.</citsent>
<aftsection>
<nextsent>and synonymy is logical first step in broader research program that seeks to account for natural language semantics through distributional means.
</nextsent>
<nextsent>previous research into corpus-analytic approaches to synonymy has used the test of english as foreign language (toefl).
</nextsent>
<nextsent>the toefl consists of300 multiple-choice question, each question involving five words: the problem or target word and four response words, one of which is synonym of the target.
</nextsent>
<nextsent>the objective is to identify the synonym (call this the answer word, and call the other response words decoys).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1863">
<title id=" W05-0604.xml">new experiments in distributional representations of synonymy </title>
<section> the space of solutions.  </section>
<citcontext>
<prevsection>
<prevsent>we answer question by comparing the target term vector and each of the response term vectors, choosing the closest.?
</prevsent>
<prevsent>this problem definition excludes common class of solutions to this problem, in which the closeness of pair of terms is statistic of the co-occurrence patterns of the specific terms in question.
</prevsent>
</prevsection>
<citsent citstr=" N03-1032 ">
it has been shown that measures based on the pointwise mutual information (pmi) between question words yield good results on the toefl (turney, 2001; terra and clarke, 2003).<papid> N03-1032 </papid></citsent>
<aftsection>
<nextsent>however, ehlert (2003) shows convincingly that, for fixed amount of data, the distributional model performs better than what we might call the pointwise co-occurrence model.
</nextsent>
<nextsent>terra and clark (2003) <papid> N03-1032 </papid>report top score of 81.3%on an 80-word version of the toefl, which compares favorably with ehlerts best of 82% on 300 word version, but their corpus is approximately 200 times as large as ehlerts.note that these two approaches are complementary and can be combined in supervised setting,along with static resources, to yield truly strong performance (97.5%) on the toefl (turney et al ,2003).</nextsent>
<nextsent>while impressive, this work begs an important question: where do we obtain the training data when moving to less commonly taught language, to say nothing of the comprehensive thesauri and web resources?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1865">
<title id=" W05-0604.xml">new experiments in distributional representations of synonymy </title>
<section> the space of solutions.  </section>
<citcontext>
<prevsection>
<prevsent>by default, we bracket token sequence with pseudo-tokens ? bos ?
</prevsent>
<prevsent>and ? eos ?.2 contextual tokens in the window may be either observed or disregarded, and the policy governing which to admit is one of the dimensions we explore here.
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
the decision whether or not to observea particular contextual token is made before counting commences, and is not sensitive to the circumstances of particular occurrence (e.g., its participation in some syntactic relation (lin, 1997; <papid> P97-1009 </papid>lee, 1999)).<papid> P99-1004 </papid></citsent>
<aftsection>
<nextsent>when contextual token is observed, it is always counted as single occurrence.
</nextsent>
<nextsent>thus, in contrast with earlier approaches (sahlgren, 2001; ehlert, 2003), we do not use weighting scheme that is function of distance from the reference token.once we have chosen to observe contextual token, additional parameters govern whether counting should be sensitive to the side of the reference tokenon which it occurs and how distant from the reference token it is. if the strict direction parameter is true, left occurrence is distinguished from right occurrence.
</nextsent>
<nextsent>if strict distance is true, occurrences at distinct removes (in number of tokens) are recorded as distinct event types.
</nextsent>
<nextsent>3.2 distance measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1866">
<title id=" W05-0604.xml">new experiments in distributional representations of synonymy </title>
<section> the space of solutions.  </section>
<citcontext>
<prevsection>
<prevsent>by default, we bracket token sequence with pseudo-tokens ? bos ?
</prevsent>
<prevsent>and ? eos ?.2 contextual tokens in the window may be either observed or disregarded, and the policy governing which to admit is one of the dimensions we explore here.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
the decision whether or not to observea particular contextual token is made before counting commences, and is not sensitive to the circumstances of particular occurrence (e.g., its participation in some syntactic relation (lin, 1997; <papid> P97-1009 </papid>lee, 1999)).<papid> P99-1004 </papid></citsent>
<aftsection>
<nextsent>when contextual token is observed, it is always counted as single occurrence.
</nextsent>
<nextsent>thus, in contrast with earlier approaches (sahlgren, 2001; ehlert, 2003), we do not use weighting scheme that is function of distance from the reference token.once we have chosen to observe contextual token, additional parameters govern whether counting should be sensitive to the side of the reference tokenon which it occurs and how distant from the reference token it is. if the strict direction parameter is true, left occurrence is distinguished from right occurrence.
</nextsent>
<nextsent>if strict distance is true, occurrences at distinct removes (in number of tokens) are recorded as distinct event types.
</nextsent>
<nextsent>3.2 distance measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1869">
<title id=" W05-0604.xml">new experiments in distributional representations of synonymy </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>measure are problematic.
</prevsent>
<prevsent>we do not know whether or to what extent this particular parameter setting is universally best, best only for english, best for newswire english, or best only for the specific test we have devised.
</prevsent>
</prevsection>
<citsent citstr=" C04-1146 ">
we have restricted our attention to relatively small space of similarity measures, excluding many previously proposed measures of lexical affinity (but see weeds, et al (2004), <papid> C04-1146 </papid>and lee (1999) <papid> P99-1004 </papid>for some empirical comparisons).</citsent>
<aftsection>
<nextsent>lee observed that measures from the space of in variant divergences (particularly the js and skew diver gences) perform at least as well as any of wide variety of alternatives.
</nextsent>
<nextsent>as noted, we experimented with the js divergence and observed accuracies that tracked those of the hell inger closely.
</nextsent>
<nextsent>this providesa point of comparison with the measures investigated by lee, and recommends both ehlerts measure and what we have called optimal?
</nextsent>
<nextsent>as credible, perhaps superior alternatives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1871">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present several statistical modeling and cross-dialectal data sharing techniques to enhance the performance of the baseline tagger and compare the results to those obtained by supervised tagger trained on hand-annotated data and, by state-ofthe-art modern standard arabic tagger applied to egyptian arabic.
</prevsent>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
</prevsection>
<citsent citstr=" W00-0731 ">
tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</citsent>
<aftsection>
<nextsent>many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</nextsent>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1872">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present several statistical modeling and cross-dialectal data sharing techniques to enhance the performance of the baseline tagger and compare the results to those obtained by supervised tagger trained on hand-annotated data and, by state-ofthe-art modern standard arabic tagger applied to egyptian arabic.
</prevsent>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
</prevsection>
<citsent citstr=" W00-0729 ">
tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</citsent>
<aftsection>
<nextsent>many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</nextsent>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1873">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present several statistical modeling and cross-dialectal data sharing techniques to enhance the performance of the baseline tagger and compare the results to those obtained by supervised tagger trained on hand-annotated data and, by state-ofthe-art modern standard arabic tagger applied to egyptian arabic.
</prevsent>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
</prevsection>
<citsent citstr=" W98-1121 ">
tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</citsent>
<aftsection>
<nextsent>many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</nextsent>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1874">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
<prevsent>tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" W95-0101 ">
many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</citsent>
<aftsection>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
<nextsent>since large amount of text material as well as standard lexicons can be obtained in these cases, pos tagging is straightforward task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1875">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
<prevsent>tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</citsent>
<aftsection>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
<nextsent>since large amount of text material as well as standard lexicons can be obtained in these cases, pos tagging is straightforward task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1876">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
<prevsent>tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</citsent>
<aftsection>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
<nextsent>since large amount of text material as well as standard lexicons can be obtained in these cases, pos tagging is straightforward task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1877">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech (pos) tagging is core natural language processing task that can benefit wide range of downstream processing applications.
</prevsent>
<prevsent>tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</citsent>
<aftsection>
<nextsent>taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></nextsent>
<nextsent>since large amount of text material as well as standard lexicons can be obtained in these cases, pos tagging is straightforward task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1878">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tagging is often the first step towards parsing or chunking (osborne, 2000; <papid> W00-0731 </papid>koeling, 2000), <papid> W00-0729 </papid>and knowledge of pos tags can benefit statistical language models for speech recognition or machine translation(heeman, 1998; <papid> W98-1121 </papid>vergyri et al, 2004).</prevsent>
<prevsent>many approaches for pos tagging have been developed in the past, including rule-based tagging (brill, 1995),<papid> W95-0101 </papid>hmm taggers (brants, 2000; <papid> A00-1031 </papid>cutting and others, 1992), maximum-entropy models (rathnaparki, 1996), cyclic dependency networks (toutanova et al., 2003), <papid> N03-1033 </papid>memory-based learning (daelemans etal., 1996), <papid> W96-0102 </papid>etc. all of these approaches require either large amount of annotated training data (for supervised tagging) or lexicon listing all possible tags for each word (for unsupervised tagging).</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
taggers have been developed for variety of languages, including modern standard arabic (msa) (khoja, 2001; diab et al, 2004).<papid> N04-4038 </papid></citsent>
<aftsection>
<nextsent>since large amount of text material as well as standard lexicons can be obtained in these cases, pos tagging is straightforward task.
</nextsent>
<nextsent>the dialects of arabic, by contrast, are spoken rather than written languages.
</nextsent>
<nextsent>apart from small amounts of written dialectal material in e.g. plays, novels, chat rooms, etc., data can only be obtained by recording and manually transcribing actual conversations.
</nextsent>
<nextsent>moreover, there is no universally agreed upon writing standard for dialects (though several standardization efforts are underway); any largescale data collection and transcription effort therefore requires extensive training of annotators to ensure consistency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1879">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> cross-dialectal data sharing.  </section>
<citcontext>
<prevsection>
<prevsent>in natural language processing, kim &amp; khu 59 danpur (2004) have explored techniques for using parallel chinese/english corpora for language modeling.
</prevsent>
<prevsent>parallel corpora have also been used to infer morphological analyzers, pos taggers, and noun phrase bracket ers by projections via word alignments (yarowsky et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W04-3229 ">
in (hana et al,2004), <papid> W04-3229 </papid>czech data is used to develop morphological analyzer for russian.in contrast to these works, we do not require par allel/comparable corpora or bilingual dictionary, which may be difficult to obtain.</citsent>
<aftsection>
<nextsent>our goal is to develop general algorithms for utilizing the commonalities across dialects for developing tool for specific dialect.
</nextsent>
<nextsent>although dialects can differ very strongly, they are similar in that they exhibit morphological simplifications and different word order compared to msa (e.g. svo rather than vso order), and close dialects share some vocabulary.
</nextsent>
<nextsent>each of the tagger components (i.e. contextual model p(ti|hi), lexical model p(wi|ti), and affix model p(ai|ti)p(bi|ti)) can be shared during training.
</nextsent>
<nextsent>in the following, we present two approaches for sharing data between dialects, each derived from following different assumptions about the underlying data generation process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1880">
<title id=" W05-0708.xml">pos tagging of dialectal arabic a minimally supervised approach </title>
<section> cross-dialectal data sharing.  </section>
<citcontext>
<prevsection>
<prevsent>pe(wn|tn) is the eca lexical model.
</prevsent>
<prevsent>the interpolation weight ? is estimated by maximizing the likelihood of held-out data set given the combined model.
</prevsent>
</prevsection>
<citsent citstr=" N03-2003 ">
as an extension, we allow the interpolation weights to be function of the current tag: ?(ti), since class-dependent interpolation has shown improvements over basic interpolation in applications such as language modeling (bu lyko et al, 2003).<papid> N03-2003 </papid></citsent>
<aftsection>
<nextsent>5.2 joint training of contextual model.
</nextsent>
<nextsent>as an alternative to model interpolation, we consider training single model jointly from the two different data sets.
</nextsent>
<nextsent>the underlying assumption of this technique is that tag sequences in lca and eca are generated by the same process, whereas the observations (the words) are generated from the tag by two different processes in the two different dialects.
</nextsent>
<nextsent>the hmm model for joint training is expressed as: ? i=0 (ipe(wi|ti) + (1 ? i)pl(wi|ti))pe+l(ti|hi) (3) where i= { 1 if word wi is eca 0 otherwise single conditional probability table is used for the contextual model, whereas the lexical model switches between two different parameter tables,one for lca observations and another for eca observations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1881">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conditional random fields (crfs) (lafferty et al, 2001) applied to sequential labeling problems are conditional models, trained to discriminate the correct sequence from all other candidate sequences without making independence assumption for features.
</prevsent>
<prevsent>they are considered to be the state-of-the-art framework to date.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
empirical successes with crf shave been reported recently in part-of-speech tagging (lafferty et al, 2001), shallow parsing (shaand pereira, 2003), <papid> N03-1028 </papid>named entity recognition (mccallum and li, 2003), <papid> W03-0430 </papid>chinese word segmentation (peng et al, 2004), <papid> C04-1081 </papid>and information extraction (pinto et al, 2003; peng and mccallum, 2004).<papid> N04-1042 </papid></citsent>
<aftsection>
<nextsent>previous applications with crfs assumed that observation sequence (e.g. word) boundaries are fixed, and the main focus was to predict label at present, ntt communication science laboratories, 2-4, hikaridai, seika-cho, soraku, kyoto, 619-0237 japan taku@cslab.kecl.ntt.co.jp sequence (e.g. part-of-speech).
</nextsent>
<nextsent>however, word boundaries are not clear in non-segmented languages.
</nextsent>
<nextsent>one has to identify word segmentation as well as to predict part-of-speech in morphological analysis of non-segmented languages.
</nextsent>
<nextsent>in this paper, we show how crfs can be applied to situations where word boundary ambiguity exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1882">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conditional random fields (crfs) (lafferty et al, 2001) applied to sequential labeling problems are conditional models, trained to discriminate the correct sequence from all other candidate sequences without making independence assumption for features.
</prevsent>
<prevsent>they are considered to be the state-of-the-art framework to date.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
empirical successes with crf shave been reported recently in part-of-speech tagging (lafferty et al, 2001), shallow parsing (shaand pereira, 2003), <papid> N03-1028 </papid>named entity recognition (mccallum and li, 2003), <papid> W03-0430 </papid>chinese word segmentation (peng et al, 2004), <papid> C04-1081 </papid>and information extraction (pinto et al, 2003; peng and mccallum, 2004).<papid> N04-1042 </papid></citsent>
<aftsection>
<nextsent>previous applications with crfs assumed that observation sequence (e.g. word) boundaries are fixed, and the main focus was to predict label at present, ntt communication science laboratories, 2-4, hikaridai, seika-cho, soraku, kyoto, 619-0237 japan taku@cslab.kecl.ntt.co.jp sequence (e.g. part-of-speech).
</nextsent>
<nextsent>however, word boundaries are not clear in non-segmented languages.
</nextsent>
<nextsent>one has to identify word segmentation as well as to predict part-of-speech in morphological analysis of non-segmented languages.
</nextsent>
<nextsent>in this paper, we show how crfs can be applied to situations where word boundary ambiguity exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1883">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conditional random fields (crfs) (lafferty et al, 2001) applied to sequential labeling problems are conditional models, trained to discriminate the correct sequence from all other candidate sequences without making independence assumption for features.
</prevsent>
<prevsent>they are considered to be the state-of-the-art framework to date.
</prevsent>
</prevsection>
<citsent citstr=" C04-1081 ">
empirical successes with crf shave been reported recently in part-of-speech tagging (lafferty et al, 2001), shallow parsing (shaand pereira, 2003), <papid> N03-1028 </papid>named entity recognition (mccallum and li, 2003), <papid> W03-0430 </papid>chinese word segmentation (peng et al, 2004), <papid> C04-1081 </papid>and information extraction (pinto et al, 2003; peng and mccallum, 2004).<papid> N04-1042 </papid></citsent>
<aftsection>
<nextsent>previous applications with crfs assumed that observation sequence (e.g. word) boundaries are fixed, and the main focus was to predict label at present, ntt communication science laboratories, 2-4, hikaridai, seika-cho, soraku, kyoto, 619-0237 japan taku@cslab.kecl.ntt.co.jp sequence (e.g. part-of-speech).
</nextsent>
<nextsent>however, word boundaries are not clear in non-segmented languages.
</nextsent>
<nextsent>one has to identify word segmentation as well as to predict part-of-speech in morphological analysis of non-segmented languages.
</nextsent>
<nextsent>in this paper, we show how crfs can be applied to situations where word boundary ambiguity exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1884">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conditional random fields (crfs) (lafferty et al, 2001) applied to sequential labeling problems are conditional models, trained to discriminate the correct sequence from all other candidate sequences without making independence assumption for features.
</prevsent>
<prevsent>they are considered to be the state-of-the-art framework to date.
</prevsent>
</prevsection>
<citsent citstr=" N04-1042 ">
empirical successes with crf shave been reported recently in part-of-speech tagging (lafferty et al, 2001), shallow parsing (shaand pereira, 2003), <papid> N03-1028 </papid>named entity recognition (mccallum and li, 2003), <papid> W03-0430 </papid>chinese word segmentation (peng et al, 2004), <papid> C04-1081 </papid>and information extraction (pinto et al, 2003; peng and mccallum, 2004).<papid> N04-1042 </papid></citsent>
<aftsection>
<nextsent>previous applications with crfs assumed that observation sequence (e.g. word) boundaries are fixed, and the main focus was to predict label at present, ntt communication science laboratories, 2-4, hikaridai, seika-cho, soraku, kyoto, 619-0237 japan taku@cslab.kecl.ntt.co.jp sequence (e.g. part-of-speech).
</nextsent>
<nextsent>however, word boundaries are not clear in non-segmented languages.
</nextsent>
<nextsent>one has to identify word segmentation as well as to predict part-of-speech in morphological analysis of non-segmented languages.
</nextsent>
<nextsent>in this paper, we show how crfs can be applied to situations where word boundary ambiguity exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1885">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one has to identify word segmentation as well as to predict part-of-speech in morphological analysis of non-segmented languages.
</prevsent>
<prevsent>in this paper, we show how crfs can be applied to situations where word boundary ambiguity exists.
</prevsent>
</prevsection>
<citsent citstr=" C00-1004 ">
crfs offer solution to the problems in japanese morphological analysis with hidden markov models (hmms) (e.g., (asahara and matsumoto, 2000)) <papid> C00-1004 </papid>or with maximum entropy markov models (memms) (e.g., (uchimoto et al, 2001)).<papid> W01-0512 </papid></citsent>
<aftsection>
<nextsent>first, as hmms are generative, it is hard to employ overlapping features stemmed from hierarchical tagsets and non independent features of the inputs such as surrounding words, word suffixes and character types.
</nextsent>
<nextsent>these features have usually been ignored in hmms, despite their effectiveness in unknown word guessing.
</nextsent>
<nextsent>second, as mentioned in the literature, memms could evade neither from label bias (lafferty et al., 2001) nor from length bias (a bias occurring because of word boundary ambiguity).
</nextsent>
<nextsent>easy sequences with low entropy are likely to be selected during decoding in memms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1886">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one has to identify word segmentation as well as to predict part-of-speech in morphological analysis of non-segmented languages.
</prevsent>
<prevsent>in this paper, we show how crfs can be applied to situations where word boundary ambiguity exists.
</prevsent>
</prevsection>
<citsent citstr=" W01-0512 ">
crfs offer solution to the problems in japanese morphological analysis with hidden markov models (hmms) (e.g., (asahara and matsumoto, 2000)) <papid> C00-1004 </papid>or with maximum entropy markov models (memms) (e.g., (uchimoto et al, 2001)).<papid> W01-0512 </papid></citsent>
<aftsection>
<nextsent>first, as hmms are generative, it is hard to employ overlapping features stemmed from hierarchical tagsets and non independent features of the inputs such as surrounding words, word suffixes and character types.
</nextsent>
<nextsent>these features have usually been ignored in hmms, despite their effectiveness in unknown word guessing.
</nextsent>
<nextsent>second, as mentioned in the literature, memms could evade neither from label bias (lafferty et al., 2001) nor from length bias (a bias occurring because of word boundary ambiguity).
</nextsent>
<nextsent>easy sequences with low entropy are likely to be selected during decoding in memms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1891">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> japanese morphological analysis.  </section>
<citcontext>
<prevsection>
<prevsent>even if the transition probability of each token is small, the total probability of the path will be amplified when the path isshort 2:(b)).
</prevsent>
<prevsent>length bias occurs in japanese morphological analysis because the number of output tokens varies by use of prior lexicons.
</prevsent>
</prevsection>
<citsent citstr=" C02-2019 ">
uchimoto et al attempted variant of memms for japanese morphological analysis with number of features including suffixes and character types (uchimoto et al, 2001; <papid> W01-0512 </papid>uchimoto et al, 2002; <papid> C02-2019 </papid>uchimoto et al, 2003).<papid> P03-1061 </papid></citsent>
<aftsection>
<nextsent>although the performance of unknown words were improved, that of known words degraded due to the label and length bias.
</nextsent>
<nextsent>wrong segmentation had been reported in sentences which are analyzed correctly by naive rule-based or hmms-based analyzers.
</nextsent>
<nextsent>conditional random fields (crfs) (lafferty et al,2001) overcome the problems described in section 2.2.
</nextsent>
<nextsent>crfs are discriminative models and can thus capture many correlated features of the inputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1892">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> japanese morphological analysis.  </section>
<citcontext>
<prevsection>
<prevsent>even if the transition probability of each token is small, the total probability of the path will be amplified when the path isshort 2:(b)).
</prevsent>
<prevsent>length bias occurs in japanese morphological analysis because the number of output tokens varies by use of prior lexicons.
</prevsent>
</prevsection>
<citsent citstr=" P03-1061 ">
uchimoto et al attempted variant of memms for japanese morphological analysis with number of features including suffixes and character types (uchimoto et al, 2001; <papid> W01-0512 </papid>uchimoto et al, 2002; <papid> C02-2019 </papid>uchimoto et al, 2003).<papid> P03-1061 </papid></citsent>
<aftsection>
<nextsent>although the performance of unknown words were improved, that of known words degraded due to the label and length bias.
</nextsent>
<nextsent>wrong segmentation had been reported in sentences which are analyzed correctly by naive rule-based or hmms-based analyzers.
</nextsent>
<nextsent>conditional random fields (crfs) (lafferty et al,2001) overcome the problems described in section 2.2.
</nextsent>
<nextsent>crfs are discriminative models and can thus capture many correlated features of the inputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1897">
<title id=" W04-3230.xml">applying conditional random fields to japanese morphological analysis </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>a normalization constant is then given by zx = weos,teos?(= wbos,tbos?).
</prevsent>
<prevsent>we attempt two types of regularizations in orderto avoid overfitting.
</prevsent>
</prevsection>
<citsent citstr=" N04-1039 ">
they are gaussian prior (l2 norm) (chen and rosenfeld, 1999) and laplacianprior (l1-norm) (goodman, 2004; <papid> N04-1039 </papid>peng and mccallum, 2004) <papid> N04-1042 </papid>l?</citsent>
<aftsection>
<nextsent>= ? log(p (yj |xj))?
</nextsent>
<nextsent>12 {?
</nextsent>
<nextsent>k |k| (l1-norm)?
</nextsent>
<nextsent>k |k|2 (l2-norm)below, we refer to crfs with l1-norm and l2norm regularization as l1-crfs and l2-crfs respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1906">
<title id=" W05-1303.xml">unsupervised gene protein named entity normalization using automatically extracted dictionaries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many investigators have examined the initial step of gene and protein ner.
</prevsent>
<prevsent>one of the most successful rules-based approaches to gene and protein ner in biomedical texts has been the abgene system (tanabe and wilbur, 2002), which has been used by several other researchers.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
after training on hand-tagged sentences from biomedical text, it applies brill-style tagger (brill, 1992) <papid> A92-1021 </papid>and manually generated postprocessing rules.</citsent>
<aftsection>
<nextsent>abgene achieves precision of 85.7% at recall of 66.7% (f1 = 75%).
</nextsent>
<nextsent>another successful system is gap score (chang et al, 2004).
</nextsent>
<nextsent>it assigns numeric score to each word in sentence based on appearance, morphology, and context of the word and then applies classifier trained on these features.
</nextsent>
<nextsent>after training on the yapex corpus (franzen et al, 2002), the system achieved precision of 81.5% at recall of 83.3% for partial matches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1907">
<title id=" W06-1111.xml">a measure of aggregate syntactic distance </title>
<section> syntactic footprints.  </section>
<citcontext>
<prevsection>
<prevsent>for example, bot et al (2005) suggest that non-transparent constructions are systematically avoided even by very good second-language learn ers).
</prevsent>
<prevsent>2.1 tagging.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we tagged the material using thorsten brantss trigrams tags (tnt) tagger, hidden markov model tagger which has performed at state-of the-art levels in organized comparisons, achieving96.7% correct on the material of the penn tree bank (brants, 2000).<papid> A00-1031 </papid>since our material is spoken english (see be low), we trained the tagger on the spoken part of the international corpus of english (ice) from great britain, which consists of 500k words.</citsent>
<aftsection>
<nextsent>thiswas sub optimal, as the material we wished to analyze was the english of finnish emigrants to australia, but we were unable to acquire sufficient 1one referee suggested that one might test the association between pos trigram differences and head differences experimentally, and we find this suggestion sensible.
</nextsent>
<nextsent>australian material.we used the tagset of the tosca-ice consisting of 270 tags (garside et al, 1997), of which 75were never instantiated in our material.
</nextsent>
<nextsent>in sample of 1, 000 words we found that the tagger was correct for 87% of words, 74% of the bigrams, and 65% of the trigrams.
</nextsent>
<nextsent>as will be obvious in the presentation of the material (below), it is free conversation with pervasive foreign influence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1908">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compared models of concepts based on values with models based on attributes, using lexical clustering as the basis for comparison.
</prevsent>
<prevsent>we find that attribute-based models work better than value-based ones, and result in shorter descriptions; but that mixed models including both the best attributes and the best values work best of all.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
in most recent research on concept acquisition from corpora (e.g., for lexicon construction), concepts are viewed as vectors of relations, or properties, extracted from syntactic structures (grefenstette, 1993; lin, 1998; <papid> P98-2127 </papid>curran and moens, 2002; <papid> W02-0908 </papid>kilgarriff, 2003, and many others).</citsent>
<aftsection>
<nextsent>these properties often specify values of attributes such as color, shape, or size: for example, the vector used by lin (1998) <papid> P98-2127 </papid>for the concept dog includes the property (dog adj-mod brown).</nextsent>
<nextsent>(we will use the term values here to refer to any modifier.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1910">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compared models of concepts based on values with models based on attributes, using lexical clustering as the basis for comparison.
</prevsent>
<prevsent>we find that attribute-based models work better than value-based ones, and result in shorter descriptions; but that mixed models including both the best attributes and the best values work best of all.
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
in most recent research on concept acquisition from corpora (e.g., for lexicon construction), concepts are viewed as vectors of relations, or properties, extracted from syntactic structures (grefenstette, 1993; lin, 1998; <papid> P98-2127 </papid>curran and moens, 2002; <papid> W02-0908 </papid>kilgarriff, 2003, and many others).</citsent>
<aftsection>
<nextsent>these properties often specify values of attributes such as color, shape, or size: for example, the vector used by lin (1998) <papid> P98-2127 </papid>for the concept dog includes the property (dog adj-mod brown).</nextsent>
<nextsent>(we will use the term values here to refer to any modifier.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1912">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two problems need to be addressed when trying to identify concept attributes.
</prevsent>
<prevsent>the first problem is that values are easier to extract.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
we found, however, that patterns like the of the dog, already used in (berland and charniak, 1999; <papid> P99-1008 </papid>poesio et al  2002) to find part-of relations (using techniques derived from those used in (hearst, 1998; caraballo, 1999) <papid> P99-1016 </papid>to find hyponymy relations) are quite effective at finding attributes.</citsent>
<aftsection>
<nextsent>a second problem might be that instances of such patterns are less frequent than those used to extract values, even in large corpora such as the british national corpus (bnc).
</nextsent>
<nextsent>but this problem, as well, is less serious when using the web as corpus (kilgarriff and schuetze, 2003; keller and lapata, 2003; <papid> J03-3005 </papid>markert et al  submitted).</nextsent>
<nextsent>we report on two experiments whose goal was to test whether identifying attributes leads to better lexical descriptions of concepts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1913">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>two problems need to be addressed when trying to identify concept attributes.
</prevsent>
<prevsent>the first problem is that values are easier to extract.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
we found, however, that patterns like the of the dog, already used in (berland and charniak, 1999; <papid> P99-1008 </papid>poesio et al  2002) to find part-of relations (using techniques derived from those used in (hearst, 1998; caraballo, 1999) <papid> P99-1016 </papid>to find hyponymy relations) are quite effective at finding attributes.</citsent>
<aftsection>
<nextsent>a second problem might be that instances of such patterns are less frequent than those used to extract values, even in large corpora such as the british national corpus (bnc).
</nextsent>
<nextsent>but this problem, as well, is less serious when using the web as corpus (kilgarriff and schuetze, 2003; keller and lapata, 2003; <papid> J03-3005 </papid>markert et al  submitted).</nextsent>
<nextsent>we report on two experiments whose goal was to test whether identifying attributes leads to better lexical descriptions of concepts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1914">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found, however, that patterns like the of the dog, already used in (berland and charniak, 1999; <papid> P99-1008 </papid>poesio et al  2002) to find part-of relations (using techniques derived from those used in (hearst, 1998; caraballo, 1999) <papid> P99-1016 </papid>to find hyponymy relations) are quite effective at finding attributes.</prevsent>
<prevsent>a second problem might be that instances of such patterns are less frequent than those used to extract values, even in large corpora such as the british national corpus (bnc).</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
but this problem, as well, is less serious when using the web as corpus (kilgarriff and schuetze, 2003; keller and lapata, 2003; <papid> J03-3005 </papid>markert et al  submitted).</citsent>
<aftsection>
<nextsent>we report on two experiments whose goal was to test whether identifying attributes leads to better lexical descriptions of concepts.
</nextsent>
<nextsent>we do this by comparing the results obtained by using attributes or more general modifiers ? that we will simply call values ? as elements of concept vectors used to identify concept similarities via clustering.
</nextsent>
<nextsent>in section 2, we discuss how web data were used to build attribute- and value- based concept vectors, and our clustering and evaluation methods.
</nextsent>
<nextsent>in section 3, we discuss first experiment using the set of concepts used in (lund and burgess, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1917">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>each system cluster, finding the class of each concept in the model clusters, and determining the majority class.
</prevsent>
<prevsent>the cluster is then labeled with this class; the concepts belonging to it are taken to be correctly clustered, whereas the remaining concepts are judged to be incorrectly clustered.
</prevsent>
</prevsection>
<citsent citstr=" P93-1023 ">
in the contingency table evaluation (swets, 1969; hatzivassiloglou and mckeown, 1993), <papid> P93-1023 </papid>the clusters are converted into two lists (one for the system clusters and one for the model clusters) of yes-no answers to the question  does the pair of concepts occur in the same cluster?  for each pair of concepts.</citsent>
<aftsection>
<nextsent>a contingency table is then built, from which recall (r), precision (p), fallout, and measures can be computed.
</nextsent>
<nextsent>for example, if the model clusters are: (a, b, c) and (d), and the system clusters are: (a, b) and (c, d), the yes-no lists are as in table 2, and the contingency table is as in table 3.
</nextsent>
<nextsent>question model answer system answer does the pair (a, b) occur in the same cluster?
</nextsent>
<nextsent>yes yes does the pair (a, c) occur in the same cluster?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1923">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> second experiment: using set of.  </section>
<citcontext>
<prevsection>
<prevsent>seat was clustered with body part concepts, which is acceptable if we think of seat as  the fleshy part of the human body that you sit on  (wordnet, sense 2).
</prevsent>
<prevsent>the same for lounge, which was clustered with buildings, which is consistent with its second sense in wordnet:  public room (as in hotel or airport) with seating where people can wait .
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
this indicates that techniques for differentiating between different senses are needed ? e.g., using soft clustering technique as in (pereira et al  1993) <papid> P93-1024 </papid>instead of hard clustering technique.</citsent>
<aftsection>
<nextsent>second, furniture concepts may not have common prototype that is shared by all of the member concepts.
</nextsent>
<nextsent>this is well known problem in the prototype theory of concepts (laurence and margolis, 1999).
</nextsent>
<nextsent>the greater compactness of attribute-based representations vs. value-based ones was more evident in this second experiment.
</nextsent>
<nextsent>we collected 51,045 distinct values and 8,934 distinct attributes; the total number of value-concept relations is 1,026,335, compared to 422,621 attribute-concept relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1924">
<title id=" W04-3221.xml">attribute based and value based clustering an evaluation </title>
<section> attributes and values: discussion.  </section>
<citcontext>
<prevsection>
<prevsent>relational attributes include qualities such as color and position, and relational roles such as son and spouse.
</prevsent>
<prevsent>non-relational attributes include parts such as wheel and engine.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
the qualia structure of the generative lexicon (pustejovsky, 1991) <papid> J91-4003 </papid>is another attempt at identifying  the essential attributes of an object as defined by the lexical item .</citsent>
<aftsection>
<nextsent>pustejovsky identifies four roles: constitutive role (guarino parts), formal role (guarino qualities), agentive role (guarino relational roles), and telic role (not included in guarino classification).
</nextsent>
<nextsent>our analysis of the attribute data shows that the attributes we found can be mapped in the four roles of the qualia structure.
</nextsent>
<nextsent>table 8 shows how we manually mapped the top 50 attributes of the concept car to the qualia roles and the guarino classes.
</nextsent>
<nextsent>this mapping is not trivial (e.g., path is not part of car, and design can be regarded as quality), but variety of tests may help: morphological and onto logical tests: dixon (1991) proposed semantic classification for nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1925">
<title id=" W06-0139.xml">description of the ncu chinese word segmentation and named entity recognition system for sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to support the above targets, it is necessary to detect the boundaries between words in given sentence.
</prevsent>
<prevsent>in tradition, the chinese word segmentation technologies can be categorized into three types, (heuristic) rule-based, machine learning, and hybrid.
</prevsent>
</prevsection>
<citsent citstr=" C04-1081 ">
among them, the machine learning-based techniques showed excellent performance in many research studies (peng et al, 2004; <papid> C04-1081 </papid>zhou et al, 2005; gao et al, 2004).<papid> P04-1059 </papid></citsent>
<aftsection>
<nextsent>this method treats the word segmentation problem as sequence of word classification.
</nextsent>
<nextsent>the classifier online assigns either boundary?
</nextsent>
<nextsent>or non-boundary?
</nextsent>
<nextsent>label to each word by learning from the large annotated corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1926">
<title id=" W06-0139.xml">description of the ncu chinese word segmentation and named entity recognition system for sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to support the above targets, it is necessary to detect the boundaries between words in given sentence.
</prevsent>
<prevsent>in tradition, the chinese word segmentation technologies can be categorized into three types, (heuristic) rule-based, machine learning, and hybrid.
</prevsent>
</prevsection>
<citsent citstr=" P04-1059 ">
among them, the machine learning-based techniques showed excellent performance in many research studies (peng et al, 2004; <papid> C04-1081 </papid>zhou et al, 2005; gao et al, 2004).<papid> P04-1059 </papid></citsent>
<aftsection>
<nextsent>this method treats the word segmentation problem as sequence of word classification.
</nextsent>
<nextsent>the classifier online assigns either boundary?
</nextsent>
<nextsent>or non-boundary?
</nextsent>
<nextsent>label to each word by learning from the large annotated corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1927">
<title id=" W06-0139.xml">description of the ncu chinese word segmentation and named entity recognition system for sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or non-boundary?
</prevsent>
<prevsent>label to each word by learning from the large annotated corpora.
</prevsent>
</prevsection>
<citsent citstr=" W06-2937 ">
machine learning-based word segmentation method is quite similar to the word sequence inference techniques, such as part-of-speech (pos) tagging, phrase chunking (wu et al, 2006<papid> W06-2937 </papid>a) and named entity recognition (wu et al, 2006<papid> W06-2937 </papid>b).</citsent>
<aftsection>
<nextsent>in this paper, we present prototype for chinese word segmentation and named entity recognition based on the word sequence inference model.
</nextsent>
<nextsent>unlike previous researches (zhou et al, 2005; shi, 2005), <papid> I05-3034 </papid>we argue that without using the word segmentation information, chinese named entity recognition task can also be viewed as variant word segmentation technique.</nextsent>
<nextsent>therefore, the two tasks can be accomplished without adapting the word sequence inference model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1935">
<title id=" W06-0139.xml">description of the ncu chinese word segmentation and named entity recognition system for sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>machine learning-based word segmentation method is quite similar to the word sequence inference techniques, such as part-of-speech (pos) tagging, phrase chunking (wu et al, 2006<papid> W06-2937 </papid>a) and named entity recognition (wu et al, 2006<papid> W06-2937 </papid>b).</prevsent>
<prevsent>in this paper, we present prototype for chinese word segmentation and named entity recognition based on the word sequence inference model.</prevsent>
</prevsection>
<citsent citstr=" I05-3034 ">
unlike previous researches (zhou et al, 2005; shi, 2005), <papid> I05-3034 </papid>we argue that without using the word segmentation information, chinese named entity recognition task can also be viewed as variant word segmentation technique.</citsent>
<aftsection>
<nextsent>therefore, the two tasks can be accomplished without adapting the word sequence inference model.
</nextsent>
<nextsent>the preliminary experimental result show that in the word segmentation task, our method can achieve 91.00 in rate for the upuc chinese treebank data, while it at 209 tends 78.76 rate for the microsoft chinese named entity recognition task.
</nextsent>
<nextsent>the rest of this paper is organized as follows.
</nextsent>
<nextsent>section 2 describes the word sequence inference model and the used learner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1936">
<title id=" W06-0139.xml">description of the ncu chinese word segmentation and named entity recognition system for sighan bakeoff 2006 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>in section 2.2, the employed classification model- conditional random fields (crf) is then presented.
</prevsent>
<prevsent>2.1 word sequence classification.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
similar to english text chunking (ramshaw and marcus, 1995; <papid> W95-0107 </papid>wu et al, 2006<papid> W06-2937 </papid>a), the word sequence classification model aims to classify each word via encoding its context features.</citsent>
<aftsection>
<nextsent>an example can be shown in figure 1.
</nextsent>
<nextsent>in figure1, the model is classifying the chinese character ???
</nextsent>
<nextsent>(country).
</nextsent>
<nextsent>the second row in figure 1 means the corresponding category of each in the word-segmentation (ws) task, while the third row indicates the class in the named entity recognition (ner) task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1945">
<title id=" W05-0823.xml">statistical machine translation of euparl data by using bilingual ngrams </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work discusses translation results for the four euparl datasets which were made available for the shared task exploiting parallel texts for statistical machine translation?.
</prevsent>
<prevsent>all results presented were generated by using statistical machine translation system which implements alog-linear combination of feature functions along with bilingual n-gram translation model.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al , 1993) <papid> J93-2003 </papid>into phrase-based translation systems (koehn et al , 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>similarly, the noisy channel approach has been expanded to more general maximum entropy approach in which log-linear combination of multiple models is implemented (och and ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>the smt approach used in this work implements log-linear combination of feature functions along with translation model which is based on bilingual n-grams.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1946">
<title id=" W05-0823.xml">statistical machine translation of euparl data by using bilingual ngrams </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work discusses translation results for the four euparl datasets which were made available for the shared task exploiting parallel texts for statistical machine translation?.
</prevsent>
<prevsent>all results presented were generated by using statistical machine translation system which implements alog-linear combination of feature functions along with bilingual n-gram translation model.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al , 1993) <papid> J93-2003 </papid>into phrase-based translation systems (koehn et al , 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>similarly, the noisy channel approach has been expanded to more general maximum entropy approach in which log-linear combination of multiple models is implemented (och and ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>the smt approach used in this work implements log-linear combination of feature functions along with translation model which is based on bilingual n-grams.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1947">
<title id=" W05-0823.xml">statistical machine translation of euparl data by using bilingual ngrams </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all results presented were generated by using statistical machine translation system which implements alog-linear combination of feature functions along with bilingual n-gram translation model.
</prevsent>
<prevsent>during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al , 1993) <papid> J93-2003 </papid>into phrase-based translation systems (koehn et al , 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
similarly, the noisy channel approach has been expanded to more general maximum entropy approach in which log-linear combination of multiple models is implemented (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>the smt approach used in this work implements log-linear combination of feature functions along with translation model which is based on bilingual n-grams.
</nextsent>
<nextsent>this translation model was developed by de gispert and marino (2002), and it differs from the well known phrase-based translation model in two basic issues: first, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies.
</nextsent>
<nextsent>this model is described in section 2.
</nextsent>
<nextsent>translation results from the four source languages made available for the shared task (es: spanish, fr: french, de: german, and fi: finnish) into english (en) are presented and discussed.the paper is structured as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1948">
<title id=" W05-0823.xml">statistical machine translation of euparl data by using bilingual ngrams </title>
<section> smt procedure description.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of french, re-tokenizing procedure was performed in which all apostrophes appearing alone were attached to their corresponding words.
</prevsent>
<prevsent>for example, pairs of tokens such as ? and qu ? were reduced to single tokens such as l?
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
and qu?.once the training data was preprocessed, wordto-word alignment was performed in both directions, source-to-target and target-to-source, by using giza++ (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>as an approximation to the most probable alignment, the viterbi alignment was considered.
</nextsent>
<nextsent>then, the intersection and union of alignment sets in both directions were computed for each training set.
</nextsent>
<nextsent>3.2 feature function computation.
</nextsent>
<nextsent>the considered translation system implements total of five feature functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1950">
<title id=" W05-0823.xml">statistical machine translation of euparl data by using bilingual ngrams </title>
<section> smt procedure description.  </section>
<citcontext>
<prevsection>
<prevsent>for all the results presented in this work the decoders monotonic search modality was used.
</prevsent>
<prevsent>an optimization tool, which is based on simplex method (press et al , 2002), was developed and usedfor computing log-linear weights for each of the feature functions described above.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
this algorithm adjusts the log-linear weights so that bleu (papineni et al , 2002) <papid> P02-1040 </papid>is maximized over given development set.</citsent>
<aftsection>
<nextsent>one optimization for each language pair was performed by using the 2000-sentence development sets made available for the shared task.
</nextsent>
<nextsent>table 2 presents the bleu scores obtained for the shared task test data.
</nextsent>
<nextsent>each test set consisted of 2000 sentences.
</nextsent>
<nextsent>the computed bleu scores were case insensitive and used one translation reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1951">
<title id=" W04-3241.xml">the entropy rate principle as a predictor of processing effort an evaluation against eye tracking data </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P02-1026 ">
this paper provides evidence for genzel and char niaks (2002) <papid> P02-1026 </papid>entropy rate principle, which predicts that the entropy of sentence increases with its position in the text.</citsent>
<aftsection>
<nextsent>we show that this principle holds for individual sentences (not just for averages), but we also find that the entropy rate effect is partly an artifact of sentence length, which also correlates with sentence position.
</nextsent>
<nextsent>secondly, we evaluate set of predictions that the entropy rate principle makes for human language processing; using corpus ofeye-tracking data, we show that entropy and processing effort are correlated, and that processing effort is constant throughout text.
</nextsent>
<nextsent>genzel and charniak (2002), <papid> P02-1026 </papid>genzel and charniak (2003) <papid> W03-1009 </papid>introduce the entropy rate principle, which states that speakers produce language whose entropy rate is on averageconstant.</nextsent>
<nextsent>the motivation for this comes from information theory: the most efficient way of transmitting information through noisy channel is at constant rate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1955">
<title id=" W04-3241.xml">the entropy rate principle as a predictor of processing effort an evaluation against eye tracking data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that this principle holds for individual sentences (not just for averages), but we also find that the entropy rate effect is partly an artifact of sentence length, which also correlates with sentence position.
</prevsent>
<prevsent>secondly, we evaluate set of predictions that the entropy rate principle makes for human language processing; using corpus ofeye-tracking data, we show that entropy and processing effort are correlated, and that processing effort is constant throughout text.
</prevsent>
</prevsection>
<citsent citstr=" W03-1009 ">
genzel and charniak (2002), <papid> P02-1026 </papid>genzel and charniak (2003) <papid> W03-1009 </papid>introduce the entropy rate principle, which states that speakers produce language whose entropy rate is on averageconstant.</citsent>
<aftsection>
<nextsent>the motivation for this comes from information theory: the most efficient way of transmitting information through noisy channel is at constant rate.
</nextsent>
<nextsent>if human communication has evolved to be optimal in this sense, then we would expect humans to produce text and speech with approximately constant entropy.
</nextsent>
<nextsent>there is some evidence that this is true for speech (aylett, 1999).
</nextsent>
<nextsent>for text, the entropy rate principle predicts that the entropy of an individual sentence increases with its position in the text, if entropy is measured out of context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1985">
<title id=" W05-0404.xml">using semantic and syntactic graphs for call classification </title>
<section> semantic and syntactic graphs.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the sequence six dollars is the amount of the predicate pay, and this is shown by the transition with label srl:pay.a1 following the propbank notation (kingsbury et al, 2002)1.
</prevsent>
<prevsent>in this work, we were only able to incorporate part-of-speech tags, syntactic parses, named entity tags and semantic role labels in the syntactic and semantic graphs.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
insertion of further information such as supertags (bangalore and joshi, 1999) <papid> J99-2004 </papid>or word stems can also be beneficial for further processing.</citsent>
<aftsection>
<nextsent>in this paper we propose extracting all  -grams fromthe ssgs to use them for call classification.
</nextsent>
<nextsent>the  grams in an utterance ssg can be extracted by converting it to finite state transducer (fst),  . each transition of  has the labels of the arcs on the ssg as input and output symbols2.
</nextsent>
<nextsent>composing this fst with another fst,  , representing all the possible -grams, forms the fst,  , which includes all  grams in the ssg:    1a1 or arg1 indicates the object of the predicate, in this case the amount.2instead of the standard notation where ?:?
</nextsent>
<nextsent>is used to separate the input and output symbols infinite state transducers, we use ?:?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1986">
<title id=" W05-0404.xml">using semantic and syntactic graphs for call classification </title>
<section> computation of the ssgs.  </section>
<citcontext>
<prevsection>
<prevsent>all of these components maybe improved independently, for the specific application domain.
</prevsent>
<prevsent>4.1 part-of-speech tagger.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
part-of-speech tagging has been very well studied in the literature for many languages, and the approaches vary from rule-based to hmm-based and classifier-based (church, 1988; <papid> A88-1019 </papid>brill, 1995, <papid> J95-4004 </papid>among others) tagging.</citsent>
<aftsection>
<nextsent>in our framework, we employ asimple hmm-based tagger, where the most probable tag sequence, flffi , given the words,  , is out put (weischedel et al, 1993): <papid> J93-2006 </papid>fl ffi   !$#&amp;%  )( * +-, ffi/.</nextsent>
<nextsent>10  !2#&amp;%  )( * +-,  . ffi 0 +3, ffi 0 since we do not have enough data which is manually tagged with part-of-speech tags for our applications, we used penn treebank (marcus et al, 1994) as our training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1987">
<title id=" W05-0404.xml">using semantic and syntactic graphs for call classification </title>
<section> computation of the ssgs.  </section>
<citcontext>
<prevsection>
<prevsent>all of these components maybe improved independently, for the specific application domain.
</prevsent>
<prevsent>4.1 part-of-speech tagger.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
part-of-speech tagging has been very well studied in the literature for many languages, and the approaches vary from rule-based to hmm-based and classifier-based (church, 1988; <papid> A88-1019 </papid>brill, 1995, <papid> J95-4004 </papid>among others) tagging.</citsent>
<aftsection>
<nextsent>in our framework, we employ asimple hmm-based tagger, where the most probable tag sequence, flffi , given the words,  , is out put (weischedel et al, 1993): <papid> J93-2006 </papid>fl ffi   !$#&amp;%  )( * +-, ffi/.</nextsent>
<nextsent>10  !2#&amp;%  )( * +-,  . ffi 0 +3, ffi 0 since we do not have enough data which is manually tagged with part-of-speech tags for our applications, we used penn treebank (marcus et al, 1994) as our training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1988">
<title id=" W05-0404.xml">using semantic and syntactic graphs for call classification </title>
<section> computation of the ssgs.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 part-of-speech tagger.
</prevsent>
<prevsent>part-of-speech tagging has been very well studied in the literature for many languages, and the approaches vary from rule-based to hmm-based and classifier-based (church, 1988; <papid> A88-1019 </papid>brill, 1995, <papid> J95-4004 </papid>among others) tagging.</prevsent>
</prevsection>
<citsent citstr=" J93-2006 ">
in our framework, we employ asimple hmm-based tagger, where the most probable tag sequence, flffi , given the words,  , is out put (weischedel et al, 1993): <papid> J93-2006 </papid>fl ffi   !$#&amp;%  )( * +-, ffi/.</citsent>
<aftsection>
<nextsent>10  !2#&amp;%  )( * +-,  . ffi 0 +3, ffi 0 since we do not have enough data which is manually tagged with part-of-speech tags for our applications, we used penn treebank (marcus et al, 1994) as our training set.
</nextsent>
<nextsent>penn treebank includes data from wall street journal, brown, atis, and switchboard corpora.
</nextsent>
<nextsent>the final two sets are the most useful for our domain, since they are also from spoken language and include disfluencies.
</nextsent>
<nextsent>as test set, we manually labeled 2,000 words of user utterances from an at&t; voice tone spoken dialog system application,and we achieved an accuracy of 94.95% on manually transcribed utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1989">
<title id=" W05-0404.xml">using semantic and syntactic graphs for call classification </title>
<section> computation of the ssgs.  </section>
<citcontext>
<prevsection>
<prevsent>transition probabilities consisted of trigram probabilities +-, 79 ;: 56 . 7= ? a@b: 5c ? a@edf7= ? gh: 5c ? gh0 over these combined tokens.
</prevsent>
<prevsent>in the final version, we extended this model with an unknown words model (hakkani-tur et al, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W03-0421 ">
in the classifier based approach, we used simple features such as the current word and surrounding 4 words, binary tags indicating if the word considered contains any digits or is formed from digits, and features checking capitalization (carreras et al, 2003).<papid> W03-0421 </papid></citsent>
<aftsection>
<nextsent>to test these approaches, we have used data froman at&t; voice tone spoken dialog system application for pharmaceutical domain, where some ofthe named entity categories were person, organization, drug name, prescription number, and date.
</nextsent>
<nextsent>the training and test sets contained around 11,000 and 5,000 utterances, respectively.
</nextsent>
<nextsent>table 1 summarizes the overall f-measure results as well as f-measurefor the most frequent named entity categories.
</nextsent>
<nextsent>over all, the classifier based approach resulted in the best performance, so it is also used for the call classification experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1990">
<title id=" W05-0404.xml">using semantic and syntactic graphs for call classification </title>
<section> computation of the ssgs.  </section>
<citcontext>
<prevsection>
<prevsent>work, we use the semantic roles and annotations from the propbank corpus (kingsbury et al, 2002), where the arguments are given mnemonic names, such as arg0, arg1, arg-loc, etc. for example, for the sentence have bought myself blue jacket from your summer catalog for twenty ve dollars last week, the agent (buyer, or arg0) is i, the predicate is buy, the thing bought (arg1) is blue jacket, the seller or source (arg2) is from your summer catalog,the price paid (arg3) is twenty ve dollars, the bene factive (arg4) is myself, and the date (argm-tmp) is last week4.semantic role labeling can be viewed as multiclass classification problem.
</prevsent>
<prevsent>given word (or phrase) and its features, the goal is to output themost probable semantic label.
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
for semantic role labeling, we have used the exact same feature set that hacioglu et al (2004) <papid> W04-2416 </papid>have used, since their system performed the best among others in the conll 2004 shared task (carreras and ma`rquez, 2004).</citsent>
<aftsection>
<nextsent>we have used boostexter (schapire and singer,2000) as the classifier.
</nextsent>
<nextsent>the features include token level features (such as the current (head) word, its part-of-speech tag, base phrase type and position, etc.), predicate-level features (such as the predicates lemma, frequency, part-of-speech tag, etc.) andargument-level features which capture the relationship between the token (head word/phrase) and the predicate (such as the syntactic path between the token and the predicate, their distance, token position relative to the predicate, etc.).
</nextsent>
<nextsent>in order to evaluate the performance of semantic role labeling, we have manually annotated 285 utterances from an at&t; voice tone spoken dialog sys 4see http://www.cis.upenn.edu/ 4 dgildea/verbs for more details tem application for retail domain.
</nextsent>
<nextsent>the utterances include 645 predicates (2.3 predicates/utterance).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1991">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the main drawback for supervised wsd is the knowledge acquisition bottleneck: the systems need large amounts of costly hand-tagged data.
</prevsent>
<prevsent>the situation is more dramatic for lesser studied languages.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in order to overcome this problem, different research lines have been explored: automatic acquisition of training examples (mihalcea, 2002), bootstrapping techniques(yarowsky, 1995), <papid> P95-1026 </papid>or active learning (argamon engelson and dagan, 1999).</citsent>
<aftsection>
<nextsent>in this work, we have focused on the automatic acquisition of examples.when supervised systems have no specific training examples for target word, they need to relyon publicly available all-words sense-tagged corpora like semcor (miller et al, 1993), <papid> H93-1061 </papid>which is tagged with wordnet word senses.</nextsent>
<nextsent>the systems performing best in the english all-words task in senseval-2were basically supervised systems trained on semcor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1992">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the situation is more dramatic for lesser studied languages.
</prevsent>
<prevsent>in order to overcome this problem, different research lines have been explored: automatic acquisition of training examples (mihalcea, 2002), bootstrapping techniques(yarowsky, 1995), <papid> P95-1026 </papid>or active learning (argamon engelson and dagan, 1999).</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
in this work, we have focused on the automatic acquisition of examples.when supervised systems have no specific training examples for target word, they need to relyon publicly available all-words sense-tagged corpora like semcor (miller et al, 1993), <papid> H93-1061 </papid>which is tagged with wordnet word senses.</citsent>
<aftsection>
<nextsent>the systems performing best in the english all-words task in senseval-2were basically supervised systems trained on semcor.
</nextsent>
<nextsent>unfortunately, for most of the words, this cor 1http://www.senseval.org.
</nextsent>
<nextsent>pus only provides handful of tagged examples.
</nextsent>
<nextsent>in fact, only few systems could overcome the most frequent sense (mfs) baseline, which would tag each word with the sense occurring most frequently in semcor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1993">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is very promising line of research, but one which remains relatively under studied (cf.
</prevsent>
<prevsent>section 2).
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
the method we applied is based on the monosemous relatives of the target words (leacock et al, 1998), <papid> J98-1006 </papid>and we studied some parameters that affect the quality of the acquired corpus, such as the distribution of the number of training instances per each word sense (bias), and the type of features used for disambiguation (local vs. topical).basically, we built three systems, one fully supervised (using examples from both semcor and automatically acquired examples), one minimally supervised (using the distribution of senses in semcor and automatically acquired examples) and another fully unsupervised (using an automatically acquired sense rank (mccarthy et al, 2004) <papid> P04-1036 </papid>and automatically acquired examples).</citsent>
<aftsection>
<nextsent>this paper is structured as follows.
</nextsent>
<nextsent>first, section2 describes previous work on the field.
</nextsent>
<nextsent>section 3 introduces the experimental setting for evaluating the acquired corpus.
</nextsent>
<nextsent>section 4 is devoted to the process of building the corpus, which is evaluated in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB1996">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is very promising line of research, but one which remains relatively under studied (cf.
</prevsent>
<prevsent>section 2).
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
the method we applied is based on the monosemous relatives of the target words (leacock et al, 1998), <papid> J98-1006 </papid>and we studied some parameters that affect the quality of the acquired corpus, such as the distribution of the number of training instances per each word sense (bias), and the type of features used for disambiguation (local vs. topical).basically, we built three systems, one fully supervised (using examples from both semcor and automatically acquired examples), one minimally supervised (using the distribution of senses in semcor and automatically acquired examples) and another fully unsupervised (using an automatically acquired sense rank (mccarthy et al, 2004) <papid> P04-1036 </papid>and automatically acquired examples).</citsent>
<aftsection>
<nextsent>this paper is structured as follows.
</nextsent>
<nextsent>first, section2 describes previous work on the field.
</nextsent>
<nextsent>section 3 introduces the experimental setting for evaluating the acquired corpus.
</nextsent>
<nextsent>section 4 is devoted to the process of building the corpus, which is evaluated in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2000">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> experimental setting for evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 decision lists.
</prevsent>
<prevsent>the learning method used to measure the quality of the corpus is decision lists (dl).
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
this algorithm is described in (yarowsky, 1994).<papid> P94-1013 </papid></citsent>
<aftsection>
<nextsent>in this method, the sense k with the highest weighted feature iis selected, according to its log-likelihood (see formula 1).
</nextsent>
<nextsent>for our implementation, we applied simple smoothing method: the cases where the denominator is zero are smoothed by the constant 0.1 . weight(s , i ) = log( pr(s |f ) ? j
</nextsent>
<nextsent>=k pr(s |f ) ) (1) 3.2 features.
</nextsent>
<nextsent>in order to represent the context, we used basic set of features frequently used in the literature for wsd tasks (agirre and martinez, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2001">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> experimental setting for evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>also the contentlemmas in 4 word window around the target.
</prevsent>
<prevsent> topical features: all the content lemmas in the context.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
2the pos tagging was performed using tnt (brants, 2000)<papid> A00-1031 </papid>we have analyzed the results using local and topical features separately, and also using both types together (combination).</citsent>
<aftsection>
<nextsent>3.3 hand-tagged corpora.
</nextsent>
<nextsent>semcor was used as training data for our supervised system.
</nextsent>
<nextsent>this corpus offers tagged examples for many words, and has been widely used for wsd.it was necessary to use an automatic mapping between the wordnet 1.6 senses in semcor and the wordnet 1.7 senses in testing (daude et al, 2000).<papid> P00-1064 </papid>for evaluation, the test part of the senseval-2 english lexical-sample task was chosen.</nextsent>
<nextsent>the advantage of this corpus was that we could focus on aword-set with enough examples for testing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2002">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> experimental setting for evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 hand-tagged corpora.
</prevsent>
<prevsent>semcor was used as training data for our supervised system.
</prevsent>
</prevsection>
<citsent citstr=" P00-1064 ">
this corpus offers tagged examples for many words, and has been widely used for wsd.it was necessary to use an automatic mapping between the wordnet 1.6 senses in semcor and the wordnet 1.7 senses in testing (daude et al, 2000).<papid> P00-1064 </papid>for evaluation, the test part of the senseval-2 english lexical-sample task was chosen.</citsent>
<aftsection>
<nextsent>the advantage of this corpus was that we could focus on aword-set with enough examples for testing.
</nextsent>
<nextsent>besides, it is different corpus, so the evaluation is more realistic than that made using cross-validation.
</nextsent>
<nextsent>the test examples whose senses were multi words or phrasal verbs were removed, because they can be efficiently detected with other methods in prepro cess.
</nextsent>
<nextsent>it is important to note that the training part ofsenseval-2 lexical-sample was not used in the construction of the systems, as our goal was to testthe performance we could achieve with minimal resources (i.e. those available for any word).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2009">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> building the monosemous relatives web.  </section>
<citcontext>
<prevsection>
<prevsent> web bias: we take all examples gathered from the web.
</prevsent>
<prevsent> automatic ranking: the number of examples is given by ranking obtained following the method described in (mccarthy et al, 2004).<papid> P04-1036 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
they used thesaurus automatically created from the bnc corpus with the method from(lin, 1998), <papid> P98-2127 </papid>coupled with wordnet-based similarity measures.</citsent>
<aftsection>
<nextsent> semcor bias: we take number of examples proportional to the bias of the word senses in semcor.for example, table 1 shows the number of examples per type (0,1,...)
</nextsent>
<nextsent>that are acquired for church following the semcor bias.
</nextsent>
<nextsent>the last column gives the number of examples in semcor.
</nextsent>
<nextsent>we have to note that the 3 first methods do not require any hand-labeled data, and that the fourth relies in semcor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2012">
<title id=" W04-3204.xml">unsupervised wsd based on automatically retrieved examples the importance of bias </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for set a, the average number of examples is higher, and this raises the results for semcor mfs (51.9%).
</prevsent>
<prevsent>we see that the recall for dl training in semcor is lower that the mfs baseline (50.5%).the main reasons for these low results are the differences between the training and testing corpora (semcor and senseval).
</prevsent>
</prevsection>
<citsent citstr=" W00-1326 ">
there have been previous works on portability of hand-tagged corpora that show how some constraints, like the genre or topic of the corpus, affect heavily the results (martinez and agirre, 2000).<papid> W00-1326 </papid></citsent>
<aftsection>
<nextsent>if we train on the web-corpusthe results improve, and the best results are obtained with the combination of both corpora, reaching 51.6%.
</nextsent>
<nextsent>we need to note, however, that this is still lower than the semcor mfs.
</nextsent>
<nextsent>finally, we will examine the results for the whole set of nouns in the senseval-2 lexical-sample (last row in table 6), where we see that the best approach relies on the web-corpus.
</nextsent>
<nextsent>in order to disambiguate the 29 nouns using only semcor, we apply mfs when there are less than 10 examples (set b), and train the dls for the rest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2013">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the role of the authors in the class project is mainly on information extraction from text.in the first phase of the project we build classifier for automatic identification and categorization of entities in texts which we report here.
</prevsent>
<prevsent>this classifier extracts entities from text, and assigns label to these entities chosen from an inventory of possible labels.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
this task is closely related toboth named entity recognition (ner), which traditionally assigns nouns to small number of categories and word sense disambiguation (agirre and 1http://class.inrialpes.fr/ rigau, 1996; yarowsky, 1995), <papid> P95-1026 </papid>where the sense for word is chosen from much larger inventory of word senses.</citsent>
<aftsection>
<nextsent>we will employ probabilistic model thats been used successfully inner (conditional random fields) and use this with an extensive inventory of word senses (the wordnet lexical database) to perform entity detection.
</nextsent>
<nextsent>in section 2 we describe wordnet and its use for entity categorization.
</nextsent>
<nextsent>section 3 gives an overview of conditional random fields and section 4 explains how the parameters of this model are estimated during training.
</nextsent>
<nextsent>we will drastically reduce the computational complexity of training in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2014">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>given that in information extraction tasks, we often lack an annotated training set that covers all possible extraction patterns, this is valuable asset.
</prevsent>
<prevsent>lafferty et al (lafferty et al, 2001) have shown that crfs outperform both memm and hmm on synthetic data and on part-of-speech taggingtask.
</prevsent>
</prevsection>
<citsent citstr=" N04-1042 ">
furthermore, crfs have been used successfully in information extraction (peng and mccallum, 2004), <papid> N04-1042 </papid>named entity recognition (li and mccallum, 2003; mccallum and li, 2003) <papid> W03-0430 </papid>and sentence parsing (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>in this section well explain to some detail how to derive the parameters ? = {k}, given the training data.
</nextsent>
<nextsent>the problem can be considered as constrained optimization problem, where we have to find set of parameters which maximizes the log likelihood of the conditional distribution (mccal lum, 2003).
</nextsent>
<nextsent>we are confronted with the problem of efficiently calculating the expectation of each feature function with respect to the crf model distribution for every observation sequence in the training data.
</nextsent>
<nextsent>formally, we are given set of training examples = { x(i),y(i) }n i=1 where each x(i) = { x(i)1 , (i) 2 , ..., (i) } is sequence of inputs and y(i) = { y(i)1 , (i) 2 , ..., (i) }is sequence of the desired labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2015">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>given that in information extraction tasks, we often lack an annotated training set that covers all possible extraction patterns, this is valuable asset.
</prevsent>
<prevsent>lafferty et al (lafferty et al, 2001) have shown that crfs outperform both memm and hmm on synthetic data and on part-of-speech taggingtask.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
furthermore, crfs have been used successfully in information extraction (peng and mccallum, 2004), <papid> N04-1042 </papid>named entity recognition (li and mccallum, 2003; mccallum and li, 2003) <papid> W03-0430 </papid>and sentence parsing (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>in this section well explain to some detail how to derive the parameters ? = {k}, given the training data.
</nextsent>
<nextsent>the problem can be considered as constrained optimization problem, where we have to find set of parameters which maximizes the log likelihood of the conditional distribution (mccal lum, 2003).
</nextsent>
<nextsent>we are confronted with the problem of efficiently calculating the expectation of each feature function with respect to the crf model distribution for every observation sequence in the training data.
</nextsent>
<nextsent>formally, we are given set of training examples = { x(i),y(i) }n i=1 where each x(i) = { x(i)1 , (i) 2 , ..., (i) } is sequence of inputs and y(i) = { y(i)1 , (i) 2 , ..., (i) }is sequence of the desired labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2016">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>given that in information extraction tasks, we often lack an annotated training set that covers all possible extraction patterns, this is valuable asset.
</prevsent>
<prevsent>lafferty et al (lafferty et al, 2001) have shown that crfs outperform both memm and hmm on synthetic data and on part-of-speech taggingtask.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
furthermore, crfs have been used successfully in information extraction (peng and mccallum, 2004), <papid> N04-1042 </papid>named entity recognition (li and mccallum, 2003; mccallum and li, 2003) <papid> W03-0430 </papid>and sentence parsing (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>in this section well explain to some detail how to derive the parameters ? = {k}, given the training data.
</nextsent>
<nextsent>the problem can be considered as constrained optimization problem, where we have to find set of parameters which maximizes the log likelihood of the conditional distribution (mccal lum, 2003).
</nextsent>
<nextsent>we are confronted with the problem of efficiently calculating the expectation of each feature function with respect to the crf model distribution for every observation sequence in the training data.
</nextsent>
<nextsent>formally, we are given set of training examples = { x(i),y(i) }n i=1 where each x(i) = { x(i)1 , (i) 2 , ..., (i) } is sequence of inputs and y(i) = { y(i)1 , (i) 2 , ..., (i) }is sequence of the desired labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2017">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>note that fig 7 gives the error rate on the training data but this 38can differ considerable from the error rate on unseen data.after these tests on small section of the semcor corpus, we trained crf using hierarchical feature selection on 7/8 of the full corpus.we trained for 23 iterations, which took approximately 102 hours.
</prevsent>
<prevsent>testing the model on there maining 1/8 of the corpus resulted in an accuracy of 77.82%.
</prevsent>
</prevsection>
<citsent citstr=" W04-0837 ">
as reported in (mccarthy et al, 2004), <papid> W04-0837 </papid>baseline approach that ignors context but simply assigns the most likely sense to given word obtains accuracy of 67%.</citsent>
<aftsection>
<nextsent>we did not have the possibility to compare the accuracy of this model with standard crf, since as already stated, training such crf takes im practically long, but we can compare our systems with existing wsd-systems.
</nextsent>
<nextsent>mihalcea and moldovan (mihalcea and moldovan, 1999) <papid> P99-1020 </papid>use the semantic density between words to determine the word sense.</nextsent>
<nextsent>they achieve an accuracy of 86.5% (testing on the first two tagged files of the semcor corpus).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2018">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>as reported in (mccarthy et al, 2004), <papid> W04-0837 </papid>baseline approach that ignors context but simply assigns the most likely sense to given word obtains accuracy of 67%.</prevsent>
<prevsent>we did not have the possibility to compare the accuracy of this model with standard crf, since as already stated, training such crf takes im practically long, but we can compare our systems with existing wsd-systems.</prevsent>
</prevsection>
<citsent citstr=" P99-1020 ">
mihalcea and moldovan (mihalcea and moldovan, 1999) <papid> P99-1020 </papid>use the semantic density between words to determine the word sense.</citsent>
<aftsection>
<nextsent>they achieve an accuracy of 86.5% (testing on the first two tagged files of the semcor corpus).
</nextsent>
<nextsent>wilks and stevenson (wilks and stevenson, 1998) <papid> P98-2228 </papid>use combination of knowledge sources and achieve an accuracy of 92%3.</nextsent>
<nextsent>note that both these methods use additional knowledge apart from the wordnet hierarchy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2019">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>mihalcea and moldovan (mihalcea and moldovan, 1999) <papid> P99-1020 </papid>use the semantic density between words to determine the word sense.</prevsent>
<prevsent>they achieve an accuracy of 86.5% (testing on the first two tagged files of the semcor corpus).</prevsent>
</prevsection>
<citsent citstr=" P98-2228 ">
wilks and stevenson (wilks and stevenson, 1998) <papid> P98-2228 </papid>use combination of knowledge sources and achieve an accuracy of 92%3.</citsent>
<aftsection>
<nextsent>note that both these methods use additional knowledge apart from the wordnet hierarchy.
</nextsent>
<nextsent>the sentences in the training and testing sets were already (perfectly) pos-tagged and nounchunked, and that in real-life situation additional preprocessing by pos-tagger (such as thelt-pos-tagger4) and noun chunker (such as described in (ramshaw and marcus, 1995)) <papid> W95-0107 </papid>which will introduce additional errors.</nextsent>
<nextsent>in this section well discuss some of the work we plan to do in the future.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2020">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>wilks and stevenson (wilks and stevenson, 1998) <papid> P98-2228 </papid>use combination of knowledge sources and achieve an accuracy of 92%3.</prevsent>
<prevsent>note that both these methods use additional knowledge apart from the wordnet hierarchy.</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
the sentences in the training and testing sets were already (perfectly) pos-tagged and nounchunked, and that in real-life situation additional preprocessing by pos-tagger (such as thelt-pos-tagger4) and noun chunker (such as described in (ramshaw and marcus, 1995)) <papid> W95-0107 </papid>which will introduce additional errors.</citsent>
<aftsection>
<nextsent>in this section well discuss some of the work we plan to do in the future.
</nextsent>
<nextsent>first of all we wish to evaluate our algorithm on standard test sets, such as the data of the senseval conference5 , which tests performance on word sense disambiguation, and the data of the conll 2003 shared task6, on named entity recognition.
</nextsent>
<nextsent>an important weakness of our algorithm is the fact that, to label sentence, we have to traverse the hierarchy tree and choose the correct synsets at every level.
</nextsent>
<nextsent>an error at certain level can not be recovered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2021">
<title id=" W06-0505.xml">efficient hierarchical entity classifier using conditional random fields </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>this can become problematic as wordnet has no hypernym/hyponym relation (or equivalent) for the synsets of adjectives and adverbs.
</prevsent>
<prevsent>wordnet has an equivalent relation for verbs (hypernym/troponym), but this structures the verb synsets in big number of loosely structured trees, which is less suitable for the described method.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
verbnet (kipper et al, 2000) seems amore promising resource to use when classifying verbs, and we will also investigate the useof other lexical databases, such as thought treasure (mueller, 1998), cyc (lenat, 1995), open mind commonsense (stork, 1999) and framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>acknowledgments the work reported in this paper was supported by the eu-ist project class (cognitive-levelannotation using latent statistical structure, ist 027978).
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2022">
<title id=" W06-0506.xml">taxonomy learning using term specificity and similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however their wide usage is still hindered by time-consuming, cost-ineffective building processes.
</prevsent>
<prevsent>the main paradigms of taxonomy learning are on the one hand pattern based approaches and on the other hand distributional hypothesis based approaches.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the former is approaches based on matching lexico-syntactic patterns which convey taxonomic relations in corpus (hearst, 1992; <papid> C92-2082 </papid>iwanska et al, 2000), and the latter is statistical approaches based on the distribution of context in corpus (cimiano et al, 2005; yamamoto et al, 2005; sanderson &amp; croft, 1999).</citsent>
<aftsection>
<nextsent>the former features high precision and low recall compared to the latter.
</nextsent>
<nextsent>the quality of learned relations is higher than those of statistical approaches, while the patterns are rarely applied in real corpus.
</nextsent>
<nextsent>it is also difficult to improve performance of pattern based approaches because they are simple and clear.
</nextsent>
<nextsent>so, many researches have been focused on raising precision of statistical approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2023">
<title id=" W06-0506.xml">taxonomy learning using term specificity and similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>firstly, we analyze characteristics of features for taxonomy learning in view of term specificity and term similarity to show that the features embed characteristics of specificity and similarity, and finally apply optimal features to our method.
</prevsent>
<prevsent>additionally we tested inside information of terms to measure term specificity and similarity.
</prevsent>
</prevsection>
<citsent citstr=" C00-1022 ">
as multiword terms cover the larger part of technical terms, lexical components are featuring information representing semantics of terms (cerbah, 2000).<papid> C00-1022 </papid></citsent>
<aftsection>
<nextsent>the remainder of this paper is organized follows.
</nextsent>
<nextsent>characteristics of term specificity are described in section 2, while term similarity and its features are addressed in section 3.
</nextsent>
<nextsent>our taxonomy learning method is discussed in section 4.
</nextsent>
<nextsent>experiment and evaluation are discussed in section 5, and finally, conclusions are drawn in section 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2024">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> compositionality of light verbs.  </section>
<citcontext>
<prevsection>
<prevsent>n  pr   lv  pr    log f   lv
</prevsent>
<prevsent>n    lv     where is an estimate of the total number of verb and object noun pairs in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
1pmi is subject to overestimation for low frequency items(dunning, 1993), <papid> J93-1003 </papid>thus we require minimum frequency of occurrence for the expressions under study.</citsent>
<aftsection>
<nextsent>40pspos represents the set of syntactic patterns preferred by less-compositional (more figurative) lvcs (e.g., as in (3a)), and psneg represents less preferred patterns (e.g., those in (3be)).
</nextsent>
<nextsent>typically, these patterns most affect the expression of the complement noun.
</nextsent>
<nextsent>thus, to measure the strength of association between an expression and set of patterns, we use the pmi of the light verb, and the complement noun appearing in all of the patterns in the set, as in: assoc   lv;n
</nextsent>
<nextsent>pspos   pmi   lv;n
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2025">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> compositionality of light verbs.  </section>
<citcontext>
<prevsection>
<prevsent>to account for resulting errors, we compare the two confidence intervals,
</prevsent>
<prevsent>assoc pos  assoc pos  and
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
assoc neg  assoc neg  , as in lin (1999).<papid> P99-1041 </papid></citsent>
<aftsection>
<nextsent>we takethe minimum distance between the two as conservative estimate of the true difference: diff   assoc   lv;n
</nextsent>
<nextsent>pspos
</nextsent>
<nextsent>assoc   lv;n
</nextsent>
<nextsent>psneg    assoc pos  asso cpos     assoc neg  assoc neg  taking the difference between confidence intervals lessens the effect of differences that are not statistically significant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2026">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> acceptability across semantic classes.  </section>
<citcontext>
<prevsection>
<prevsent>our hypothesis is that semantically similar lvcsi.e., those formed from an lv plus any ofa set of semantically similar pns distinguish figurative sub sense of the lv.
</prevsent>
<prevsent>in the long run, if this is true, it could be exploited by using class information to extend our knowledge of acceptable lvcs and their likely meaning (cf.
</prevsent>
</prevsection>
<citsent citstr=" W03-1808 ">
such an approach to verb particle constructions by villavicencio, 2003).<papid> W03-1808 </papid></citsent>
<aftsection>
<nextsent>as steps to achieving this long-term goal, we must first devise an acceptability measure which determines, forgiven lv, which pns it successfully combines with.
</nextsent>
<nextsent>we can even use this measure to provide evidence on whether the hypothesized class based behaviour holds, by seeing if the measure exhibits differing behaviour across semantic classes of potential complements.
</nextsent>
<nextsent>3.2 statistical measure of acceptability we develop probability formula that captures the likelihood of given lv and pn forming an accept able lvc.
</nextsent>
<nextsent>the probability depends on both the lv and the pn, and on these elements being used in an lvc: acpt   lv
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2028">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>experimental expressionsi.e., potential lvcs using give and takeare drawn from two sources.
</prevsent>
<prevsent>the development and test data used in experiments of compositionality (bncd and bnct, respectively)are randomly extracted from the bnc (bnc reference guide, 2000), yielding expressions covering wide range of figurative usages of give andtake, with complements from different semantic categories.
</prevsent>
</prevsection>
<citsent citstr=" W04-0401 ">
in contrast, in experiments that involve acceptability, we need figurative usages of the same type?, i.e., with semantically similar complement nouns, to further examine our hypothesis on the class-based behaviour of light verb combinations.since in these lvcs the complement is predica tive noun instem form identical to verb, we form development and test expressions by combining give or take with verbs from selected semantic classes of levin (1993), taken from stevenson et al (2004).<papid> W04-0401 </papid></citsent>
<aftsection>
<nextsent>4.3 corpora.
</nextsent>
<nextsent>we gather estimates for our comp measure from the bnc, processed using the collins parser (collins, 1999) and tgrep2 (rohde, 2004).
</nextsent>
<nextsent>because somelvcs can be rare in classical corpora, our acpt estimates are drawn from the world wide web (thesubsection indexed by altavista).
</nextsent>
<nextsent>in our comparison of the two measures, we use web data for both, using simplified version of comp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2037">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> discussion and concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>the results confirm that compd correlates better than does acpt with compositionalityratings, while acpt correlates best with acceptability ratings.
</prevsent>
<prevsent>recently, there has been increasing awareness of theneed for appropriate handling of multiword expressions (mwes) in nlp tasks (sag et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of mwes, such as compound nouns or verb particle constructions (vpcs) (e.g., lin, 1999; <papid> P99-1041 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>villavicencio, 2003).<papid> W03-1808 </papid></citsent>
<aftsection>
<nextsent>previous research on lvcs, on the other hand, has primarily focused on their automatic extraction (e.g., grefenstette and teufel 1995; dras and johnson 1996; moiron 2004; though see stevenson et al 2004).<papid> W04-0401 </papid>like most previous studies that focus on semantic properties of mwes, we are interested in the issue of compositionality.</nextsent>
<nextsent>our comp measure aims to identify continuum along which light verb contributes to the semantics of an expression.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2043">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> discussion and concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>in this way, our work combines aspects of earlier work on vpc semantics.
</prevsent>
<prevsent>mccarthy et al (2003) <papid> W03-1810 </papid>determine continuum of compositionality of vpcs, but do not distinguish the contribution of the individual compo nents.</prevsent>
</prevsection>
<citsent citstr=" W03-1809 ">
bannard et al (2003), <papid> W03-1809 </papid>on the other hand, look at the separate contribution of the verb and particle,but assume that binary decision on the composi tionality of each is sufficient.</citsent>
<aftsection>
<nextsent>previous studies determine compositionality by looking at the degree of distributional similarity between an expression and its component words (e.g.,mccarthy et al, 2003; <papid> W03-1810 </papid>bannard et al, 2003; <papid> W03-1809 </papid>baldwin et al, 2003).<papid> W03-1812 </papid></nextsent>
<nextsent>because light verbs are highly polysemous and frequently used in lvcs, such an approach is not appropriate for determining their contribution to the semantics of an expression.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2047">
<title id=" W05-1005.xml">automatically distinguishing literal and figurative usages of highly polysemous verbs </title>
<section> discussion and concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>mccarthy et al (2003) <papid> W03-1810 </papid>determine continuum of compositionality of vpcs, but do not distinguish the contribution of the individual compo nents.</prevsent>
<prevsent>bannard et al (2003), <papid> W03-1809 </papid>on the other hand, look at the separate contribution of the verb and particle,but assume that binary decision on the composi tionality of each is sufficient.</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
previous studies determine compositionality by looking at the degree of distributional similarity between an expression and its component words (e.g.,mccarthy et al, 2003; <papid> W03-1810 </papid>bannard et al, 2003; <papid> W03-1809 </papid>baldwin et al, 2003).<papid> W03-1812 </papid></citsent>
<aftsection>
<nextsent>because light verbs are highly polysemous and frequently used in lvcs, such an approach is not appropriate for determining their contribution to the semantics of an expression.
</nextsent>
<nextsent>we instead examine the degree to which light verb usageis similar?
</nextsent>
<nextsent>to the prototypical lvc, through statistical comparison of its behaviour within different syntactic patterns.
</nextsent>
<nextsent>syntactic flexibility and semantic compositionality are known to be strongly correlated for many types of mwes (nunberg et al, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2055">
<title id=" W05-0814.xml">isis participation in the romanian english alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also report on new alignment model and anew training algorithm based on alternating maximization of likelihood with minimization of error rate.
</prevsent>
<prevsent>isi participated in the wpt05 romanian-english word alignment task.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the system used for baseline experiments is two runs of ibm model 4 (brown etal., 1993) <papid> J93-2003 </papid>in the giza++ (och and ney, 2003) <papid> J03-1002 </papid>implementation, which includes smoothing extensions to model 4.</citsent>
<aftsection>
<nextsent>for symmetrization, we found that och and neys refined?
</nextsent>
<nextsent>technique described in (och and ney, 2003) <papid> J03-1002 </papid>produced the best aer for this dataset under all experimental conditions.we experimented with statistical model for inducing stemmer cross-lingually, but found that thebest performance was obtained by simply lower casing both the english and romanian text andre moving all but the first four characters of each word.</nextsent>
<nextsent>we also tried new model and new training criterion based on alternating the maximization of likelihood and minimization of the alignment error rate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2056">
<title id=" W05-0814.xml">isis participation in the romanian english alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also report on new alignment model and anew training algorithm based on alternating maximization of likelihood with minimization of error rate.
</prevsent>
<prevsent>isi participated in the wpt05 romanian-english word alignment task.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the system used for baseline experiments is two runs of ibm model 4 (brown etal., 1993) <papid> J93-2003 </papid>in the giza++ (och and ney, 2003) <papid> J03-1002 </papid>implementation, which includes smoothing extensions to model 4.</citsent>
<aftsection>
<nextsent>for symmetrization, we found that och and neys refined?
</nextsent>
<nextsent>technique described in (och and ney, 2003) <papid> J03-1002 </papid>produced the best aer for this dataset under all experimental conditions.we experimented with statistical model for inducing stemmer cross-lingually, but found that thebest performance was obtained by simply lower casing both the english and romanian text andre moving all but the first four characters of each word.</nextsent>
<nextsent>we also tried new model and new training criterion based on alternating the maximization of likelihood and minimization of the alignment error rate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2063">
<title id=" W05-0814.xml">isis participation in the romanian english alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also tried new model and new training criterion based on alternating the maximization of likelihood and minimization of the alignment error rate.
</prevsent>
<prevsent>for these experiments, we have implemented an alignment package for ibm model 4 using hill climbing search and viterbi training as described in (brown et al, 1993), <papid> J93-2003 </papid>and extended this to use new submodels.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the starting point is the final alignment generated using giza++s implementation of ibm model 1 and the aachen hmm model (vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>paper organization: section 2 is on the baseline, section 3 discusses vocabulary reduction, section 4introduces our new model and training method, section 5 describes experiments, section 6 concludes.we use the following notation: refers to an english sentence composed of english words labeled ei.
</nextsent>
<nextsent>f refers to romanian sentence composed of romanian words labeled fj . is an alignment of to . we use the term viterbi alignment?
</nextsent>
<nextsent>to denote the most probable alignment we can find, rather than the true viterbi alignment.
</nextsent>
<nextsent>to train our systems, model 4 was trained two times, first using romanian as the source language and then using english as the source language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2068">
<title id=" W05-0814.xml">isis participation in the romanian english alignment task </title>
<section> vocabulary size reduction.  </section>
<citcontext>
<prevsection>
<prevsent>given the small amount of training data,we decided that vocabulary size reduction was desirable.
</prevsent>
<prevsent>as baseline for vocabulary reduction, we tried reducing words to prefixes of varying sizes for both english and romanian after lower casing the corpora.
</prevsent>
</prevsection>
<citsent citstr=" P03-1050 ">
we also tried porter stemming (porter, 1997) for english.(rogati et al, 2003) <papid> P03-1050 </papid>extended model 1 with an additional hidden variable to represent the split point sin arabic between the prefix, the stem and the suffix to generate stemming for use in cross-lingual information retrieval.</citsent>
<aftsection>
<nextsent>as in (rogati et al, 2003), <papid> P03-1050 </papid>we can find the most probable stemming given the model, apply this stemming, and retrain our word alignment system.</nextsent>
<nextsent>however, we can also use the modified model directly to find the best word alignment without converting the text to its stemmed form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2074">
<title id=" W05-0814.xml">isis participation in the romanian english alignment task </title>
<section> new model and training algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>given sequence of alignments we can calculate an error function, e(a).
</prevsent>
<prevsent>for these experiments average sentence aer was used.we wish to minimize this error function, so we select ? accordingly: argmin ? ?
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
a? e(a?)?(a?, (argmax p?(a, |e))) (4) maximizing performance for all of the weights at once is not computationally tractable, but (och, 2003) <papid> P03-1021 </papid>has described an efficient one-dimensional search for similar problem.</citsent>
<aftsection>
<nextsent>we search over eachm (holding the others constant) using this technique to find the best to update and the best value to update it to.
</nextsent>
<nextsent>we repeat the process until no further gain can be found.
</nextsent>
<nextsent>our new training method is: repeat?
</nextsent>
<nextsent>start with sub models and lambda from previous iteration?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2076">
<title id=" W05-0814.xml">isis participation in the romanian english alignment task </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the discriminative training regimen is otherwise similar to (och, 2003).<papid> P03-1021 </papid></prevsent>
<prevsent>table 2 provides comparison of our baseline systems using the refined?</prevsent>
</prevsection>
<citsent citstr=" W03-0305 ">
symmetrization metric with the best limited resources track system from wpt03 (dejean et al, 2003) <papid> W03-0305 </papid>on the 2003 test set.</citsent>
<aftsection>
<nextsent>the best results are obtained by stemming both english and romanian words to the first four letters, as described in section 2.table 3 provides details on our shared task submission.
</nextsent>
<nextsent>run1 is the word-based baseline system.
</nextsent>
<nextsent>run2 is the stem-based baseline system.
</nextsent>
<nextsent>run4 uses only the first 6 sub models, while run5 uses all 11 submodels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2077">
<title id=" W04-3103.xml">the language of bioscience facts speculations and statements in between </title>
<section> manual annotation experiment.  </section>
<citcontext>
<prevsection>
<prevsent>these include the treatment of burns, stomach ulcers and ailments, and various skin diseases.
</prevsent>
<prevsent>there has been surge of interest in cur cumin over the last decade.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
each abstract set was prepared for annotation as follows: the order of the abstracts was randomized and the abstracts were broken into sentences using mxterminator (reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>the following people performed the annotations: padmini srinivasan, who has analyzed crohns and turmeric documents for separate knowledge discover research task, xinying qiu, who is completely new to all three topics, marc light, who has some experience with gene regulation texts (e.g.,(light et al, 2003)), vladimir leontiev, who is research scientist in an anatomy and cell biology department.
</nextsent>
<nextsent>it certainly would have been preferable to have four experts on the topics do the annotation but this was not possible.the following manual annotations were per formed: a. 63 gene regulation abstracts (all sentences) by both leontiev and light,b. 47 gene regulation additional abstracts (all sen tences) by light, c. 100 crohns abstracts (last 2 sentences) by both srinivasan and qiu,d. 400 crohns abstracts additional (last 2 sen tences) by qiu,e. 100 turmeric abstracts (all sentences) by srini vasan,f. 400 turmeric additional abstracts (last 2 sen tences) by srinivasan.
</nextsent>
<nextsent>the 63 double annotated gene regulation abstracts(set a) contained 547 sentences.
</nextsent>
<nextsent>the additional abstracts (set b) marked by light1 contained 344 sentences summing to 891 sentences of gene regulation abstracts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2078">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to alleviate this problem, one common approach from machine learning is loopy belief propagation (pearl, 1988).
</prevsent>
<prevsent>another solution (which is popular in nlp) is to split the computation into two phases: in the first phase, use some compatible objective function ? to produce k-best list (the top candidates under ?), which serves as an approximation to the full set.then, in the second phase, optimize over all the analyses in the k-best list.
</prevsent>
</prevsection>
<citsent citstr=" N04-1023 ">
a typical example is discriminative reranking on k-best lists from generative module, such as (collins, 2000) for parsing and (shen et al, 2004) <papid> N04-1023 </papid>for translation, where the reranking model has non local features that cannot be computed during parsing proper.another example is minimum-bayes-risk decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>goodman, 1998),where, assuming ? defines probability distribution over all candidates, one seeks the candidate with the highest expected score according to an arbitrary metric (e.g., parse valor bleu); since in general the metric will not be compatible with the parsing algorithm, the k-best lists canbe used to approximate the full distribution ?.</citsent>
<aftsection>
<nextsent>a similar situation occurs when the parser can produce multiple derivations that are regarded as equivalent (e.g., multiple lexicalized parse trees corresponding to the same unlexi calized parse tree); if we want the maximum posteriori parse, we have to sum over equivalent derivations.
</nextsent>
<nextsent>again,the equivalence relation will in general not be compatible with the parsing algorithm, so the k-best lists can be used to approximate ?, as in data oriented parsing (bod, 2000) <papid> C00-1011 </papid>and in speech recognition (mohri and riley, 2002).</nextsent>
<nextsent>another instance of this k-best approach is cascadedoptimization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2079">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to alleviate this problem, one common approach from machine learning is loopy belief propagation (pearl, 1988).
</prevsent>
<prevsent>another solution (which is popular in nlp) is to split the computation into two phases: in the first phase, use some compatible objective function ? to produce k-best list (the top candidates under ?), which serves as an approximation to the full set.then, in the second phase, optimize over all the analyses in the k-best list.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
a typical example is discriminative reranking on k-best lists from generative module, such as (collins, 2000) for parsing and (shen et al, 2004) <papid> N04-1023 </papid>for translation, where the reranking model has non local features that cannot be computed during parsing proper.another example is minimum-bayes-risk decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>goodman, 1998),where, assuming ? defines probability distribution over all candidates, one seeks the candidate with the highest expected score according to an arbitrary metric (e.g., parse valor bleu); since in general the metric will not be compatible with the parsing algorithm, the k-best lists canbe used to approximate the full distribution ?.</citsent>
<aftsection>
<nextsent>a similar situation occurs when the parser can produce multiple derivations that are regarded as equivalent (e.g., multiple lexicalized parse trees corresponding to the same unlexi calized parse tree); if we want the maximum posteriori parse, we have to sum over equivalent derivations.
</nextsent>
<nextsent>again,the equivalence relation will in general not be compatible with the parsing algorithm, so the k-best lists can be used to approximate ?, as in data oriented parsing (bod, 2000) <papid> C00-1011 </papid>and in speech recognition (mohri and riley, 2002).</nextsent>
<nextsent>another instance of this k-best approach is cascadedoptimization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2080">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a typical example is discriminative reranking on k-best lists from generative module, such as (collins, 2000) for parsing and (shen et al, 2004) <papid> N04-1023 </papid>for translation, where the reranking model has non local features that cannot be computed during parsing proper.another example is minimum-bayes-risk decoding (kumar and byrne, 2004; <papid> N04-1022 </papid>goodman, 1998),where, assuming ? defines probability distribution over all candidates, one seeks the candidate with the highest expected score according to an arbitrary metric (e.g., parse valor bleu); since in general the metric will not be compatible with the parsing algorithm, the k-best lists canbe used to approximate the full distribution ?.</prevsent>
<prevsent>a similar situation occurs when the parser can produce multiple derivations that are regarded as equivalent (e.g., multiple lexicalized parse trees corresponding to the same unlexi calized parse tree); if we want the maximum posteriori parse, we have to sum over equivalent derivations.</prevsent>
</prevsection>
<citsent citstr=" C00-1011 ">
again,the equivalence relation will in general not be compatible with the parsing algorithm, so the k-best lists can be used to approximate ?, as in data oriented parsing (bod, 2000) <papid> C00-1011 </papid>and in speech recognition (mohri and riley, 2002).</citsent>
<aftsection>
<nextsent>another instance of this k-best approach is cascadedoptimization.
</nextsent>
<nextsent>nlp systems are often cascades of modules, where we want to optimize the modules?
</nextsent>
<nextsent>objective functions jointly.
</nextsent>
<nextsent>however, often module is incompatible with the packed representation of the previous module due to factors like non-local dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2081">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>objective functions jointly.
</prevsent>
<prevsent>however, often module is incompatible with the packed representation of the previous module due to factors like non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
so we might want to postpone some disambiguation by propagating k-best lists to subsequent phases, as in joint parsing and semantic role labeling (gildea and jurafsky, 2002; <papid> J02-3001 </papid>sutton and mccallum, 2005), <papid> W05-0636 </papid>information extraction and coreference resolution (wellner et al, 2004), and formal semantics of tag (joshi and vijay-shanker, 1999).moreover, much recent work on discriminative training uses k-best lists; they are sometimes used to approximate the normalization constant or partition function (which would otherwise be intractable), or to train model by optimizing some metric incompatible with the packed representation.</citsent>
<aftsection>
<nextsent>for example, och (2003) <papid> P03-1021 </papid>show show to train log-linear translation model not by maximizing the likelihood of training data, but maximizing the bleu score (among other metrics) of the model on 53the data.</nextsent>
<nextsent>similarly, chiang (2005) <papid> P05-1033 </papid>uses the k-best parsing algorithm described below in cfg-based log-linear translation model in order to learn feature weights which maximize bleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2082">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>objective functions jointly.
</prevsent>
<prevsent>however, often module is incompatible with the packed representation of the previous module due to factors like non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" W05-0636 ">
so we might want to postpone some disambiguation by propagating k-best lists to subsequent phases, as in joint parsing and semantic role labeling (gildea and jurafsky, 2002; <papid> J02-3001 </papid>sutton and mccallum, 2005), <papid> W05-0636 </papid>information extraction and coreference resolution (wellner et al, 2004), and formal semantics of tag (joshi and vijay-shanker, 1999).moreover, much recent work on discriminative training uses k-best lists; they are sometimes used to approximate the normalization constant or partition function (which would otherwise be intractable), or to train model by optimizing some metric incompatible with the packed representation.</citsent>
<aftsection>
<nextsent>for example, och (2003) <papid> P03-1021 </papid>show show to train log-linear translation model not by maximizing the likelihood of training data, but maximizing the bleu score (among other metrics) of the model on 53the data.</nextsent>
<nextsent>similarly, chiang (2005) <papid> P05-1033 </papid>uses the k-best parsing algorithm described below in cfg-based log-linear translation model in order to learn feature weights which maximize bleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2083">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, often module is incompatible with the packed representation of the previous module due to factors like non-local dependencies.
</prevsent>
<prevsent>so we might want to postpone some disambiguation by propagating k-best lists to subsequent phases, as in joint parsing and semantic role labeling (gildea and jurafsky, 2002; <papid> J02-3001 </papid>sutton and mccallum, 2005), <papid> W05-0636 </papid>information extraction and coreference resolution (wellner et al, 2004), and formal semantics of tag (joshi and vijay-shanker, 1999).moreover, much recent work on discriminative training uses k-best lists; they are sometimes used to approximate the normalization constant or partition function (which would otherwise be intractable), or to train model by optimizing some metric incompatible with the packed representation.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for example, och (2003) <papid> P03-1021 </papid>show show to train log-linear translation model not by maximizing the likelihood of training data, but maximizing the bleu score (among other metrics) of the model on 53the data.</citsent>
<aftsection>
<nextsent>similarly, chiang (2005) <papid> P05-1033 </papid>uses the k-best parsing algorithm described below in cfg-based log-linear translation model in order to learn feature weights which maximize bleu.</nextsent>
<nextsent>for algorithms whose packed representations are graphs, such as hidden markov models and other finite state methods, ratnaparkhis mxparse parser (ratnaparkhi, 1997), <papid> W97-0301 </papid>and many stack-based machine translation decoders (brown et al, 1995; och and ney, 2004), <papid> J04-4002 </papid>the k-best paths problem is well-studied in both pure algorithmic context (see (eppstein, 2001) and (branderand sinclair, 1995) for surveys) and nlp/speech community (mohri, 2002; mohri and riley, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2084">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so we might want to postpone some disambiguation by propagating k-best lists to subsequent phases, as in joint parsing and semantic role labeling (gildea and jurafsky, 2002; <papid> J02-3001 </papid>sutton and mccallum, 2005), <papid> W05-0636 </papid>information extraction and coreference resolution (wellner et al, 2004), and formal semantics of tag (joshi and vijay-shanker, 1999).moreover, much recent work on discriminative training uses k-best lists; they are sometimes used to approximate the normalization constant or partition function (which would otherwise be intractable), or to train model by optimizing some metric incompatible with the packed representation.</prevsent>
<prevsent>for example, och (2003) <papid> P03-1021 </papid>show show to train log-linear translation model not by maximizing the likelihood of training data, but maximizing the bleu score (among other metrics) of the model on 53the data.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
similarly, chiang (2005) <papid> P05-1033 </papid>uses the k-best parsing algorithm described below in cfg-based log-linear translation model in order to learn feature weights which maximize bleu.</citsent>
<aftsection>
<nextsent>for algorithms whose packed representations are graphs, such as hidden markov models and other finite state methods, ratnaparkhis mxparse parser (ratnaparkhi, 1997), <papid> W97-0301 </papid>and many stack-based machine translation decoders (brown et al, 1995; och and ney, 2004), <papid> J04-4002 </papid>the k-best paths problem is well-studied in both pure algorithmic context (see (eppstein, 2001) and (branderand sinclair, 1995) for surveys) and nlp/speech community (mohri, 2002; mohri and riley, 2002).</nextsent>
<nextsent>this paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (gallo et al, 1993; klein and manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parser sand parsing-based mt decoders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2085">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, och (2003) <papid> P03-1021 </papid>show show to train log-linear translation model not by maximizing the likelihood of training data, but maximizing the bleu score (among other metrics) of the model on 53the data.</prevsent>
<prevsent>similarly, chiang (2005) <papid> P05-1033 </papid>uses the k-best parsing algorithm described below in cfg-based log-linear translation model in order to learn feature weights which maximize bleu.</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
for algorithms whose packed representations are graphs, such as hidden markov models and other finite state methods, ratnaparkhis mxparse parser (ratnaparkhi, 1997), <papid> W97-0301 </papid>and many stack-based machine translation decoders (brown et al, 1995; och and ney, 2004), <papid> J04-4002 </papid>the k-best paths problem is well-studied in both pure algorithmic context (see (eppstein, 2001) and (branderand sinclair, 1995) for surveys) and nlp/speech community (mohri, 2002; mohri and riley, 2002).</citsent>
<aftsection>
<nextsent>this paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (gallo et al, 1993; klein and manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parser sand parsing-based mt decoders.
</nextsent>
<nextsent>any algorithm express ible as weighted deductive system (shieber et al, 1995; goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003) <papid> J03-1006 </papid>falls into this class.</nextsent>
<nextsent>inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2086">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, och (2003) <papid> P03-1021 </papid>show show to train log-linear translation model not by maximizing the likelihood of training data, but maximizing the bleu score (among other metrics) of the model on 53the data.</prevsent>
<prevsent>similarly, chiang (2005) <papid> P05-1033 </papid>uses the k-best parsing algorithm described below in cfg-based log-linear translation model in order to learn feature weights which maximize bleu.</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
for algorithms whose packed representations are graphs, such as hidden markov models and other finite state methods, ratnaparkhis mxparse parser (ratnaparkhi, 1997), <papid> W97-0301 </papid>and many stack-based machine translation decoders (brown et al, 1995; och and ney, 2004), <papid> J04-4002 </papid>the k-best paths problem is well-studied in both pure algorithmic context (see (eppstein, 2001) and (branderand sinclair, 1995) for surveys) and nlp/speech community (mohri, 2002; mohri and riley, 2002).</citsent>
<aftsection>
<nextsent>this paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (gallo et al, 1993; klein and manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parser sand parsing-based mt decoders.
</nextsent>
<nextsent>any algorithm express ible as weighted deductive system (shieber et al, 1995; goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003) <papid> J03-1006 </papid>falls into this class.</nextsent>
<nextsent>inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2087">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for algorithms whose packed representations are graphs, such as hidden markov models and other finite state methods, ratnaparkhis mxparse parser (ratnaparkhi, 1997), <papid> W97-0301 </papid>and many stack-based machine translation decoders (brown et al, 1995; och and ney, 2004), <papid> J04-4002 </papid>the k-best paths problem is well-studied in both pure algorithmic context (see (eppstein, 2001) and (branderand sinclair, 1995) for surveys) and nlp/speech community (mohri, 2002; mohri and riley, 2002).</prevsent>
<prevsent>this paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (gallo et al, 1993; klein and manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parser sand parsing-based mt decoders.</prevsent>
</prevsection>
<citsent citstr=" J99-4004 ">
any algorithm express ible as weighted deductive system (shieber et al, 1995; goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003) <papid> J03-1006 </papid>falls into this class.</citsent>
<aftsection>
<nextsent>inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</nextsent>
<nextsent>model 2 (collins, 2003), <papid> J03-4003 </papid>and to synchronous cfg based machine translation system (chiang, 2005).<papid> P05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2089">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for algorithms whose packed representations are graphs, such as hidden markov models and other finite state methods, ratnaparkhis mxparse parser (ratnaparkhi, 1997), <papid> W97-0301 </papid>and many stack-based machine translation decoders (brown et al, 1995; och and ney, 2004), <papid> J04-4002 </papid>the k-best paths problem is well-studied in both pure algorithmic context (see (eppstein, 2001) and (branderand sinclair, 1995) for surveys) and nlp/speech community (mohri, 2002; mohri and riley, 2002).</prevsent>
<prevsent>this paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (gallo et al, 1993; klein and manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parser sand parsing-based mt decoders.</prevsent>
</prevsection>
<citsent citstr=" J03-1006 ">
any algorithm express ible as weighted deductive system (shieber et al, 1995; goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003) <papid> J03-1006 </papid>falls into this class.</citsent>
<aftsection>
<nextsent>inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</nextsent>
<nextsent>model 2 (collins, 2003), <papid> J03-4003 </papid>and to synchronous cfg based machine translation system (chiang, 2005).<papid> P05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2090">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (gallo et al, 1993; klein and manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parser sand parsing-based mt decoders.
</prevsent>
<prevsent>any algorithm express ible as weighted deductive system (shieber et al, 1995; goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003) <papid> J03-1006 </papid>falls into this class.</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</citsent>
<aftsection>
<nextsent>model 2 (collins, 2003), <papid> J03-4003 </papid>and to synchronous cfg based machine translation system (chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>as pointed out by charniak and johnson (2005), <papid> P05-1022 </papid>thema jor difficulty in k-best parsing is dynamic programming.the simplest method is to abandon dynamic programming and relyon aggressive pruning to maintain tractabil ity, as is used in (collins, 2000; bikel, 2004).<papid> J04-4004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2091">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>any algorithm express ible as weighted deductive system (shieber et al, 1995; goodman, 1999; <papid> J99-4004 </papid>nederhof, 2003) <papid> J03-1006 </papid>falls into this class.</prevsent>
<prevsent>inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
model 2 (collins, 2003), <papid> J03-4003 </papid>and to synchronous cfg based machine translation system (chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>as pointed out by charniak and johnson (2005), <papid> P05-1022 </papid>thema jor difficulty in k-best parsing is dynamic programming.the simplest method is to abandon dynamic programming and relyon aggressive pruning to maintain tractabil ity, as is used in (collins, 2000; bikel, 2004).<papid> J04-4004 </papid></nextsent>
<nextsent>but this approach is prohibitively slow, and produces rather low quality k-best lists (see sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2093">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>inour experiments, we apply the algorithms to the lexicalized pcfg parser of bikel (2004), <papid> J04-4004 </papid>which is very similar to collins?</prevsent>
<prevsent>model 2 (collins, 2003), <papid> J03-4003 </papid>and to synchronous cfg based machine translation system (chiang, 2005).<papid> P05-1033 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
as pointed out by charniak and johnson (2005), <papid> P05-1022 </papid>thema jor difficulty in k-best parsing is dynamic programming.the simplest method is to abandon dynamic programming and relyon aggressive pruning to maintain tractabil ity, as is used in (collins, 2000; bikel, 2004).<papid> J04-4004 </papid></citsent>
<aftsection>
<nextsent>but this approach is prohibitively slow, and produces rather low quality k-best lists (see sec.
</nextsent>
<nextsent>5.1.2).
</nextsent>
<nextsent>gildea and jurafsky (2002) <papid> J02-3001 </papid>described an o(k2)-overhead extension for the cky algorithm and reimplemented collins?</nextsent>
<nextsent>model 1 to obtain k-best parses with an average of 14.9 parses per sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2097">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>jimenez and marzal present an algorithm very similar to our algorithm 3 (sec.
</prevsent>
<prevsent>4.4) while charniak and johnson propose using an algorithm similar to our algorithm 0, but with multiple passes to improve efficiency.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
they apply this method to the charniak (2000)<papid> A00-2018 </papid>parser to get 50-best lists for reranking, yielding an improvement in parsing accuracy.</citsent>
<aftsection>
<nextsent>our work differs from jimenez and marzals in the following three respects.
</nextsent>
<nextsent>first, we formulate the parsing problem in the more general framework of hypergraphs (klein and manning, 2001), making it applicable to very wide variety of parsing algorithms, whereas jimenez and marzal define their algorithm as an extension of cky, for cfgs in chomsky normal form (cnf)only.
</nextsent>
<nextsent>this generalization is not only of theoretical importance, but also critical in the application to state-of-the art parsers such as (collins, 2003) <papid> J03-4003 </papid>and (charniak, 2000).<papid> A00-2018 </papid>in collins?</nextsent>
<nextsent>parsing model, for instance, the rules are dynamically generated and include unary productions, making it very hard to convert to cnf by preprocessing, whereas our algorithms can be applied directly to these parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2102">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>first, we solve the problem of k-best derivations (i.e., trees), not the k-best hyper paths, although in many cases they coincide (see sec.
</prevsent>
<prevsent>3 for further discussions).second, their work assumes non-negative costs (or probabilities ? 1) so that they can apply dijkstra-like algorithms.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
although generative models, being probability based, do not suffer from this problem, more general models (e.g., log-linear models) may require negative edge costs (mcdonald et al, 2005; <papid> P05-1012 </papid>taskar et al, 2004).<papid> W04-3201 </papid>our work, based on the viterbi algorithm, is still applicable as long as the hypergraph is acyclic, and is used by mcdonald et al (2005) <papid> P05-1012 </papid>to get the k-best parses.</citsent>
<aftsection>
<nextsent>following klein and manning (2001), we use weighted directed hypergraphs (gallo et al, 1993) as an abstraction of the probabilistic parsing problem.definition 1.
</nextsent>
<nextsent>an ordered hypergraph (henceforth hy pergraph) is tuple v, e, t,r?, where is finite set of vertices, is finite set of hyper arcs, and is the set of weights.
</nextsent>
<nextsent>each hyper arc ? is triple 54 = (e), h(e), (e)?, where h(e) ? is its head andt (e) ? v? is vector of tail nodes.
</nextsent>
<nextsent>f (e) is weight function from r|t (e)| to r. ? is distinguished vertex called target vertex.note that our definition is different from those in previous work in the sense that the tails are now vectors rather than sets, so that we can allow multiple occurrences of the same vertex in tail and there is an ordering among the components of tail.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2103">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>first, we solve the problem of k-best derivations (i.e., trees), not the k-best hyper paths, although in many cases they coincide (see sec.
</prevsent>
<prevsent>3 for further discussions).second, their work assumes non-negative costs (or probabilities ? 1) so that they can apply dijkstra-like algorithms.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
although generative models, being probability based, do not suffer from this problem, more general models (e.g., log-linear models) may require negative edge costs (mcdonald et al, 2005; <papid> P05-1012 </papid>taskar et al, 2004).<papid> W04-3201 </papid>our work, based on the viterbi algorithm, is still applicable as long as the hypergraph is acyclic, and is used by mcdonald et al (2005) <papid> P05-1012 </papid>to get the k-best parses.</citsent>
<aftsection>
<nextsent>following klein and manning (2001), we use weighted directed hypergraphs (gallo et al, 1993) as an abstraction of the probabilistic parsing problem.definition 1.
</nextsent>
<nextsent>an ordered hypergraph (henceforth hy pergraph) is tuple v, e, t,r?, where is finite set of vertices, is finite set of hyper arcs, and is the set of weights.
</nextsent>
<nextsent>each hyper arc ? is triple 54 = (e), h(e), (e)?, where h(e) ? is its head andt (e) ? v? is vector of tail nodes.
</nextsent>
<nextsent>f (e) is weight function from r|t (e)| to r. ? is distinguished vertex called target vertex.note that our definition is different from those in previous work in the sense that the tails are now vectors rather than sets, so that we can allow multiple occurrences of the same vertex in tail and there is an ordering among the components of tail.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2116">
<title id=" W05-1506.xml">better kbest parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we implemented our k-best algorithms 0, 1, and 3 on top of bikels parser and conducted experiments on 2.4ghz 64-bit amd opteron with 32 gb memory.
</prevsent>
<prevsent>the program is written in java 1.5 running on the sun jvm in server mode with maximum heap size of 5 gb.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for this experiment, we used sections 0221 of the penn tree bank (ptb) (marcus et al, 1993) <papid> J93-2004 </papid>as the training data and section 23 (2416 sentences) for evaluation, as is now stan dard.</citsent>
<aftsection>
<nextsent>we ran bikels parser using its settings to emulate model 2 of (collins, 2003).<papid> J03-4003 </papid></nextsent>
<nextsent>5.1.1 efficiency we tested our algorithms under various conditions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2145">
<title id=" W05-1620.xml">an evolutionary approach to referring expression generation and aggregation </title>
<section> natural language generation tasks and.  </section>
<citcontext>
<prevsection>
<prevsent>two occurrences of the same concept in paragraph can be far apart,and this may confuse the reader.
</prevsent>
<prevsent>knowledge intensive approaches modelled on the way humans do it require certain measure of content understanding that is resource hungry.
</prevsent>
</prevsection>
<citsent citstr=" C92-1038 ">
as shown in [reiter and dale, 1992], <papid> C92-1038 </papid>referring expression must communicate enough information to be able to uniquely identify the intended referent in the current discourse context,but avoiding the presence of redundant or otherwise unnecessary modifiers.</citsent>
<aftsection>
<nextsent>therefore, it is essential to choose reference which matches these constraints.
</nextsent>
<nextsent>taking into account these features, reiter and dale proposed an algorithm to generate definite noun phrases to identify objects in the current focus of attention of the reader or the hearer.
</nextsent>
<nextsent>however, krahmer and theune [krahmer and theune, 2000] argue that due tothe original motivation of the work of reiter and dale of making distinguishing descriptions, various other aspects of the generation of definites remained somewhat underdeveloped.
</nextsent>
<nextsent>in particular they focus on the role of context-sensitivity for referring expression generation.kibble and power [kibble and power, 2000] <papid> W00-1411 </papid>propose system which uses centering theory [walker et al, 1998] for planning of coherent texts and choice of referring expres sions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2146">
<title id=" W05-1620.xml">an evolutionary approach to referring expression generation and aggregation </title>
<section> natural language generation tasks and.  </section>
<citcontext>
<prevsection>
<prevsent>taking into account these features, reiter and dale proposed an algorithm to generate definite noun phrases to identify objects in the current focus of attention of the reader or the hearer.
</prevsent>
<prevsent>however, krahmer and theune [krahmer and theune, 2000] argue that due tothe original motivation of the work of reiter and dale of making distinguishing descriptions, various other aspects of the generation of definites remained somewhat underdeveloped.
</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
in particular they focus on the role of context-sensitivity for referring expression generation.kibble and power [kibble and power, 2000] <papid> W00-1411 </papid>propose system which uses centering theory [walker et al, 1998] for planning of coherent texts and choice of referring expres sions.</citsent>
<aftsection>
<nextsent>they argue that text and sentence planning need tobe driven in part by the goal of maintaining referential con tinuity: obtaining favourable ordering of clauses, and of arguments within clauses, is likely to increase opportunities for non-ambiguous pronoun use.aggregation can be seen as the nlg task that involves deciding how compact the presentation of information should bein given text, although there is no exact definition in the literature about what aggregation is [reape and mellish, 1999].
</nextsent>
<nextsent>it operates at several linguistic levels, and due to that reapeand mellish make classification of the different types of ag gregation: conceptual, discourse, semantic, syntactic, lexical and referential.
</nextsent>
<nextsent>however, the line between them is very narrow, and in some cases specific example could be classified as different types of aggregation.
</nextsent>
<nextsent>2.2 evolutionary algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2147">
<title id=" W05-1620.xml">an evolutionary approach to referring expression generation and aggregation </title>
<section> natural language generation tasks and.  </section>
<citcontext>
<prevsection>
<prevsent>in [duboue and mckeown, 2002] the authors pre senta technique to learn tree-like structure for content planner from an aligned corpus of semantic inputs and corresponding, human produced, outputs.
</prevsent>
<prevsent>they apply stochastic search mechanism with two-level fitness function to create the structure of the planner.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
genetic algorithms are also used in [mellish et al, 1998] <papid> W98-1411 </papid>where the authors state the problem of given set of facts to convey and set of rhetorical relations that can be used to link them together, how one can arrange this material so as to yield the best possible text.</citsent>
<aftsection>
<nextsent>an important conclusion to draw from these efforts is the suitability of evolutionary techniques for natural language generation tasks in which the form plays significant role,to the extent of sometimes interfering with the intended content, such as is the case for lyrics generation.
</nextsent>
<nextsent>generator the work presented here is intended to be module for the tasks of referring expressions generation and aggregation enclosed in the architecture of cfrogs [garca et al, 2004].
</nextsent>
<nextsent>cfrogs is framework-like library of architectural classes intended to facilitate the development of nlg applications.
</nextsent>
<nextsent>cfrogs identifies three basic design decisions: what set of modules to use, how control should flow between them, and what data structures are used to communicate between the modules.we have tested the implementation of the module in an existing application: proto propp [gervas et al, 2004].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2150">
<title id=" W05-0810.xml">nukti englishinuktitut word alignment system description </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we concentrated our effort on the english-inuktitut word alignment shared task and report on two approaches we implemented and combination of both.
</prevsent>
<prevsent>word alignment is an important step in exploiting parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
when efficient techniques have been proposed (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003), <papid> J03-1002 </papid>they have been mostly evaluated on safe?</citsent>
<aftsection>
<nextsent>pairs of languages where the notion of word is rather clear.
</nextsent>
<nextsent>we devoted two weeks to the intriguing task of aligning at the word level pairs of sentences of english and inuktitut.
</nextsent>
<nextsent>we experimented withtwo different approaches.
</nextsent>
<nextsent>for the first one, we relied on an in-house sentence alignment program (japa) where english and inuktitut tokens were considered as sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2151">
<title id=" W05-0810.xml">nukti englishinuktitut word alignment system description </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we concentrated our effort on the english-inuktitut word alignment shared task and report on two approaches we implemented and combination of both.
</prevsent>
<prevsent>word alignment is an important step in exploiting parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
when efficient techniques have been proposed (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003), <papid> J03-1002 </papid>they have been mostly evaluated on safe?</citsent>
<aftsection>
<nextsent>pairs of languages where the notion of word is rather clear.
</nextsent>
<nextsent>we devoted two weeks to the intriguing task of aligning at the word level pairs of sentences of english and inuktitut.
</nextsent>
<nextsent>we experimented withtwo different approaches.
</nextsent>
<nextsent>for the first one, we relied on an in-house sentence alignment program (japa) where english and inuktitut tokens were considered as sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2152">
<title id=" W05-0810.xml">nukti englishinuktitut word alignment system description </title>
<section> japa: word alignment as sentence.  </section>
<citcontext>
<prevsection>
<prevsent>a fast inspection of this material reveals that in most of the cases, the alignment produced are monotonic and involve cepts of adjacent english words aligned to single inuktitut word.
</prevsent>
<prevsent>many sentence alignment techniques strongly rely on the monotonic nature of the inherent alignment.
</prevsent>
</prevsection>
<citsent citstr=" P98-1117 ">
therefore, we conducted first experiment using an in-house sentence alignment program called japa that we developed within the framework of the arcade evaluation campaign(langlais et al, 1998).<papid> P98-1117 </papid></citsent>
<aftsection>
<nextsent>the implementation details of this aligner can be found in (langlais, 1997), but in few words, japa aligns pairs of sentences by first grossly aligning their words (making use of either cognate-like tokens, or specified bilingual dictionary).
</nextsent>
<nextsent>a second pass aligns the sentences in way similar1 to the algorithm described by gale and church (1993), <papid> J93-1004 </papid>but where the search space is constrained to be close to the one delimited by the word alignment.</nextsent>
<nextsent>this technique happened to be among the most accurate of the ones tested during the arcade exercise.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2153">
<title id=" W05-0810.xml">nukti englishinuktitut word alignment system description </title>
<section> japa: word alignment as sentence.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we conducted first experiment using an in-house sentence alignment program called japa that we developed within the framework of the arcade evaluation campaign(langlais et al, 1998).<papid> P98-1117 </papid></prevsent>
<prevsent>the implementation details of this aligner can be found in (langlais, 1997), but in few words, japa aligns pairs of sentences by first grossly aligning their words (making use of either cognate-like tokens, or specified bilingual dictionary).</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
a second pass aligns the sentences in way similar1 to the algorithm described by gale and church (1993), <papid> J93-1004 </papid>but where the search space is constrained to be close to the one delimited by the word alignment.</citsent>
<aftsection>
<nextsent>this technique happened to be among the most accurate of the ones tested during the arcade exercise.
</nextsent>
<nextsent>to adapt japa to our needs, we only did two things.
</nextsent>
<nextsent>first, we considered single sentences as documents, and tokens as sentences (we define token as sequence of characters delimited by 1in our case, the score we seek to globally maximize by dynamic programming is not only taking into account the length criteria described in (gale and church, 1993) <papid> J93-1004 </papid>but also cognate-based one similar to (simard et al, 1992).</nextsent>
<nextsent>75 1-1 0.406 4-1 0.092 4-2 0.015 2-1 0.172 5-1 0.038 5-2 0.011 3-1 0.123 7-1 0.027 3-2 0.011 table 1: the 9 most frequent english-inuktitut patterns observed on the development set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2155">
<title id=" W05-0810.xml">nukti englishinuktitut word alignment system description </title>
<section> nukti: word and substring.  </section>
<citcontext>
<prevsection>
<prevsent>f-meas.
</prevsent>
<prevsent>aer 22.34 78.17 34.75 74.59table 2: performance of the japa alignment technique on the dev corpus.
</prevsent>
</prevsection>
<citsent citstr=" W03-0320 ">
alignment martin et al (2003) <papid> W03-0320 </papid>documented study in building and using an english-inuktitut bitext.</citsent>
<aftsection>
<nextsent>they described sentence alignment technique tuned for the specificity of the inuktitut language, and described as well technique for acquiring correspondent pairs of english tokens and inuktitut substrings.
</nextsent>
<nextsent>the motivation behind their work was to populate glossary with reliable such pairs.
</nextsent>
<nextsent>we extended this line of work in order to achieve word alignment.
</nextsent>
<nextsent>3.1 association score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2160">
<title id=" W05-0810.xml">nukti englishinuktitut word alignment system description </title>
<section> nukti: word and substring.  </section>
<citcontext>
<prevsection>
<prevsent>inutktitut % english % tokens 2 153 034 3 992 298 types 417 407 19.4 27 127 0.68 hapax 337 798 80.9 8 792 32.4 table 3: ratios of token types and happax words in the train corpus.
</prevsent>
<prevsent>the main idea presented in (martin et al, 2003) <papid> W03-0320 </papid>is to compute an association score between any english word seen in the training corpus and all the inuktitut sub strings of those tokens that were seen in the same region.</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
in our case, we computed likelihood ratio score (dunning, 1993) <papid> J93-1003 </papid>for all pairs of english tokens and inuktitut substringsof length ranging from 3 to 10 characters.</citsent>
<aftsection>
<nextsent>a maximum of 25 000 associations were kept for each english word (the top ranked ones).to reduce the computation load, we used suffix tree structure and computed the association scores only for the english words belonging to the test corpus we had to align.
</nextsent>
<nextsent>we also filtered out inuktitut sub strings we observed less than three times in the training corpus.
</nextsent>
<nextsent>altogether, it takes about one hour for good desktop computer to produce the association scores for one hundred english words.
</nextsent>
<nextsent>we normalize the association scores such that for each english word e, we have distribution of likely inuktitut sub strings s: ? pllr(s|e) = 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2161">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this both provides baseline for future evaluations and allows designers of nlg applications needing off-the-shelf surface realizers to choose on quantitative basis.
</prevsent>
<prevsent>surface realization is the process of converting the semantic and syntactic representation of sentence or series of sentences into surface form for particular language.
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
most reusable deep surface realizers [elhadad, 1991; bateman, 1995; lavoie and rambow, 1997; <papid> A97-1039 </papid>white and caldwell, 1998 ] <papid> W98-1428 </papid>have been symbolic, hand-written grammar-based systems, often based on syntactic linguistic theories such as hallidays [halliday, 1976] systemic functional theory (fuf/surge and kpml) or melcuks [melcuk, 1988] meaning-text theory (realpro).however, corpus-based components, and in particular statistical surface realizers [langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>ratnaparkhi, 2000; <papid> A00-2026 </papid>langkilde geary, 2002] have focused attention on number of problems facing symbolic nlg systems that until now have been generally considered future work: large-scale, data-robust and language- and domain-independent generation.</citsent>
<aftsection>
<nextsent>in each case,empirical evaluation plays fundamental role in determining performance at the task of surface realization and setting baselines for future performance evaluation.for instance, the halogen statistical realizer [langkilde geary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the penn treebank [marcus et al,1993], <papid> J93-2004 </papid>converting them into its input formalism, and then producing output strings.</nextsent>
<nextsent>using automatic metrics from machine translation then quickly produces figures for global characteristics of traits such as accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2162">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this both provides baseline for future evaluations and allows designers of nlg applications needing off-the-shelf surface realizers to choose on quantitative basis.
</prevsent>
<prevsent>surface realization is the process of converting the semantic and syntactic representation of sentence or series of sentences into surface form for particular language.
</prevsent>
</prevsection>
<citsent citstr=" W98-1428 ">
most reusable deep surface realizers [elhadad, 1991; bateman, 1995; lavoie and rambow, 1997; <papid> A97-1039 </papid>white and caldwell, 1998 ] <papid> W98-1428 </papid>have been symbolic, hand-written grammar-based systems, often based on syntactic linguistic theories such as hallidays [halliday, 1976] systemic functional theory (fuf/surge and kpml) or melcuks [melcuk, 1988] meaning-text theory (realpro).however, corpus-based components, and in particular statistical surface realizers [langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>ratnaparkhi, 2000; <papid> A00-2026 </papid>langkilde geary, 2002] have focused attention on number of problems facing symbolic nlg systems that until now have been generally considered future work: large-scale, data-robust and language- and domain-independent generation.</citsent>
<aftsection>
<nextsent>in each case,empirical evaluation plays fundamental role in determining performance at the task of surface realization and setting baselines for future performance evaluation.for instance, the halogen statistical realizer [langkilde geary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the penn treebank [marcus et al,1993], <papid> J93-2004 </papid>converting them into its input formalism, and then producing output strings.</nextsent>
<nextsent>using automatic metrics from machine translation then quickly produces figures for global characteristics of traits such as accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2163">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this both provides baseline for future evaluations and allows designers of nlg applications needing off-the-shelf surface realizers to choose on quantitative basis.
</prevsent>
<prevsent>surface realization is the process of converting the semantic and syntactic representation of sentence or series of sentences into surface form for particular language.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
most reusable deep surface realizers [elhadad, 1991; bateman, 1995; lavoie and rambow, 1997; <papid> A97-1039 </papid>white and caldwell, 1998 ] <papid> W98-1428 </papid>have been symbolic, hand-written grammar-based systems, often based on syntactic linguistic theories such as hallidays [halliday, 1976] systemic functional theory (fuf/surge and kpml) or melcuks [melcuk, 1988] meaning-text theory (realpro).however, corpus-based components, and in particular statistical surface realizers [langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>ratnaparkhi, 2000; <papid> A00-2026 </papid>langkilde geary, 2002] have focused attention on number of problems facing symbolic nlg systems that until now have been generally considered future work: large-scale, data-robust and language- and domain-independent generation.</citsent>
<aftsection>
<nextsent>in each case,empirical evaluation plays fundamental role in determining performance at the task of surface realization and setting baselines for future performance evaluation.for instance, the halogen statistical realizer [langkilde geary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the penn treebank [marcus et al,1993], <papid> J93-2004 </papid>converting them into its input formalism, and then producing output strings.</nextsent>
<nextsent>using automatic metrics from machine translation then quickly produces figures for global characteristics of traits such as accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2164">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this both provides baseline for future evaluations and allows designers of nlg applications needing off-the-shelf surface realizers to choose on quantitative basis.
</prevsent>
<prevsent>surface realization is the process of converting the semantic and syntactic representation of sentence or series of sentences into surface form for particular language.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
most reusable deep surface realizers [elhadad, 1991; bateman, 1995; lavoie and rambow, 1997; <papid> A97-1039 </papid>white and caldwell, 1998 ] <papid> W98-1428 </papid>have been symbolic, hand-written grammar-based systems, often based on syntactic linguistic theories such as hallidays [halliday, 1976] systemic functional theory (fuf/surge and kpml) or melcuks [melcuk, 1988] meaning-text theory (realpro).however, corpus-based components, and in particular statistical surface realizers [langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>ratnaparkhi, 2000; <papid> A00-2026 </papid>langkilde geary, 2002] have focused attention on number of problems facing symbolic nlg systems that until now have been generally considered future work: large-scale, data-robust and language- and domain-independent generation.</citsent>
<aftsection>
<nextsent>in each case,empirical evaluation plays fundamental role in determining performance at the task of surface realization and setting baselines for future performance evaluation.for instance, the halogen statistical realizer [langkilde geary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the penn treebank [marcus et al,1993], <papid> J93-2004 </papid>converting them into its input formalism, and then producing output strings.</nextsent>
<nextsent>using automatic metrics from machine translation then quickly produces figures for global characteristics of traits such as accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2165">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this both provides baseline for future evaluations and allows designers of nlg applications needing off-the-shelf surface realizers to choose on quantitative basis.
</prevsent>
<prevsent>surface realization is the process of converting the semantic and syntactic representation of sentence or series of sentences into surface form for particular language.
</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
most reusable deep surface realizers [elhadad, 1991; bateman, 1995; lavoie and rambow, 1997; <papid> A97-1039 </papid>white and caldwell, 1998 ] <papid> W98-1428 </papid>have been symbolic, hand-written grammar-based systems, often based on syntactic linguistic theories such as hallidays [halliday, 1976] systemic functional theory (fuf/surge and kpml) or melcuks [melcuk, 1988] meaning-text theory (realpro).however, corpus-based components, and in particular statistical surface realizers [langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>ratnaparkhi, 2000; <papid> A00-2026 </papid>langkilde geary, 2002] have focused attention on number of problems facing symbolic nlg systems that until now have been generally considered future work: large-scale, data-robust and language- and domain-independent generation.</citsent>
<aftsection>
<nextsent>in each case,empirical evaluation plays fundamental role in determining performance at the task of surface realization and setting baselines for future performance evaluation.for instance, the halogen statistical realizer [langkilde geary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the penn treebank [marcus et al,1993], <papid> J93-2004 </papid>converting them into its input formalism, and then producing output strings.</nextsent>
<nextsent>using automatic metrics from machine translation then quickly produces figures for global characteristics of traits such as accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2166">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surface realization is the process of converting the semantic and syntactic representation of sentence or series of sentences into surface form for particular language.
</prevsent>
<prevsent>most reusable deep surface realizers [elhadad, 1991; bateman, 1995; lavoie and rambow, 1997; <papid> A97-1039 </papid>white and caldwell, 1998 ] <papid> W98-1428 </papid>have been symbolic, hand-written grammar-based systems, often based on syntactic linguistic theories such as hallidays [halliday, 1976] systemic functional theory (fuf/surge and kpml) or melcuks [melcuk, 1988] meaning-text theory (realpro).however, corpus-based components, and in particular statistical surface realizers [langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and rambow, 2000; <papid> C00-1007 </papid>ratnaparkhi, 2000; <papid> A00-2026 </papid>langkilde geary, 2002] have focused attention on number of problems facing symbolic nlg systems that until now have been generally considered future work: large-scale, data-robust and language- and domain-independent generation.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in each case,empirical evaluation plays fundamental role in determining performance at the task of surface realization and setting baselines for future performance evaluation.for instance, the halogen statistical realizer [langkilde geary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the penn treebank [marcus et al,1993], <papid> J93-2004 </papid>converting them into its input formalism, and then producing output strings.</citsent>
<aftsection>
<nextsent>using automatic metrics from machine translation then quickly produces figures for global characteristics of traits such as accuracy.
</nextsent>
<nextsent>in recent experiment, we compared the performance of halogen relative to the grammar-based fuf/surge surface realizer on the identical corpus and with similar methodology [callaway, 2003; 2004].
</nextsent>
<nextsent>although fuf/surge scored higher than the halogen realizer, we were interested in absolute as well as relative performance: e.g., what particular grammatical rules are not well-covered by surges grammar?
</nextsent>
<nextsent>while the above methodology gives an average figure for what coverage and accuracy are on corpus like the penn treebank, it describes very wide array of errors as simple numerical averages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2168">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> types of syntactic errors.  </section>
<citcontext>
<prevsection>
<prevsent>thus sentences like among those sighing with relief was john h. gutfreund?
</prevsent>
<prevsent>may generate correctly depending on their clausal thematic type, like material or equative.
</prevsent>
</prevsection>
<citsent citstr=" P04-3009 ">
while we present the results of manual analysis of the data in the next section, it is important to remember that the large majority of syntactic constructions, punctuation and morphology worked flawlessly in the evaluation of fuf/surge as described in [callaway, 2004].<papid> P04-3009 </papid></citsent>
<aftsection>
<nextsent>as described earlier, almost 7 out of every 10 sentences in the unseen testset were exact matches, including punctuation and capitalization.
</nextsent>
<nextsent>additionally, most errors that did occur were in the transformation component rather than the surface realizer, as we will describe shortly.
</nextsent>
<nextsent>finally, some well-studied but rare syntactic constructions did not occur in the sections of the penn treebank that we examined, such as left dislocation and negative np preposing.
</nextsent>
<nextsent>as mentioned previously, we undertook manual analysis of sections 2022 of the penn treebank by hand to determine specific reasons behind the failure of 629 sentences out of 4,240 that met the criteria of having between 15 and 44 words, and having character error rate of more than 9 as determined by the ssa metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2169">
<title id=" W05-1619.xml">the types and distributions of errors in a wide coverage surface realizer evaluation </title>
<section> data analysis.  </section>
<citcontext>
<prevsection>
<prevsent>penalty corpus error 40 6.36% 1922 7.74% 48.05 transformer rule error 166 26.39% 7201 29.01% 43.38 no transformer tag 12 1.91% 679 2.74% 56.58 no transformer rule 102 16.22% 4320 17.40% 42.35 ordering (good) 55 8.74% 2137 8.61% 38.85 ordering (bad) 55 8.74% 1396 5.62% 25.38 punctuation/morphology 14 2.23% 389 1.57% 27.79 syntax 185 29.41% 6777 27.30% 33.70 total 629 100.0% 24821 100.0% 38.60 table 2: distribution of 629 high-level errors in the 4,240 tested sentences from sections 2022.
</prevsent>
<prevsent>functional description.
</prevsent>
</prevsection>
<citsent citstr=" E03-1068 ">
the error rate of the penn treebank annotation is reasonably well-known quantity, and there isa specialized literature describing automatic correction methods (e.g., [dickinson and meurers, 2003]).<papid> E03-1068 </papid></citsent>
<aftsection>
<nextsent>one surprise though is that while the number of errors due to the ordering of floating constituents is the same, the error inaccuracy is skewed to semantically acceptable interpretations.
</nextsent>
<nextsent>and while the distribution of the order seems like random chance, it should be remembered that there can potentially be up to 10 acceptable placements when there are multiple floating constituents.
</nextsent>
<nextsent>additionally, unrecognized annotation tags seem to invoke the heaviest average penalty for any error type, but have the lowest rate of occurrence.
</nextsent>
<nextsent>some advice then for future evaluations of this type would be to systematically ensure that all tags are normalized in the corpus before writing transformation rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2170">
<title id=" W05-1302.xml">adaptive string similarity metrics for biomedical reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>b. cross-document or corpus reference resolution.
</prevsent>
<prevsent>c. resolution of entities found in corpus with databases, dictionaries or other external knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" W04-0711 ">
this is also called semantic integration, e.g., (li et al, 2005), reference grounding, e.g., (kim and park, 2004) <papid> W04-0711 </papid>or normalization, e.g., (pustejovsky et al, 2002; <papid> W02-0312 </papid>morgan et al., 2004).</citsent>
<aftsection>
<nextsent>the last two aspects of reference resolution are particularly important for information extraction,and the interaction of reference resolution with information extraction techniques (see for example bagga (1998)).
</nextsent>
<nextsent>the extraction of particular set of entities from corpus requires reference resolution for the set of entities extracted (e.g., the edt task in ace1), and it is apparent that there is more variation in the cross-document naming conventions than in single document.
</nextsent>
<nextsent>the importance of edit distance algorithms has already been noticed, (muller et al, 2002) and the importance of string similarity techniques in the biomedical domain has also been acknowledged, e.g., (yang et al, 2004).
</nextsent>
<nextsent>string similarity/matching algorithms have also been used extensively in related problems such as name databases and similar problems in structured data, see (li et al, 2005) and references mentioned therein.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2171">
<title id=" W05-1302.xml">adaptive string similarity metrics for biomedical reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>b. cross-document or corpus reference resolution.
</prevsent>
<prevsent>c. resolution of entities found in corpus with databases, dictionaries or other external knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" W02-0312 ">
this is also called semantic integration, e.g., (li et al, 2005), reference grounding, e.g., (kim and park, 2004) <papid> W04-0711 </papid>or normalization, e.g., (pustejovsky et al, 2002; <papid> W02-0312 </papid>morgan et al., 2004).</citsent>
<aftsection>
<nextsent>the last two aspects of reference resolution are particularly important for information extraction,and the interaction of reference resolution with information extraction techniques (see for example bagga (1998)).
</nextsent>
<nextsent>the extraction of particular set of entities from corpus requires reference resolution for the set of entities extracted (e.g., the edt task in ace1), and it is apparent that there is more variation in the cross-document naming conventions than in single document.
</nextsent>
<nextsent>the importance of edit distance algorithms has already been noticed, (muller et al, 2002) and the importance of string similarity techniques in the biomedical domain has also been acknowledged, e.g., (yang et al, 2004).
</nextsent>
<nextsent>string similarity/matching algorithms have also been used extensively in related problems such as name databases and similar problems in structured data, see (li et al, 2005) and references mentioned therein.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2172">
<title id=" W05-1302.xml">adaptive string similarity metrics for biomedical reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>string similarity/matching algorithms have also been used extensively in related problems such as name databases and similar problems in structured data, see (li et al, 2005) and references mentioned therein.
</prevsent>
<prevsent>the problem of determining whether two similar strings may denot ate the same entity is particularly challenging in the biomedical literature.
</prevsent>
</prevsection>
<citsent citstr=" W02-0303 ">
it has already been noticed (cohen et al, 2002) <papid> W02-0303 </papid>that there is great variation in the naming conventions, and noun phrase constructions in the literature.</citsent>
<aftsection>
<nextsent>it has also been noticed that bio-databases are hardly ever updated with the names in the literature (blaschke 1http://www.nist.gov/speech/tests/ace/ 9et al, 2003).
</nextsent>
<nextsent>a further complication is that the actual mentions found in text are more complex than just names - including descriptors, in particular.
</nextsent>
<nextsent>finally, ambiguity (where multiple entities have the same name) is very pervasive in biomedicine.
</nextsent>
<nextsent>in this paper we investigate the use of several string similarity methods to group together string mentions that might refer to the same entity or concept.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2174">
<title id=" W05-1302.xml">adaptive string similarity metrics for biomedical reference resolution </title>
<section> an adaptive string similarity model.  </section>
<citcontext>
<prevsection>
<prevsent>in our setting, the number of state variable values is very large - one foreach character in our alphabet (which is on the order of 40 or more including digits and punctuation).
</prevsent>
<prevsent>moreover, we typically have very large training sets largely due to the fact that t.u v training pairs are derivable from an equivalence class of size . given this situation, standard training for crfs becomes unwieldy, since it involves performing inference over the entire dataset repeatedly (typically few hundred iterations are required to converge).
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
12as such, we resort to an approximation: voted perceptron training (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>voted perceptron training does not involve maximizing log-likelihood,but instead updates parameters via stochastic gradient descent with small number of passes over the data.
</nextsent>
<nextsent>another consideration that arises is given pairof strings, which one should be considered the observed?
</nextsent>
<nextsent>sequence and which one the hidden?
</nextsent>
<nextsent>sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2175">
<title id=" W04-3007.xml">robustness issues in a data driven spoken language understanding system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the key component of spoken language understanding (slu) system is the semantic parser, which translates the users?
</prevsent>
<prevsent>utterances into semantic representations.
</prevsent>
</prevsection>
<citsent citstr=" P94-1016 ">
traditionally, most semantic parser systems have been built using hand-crafted semantic grammar rules and so-called robust parsing (ward and issar, 1996; seneff, 1992; dowding et al, 1994) <papid> P94-1016 </papid>is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel.</citsent>
<aftsection>
<nextsent>the frame with the highest score then yields the selected semantic representation.formally speaking, the robustness of language (recognition, parsing, etc.) is measure of the ability of human speakers to communicate despite incomplete information, ambiguity, and the constant element of surprise(briscoe, 1996).
</nextsent>
<nextsent>in this paper, two aspects of slu system performance are investigated: noise robustness and adaptability to different applications.
</nextsent>
<nextsent>for the former, we expect that an slu system should maintain acceptable performance when given noisy input speech data.
</nextsent>
<nextsent>this requires, the understanding components of the slu system to be able to correctly interpret the meaning of an utterance even when faced with recognition errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2176">
<title id=" W04-3007.xml">robustness issues in a data driven spoken language understanding system </title>
<section> noise robustness.  </section>
<citcontext>
<prevsection>
<prevsent>cn, (gu|c1 ? ?
</prevsent>
<prevsent>cn).
</prevsent>
</prevsection>
<citsent citstr=" H94-1010 ">
the atis corpus which contains air travel information data (dahl et al, 1994) <papid> H94-1010 </papid>has been chosen for the slu system development and evaluation.</citsent>
<aftsection>
<nextsent>atis was developed in the darpa sponsored spoken language understanding programme conducted from 1990 to 1995 and it providesa convenient and well-documented standard for measuring the end-to-end performance of an slu system.
</nextsent>
<nextsent>how ever, since the atis corpus contains only clean speech, corrupted test data has been generated by adding samples of background noise to the clean test data at the waveform level.
</nextsent>
<nextsent>3.1 experimental setup.
</nextsent>
<nextsent>the experimental setup used to evaluate the slu system was similar to that described in (he and young, 2003a).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2177">
<title id=" W04-3007.xml">robustness issues in a data driven spoken language understanding system </title>
<section> adaptation to new applications.  </section>
<citcontext>
<prevsection>
<prevsent>statistical model adaptation techniques are widely used to reduce the mismatch between training and test or toadapt well-trained model to novel domain.
</prevsent>
<prevsent>commonly used techniques can be classified into two categories, bayesian adaptation which uses maximum posteriori (map) probability criteria (gauvain and lee,1994) and transformation-based approaches such as maximum likelihood linear regression (mllr) (gales and woodland, 1996), which uses maximum likelihood (ml) criteria.
</prevsent>
</prevsection>
<citsent citstr=" N03-1027 ">
in recent years, map adaptation has been successfully applied to n-gram language models (bac chiani and roark, 2003) and lexicalized pcfg models (roark and bacchiani, 2003).<papid> N03-1027 </papid></citsent>
<aftsection>
<nextsent>luo et al have proposed transformation-based approaches based on the markov transform (luo et al, 1999) and the householder transform (luo, 2000), to adapt statistical parsers.
</nextsent>
<nextsent>however, the optimisation processes for the latter are complex and it is not clear how general they are.
</nextsent>
<nextsent>since map adaptation is straightforward and has been applied successfully to pcfg parsers, it has been selected for investigation in this paper.
</nextsent>
<nextsent>since one of the special forms of map adaptation is interpolation between the in domain and out-of-domain models, it is natural to also consider the use of non-linear interpolation and hence this has been studied as well 1.1experiments using linear interpolation have also been conducted but it was found that the results are worse than those 4.1 map adaptation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2178">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, the traditional feature selection techniques (kohavi and sommer field, 1995) are not so useful since the critical problem relates to feature generation rather than selection.
</prevsent>
<prevsent>for example, the design of features for natural language syntacticparse-tree re-ranking problem (collins, 2000) can not be carried out without deep knowledge about automatic syntactic parsing.
</prevsent>
</prevsection>
<citsent citstr=" W04-3222 ">
the modeling of syntactic/semantic based features should take into account linguistic aspects to detect the interesting context, e.g. the ancestor nodes or the semantic dependencies (toutanova et al, 2004).<papid> W04-3222 </papid></citsent>
<aftsection>
<nextsent>a viable alternative has been proposed in (collins and duffy, 2002), <papid> P02-1034 </papid>where convolution kernels were used to implicitly define tree substructure space.</nextsent>
<nextsent>the selection of the relevant structural features wasleft to the voted perceptron learning algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2179">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the design of features for natural language syntacticparse-tree re-ranking problem (collins, 2000) can not be carried out without deep knowledge about automatic syntactic parsing.
</prevsent>
<prevsent>the modeling of syntactic/semantic based features should take into account linguistic aspects to detect the interesting context, e.g. the ancestor nodes or the semantic dependencies (toutanova et al, 2004).<papid> W04-3222 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
a viable alternative has been proposed in (collins and duffy, 2002), <papid> P02-1034 </papid>where convolution kernels were used to implicitly define tree substructure space.</citsent>
<aftsection>
<nextsent>the selection of the relevant structural features wasleft to the voted perceptron learning algorithm.
</nextsent>
<nextsent>an other interesting model for parsing re-ranking based on tree kernel is presented in (taskar et al, 2004).<papid> W04-3201 </papid></nextsent>
<nextsent>the good results show that tree kernels are very promising for automatic feature engineering, especially when the available knowledge about the phenomenon is limited.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2180">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a viable alternative has been proposed in (collins and duffy, 2002), <papid> P02-1034 </papid>where convolution kernels were used to implicitly define tree substructure space.</prevsent>
<prevsent>the selection of the relevant structural features wasleft to the voted perceptron learning algorithm.</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
an other interesting model for parsing re-ranking based on tree kernel is presented in (taskar et al, 2004).<papid> W04-3201 </papid></citsent>
<aftsection>
<nextsent>the good results show that tree kernels are very promising for automatic feature engineering, especially when the available knowledge about the phenomenon is limited.
</nextsent>
<nextsent>along the same line, automatic learning tasks that relyon syntactic information may take advantage ofa tree kernel approach.
</nextsent>
<nextsent>one of such tasks is the automatic boundary detection of predicate arguments of the kind defined in propbank (kingsbury and palmer, 2002).
</nextsent>
<nextsent>for this purpose, given predicate in sentence s, we can define the notion of predicate argument spanning trees (past s) as those syntactic subtrees of which exactly cover all and onlythe ps arguments (see section 4.1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2183">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> automated semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>m n np n vp john in rented room pp in boston arg.
</prevsent>
<prevsent>1 figure 1: predicate argument structure in parse-tree rep resentation.several machine learning approaches for automatic predicate argument extraction have been developed, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
(gildea and jurasfky, 2002; gildea and palmer, 2002; <papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>pradhan et al, 2004).</citsent>
<aftsection>
<nextsent>their common characteristic isthe adoption of feature spaces that model predicate argument structures in flat feature representation.
</nextsent>
<nextsent>in the next section, we present the common parse tree-based approach to this problem.
</nextsent>
<nextsent>2.1 predicate argument extraction.
</nextsent>
<nextsent>given sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2184">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> automated semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>m n np n vp john in rented room pp in boston arg.
</prevsent>
<prevsent>1 figure 1: predicate argument structure in parse-tree rep resentation.several machine learning approaches for automatic predicate argument extraction have been developed, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W03-1008 ">
(gildea and jurasfky, 2002; gildea and palmer, 2002; <papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>pradhan et al, 2004).</citsent>
<aftsection>
<nextsent>their common characteristic isthe adoption of feature spaces that model predicate argument structures in flat feature representation.
</nextsent>
<nextsent>in the next section, we present the common parse tree-based approach to this problem.
</nextsent>
<nextsent>2.1 predicate argument extraction.
</nextsent>
<nextsent>given sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2187">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> boundary detection via argument.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, we can use eq.
</prevsent>
<prevsent>1 to estimate the similarity between two past avoiding to define explicit features.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
the same ideahas been successfully applied to the parse-tree reranking task (taskar et al, 2004; <papid> W04-3201 </papid>collins and duffy,2002) <papid> P02-1034 </papid>and predicate argument classification (mos chitti, 2004).<papid> P04-1043 </papid>for the second problem, i.e. the high computational complexity, we can cut the search space by using traditional boundary classifier (tbc), e.g.</citsent>
<aftsection>
<nextsent>(pradhan et al, 2004), which provides small set of potential argument nodes.
</nextsent>
<nextsent>let pa be the set of nodes located by tbc as arguments.
</nextsent>
<nextsent>we may consider the set of the nst associated with any subset of pa, i.e. = {ps : ? pa}.
</nextsent>
<nextsent>however, alsothe classification ofp may be computationally problematic since theoretically there are |p| = 2|pa| members.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2189">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments were carried out with the svm-light-tk software available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes the tree kernels in the svm-light software (joachims, 1999).
</prevsent>
<prevsent>for tbc, we used the linear kernel with regularization parameter (option -c) equal to 1 and cost-factor (option -j) of 10 to have higher recall.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for the pastc we used ? = 0.4 (see (moschitti, 2004)).<papid> P04-1043 </papid>as referring dataset, we used the propbank corpora available at www.cis.upenn.edu/ace, along with the penn treebank 2 (www.cis.upenn.edu/treebank) (marcus et al., 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>this corpus contains about 53,700 sentences and fixed split between training and testing which has been used in other researches, e.g.
</nextsent>
<nextsent>(pradhan et al, 2004; gildea and palmer, 2002).<papid> P02-1031 </papid></nextsent>
<nextsent>we did not include continuation and co-referring arguments in our experiments.we used sections from 02 to 07 (54,443 argument nodes and 1,343,046 non-argument nodes) to train the traditional boundary classifier (tbc).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2194">
<title id=" W05-0407.xml">engineering of syntactic features for shallow semantic parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of relation extraction the concept graph is associated with syntactic shallow parse and the extracted propositional features express fragments of such syntactic structure.
</prevsent>
<prevsent>the experiments over the named entity class categorization show that when the description language select san adequate set of tree fragments the voted perceptron algorithm increases its classification accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
in (culotta and sorensen, 2004) <papid> P04-1054 </papid>dependency 54 tree kernel is used to detect the named entity classes in natural language texts.</citsent>
<aftsection>
<nextsent>the major novelty wasthe combination of the contiguous and sparse kernels with the word kernel.
</nextsent>
<nextsent>the results show that the contiguous outperforms the sparse kernel and the bag-of-words.
</nextsent>
<nextsent>the feature design for new natural language learning tasks is difficult.
</nextsent>
<nextsent>we can take advantage from the kernel methods to model our intuitive knowledge about the target linguistic phenomenon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2195">
<title id=" W06-0704.xml">situated question answering in the clinical domain selecting the best drug treatment for diseases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they do not occur in isolation, but are rather embedded withina broader context, i.e., scenario?.
</prevsent>
<prevsent>these complex questions set forth parameters of the desired knowledge, which may include additional facts about the motivation of the information seeker, her assumptions, her current state of knowledge, etc. presently, most systems that attempt to tackle such complex questions are aimed at serving intelligence analysts, for activities such as counterterrorism and war-fighting.
</prevsent>
</prevsection>
<citsent citstr=" C04-1100 ">
systems for addressing complex information needs are interesting because they provide an opportunity to explore the role of semantic structures in question answering, e.g., (narayanan and harabagiu, 2004).<papid> C04-1100 </papid></citsent>
<aftsection>
<nextsent>opportunities include explicit semantic representations for capturing the content of questions and documents, deep inferential mechanisms (moldovan et al, 2002), <papid> P02-1005 </papid>and attempt sto model task-specific influences in information seeking environments (freund et al, 2005).</nextsent>
<nextsent>our own interest in question answering falls in line with these recent developments, but we focus on different type of userthe primary care physician.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2196">
<title id=" W06-0704.xml">situated question answering in the clinical domain selecting the best drug treatment for diseases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these complex questions set forth parameters of the desired knowledge, which may include additional facts about the motivation of the information seeker, her assumptions, her current state of knowledge, etc. presently, most systems that attempt to tackle such complex questions are aimed at serving intelligence analysts, for activities such as counterterrorism and war-fighting.
</prevsent>
<prevsent>systems for addressing complex information needs are interesting because they provide an opportunity to explore the role of semantic structures in question answering, e.g., (narayanan and harabagiu, 2004).<papid> C04-1100 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1005 ">
opportunities include explicit semantic representations for capturing the content of questions and documents, deep inferential mechanisms (moldovan et al, 2002), <papid> P02-1005 </papid>and attempt sto model task-specific influences in information seeking environments (freund et al, 2005).</citsent>
<aftsection>
<nextsent>our own interest in question answering falls in line with these recent developments, but we focus on different type of userthe primary care physician.
</nextsent>
<nextsent>the need to answer questions related to patient care at the point of service has been well studied and documented (gorman et al., 1994; ely et al, 1999; ely et al, 2005).
</nextsent>
<nextsent>however, research has shown that existing search systems, e.g., pubmed, are often unable to supply clinically-relevant answers in timely manner (gorman et al, 1994; cham bliss and conley, 1996).
</nextsent>
<nextsent>clinical question answering represents high-impact application that has the potential to improve the quality of medical care.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2197">
<title id=" W06-0704.xml">situated question answering in the clinical domain selecting the best drug treatment for diseases </title>
<section> discussion and related work.  </section>
<citcontext>
<prevsection>
<prevsent>many researchers have studied mesh terms associated with basic clinical tasks (mendonca and cimino, 2001; haynes et al, 1994).
</prevsent>
<prevsent>although originally developed as tool to assist in query formulation, booth (2000) pointed out that pico frames can be employed to structure ir results for improving precision; pico based querying is merely an instance of faceted querying, which has been widely used by librarians since the invention of automated retrieval systems.
</prevsent>
</prevsection>
<citsent citstr=" W04-0509 ">
the feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by niu and hirst (2004), <papid> W04-0509 </papid>but ourwork differs in its focus on the primary medical literature.</citsent>
<aftsection>
<nextsent>approaching clinical needs from different perspective, the persival system leverages patient records to rerank search results (mckeownet al, 2003).
</nextsent>
<nextsent>since the primary focus is on person 30alization, this work can be viewed as complementary to our own.the dearth of related work and the lack of preexisting clinical test collection to large extent explains the ad hoc nature of some aspects of our semantic matching algorithm.
</nextsent>
<nextsent>all weights were heuristic ally chosen to reflect our understanding of the domain, and were not optimized in principled manner.
</nextsent>
<nextsent>nevertheless, performance gains observed in the development set carried over tothe blind held-out test collection, providing confidence in the generality of our methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2198">
<title id=" W05-1615.xml">evaluation of an nlg system using post edit data lessons learnt </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>sumtime-mousam is operational and is used by weather news (uk) ltd to generate 150 draft forecasts per day, which are post-edited by weather news forecasters before being released to clients.
</prevsent>
<prevsent>2.1 evaluating nlg systems.
</prevsent>
</prevsection>
<citsent citstr=" J97-1004 ">
common evaluation techniques for nlg systems [mellish and dale, 1998] include: ? showing generated texts to users, and measuring how effective they are at achieving their goal, compared to some control text (for example, [young, 1999]) ? asking experts to rate computer-generated texts in various ways, and comparing this to their rating of manually authored texts (for example, [lester and porter, 1997]) ? <papid> J97-1004 </papid>automatically comparing generated texts to corpus of human authored texts (for example, [bangalore et al 2000]).<papid> W00-1401 </papid></citsent>
<aftsection>
<nextsent>each of these techniques is effective under different application contexts in which nlg systems operate.
</nextsent>
<nextsent>for instance, corpus based technique is effective when high quality corpus is available.
</nextsent>
<nextsent>the appeal of post-edit evaluation as done with sumtime-mousam is that (a) the edits should indicate actual mistakes instead of just differences in how things can be said and (b) the amount of post-editing required is very important practical measure of how useful the system is to real users (forecasters in our case).
</nextsent>
<nextsent>post-edit evaluations are standard technique in machine translation [hutchins and somers, 1992].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2199">
<title id=" W05-1615.xml">evaluation of an nlg system using post edit data lessons learnt </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>sumtime-mousam is operational and is used by weather news (uk) ltd to generate 150 draft forecasts per day, which are post-edited by weather news forecasters before being released to clients.
</prevsent>
<prevsent>2.1 evaluating nlg systems.
</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
common evaluation techniques for nlg systems [mellish and dale, 1998] include: ? showing generated texts to users, and measuring how effective they are at achieving their goal, compared to some control text (for example, [young, 1999]) ? asking experts to rate computer-generated texts in various ways, and comparing this to their rating of manually authored texts (for example, [lester and porter, 1997]) ? <papid> J97-1004 </papid>automatically comparing generated texts to corpus of human authored texts (for example, [bangalore et al 2000]).<papid> W00-1401 </papid></citsent>
<aftsection>
<nextsent>each of these techniques is effective under different application contexts in which nlg systems operate.
</nextsent>
<nextsent>for instance, corpus based technique is effective when high quality corpus is available.
</nextsent>
<nextsent>the appeal of post-edit evaluation as done with sumtime-mousam is that (a) the edits should indicate actual mistakes instead of just differences in how things can be said and (b) the amount of post-editing required is very important practical measure of how useful the system is to real users (forecasters in our case).
</nextsent>
<nextsent>post-edit evaluations are standard technique in machine translation [hutchins and somers, 1992].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2200">
<title id=" W05-1615.xml">evaluation of an nlg system using post edit data lessons learnt </title>
<section> post-edit evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for each forecast, we have the following data ? data: the final edited nwp data ? pre-edit text: the final draft forecast produced by sumtime-mousam, which we reconstruct as described in section 2.3.
</prevsent>
<prevsent>? post-edit text: the manually post-edited forecast, which was sent to the client.
</prevsent>
</prevsection>
<citsent citstr=" W03-0611 ">
background information: includes date, location, and forecaster we do not currently use the nwp data (other than for reconstructing sumtime-mousam texts), although we hope in the future to include it in our analyses, in manner roughly analogous to reiter and sripada [2003].<papid> W03-0611 </papid></citsent>
<aftsection>
<nextsent>this dataset continues to grow, we receive approximately 150 new forecasts per day.
</nextsent>
<nextsent>3.2 analysis procedure.
</nextsent>
<nextsent>the following procedure is performed automatically by software tool.
</nextsent>
<nextsent>first, we perform some data transformation and cleaning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2201">
<title id=" W05-1615.xml">evaluation of an nlg system using post edit data lessons learnt </title>
<section> post-edit evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>however, since post editors can delete words more quickly than they can add words, it probably makes sense from practical perspective to be conservative about elision, and only elide in unambiguous cases.
</prevsent>
<prevsent>we will not further discuss data replacement errors, since they reflect either content problems or cases where nwp data was not corrected at the input time but edited directly in the final text.
</prevsent>
</prevsection>
<citsent citstr=" J02-4007 ">
we have discussed lexical replacement errors in detail elsewhere [reiter and sripada, 2002].<papid> J02-4007 </papid></citsent>
<aftsection>
<nextsent>in general terms, some errors reflect problems with sumtime-mousam; for example, the system ove ruses then as connective, so forecasters often replaced then by alternative connectives such as and.
</nextsent>
<nextsent>however, many lexical replacement errors simply reflected the lexical preferences of individual forecasters [reiter and sripada, 2002].<papid> J02-4007 </papid></nextsent>
<nextsent>for example, sumtimemousam always uses the verb easing to indicate reduction in wind speed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2205">
<title id=" W05-1615.xml">evaluation of an nlg system using post edit data lessons learnt </title>
<section> lessons from our post-edit evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>although we have not measured the time required for performing post-edits, we have used edit-distance measures used in mt evaluations as an approximate cost metric.
</prevsent>
<prevsent>we have computed our cost metric by setting different cost (weight) values to different edit operations.
</prevsent>
</prevsection>
<citsent citstr=" C92-2067 ">
cost of add and replace operations is set to 5 and cost of delete is set to 1 as used in su et al[1992].<papid> C92-2067 </papid></citsent>
<aftsection>
<nextsent>the ratio of the cost of edits and the cost of writing the entire forecast manually (adding all the words) is computed to be 0.15.
</nextsent>
<nextsent>(a) however was perhaps less true than we had hoped.
</nextsent>
<nextsent>wagner [1998] also described post edited texts in mt as at times noisy.
</nextsent>
<nextsent>our analysis of manually written forecasts [reiter and sripada, 2002] <papid> J02-4007 </papid>had highlighted number of noise?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2207">
<title id=" W05-1603.xml">ten years after an update on tg2 and friends </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a revival of template-based systems followed, and subsequent scientific discussions clarified the relation to more advanced nlg research themes.
</prevsent>
<prevsent>the papers in [becker and busemann, 1999] nicely show continuum between template- and plan?-based systems.
</prevsent>
</prevsection>
<citsent citstr=" W96-0411 ">
since its first implementation in 1995, the shallow nlg system tg/2 [busemann, 1996] <papid> W96-0411 </papid>has been used as component in several diverse applications involving nlg.</citsent>
<aftsection>
<nextsent>implemented in common lisp, tg/2 has continuously been refined over the years; java brother implementation, called xtragen, has eventually become available, and the grammar development environment egram eventually allows the grammar writer to design large-scale grammars.among the attractive properties of tg/2 is the quick development of new nlg applications with limited requirements on linguistic expressiveness.
</nextsent>
<nextsent>numerous implementations show that tg/2 is well suited for simple dialogues, report generation (from database content), and even as real izer for complex surface-semantic sentence representations.
</nextsent>
<nextsent>besides better understanding of the pros and cons of tg/2 has emerged.
</nextsent>
<nextsent>time has come to summarize these developments and, more generally, reassess the value of tg/2 as framework to specify generation systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2211">
<title id=" W05-1603.xml">ten years after an update on tg2 and friends </title>
<section> what tg/2 is and what it isnt.  </section>
<citcontext>
<prevsection>
<prevsent>we then describe in section 5 the need for, and the benefits of, the dedicated grammar development environment egram that supports the fast developments of large rule sets.
</prevsent>
<prevsent>the paper concludes with an outlook to upcoming work.
</prevsent>
</prevsection>
<citsent citstr=" W98-1425 ">
tg/2 has been described originally in [busemann, 1996;<papid> W96-0411 </papid>busemann and horacek, 1998] <papid> W98-1425 </papid>as template-based gener ator.</citsent>
<aftsection>
<nextsent>to remind the reader of the main points, tg/2 is aflexible production system [davis and king, 1977] that provides generic interpreter to separate set of user-defined condition-action rules representing the generation grammar.
</nextsent>
<nextsent>the generic task is to map content representation, which must be encoded as feature structure1, onto chain of terminal elements as defined by the rule set.
</nextsent>
<nextsent>the rules have context-free categorial backbone used for standard top-downderivation guided by the input representation.
</nextsent>
<nextsent>the rules specify conditions on the input ? the so-called test predicates ? that determine their applicability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2219">
<title id=" W05-1603.xml">ten years after an update on tg2 and friends </title>
<section> what tg/2 is and what it isnt.  </section>
<citcontext>
<prevsection>
<prevsent>while this insight resulted from comparing different systems, tg/2 implements this claim by forming single framework thatmay host any approach ranging from pure canned text to completely lexicon-based.
</prevsent>
<prevsent>as section 3 demonstrates, tg/2 can implement template-based systems and full-fledged realizers.
</prevsent>
</prevsection>
<citsent citstr=" A00-1017 ">
in an attempt to relate existing nlg systems to the rags framework [mellish et al, 2000], <papid> A00-1017 </papid>tg/2 was among the systems to look at.</citsent>
<aftsection>
<nextsent>it turned out that tg/2 differs from the principles underlying rags in that it does not support any of the levels of conceptual, semantic, rhetoric, document or syntactic representation, which were abstractly defined to capture many (most) nlg approaches.
</nextsent>
<nextsent>rather tg/2 entails single mapping from input to output, and any tasks generally ascribed to components delivering the above intermediate representations must be encoded by one or several productionrules.
</nextsent>
<nextsent>there is no pipeline of modules with intermediate representations, as ideally assumed in rags.
</nextsent>
<nextsent>rather all tasks need to be encoded within the production rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2239">
<title id=" W05-1603.xml">ten years after an update on tg2 and friends </title>
<section> grammar development.  </section>
<citcontext>
<prevsection>
<prevsent>with the musi grammar, adimension was reached that made dedicated grammar development environment necessary.
</prevsent>
<prevsent>while some abstraction from 5parameters should not depend on each other to guarantee that the best version is generated first, cf.
</prevsent>
</prevsection>
<citsent citstr=" W02-1713 ">
the discussion in[busemann, 1996, <papid> W96-0411 </papid>section 5].the lisp-like rule format was desirable, the java implementation xtragen [stenzhorn, 2002] <papid> W02-1713 </papid>required different format anyway, as it is consistently using xml to encode all objects.egram [busemann, 2004] was hence designed to developing grammars without bothering about their syntax or size or interpreting nlg system.</citsent>
<aftsection>
<nextsent>major benefits of egram include ? developer-friendly grammar format, ? syntactic and semantic checks of grammar knowledge,?
</nextsent>
<nextsent>the option to derive additional grammar rules by meta rules, and ? integration with grammar testing in generation systems.
</nextsent>
<nextsent>a major difficulty in the course of developing the musi grammar was to maintain consistency.
</nextsent>
<nextsent>features used are sometimes not defined, values are not sufficiently restricted, or certain categories do not occur in any other rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2240">
<title id=" W05-0621.xml">inferring semantic roles using subcategorization frames and maximum entropy model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we submitted our system for closed challenge at conll-2005 shared task.
</prevsent>
<prevsent>this task encourages participants to use novel machine learning techniques suited to the task of semantic role labelling.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
previous approaches on semantic role labelling can be classified into three categories (1) explicit probabilistic methods (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>(2) general machine learning algorithms (pradhan et al, 2003) (lim et al, 2004) <papid> W04-2419 </papid>and (3) generative model (thompson et al., 2003).our approach has two stages; first, identification whether the argument is mandatory or optional and second, the classification or labelling of the arguments.</nextsent>
<nextsent>in the first stage, the arguments of verb are put into three classes, (1) mandatory, (2) optional or (3) null.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2241">
<title id=" W05-0621.xml">inferring semantic roles using subcategorization frames and maximum entropy model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this task encourages participants to use novel machine learning techniques suited to the task of semantic role labelling.
</prevsent>
<prevsent>previous approaches on semantic role labelling can be classified into three categories (1) explicit probabilistic methods (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-2419 ">
(2) general machine learning algorithms (pradhan et al, 2003) (lim et al, 2004) <papid> W04-2419 </papid>and (3) generative model (thompson et al., 2003).our approach has two stages; first, identification whether the argument is mandatory or optional and second, the classification or labelling of the arguments.</citsent>
<aftsection>
<nextsent>in the first stage, the arguments of verb are put into three classes, (1) mandatory, (2) optional or (3) null.
</nextsent>
<nextsent>null stands for the fact that the constituent of the verb in the sentence is not an semantic argument of the verb.
</nextsent>
<nextsent>it is used to rule out the false argument of the verb which were obtained using the parser.
</nextsent>
<nextsent>the maximum entropy based classifier is used to classify the arguments into one of the above three labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2242">
<title id=" W06-1302.xml">multi domain spoken dialogue system with extensibility and robustness against speech recognition errors </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the third choice we newly introduced, our system can prevent dialogues from continuously being stuck in an erroneous domain.
</prevsent>
<prevsent>our experimental results, obtained with 10 subjects, showed that our method reduced the domain selection errors by 18.3%, compared to conventional method.
</prevsent>
</prevsection>
<citsent citstr=" N04-1028 ">
many spoken dialogue systems have been developed for various domains, including: flight reservations (levin et al, 2000; potamianos and kuo,2000; san-segundo et al, 2000), train travel information (lamel et al, 1999), and bus information (komatani et al, 2005b; raux and eskenazi,2004).<papid> N04-1028 </papid></citsent>
<aftsection>
<nextsent>since these systems only handle single domain, users must be aware of the limitations of these domains, which were defined by the system developer.
</nextsent>
<nextsent>to handle various domains through single interface, we have developed multi-domain spoken dialogue system, which is composed of several single-domain systems.
</nextsent>
<nextsent>the system can handle complicated tasks that contain requests across several domains.
</nextsent>
<nextsent>multi-domain spoken dialogue systems need to satisfy the following two requirements: (1) extensibility and (2) robustness against speech recognition errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2243">
<title id=" W05-0712.xml">an integrated approach for arabic english named entity translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the transliteration approach depends on phonetic transliteration and is only appropriate for out of vocabulary and completely unknown words.
</prevsent>
<prevsent>for more frequently used words, transliteration does not provide sophisticated results.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
a word based approach depends upon traditional statistical machine translation techniques such as ibm model1 (brown et al, 1993) <papid> J93-2003 </papid>and may not always yield satisfactory results due to its inability to handle difficult many-to-many phrase translations.</citsent>
<aftsection>
<nextsent>a phrase based approach could provide good translation for frequently used ne phrases though it is inefficient for less frequent words.
</nextsent>
<nextsent>each of the approaches has its advantages and disadvantages.
</nextsent>
<nextsent>in this paper we introduce an integrated approach for combining phrase based ne translation, word based ne translation, and ne transliteration in single framework.
</nextsent>
<nextsent>our approach attempts to harness the advantages of the three approaches while avoiding their pitfalls.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2244">
<title id=" W05-0712.xml">an integrated approach for arabic english named entity translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the named entity translation problem was previously addressed using two different approaches: named entity phrase translation (which includes word-based translation) and named entity transliteration.
</prevsent>
<prevsent>recently, many ne phrase translation approaches have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" W03-1502 ">
huang et al (huang et al, 2003) <papid> W03-1502 </papid>proposed an approach to extract ne trans-lingual equivalences based on the minimization of linearly combined multi-feature cost.</citsent>
<aftsection>
<nextsent>however this approach used bilingual dictionary to extract ne pairs and deployed it itera tively to extract more nes.
</nextsent>
<nextsent>moore (moore, 2003), proposed an approach deploying sequence of cost models.
</nextsent>
<nextsent>however this approach relies on orthographic clues, such as strings repeated in the source and target languages and capitalization, which are only suitable for language pairs with similar scripts and/or orthographic conventions.
</nextsent>
<nextsent>most prior work in arabic-related transliteration has been developed for the purpose of machine translation and for arabic-english transliteration in particular.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2245">
<title id=" W05-0712.xml">an integrated approach for arabic english named entity translation </title>
<section> integrated approach for named entity.  </section>
<citcontext>
<prevsection>
<prevsent>our system utilizes parallel corpus to separately acquire the phrases for the phrase based sys 88tem, the translation matrix for the word based system, and training data for the transliteration system.
</prevsent>
<prevsent>more details about the three systems will be presented in the next section.
</prevsent>
</prevsection>
<citsent citstr=" N04-1001 ">
initially, the corpus is automatically annotated with ne types in the source and target languages using ne identifiers similar to the systems described in (florian et al, 2004) <papid> N04-1001 </papid>for ne detection.</citsent>
<aftsection>
<nextsent>ules 4.1 word based ne translation.
</nextsent>
<nextsent>basic multi-cost ne alignment we introduce novel ne alignment technique to align nes from parallel corpus that has been automatically annotated with ne types for source and target languages.
</nextsent>
<nextsent>we use ibm model1, as introduced in (brown et. al, 1993), <papid> J93-2003 </papid>with modified alignment cost.</nextsent>
<nextsent>the cost function has some similarity with the multi-cost aligning approach introduced by huang (huang et al 2003) <papid> W03-1502 </papid>but it is significantly different.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2248">
<title id=" W05-0712.xml">an integrated approach for arabic english named entity translation </title>
<section> translation and transliteration mod-.  </section>
<citcontext>
<prevsection>
<prevsent>technique helps in reducing alignment errors due to identification errors by reducing the candidate words for alignment and thus reducing the aligner confusion.
</prevsent>
<prevsent>4.2 phrase based named entity transla-.
</prevsent>
</prevsection>
<citsent citstr=" W03-1001 ">
tion for phrase-based ne translation, we used an approach similar to that presented by tillman (till mann, 2003) <papid> W03-1001 </papid>for block generation with modifications suitable for ne phrase extraction.</citsent>
<aftsection>
<nextsent>a block is defined to be any pair of source and target phrases.
</nextsent>
<nextsent>this approach starts from word alignment generated by hmm viterbi training (vogel et. al, 1996), <papid> C96-2141 </papid>which is done in both directions between source and target.</nextsent>
<nextsent>the intersection of the two alignments is considered high precision alignment and the union is considered low precision alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2249">
<title id=" W05-0712.xml">an integrated approach for arabic english named entity translation </title>
<section> translation and transliteration mod-.  </section>
<citcontext>
<prevsection>
<prevsent>tion for phrase-based ne translation, we used an approach similar to that presented by tillman (till mann, 2003) <papid> W03-1001 </papid>for block generation with modifications suitable for ne phrase extraction.</prevsent>
<prevsent>a block is defined to be any pair of source and target phrases.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
this approach starts from word alignment generated by hmm viterbi training (vogel et. al, 1996), <papid> C96-2141 </papid>which is done in both directions between source and target.</citsent>
<aftsection>
<nextsent>the intersection of the two alignments is considered high precision alignment and the union is considered low precision alignment.
</nextsent>
<nextsent>the high precision alignments are used to generate high precision blocks which are further expanded using low precision alignments.
</nextsent>
<nextsent>the reader is referred to (tillmann, 2003) <papid> W03-1001 </papid>forde tailed description of the algorithm.</nextsent>
<nextsent>in our approach, for extracting ne blocks, we limited high precision alignments to ne phrases of the same ne types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2253">
<title id=" W05-0712.xml">an integrated approach for arabic english named entity translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we manually constructed test set as follows: 91 category no.
</prevsent>
<prevsent>of phrases no.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
of words person names 803 1749 organization names 312 867 location names 345 614 the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>with single reference translation was deployed for evalua tion.</citsent>
<aftsection>
<nextsent>bleu-3 which uses up to 3-grams is deployed since three words phrase is reasonable length for various ne types.
</nextsent>
<nextsent>table 1 reports the results for person names; the baseline system is general-purpose machine translation system with relatively good bleu score.
</nextsent>
<nextsent>system bleu score base line 0.2942 word based only 0.3254 word + phrase 0.4620 word + phrase + transliteration 0.5432 table 1: person names results table 2 reports the bleu score for location category with the same three systems presented before with persons: table 2: locations names results table 3 reports the bleu score for organization category with the same three systems presented before: system bleu score base line 0.2235 word based only 0.2541 word + phrase 0.3789 word + phrase + transliteration 0.3876 table 3: organizations names results figure 1, illustrates various bleu scores for various categories.
</nextsent>
<nextsent>the results indicate that phrase based translation provided enhancement for all ne types, while transliteration proved more effective for person names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2254">
<title id=" W05-0304.xml">parallel entity and treebank annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tree bank annotation has been modified from the penn treebank guidelines in various ways, such as greater structure for pre nominal modifiers.
</prevsent>
<prevsent>again, while this would have been done regardless of the mapping of entities, it does make such mapping more successful.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
previous work on integrating syntactic structure with entity information, as well as relation infor 21 mation, is described in (miller et al, 2000).<papid> A00-2030 </papid></citsent>
<aftsection>
<nextsent>our work is in much the same spirit, although we do not integrate relation annotation into the syntactic trees.
</nextsent>
<nextsent>pubmed abstracts are quite different from the newswire sources used in that earlier work, with several consequences discussed throughout, such as the use of discontinuous entities.
</nextsent>
<nextsent>section 2 discusses some of the main issues around the development of the guidelines for entity annotation, and section 3 discusses some of the changes that have been made for the treebank guidelines.
</nextsent>
<nextsent>section 4 describes the annotation workflow and the resulting merged representation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2255">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose thatvector-similarity between distribution vectors associated with an mwe as whole and those associated with its constitutent parts can serve as good measure of the degree to which the mwe is compositional.
</prevsent>
<prevsent>we present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
identifying non-compositional (or idiomatic) multi-word expressions (mwes) is an important subtask for any computational system (sag et al , 2002), and significant attention has been paid to practical methods for solving this problem in recent years (lin, 1999; <papid> P99-1041 </papid>baldwin et al , 2003; <papid> W03-1812 </papid>villada moiron and tiedemann, 2006).</citsent>
<aftsection>
<nextsent>whilecorpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (evert and krenn, 2001; <papid> P01-1025 </papid>evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (manning and schutze, 1999, ch.</nextsent>
<nextsent>5).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2256">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose thatvector-similarity between distribution vectors associated with an mwe as whole and those associated with its constitutent parts can serve as good measure of the degree to which the mwe is compositional.
</prevsent>
<prevsent>we present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
identifying non-compositional (or idiomatic) multi-word expressions (mwes) is an important subtask for any computational system (sag et al , 2002), and significant attention has been paid to practical methods for solving this problem in recent years (lin, 1999; <papid> P99-1041 </papid>baldwin et al , 2003; <papid> W03-1812 </papid>villada moiron and tiedemann, 2006).</citsent>
<aftsection>
<nextsent>whilecorpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (evert and krenn, 2001; <papid> P01-1025 </papid>evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (manning and schutze, 1999, ch.</nextsent>
<nextsent>5).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2257">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality.
</prevsent>
<prevsent>identifying non-compositional (or idiomatic) multi-word expressions (mwes) is an important subtask for any computational system (sag et al , 2002), and significant attention has been paid to practical methods for solving this problem in recent years (lin, 1999; <papid> P99-1041 </papid>baldwin et al , 2003; <papid> W03-1812 </papid>villada moiron and tiedemann, 2006).</prevsent>
</prevsection>
<citsent citstr=" P01-1025 ">
whilecorpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (evert and krenn, 2001; <papid> P01-1025 </papid>evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (manning and schutze, 1999, ch.</citsent>
<aftsection>
<nextsent>5).
</nextsent>
<nextsent>while expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (evert and krenn, 2001; <papid> P01-1025 </papid>evert and kermes, 2003), <papid> E03-1080 </papid>other techniques must be used to determining whether or not particular mwe does, in fact, have an idiomatic use.</nextsent>
<nextsent>in this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose one method for doing this.we characterize our task on analogy with word sense disambiguation (schutze, 1998; ide and veronis, 1998).<papid> J98-1001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2261">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>whilecorpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (evert and krenn, 2001; <papid> P01-1025 </papid>evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (manning and schutze, 1999, ch.</prevsent>
<prevsent>5).</prevsent>
</prevsection>
<citsent citstr=" E03-1080 ">
while expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (evert and krenn, 2001; <papid> P01-1025 </papid>evert and kermes, 2003), <papid> E03-1080 </papid>other techniques must be used to determining whether or not particular mwe does, in fact, have an idiomatic use.</citsent>
<aftsection>
<nextsent>in this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose one method for doing this.we characterize our task on analogy with word sense disambiguation (schutze, 1998; ide and veronis, 1998).<papid> J98-1001 </papid></nextsent>
<nextsent>as noted by schutze, wsd involves two related tasks: the general task of sense discrimination determining what senses given word hasand the more specific task of sense selection determining for particular use of the word in context which sense was in tended.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2262">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>5).
</prevsent>
<prevsent>while expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (evert and krenn, 2001; <papid> P01-1025 </papid>evert and kermes, 2003), <papid> E03-1080 </papid>other techniques must be used to determining whether or not particular mwe does, in fact, have an idiomatic use.</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
in this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose one method for doing this.we characterize our task on analogy with word sense disambiguation (schutze, 1998; ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>as noted by schutze, wsd involves two related tasks: the general task of sense discrimination determining what senses given word hasand the more specific task of sense selection determining for particular use of the word in context which sense was intended.
</nextsent>
<nextsent>for us the discrimination task involves determining forgiven expression whether it has non-compositional interpretation in addition toits compositional interpretation, and the selection task involves determining in given context,whether given expression is being used compositionally or non-compostionally.
</nextsent>
<nextsent>the german expression ins wasser fallen, for example, has non compositional interpretation on which it means tofail to happen?
</nextsent>
<nextsent>(as in (1)) and compositional interpretation on which it means to fall into water (as in (2)).1(1) das kind war beim baden von einer luftma tratze ins wasser gefallen.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2265">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>our hope is simply that this rough model is sufficient to the task of identifying non-compositional mwes.
</prevsent>
<prevsent>recent work which attempts to discriminate between compositional and non-compositionalmwes include lin (1999), <papid> P99-1041 </papid>who used mutual information measures identify such phrases, baldwin et al  (2003), <papid> W03-1812 </papid>who compare the distribution of the head of the mwe with the distribution ofthe entire mwe, and vallada moiron &amp; tiedemann (2006), who use word-alignment strategy to identify non-compositional mwes making use of parallel texts.</prevsent>
</prevsection>
<citsent citstr=" W01-0513 ">
schone &amp; jurafsky (2001) <papid> W01-0513 </papid>applied lsa to mwe identification, althought they did not focus on distinguishing compositional from non-compositional mwes.lins goal, like ours, was to discriminate non compositional mwes from compositional mwes.his method was to compare the mutual information measure of the constituents parts of an mwe with the mutual information of similar expressions obtained by substituting one of the constituents with related word obtained by thesaurus lookup.</citsent>
<aftsection>
<nextsent>the hope was that significant difference between these measures, as in the case of red tape (mutual information: 5.87) compared to yellow tape (3.75) or orange tape (2.64), would be characteristic of non-compositional mwes.
</nextsent>
<nextsent>although intuitively appealing, lins algorithm only achieves precision and recall of 15.7% and 13.7%, respectively (ascompared to gold standard generate from an idiom dictionary but see below for discussion).schone &amp; jurafsky (2001) <papid> W01-0513 </papid>evaluated number of co-occurrence-based metrics for identifying mwes, showing that, as suggested by lins results, there was need for improvement in this area.</nextsent>
<nextsent>since lsa has been used in number of meaning-related language tasks to good effect (landauer and dumais, 1997; landauer and psotka, 2000; cederberg and widdows, 2003), <papid> W03-0415 </papid>they had hoped to improve their results by identify non-compositional expressions using method similar to that which we are exploring here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2271">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the hope was that significant difference between these measures, as in the case of red tape (mutual information: 5.87) compared to yellow tape (3.75) or orange tape (2.64), would be characteristic of non-compositional mwes.
</prevsent>
<prevsent>although intuitively appealing, lins algorithm only achieves precision and recall of 15.7% and 13.7%, respectively (ascompared to gold standard generate from an idiom dictionary but see below for discussion).schone &amp; jurafsky (2001) <papid> W01-0513 </papid>evaluated number of co-occurrence-based metrics for identifying mwes, showing that, as suggested by lins results, there was need for improvement in this area.</prevsent>
</prevsection>
<citsent citstr=" W03-0415 ">
since lsa has been used in number of meaning-related language tasks to good effect (landauer and dumais, 1997; landauer and psotka, 2000; cederberg and widdows, 2003), <papid> W03-0415 </papid>they had hoped to improve their results by identify non-compositional expressions using method similar to that which we are exploring here.</citsent>
<aftsection>
<nextsent>although they do not demonstrate that this method actually identifies non-compositional expressions, they do show that the lsa similarity technique only improves mwe identification minimally.
</nextsent>
<nextsent>baldwin et al , (2003) <papid> W03-1812 </papid>focus more narrowly on distinguishing english noun-noun compound sand verb-particle constructions which are compositional from those which are not composi tional.</nextsent>
<nextsent>their approach is methodologically similar to ours, in that they compute similarity on the basis of contexts of occur rance, making use of lsa.their hypothesis is that high lsa-based similarity between the mwe and each of its constituent parts is indicative of compositionality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2273">
<title id=" W06-1203.xml">automatic identification of non compositional multiword expressions using latent semantic analysis </title>
<section> proceed ure.  </section>
<citcontext>
<prevsection>
<prevsent>our result of an average accurace of 72%for our lsa-based classifier far exceeds the simple maximum-likelihood baseline of 58%.
</prevsent>
<prevsent>in the final part of this experiment we compared the meaning vector that was computed by summing over all uses of ins wasser fallen with the literal and idiomatic vectors from above.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
since idiomatic uses of ins wasser fallen prevail in the corpus (2/3 vs. 1/3), it is not surprisingly that the similarity to the literal vector (0.0946) is much than similarity to the idiomatic vector (0.3712).to summarize experiment i, which is variant of supervised phrase sense disambiguation task, demonstrates that we can use lsa to distinguish between literal and the idiomatic usage of an mwe by using local linguistic context.4this was straightforward task; two annotators annotated independently, with very high agreement kappa scoreof over 0.95 (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>occurrences on which the annotators disagreed were thrown out.
</nextsent>
<nextsent>of the 64 occurrences we used, 37 were idiomatic and 27 were literal.
</nextsent>
<nextsent>3.2 experiment ii.
</nextsent>
<nextsent>in our second experiment we sought to make use of the fact that there are typically clear distributional difference between composition aland non-compositional uses of mwes to determine whether given mwe indeed has non compositional uses at all.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2279">
<title id=" W06-0101.xml">improving context vector models by feature clustering for automatic thesaurus construction </title>
<section> conventional approaches for auto-.  </section>
<citcontext>
<prevsection>
<prevsent>= == ? = === = 1k yktf itfxiq}, n,...q 2q, 1{q wordy 1k ktf itfxip}, n,...p 2p, 1{pwordx pthen calculate the distance between probabilistic vectors by sums up the all probabilistic difference among each context word so called cross entropy.
</prevsent>
<prevsent>due to the original kl distance is asymmetric and is not defined when zero frequency occurs.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
some enhanced kl models were developed to prevent these problems such as jensen-shannon (jianhua, 1991), which introducing probabilistic variable m, or ? -skew divergence (lee, 1999), <papid> P99-1004 </papid>by adopting adjustable variable ?.</citsent>
<aftsection>
<nextsent>research shows that skew divergence achieves better performance than other measures.
</nextsent>
<nextsent>(lee, 2001) ))1(||(yxs rgence)d(skewdive yxxkl aaa -+== 2/)( ,2/)}||()||({y)x,(js shannon)-d(jensen yxm myklmxkl += +== to convert distance to similarity value, we adopt the formula inspired by mochihashi, and matsumoto 2002.
</nextsent>
<nextsent>2.3 organize similar words into thesaurus.
</nextsent>
<nextsent>there are several clustering methods can be used to cluster similar words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2280">
<title id=" W06-0101.xml">improving context vector models by feature clustering for automatic thesaurus construction </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>as well as, na and nb are the numbers of correct labeled pairs in synonyms and unrelated words.
</prevsent>
<prevsent>4.2 nonlinear interpolated precision.
</prevsent>
</prevsection>
<citsent citstr=" N03-1036 ">
the nap evaluation is used to measure the performance of restoring words to taxonomy, similar task of restoring words in wordnet (dominic widdows, 2003).<papid> N03-1036 </papid></citsent>
<aftsection>
<nextsent>the way we adopted nap evaluation is to reconstruct partial chinese synonym set, and measure the structure resemblance between original synonyms and the reconstructed one.
</nextsent>
<nextsent>by doing so, one has to prepare certain number of synonyms sets from chinese taxonomy, and try to reclassify these words.
</nextsent>
<nextsent>assume there are testing words distributed in synonyms sets.
</nextsent>
<nextsent>let i1r stands for the represented word of the ith synonyms set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2281">
<title id=" W06-0607.xml">manual annotation of opinion categories in meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>2) social interactions may constrain how openly people express their opinions; i.e., they are often indirect in their negative evaluations.
</prevsent>
<prevsent>we also explore the influence of speech on human perception of opinions.
</prevsent>
</prevsection>
<citsent citstr=" W05-0308 ">
specifically, we annotated some meeting data with the opinion categories sentiment and arguing as defined in wilson and wiebe (2005).<papid> W05-0308 </papid></citsent>
<aftsection>
<nextsent>in our annotation we first distinguish whether sentiment or arguing is being expressed.
</nextsent>
<nextsent>if one is, we then mark the polarity (i.e., positive or negative) and the intensity (i.e., how strong the opinion is).
</nextsent>
<nextsent>annotating the individual opinion expressions is useful in this genre, because we see many utterances that have more than one type of opinion (e.g.
</nextsent>
<nextsent>(3) above).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2291">
<title id=" W06-0607.xml">manual annotation of opinion categories in meetings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they define their annotations as an experiencer having some type of attitude (such as sentiment or arguing), of certain intensity, towards target.
</prevsent>
<prevsent>wilson and wiebe (2005) <papid> W05-0308 </papid>extend this basic annotation scheme to include different types of subjectivity, including positive sentiment, negative sentiment, positive arguing, and negative arguing.</prevsent>
</prevsection>
<citsent citstr=" P96-1038 ">
speech was found to improve inter-annotator agreement in discourse segmentation of mono logs (hirschberg and nakatani 1996).<papid> P96-1038 </papid></citsent>
<aftsection>
<nextsent>acoustic clues have been successfully employed for the reliable detection of the speakers emotions, including frustration, annoyance, anger, happiness, sadness, and boredom (liscombe et al  2003).
</nextsent>
<nextsent>devillers et al  (2003) performed perceptual tests with and without speech in detecting the speakers fear, anger, satisfaction and embarrassment.
</nextsent>
<nextsent>though related, our work is not concerned with the speakers emotions, but rather opinions toward the issues and topics addressed in the meeting.
</nextsent>
<nextsent>most annotation work in multiparty conversation has focused on exchange structures and discourse functional units like common grounding (nakatani and traum, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2292">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this section reviews previous works in both sentiment detection and semantic role labeling.
</prevsent>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></citsent>
<aftsection>
<nextsent>identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></nextsent>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2293">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this section reviews previous works in both sentiment detection and semantic role labeling.
</prevsent>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
</prevsection>
<citsent citstr=" C00-1044 ">
subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></citsent>
<aftsection>
<nextsent>identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></nextsent>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2294">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this section reviews previous works in both sentiment detection and semantic role labeling.
</prevsent>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
</prevsection>
<citsent citstr=" W03-0404 ">
subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></citsent>
<aftsection>
<nextsent>identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></nextsent>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2295">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
<prevsent>subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.
</nextsent>
<nextsent>(bethard et al, 2004) identify opinion propositions and holders.
</nextsent>
<nextsent>their 1 http://framenet.icsi.berkeley.edu/ work is similar to ours but different because their opinion is restricted to propositional opinion and mostly to verbs.
</nextsent>
<nextsent>another related works are (choi et al, 2005; <papid> H05-1045 </papid>kim and hovy, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2296">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
<prevsent>subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.
</nextsent>
<nextsent>(bethard et al, 2004) identify opinion propositions and holders.
</nextsent>
<nextsent>their 1 http://framenet.icsi.berkeley.edu/ work is similar to ours but different because their opinion is restricted to propositional opinion and mostly to verbs.
</nextsent>
<nextsent>another related works are (choi et al, 2005; <papid> H05-1045 </papid>kim and hovy, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2297">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
<prevsent>subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1200 ">
identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.
</nextsent>
<nextsent>(bethard et al, 2004) identify opinion propositions and holders.
</nextsent>
<nextsent>their 1 http://framenet.icsi.berkeley.edu/ work is similar to ours but different because their opinion is restricted to propositional opinion and mostly to verbs.
</nextsent>
<nextsent>another related works are (choi et al, 2005; <papid> H05-1045 </papid>kim and hovy, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2298">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
<prevsent>subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.
</nextsent>
<nextsent>(bethard et al, 2004) identify opinion propositions and holders.
</nextsent>
<nextsent>their 1 http://framenet.icsi.berkeley.edu/ work is similar to ours but different because their opinion is restricted to propositional opinion and mostly to verbs.
</nextsent>
<nextsent>another related works are (choi et al, 2005; <papid> H05-1045 </papid>kim and hovy, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2299">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 subjectivity and sentiment detection.
</prevsent>
<prevsent>subjectivity detection is the task of identifying subjective words, expressions, and sentences (wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>riloff et al, 2003).<papid> W03-0404 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. sentiment detection is the task of determining positive or negative sentiment of words (hat zivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney, 2002; <papid> P02-1053 </papid>esuli and sebastiani, 2005), phrases and sentences (kim and hovy, 2004; <papid> C04-1200 </papid>wilson et al, 2005), <papid> H05-1044 </papid>or documents (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>building on this work, more sophisticated problems such as opinion holder identification have also been studied.
</nextsent>
<nextsent>(bethard et al, 2004) identify opinion propositions and holders.
</nextsent>
<nextsent>their 1 http://framenet.icsi.berkeley.edu/ work is similar to ours but different because their opinion is restricted to propositional opinion and mostly to verbs.
</nextsent>
<nextsent>another related works are (choi et al, 2005; <papid> H05-1045 </papid>kim and hovy, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2301">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(bethard et al, 2004) identify opinion propositions and holders.
</prevsent>
<prevsent>their 1 http://framenet.icsi.berkeley.edu/ work is similar to ours but different because their opinion is restricted to propositional opinion and mostly to verbs.
</prevsent>
</prevsection>
<citsent citstr=" H05-1045 ">
another related works are (choi et al, 2005; <papid> H05-1045 </papid>kim and hovy, 2005).</citsent>
<aftsection>
<nextsent>both of them use the mpqa corpus 2 but they only identify opinion holders, not topics.
</nextsent>
<nextsent>as for opinion topic identification, little research has been conducted, and only in very limited domain, product reviews.
</nextsent>
<nextsent>(hu and liu, 2004; popescu and etzioni, 2005) <papid> H05-1043 </papid>present product mining algorithms with extracting certain product features given specific product types.</nextsent>
<nextsent>our paper aims at extracting topics of opinion in general news media text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2302">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>both of them use the mpqa corpus 2 but they only identify opinion holders, not topics.
</prevsent>
<prevsent>as for opinion topic identification, little research has been conducted, and only in very limited domain, product reviews.
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
(hu and liu, 2004; popescu and etzioni, 2005) <papid> H05-1043 </papid>present product mining algorithms with extracting certain product features given specific product types.</citsent>
<aftsection>
<nextsent>our paper aims at extracting topics of opinion in general news media text.
</nextsent>
<nextsent>2.2 semantic role labeling.
</nextsent>
<nextsent>semantic role labeling is the task of identifying semantic roles such as agent, patient, speaker, or topic, in sentence.
</nextsent>
<nextsent>a statistical approach for semantic role labeling was introduced by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2303">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 semantic role labeling.
</prevsent>
<prevsent>semantic role labeling is the task of identifying semantic roles such as agent, patient, speaker, or topic, in sentence.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
a statistical approach for semantic role labeling was introduced by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>their system learned semantic relationship among constituents in sentence from framenet, large corpus of semantically hand-annotated data.
</nextsent>
<nextsent>the framenet annotation scheme is based on frame semantics (fill more, 1976).
</nextsent>
<nextsent>frames are defined as schematic representations of situations involving various frame elements such as participants, props, and other conceptual roles.?
</nextsent>
<nextsent>for example, given sentence jack built new house out of bricks?, semantic role labeling system should identify the roles for the verb built such as ?[agent jack] built [created_entity new house] [component out of bricks]3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2306">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> finding opinions and their holders.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 semantic role labeling.
</prevsent>
<prevsent>to find potential holder and topic of an opinion word in sentence, we first label semantic roles in sentence.
</prevsent>
</prevsection>
<citsent citstr=" W03-1007 ">
modeling: we follow the statistical approaches for semantic role labeling (gildea and jurafsky, 2002; <papid> J02-3001 </papid>fleischman et. al, 2003) <papid> W03-1007 </papid>which separate the task into two steps: identify candidates of frame elements (step 1) and assign semantic roles for those candidates (step 2).</citsent>
<aftsection>
<nextsent>like their intuition, we treated both steps as classification problems.
</nextsent>
<nextsent>we first collected all constituents of the given sentence by parsing it using the charniak parser.
</nextsent>
<nextsent>then, in step 1, we classified candidate constituents of frame elements from non-candidates.
</nextsent>
<nextsent>in step 2, each selected candidate was thus classified into one of frame element types (e.g. stimulus, degree, experiencer, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2307">
<title id=" W06-0301.xml">extracting opinions opinion holders and topics expressed in online news media text </title>
<section> finding opinions and their holders.  </section>
<citcontext>
<prevsection>
<prevsent>then, in step 1, we classified candidate constituents of frame elements from non-candidates.
</prevsent>
<prevsent>in step 2, each selected candidate was thus classified into one of frame element types (e.g. stimulus, degree, experiencer, etc.).
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
as learning algorithm for our classification model, we used maximum entropy (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>for system development, we used mega model optimization package6, an implementation of me models.
</nextsent>
<nextsent>data: we collected 8256 and 11877 sentences which were associated to opinion bearing frames for verbs and adjectives from framenet annotation data.
</nextsent>
<nextsent>each sentence in our dataset contained frame name, target predicate (a word whose meaning represents aspects of the frame), and frame elements labeled with element types.
</nextsent>
<nextsent>we divided the data into 90% for training and 10% for test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2308">
<title id=" W05-1008.xml">bootstrapping deep lexical resources resources for courses </title>
<section> task outline.  </section>
<citcontext>
<prevsection>
<prevsent>crucially, we investigate only lrs which we believe to be plausibly available for languages of varying density, and aim to minimise assumptions as to the pre-existence of particular preprocessing tools.
</prevsent>
<prevsent>the basic types of resources and tools we experiment with in this paper are detailed in table 1.past research on dla falls into two basic cat egories: expert system-style dla customised to learning particular linguistic properties, and dlavia resource translation.
</prevsent>
</prevsection>
<citsent citstr=" W03-1010 ">
in the first instance, specialised methodology is proposed to (automatically) learn particular linguistic property such as verb subcategorisation (e.g. korhonen (2002)) or noun count ability (e.g. baldwin and bond (2003<papid> W03-1010 </papid>a)), and little consideration is given to the applicability of that method to more general linguistic properties.</citsent>
<aftsection>
<nextsent>in the second instance, we take one dlr and map it onto another to arrive at the lexical information inthe desired format.
</nextsent>
<nextsent>this can take the form of one step process, in mining lexical items directly froma dlr (e.g. machine-readable dictionary (sanfil ippo and poznanski, 1992)), <papid> A92-1011 </papid>or two-step process in reusing an existing system to learn lexical properties in one format and then mapping this onto the dlrof choice (e.g. carroll and fang (2004) for verb subcategorisation learning).there have also been instances of more general methods for dla, aligned more closely with this research.</nextsent>
<nextsent>fouvry (2003) proposed method of token-based dla for unification-based precision grammars, whereby partially-specified lexical features generated via the constraints of syntactically interacting words in given sentence context, are combined to form consolidated lexical entry forthat word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2314">
<title id=" W05-1008.xml">bootstrapping deep lexical resources resources for courses </title>
<section> task outline.  </section>
<citcontext>
<prevsection>
<prevsent>in the first instance, specialised methodology is proposed to (automatically) learn particular linguistic property such as verb subcategorisation (e.g. korhonen (2002)) or noun count ability (e.g. baldwin and bond (2003<papid> W03-1010 </papid>a)), and little consideration is given to the applicability of that method to more general linguistic properties.</prevsent>
<prevsent>in the second instance, we take one dlr and map it onto another to arrive at the lexical information inthe desired format.</prevsent>
</prevsection>
<citsent citstr=" A92-1011 ">
this can take the form of one step process, in mining lexical items directly froma dlr (e.g. machine-readable dictionary (sanfil ippo and poznanski, 1992)), <papid> A92-1011 </papid>or two-step process in reusing an existing system to learn lexical properties in one format and then mapping this onto the dlrof choice (e.g. carroll and fang (2004) for verb subcategorisation learning).there have also been instances of more general methods for dla, aligned more closely with this research.</citsent>
<aftsection>
<nextsent>fouvry (2003) proposed method of token-based dla for unification-based precision grammars, whereby partially-specified lexical features generated via the constraints of syntactically interacting words in given sentence context, are combined to form consolidated lexical entry forthat word.
</nextsent>
<nextsent>that is, rather than relying on indirect feature signatures to perform lexical acquisition,the dlr itself drives the incremental learning process.
</nextsent>
<nextsent>also somewhat related to this research is the general-purpose verb feature set proposed by joanisand stevenson (2003), <papid> E03-1040 </papid>which is shown to be applicable in range of dla tasks relating to english verbs.</nextsent>
<nextsent>2.1 english resource grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2315">
<title id=" W05-1008.xml">bootstrapping deep lexical resources resources for courses </title>
<section> task outline.  </section>
<citcontext>
<prevsection>
<prevsent>fouvry (2003) proposed method of token-based dla for unification-based precision grammars, whereby partially-specified lexical features generated via the constraints of syntactically interacting words in given sentence context, are combined to form consolidated lexical entry forthat word.
</prevsent>
<prevsent>that is, rather than relying on indirect feature signatures to perform lexical acquisition,the dlr itself drives the incremental learning process.
</prevsent>
</prevsection>
<citsent citstr=" E03-1040 ">
also somewhat related to this research is the general-purpose verb feature set proposed by joanisand stevenson (2003), <papid> E03-1040 </papid>which is shown to be applicable in range of dla tasks relating to english verbs.</citsent>
<aftsection>
<nextsent>2.1 english resource grammar.
</nextsent>
<nextsent>all experiments in this paper are targeted at the english resource grammar (erg; flickinger (2002), copestake and flickinger (2000)).
</nextsent>
<nextsent>the erg is an implemented open-source broad-coverage precision head-driven phrase structure grammar 68 secondary lr type description preprocessor(s) word list???
</nextsent>
<nextsent>list of words with basic pos ? morphological lexicon?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2328">
<title id=" W05-1008.xml">bootstrapping deep lexical resources resources for courses </title>
<section> syntax-based deep lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>2).8 4.1 tagging.
</prevsent>
<prevsent>the first and most basic form of syntactic preprocessing is part-of-speech (pos) tagging.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
for our purposes, we use penn treebank-style tagger custom-built using fntbl 1.0 (ngai and florian, 2001), <papid> N01-1006 </papid>and further lemmatise the output of the tagger using morph (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>8note that we will have less than 50 feature instances for some feature types, e.g. the pos tag of the target word, given that the combined size of the penn pos tagset is 36 elements (not including punctuation).
</nextsent>
<nextsent>the feature types used with the tagger are detailed in table 2, where the position indices are relative to the target word (e.g. the word at position 2 is two words to the left of the target word, and the pos tag at position 0 is the pos of the target word).
</nextsent>
<nextsent>all features are relative to the pos tags and words in the immediate context of each token occurrence of the target word.
</nextsent>
<nextsent>bi-words?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2329">
<title id=" W05-1008.xml">bootstrapping deep lexical resources resources for courses </title>
<section> syntax-based deep lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>2).8 4.1 tagging.
</prevsent>
<prevsent>the first and most basic form of syntactic preprocessing is part-of-speech (pos) tagging.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
for our purposes, we use penn treebank-style tagger custom-built using fntbl 1.0 (ngai and florian, 2001), <papid> N01-1006 </papid>and further lemmatise the output of the tagger using morph (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>8note that we will have less than 50 feature instances for some feature types, e.g. the pos tag of the target word, given that the combined size of the penn pos tagset is 36 elements (not including punctuation).
</nextsent>
<nextsent>the feature types used with the tagger are detailed in table 2, where the position indices are relative to the target word (e.g. the word at position 2 is two words to the left of the target word, and the pos tag at position 0 is the pos of the target word).
</nextsent>
<nextsent>all features are relative to the pos tags and words in the immediate context of each token occurrence of the target word.
</nextsent>
<nextsent>bi-words?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2330">
<title id=" W05-1008.xml">bootstrapping deep lexical resources resources for courses </title>
<section> syntax-based deep lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>see table 2 for full details.
</prevsent>
<prevsent>4.4 corpora.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we ran the three syntactic pre processors over total of three corpora, of varying size: the brown corpus (460k tokens) and wall street journal corpus(1.2m tokens), both derived from the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>and the written component of the british national corpus (98m tokens: burnard (2000)).</citsent>
<aftsection>
<nextsent>this selection is intended to model the effects of variation in corpus size, to investigate how well we could expect syntax-based dla methods to perform over both smaller and larger corpora.
</nextsent>
<nextsent>note that the only corpus annotation we make useof is sentence token isation, and that all pre proces sors are run automatically over the raw corpus data.
</nextsent>
<nextsent>this is in an attempt to make the methods maximally applicable to lower-density languages where annotated corpora tend not to exist but there is at least the possibility of accessing raw text collections.
</nextsent>
<nextsent>acquisition the final dla method we explore is based on the hypothesis that there is strong correlation between the semantic and syntactic similarity of words, claim which is best exemplified in the work of levin (1993) on dia thesis alternations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2331">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>theuse of machine-learning to solve such tasks facilitates building complex applications out of many light components.
</prevsent>
<prevsent>the architecture of choice forsuch systems has become pipeline, with strict ordering of the processing stages.
</prevsent>
</prevsection>
<citsent citstr=" A97-1035 ">
an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</citsent>
<aftsection>
<nextsent>sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</nextsent>
<nextsent>we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2332">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the architecture of choice forsuch systems has become pipeline, with strict ordering of the processing stages.
</prevsent>
<prevsent>an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</prevsent>
</prevsection>
<citsent citstr=" W94-0319 ">
sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</citsent>
<aftsection>
<nextsent>we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></nextsent>
<nextsent>whereas roth and yih used optimization to solve two tasks only, and punyakanok et aland althaus et al focused on single task, we propose general formulation capable of combining large number of different nlp tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2333">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the architecture of choice forsuch systems has become pipeline, with strict ordering of the processing stages.
</prevsent>
<prevsent>an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</prevsent>
</prevsection>
<citsent citstr=" W99-0629 ">
sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</citsent>
<aftsection>
<nextsent>we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></nextsent>
<nextsent>whereas roth and yih used optimization to solve two tasks only, and punyakanok et aland althaus et al focused on single task, we propose general formulation capable of combining large number of different nlp tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2334">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the architecture of choice forsuch systems has become pipeline, with strict ordering of the processing stages.
</prevsent>
<prevsent>an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</citsent>
<aftsection>
<nextsent>we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></nextsent>
<nextsent>whereas roth and yih used optimization to solve two tasks only, and punyakanok et aland althaus et al focused on single task, we propose general formulation capable of combining large number of different nlp tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2335">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</prevsent>
<prevsent>sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></citsent>
<aftsection>
<nextsent>whereas roth and yih used optimization to solve two tasks only, and punyakanok et aland althaus et al focused on single task, we propose general formulation capable of combining large number of different nlp tasks.
</nextsent>
<nextsent>we apply the proposed model to solving numerous tasks in the generation process and compare it with two pipeline-based systems.
</nextsent>
<nextsent>the paper is structured as follows: in section 2 we discuss the use of classifiers for handling nlp tasks and point to the limitations of pipeline processing.in section 3 we present general discrete optimization model whose application in nlg is described in section 4.
</nextsent>
<nextsent>finally, in section 5 we report on the experiments and evaluation of our approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2336">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</prevsent>
<prevsent>sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></citsent>
<aftsection>
<nextsent>whereas roth and yih used optimization to solve two tasks only, and punyakanok et aland althaus et al focused on single task, we propose general formulation capable of combining large number of different nlp tasks.
</nextsent>
<nextsent>we apply the proposed model to solving numerous tasks in the generation process and compare it with two pipeline-based systems.
</nextsent>
<nextsent>the paper is structured as follows: in section 2 we discuss the use of classifiers for handling nlp tasks and point to the limitations of pipeline processing.in section 3 we present general discrete optimization model whose application in nlg is described in section 4.
</nextsent>
<nextsent>finally, in section 5 we report on the experiments and evaluation of our approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2337">
<title id=" W05-0618.xml">beyond the pipeline discrete optimization in nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example ofa generic pipeline architecture is gate (cunning ham et al, 1997) <papid> A97-1035 </papid>which provides an infrastructure for building nlp applications.</prevsent>
<prevsent>sequential processing has also been used in several nlg systems (e.g. reiter (1994), <papid> W94-0319 </papid>reiter &amp; dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g. buchholz et al (1999), <papid> W99-0629 </papid>soon et al (2001)).<papid> J01-4004 </papid>in this paper we address the problem of aggregating the outputs of classifiers solving different nlp tasks.</prevsent>
</prevsection>
<citsent citstr=" P04-1051 ">
we compare pipeline-based processing with discrete optimization modeling used in the field of computervision and image recognition (kleinberg &amp; tardos, 2000; chekuri et al, 2001) and recently applied in nlp by roth &amp; yih (2004), <papid> W04-2401 </papid>punyakanok et al (2004) <papid> C04-1197 </papid>and althaus et al (2004).<papid> P04-1051 </papid></citsent>
<aftsection>
<nextsent>whereas roth and yih used optimization to solve two tasks only, and punyakanok et aland althaus et al focused on single task, we propose general formulation capable of combining large number of different nlp tasks.
</nextsent>
<nextsent>we apply the proposed model to solving numerous tasks in the generation process and compare it with two pipeline-based systems.
</nextsent>
<nextsent>the paper is structured as follows: in section 2 we discuss the use of classifiers for handling nlp tasks and point to the limitations of pipeline processing.in section 3 we present general discrete optimization model whose application in nlg is described in section 4.
</nextsent>
<nextsent>finally, in section 5 we report on the experiments and evaluation of our approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2342">
<title id=" W04-3244.xml">learning nonstructural distance metric by minimum cluster distortions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generally, two basic approaches exist to compare two expressions: (a) structural and (b) nonstructural.
</prevsent>
<prevsent>structural approaches make use of syntactic parsing or dependency analysis to make rigorous comparison; nonstructural approaches use vector representation and provide rough but fast comparison that is required for search/retrieval from vast amount of corpora.
</prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
while structural approaches have recently become available in kernel-based sophisticated treatment (collins and duffy, 2001;suzuki et al, 2003), <papid> P03-1005 </papid>here we concentrate on nonstructural comparison.</citsent>
<aftsection>
<nextsent>this is not only because nonstructural comparison constitutes an integral partin structural methods (that is, even in hierarchical methods the leaf comparison is still atomic),but because it is frequently embedded in many applications where structural par sings are not available or computationally too expensive.
</nextsent>
<nextsent>for example, information retrieval has long used the bag of words?
</nextsent>
<nextsent>approach (baeza-yates and ribeiro-neto,1999; schutze, 1992) mainly due to lack of scalable segmentation algorithms and the huge amount of data involved.
</nextsent>
<nextsent>while segmentation algorithms, such as text tiling (hearst, 1994) <papid> P94-1002 </papid>and its recent successors using the inter-paragraph similarity matrix (choi, 2000), <papid> A00-2004 </papid>all themselves use nonstructuralcosine similarity as measure of semantic proximity between paragraphs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2343">
<title id=" W04-3244.xml">learning nonstructural distance metric by minimum cluster distortions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, information retrieval has long used the bag of words?
</prevsent>
<prevsent>approach (baeza-yates and ribeiro-neto,1999; schutze, 1992) mainly due to lack of scalable segmentation algorithms and the huge amount of data involved.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
while segmentation algorithms, such as text tiling (hearst, 1994) <papid> P94-1002 </papid>and its recent successors using the inter-paragraph similarity matrix (choi, 2000), <papid> A00-2004 </papid>all themselves use nonstructuralcosine similarity as measure of semantic proximity between paragraphs.</citsent>
<aftsection>
<nextsent>however, the distance function so far has been largely defined and used ad hoc, usually by tf.idf weighting scheme (salton and yang, 1973) and simple cosine similarity, equivalently, an euclidean dot product.
</nextsent>
<nextsent>in this paper, we propose an optimal distance function that is parameterized by global metric matrix.
</nextsent>
<nextsent>this metric is optimal in the sense of global quadratic minimization, and can be learned from the given clusters in the training data.
</nextsent>
<nextsent>these clusters are often attributable with many forms, such as paragraphs, documents or document collections,as long as the items in the training data are not completely independent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2344">
<title id=" W04-3244.xml">learning nonstructural distance metric by minimum cluster distortions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, information retrieval has long used the bag of words?
</prevsent>
<prevsent>approach (baeza-yates and ribeiro-neto,1999; schutze, 1992) mainly due to lack of scalable segmentation algorithms and the huge amount of data involved.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
while segmentation algorithms, such as text tiling (hearst, 1994) <papid> P94-1002 </papid>and its recent successors using the inter-paragraph similarity matrix (choi, 2000), <papid> A00-2004 </papid>all themselves use nonstructuralcosine similarity as measure of semantic proximity between paragraphs.</citsent>
<aftsection>
<nextsent>however, the distance function so far has been largely defined and used ad hoc, usually by tf.idf weighting scheme (salton and yang, 1973) and simple cosine similarity, equivalently, an euclidean dot product.
</nextsent>
<nextsent>in this paper, we propose an optimal distance function that is parameterized by global metric matrix.
</nextsent>
<nextsent>this metric is optimal in the sense of global quadratic minimization, and can be learned from the given clusters in the training data.
</nextsent>
<nextsent>these clusters are often attributable with many forms, such as paragraphs, documents or document collections,as long as the items in the training data are not completely independent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2345">
<title id=" W05-1002.xml">verb subcategorization kernels for automatic semantic labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the semantic shallow information embodied by the verbal predicate to rent and its three arguments: arg0, arg1 and argm.
</prevsent>
<prevsent>the scf of such verb, i.e.np-pp, provides synthesis of the predicate argument structure.currently, the systems which aim to derive semantic shallow information from texts recognize the scf of target verb and represent it as flat feature (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
(xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al , 2004))in the learning algorithm.</citsent>
<aftsection>
<nextsent>to achieve this goal, lexicon which describes the scfs for each verb, is required.
</nextsent>
<nextsent>such resource is difficult to find especially for specific domains, thus, several methods to automatically extract scf have been proposed (korho nen, 2003).
</nextsent>
<nextsent>in (moschitti, 2004), <papid> P04-1043 </papid>an alternative tothe scf extraction was proposed, i.e. the scf kernel (sk).</nextsent>
<nextsent>the subcategorization frame of verbs was implicitly represented by means of the syntactic subtrees which include the predicate with its arguments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2346">
<title id=" W05-1002.xml">verb subcategorization kernels for automatic semantic labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to achieve this goal, lexicon which describes the scfs for each verb, is required.
</prevsent>
<prevsent>such resource is difficult to find especially for specific domains, thus, several methods to automatically extract scf have been proposed (korho nen, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
in (moschitti, 2004), <papid> P04-1043 </papid>an alternative tothe scf extraction was proposed, i.e. the scf kernel (sk).</citsent>
<aftsection>
<nextsent>the subcategorization frame of verbs was implicitly represented by means of the syntactic subtrees which include the predicate with its arguments.
</nextsent>
<nextsent>the similarity between such syntactic structures was evaluated by means of convolution kernels.convolution kernels are machine learning approaches which aim to describe structured data in 10 terms of its substructures.
</nextsent>
<nextsent>the similarity between two structures is carried out by kernel functions which determine the number of common substructures without evaluating the overall substructure space.
</nextsent>
<nextsent>thus, if we associate two scfs with two subtrees, we can measure their similarity with such functions applied to the two trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2348">
<title id=" W05-1002.xml">verb subcategorization kernels for automatic semantic labeling </title>
<section> parsing of semantic roles and semantic.  </section>
<citcontext>
<prevsection>
<prevsent>for example, assuming that attach is the target word and attaching is the target frame, typical sentence annotation is the following.
</prevsent>
<prevsent>[agent they] attachtgt [item themselves] [connector with their mouthparts] and then release digestive enzyme secretion which eats into the skin.several machine learning approaches for argument identification and classification have been developed, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W03-1008 ">
(gildea and jurasfky, 2002; gildea and palmer, ; gildea and hockenmaier, 2003; <papid> W03-1008 </papid>pradhan etal., 2004).</citsent>
<aftsection>
<nextsent>their common characteristic is the adoption of feature spaces that model predicate-argument structures in flat feature representation.
</nextsent>
<nextsent>in the next section we present the common parse tree-based approach to this problem.
</nextsent>
<nextsent>2.1 predicate argument extraction.
</nextsent>
<nextsent>given sentence in natural language, all the predicates associated with the verbs have to be identified 11 along with their arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2355">
<title id=" W05-1002.xml">verb subcategorization kernels for automatic semantic labeling </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>and sk.
</prevsent>
<prevsent>for the experiments we adopted two corpora propbank (pb) and framenet (fn).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
pb, available at www.cis.upenn.edu/ace, is used along with the penn treebank 2 (www.cis.upenn.edu /treebank) (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>this corpus contains about 53,700 sentences and fixed split between training and testing which has been used in other researches, e.g.
</nextsent>
<nextsent>(pradhan et al , 2004; gildea and palmer, ).
</nextsent>
<nextsent>in this split, sections from 02 to 21are used for training, section 23 for testing and sections 1 and 22 as development set.
</nextsent>
<nextsent>we considered all 12 arguments from arg0 to arg9, arga and argm fora total of 123,918 and 7,426 arguments in the training and test sets, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2356">
<title id=" W05-1002.xml">verb subcategorization kernels for automatic semantic labeling </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>only verbs are selected to be predicates in our evaluations.
</prevsent>
<prevsent>moreover, as there isno fixed split between training and testing, we randomly selected 30% of the sentences for testing and 30% for validation-set, respectively.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
both training and testing sentences were processed using collins parser (collins, 1997) <papid> P97-1003 </papid>to generate parse-tree auto matically.</citsent>
<aftsection>
<nextsent>this means that our shallow semantic parser for framenet is fully automated.
</nextsent>
<nextsent>4.1 the classification set-up.
</nextsent>
<nextsent>the evaluations were carried out with the svm light-tk software (moschitti, 2004) <papid> P04-1043 </papid>available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes the tree kernels in the svm-light software (joachims, 1999).the classification performance was measured using the f1 measure4 for the individual arguments and the accuracy for the final multi-class classifier.</nextsent>
<nextsent>this latter choice allows us to compare the results 3we mapped together roles having the same name 4f1 assigns equal importance to precision and recall r, i.e. f1 = 2prp+r . 14 with previous literature works, e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2361">
<title id=" W05-1210.xml">definition and analysis of intermediate entailment levels </title>
<section> definition of entailment levels.  </section>
<citcontext>
<prevsection>
<prevsent>57entailment paraphrases this inference mechanism refers to transformations that modify the syntactic structure of text fragment as well as some of its lexical elements, while holding an entailment relationship between the original text and the transformed one.
</prevsent>
<prevsent>such transformations are typically denoted as paraphrases?
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
in the literature, where wealth of methods for their automatic acquisition were proposed (lin and pantel, 2001; shinyama et al., 2002; barzilay and lee, 2003; <papid> N03-1003 </papid>szpektor et al, 2004).<papid> W04-3206 </papid></citsent>
<aftsection>
<nextsent>following the same spirit, we focus here on transformations that are local in nature, which, according to the literature, may be amenable for large scale acquisition.
</nextsent>
<nextsent>examples include: is manby birth ? was born in y?
</nextsent>
<nextsent>(example 1584 in table 1), take in ? join x1 and is holy book of ? follow x2.
</nextsent>
<nextsent>co-reference co-references provide equivalence relations between different terms in the text and thus induce transformations that replace one term in text with any of its co-referenced terms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2362">
<title id=" W05-1210.xml">definition and analysis of intermediate entailment levels </title>
<section> definition of entailment levels.  </section>
<citcontext>
<prevsection>
<prevsent>57entailment paraphrases this inference mechanism refers to transformations that modify the syntactic structure of text fragment as well as some of its lexical elements, while holding an entailment relationship between the original text and the transformed one.
</prevsent>
<prevsent>such transformations are typically denoted as paraphrases?
</prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
in the literature, where wealth of methods for their automatic acquisition were proposed (lin and pantel, 2001; shinyama et al., 2002; barzilay and lee, 2003; <papid> N03-1003 </papid>szpektor et al, 2004).<papid> W04-3206 </papid></citsent>
<aftsection>
<nextsent>following the same spirit, we focus here on transformations that are local in nature, which, according to the literature, may be amenable for large scale acquisition.
</nextsent>
<nextsent>examples include: is manby birth ? was born in y?
</nextsent>
<nextsent>(example 1584 in table 1), take in ? join x1 and is holy book of ? follow x2.
</nextsent>
<nextsent>co-reference co-references provide equivalence relations between different terms in the text and thus induce transformations that replace one term in text with any of its co-referenced terms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2363">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper explores the possibilities of improving parsing results by combining outputs of several parsers.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
to some extent, we are porting the ideas of henderson and brill (1999) <papid> W99-0623 </papid>to the world of dependency structures.</citsent>
<aftsection>
<nextsent>we differ from them in exploring context features more deeply.
</nextsent>
<nextsent>all our experiments were conducted on czech but the method is lan guage-independent.
</nextsent>
<nextsent>we were able to significantly improve over the best parsing result for the given setting, known so far.
</nextsent>
<nextsent>moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2364">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combination techniques have been successfully applied to part of speech tagging (van halteren et al., 1998; brill and wu, 1998; van halteren et al, 2001).
</prevsent>
<prevsent>in both cases the investigators were able to achieve significant improvements over the previous best tagging results.
</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
similar advances have been made in machine translation (frederking and nirenburg, 1994), <papid> A94-1016 </papid>speech recognition (fiscus, 1997), named entity recognition (borthwick et al, 1998), <papid> W98-1118 </papid>partial parsing (inui and inui, 2000), <papid> C00-1051 </papid>word sense disambiguation (florian and yarowsky, 2002) <papid> W02-1004 </papid>and question answering (chu-carroll et al, 2003).</citsent>
<aftsection>
<nextsent>brill and hladk?
</nextsent>
<nextsent>(haji et al, 1998) have first explored committee-based dependency parsing.
</nextsent>
<nextsent>however, they generated multiple parsers from single one using bagging (breiman, 1994).
</nextsent>
<nextsent>there have not been more sufficiently good parsers available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2365">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combination techniques have been successfully applied to part of speech tagging (van halteren et al., 1998; brill and wu, 1998; van halteren et al, 2001).
</prevsent>
<prevsent>in both cases the investigators were able to achieve significant improvements over the previous best tagging results.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
similar advances have been made in machine translation (frederking and nirenburg, 1994), <papid> A94-1016 </papid>speech recognition (fiscus, 1997), named entity recognition (borthwick et al, 1998), <papid> W98-1118 </papid>partial parsing (inui and inui, 2000), <papid> C00-1051 </papid>word sense disambiguation (florian and yarowsky, 2002) <papid> W02-1004 </papid>and question answering (chu-carroll et al, 2003).</citsent>
<aftsection>
<nextsent>brill and hladk?
</nextsent>
<nextsent>(haji et al, 1998) have first explored committee-based dependency parsing.
</nextsent>
<nextsent>however, they generated multiple parsers from single one using bagging (breiman, 1994).
</nextsent>
<nextsent>there have not been more sufficiently good parsers available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2366">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combination techniques have been successfully applied to part of speech tagging (van halteren et al., 1998; brill and wu, 1998; van halteren et al, 2001).
</prevsent>
<prevsent>in both cases the investigators were able to achieve significant improvements over the previous best tagging results.
</prevsent>
</prevsection>
<citsent citstr=" C00-1051 ">
similar advances have been made in machine translation (frederking and nirenburg, 1994), <papid> A94-1016 </papid>speech recognition (fiscus, 1997), named entity recognition (borthwick et al, 1998), <papid> W98-1118 </papid>partial parsing (inui and inui, 2000), <papid> C00-1051 </papid>word sense disambiguation (florian and yarowsky, 2002) <papid> W02-1004 </papid>and question answering (chu-carroll et al, 2003).</citsent>
<aftsection>
<nextsent>brill and hladk?
</nextsent>
<nextsent>(haji et al, 1998) have first explored committee-based dependency parsing.
</nextsent>
<nextsent>however, they generated multiple parsers from single one using bagging (breiman, 1994).
</nextsent>
<nextsent>there have not been more sufficiently good parsers available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2367">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combination techniques have been successfully applied to part of speech tagging (van halteren et al., 1998; brill and wu, 1998; van halteren et al, 2001).
</prevsent>
<prevsent>in both cases the investigators were able to achieve significant improvements over the previous best tagging results.
</prevsent>
</prevsection>
<citsent citstr=" W02-1004 ">
similar advances have been made in machine translation (frederking and nirenburg, 1994), <papid> A94-1016 </papid>speech recognition (fiscus, 1997), named entity recognition (borthwick et al, 1998), <papid> W98-1118 </papid>partial parsing (inui and inui, 2000), <papid> C00-1051 </papid>word sense disambiguation (florian and yarowsky, 2002) <papid> W02-1004 </papid>and question answering (chu-carroll et al, 2003).</citsent>
<aftsection>
<nextsent>brill and hladk?
</nextsent>
<nextsent>(haji et al, 1998) have first explored committee-based dependency parsing.
</nextsent>
<nextsent>however, they generated multiple parsers from single one using bagging (breiman, 1994).
</nextsent>
<nextsent>there have not been more sufficiently good parsers available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2370">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> component parsers.  </section>
<citcontext>
<prevsection>
<prevsent>the necessary assumption for meaningful combination is that the outputs of the individual parsers are sufficiently un correlated, i.e. that the parsers do not produce the same errors.
</prevsent>
<prevsent>if some accuracy parser author brief description tune test ec eugene charniak maximum-entropy inspired parser, home in constituency-based structures.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
english version described in charniak (2000), <papid> A00-2018 </papid>czech adaptation 2002 ? 2003, unpublished.</citsent>
<aftsection>
<nextsent>83.6 85.0 mcmichael collins uses probabilistic context-free grammar, home in constituency based structures.
</nextsent>
<nextsent>described in (haji et al, 1998; collins et al, 1999).<papid> P99-1065 </papid></nextsent>
<nextsent>81.7 83.3 z?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2371">
<title id=" W05-1518.xml">improving parsing accuracy by combining diverse dependency parsers </title>
<section> component parsers.  </section>
<citcontext>
<prevsection>
<prevsent>english version described in charniak (2000), <papid> A00-2018 </papid>czech adaptation 2002 ? 2003, unpublished.</prevsent>
<prevsent>83.6 85.0 mcmichael collins uses probabilistic context-free grammar, home in constituency based structures.</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
described in (haji et al, 1998; collins et al, 1999).<papid> P99-1065 </papid></citsent>
<aftsection>
<nextsent>81.7 83.3 z?
</nextsent>
<nextsent>zden abokrtsk?
</nextsent>
<nextsent>purely rule-based parser, rules are designed manually, just few lexical lists are collected from the training data.
</nextsent>
<nextsent>2002, unpublished.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2375">
<title id=" W06-0610.xml">on distance between deep syntax and semantic representation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present comparison of two formalisms for representing natural language utterances, namely deep syntactical tectogrammatical layer of functional generative description (fgd) and semantic formalism, multinet.
</prevsent>
<prevsent>we discuss the possible position of multi net in the fgd framework and present preliminary mapping of representational means of these two formalisms.
</prevsent>
</prevsection>
<citsent citstr=" W04-2706 ">
the prague dependency treebank 2.0 (pdt 2.0) described in sgall et al  (2004) <papid> W04-2706 </papid>contains large amount of czech texts with complex and interlinked morphological (2 million words), syntactic(1.5m words), and complex semantic (tectogram matical) annotation (0.8m words); in addition,certain properties of sentence information structure and coreference relations are annotated at the semantic level.</citsent>
<aftsection>
<nextsent>the theoretical basis of the treebank lies in the functional generative description (fgd) of language system by sgall et al  (1986).
</nextsent>
<nextsent>pdt 2.0 is based on the long-standing praguian linguistic tradition, adapted for the current computational-linguistics research needs.
</nextsent>
<nextsent>the corpus itself is embedded into the latest annotationtechnology.
</nextsent>
<nextsent>software tools for corpus search, annotation, and language analysis are included.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2376">
<title id=" W05-1626.xml">chart generation using production systems </title>
<section> case study 2: referring expression.  </section>
<citcontext>
<prevsection>
<prevsent>in the example above,they describe musician with black hair holding an instrument.
</prevsent>
<prevsent>the facts are defined in nam espace domain and are related by means of the indices held in the index and other slots.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
the use of vertex facts indicates that the representation is inspired by the graph approach to referring expression generation [krahmer et al, 2003].<papid> J03-1003 </papid></citsent>
<aftsection>
<nextsent>at the first stage of processing, content determination rules produce logical forms paired with list containing the vertices of the domain objects they describe: (lf::type-extension (extension v1) (id 3) (lf  (  type  =  musician  ) ) (depth 1) (type musician)) (lf::neq-type-extension (extension v1) (id 17) (lf  (  not  (  type  =  instrument  )   ) ) (depth 2) (negated 3))the first fact lists, in slot extension, all domain objects of type musician?, which is only v1 in our example.
</nextsent>
<nextsent>the second fact contains the vertices of all objects that are not of type instrument, which again is v1.
</nextsent>
<nextsent>the facts contain the logical form as sequence of atoms and strings.
</nextsent>
<nextsent>however, the fact heads are more important for matching since the logical forms (and many other slot values) are just passed on to the right-hand side.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2377">
<title id=" W05-1626.xml">chart generation using production systems </title>
<section> discussion and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>this points to characteristic of production languages that at the same timeis source of their efficiency (by allowing the construction of the rete networks) and limitation: since theslot values of facts cannot contain recursive data structures, we need to resort to the use of indices to express that certain facts belong together.?
</prevsent>
<prevsent>this is evident in the index slots of the domain model in the second case study, for example.
</prevsent>
</prevsection>
<citsent citstr=" W94-0323 ">
the same technique is used in the nl-soar project [rubinoff and lehman, 1994], <papid> W94-0323 </papid>to our knowledge the most extensive use of production systems for nlp.</citsent>
<aftsection>
<nextsent>however, if indices are used extensively, more work needs to be done in the join network part of the rete network, partially offsetting its benefits.
</nextsent>
<nextsent>in sum,we see the following advantages of using production systems for nlg:?
</nextsent>
<nextsent>they are able to deal with large numbers of (pos sibly machine-learned) rules (case study 1, see also [doorenbos, 1993]), ? they are suitable for integrating nlg with more general inferencing/reasoning (case study 2), ? general advantages: (largely) declarative behaviour;seamless integration with java if jess is used; de velopment: rapid prototyping, read-eval-print loop.
</nextsent>
<nextsent>on the other hand, we see the following disadvantages:?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2378">
<title id=" W04-3246.xml">learning hebrew roots machine learning with linguistic constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe that this information can be useful for computational applications and are currently experimenting with the benefits of using root and pattern information for automating the construction of wordnet for hebrew.we present machine learning approach, augmented by limited linguistic knowledge, to the problem of identifying the roots of hebrew words.
</prevsent>
<prevsent>tothe best of our knowledge, this is the first application of machine learning to this problem.
</prevsent>
</prevsection>
<citsent citstr=" W98-1007 ">
while there exist programs which can extract the root of words in arabic (beesley, 1998<papid> W98-1007 </papid>a; beesley, 1998<papid> W98-1007 </papid>b)and hebrew (choueka, 1990), they are all dependent on labor intensive construction of large-scalelexicons which are components of full-scale morphological analyzers.</citsent>
<aftsection>
<nextsent>note that tim bock walters arabic morphological analyzer2 only uses word stems ? rather than root and pattern morphemes ? to identify lexical items.
</nextsent>
<nextsent>(the information on root and pattern morphemes could be added to each stem entry if this were desired.)?
</nextsent>
<nextsent>the challenge of our work is to automate this process, avoiding the bottleneck of having to laboriously list the root and pattern ofeach lexeme in the language, and thereby gain insights that can be used for more detailed morphological analysis of semitic languages.
</nextsent>
<nextsent>as we show in section 2, identifying roots is non-trivial problem even for humans, due to the complex nature of hebrew derivational and inflectional morphology and the peculiarities of the hebrew orthography.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2382">
<title id=" W04-3246.xml">learning hebrew roots machine learning with linguistic constraints </title>
<section> data and methodology.  </section>
<citcontext>
<prevsection>
<prevsent>of these, only 9752 were annotated; the reason for the gap is that some hebrew words, mainly borrowed but also some frequent words suchas prepositions, do not have roots; we further eliminated 168 roots with more than three consonant sand were left with 5242 annotated word types, exhibiting 1043 different roots.
</prevsent>
<prevsent>table 1 shows the distribution of word types according to root ambiguity.3only tri-consonantal roots are counted.
</prevsent>
</prevsection>
<citsent citstr=" W02-0506 ">
ornan (2003) mentions 3407 roots, whereas the number of roots in arabic is estimated to be 10,000 (darwish, 2002).<papid> W02-0506 </papid></citsent>
<aftsection>
<nextsent>number of roots 1 2 3 4 number of words 4886 335 18 3 table 1: root ambiguity in the corpus table 2 provides the distribution of the roots of the 5242 word types in our corpus according to root type, where ci is the i-th radical (note that some roots may belong to more than one group).
</nextsent>
<nextsent>paradigm number percentage c1 = 414 7.90% c1 = 28 0.53% c1 = 419 7.99% c2 = 297 5.66% c2 = 517 9.86% c3 = 18 0.19% c3 = 677 12.92% c2 = c3 445 8.49% regular 3061 58.41% table 2: distribution of root paradigms as assurance for statistical reliability, in all the experiments discussed in the sequel (unless otherwise mentioned) we performed 10-fold cross validation runs for every classification task during evaluation.
</nextsent>
<nextsent>we also divided the test corpus into two sets: development set of 4800 words and held-out set of 442 words.
</nextsent>
<nextsent>only the development set was used for parameter tuning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2383">
<title id=" W04-3246.xml">learning hebrew roots machine learning with linguistic constraints </title>
<section> a machine learning approach </section>
<citcontext>
<prevsection>
<prevsent>snow is multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which nlp is principal example.
</prevsent>
<prevsent>it works by learning sparse network of linear functions over pre-defined or incrementally learned feature space.
</prevsent>
</prevsection>
<citsent citstr=" W02-2010 ">
snow has already been used successfully as the learning vehicle in large collection of natural language related tasks, including pos tagging, shallow parsing, information extraction tasks, etc., and compared favorably with other classifiers (roth, 1998; punyakanok and roth, 2001; florian, 2002).<papid> W02-2010 </papid></citsent>
<aftsection>
<nextsent>typically, snow is used as classifier, and predicts using winner-take-all mechanism over the activation values of the target classes.
</nextsent>
<nextsent>however, in addition to the prediction, it provides reliable confidence level in the prediction, which enables its use in an inference algorithm that combines predictors to produce coherent inference.
</nextsent>
<nextsent>4.1 feature types.
</nextsent>
<nextsent>all the experiments we describe in this work share the same features and differ only in the target classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2384">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the maximization of joint and conditional probabilities are theoretically equivalent, the conditional model allows us to use distributional word similarity to generalize the observed frequency counts in the training corpus.
</prevsent>
<prevsent>our experiments with the chinese treebank show that the accuracy of the conditional model is 13.6% higher than the joint model and that the strictly lexicalized conditional model outperforms the corresponding un lexicalized model based on part-of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
there has been great deal of progress in statistical parsing in the past decade (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>chaniak, 2000).</citsent>
<aftsection>
<nextsent>a common characteristic of these parsers is their use of lexicalized statistics.
</nextsent>
<nextsent>however, it was discovered recently that bi-lexical statistics (parameters that involve two words) actually played much smaller role than previously believed.
</nextsent>
<nextsent>it was found in (gildea, 2001) <papid> W01-0521 </papid>that the removal of bi-lexical statistics from state-of-the-art pcfg parser resulted very small change in the output.</nextsent>
<nextsent>bikel (2004) <papid> J04-4004 </papid>observed that the bi-lexical statistics accounted for only 1.49% of the bigram statistics used by the parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2385">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the maximization of joint and conditional probabilities are theoretically equivalent, the conditional model allows us to use distributional word similarity to generalize the observed frequency counts in the training corpus.
</prevsent>
<prevsent>our experiments with the chinese treebank show that the accuracy of the conditional model is 13.6% higher than the joint model and that the strictly lexicalized conditional model outperforms the corresponding un lexicalized model based on part-of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
there has been great deal of progress in statistical parsing in the past decade (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>chaniak, 2000).</citsent>
<aftsection>
<nextsent>a common characteristic of these parsers is their use of lexicalized statistics.
</nextsent>
<nextsent>however, it was discovered recently that bi-lexical statistics (parameters that involve two words) actually played much smaller role than previously believed.
</nextsent>
<nextsent>it was found in (gildea, 2001) <papid> W01-0521 </papid>that the removal of bi-lexical statistics from state-of-the-art pcfg parser resulted very small change in the output.</nextsent>
<nextsent>bikel (2004) <papid> J04-4004 </papid>observed that the bi-lexical statistics accounted for only 1.49% of the bigram statistics used by the parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2387">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a common characteristic of these parsers is their use of lexicalized statistics.
</prevsent>
<prevsent>however, it was discovered recently that bi-lexical statistics (parameters that involve two words) actually played much smaller role than previously believed.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
it was found in (gildea, 2001) <papid> W01-0521 </papid>that the removal of bi-lexical statistics from state-of-the-art pcfg parser resulted very small change in the output.</citsent>
<aftsection>
<nextsent>bikel (2004) <papid> J04-4004 </papid>observed that the bi-lexical statistics accounted for only 1.49% of the bigram statistics used by the parser.</nextsent>
<nextsent>when considering only bigram statistics involved in the highest probability parse, this percentage becomes 28.8%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2388">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it was discovered recently that bi-lexical statistics (parameters that involve two words) actually played much smaller role than previously believed.
</prevsent>
<prevsent>it was found in (gildea, 2001) <papid> W01-0521 </papid>that the removal of bi-lexical statistics from state-of-the-art pcfg parser resulted very small change in the output.</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
bikel (2004) <papid> J04-4004 </papid>observed that the bi-lexical statistics accounted for only 1.49% of the bigram statistics used by the parser.</citsent>
<aftsection>
<nextsent>when considering only bigram statistics involved in the highest probability parse, this percentage becomes 28.8%.
</nextsent>
<nextsent>however, even when the bi-lexical statistics do get used, they are remarkably similar to their back-off values using part-of-speech tags.
</nextsent>
<nextsent>therefore, the utility of bi-lexical statistics becomes rather questionable.
</nextsent>
<nextsent>klein and manning (2003) <papid> P03-1054 </papid>presented an un lexicalized parser that eliminated all lexicalized parameters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2389">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, even when the bi-lexical statistics do get used, they are remarkably similar to their back-off values using part-of-speech tags.
</prevsent>
<prevsent>therefore, the utility of bi-lexical statistics becomes rather questionable.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
klein and manning (2003) <papid> P03-1054 </papid>presented an un lexicalized parser that eliminated all lexicalized parameters.</citsent>
<aftsection>
<nextsent>its performance was close to the state-of-the-art lexicalized parsers.
</nextsent>
<nextsent>we present statistical dependency parser that represents the other end of spectrum where all statistical parameters are lexical and the parser does not require part-of-speech tags or grammatical categories.
</nextsent>
<nextsent>we call this strictly lexicalized parsing.
</nextsent>
<nextsent>a part-of-speech lexicon has always been considered to be necessary component in any natural language parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2390">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> a probabilistic dependency model  </section>
<citcontext>
<prevsection>
<prevsent>suppose the dependency tree is constructed in steps g1, ?, gn in the canonical order of the dependency links, where is the number of words in the sentence.
</prevsent>
<prevsent>we can compute the probability of as follows: ( ) ( ) ( )?
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
= ?= = i ii ggsgp sgggp stp 1 11 21 ,...,,| |,...,, |following (klein and manning, 2004), <papid> P04-1061 </papid>we require that the creation of dependency link from head to modifier be preceded by placing left stop and right stop around the modifier and stop between and m. let lwe (and we ) denote the event that there are no more modifiers on the left (and right) of word w. suppose the dependency link created in the step is (u, v, d).</citsent>
<aftsection>
<nextsent>if = l, gi is the conjunction of the four events: rue , ue , ve?
</nextsent>
<nextsent>and linkl(u, v).
</nextsent>
<nextsent>if = r, gi consists of four events: ve , ve , ue?
</nextsent>
<nextsent>and linkr(u, v).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2393">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> similarity-based smoothing.  </section>
<citcontext>
<prevsection>
<prevsent>this is known as the distributional hypothesis in linguistics (harris, 1968).
</prevsent>
<prevsent>for example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct, ... and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult, ...
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
many methods have been proposed to compute distributional similarity between words (hindle, 1990; <papid> P90-1034 </papid>pereira et al, 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>almost all of the methods represent word by feature vector where each feature corresponds to type of context in which the word appeared.
</nextsent>
<nextsent>they differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed.
</nextsent>
<nextsent>we define the features of word to be the set of words that occurred within small context window of in large corpus.
</nextsent>
<nextsent>the context window of an instance of consists of the closest non stop-word on each side of and the stop-words in between.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2394">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> similarity-based smoothing.  </section>
<citcontext>
<prevsection>
<prevsent>this is known as the distributional hypothesis in linguistics (harris, 1968).
</prevsent>
<prevsent>for example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct, ... and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult, ...
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
many methods have been proposed to compute distributional similarity between words (hindle, 1990; <papid> P90-1034 </papid>pereira et al, 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>almost all of the methods represent word by feature vector where each feature corresponds to type of context in which the word appeared.
</nextsent>
<nextsent>they differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed.
</nextsent>
<nextsent>we define the features of word to be the set of words that occurred within small context window of in large corpus.
</nextsent>
<nextsent>the context window of an instance of consists of the closest non stop-word on each side of and the stop-words in between.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2395">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> similarity-based smoothing.  </section>
<citcontext>
<prevsection>
<prevsent>this is known as the distributional hypothesis in linguistics (harris, 1968).
</prevsent>
<prevsent>for example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct, ... and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult, ...
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
many methods have been proposed to compute distributional similarity between words (hindle, 1990; <papid> P90-1034 </papid>pereira et al, 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>almost all of the methods represent word by feature vector where each feature corresponds to type of context in which the word appeared.
</nextsent>
<nextsent>they differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed.
</nextsent>
<nextsent>we define the features of word to be the set of words that occurred within small context window of in large corpus.
</nextsent>
<nextsent>the context window of an instance of consists of the closest non stop-word on each side of and the stop-words in between.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2400">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>models accuracy (a) strictly lexicalized conditional model 79.9 (b) at most one word is different in similar context 77.7 (c) strictly lexicalized joint model 66.3 (d) un lexicalized conditional mod-els 71.1 (e) un lexicalized joint models 71.1 table 2.
</prevsent>
<prevsent>performance of alternative models 157
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
previous parsing models (e.g., collins, 1997; <papid> P97-1003 </papid>charniak, 2000) <papid> A00-2018 </papid>maximize the joint probability p(s, t) of sentence and its parse tree t. we maximize the conditional probability p(t | s).</citsent>
<aftsection>
<nextsent>although they are theoretically equivalent, the use of conditional model allows us to take advantage of similarity-based smoothing.
</nextsent>
<nextsent>clark et al (2002) <papid> P02-1042 </papid>also computes conditional probability of dependency structures.</nextsent>
<nextsent>while the probability space in our model consists of all possible non-projective dependency trees, their probability space is constrained to all the dependency structures that are allowed by combinatorial category grammar (ccg) and category dictionary (lexicon).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2401">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>previous parsing models (e.g., collins, 1997; <papid> P97-1003 </papid>charniak, 2000) <papid> A00-2018 </papid>maximize the joint probability p(s, t) of sentence and its parse tree t. we maximize the conditional probability p(t | s).</prevsent>
<prevsent>although they are theoretically equivalent, the use of conditional model allows us to take advantage of similarity-based smoothing.</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
clark et al (2002) <papid> P02-1042 </papid>also computes conditional probability of dependency structures.</citsent>
<aftsection>
<nextsent>while the probability space in our model consists of all possible non-projective dependency trees, their probability space is constrained to all the dependency structures that are allowed by combinatorial category grammar (ccg) and category dictionary (lexicon).
</nextsent>
<nextsent>they therefore do not need the stop markers in their model.
</nextsent>
<nextsent>another major difference between our model and (clark et al, 2002) <papid> P02-1042 </papid>is that the parameters in our model consist exclusively of conditional probabilities of binary variables.</nextsent>
<nextsent>ratnaparkhis maximum entropy model (ratnaparkhi, 1999) is also conditional model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2403">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>yamada and matsumoto (2002) presented dependency parsing model using support vector machines.
</prevsent>
<prevsent>their model is discriminative model that maximizes the differences between scores of the correct parse and the scores of the top competing incorrect parses.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
in many dependency parsing models such as (eisner, 1996) <papid> C96-1058 </papid>and (macdonald et al, 2005), the score of dependency tree is the sum of the scores of the dependency links, which are computed independently of other links.</citsent>
<aftsection>
<nextsent>an undesirable consequence of this is that the parser often creates multiple dependency links that are separately likely but jointly improbable (or even impossible).
</nextsent>
<nextsent>for example, there is nothing in such models to prevent the parser from assigning two subjects to verb.
</nextsent>
<nextsent>in the dmv model (klein and manning, 2004), <papid> P04-1061 </papid>the probability of dependency link is partly conditioned on whether or not there is head word of the link already has modifier.</nextsent>
<nextsent>our model is quite similar to the dmv model, except that we compute the conditional probability of the parse tree given the sentence, instead of the joint probability of the parse tree and the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2406">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the dmv model (klein and manning, 2004), <papid> P04-1061 </papid>the probability of dependency link is partly conditioned on whether or not there is head word of the link already has modifier.</prevsent>
<prevsent>our model is quite similar to the dmv model, except that we compute the conditional probability of the parse tree given the sentence, instead of the joint probability of the parse tree and the sentence.</prevsent>
</prevsection>
<citsent citstr=" W00-1201 ">
there have been several previous approaches to parsing chinese with the penn chinese treebank (e.g., bikel and chiang, 2000; <papid> W00-1201 </papid>levy and manning, 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>both of these approaches employed phrase structure joint models and used part-of-speech tags in back-off smoothing.
</nextsent>
<nextsent>their results were evaluated with the precision and recall of the bracketings implied in the phrase structure parse trees.
</nextsent>
<nextsent>in contrast, the accuracy of our model is measured in terms of the dependency relationships.
</nextsent>
<nextsent>a dependency tree may correspond to more than one constituency trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2407">
<title id=" W05-1516.xml">strictly lexical dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the dmv model (klein and manning, 2004), <papid> P04-1061 </papid>the probability of dependency link is partly conditioned on whether or not there is head word of the link already has modifier.</prevsent>
<prevsent>our model is quite similar to the dmv model, except that we compute the conditional probability of the parse tree given the sentence, instead of the joint probability of the parse tree and the sentence.</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
there have been several previous approaches to parsing chinese with the penn chinese treebank (e.g., bikel and chiang, 2000; <papid> W00-1201 </papid>levy and manning, 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>both of these approaches employed phrase structure joint models and used part-of-speech tags in back-off smoothing.
</nextsent>
<nextsent>their results were evaluated with the precision and recall of the bracketings implied in the phrase structure parse trees.
</nextsent>
<nextsent>in contrast, the accuracy of our model is measured in terms of the dependency relationships.
</nextsent>
<nextsent>a dependency tree may correspond to more than one constituency trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2408">
<title id=" W05-0626.xml">semantic role labeling via consensus in pattern matching </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe the system architecture and report results for the conll2005 development dataset.
</prevsent>
<prevsent>semantic role labeling is to find all arguments for all predicates in sentence, and classify them by semantic roles such as a0, a1, am-tmp and so on.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
the performance of semantic role labeling can play key role in natural language processing applications, such as information extraction, question answering, and summarization (pradhan et al, 2004).<papid> N04-1030 </papid></citsent>
<aftsection>
<nextsent>most existing systems separate semantic role labeling into two sub-problems, boundary recognition and role classification, and use feature-based models to address both (carreras et al, 2004).<papid> W04-2415 </papid></nextsent>
<nextsent>our strategy is to develop boundary analyzer by general tree-based predicate-argument recognition algorithm (gt-para) for boundary recognition, and pattern-matching model for role classifica tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2410">
<title id=" W05-0626.xml">semantic role labeling via consensus in pattern matching </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic role labeling is to find all arguments for all predicates in sentence, and classify them by semantic roles such as a0, a1, am-tmp and so on.
</prevsent>
<prevsent>the performance of semantic role labeling can play key role in natural language processing applications, such as information extraction, question answering, and summarization (pradhan et al, 2004).<papid> N04-1030 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-2415 ">
most existing systems separate semantic role labeling into two sub-problems, boundary recognition and role classification, and use feature-based models to address both (carreras et al, 2004).<papid> W04-2415 </papid></citsent>
<aftsection>
<nextsent>our strategy is to develop boundary analyzer by general tree-based predicate-argument recognition algorithm (gt-para) for boundary recognition, and pattern-matching model for role classification.
</nextsent>
<nextsent>the only information used in our system is charniaks annotation with words, which contains all useful syntactic annotations.
</nextsent>
<nextsent>five features, which are headword, phrase type, voice, target verb, and preposition (of the first word), and pattern set, which includes numbers and types of roles in pattern, are used for the pattern-matching approach.
</nextsent>
<nextsent>we develop pattern database, trained by wall street journal section 02 to 21, as our knowl edge/data base.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2414">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the accuracy of the original parser on questions is very poor, and we propose novel technique for porting the parser to new domain, by creating new labelled data at the lexical category level only.
</prevsent>
<prevsent>using super tagger to assign categories to words, trained on the new data, leads to dramatic increase in question parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
several wide-coverage statistical parsers have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and applied tothe wsj penn treebank (clark et al , 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>one motivation for using ccg is the recovery of the long-range dependencies inherent in phenomena such as coordination and extraction.
</nextsent>
<nextsent>recovery of these dependencies is important for nlp tasks which require semantic interpretation and for processing text which contains high frequency of such cases, e.g. wh-questions fed to question answering (qa) system.
</nextsent>
<nextsent>one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</nextsent>
<nextsent>johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2415">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the accuracy of the original parser on questions is very poor, and we propose novel technique for porting the parser to new domain, by creating new labelled data at the lexical category level only.
</prevsent>
<prevsent>using super tagger to assign categories to words, trained on the new data, leads to dramatic increase in question parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
several wide-coverage statistical parsers have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and applied tothe wsj penn treebank (clark et al , 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>one motivation for using ccg is the recovery of the long-range dependencies inherent in phenomena such as coordination and extraction.
</nextsent>
<nextsent>recovery of these dependencies is important for nlp tasks which require semantic interpretation and for processing text which contains high frequency of such cases, e.g. wh-questions fed to question answering (qa) system.
</nextsent>
<nextsent>one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</nextsent>
<nextsent>johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2416">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the accuracy of the original parser on questions is very poor, and we propose novel technique for porting the parser to new domain, by creating new labelled data at the lexical category level only.
</prevsent>
<prevsent>using super tagger to assign categories to words, trained on the new data, leads to dramatic increase in question parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P03-1046 ">
several wide-coverage statistical parsers have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and applied tothe wsj penn treebank (clark et al , 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>one motivation for using ccg is the recovery of the long-range dependencies inherent in phenomena such as coordination and extraction.
</nextsent>
<nextsent>recovery of these dependencies is important for nlp tasks which require semantic interpretation and for processing text which contains high frequency of such cases, e.g. wh-questions fed to question answering (qa) system.
</nextsent>
<nextsent>one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</nextsent>
<nextsent>johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2419">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the accuracy of the original parser on questions is very poor, and we propose novel technique for porting the parser to new domain, by creating new labelled data at the lexical category level only.
</prevsent>
<prevsent>using super tagger to assign categories to words, trained on the new data, leads to dramatic increase in question parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
several wide-coverage statistical parsers have recently been developed for combinatory categorial grammar (ccg; steedman, 2000) and applied tothe wsj penn treebank (clark et al , 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002; <papid> P02-1043 </papid>hockenmaier, 2003<papid> P03-1046 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>one motivation for using ccg is the recovery of the long-range dependencies inherent in phenomena such as coordination and extraction.
</nextsent>
<nextsent>recovery of these dependencies is important for nlp tasks which require semantic interpretation and for processing text which contains high frequency of such cases, e.g. wh-questions fed to question answering (qa) system.
</nextsent>
<nextsent>one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</nextsent>
<nextsent>johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2427">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one motivation for using ccg is the recovery of the long-range dependencies inherent in phenomena such as coordination and extraction.
</prevsent>
<prevsent>recovery of these dependencies is important for nlp tasks which require semantic interpretation and for processing text which contains high frequency of such cases, e.g. wh-questions fed to question answering (qa) system.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</citsent>
<aftsection>
<nextsent>johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</nextsent>
<nextsent>nodes into the trees, and dienes and dubey (2003) <papid> P03-1055 </papid>use preprocessing methods to determine where discontinuities are likely to appear in the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2428">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recovery of these dependencies is important for nlp tasks which require semantic interpretation and for processing text which contains high frequency of such cases, e.g. wh-questions fed to question answering (qa) system.
</prevsent>
<prevsent>one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</citsent>
<aftsection>
<nextsent>nodes into the trees, and dienes and dubey (2003) <papid> P03-1055 </papid>use preprocessing methods to determine where discontinuities are likely to appear in the sentence.</nextsent>
<nextsent>in contrast, the ccg parsers detect long-range dependencies as an integral part of the parsing process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2430">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one shortcoming of treebank parsers such as collins (1999) and charniak (2000) <papid> A00-2018 </papid>is that they typically produce phrase-structure trees containing only local syntactic information.</prevsent>
<prevsent>johnson (2002) <papid> P02-1018 </papid>uses post-processing methods to insert empty?</prevsent>
</prevsection>
<citsent citstr=" P03-1055 ">
nodes into the trees, and dienes and dubey (2003) <papid> P03-1055 </papid>use preprocessing methods to determine where discontinuities are likely to appear in the sentence.</citsent>
<aftsection>
<nextsent>in contrast, the ccg parsers detect long-range dependencies as an integral part of the parsing process.
</nextsent>
<nextsent>the ccg parser used here (clark and curran, 2004<papid> P04-1014 </papid>b) is highly accurate and efficient, recovering labelled dependencies with an overall f-score ofover 84% on wsj text, and parsing up to 50 sentences per second.</nextsent>
<nextsent>thus the parser should be useful for large-scale nlp tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2439">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for evaluation we focus on what questions used in the trec competitions.
</prevsent>
<prevsent>as well as giving an overall evaluation on this test set, we also consider number of object extraction cases.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
the creation of new training data at the lexical category level alone is technique which could be used to rapidly port the parser to other domains.this technique may also be applicable to other lexicalised grammar formalisms, such as tree adjoining grammar (bangalore and joshi, 1999).<papid> J99-2004 </papid>11doran et al  (1997) <papid> W97-1505 </papid>propose using super tagger for semi automatically porting the xtag grammar to new domain.</citsent>
<aftsection>
<nextsent>the parser used in this paper is described in clark and curran (2004<papid> P04-1014 </papid>b).</nextsent>
<nextsent>it takes as input pos tagged sentence with set of lexical categories assigned to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2441">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for evaluation we focus on what questions used in the trec competitions.
</prevsent>
<prevsent>as well as giving an overall evaluation on this test set, we also consider number of object extraction cases.
</prevsent>
</prevsection>
<citsent citstr=" W97-1505 ">
the creation of new training data at the lexical category level alone is technique which could be used to rapidly port the parser to other domains.this technique may also be applicable to other lexicalised grammar formalisms, such as tree adjoining grammar (bangalore and joshi, 1999).<papid> J99-2004 </papid>11doran et al  (1997) <papid> W97-1505 </papid>propose using super tagger for semi automatically porting the xtag grammar to new domain.</citsent>
<aftsection>
<nextsent>the parser used in this paper is described in clark and curran (2004<papid> P04-1014 </papid>b).</nextsent>
<nextsent>it takes as input pos tagged sentence with set of lexical categories assigned to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2479">
<title id=" W04-3215.xml">object extraction and question parsing using ccg </title>
<section> the parser.  </section>
<citcontext>
<prevsection>
<prevsent>we have also tried predicate-argument dependencies, including long-range dependencies, but these have not improved performance.
</prevsent>
<prevsent>note we still recover long range dependencies, even if modelling them does not improve performance.the parser returns derived structure corresponding to the most probable derivation.
</prevsent>
</prevsection>
<citsent citstr=" C04-1180 ">
for evaluation the parser returns dependency structures, butwe have also developed module which builds first order semantic representations from the derivations, which can be used for inference (bos et al , 2004).<papid> C04-1180 </papid></citsent>
<aftsection>
<nextsent>steedman (1996) presents detailed study of various extraction phenomena.
</nextsent>
<nextsent>here we focus on object extraction, since the dependencies in such cases are unbounded, and ccg has been designed to handle these cases.
</nextsent>
<nextsent>correct dependency recovery for object extraction is also difficult for shallow methods such as johnson (2002) <papid> P02-1018 </papid>and dienes and dubey (2003).<papid> P03-1055 </papid>we consider three types of object extraction: object relative clauses, free object relatives, and tough adjectives (hockenmaier, 2003<papid> P03-1046 </papid>a).</nextsent>
<nextsent>examples of the first two from ccgbank are given in figures 1 and 2, together with the normal-form derivation.the caption gives the number of sentences containing such case in sections 2-21 of ccgbank (the training data) and section 00 (development data).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2518">
<title id=" W05-0106.xml">making hidden markov models more transparent </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>(if this pattern ofmis-taggings caused by high generation probability ratios was found repeatedly, we might consider smoothing these distributions more aggressively.)
</prevsent>
<prevsent>the hmm part-of-speech tagging model and corresponding viterbi algorithm were implemented based on their description in the updated version, http://www.cs.colorado.edu/martin/ slp/updated.html , of chapter 8 of (jurafsky and martin, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
a model was trained using maximum likelihood from the upenn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the input model file is encoded using xml and thus models built by other systems can be read in and displayed.
</nextsent>
<nextsent>the system is implemented in java and requires 1.4 or higher to run.
</nextsent>
<nextsent>it has been tested on linux and apple operating systems.
</nextsent>
<nextsent>we will release it under standard open source license.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2519">
<title id=" W05-0106.xml">making hidden markov models more transparent </title>
<section> summary and future work.  </section>
<citcontext>
<prevsection>
<prevsent>in the future we plan to implement good-turing smoothing and method for dealing with unknown words.
</prevsent>
<prevsent>we also plan to provide an additional display that shows the traditional viterbi lattice figure, i.e., observations listed left-to-right, possible states listed from top-to-bottom, and lines from left-to-right connecting states at observation index with the previous states, i-1, that are part of the most likely state sequence to i. finally, we would like to incorporate an additional display that will provide visualization of em hmm training.
</prevsent>
</prevsection>
<citsent citstr=" W02-0102 ">
we will use (eisner, 2002) <papid> W02-0102 </papid>as starting point.</citsent>
<aftsection>
<nextsent>35
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2520">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to date, most methods for constructing discourse structures are not robust.
</prevsent>
<prevsent>they typically relyon grammatical input and use symbolic methods which inevitably lack coverage.
</prevsent>
</prevsection>
<citsent citstr=" P97-1013 ">
one exception is marcus work (marcu, 1997, <papid> P97-1013 </papid>1999) (see also soricut and marcu (2003) <papid> N03-1030 </papid>for constructing discourse structures for individual sentences).</citsent>
<aftsection>
<nextsent>marcu (1999) <papid> P99-1047 </papid>uses decision-tree learner and shallow syntactic features 96 to create classifiers for discourse segmentation and for identifying rhetorical relations.</nextsent>
<nextsent>together, these amount to model of discourse parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2521">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to date, most methods for constructing discourse structures are not robust.
</prevsent>
<prevsent>they typically relyon grammatical input and use symbolic methods which inevitably lack coverage.
</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
one exception is marcus work (marcu, 1997, <papid> P97-1013 </papid>1999) (see also soricut and marcu (2003) <papid> N03-1030 </papid>for constructing discourse structures for individual sentences).</citsent>
<aftsection>
<nextsent>marcu (1999) <papid> P99-1047 </papid>uses decision-tree learner and shallow syntactic features 96 to create classifiers for discourse segmentation and for identifying rhetorical relations.</nextsent>
<nextsent>together, these amount to model of discourse parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2522">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they typically relyon grammatical input and use symbolic methods which inevitably lack coverage.
</prevsent>
<prevsent>one exception is marcus work (marcu, 1997, <papid> P97-1013 </papid>1999) (see also soricut and marcu (2003) <papid> N03-1030 </papid>for constructing discourse structures for individual sentences).</prevsent>
</prevsection>
<citsent citstr=" P99-1047 ">
marcu (1999) <papid> P99-1047 </papid>uses decision-tree learner and shallow syntactic features 96 to create classifiers for discourse segmentation and for identifying rhetorical relations.</citsent>
<aftsection>
<nextsent>together, these amount to model of discourse parsing.
</nextsent>
<nextsent>however, the results are trees of rhetorical structure theory(rst) (mann and thompson, 1986), and the classifiers relyon well-formedness constraints on rst trees which are too restrictive (moore and pollack, 1992).<papid> J92-4007 </papid></nextsent>
<nextsent>furthermore, rst does not offer an account of how compositional semantics gets augmented, nor does it model anaphora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2524">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>marcu (1999) <papid> P99-1047 </papid>uses decision-tree learner and shallow syntactic features 96 to create classifiers for discourse segmentation and for identifying rhetorical relations.</prevsent>
<prevsent>together, these amount to model of discourse parsing.</prevsent>
</prevsection>
<citsent citstr=" J92-4007 ">
however, the results are trees of rhetorical structure theory(rst) (mann and thompson, 1986), and the classifiers relyon well-formedness constraints on rst trees which are too restrictive (moore and pollack, 1992).<papid> J92-4007 </papid></citsent>
<aftsection>
<nextsent>furthermore, rst does not offer an account of how compositional semantics gets augmented, nor does it model anaphora.
</nextsent>
<nextsent>it is also designed for monologue rather than dialogue, so it does not offer precise semantics of questions or non-sentential utterances which convey propositional content (e.g., 154 and 155 in figure 1).
</nextsent>
<nextsent>another main approach to robust dialogue processing has been statistical models for identifying dialogue acts (e.g., stolcke et al (2000)).<papid> J00-3003 </papid></nextsent>
<nextsent>however, dialogue acts are properties of utterances rather than hierarchically arranged relations between them, so they do not provide basis for resolving semantic under specification generated by the grammar (asher and lascarides, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2525">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, rst does not offer an account of how compositional semantics gets augmented, nor does it model anaphora.
</prevsent>
<prevsent>it is also designed for monologue rather than dialogue, so it does not offer precise semantics of questions or non-sentential utterances which convey propositional content (e.g., 154 and 155 in figure 1).
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
another main approach to robust dialogue processing has been statistical models for identifying dialogue acts (e.g., stolcke et al (2000)).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>however, dialogue acts are properties of utterances rather than hierarchically arranged relations between them, so they do not provide basis for resolving semantic under specification generated by the grammar (asher and lascarides, 2003).
</nextsent>
<nextsent>here, we present the first probabilistic approach to parsing the discourse structure of dialogue.
</nextsent>
<nextsent>we use dialogues from redwoods?
</nextsent>
<nextsent>appointment scheduling domain and adapt head-driven generative parsing strategies from sentential parsing (e.g., collins (2003)) <papid> J03-4003 </papid>for discourse parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2526">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here, we present the first probabilistic approach to parsing the discourse structure of dialogue.
</prevsent>
<prevsent>we use dialogues from redwoods?
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
appointment scheduling domain and adapt head-driven generative parsing strategies from sentential parsing (e.g., collins (2003)) <papid> J03-4003 </papid>for discourse parsing.</citsent>
<aftsection>
<nextsent>the discourse structures we build conform to segmented discourse representation theory (sdrt) (asher and lascarides, 2003).
</nextsent>
<nextsent>sdrt provides precise dynamic semantic interpretation for its discourse structures which augments the conventional semantic representations that are built by most grammars.
</nextsent>
<nextsent>we thus view the task of learning model of sdrt-style discourse structures as one step towards achieving the goal of robust and precise semantic interpretations.
</nextsent>
<nextsent>we describe sdrt in the context of our domain in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2531">
<title id=" W05-0613.xml">probabilistic head driven parsing for discourse structure </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>this extra information improves the determination of labelled relations.
</prevsent>
<prevsent>for example, it is especially useful in distinguishing plan-correction from plan-elaboration.the overall trend of differences between parseval and relations scoring show that parseval is tougher on overall segmentation and relations scoring is tougher on whether model got the right arguments for each labelled relation.
</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
it is the latter that ultimately matters for the discourse structures produced by the parser to be useful; nonetheless, the parseval scores do show that each model progressively improves on capturing the trees themselves, and that even model 1 ? as syntactic model ? is far superior to the baseline for capturing the overall form of the trees.we also compare our best model against two up perbounds: (1) inter-annotator agreement on ten dialogues that were annotated independently and (2) the best annotator against the gold standard agreed upon after the independent annotation phase.for the first, the labelled/unlabelled relations scores are 50.3%/73.0% and for the latter, they are 75.3%/84.0%this is similar to the performance on other discourse annotation projects, e.g., carlson et al (2001).<papid> W01-1605 </papid></citsent>
<aftsection>
<nextsent>on the same ten dialogues, model 4 achieves 42.3%/64.9%.
</nextsent>
<nextsent>it is hard to compare these models with marcus (1999) rhetorical parsing model.
</nextsent>
<nextsent>unlike marcu, wedid not use variety of corpora, have smaller training corpus, are analysing dialogues as opposed to monologues, have larger class of rhetorical relations, and obtain the elementary discourse units 102from the redwoods annotations rather than estimating them.
</nextsent>
<nextsent>even so, it is interesting that the scores reported in marcu (1999) <papid> P99-1047 </papid>for labelled and un labelled relations are similar to our scores for model 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2534">
<title id=" W06-0110.xml">hybrid models for chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>palma and day (1997) reported that person (per), location (loc) and organization (org) names are the most difficult sub-tasks as compared to other entities as defined in message understanding conference (muc).
</prevsent>
<prevsent>so we focus on the recognition of per, loc and org entities.
</prevsent>
</prevsection>
<citsent citstr=" W02-2002 ">
recently, machine learning approaches are widely used inner, including the hidden markov model (zhou and su, 2000; miller and crystal, 1998), maximum entropy model (borthwick, 1999), decision tree (qin and yuan, 2004), transformation-based learning (black and vasilakopoulos, 2002), <papid> W02-2002 </papid>boosting (collins, 2002; <papid> P02-1062 </papid>carreras et al, 2002), <papid> W02-2004 </papid>support vector machine (takeuchi and collier, 2002; <papid> W02-2029 </papid>yu et al, 2004; goh et al, 2003), <papid> P03-2039 </papid>memory-based learning (sang, 2002).</citsent>
<aftsection>
<nextsent>svm has given high performance in various classification tasks (joachims, 1998; kudo and matsumoto, 2001).<papid> N01-1025 </papid></nextsent>
<nextsent>goh et al (2003) <papid> P03-2039 </papid>presented svm-based chunker to extract chinese unknown words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2535">
<title id=" W06-0110.xml">hybrid models for chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>palma and day (1997) reported that person (per), location (loc) and organization (org) names are the most difficult sub-tasks as compared to other entities as defined in message understanding conference (muc).
</prevsent>
<prevsent>so we focus on the recognition of per, loc and org entities.
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
recently, machine learning approaches are widely used inner, including the hidden markov model (zhou and su, 2000; miller and crystal, 1998), maximum entropy model (borthwick, 1999), decision tree (qin and yuan, 2004), transformation-based learning (black and vasilakopoulos, 2002), <papid> W02-2002 </papid>boosting (collins, 2002; <papid> P02-1062 </papid>carreras et al, 2002), <papid> W02-2004 </papid>support vector machine (takeuchi and collier, 2002; <papid> W02-2029 </papid>yu et al, 2004; goh et al, 2003), <papid> P03-2039 </papid>memory-based learning (sang, 2002).</citsent>
<aftsection>
<nextsent>svm has given high performance in various classification tasks (joachims, 1998; kudo and matsumoto, 2001).<papid> N01-1025 </papid></nextsent>
<nextsent>goh et al (2003) <papid> P03-2039 </papid>presented svm-based chunker to extract chinese unknown words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2536">
<title id=" W06-0110.xml">hybrid models for chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>palma and day (1997) reported that person (per), location (loc) and organization (org) names are the most difficult sub-tasks as compared to other entities as defined in message understanding conference (muc).
</prevsent>
<prevsent>so we focus on the recognition of per, loc and org entities.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
recently, machine learning approaches are widely used inner, including the hidden markov model (zhou and su, 2000; miller and crystal, 1998), maximum entropy model (borthwick, 1999), decision tree (qin and yuan, 2004), transformation-based learning (black and vasilakopoulos, 2002), <papid> W02-2002 </papid>boosting (collins, 2002; <papid> P02-1062 </papid>carreras et al, 2002), <papid> W02-2004 </papid>support vector machine (takeuchi and collier, 2002; <papid> W02-2029 </papid>yu et al, 2004; goh et al, 2003), <papid> P03-2039 </papid>memory-based learning (sang, 2002).</citsent>
<aftsection>
<nextsent>svm has given high performance in various classification tasks (joachims, 1998; kudo and matsumoto, 2001).<papid> N01-1025 </papid></nextsent>
<nextsent>goh et al (2003) <papid> P03-2039 </papid>presented svm-based chunker to extract chinese unknown words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2537">
<title id=" W06-0110.xml">hybrid models for chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>palma and day (1997) reported that person (per), location (loc) and organization (org) names are the most difficult sub-tasks as compared to other entities as defined in message understanding conference (muc).
</prevsent>
<prevsent>so we focus on the recognition of per, loc and org entities.
</prevsent>
</prevsection>
<citsent citstr=" W02-2029 ">
recently, machine learning approaches are widely used inner, including the hidden markov model (zhou and su, 2000; miller and crystal, 1998), maximum entropy model (borthwick, 1999), decision tree (qin and yuan, 2004), transformation-based learning (black and vasilakopoulos, 2002), <papid> W02-2002 </papid>boosting (collins, 2002; <papid> P02-1062 </papid>carreras et al, 2002), <papid> W02-2004 </papid>support vector machine (takeuchi and collier, 2002; <papid> W02-2029 </papid>yu et al, 2004; goh et al, 2003), <papid> P03-2039 </papid>memory-based learning (sang, 2002).</citsent>
<aftsection>
<nextsent>svm has given high performance in various classification tasks (joachims, 1998; kudo and matsumoto, 2001).<papid> N01-1025 </papid></nextsent>
<nextsent>goh et al (2003) <papid> P03-2039 </papid>presented svm-based chunker to extract chinese unknown words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2538">
<title id=" W06-0110.xml">hybrid models for chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>palma and day (1997) reported that person (per), location (loc) and organization (org) names are the most difficult sub-tasks as compared to other entities as defined in message understanding conference (muc).
</prevsent>
<prevsent>so we focus on the recognition of per, loc and org entities.
</prevsent>
</prevsection>
<citsent citstr=" P03-2039 ">
recently, machine learning approaches are widely used inner, including the hidden markov model (zhou and su, 2000; miller and crystal, 1998), maximum entropy model (borthwick, 1999), decision tree (qin and yuan, 2004), transformation-based learning (black and vasilakopoulos, 2002), <papid> W02-2002 </papid>boosting (collins, 2002; <papid> P02-1062 </papid>carreras et al, 2002), <papid> W02-2004 </papid>support vector machine (takeuchi and collier, 2002; <papid> W02-2029 </papid>yu et al, 2004; goh et al, 2003), <papid> P03-2039 </papid>memory-based learning (sang, 2002).</citsent>
<aftsection>
<nextsent>svm has given high performance in various classification tasks (joachims, 1998; kudo and matsumoto, 2001).<papid> N01-1025 </papid></nextsent>
<nextsent>goh et al (2003) <papid> P03-2039 </papid>presented svm-based chunker to extract chinese unknown words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2539">
<title id=" W06-0110.xml">hybrid models for chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so we focus on the recognition of per, loc and org entities.
</prevsent>
<prevsent>recently, machine learning approaches are widely used inner, including the hidden markov model (zhou and su, 2000; miller and crystal, 1998), maximum entropy model (borthwick, 1999), decision tree (qin and yuan, 2004), transformation-based learning (black and vasilakopoulos, 2002), <papid> W02-2002 </papid>boosting (collins, 2002; <papid> P02-1062 </papid>carreras et al, 2002), <papid> W02-2004 </papid>support vector machine (takeuchi and collier, 2002; <papid> W02-2029 </papid>yu et al, 2004; goh et al, 2003), <papid> P03-2039 </papid>memory-based learning (sang, 2002).</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
svm has given high performance in various classification tasks (joachims, 1998; kudo and matsumoto, 2001).<papid> N01-1025 </papid></citsent>
<aftsection>
<nextsent>goh et al (2003) <papid> P03-2039 </papid>presented svm-based chunker to extract chinese unknown words.</nextsent>
<nextsent>it obtained higher f-measure for person names and organization names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2542">
<title id=" W06-0113.xml">a svm based model for chinese functional chunk parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, the type of functional chunk could not be simply determined by its constitution, but depends heavily on the context.
</prevsent>
<prevsent>therefore, we will have new challenges in the functional chunk parsing.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
ramshaw and marcus (1995) <papid> W95-0107 </papid>first introduced the machine learning techniques to chunking problem.</citsent>
<aftsection>
<nextsent>by formulating the np-chunking task as tagging process, they marked each word with tag from set {b, i, o}, and successfully applied tbl to it.
</nextsent>
<nextsent>inspired by their work, we introduce svm algorithm to our functional chunking problem.
</nextsent>
<nextsent>instead of using the bio tagging system, we propose new model for solving this problem.
</nextsent>
<nextsent>in this model, we do not tag the words with bio tags, but directly discover the chunk boundaries between every two adjacent functional chunks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2544">
<title id=" W06-0113.xml">a svm based model for chinese functional chunk parsing </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>mbt #mb of t1 #mb of t4 t4-t1 pj 17 18 1 pd 9 9 0 pc 8 8 0 sp 6 6 0 ps 5 5 0 sd 5 4 -1 dp 3 2 -1 ts 3 3 0 od 1 0 -1 py 1 1 0 sum 58 56 -2 in contrast to the results of sp boundary detection task, the mbt errors could not be largely reduced by simply expanding the context window.
</prevsent>
<prevsent>therefore, we need to pay more attention to these problems in our future work.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
after the work of ramshaw and marcus (1995) <papid> W95-0107 </papid>, many machine learning techniques have been applied to the basic chunking task, such as support vector machines (kudo and matsumoto, 2001), <papid> N01-1025 </papid>hidden markov model(molina and pla 2002), memory based learning (sang, 2002), conditional random fields (sha and pereira, 2003), <papid> N03-1028 </papid>and so on.</citsent>
<aftsection>
<nextsent>but only small amount of attention has been paid to the functional chunk parsing problem.
</nextsent>
<nextsent>sandra and erhard (2001) tried to construct the function-argument structures based on the pre-chunked input.
</nextsent>
<nextsent>they proposed similarity based algorithm to assign the functional labels to complete syntactic structures, and achieved 100 precision of 89.73% and 90.40% for german and english respectively.
</nextsent>
<nextsent>different from our top down scheme, their function-argument structures are still constituted from bottom-up, and the prechunked input helps simplify the chunking process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2545">
<title id=" W06-0113.xml">a svm based model for chinese functional chunk parsing </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>mbt #mb of t1 #mb of t4 t4-t1 pj 17 18 1 pd 9 9 0 pc 8 8 0 sp 6 6 0 ps 5 5 0 sd 5 4 -1 dp 3 2 -1 ts 3 3 0 od 1 0 -1 py 1 1 0 sum 58 56 -2 in contrast to the results of sp boundary detection task, the mbt errors could not be largely reduced by simply expanding the context window.
</prevsent>
<prevsent>therefore, we need to pay more attention to these problems in our future work.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
after the work of ramshaw and marcus (1995) <papid> W95-0107 </papid>, many machine learning techniques have been applied to the basic chunking task, such as support vector machines (kudo and matsumoto, 2001), <papid> N01-1025 </papid>hidden markov model(molina and pla 2002), memory based learning (sang, 2002), conditional random fields (sha and pereira, 2003), <papid> N03-1028 </papid>and so on.</citsent>
<aftsection>
<nextsent>but only small amount of attention has been paid to the functional chunk parsing problem.
</nextsent>
<nextsent>sandra and erhard (2001) tried to construct the function-argument structures based on the pre-chunked input.
</nextsent>
<nextsent>they proposed similarity based algorithm to assign the functional labels to complete syntactic structures, and achieved 100 precision of 89.73% and 90.40% for german and english respectively.
</nextsent>
<nextsent>different from our top down scheme, their function-argument structures are still constituted from bottom-up, and the prechunked input helps simplify the chunking process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2546">
<title id=" W05-0828.xml">first steps towards multiengine machine translation </title>
<section> motivation and long-term perspective.  </section>
<citcontext>
<prevsection>
<prevsent>(wahlster, 2001) although this statement has been coined in the context of verbmo bil, aiming at translation for direct communication, it appears also realistic for many other translation scenarios, where demands on robustness, coverage, or adaptability on the input side and quality on the output side go beyond todays technological possibilities.
</prevsent>
<prevsent>the increasing availability of mt engine sand the need for better quality has motivated considerable efforts to combine multiple engines into one super-engine?
</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
that is hopefully better than any of its ingredients, an idea pionieered in (frederking and nirenburg, 1994).<papid> A94-1016 </papid></citsent>
<aftsection>
<nextsent>so far, the larger group of related publications has focused on the task of selecting, from set of translation candidates obtained from different engines, one translation that looks most promising (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba etal., 2001; callison-burch and flournoy, 2001; akiba et al, 2002; <papid> C02-1076 </papid>nomoto, 2004).<papid> P04-1063 </papid></nextsent>
<nextsent>but also the more challenging problem of decomposing the candidates and re-assembling from the pieces new sentence, hopefully better than any of the given inputs, has recently gained considerable attention (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2547">
<title id=" W05-0828.xml">first steps towards multiengine machine translation </title>
<section> motivation and long-term perspective.  </section>
<citcontext>
<prevsection>
<prevsent>the increasing availability of mt engine sand the need for better quality has motivated considerable efforts to combine multiple engines into one super-engine?
</prevsent>
<prevsent>that is hopefully better than any of its ingredients, an idea pionieered in (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-2122 ">
so far, the larger group of related publications has focused on the task of selecting, from set of translation candidates obtained from different engines, one translation that looks most promising (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba etal., 2001; callison-burch and flournoy, 2001; akiba et al, 2002; <papid> C02-1076 </papid>nomoto, 2004).<papid> P04-1063 </papid></citsent>
<aftsection>
<nextsent>but also the more challenging problem of decomposing the candidates and re-assembling from the pieces new sentence, hopefully better than any of the given inputs, has recently gained considerable attention (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005).
</nextsent>
<nextsent>although statistical mt approaches currently come out as winners in most comparative evaluations, it is clear that the achievable quality of methods relying purely on lookup of fixed phrases will be limited by the simple fact that for any given combination of topic, application scenario, language pair, and text style there will never be sufficient amounts of pre-existing translations to satisfy the needs of purely data-driven approaches.
</nextsent>
<nextsent>rule-based approaches can exploit the effort that goes into single entries in their knowledge repositories in broader way, as these entries can be unfolded, via rule applications, into large numbers of possible usages.
</nextsent>
<nextsent>however, this increased generality comes at significant costs for the acquisition of the required knowledge, which needs to be encoded by specialists in formalisms requiring extensive training to be used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2548">
<title id=" W05-0828.xml">first steps towards multiengine machine translation </title>
<section> motivation and long-term perspective.  </section>
<citcontext>
<prevsection>
<prevsent>the increasing availability of mt engine sand the need for better quality has motivated considerable efforts to combine multiple engines into one super-engine?
</prevsent>
<prevsent>that is hopefully better than any of its ingredients, an idea pionieered in (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1076 ">
so far, the larger group of related publications has focused on the task of selecting, from set of translation candidates obtained from different engines, one translation that looks most promising (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba etal., 2001; callison-burch and flournoy, 2001; akiba et al, 2002; <papid> C02-1076 </papid>nomoto, 2004).<papid> P04-1063 </papid></citsent>
<aftsection>
<nextsent>but also the more challenging problem of decomposing the candidates and re-assembling from the pieces new sentence, hopefully better than any of the given inputs, has recently gained considerable attention (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005).
</nextsent>
<nextsent>although statistical mt approaches currently come out as winners in most comparative evaluations, it is clear that the achievable quality of methods relying purely on lookup of fixed phrases will be limited by the simple fact that for any given combination of topic, application scenario, language pair, and text style there will never be sufficient amounts of pre-existing translations to satisfy the needs of purely data-driven approaches.
</nextsent>
<nextsent>rule-based approaches can exploit the effort that goes into single entries in their knowledge repositories in broader way, as these entries can be unfolded, via rule applications, into large numbers of possible usages.
</nextsent>
<nextsent>however, this increased generality comes at significant costs for the acquisition of the required knowledge, which needs to be encoded by specialists in formalisms requiring extensive training to be used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2549">
<title id=" W05-0828.xml">first steps towards multiengine machine translation </title>
<section> motivation and long-term perspective.  </section>
<citcontext>
<prevsection>
<prevsent>the increasing availability of mt engine sand the need for better quality has motivated considerable efforts to combine multiple engines into one super-engine?
</prevsent>
<prevsent>that is hopefully better than any of its ingredients, an idea pionieered in (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1063 ">
so far, the larger group of related publications has focused on the task of selecting, from set of translation candidates obtained from different engines, one translation that looks most promising (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba etal., 2001; callison-burch and flournoy, 2001; akiba et al, 2002; <papid> C02-1076 </papid>nomoto, 2004).<papid> P04-1063 </papid></citsent>
<aftsection>
<nextsent>but also the more challenging problem of decomposing the candidates and re-assembling from the pieces new sentence, hopefully better than any of the given inputs, has recently gained considerable attention (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005).
</nextsent>
<nextsent>although statistical mt approaches currently come out as winners in most comparative evaluations, it is clear that the achievable quality of methods relying purely on lookup of fixed phrases will be limited by the simple fact that for any given combination of topic, application scenario, language pair, and text style there will never be sufficient amounts of pre-existing translations to satisfy the needs of purely data-driven approaches.
</nextsent>
<nextsent>rule-based approaches can exploit the effort that goes into single entries in their knowledge repositories in broader way, as these entries can be unfolded, via rule applications, into large numbers of possible usages.
</nextsent>
<nextsent>however, this increased generality comes at significant costs for the acquisition of the required knowledge, which needs to be encoded by specialists in formalisms requiring extensive training to be used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2550">
<title id=" W05-0828.xml">first steps towards multiengine machine translation </title>
<section> heuristic selection.  </section>
<citcontext>
<prevsection>
<prevsent>in order to obtain first impression of the potential of triangulation in the domain of parliament debates, we applied the selection heuristics to set of four translations, one from finnish, the other three the result of the selections mentioned above.
</prevsent>
<prevsent>3.2 results and discussion.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>for 10 direct translations and 4 sets of heuristic selections 4admittedly, in typical instances of such chains, english would appear earlier.</citsent>
<aftsection>
<nextsent>source mt bleu language engine score de pharaoh 20.48 &amp; 13.97 systran 14.92 heuristic selection 16.01 statistical selection 20.55 fr pharaoh 26.29 &amp; 17.82 systran 20.29 heuristic selection 21.44 statistical selection 26.49 es pharaoh 26.69 &amp; 17.28 systran 17.38 heuristic selection 19.16 statistical selection 26.74 fi pharaoh 16.76 all heuristic selection 22.83 statistical selection 25.80 table 1: bleu scores of various mt engines and combinations thereof are given in table 1.
</nextsent>
<nextsent>these results show that in each group of translations forgiven source language, the statistical engine came out best.
</nextsent>
<nextsent>furthermore, our heuristic approach for the selection of the best among small set of candidate translations did not result in an increase of the measured bleu score, but typically gave score that wasonly slightly better than the second best of the ingredients.
</nextsent>
<nextsent>this somewhat disappointing result can be explained in two ways.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2551">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present experimental results demonstrating that scissor produces more accurate semantic representations than several previous approaches.
</prevsent>
<prevsent>most recent work in learning for semantic parsing has focused on shallow?
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
analysis such as semantic role labeling (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>in this paper, we address the more ambitious task of learning to map sentences to complete formal meaning representation language (mrl).
</nextsent>
<nextsent>we consider two mrls that can be directly used to perform useful, complex tasks.
</nextsent>
<nextsent>the first is prolog-based language used in previously-developed corpus of queries to database on u.s. geography (zelle and mooney, 1996).
</nextsent>
<nextsent>the second mrl is coaching language for robotic soccer developed for the robocup coach competition, in which ai researchers compete to provide effective instructions to coach able team of agents in simulated soccer domain (et al, 2003).we present an approach based on statistical parser that generates semantically augmented parse tree (sapt), in which each internal node includes both syntactic and semantic label.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2552">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second mrl is coaching language for robotic soccer developed for the robocup coach competition, in which ai researchers compete to provide effective instructions to coach able team of agents in simulated soccer domain (et al, 2003).we present an approach based on statistical parser that generates semantically augmented parse tree (sapt), in which each internal node includes both syntactic and semantic label.
</prevsent>
<prevsent>we augment collins?
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
head-driven model 2 (collins, 1997) <papid> P97-1003 </papid>to incorporate semantic label on each internalnode.</citsent>
<aftsection>
<nextsent>by integrating syntactic and semantic interpretation into single statistical model and finding the globally most likely parse, an accurate combined syntactic/semantic analysis can be obtained.
</nextsent>
<nextsent>once sapt is generated, an additional step is required to translate it into final formal meaning representation (mr).
</nextsent>
<nextsent>our approach is implemented in system called scissor (semantic composition that integrates syntax and semantics to get optimal representations).
</nextsent>
<nextsent>training the system requires sentences annotated with both gold-standard sapts and mrs. we present experimental results on corpora for bothgeography-database querying and robocup coaching demonstrating that scissor produces more accurate semantic representations than several previous approaches based on symbolic learning (tang and mooney, 2001; kate et al, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2555">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> corpus annotation.  </section>
<citcontext>
<prevsection>
<prevsent>due to space limitations, we do not present the straightforward techniques we used to handle them.
</prevsent>
<prevsent>this section discusses how sentences for training scissor were manually annotated with sapts. sentences were parsed by collins?
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
head-driven model 2 (bikel, 2004) (<papid> J04-4004 </papid>trained on sections 02-21 of the wsj penn treebank) to generate an initial syntactic parse tree.</citsent>
<aftsection>
<nextsent>the trees were then manually corrected and each node augmented with semantic label.
</nextsent>
<nextsent>first, semantic labels for individual words, called semantic tags, are added to the pos nodes in thetree.
</nextsent>
<nextsent>the tag null is used for words that have no corresponding concept.
</nextsent>
<nextsent>some concepts are conveyed by phrases, like has the ball?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2573">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>into logical form (zelle and mooney, 1996).
</prevsent>
<prevsent>the average length of an nl sentence in this corpus is 6.87 words.
</prevsent>
</prevsection>
<citsent citstr=" C04-1021 ">
the queries in this corpus are more complex than those in the atis database-query corpus used in the speech community (zue and glass, 2000) which makes the geo query problem harder, as also shown by the results in (popescu et al, 2004).<papid> C04-1021 </papid></citsent>
<aftsection>
<nextsent>the average number of possible semantic tags for each word which can represent meanings in clang is 1.59 and that in geo query is 1.46.
</nextsent>
<nextsent>scissor was evaluated using standard 10-fold cross validation.
</nextsent>
<nextsent>nl test sentences are first parsed to generate their sapts, then their mrs were built from the trees.
</nextsent>
<nextsent>we measured the number of test sentences that produced complete mrs, and the number of these mrs that were correct.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2574">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>by comparison, scissor is more general and can work with other mrls as well (e.g. clang).
</prevsent>
<prevsent>also, precise is nota learning system and can fail to parse query it considers ambiguous, even though it may not be considered ambiguous by human and could potentially be resolved by learning regularities in the training data.
</prevsent>
</prevsection>
<citsent citstr=" W04-0902 ">
in (lev et al, 2004), <papid> W04-0902 </papid>syntax-driven approach is used to map logic puzzles described in nl to an mrl.</citsent>
<aftsection>
<nextsent>the syntactic structures are paired with hand-written rules.
</nextsent>
<nextsent>a statistical parser is used to generate syntactic parse trees, and then mrs are built using compositional semantics.
</nextsent>
<nextsent>the meaning of open-category words (with only few exceptions) is considered irrelevant to solving the puzzle and their meanings are not resolved.
</nextsent>
<nextsent>further steps would be needed to generate mrs in other domains like clang and geoquery.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2575">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several machine translation systems also attempt to generate mrs for sentences.
</prevsent>
<prevsent>in (et al, 2002), an english-chinese speech translation system for limited domains is described.
</prevsent>
</prevsection>
<citsent citstr=" P93-1005 ">
they train statistical parser on trees with only semantic labels on the nodes; however, they do not integrate syntactic and semantic parsing.history-based models of parsing were first introduced in (black et al, 1993).<papid> P93-1005 </papid></citsent>
<aftsection>
<nextsent>their original model also included semantic labels on parse-tree nodes, but they were not used to generate formalmr.
</nextsent>
<nextsent>also, their parsing model is impoverished compared to the history included in collins?
</nextsent>
<nextsent>more recent model.
</nextsent>
<nextsent>scissor explores incorporating semantic labels into collins?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2576">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recent model.
</prevsent>
<prevsent>scissor explores incorporating semantic labels into collins?
</prevsent>
</prevsection>
<citsent citstr=" P96-1008 ">
model in order to produce complete sapt which is then used to generate formal mr. the systems introduced in (miller et al, 1996; <papid> P96-1008 </papid>miller et al, 2000) <papid> A00-2030 </papid>also integrate semantic labels into parsing; however, their sapts are used to pro 15 duce much simpler mr, i.e., single semantic frame.</citsent>
<aftsection>
<nextsent>a sample frame is air transportation which has three slots ? the arrival time, origin and destination.
</nextsent>
<nextsent>only one frame needs to be extracted from each sentence, which is an easier task thanour problem in which multiple nested frames (pred icates) must be extracted.
</nextsent>
<nextsent>the syntactic model in (miller et al, 2000) <papid> A00-2030 </papid>is similar to collins?, but doesnot use features like subcat frames and distance mea sures.</nextsent>
<nextsent>also, the non-terminal label is not further decomposed into separately-generated semantic and syntactic components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2577">
<title id=" W05-0602.xml">a statistical semantic parser that integrates syntax and semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recent model.
</prevsent>
<prevsent>scissor explores incorporating semantic labels into collins?
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
model in order to produce complete sapt which is then used to generate formal mr. the systems introduced in (miller et al, 1996; <papid> P96-1008 </papid>miller et al, 2000) <papid> A00-2030 </papid>also integrate semantic labels into parsing; however, their sapts are used to pro 15 duce much simpler mr, i.e., single semantic frame.</citsent>
<aftsection>
<nextsent>a sample frame is air transportation which has three slots ? the arrival time, origin and destination.
</nextsent>
<nextsent>only one frame needs to be extracted from each sentence, which is an easier task thanour problem in which multiple nested frames (pred icates) must be extracted.
</nextsent>
<nextsent>the syntactic model in (miller et al, 2000) <papid> A00-2030 </papid>is similar to collins?, but doesnot use features like subcat frames and distance mea sures.</nextsent>
<nextsent>also, the non-terminal label is not further decomposed into separately-generated semantic and syntactic components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2581">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the computation of surface similarity between pairsof words is an important task in many areas of natural language processing.
</prevsent>
<prevsent>in historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share common origin (oakes, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W01-0504 ">
in statistical machine translation, cognates are helpful in inducing translation lexicons (koehn and knight, 2001; <papid> W01-0504 </papid>mann and yarowsky, 2001), <papid> N01-1020 </papid>sentence alignment (melamed, 1999), <papid> J99-1003 </papid>and word alignment (tiedemann, 2003).</citsent>
<aftsection>
<nextsent>indialectology, similarity is used for estimating distance between dialects (nerbonne, 2003).<papid> E03-1088 </papid></nextsent>
<nextsent>other applications include cross-lingual information retrieval (pirkola et al, 2003), detection of confusabledrug names (kondrak and dorr, 2004), <papid> C04-1137 </papid>and lexicog raphy (brew and mckelvie, 1996).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2582">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the computation of surface similarity between pairsof words is an important task in many areas of natural language processing.
</prevsent>
<prevsent>in historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share common origin (oakes, 2000).
</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
in statistical machine translation, cognates are helpful in inducing translation lexicons (koehn and knight, 2001; <papid> W01-0504 </papid>mann and yarowsky, 2001), <papid> N01-1020 </papid>sentence alignment (melamed, 1999), <papid> J99-1003 </papid>and word alignment (tiedemann, 2003).</citsent>
<aftsection>
<nextsent>indialectology, similarity is used for estimating distance between dialects (nerbonne, 2003).<papid> E03-1088 </papid></nextsent>
<nextsent>other applications include cross-lingual information retrieval (pirkola et al, 2003), detection of confusabledrug names (kondrak and dorr, 2004), <papid> C04-1137 </papid>and lexicog raphy (brew and mckelvie, 1996).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2583">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the computation of surface similarity between pairsof words is an important task in many areas of natural language processing.
</prevsent>
<prevsent>in historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share common origin (oakes, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
in statistical machine translation, cognates are helpful in inducing translation lexicons (koehn and knight, 2001; <papid> W01-0504 </papid>mann and yarowsky, 2001), <papid> N01-1020 </papid>sentence alignment (melamed, 1999), <papid> J99-1003 </papid>and word alignment (tiedemann, 2003).</citsent>
<aftsection>
<nextsent>indialectology, similarity is used for estimating distance between dialects (nerbonne, 2003).<papid> E03-1088 </papid></nextsent>
<nextsent>other applications include cross-lingual information retrieval (pirkola et al, 2003), detection of confusabledrug names (kondrak and dorr, 2004), <papid> C04-1137 </papid>and lexicog raphy (brew and mckelvie, 1996).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2585">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share common origin (oakes, 2000).
</prevsent>
<prevsent>in statistical machine translation, cognates are helpful in inducing translation lexicons (koehn and knight, 2001; <papid> W01-0504 </papid>mann and yarowsky, 2001), <papid> N01-1020 </papid>sentence alignment (melamed, 1999), <papid> J99-1003 </papid>and word alignment (tiedemann, 2003).</prevsent>
</prevsection>
<citsent citstr=" E03-1088 ">
indialectology, similarity is used for estimating distance between dialects (nerbonne, 2003).<papid> E03-1088 </papid></citsent>
<aftsection>
<nextsent>other applications include cross-lingual information retrieval (pirkola et al, 2003), detection of confusabledrug names (kondrak and dorr, 2004), <papid> C04-1137 </papid>and lexicog raphy (brew and mckelvie, 1996).</nextsent>
<nextsent>depending on the context, strong word similarity may indicate either that words share common origin (cognates), common meaning (synonyms), or are related in some way (e.g. spelling variants).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2586">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in statistical machine translation, cognates are helpful in inducing translation lexicons (koehn and knight, 2001; <papid> W01-0504 </papid>mann and yarowsky, 2001), <papid> N01-1020 </papid>sentence alignment (melamed, 1999), <papid> J99-1003 </papid>and word alignment (tiedemann, 2003).</prevsent>
<prevsent>indialectology, similarity is used for estimating distance between dialects (nerbonne, 2003).<papid> E03-1088 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1137 ">
other applications include cross-lingual information retrieval (pirkola et al, 2003), detection of confusabledrug names (kondrak and dorr, 2004), <papid> C04-1137 </papid>and lexicog raphy (brew and mckelvie, 1996).</citsent>
<aftsection>
<nextsent>depending on the context, strong word similarity may indicate either that words share common origin (cognates), common meaning (synonyms), or are related in some way (e.g. spelling variants).
</nextsent>
<nextsent>in this paper, we focus on cognates.
</nextsent>
<nextsent>genetic cognatesare well-suited for testing measures of word similarity because they arise by evolving from single word in proto-language.
</nextsent>
<nextsent>unlike rather indefinite concepts like synonymy or conf usability, cognationis binary notion, which in most cases can be reliably determined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2589">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> pair hidden markov models.  </section>
<citcontext>
<prevsection>
<prevsent>if there is many-to-one correspondence that is consistent between languages, it would be beneficial to change the word representation so thatthe many symbols are considered as single symbol instead.
</prevsent>
<prevsent>for example, group of characters in the orthographic representation may correspond to single phoneme if the word is written phonetically.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
hidden markov models have been applied successfully to number of problems in natural language processing, including speech recognition (jelinek, 1999) and statistical machine translation (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>one of the more intangible aspects of hidden markov model is the choice of the model itself.
</nextsent>
<nextsent>while algorithms exist to train the parameters of the model so that the model better describes its data, there is no formulaic way to create the model.we decided to adopt as starting point model developed in different field of study.durbin et al (1998) created new type of hidden markov model that has been used for the task of aligning biological sequences (figure 1).
</nextsent>
<nextsent>called pair hidden markov model, it uses two output streams in parallel, each corresponding to sequence that is being aligned.1 the alignment model has three states that represent the basic edit operations: substitution (represented by state m?), insertion (y?), and deletion (x?).
</nextsent>
<nextsent>m?, the match state, emits an aligned pair of symbols (not necessarily identical) with one symbol on the top and the other on the bottom output stream.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2590">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> phmms for word similarity.  </section>
<citcontext>
<prevsection>
<prevsent>spon ding algorithms.
</prevsent>
<prevsent>the modified model is shown in figure 3.first, the original models assumption that an insertion followed by deletion is the same as substitution is problematic in the context of word similarity.
</prevsent>
</prevsection>
<citsent citstr=" P98-1043 ">
covington (1998) <papid> P98-1043 </papid>illustrates the problem with an example of italian due?</citsent>
<aftsection>
<nextsent>and the spanish dos?, both of which mean two?.
</nextsent>
<nextsent>while there is no doubt that the first two pairs of symbols should be aligned, there is no historical connection between the italian e? and the spanish s?.
</nextsent>
<nextsent>in this case, sequence of an insertion and deletion is more appropriate than substitution.
</nextsent>
<nextsent>in order to remedy this problem, we decided to add pair of transitions between states x? and y?, which is denoted by ? in figure 3.the second modification involves splitting the parameter ? into two separate values: for the match state, and xy for the gap states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2596">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 significance tests.
</prevsent>
<prevsent>we performed pairwise statistical significance tests for various model and algorithm combinations.
</prevsent>
</prevsection>
<citsent citstr=" C04-1136 ">
following the method proposed by evert (2004), <papid> C04-1136 </papid>we applied fishers exact test to counts of word pairs that are accepted by only one of the two tested al gorithms.</citsent>
<aftsection>
<nextsent>forgiven language pair, the cutoff level was set equal to the actual number of cognate pairs in the list.
</nextsent>
<nextsent>for example, since 118 out of 200 word pairs in the english/german list are cognate, we considered the true and false positives among the set of 118 top scoring pairs.
</nextsent>
<nextsent>for the overall average of number of different language pairs, we took the union of the individual sets.
</nextsent>
<nextsent>for the results in tables 1 and 2, the pooled set contained 567 out of 2000 pairs, which corresponds to the proportion of cognates in the entire test data (28.35%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2599">
<title id=" W05-0606.xml">computing word similarity and identifying cognates with pair hidden markov models </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the lcsr of two words is computed by dividing the length of their longest common sub sequence by the length of the longer word.
</prevsent>
<prevsent>llw stands for levenshteinwith learned weights?, which is described in section 4.4.
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
we also include the results obtained by the aline word aligner (kondrak, 2000) <papid> A00-2038 </papid>on phonetically-transcribed word lists.</citsent>
<aftsection>
<nextsent>because of the relatively small size of the lists,the differences among results for individual language pairs are not statistically significant in many cases.
</nextsent>
<nextsent>however, when the average over all language pairs is considered, the viterbi-based log odds algorithm (log) is significantly better than all other algorithms in table 2.
</nextsent>
<nextsent>the differences between the remaining algorithms are not statistically significant, except that they all significantly outperform the lcsr baseline.
</nextsent>
<nextsent>the fact that log is significantly better than aline demonstrates that given sufficiently large training set, an hmm-based algorithm can automatically learn the notion of phonetic similarity, whichis incorporated into aline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2600">
<title id=" W04-2906.xml">assessing prosodic and text features for segmentation of mandarin broadcast news </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this structure in turn guides the interpretation of individual utterances and the discourse as whole.
</prevsent>
<prevsent>formal written discourse signals hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
this structure, in turn, identifies domains for in terpretation; many systems for anaphora resolution relyon some notion of locality (grosz and sidner, 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>similarly, this structure represents topical organization,and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic.
</nextsent>
<nextsent>unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse.
</nextsent>
<nextsent>instead, one must infer the hierarchical structure of spoken discourse from other cues.
</nextsent>
<nextsent>prior research (nakatani et al, 1995; swerts, 1997) has shown that human label ers can more sharply, consistently, and confidently identify discourse structure in aword-level transcription when an original audio recording is available than they can on the basis of the transcribed text alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2601">
<title id=" W04-2906.xml">assessing prosodic and text features for segmentation of mandarin broadcast news </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>not only is the useof prosodic cues to topic segmentation much less well studied in general than is the use of text cues, but the use of prosodic cues has been largely limited to english and other european languages.
</prevsent>
<prevsent>most prior research on automatic topic segmentation hasbeen applied to clean text only and thus used textual features.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
text-based segmentation approaches have utilizedterm-based similarity measures computed across candidate segments (hearst, 1994) <papid> P94-1002 </papid>and also discourse markers to identify discourse structure (marcu, 2000).</citsent>
<aftsection>
<nextsent>the topic detection and tracking (tdt) evaluations focused on segmentation of both text and speech sources.
</nextsent>
<nextsent>this framework introduced new challenges in dealing with error ful automatic transcriptions as well as new opportunities to exploit cues in the original speech.
</nextsent>
<nextsent>themost successful approach (beeferman et al, 1999) produced automatic segment ations that yielded retrieval results comparable to those with manual segment ations, using text and silence features.
</nextsent>
<nextsent>(tur et al, 2001) <papid> J01-1002 </papid>applied both prosody-only and mixed text-prosody model to segmentation of tdt english broadcast news, with the best results combining text and prosodic features.(hirschberg and nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of english broadcast news.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2602">
<title id=" W04-2906.xml">assessing prosodic and text features for segmentation of mandarin broadcast news </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this framework introduced new challenges in dealing with error ful automatic transcriptions as well as new opportunities to exploit cues in the original speech.
</prevsent>
<prevsent>themost successful approach (beeferman et al, 1999) produced automatic segment ations that yielded retrieval results comparable to those with manual segment ations, using text and silence features.
</prevsent>
</prevsection>
<citsent citstr=" J01-1002 ">
(tur et al, 2001) <papid> J01-1002 </papid>applied both prosody-only and mixed text-prosody model to segmentation of tdt english broadcast news, with the best results combining text and prosodic features.(hirschberg and nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of english broadcast news.</citsent>
<aftsection>
<nextsent>work in discourse analysis (nakatani et al, 1995; swerts, 1997) in both english and dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries and with boundaries of different strengths.
</nextsent>
<nextsent>we utilize the topic detection and tracking (tdt) 3 (wayne, 2000) collection mandarin chinese broadcast news audio corpus as our dataset.
</nextsent>
<nextsent>story segmentation in mandarin and english broadcast news and newswire textwas one of the tdt tasks and also an enabling technology for other retrieval tasks.
</nextsent>
<nextsent>we use the segment boundaries provided with the corpus as our gold standard labeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2603">
<title id=" W04-2906.xml">assessing prosodic and text features for segmentation of mandarin broadcast news </title>
<section> prosodic features.  </section>
<citcontext>
<prevsection>
<prevsent>we have found highly significant differences based on paired t-test two-tailed, ( ffflfiffi  !
</prevsent>
<prevsent>#$ ) for words in segment-final position, relative to the same word in non-final positions.
</prevsent>
</prevsection>
<citsent citstr=" N04-4035 ">
(levow, 2004).<papid> N04-4035 </papid></citsent>
<aftsection>
<nextsent>specifically, word duration, normalized mean pitch, and normalized mean intensity all differ significantly for words in topic final position relative to occurrences throughout the story.
</nextsent>
<nextsent>word duration increases, while both pitch and intensity decrease.
</nextsent>
<nextsent>importantly, reduction in pitch as signal of topic finality is robust across the typo logical contrast of tone and non-tone languages, such as english (nakatani et al, 1995) and dutch (swerts, 1997).
</nextsent>
<nextsent>1this is an imperfect approximation as some stories include off-site interviews, but seems reasonable choice in the absence of automatic speaker identification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2604">
<title id=" W04-3232.xml">identifying broken plurals in unvowelised arabic text </title>
<section> arabic morphology and its number.  </section>
<citcontext>
<prevsection>
<prevsent>its grammatical system is traditionally described in terms of root-and-pattern structure, with about 10,000 roots (ali, 1988).
</prevsent>
<prevsent>roots such as drs (
</prevsent>
</prevsection>
<citsent citstr=" C96-1017 ">
) and ktb () are listed alphabetically in standard arabic dictionaries like the wehr-cowan (beesley, 1996).<papid> C96-1017 </papid></citsent>
<aftsection>
<nextsent>the root is the most basic verb form.
</nextsent>
<nextsent>roots are categorized into: tri literal, quadriliteral, or rarely pentaliteral.
</nextsent>
<nextsent>most words are derived from finite set of roots formed by adding diacritics1 or affixes (prefixes, suffixes, and infixes) through an application of fixed patterns which are templates to help in deriving inflectional and derivational forms of word.
</nextsent>
<nextsent>theoretically, several hundreds of arabic words can be derived from single root.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2605">
<title id=" W04-3232.xml">identifying broken plurals in unvowelised arabic text </title>
<section> arabic morphology and its number.  </section>
<citcontext>
<prevsection>
<prevsent>some of which especially concerned with broken plurals (mccarthy and prince, 1990b; kiraz, 1996a; idrissi, 1997).
</prevsent>
<prevsent>these are successful to varying degrees, but have main practical drawback in the context of information retrieval: they assume that words are fully vowelised.
</prevsent>
</prevsection>
<citsent citstr=" W98-1001 ">
unfortunately, short vowels are usually not written in published arabic text, with the exception of the religious texts (e.g., the holy quran), poetry, and books for school children (abuleil and evens, 1998).<papid> W98-1001 </papid></citsent>
<aftsection>
<nextsent>we tested several different approaches for bp identification: simple bp matching, restricted bp matching (hand restricted &amp; decision tree restricted), and dictionary approach.
</nextsent>
<nextsent>3.1 the simple bp matching approach.
</nextsent>
<nextsent>given the characterisation of broken plurals one finds in standard arabic grammars, the most obvious method for identifying broken plural is to light stem it (strip off any prefixes and/or suffixes), then trying to match the obtained stem against bp patterns found in standard grammars.
</nextsent>
<nextsent>since this method is widely used, we adopted it as baseline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2606">
<title id=" W04-3112.xml">using natural language processing locus link and the gene ontology to compare omim to medline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semgen identifies gene interaction predications based on semantic interpretation adapted from semrep (srini vasan and rindflesch 2002; rindflesch and fiszman 2003), general natural language processing system being developed for the biomedical domain.
</prevsent>
<prevsent>after the application of statistically-based labeled categorizer (humphrey 1999) that limits input text to the molecular biology domain, semgen processing proceeds in three major phases: categorial analysis, identification of concepts, and identification of relations.
</prevsent>
</prevsection>
<citsent citstr=" A92-1018 ">
the initial phase relies on parser that draws on the specialist lexicon (mccray et al 1994) and the xerox part-of-speech tagger (cutting et al 1992) <papid> A92-1018 </papid>to produce an underspecified categorial analysis.</citsent>
<aftsection>
<nextsent>in the phase for identifying concepts, disorders as well as genes and proteins are isolated by mapping simple noun phrases from the previous phase to concepts in the unified medical language system?
</nextsent>
<nextsent>(umls)?
</nextsent>
<nextsent>metathesaurus?
</nextsent>
<nextsent>(humphreys et al 1998), using metamap (aronson 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2607">
<title id=" W04-2709.xml">inter lingual annotation of multilingual text corpora </title>
<section> interlingua.  </section>
<citcontext>
<prevsection>
<prevsent>4.1.3 il2 il2 is intended to be an interlingua, representation of meaning that is reasonably independent of language.
</prevsent>
<prevsent>il2 is intended to capture similarities in meaning across languages and across different lexical/syntactic realizations within language.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
for example, il2 is expected to normalize over conversives (e.g. bought book from vs. sold book to x) (as does framenet (baker et al  1998)) <papid> P98-1013 </papid>and non-literal language usage (e.g. started its business vs. opened its doors to customers).</citsent>
<aftsection>
<nextsent>the exact definition of il2 will be the major research contribution of this project.
</nextsent>
<nextsent>4.2 the omega ontology.
</nextsent>
<nextsent>in progressing from il0 to il1, annotators have to select semantic terms (concepts) to represent the nouns, verbs, adjectives, and adverbs present in each sentence.
</nextsent>
<nextsent>these terms are represented in the 110,000-node ontology omega (philpot et al , 2003), under construction at isi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2608">
<title id=" W04-2709.xml">inter lingual annotation of multilingual text corpora </title>
<section> interlingua.  </section>
<citcontext>
<prevsection>
<prevsent>after the uppermost region of omega was created by hand, these various resources?
</prevsent>
<prevsent>contents were incorporated and, to some extent, reconciled.
</prevsent>
</prevsection>
<citsent citstr=" P03-1001 ">
after that, several million instances of people, locations, and other facts were added (fleischman et al , 2003).<papid> P03-1001 </papid></citsent>
<aftsection>
<nextsent>the ontology, which has been used in several projects in recent years (hovy et al , 2001), can be browsed using the dino browser at http://blombos.isi.edu:8000/dino; this browser forms part of the annotation environment.
</nextsent>
<nextsent>omega remains under continued development and extension.
</nextsent>
<nextsent>4.3 the theta grids.
</nextsent>
<nextsent>each verb in omega is assigned one or more theta grids specifying the arguments associated with verb and their theta roles (or thematic role).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2609">
<title id=" W04-2709.xml">inter lingual annotation of multilingual text corpora </title>
<section> annotation task.  </section>
<citcontext>
<prevsection>
<prevsent>the process for non-english texts will be, mutatis mutandis, the same.
</prevsent>
<prevsent>each sentence of the text is parsed into dependency tree structure.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
for english texts, these trees were first provided by the conn exor parser at umiacs (tapanainen and jarvinen, 1997), <papid> A97-1011 </papid>and then corrected by one of the team pis.</citsent>
<aftsection>
<nextsent>for the initial testing period, annotators were not permitted to alter these structures.
</nextsent>
<nextsent>already at this stage, some of the lexical items are replaced by features (e.g., tense), morphological forms are replaced by features on the citation form, and certain constructions are regularized (e.g., passive) and empty arguments inserted.
</nextsent>
<nextsent>it is this dependency structure that is loaded into the annotation tool and which each annotator then marks up.
</nextsent>
<nextsent>the annotator was instructed to annotate all nouns, verbs, adjectives, and adverbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2611">
<title id=" W06-0107.xml">latent features in automatic tense translation between chinese and english </title>
<section> experiments and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this is because the conditional model makes it unnecessary to explicitly represent and model the dependencies among the input variables, thus making it feasible to use interacting and global features from the input.
</prevsent>
<prevsent>crfs also avoid the label bias problem exhibited by maximum entropy markov models (memms) and other conditional markov models based on directed graphical models.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
crfs have been shown to perform well on number of nlp problems such as shallow parsing (sha and pereira, 2003), <papid> N03-1028 </papid>table extraction (pinto et al, 2003), and named entity recognition (mccallum and li, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>for our experiments, we use the mallet implementation of crfs (mccallum, 2002).
</nextsent>
<nextsent>5.2 experiments.
</nextsent>
<nextsent>5.2.1 human inter-annotator agreement all supervised learning algorithms require certain amount of training data, and the reliability of the computational solutions is intricately tiedto the accuracy of the annotated data.
</nextsent>
<nextsent>human annotations typically suffer from errors, subjectivity, and the expertise effect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2612">
<title id=" W06-0107.xml">latent features in automatic tense translation between chinese and english </title>
<section> experiments and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this is because the conditional model makes it unnecessary to explicitly represent and model the dependencies among the input variables, thus making it feasible to use interacting and global features from the input.
</prevsent>
<prevsent>crfs also avoid the label bias problem exhibited by maximum entropy markov models (memms) and other conditional markov models based on directed graphical models.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
crfs have been shown to perform well on number of nlp problems such as shallow parsing (sha and pereira, 2003), <papid> N03-1028 </papid>table extraction (pinto et al, 2003), and named entity recognition (mccallum and li, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>for our experiments, we use the mallet implementation of crfs (mccallum, 2002).
</nextsent>
<nextsent>5.2 experiments.
</nextsent>
<nextsent>5.2.1 human inter-annotator agreement all supervised learning algorithms require certain amount of training data, and the reliability of the computational solutions is intricately tiedto the accuracy of the annotated data.
</nextsent>
<nextsent>human annotations typically suffer from errors, subjectivity, and the expertise effect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2613">
<title id=" W06-0130.xml">chinese named entity recognition with conditional probabilistic models </title>
<section> named entity recognizer.  </section>
<citcontext>
<prevsection>
<prevsent>while in crfs, these two steps are integrated together.
</prevsent>
<prevsent>thus, in theory, crfs are superior to maximum entropy models in sequence modeling problem and this will also confirmed in our chinese ner experiments.
</prevsent>
</prevsection>
<citsent citstr=" C04-1081 ">
the superiority of crfs on chinese information processing was also demonstrated in word segmentation (peng et al 2004).<papid> C04-1081 </papid></citsent>
<aftsection>
<nextsent>however, the training speed of crfs is much slower than that of maximum entropy models since training crfs requires expensive forward-backward algorithm to compute the partition function.
</nextsent>
<nextsent>173 we used takus crf package1 to train the first crf recognizer, and the mallet 2 package with bfgs optimization to train the second crf recognizer.
</nextsent>
<nextsent>we used c++ implementation3 of maximum entropy modeling and wrote our own second order dynamic programming for decoding.
</nextsent>
<nextsent>2.2 features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2614">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>a referential description [donellan 1966] serves the purpose of letting the hearer or reader identify particular object or set of objects in given situation.
</prevsent>
<prevsent>the referring expression to be generated is required to be distinguishing description, that is description of the enitties being referred to, but not to any other object in the context set.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
a context set is defined as the set of the entities the addressee is currently assumed to be attending to ? this is similar to the set of entities in the focus spaces of the discourse focus stack in grosz  and sidner [1986] <papid> J86-3001 </papid>theory of discourse structure.</citsent>
<aftsection>
<nextsent>moreover, the contrast set (or the set of potential dis tractors [mcdonald 1981]) is defined to entail all elements of the context set except the intended referents.
</nextsent>
<nextsent>generating referring expressions is pursued since the eighties [appelt 1985, kronfeld 1986, <papid> P86-1029 </papid>appelt and kronfeld 1987].</nextsent>
<nextsent>subsequent years were characterized by debate about computational efficiency versus minimality of the elements appearing in the resulting referring expression [dale 1988, reiter 1990, <papid> P90-1013 </papid>reiter and dale 1992].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2615">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>a context set is defined as the set of the entities the addressee is currently assumed to be attending to ? this is similar to the set of entities in the focus spaces of the discourse focus stack in grosz  and sidner [1986] <papid> J86-3001 </papid>theory of discourse structure.</prevsent>
<prevsent>moreover, the contrast set (or the set of potential dis tractors [mcdonald 1981]) is defined to entail all elements of the context set except the intended referents.</prevsent>
</prevsection>
<citsent citstr=" P86-1029 ">
generating referring expressions is pursued since the eighties [appelt 1985, kronfeld 1986, <papid> P86-1029 </papid>appelt and kronfeld 1987].</citsent>
<aftsection>
<nextsent>subsequent years were characterized by debate about computational efficiency versus minimality of the elements appearing in the resulting referring expression [dale 1988, reiter 1990, <papid> P90-1013 </papid>reiter and dale 1992].</nextsent>
<nextsent>in the mid-nineties, this debate seemed to be settled in favor of the incremental approach [dale and reiter 1995] ? motivated by results of psychological experiments [levelt 1989, pechmann 1989], certain non-minimal expressions are tolerated in favor of adopting the fast strategy of incrementally selecting ambi guity-reducing attributes from domain-dependent preference list.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2616">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the contrast set (or the set of potential dis tractors [mcdonald 1981]) is defined to entail all elements of the context set except the intended referents.
</prevsent>
<prevsent>generating referring expressions is pursued since the eighties [appelt 1985, kronfeld 1986, <papid> P86-1029 </papid>appelt and kronfeld 1987].</prevsent>
</prevsection>
<citsent citstr=" P90-1013 ">
subsequent years were characterized by debate about computational efficiency versus minimality of the elements appearing in the resulting referring expression [dale 1988, reiter 1990, <papid> P90-1013 </papid>reiter and dale 1992].</citsent>
<aftsection>
<nextsent>in the mid-nineties, this debate seemed to be settled in favor of the incremental approach [dale and reiter 1995] ? motivated by results of psychological experiments [levelt 1989, pechmann 1989], certain non-minimal expressions are tolerated in favor of adopting the fast strategy of incrementally selecting ambi guity-reducing attributes from domain-dependent preference list.
</nextsent>
<nextsent>recently, algorithms have been applied to the identification of sets of objects rather than individuals [bateman 1999, <papid> P99-1017 </papid>stone 2000, <papid> W00-1416 </papid>krahmer, v. erk, and verweg 2001], and the repertoire of descriptions has been extended to boolean combinations of attributes, including neg ations [van deemter 2002].</nextsent>
<nextsent>to avoid the generation of redundant descriptions that is typical for incremental approaches, gardent [2002] <papid> P02-1013 </papid>and horacek [2003] <papid> E03-1017 </papid>proposed exhaustive resp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2617">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>subsequent years were characterized by debate about computational efficiency versus minimality of the elements appearing in the resulting referring expression [dale 1988, reiter 1990, <papid> P90-1013 </papid>reiter and dale 1992].</prevsent>
<prevsent>in the mid-nineties, this debate seemed to be settled in favor of the incremental approach [dale and reiter 1995] ? motivated by results of psychological experiments [levelt 1989, pechmann 1989], certain non-minimal expressions are tolerated in favor of adopting the fast strategy of incrementally selecting ambi guity-reducing attributes from domain-dependent preference list.</prevsent>
</prevsection>
<citsent citstr=" P99-1017 ">
recently, algorithms have been applied to the identification of sets of objects rather than individuals [bateman 1999, <papid> P99-1017 </papid>stone 2000, <papid> W00-1416 </papid>krahmer, v. erk, and verweg 2001], and the repertoire of descriptions has been extended to boolean combinations of attributes, including neg ations [van deemter 2002].</citsent>
<aftsection>
<nextsent>to avoid the generation of redundant descriptions that is typical for incremental approaches, gardent [2002] <papid> P02-1013 </papid>and horacek [2003] <papid> E03-1017 </papid>proposed exhaustive resp.</nextsent>
<nextsent>best-first searches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2618">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>subsequent years were characterized by debate about computational efficiency versus minimality of the elements appearing in the resulting referring expression [dale 1988, reiter 1990, <papid> P90-1013 </papid>reiter and dale 1992].</prevsent>
<prevsent>in the mid-nineties, this debate seemed to be settled in favor of the incremental approach [dale and reiter 1995] ? motivated by results of psychological experiments [levelt 1989, pechmann 1989], certain non-minimal expressions are tolerated in favor of adopting the fast strategy of incrementally selecting ambi guity-reducing attributes from domain-dependent preference list.</prevsent>
</prevsection>
<citsent citstr=" W00-1416 ">
recently, algorithms have been applied to the identification of sets of objects rather than individuals [bateman 1999, <papid> P99-1017 </papid>stone 2000, <papid> W00-1416 </papid>krahmer, v. erk, and verweg 2001], and the repertoire of descriptions has been extended to boolean combinations of attributes, including neg ations [van deemter 2002].</citsent>
<aftsection>
<nextsent>to avoid the generation of redundant descriptions that is typical for incremental approaches, gardent [2002] <papid> P02-1013 </papid>and horacek [2003] <papid> E03-1017 </papid>proposed exhaustive resp.</nextsent>
<nextsent>best-first searches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2619">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the mid-nineties, this debate seemed to be settled in favor of the incremental approach [dale and reiter 1995] ? motivated by results of psychological experiments [levelt 1989, pechmann 1989], certain non-minimal expressions are tolerated in favor of adopting the fast strategy of incrementally selecting ambi guity-reducing attributes from domain-dependent preference list.
</prevsent>
<prevsent>recently, algorithms have been applied to the identification of sets of objects rather than individuals [bateman 1999, <papid> P99-1017 </papid>stone 2000, <papid> W00-1416 </papid>krahmer, v. erk, and verweg 2001], and the repertoire of descriptions has been extended to boolean combinations of attributes, including neg ations [van deemter 2002].</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
to avoid the generation of redundant descriptions that is typical for incremental approaches, gardent [2002] <papid> P02-1013 </papid>and horacek [2003] <papid> E03-1017 </papid>proposed exhaustive resp.</citsent>
<aftsection>
<nextsent>best-first searches.
</nextsent>
<nextsent>all these procedures more or less share the design of the underlying knowledge base.
</nextsent>
<nextsent>objects are conceived in terms of sets of attributes, each with anatomic value as its filler.
</nextsent>
<nextsent>some models distinguish specializations of these values according to taxonomic hierarchy, so that the most accurate value can be replaced by one of its generalizations if there are reasons to assume this alternative is preferable ? due to insufficient knowledge attributed to the audience, or to prevent unintended implications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2620">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the mid-nineties, this debate seemed to be settled in favor of the incremental approach [dale and reiter 1995] ? motivated by results of psychological experiments [levelt 1989, pechmann 1989], certain non-minimal expressions are tolerated in favor of adopting the fast strategy of incrementally selecting ambi guity-reducing attributes from domain-dependent preference list.
</prevsent>
<prevsent>recently, algorithms have been applied to the identification of sets of objects rather than individuals [bateman 1999, <papid> P99-1017 </papid>stone 2000, <papid> W00-1416 </papid>krahmer, v. erk, and verweg 2001], and the repertoire of descriptions has been extended to boolean combinations of attributes, including neg ations [van deemter 2002].</prevsent>
</prevsection>
<citsent citstr=" E03-1017 ">
to avoid the generation of redundant descriptions that is typical for incremental approaches, gardent [2002] <papid> P02-1013 </papid>and horacek [2003] <papid> E03-1017 </papid>proposed exhaustive resp.</citsent>
<aftsection>
<nextsent>best-first searches.
</nextsent>
<nextsent>all these procedures more or less share the design of the underlying knowledge base.
</nextsent>
<nextsent>objects are conceived in terms of sets of attributes, each with anatomic value as its filler.
</nextsent>
<nextsent>some models distinguish specializations of these values according to taxonomic hierarchy, so that the most accurate value can be replaced by one of its generalizations if there are reasons to assume this alternative is preferable ? due to insufficient knowledge attributed to the audience, or to prevent unintended implications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2621">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>redundant expressions motivated by uncertainties about recognition cannot be generated under any modeling alternative.
</prevsent>
<prevsent>there are only few computational approaches which address the problem of uncertainty about the recognition of referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" C94-2182 ">
for example, [edmonds 1994] <papid> C94-2182 </papid>and [heeman and hirst 1995] <papid> J95-3003 </papid>describe both plan-based methods, where vague and partial description is produced initially, which is narrowed and ultimately confirmed in the subsequent discourse.</citsent>
<aftsection>
<nextsent>however, the documented examples do only emphasize incomplete, but never incorrect interpretations.
</nextsent>
<nextsent>an approach that fits better to our intentions is the work by goodman [1987], which emphasizes reference identification and associated failures in task-oriented dialogs [goodman 1986].<papid> J86-4002 </papid></nextsent>
<nextsent>this case study demonstrates various impacts of limitations and discrepancies of expertise on referential identification: subjects exhibit uncertainty in identification, which manifests itself in tentative actions and changes of mind, they misinterpret descriptions (e.g.,  outlet  interpreted as  hole ), and they may find no appropriate referent at all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2622">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>redundant expressions motivated by uncertainties about recognition cannot be generated under any modeling alternative.
</prevsent>
<prevsent>there are only few computational approaches which address the problem of uncertainty about the recognition of referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" J95-3003 ">
for example, [edmonds 1994] <papid> C94-2182 </papid>and [heeman and hirst 1995] <papid> J95-3003 </papid>describe both plan-based methods, where vague and partial description is produced initially, which is narrowed and ultimately confirmed in the subsequent discourse.</citsent>
<aftsection>
<nextsent>however, the documented examples do only emphasize incomplete, but never incorrect interpretations.
</nextsent>
<nextsent>an approach that fits better to our intentions is the work by goodman [1987], which emphasizes reference identification and associated failures in task-oriented dialogs [goodman 1986].<papid> J86-4002 </papid></nextsent>
<nextsent>this case study demonstrates various impacts of limitations and discrepancies of expertise on referential identification: subjects exhibit uncertainty in identification, which manifests itself in tentative actions and changes of mind, they misinterpret descriptions (e.g.,  outlet  interpreted as  hole ), and they may find no appropriate referent at all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2623">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>for example, [edmonds 1994] <papid> C94-2182 </papid>and [heeman and hirst 1995] <papid> J95-3003 </papid>describe both plan-based methods, where vague and partial description is produced initially, which is narrowed and ultimately confirmed in the subsequent discourse.</prevsent>
<prevsent>however, the documented examples do only emphasize incomplete, but never incorrect interpretations.</prevsent>
</prevsection>
<citsent citstr=" J86-4002 ">
an approach that fits better to our intentions is the work by goodman [1987], which emphasizes reference identification and associated failures in task-oriented dialogs [goodman 1986].<papid> J86-4002 </papid></citsent>
<aftsection>
<nextsent>this case study demonstrates various impacts of limitations and discrepancies of expertise on referential identification: subjects exhibit uncertainty in identification, which manifests itself in tentative actions and changes of mind, they misinterpret descriptions (e.g.,  outlet  interpreted as  hole ), and they may find no appropriate referent at all.
</nextsent>
<nextsent>in the latter case, subject even undertake attempts to repair an otherwise uninterpretable description by relaxing descriptors.
</nextsent>
<nextsent>in the following, we interpret some of these findings for our model of uncertainty, including model of repair mechanism.
</nextsent>
<nextsent>basically, our model of uncertainty combines the three kinds of uncertainty described in the previous section.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2624">
<title id=" W05-1606.xml">generating referential descriptions under conditions of uncertainty </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>a single result is produced even if several reasonable variants exist, and this choice is implicitly determined by the preference ordering imposed on the descriptors.?
</prevsent>
<prevsent>the interaction with other components of an nl generation system and an embedding dialog system is rather limited.
</prevsent>
</prevsection>
<citsent citstr=" P97-1027 ">
reference generation is typically conceived as pure functional service, with no feedback, taking into account syntactic constraints, at best (e.g., [horacek 1997]).<papid> P97-1027 </papid></citsent>
<aftsection>
<nextsent>an embedding dialog system has no chance to find out possible sources for an identification failure.
</nextsent>
<nextsent>the algorithm incorporating measures to deal with uncertainties provides facilities to improve this situation: ? specifications concerning attribution of descriptors to referents and knowledge of the audience can be done in direct fashion, requiring no interpretations.
</nextsent>
<nextsent>there are some parameters to control the choice of descriptors, the conciseness and expected effectiveness of the result, including an afterwards optimization which only requires re-calculation of probabilities.
</nextsent>
<nextsent>the probabilities of identification associated with the intended referents and those potential dis tractors that fall under the repair facility give an indication about the likelihood of success of the identification task and also about potential sources for failure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2625">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this imposes strong requirements on both automatic evaluation measures and statistical significance tests: evaluation measures are needed that have high discriminative power and yet are sensitive to the interesting aspects of the evaluation task.
</prevsent>
<prevsent>significance tests are required to be powerful and yet accurate, i.e., if there are significant differences they should be able to assess them, but not if there are none.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
in the area of statistical machine translation(smt), recently combination of the bleu evaluation metric (papineni et al, 2001) and the bootstrap method for statistical significance testing (efron and tibshirani, 1993) has become popular (och, 2003; <papid> P03-1021 </papid>kumar and byrne, 2004; <papid> N04-1022 </papid>koehn, 2004<papid> W04-3250 </papid>b; zhang et al., 2004).</citsent>
<aftsection>
<nextsent>given the current practice of reporting result differences as small as .3% in bleu score,assessed at confidence levels as low as 70%, questions arise concerning the sensitivity of the employed evaluation metrics and the accuracy of the employed significance tests, especially when result differences are small.
</nextsent>
<nextsent>we believe that is important to accurately detect such small-magnitude differences in order to understand how to improve systems and technologies, even though such differences may not matter in current applications.
</nextsent>
<nextsent>in this paper we will investigate some pitfalls that arise in automatic evaluation and statistical significance testing in mt research.
</nextsent>
<nextsent>the first pitfall concerns the discriminatory power of automatic evaluation measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2626">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this imposes strong requirements on both automatic evaluation measures and statistical significance tests: evaluation measures are needed that have high discriminative power and yet are sensitive to the interesting aspects of the evaluation task.
</prevsent>
<prevsent>significance tests are required to be powerful and yet accurate, i.e., if there are significant differences they should be able to assess them, but not if there are none.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
in the area of statistical machine translation(smt), recently combination of the bleu evaluation metric (papineni et al, 2001) and the bootstrap method for statistical significance testing (efron and tibshirani, 1993) has become popular (och, 2003; <papid> P03-1021 </papid>kumar and byrne, 2004; <papid> N04-1022 </papid>koehn, 2004<papid> W04-3250 </papid>b; zhang et al., 2004).</citsent>
<aftsection>
<nextsent>given the current practice of reporting result differences as small as .3% in bleu score,assessed at confidence levels as low as 70%, questions arise concerning the sensitivity of the employed evaluation metrics and the accuracy of the employed significance tests, especially when result differences are small.
</nextsent>
<nextsent>we believe that is important to accurately detect such small-magnitude differences in order to understand how to improve systems and technologies, even though such differences may not matter in current applications.
</nextsent>
<nextsent>in this paper we will investigate some pitfalls that arise in automatic evaluation and statistical significance testing in mt research.
</nextsent>
<nextsent>the first pitfall concerns the discriminatory power of automatic evaluation measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2627">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this imposes strong requirements on both automatic evaluation measures and statistical significance tests: evaluation measures are needed that have high discriminative power and yet are sensitive to the interesting aspects of the evaluation task.
</prevsent>
<prevsent>significance tests are required to be powerful and yet accurate, i.e., if there are significant differences they should be able to assess them, but not if there are none.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
in the area of statistical machine translation(smt), recently combination of the bleu evaluation metric (papineni et al, 2001) and the bootstrap method for statistical significance testing (efron and tibshirani, 1993) has become popular (och, 2003; <papid> P03-1021 </papid>kumar and byrne, 2004; <papid> N04-1022 </papid>koehn, 2004<papid> W04-3250 </papid>b; zhang et al., 2004).</citsent>
<aftsection>
<nextsent>given the current practice of reporting result differences as small as .3% in bleu score,assessed at confidence levels as low as 70%, questions arise concerning the sensitivity of the employed evaluation metrics and the accuracy of the employed significance tests, especially when result differences are small.
</nextsent>
<nextsent>we believe that is important to accurately detect such small-magnitude differences in order to understand how to improve systems and technologies, even though such differences may not matter in current applications.
</nextsent>
<nextsent>in this paper we will investigate some pitfalls that arise in automatic evaluation and statistical significance testing in mt research.
</nextsent>
<nextsent>the first pitfall concerns the discriminatory power of automatic evaluation measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2629">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the following, we compare the sensitivity of three intrinsic evaluation measures that differ with respect to their focus on different aspects 57 of translation.
</prevsent>
<prevsent>we consider the well-known bleu score (papineni et al, 2001) which emphasizes fluency by incorporating matches of high n-grams.
</prevsent>
</prevsection>
<citsent citstr=" N03-1026 ">
furthermore, we consider an f-score measure that is adapted from dependency-based parsing (crouch et al., 2002) and sentence-condensation (riezler et al,2003).<papid> N03-1026 </papid></citsent>
<aftsection>
<nextsent>this measure matches grammatical dependency relations of parses for system output and reference translations, and thus emphasizes semantic aspects of translational adequacy.
</nextsent>
<nextsent>as third measure we consider nist (doddington, 2002), which favors lexical choice over word order and does nottake structural information into account.
</nextsent>
<nextsent>on an experimental evaluation on reranking experiment wefound that only nist was sensitive enough to detect small result differences, whereas bleu and fscore produced result differences that were statistically not significant.
</nextsent>
<nextsent>a second pitfall addressed inthis paper concerns the relation of power and accuracy of significance tests.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2630">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> the experimental setup: discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>this is especially important in situations where multiple pairwise comparisons are conducted, and small result differences are expected.
</prevsent>
<prevsent>reranking for phrase-based smt the experimental setup we employed to compare evaluation measures and significance tests is discriminative reranking experiment on 1000-best lists of phrase-based smt system.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
our system is are-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney,2003)<papid> J03-1002 </papid>1, decoding (koehn, 2004<papid> W04-3250 </papid>a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4.</citsent>
<aftsection>
<nextsent>training and test data are taken from the europarl parallel corpus (koehn, 2002)5.
</nextsent>
<nextsent>phrase-extraction follows och et al (1999) <papid> W99-0604 </papid>and was implemented by the authors: first, the word aligner is applied in both translation directions, and the intersection of the alignment matrices is built.then, the alignment is extended by adding immediately adjacent alignment points and alignment points that align previously unaligned words.</nextsent>
<nextsent>from thismany-to-many alignment matrix, phrases are extracted according to contiguity requirement that states that words in the source phrase are aligned only with words in the target phrase, and vice versa.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2633">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> the experimental setup: discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>our system is are-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney,2003)<papid> J03-1002 </papid>1, decoding (koehn, 2004<papid> W04-3250 </papid>a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4.</prevsent>
<prevsent>training and test data are taken from the europarl parallel corpus (koehn, 2002)5.</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
phrase-extraction follows och et al (1999) <papid> W99-0604 </papid>and was implemented by the authors: first, the word aligner is applied in both translation directions, and the intersection of the alignment matrices is built.then, the alignment is extended by adding immediately adjacent alignment points and alignment points that align previously unaligned words.</citsent>
<aftsection>
<nextsent>from thismany-to-many alignment matrix, phrases are extracted according to contiguity requirement that states that words in the source phrase are aligned only with words in the target phrase, and vice versa.
</nextsent>
<nextsent>discriminative reranking on 1000-best list of translations of the smt system uses an `1 regularized log-linear model that combines standardmaximum-entropy estimator with an efficient, incremental feature selection technique for `1 regularization (riezler and vasserman, 2004).<papid> W04-3223 </papid></nextsent>
<nextsent>training data are defined as pairs {(sj , tj)}mj=1 of source sentences sj and gold-standard translations tj that are determined as the translations in the 1000-best list that best match given reference translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2634">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> the experimental setup: discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>phrase-extraction follows och et al (1999) <papid> W99-0604 </papid>and was implemented by the authors: first, the word aligner is applied in both translation directions, and the intersection of the alignment matrices is built.then, the alignment is extended by adding immediately adjacent alignment points and alignment points that align previously unaligned words.</prevsent>
<prevsent>from thismany-to-many alignment matrix, phrases are extracted according to contiguity requirement that states that words in the source phrase are aligned only with words in the target phrase, and vice versa.</prevsent>
</prevsection>
<citsent citstr=" W04-3223 ">
discriminative reranking on 1000-best list of translations of the smt system uses an `1 regularized log-linear model that combines standardmaximum-entropy estimator with an efficient, incremental feature selection technique for `1 regularization (riezler and vasserman, 2004).<papid> W04-3223 </papid></citsent>
<aftsection>
<nextsent>training data are defined as pairs {(sj , tj)}mj=1 of source sentences sj and gold-standard translations tj that are determined as the translations in the 1000-best list that best match given reference translation.
</nextsent>
<nextsent>the objective function to be minimized is the conditional log-likelihood l(?)
</nextsent>
<nextsent>subject to regularization term r(?), where (s) is the set of 1000-best translations for sentence s, ? is vector or log-parameters, and 1http://www.fjoch.com/giza++.html 2http://www.isi.edu/licensed-sw/pharaoh/ 3http://www.speech.sri.com/projects/srilm/ 4http://www.isi.edu/licensed-sw/carmel/ 5http://people.csail.mit.edu/people/ koehn/publications/europarl/ 58 table 1: nist, bleu, f-scores for reranker and baseline on development set nist bleu baseline 6.43 .301 .385 reranking 6.58 .298 .383 approx rand p-value   .0001 .158 .424bootstrap p-value   .0001 .1 is vector of feature functions: l(?)
</nextsent>
<nextsent>+ r(?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2635">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> the experimental setup: discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>i ? ?
</prevsent>
<prevsent>  ? this gradient test is applied to each feature and ateach step the features that pass the test with maximum magnitude are added to the model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
this provides both efficient and accurate estimation with large feature sets.work on discriminative reranking has been reported before by och and ney (2002), <papid> P02-1038 </papid>och et al (2004), <papid> N04-1021 </papid>and shen et al (2004).<papid> N04-1023 </papid></citsent>
<aftsection>
<nextsent>the main purpose of our reranking experiments is to have system that can easily be adjusted to yield system variants that differ at controllable amounts.
</nextsent>
<nextsent>for quick experimental turnaround we selected the training and test data from sentences with 5 to 15 words, resulting in training set of 160,000 sentences, and development set of 2,000 sentences.
</nextsent>
<nextsent>the phrase-table employed was restricted to phrases of maximally 3 words, resulting in 200,000 phrases.
</nextsent>
<nextsent>intrinsic evaluations metrics the intrinsic evaluation measures used in our experiments are the well-known bleu (papineni et al., 2001) and nist (doddington, 2002) metrics,and an f-score measure that adapts evaluation techniques from dependency-based parsing (crouch et al., 2002) and sentence-condensation (riezler et al, 2003) <papid> N03-1026 </papid>to machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2636">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> the experimental setup: discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>i ? ?
</prevsent>
<prevsent>  ? this gradient test is applied to each feature and ateach step the features that pass the test with maximum magnitude are added to the model.
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
this provides both efficient and accurate estimation with large feature sets.work on discriminative reranking has been reported before by och and ney (2002), <papid> P02-1038 </papid>och et al (2004), <papid> N04-1021 </papid>and shen et al (2004).<papid> N04-1023 </papid></citsent>
<aftsection>
<nextsent>the main purpose of our reranking experiments is to have system that can easily be adjusted to yield system variants that differ at controllable amounts.
</nextsent>
<nextsent>for quick experimental turnaround we selected the training and test data from sentences with 5 to 15 words, resulting in training set of 160,000 sentences, and development set of 2,000 sentences.
</nextsent>
<nextsent>the phrase-table employed was restricted to phrases of maximally 3 words, resulting in 200,000 phrases.
</nextsent>
<nextsent>intrinsic evaluations metrics the intrinsic evaluation measures used in our experiments are the well-known bleu (papineni et al., 2001) and nist (doddington, 2002) metrics,and an f-score measure that adapts evaluation techniques from dependency-based parsing (crouch et al., 2002) and sentence-condensation (riezler et al, 2003) <papid> N03-1026 </papid>to machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2637">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> the experimental setup: discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>i ? ?
</prevsent>
<prevsent>  ? this gradient test is applied to each feature and ateach step the features that pass the test with maximum magnitude are added to the model.
</prevsent>
</prevsection>
<citsent citstr=" N04-1023 ">
this provides both efficient and accurate estimation with large feature sets.work on discriminative reranking has been reported before by och and ney (2002), <papid> P02-1038 </papid>och et al (2004), <papid> N04-1021 </papid>and shen et al (2004).<papid> N04-1023 </papid></citsent>
<aftsection>
<nextsent>the main purpose of our reranking experiments is to have system that can easily be adjusted to yield system variants that differ at controllable amounts.
</nextsent>
<nextsent>for quick experimental turnaround we selected the training and test data from sentences with 5 to 15 words, resulting in training set of 160,000 sentences, and development set of 2,000 sentences.
</nextsent>
<nextsent>the phrase-table employed was restricted to phrases of maximally 3 words, resulting in 200,000 phrases.
</nextsent>
<nextsent>intrinsic evaluations metrics the intrinsic evaluation measures used in our experiments are the well-known bleu (papineni et al., 2001) and nist (doddington, 2002) metrics,and an f-score measure that adapts evaluation techniques from dependency-based parsing (crouch et al., 2002) and sentence-condensation (riezler et al, 2003) <papid> N03-1026 </papid>to machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2639">
<title id=" W05-0908.xml">on some pitfalls in automatic evaluation and significance testing for mt </title>
<section> assessing statistical significance of.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 approximate randomization.
</prevsent>
<prevsent>an excellent introduction to the approximate randomization test is noreen (1989).
</prevsent>
</prevsection>
<citsent citstr=" J93-3001 ">
applications of this test to natural language processing problems can be found in chinchor et al (1993).<papid> J93-3001 </papid></citsent>
<aftsection>
<nextsent>in our case of assessing statistical significance of result differences between smt systems, the test statistic of interest is the absolute value of the difference in bleu, nist, or f-scores produced by two systems on the same test set.
</nextsent>
<nextsent>these test statistics are computed by accumulating certain count variables over the sentences in the test set.
</nextsent>
<nextsent>for example, in case of bleu and nist, variables for the length of reference translations and system translations, andfor n-gram matches and n-gram counts are accumulated over the test corpus.
</nextsent>
<nextsent>in case of f-score, variable tuples consisting of the number of dependency relations in the parse for the system translation, the number of dependency-relations in the parse for the reference translation, and the number of matching dependency-relations between system and reference parse, are accumulated over the test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2640">
<title id=" W05-0210.xml">measuring nonnative speakers proficiency of english by using a test with automatically generated fillintheblank questions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to generate an fbq, the incorrectness of the sentence restored by each distracter candidate must be verified and if the combination is not incorrect, the candidate is rejected.
</prevsent>
<prevsent>zero-hit sentence the web includes all manners of language data in vast quantities, which are for everyone easy to access through networked computer.
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
recently, exploitation of the web for various natural language applications is rising (grefenstette, 1999; turney, 2001; kilgarriff and grefenstette, 2003; <papid> J03-3001 </papid>tonoike et al, 2004).</citsent>
<aftsection>
<nextsent>we also propose web-based approach.
</nextsent>
<nextsent>we dare to assume that if there is sentence on the web, that sentence is considered correct; otherwise, the sentence is unlikely to be correct in that there is no sentence written on the web despite the variety and quantity of data on it.
</nextsent>
<nextsent>* testing knowledge tells us what part of the seed sentence should be blanked.
</nextsent>
<nextsent>for example, we selected the verb of the seed because it is one of the basic types of blanked words in popular fbqs such as in toeic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2641">
<title id=" W05-0409.xml">studying feature generation from various data representations for answer extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these evidences are further combined by using pipeline structure, scoring function or machine learning method.
</prevsent>
<prevsent>in the machine learning framework, it is critical but not trivial to generate the features from the various resources which may be represented as surface texts, syntactic structures and logic forms, etc. the complexity of feature generation strongly depends on the complexity of data representation.
</prevsent>
</prevsection>
<citsent citstr=" W03-1209 ">
many previous qa systems (echihabi et al, 2003; ravichandran, et al, 2003; <papid> W03-1209 </papid>ittycheriah and roukos, 2002; ittycheriah, 2001; xu et al, 2002) have well studied the features in the surface texts.</citsent>
<aftsection>
<nextsent>in this paper, we will use the answer extraction module of qa as case study to further explore how to generate the features for the more complex sentence representations, such as parse tree.
</nextsent>
<nextsent>since parsing gives the deeper understanding of the sentence, the features generated from the parse tree are expected to improve the performance based on the features generated from the surface text.
</nextsent>
<nextsent>the answer ex 65traction module is built using support vector machines (svm).
</nextsent>
<nextsent>we propose three methods to represent the features in the parse tree: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2643">
<title id=" W05-0409.xml">studying feature generation from various data representations for answer extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many researchers have explored the rich textual features for the answer extraction.
</prevsent>
<prevsent>ibm (ittycheriah and roukos, 2002; ittycheriah, 2001) used maximum entropy model to integrate the rich features, including query expansion features, focus matching features, answer candidate co-occurrence features, certain word frequency features, named entity features, dependency relation features, linguistic motivated features and surface patterns.
</prevsent>
</prevsection>
<citsent citstr=" P03-1003 ">
isis (echihabi et al 2003; echihabi and marcu, 2003) <papid> P03-1003 </papid>statistical-based ae module implemented noisy-channel model to explain how given sentence tagged with an answer can be rewritten into question through sequence of stochastic operations.</citsent>
<aftsection>
<nextsent>(ravichandran et al, 2003) <papid> W03-1209 </papid>compared two maximum entropy-based qa systems, which view the ae as classification problem and re-ranking problem respectively, based on the word frequency features, expected answer class features, question word absent features and word match features.</nextsent>
<nextsent>bbn (xu et al 2002) used hmm-based ir system to score the answer candidates based on the answer contexts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2645">
<title id=" W05-0409.xml">studying feature generation from various data representations for answer extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>bbn (xu et al 2002) used hmm-based ir system to score the answer candidates based on the answer contexts.
</prevsent>
<prevsent>they further re-ranked the scored answer candidates using the constraint features, such as whether numerical answer quantifies the correct noun, whether the answer is of the correct location sub-type and whether the answer satisfies the verb arguments of the questions.
</prevsent>
</prevsection>
<citsent citstr=" C02-1119 ">
(suzuki et al 2002) <papid> C02-1119 </papid>explored the answer extraction using svm.</citsent>
<aftsection>
<nextsent>however, in the previous statistical-based ae modules, most of the features were extracted from the surface texts which are mainly based on the key words/phrases matching and the key word frequency statistics.
</nextsent>
<nextsent>these features only capture the surface-based information for the proper answers and may not provide the deeper understanding of the sentences.
</nextsent>
<nextsent>in addition, the contribution of the individual feature has not been evaluated by them.
</nextsent>
<nextsent>as for the features extracted from the structured texts, such as parse trees, only few works explored some predefined syntactic relation features by partial matching.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2648">
<title id=" W05-0409.xml">studying feature generation from various data representations for answer extraction </title>
<section> syntactic features.  </section>
<citcontext>
<prevsection>
<prevsent>tree kernels are the structure-driven kernels to calculate the similarity between two trees.
</prevsent>
<prevsent>they have been successfully accepted in the nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
(collins and duffy, 2002) <papid> P02-1034 </papid>defined kernel on parse tree and used it to improve parsing.</citsent>
<aftsection>
<nextsent>(collins, 2002) extended the approach to pos tagging and named entity recognition.
</nextsent>
<nextsent>(zelenko et al, 2003; culotta and sorensen, 2004) <papid> P04-1054 </papid>further explored tree kernels for relation extraction.</nextsent>
<nextsent>we define an object (a relation tree) as the smallest tree which covers one answer candidate node and one question key word node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2649">
<title id=" W05-0409.xml">studying feature generation from various data representations for answer extraction </title>
<section> syntactic features.  </section>
<citcontext>
<prevsection>
<prevsent>(collins and duffy, 2002) <papid> P02-1034 </papid>defined kernel on parse tree and used it to improve parsing.</prevsent>
<prevsent>(collins, 2002) extended the approach to pos tagging and named entity recognition.</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
(zelenko et al, 2003; culotta and sorensen, 2004) <papid> P04-1054 </papid>further explored tree kernels for relation extraction.</citsent>
<aftsection>
<nextsent>we define an object (a relation tree) as the smallest tree which covers one answer candidate node and one question key word node.
</nextsent>
<nextsent>suppose that relation tree has nodes 0 1{ , , ..., }nt t and each node it is attached with set of attributes 0 1{ , , ..., }ma a , which represents the local characteristics of ti . in our task, the set of the attributes includes type attributes, orthographic attributes and relation role attributes, as shown in table 2.
</nextsent>
<nextsent>the core idea of the tree kernel ( , )1 2k t is that the similarity between two trees t1 and t2 is punc . away 221,456 miles pp npb vp vbz advp npb rb the moon is q1980: how far is the moon from earth in miles?
</nextsent>
<nextsent>s: at its perigee, the closest approach to earth , the moon is 221,456 miles away.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2650">
<title id=" W05-0701.xml">memory based morphological analysis generation and partofspeech tagging of arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report onthe performance of the morphological analyzer and part-of-speech tagger.
</prevsent>
<prevsent>we observe that the tagger, which has an accuracy of 91.9% on new data, can be used to select the appropriate morphological analysis of words in context at precision of 64.0 and recall of 89.7.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
memory-based learning has been successfully applied to morphological analysis and part-of-speech tagging in western and eastern-european languages (van den bosch and daelemans, 1999; daelemans et al., 1996).<papid> W96-0102 </papid></citsent>
<aftsection>
<nextsent>with the release of the arabic treebank by the linguistic data consortium (current version:3), large corpus has become available for arabic that can act as training material for machine learning algorithms.
</nextsent>
<nextsent>the data facilitates machine learned part-of-speech taggers, tokenizers, and shallow parsing units such as chunk ers, as exemplified by diab et al (2004).<papid> N04-4038 </papid></nextsent>
<nextsent>however, arabic appears to be special challenge for data-driven approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2651">
<title id=" W05-0701.xml">memory based morphological analysis generation and partofspeech tagging of arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>memory-based learning has been successfully applied to morphological analysis and part-of-speech tagging in western and eastern-european languages (van den bosch and daelemans, 1999; daelemans et al., 1996).<papid> W96-0102 </papid></prevsent>
<prevsent>with the release of the arabic treebank by the linguistic data consortium (current version:3), large corpus has become available for arabic that can act as training material for machine learning algorithms.</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
the data facilitates machine learned part-of-speech taggers, tokenizers, and shallow parsing units such as chunk ers, as exemplified by diab et al (2004).<papid> N04-4038 </papid></citsent>
<aftsection>
<nextsent>however, arabic appears to be special challenge for data-driven approaches.
</nextsent>
<nextsent>it is semitic language with non-concatenative morphology.
</nextsent>
<nextsent>in addition toprefixation and suffix ation, inflectional and derivational processes may cause stems to undergo infixational modification in the presence of different syntactic features as well as certain consonants.
</nextsent>
<nextsent>an arabic word may be composed of stem consisting of consonantal root and pattern, affixes, and clitics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2654">
<title id=" W05-0701.xml">memory based morphological analysis generation and partofspeech tagging of arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on both known and unknown words the integration of the morphological analyzer and the tagger is able to narrow down the analyses by the analyzer to subset of matching analyses that in about nine out of ten cases contains the ?* solution?
</prevsent>
<prevsent>word.
</prevsent>
</prevsection>
<citsent citstr=" E87-1002 ">
the application of machine learning methods to arabic morphology and pos tagging appears to be somewhat limited and recent, compared to the vast descriptive and rule-based literature particularly on morphology (kay, 1987; <papid> E87-1002 </papid>beesley, 1990; kiraz, 1994; <papid> C94-1029 </papid>beesley, 1998; <papid> P98-1018 </papid>cavalli-sfora et al, 2000; soudi, 2002).we are not aware of any machine-learning approach to arabic morphology, but find related issues treated in (daya et al, 2004), <papid> W04-3246 </papid>who propose machine-learning method augmented with linguistic constraints to identifying roots in hebrew words related but reverse task to ours.</citsent>
<aftsection>
<nextsent>arabic pos tagging seems to have attracted some more attention.
</nextsent>
<nextsent>freeman (2001) describes initial work in developing pos tagger based on transformational error-driven learning (i.e. the brill tagger), but does not provide performance analyses.
</nextsent>
<nextsent>khoja (2001) reports 90% accurate morpho-syntactic statistical tagger that uses 7 the viterbi algorithm to select maximally-likely part-of-speech tag sequence over sentence.
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>describe part-of-speech tagger basedon support vector machines that is trained on tokenized data (clitics are separate tokens), reporting tagging accuracy of 95.5%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2655">
<title id=" W05-0701.xml">memory based morphological analysis generation and partofspeech tagging of arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on both known and unknown words the integration of the morphological analyzer and the tagger is able to narrow down the analyses by the analyzer to subset of matching analyses that in about nine out of ten cases contains the ?* solution?
</prevsent>
<prevsent>word.
</prevsent>
</prevsection>
<citsent citstr=" C94-1029 ">
the application of machine learning methods to arabic morphology and pos tagging appears to be somewhat limited and recent, compared to the vast descriptive and rule-based literature particularly on morphology (kay, 1987; <papid> E87-1002 </papid>beesley, 1990; kiraz, 1994; <papid> C94-1029 </papid>beesley, 1998; <papid> P98-1018 </papid>cavalli-sfora et al, 2000; soudi, 2002).we are not aware of any machine-learning approach to arabic morphology, but find related issues treated in (daya et al, 2004), <papid> W04-3246 </papid>who propose machine-learning method augmented with linguistic constraints to identifying roots in hebrew words related but reverse task to ours.</citsent>
<aftsection>
<nextsent>arabic pos tagging seems to have attracted some more attention.
</nextsent>
<nextsent>freeman (2001) describes initial work in developing pos tagger based on transformational error-driven learning (i.e. the brill tagger), but does not provide performance analyses.
</nextsent>
<nextsent>khoja (2001) reports 90% accurate morpho-syntactic statistical tagger that uses 7 the viterbi algorithm to select maximally-likely part-of-speech tag sequence over sentence.
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>describe part-of-speech tagger basedon support vector machines that is trained on tokenized data (clitics are separate tokens), reporting tagging accuracy of 95.5%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2656">
<title id=" W05-0701.xml">memory based morphological analysis generation and partofspeech tagging of arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on both known and unknown words the integration of the morphological analyzer and the tagger is able to narrow down the analyses by the analyzer to subset of matching analyses that in about nine out of ten cases contains the ?* solution?
</prevsent>
<prevsent>word.
</prevsent>
</prevsection>
<citsent citstr=" P98-1018 ">
the application of machine learning methods to arabic morphology and pos tagging appears to be somewhat limited and recent, compared to the vast descriptive and rule-based literature particularly on morphology (kay, 1987; <papid> E87-1002 </papid>beesley, 1990; kiraz, 1994; <papid> C94-1029 </papid>beesley, 1998; <papid> P98-1018 </papid>cavalli-sfora et al, 2000; soudi, 2002).we are not aware of any machine-learning approach to arabic morphology, but find related issues treated in (daya et al, 2004), <papid> W04-3246 </papid>who propose machine-learning method augmented with linguistic constraints to identifying roots in hebrew words related but reverse task to ours.</citsent>
<aftsection>
<nextsent>arabic pos tagging seems to have attracted some more attention.
</nextsent>
<nextsent>freeman (2001) describes initial work in developing pos tagger based on transformational error-driven learning (i.e. the brill tagger), but does not provide performance analyses.
</nextsent>
<nextsent>khoja (2001) reports 90% accurate morpho-syntactic statistical tagger that uses 7 the viterbi algorithm to select maximally-likely part-of-speech tag sequence over sentence.
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>describe part-of-speech tagger basedon support vector machines that is trained on tokenized data (clitics are separate tokens), reporting tagging accuracy of 95.5%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2657">
<title id=" W05-0701.xml">memory based morphological analysis generation and partofspeech tagging of arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on both known and unknown words the integration of the morphological analyzer and the tagger is able to narrow down the analyses by the analyzer to subset of matching analyses that in about nine out of ten cases contains the ?* solution?
</prevsent>
<prevsent>word.
</prevsent>
</prevsection>
<citsent citstr=" W04-3246 ">
the application of machine learning methods to arabic morphology and pos tagging appears to be somewhat limited and recent, compared to the vast descriptive and rule-based literature particularly on morphology (kay, 1987; <papid> E87-1002 </papid>beesley, 1990; kiraz, 1994; <papid> C94-1029 </papid>beesley, 1998; <papid> P98-1018 </papid>cavalli-sfora et al, 2000; soudi, 2002).we are not aware of any machine-learning approach to arabic morphology, but find related issues treated in (daya et al, 2004), <papid> W04-3246 </papid>who propose machine-learning method augmented with linguistic constraints to identifying roots in hebrew words related but reverse task to ours.</citsent>
<aftsection>
<nextsent>arabic pos tagging seems to have attracted some more attention.
</nextsent>
<nextsent>freeman (2001) describes initial work in developing pos tagger based on transformational error-driven learning (i.e. the brill tagger), but does not provide performance analyses.
</nextsent>
<nextsent>khoja (2001) reports 90% accurate morpho-syntactic statistical tagger that uses 7 the viterbi algorithm to select maximally-likely part-of-speech tag sequence over sentence.
</nextsent>
<nextsent>diab et al (2004) <papid> N04-4038 </papid>describe part-of-speech tagger basedon support vector machines that is trained on tokenized data (clitics are separate tokens), reporting tagging accuracy of 95.5%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2659">
<title id=" W06-0103.xml">mining atomic chinese abbreviation pairs a probabilistic model for single character word recovery </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as such, we can find the most likely root words, by finding those candidates that maximizes the likelihood of the whole text.
</prevsent>
<prevsent>an abbreviation lexicon, which consists of the root-abbreviation pairs, can thus be constructed automatically.
</prevsent>
</prevsection>
<citsent citstr=" W04-1102 ">
in preliminary study (chang and lai, 2004), <papid> W04-1102 </papid>some probabilistic models had been developed to handle this problem by applying the models to parallel corpus of compound words and their abbreviations, without knowing the context of the abbreviation pairs.</citsent>
<aftsection>
<nextsent>in this work, the same framework is extended and method is proposed to automatically acquire large abbreviation lexicon for indivisual characters from web texts or large corpora, instead of building abbreviation models based on aligned abbreviation pairs of short compound words.
</nextsent>
<nextsent>unlike the previous task, which trains the abbreviation model parameters from list of known abbreviation pairs, the current work aims at extracting abbreviation pairs from corpus of free text, in which the locations of prospective abbreviations and full forms are unknown and the correspondence between them is not known either.
</nextsent>
<nextsent>in particular, single character recovery (scr) model is exploited in the current work to extract atomic abbreviation pairs from large text corpus.
</nextsent>
<nextsent>with only few training iterations, the acquisition accuracy achieves 62% and 50 % precision for training set and test set from the aswsc-2001 corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2672">
<title id=" W06-0103.xml">mining atomic chinese abbreviation pairs a probabilistic model for single character word recovery </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are essentially no prior arts for automatically extracting atomic abbreviation pairs.
</prevsent>
<prevsent>since such formulations regard the word segmentation process and abbreviation 19 identification as two independent processes, they probably cannot optimize the identification process jointly with the word segmentation process, and thus may lose some useful contextual information.
</prevsent>
</prevsection>
<citsent citstr=" C02-1012 ">
some class-based segmentation models (sun et al, 2002; <papid> C02-1012 </papid>gao et al., 2003) <papid> P03-1035 </papid>well integrate the identification of some regular non-lexicalized units (such as named entities).</citsent>
<aftsection>
<nextsent>however, the abbreviation process can be applied to almost all word forms (or classes of words).
</nextsent>
<nextsent>therefore, this particular word formation process may have to be handled as separate layer in the segmentation process.
</nextsent>
<nextsent>to resolve the chinese abbreviation problems and integrate its identification into the word segmentation process, (chang and lai, 2004) <papid> W04-1102 </papid>proposes to regard the abbreviation problem in the word segmentation process as an eror recovery?</nextsent>
<nextsent>problem in which the suspect root words are the erors?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2673">
<title id=" W06-0103.xml">mining atomic chinese abbreviation pairs a probabilistic model for single character word recovery </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are essentially no prior arts for automatically extracting atomic abbreviation pairs.
</prevsent>
<prevsent>since such formulations regard the word segmentation process and abbreviation 19 identification as two independent processes, they probably cannot optimize the identification process jointly with the word segmentation process, and thus may lose some useful contextual information.
</prevsent>
</prevsection>
<citsent citstr=" P03-1035 ">
some class-based segmentation models (sun et al, 2002; <papid> C02-1012 </papid>gao et al., 2003) <papid> P03-1035 </papid>well integrate the identification of some regular non-lexicalized units (such as named entities).</citsent>
<aftsection>
<nextsent>however, the abbreviation process can be applied to almost all word forms (or classes of words).
</nextsent>
<nextsent>therefore, this particular word formation process may have to be handled as separate layer in the segmentation process.
</nextsent>
<nextsent>to resolve the chinese abbreviation problems and integrate its identification into the word segmentation process, (chang and lai, 2004) <papid> W04-1102 </papid>proposes to regard the abbreviation problem in the word segmentation process as an eror recovery?</nextsent>
<nextsent>problem in which the suspect root words are the erors?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2695">
<title id=" W05-0111.xml">handson nlp for an interdisciplinary audience </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the programs contained filters that could be used to remove extraneous text such as headers and forwarded text.
</prevsent>
<prevsent>the teams adapted parts of these programs to convert the email files to files with text suitable for nl processing.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
for the nl processing, the natural language toolkit (nl toolkit or nltk), developed at the university of pennsylvania by loper and bird (2002), <papid> W02-0109 </papid>and available for download from source forge at http://nltk.sourceforge.net/ was used.</citsent>
<aftsection>
<nextsent>the nl toolkit is set of libraries written in the python programming language that provides core data types for processing natural language text, support for statistical processing, and number of standard processing algorithms used in nlp, including tokenization, part of speech (pos) tagging, chunk parsing, and syntactic parsing.
</nextsent>
<nextsent>the toolkit provides demonstration packages, tutorials, example corpora and documentation to support its use in educational classes.
</nextsent>
<nextsent>experience using the toolkit shows that in order to use the nl toolkit, one member of each team should have at least some programming background in order to write python programs that use the nl toolkit libraries.
</nextsent>
<nextsent>the use of python as the programming language was successful in that the level needed to use the nl toolkit was manageable by the students with only little programming background and in that the computer science students were able to adapt to the python programming style and could easily utilize the classes and libraries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2696">
<title id=" W04-3229.xml">a resource light approach to russian morphology tagging russian using czech resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>czech is sufficiently similar to russian that it is reasonable to suppose that information about czech will be relevant in some way to the tagging of russian.
</prevsent>
<prevsent>the languages share many linguistic properties (free word order and rich morphology which plays considerable role in determining agreement and argument relationships).
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we created morphological analyzer for russian, combined the results with information derived from czech and used thetnt (brants, 2000) <papid> A00-1031 </papid>tagger in number of differ 1all russian examples in this paper are transcribed in the roman alphabet.</citsent>
<aftsection>
<nextsent>our system is able to analyze russian texts in both cyrillic and various transcriptions.
</nextsent>
<nextsent>krasiv-a beautiful (short adjective, feminine) muz?-a husband (noun, masc., sing., genitive) husband (noun, masc., sing., accusative) okn-a window (noun, neuter, sing., genitive) window (noun, neuter, pl., nominative) window (noun, neuter, pl., accusative) knig-a book (noun, fem., sing., nominative) dom-a house (noun, masc., sing., genitive) house (noun, masc., pl., nominative) house (noun, masc., pl., accusative) skazal-a say (verb, fem., sing., past tense) dv-a two (numeral, masc., nominative) table 1: homonymy of the ending ent ways, including a committee-based approach,which turned out to give the best results.
</nextsent>
<nextsent>to evaluate the results, we morphologically annotated (byhand) small corpus of russian: part of the translation of orwells 1984?
</nextsent>
<nextsent>from the multext-east project (veronis, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2698">
<title id=" W04-3229.xml">a resource light approach to russian morphology tagging russian using czech resources </title>
<section> case 9 8.  </section>
<citcontext>
<prevsection>
<prevsent>table 2: overview and comparison of the tagsets the tagset used for czech (4290+ tags) is larger than the tagset we use for russian (about 900 tags).
</prevsent>
<prevsent>there is good theoretical reason for this choice ? russian morphological categories usually have fewer values (e.g., 6 cases in russian vs. 7 in czech; czech often has formal and colloquial variants ofthe same morpheme); but there is also an immediate practical reason ? the czech tag system is very elaborate and specifically devised to serve multiple needs, while our tagset is designed solely to capture the core of russian morphology, as we need it forour primary purpose of demonstrating the portability and feasibility of our technique.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
still, our tagset is much larger than the penn treebank tagset, which uses only 36 non-punctuation tags (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>4.2 morphological analysis.
</nextsent>
<nextsent>in this section we describe our approach to resource-light encoding of salient facts about the russian lexicon.
</nextsent>
<nextsent>our techniques are not as radical as previously explored unsupervised methods (goldsmith, 2001; <papid> J01-2001 </papid>yarowsky and wicentowski, 2000), <papid> P00-1027 </papid>but are designed to be feasible for languages for which serious morphological expertise is unavailable to us.</nextsent>
<nextsent>we use paradigm-based morphology that avoids the need to explicitly create largelexicon.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2699">
<title id=" W04-3229.xml">a resource light approach to russian morphology tagging russian using czech resources </title>
<section> case 9 8.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 morphological analysis.
</prevsent>
<prevsent>in this section we describe our approach to resource-light encoding of salient facts about the russian lexicon.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
our techniques are not as radical as previously explored unsupervised methods (goldsmith, 2001; <papid> J01-2001 </papid>yarowsky and wicentowski, 2000), <papid> P00-1027 </papid>but are designed to be feasible for languages for which serious morphological expertise is unavailable to us.</citsent>
<aftsection>
<nextsent>we use paradigm-based morphology that avoids the need to explicitly create largelexicon.
</nextsent>
<nextsent>the price that we pay for this is overgener ation.
</nextsent>
<nextsent>most of these analyses look very implausible to russian speaker, but significantly increasing the precision would be at the cost of greater development time than our resource-light approach is able to commit.
</nextsent>
<nextsent>we wish our work to be portable at least to other slavic languages, for which we assume that elaborate morphological analyzers will not be available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2700">
<title id=" W04-3229.xml">a resource light approach to russian morphology tagging russian using czech resources </title>
<section> case 9 8.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 morphological analysis.
</prevsent>
<prevsent>in this section we describe our approach to resource-light encoding of salient facts about the russian lexicon.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
our techniques are not as radical as previously explored unsupervised methods (goldsmith, 2001; <papid> J01-2001 </papid>yarowsky and wicentowski, 2000), <papid> P00-1027 </papid>but are designed to be feasible for languages for which serious morphological expertise is unavailable to us.</citsent>
<aftsection>
<nextsent>we use paradigm-based morphology that avoids the need to explicitly create largelexicon.
</nextsent>
<nextsent>the price that we pay for this is overgener ation.
</nextsent>
<nextsent>most of these analyses look very implausible to russian speaker, but significantly increasing the precision would be at the cost of greater development time than our resource-light approach is able to commit.
</nextsent>
<nextsent>we wish our work to be portable at least to other slavic languages, for which we assume that elaborate morphological analyzers will not be available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2702">
<title id=" W04-3229.xml">a resource light approach to russian morphology tagging russian using czech resources </title>
<section> ongoing research.  </section>
<citcontext>
<prevsection>
<prevsent>just as knowledge of english words is sometimes helpful (modulo sound changes) when reading german, knowledge of the czech lexicon should be helpful (mod ulo character set issues) when reading russian.
</prevsent>
<prevsent>weare seeking the right way to ope rationalize this intuition in our system, bearing in mind that we want sufficiently general algorithm to make the method portable to other languages, for which we assume we have neither the time nor the expertise to undertake knowledge-intensive work.
</prevsent>
</prevsection>
<citsent citstr=" N01-1014 ">
a potentially suit able cognate algorithm is described by (kondrak, 2001).<papid> N01-1014 </papid></citsent>
<aftsection>
<nextsent>finally, we would like to extend our work to slavic languages for which there are even fewer available resources than russian, such as belarusian, since this was the original motivation for undertaking the work in the first place.
</nextsent>
<nextsent>acknowledgements we thank erhard hinrichs and eric fosler-lussier forgiving us feedback on previous versions of the paper and providing useful suggestions for subtag gers and voting; jan hajic?
</nextsent>
<nextsent>for the help with the czech tag system and the morphological analyzer; to the clippers discussion group for allowing us to interview ourselves in front of them, and for ensuing discussion, and to two anonymous emnlp reviewers for extremely constructive feedback.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2703">
<title id=" W06-0304.xml">user directed sentiment analysis visualizing the affective content of documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, corporations use sentiment analysis to determine employee attitude and customer satisfaction with their products.
</prevsent>
<prevsent>given the plethora of data in digital form, the ability to accurately and efficiently measure the emotional content of documents is paramount.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
the focus of much of the automatic sentiment analysis research is on identifying the affect bearing words (words with emotional content) and on measurement approaches for sentiment (turney &amp; littman, 2003; pang &amp; lee, 2004; <papid> P04-1035 </papid>wilson et al, 2005).<papid> H05-1044 </papid></citsent>
<aftsection>
<nextsent>while identifying related content is an essential component for automatic sentiment analysis, it only provides half the story.
</nextsent>
<nextsent>a useful area of research that has received much less attention is how these measurements might be presented to the users for exploration and added value.
</nextsent>
<nextsent>this paper discusses approaches for visualizing affect and describes an interactive capability for exploring emotion in large document collection.
</nextsent>
<nextsent>in section 2 we review current approaches to identifying the affective content of documents, as well as possible ways of visualizing it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2705">
<title id=" W06-0304.xml">user directed sentiment analysis visualizing the affective content of documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, corporations use sentiment analysis to determine employee attitude and customer satisfaction with their products.
</prevsent>
<prevsent>given the plethora of data in digital form, the ability to accurately and efficiently measure the emotional content of documents is paramount.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
the focus of much of the automatic sentiment analysis research is on identifying the affect bearing words (words with emotional content) and on measurement approaches for sentiment (turney &amp; littman, 2003; pang &amp; lee, 2004; <papid> P04-1035 </papid>wilson et al, 2005).<papid> H05-1044 </papid></citsent>
<aftsection>
<nextsent>while identifying related content is an essential component for automatic sentiment analysis, it only provides half the story.
</nextsent>
<nextsent>a useful area of research that has received much less attention is how these measurements might be presented to the users for exploration and added value.
</nextsent>
<nextsent>this paper discusses approaches for visualizing affect and describes an interactive capability for exploring emotion in large document collection.
</nextsent>
<nextsent>in section 2 we review current approaches to identifying the affective content of documents, as well as possible ways of visualizing it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2709">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by using aparser to constrain-parse its own output, and by hy pothesizing and testing for distributional similarity with back-off distributions, we have evidence that finally explains that (a) bilexical statistics are actually getting used quite often but that (b) the distributions are so similar to those that do not include head words as to be nearly indistinguishable insofar as making parse decisions.
</prevsent>
<prevsent>finally, our analysis has provided for the first time an effective way to do parameter selection for generative lexicalized statistical parsing model.
</prevsent>
</prevsection>
<citsent citstr=" P92-1024 ">
lexicalized statistical parsing models, such as those built by black et al  (1992<papid> P92-1024 </papid>a), magerman (1994), collins (1999) and charniak (2000), <papid> A00-2018 </papid>have been enormously successful, but they also have an enormous complexity.</citsent>
<aftsection>
<nextsent>their success has often been attributed to their sensitivity to individual lexical items, and it is precisely this incorporation of lexical items into features or parameter schemata that gives rise to their complexity.
</nextsent>
<nextsent>in order to help determine which features are helpful, the somewhat crude-but effective method has been to compare models overall parsing performance with and without feature.
</nextsent>
<nextsent>often, it has seemed that features that are derived from linguistic principles result in higher performing models (cf.
</nextsent>
<nextsent>(collins, 1999)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2711">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by using aparser to constrain-parse its own output, and by hy pothesizing and testing for distributional similarity with back-off distributions, we have evidence that finally explains that (a) bilexical statistics are actually getting used quite often but that (b) the distributions are so similar to those that do not include head words as to be nearly indistinguishable insofar as making parse decisions.
</prevsent>
<prevsent>finally, our analysis has provided for the first time an effective way to do parameter selection for generative lexicalized statistical parsing model.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
lexicalized statistical parsing models, such as those built by black et al  (1992<papid> P92-1024 </papid>a), magerman (1994), collins (1999) and charniak (2000), <papid> A00-2018 </papid>have been enormously successful, but they also have an enormous complexity.</citsent>
<aftsection>
<nextsent>their success has often been attributed to their sensitivity to individual lexical items, and it is precisely this incorporation of lexical items into features or parameter schemata that gives rise to their complexity.
</nextsent>
<nextsent>in order to help determine which features are helpful, the somewhat crude-but effective method has been to compare models overall parsing performance with and without feature.
</nextsent>
<nextsent>often, it has seemed that features that are derived from linguistic principles result in higher performing models (cf.
</nextsent>
<nextsent>(collins, 1999)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2712">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a rigorous analysis of features or parameters in relation to the entire model is calledfor.
</prevsent>
<prevsent>accordingly, this work aims to provide thorough analysis of the nature of the parameters in collins-style parsing model, with particular focuson the two parameter classes that generate lexicalized modifying nonterminals, for these are where all sentences words are generated except for the head word of the entire sentence; also, these two parameter classes have by far the most parameters and suffer the most from sparse data problems.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
inspite of using collins-style model as the basis for analysis, throughout this paper, we will attempt to present information that is widely applicable be cause it pertains to properties of the widely-usedtreebank (marcus et al , 1993) <papid> J93-2004 </papid>and lexicalized parsing models in general.</citsent>
<aftsection>
<nextsent>this work also sheds light on the much-discussedbilexical dependencies?
</nextsent>
<nextsent>of statistical parsing models.
</nextsent>
<nextsent>beginning with the seminal work at ibm (black et al , 1991; <papid> H91-1060 </papid>black et al , 1992<papid> P92-1024 </papid>b; black et al , 1992<papid> P92-1024 </papid>a), and continuing with such lexical ist approaches as (eisner, 1996), <papid> C96-1058 </papid>these features have been lauded for their ability to approximate words semantics asa means to override syntactic preferences with semantic ones (collins, 1999; eisner, 2000).</nextsent>
<nextsent>how ever, the work of gildea (2001) <papid> W01-0521 </papid>showed that, with an approximate re implementation of collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2713">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work also sheds light on the much-discussedbilexical dependencies?
</prevsent>
<prevsent>of statistical parsing models.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
beginning with the seminal work at ibm (black et al , 1991; <papid> H91-1060 </papid>black et al , 1992<papid> P92-1024 </papid>b; black et al , 1992<papid> P92-1024 </papid>a), and continuing with such lexical ist approaches as (eisner, 1996), <papid> C96-1058 </papid>these features have been lauded for their ability to approximate words semantics asa means to override syntactic preferences with semantic ones (collins, 1999; eisner, 2000).</citsent>
<aftsection>
<nextsent>how ever, the work of gildea (2001) <papid> W01-0521 </papid>showed that, with an approximate re implementation of collins?</nextsent>
<nextsent>model1, removing all parameters that involved dependencies between modifier word and its head resulted in surprisingly small decrease in overall parse ac curacy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2722">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work also sheds light on the much-discussedbilexical dependencies?
</prevsent>
<prevsent>of statistical parsing models.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
beginning with the seminal work at ibm (black et al , 1991; <papid> H91-1060 </papid>black et al , 1992<papid> P92-1024 </papid>b; black et al , 1992<papid> P92-1024 </papid>a), and continuing with such lexical ist approaches as (eisner, 1996), <papid> C96-1058 </papid>these features have been lauded for their ability to approximate words semantics asa means to override syntactic preferences with semantic ones (collins, 1999; eisner, 2000).</citsent>
<aftsection>
<nextsent>how ever, the work of gildea (2001) <papid> W01-0521 </papid>showed that, with an approximate re implementation of collins?</nextsent>
<nextsent>model1, removing all parameters that involved dependencies between modifier word and its head resulted in surprisingly small decrease in overall parse ac curacy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2723">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of statistical parsing models.
</prevsent>
<prevsent>beginning with the seminal work at ibm (black et al , 1991; <papid> H91-1060 </papid>black et al , 1992<papid> P92-1024 </papid>b; black et al , 1992<papid> P92-1024 </papid>a), and continuing with such lexical ist approaches as (eisner, 1996), <papid> C96-1058 </papid>these features have been lauded for their ability to approximate words semantics asa means to override syntactic preferences with semantic ones (collins, 1999; eisner, 2000).</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
how ever, the work of gildea (2001) <papid> W01-0521 </papid>showed that, with an approximate re implementation of collins?</citsent>
<aftsection>
<nextsent>model1, removing all parameters that involved dependencies between modifier word and its head resulted in surprisingly small decrease in overall parse accuracy.
</nextsent>
<nextsent>the prevailing assumption was then that such bilexical statistics were not useful for making syntactic decisions, although it was not entirely clear why.
</nextsent>
<nextsent>subsequently, we replicated gildeas experiment with complete emulation of model 2 and presented additional evidence that bilexicalstatistics were barely getting used during decoding (bikel, 2004), <papid> J04-4004 </papid>appearing to confirm the original result.</nextsent>
<nextsent>however, the present work will show that such statistics do get frequently used for thehighest-probability parses, but that when collins style model generates modifier words, the bilexicalparameters are so similar to their back-off distributions as to provide almost no extra predictive infor mation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2726">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>model1, removing all parameters that involved dependencies between modifier word and its head resulted in surprisingly small decrease in overall parse accuracy.
</prevsent>
<prevsent>the prevailing assumption was then that such bilexical statistics were not useful for making syntactic decisions, although it was not entirely clear why.
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
subsequently, we replicated gildeas experiment with complete emulation of model 2 and presented additional evidence that bilexicalstatistics were barely getting used during decoding (bikel, 2004), <papid> J04-4004 </papid>appearing to confirm the original result.</citsent>
<aftsection>
<nextsent>however, the present work will show that such statistics do get frequently used for thehighest-probability parses, but that when collins style model generates modifier words, the bilexicalparameters are so similar to their back-off distributions as to provide almost no extra predictive information.
</nextsent>
<nextsent>a parsing model coupled with decoder (an algorithm to search the space of possible trees forgiven terminal sequence) is largely an engineering effort.
</nextsent>
<nextsent>in the end, the performance of the parser with respect to its evaluation criteria typically accuracy, and perhaps also speed are all that matter.
</nextsent>
<nextsent>consequently, the engineer must understand what the model is doing only to the point that it helps make the model perform better.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2737">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> distributional similarity and bilexical.  </section>
<citcontext>
<prevsection>
<prevsent>the exploratory data analysis of 3.3 suggests an explanation for this perplexing behavior: the distributions that include the head word versus those that do not are so similar as to make almost no difference in terms of parse accuracy.
</prevsent>
<prevsent>5.1 distributional similarity.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
a useful metric for measuring distributional similarity, as explored by (lee, 1999), <papid> P99-1004 </papid>is the jensen shannon divergence (lin, 1991): js (p ? ) = 1 2 [ ( ? ?</citsent>
<aftsection>
<nextsent>avgp,q ) + ( ? ?
</nextsent>
<nextsent>avgp,q )] (2) where is the kullback-leibler divergence (cover and thomas, 1991) and where avgp,q = 1 2 (p(a) + q(a)) for an event in the event spaceof at least one of the two distributions.
</nextsent>
<nextsent>one interpretation for the jensen-shannon divergence due toslonim et al  (2002) is that it is related to the log likelihood that the two sample distributions originate by the most likely common source,?
</nextsent>
<nextsent>relating the quantity to the two-sample problem?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2739">
<title id=" W04-3224.xml">a distributional analysis of a lexicalized statistical parsing model </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>examining the lower-entropy pmw distributions revealed that, in many cases, the model was not somuch learning how to disambiguate given syn tactic/lexical choice, but simply not having much to learn.
</prevsent>
<prevsent>for example, once partially-lexicalized nonterminal has been generated whose tag is fairly specialized, such as in, then the model has painted itself into lexical corner?, as it were (the extreme example is to, tag that can only be assigned to the word to).
</prevsent>
</prevsection>
<citsent citstr=" W02-1002 ">
this is an example of the label bias problem, which has been the subject of recent discussion (lafferty et al , 2001; klein and manning, 2002).<papid> W02-1002 </papid></citsent>
<aftsection>
<nextsent>of course, just because there is label bias?
</nextsent>
<nextsent>does not necessarily mean there is problem.
</nextsent>
<nextsent>ifthe decoder pursues theory to nonterminal/part of-speech tag pre terminal that has an extremely low entropy distribution for possible headwords, then there is certainly chance that it will get stuck?
</nextsent>
<nextsent>in potentially bad theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2740">
<title id=" W04-3110.xml">a large scale terminology resource for biomedical text processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has been widely recognized that the biomedical literature is now so large, and growing so quickly, that it is be coming increasingly difficult for researchers to access the published results that are relevant to their research.
</prevsent>
<prevsent>consequently, any technology that can facilitate this access should help to increase research productivity.
</prevsent>
</prevsection>
<citsent citstr=" W02-0312 ">
this has led to an increased interest in the application of natural language processing techniques for the automatic capture of biomedical content from journal abstracts, complete papers, and other textual documents (gaizauskas et al,2003; hahn et al, 2002; pustejovsky et al, 2002; <papid> W02-0312 </papid>rindflesch et al, 2000).<papid> A00-1026 </papid></citsent>
<aftsection>
<nextsent>an essential processing step in these applications isthe identification and semantic classification of technical terms in text, since these terms often point to entities about which information should be extracted.
</nextsent>
<nextsent>proper semantic classification of terms also helps in resolving anaphora and extracting relations whose arguments are restricted semantically.
</nextsent>
<nextsent>1.1 challenge.
</nextsent>
<nextsent>any technical domain generates very large numbers of terms ? single or multiword expressions that have some specialised use or meaning in that domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2741">
<title id=" W04-3110.xml">a large scale terminology resource for biomedical text processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has been widely recognized that the biomedical literature is now so large, and growing so quickly, that it is be coming increasingly difficult for researchers to access the published results that are relevant to their research.
</prevsent>
<prevsent>consequently, any technology that can facilitate this access should help to increase research productivity.
</prevsent>
</prevsection>
<citsent citstr=" A00-1026 ">
this has led to an increased interest in the application of natural language processing techniques for the automatic capture of biomedical content from journal abstracts, complete papers, and other textual documents (gaizauskas et al,2003; hahn et al, 2002; pustejovsky et al, 2002; <papid> W02-0312 </papid>rindflesch et al, 2000).<papid> A00-1026 </papid></citsent>
<aftsection>
<nextsent>an essential processing step in these applications isthe identification and semantic classification of technical terms in text, since these terms often point to entities about which information should be extracted.
</nextsent>
<nextsent>proper semantic classification of terms also helps in resolving anaphora and extracting relations whose arguments are restricted semantically.
</nextsent>
<nextsent>1.1 challenge.
</nextsent>
<nextsent>any technical domain generates very large numbers of terms ? single or multiword expressions that have some specialised use or meaning in that domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2743">
<title id=" W05-1616.xml">generating readable texts for readers with low basic skills </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, generating turns in intelligent tutoring system (its) dialogues (e.g. [di eugenio et al , 2001; [moore et al , 2004]).
</prevsent>
<prevsent>although turns can give feedback, the kind of feed back differs in that it attempts to teach student about an immediate domain-specific learning problem, rather than to summarise his/her overall skills.
</prevsent>
</prevsection>
<citsent citstr=" P93-1031 ">
with regard to tailoring texts for different readers, number of previous researchers have looked at tailoring generated texts according to whether the reader is domain expert or novice (for example [paris, 1988; mckeown et al , 1993; <papid> P93-1031 </papid>milosavljevic and oberlander, 1998]).</citsent>
<aftsection>
<nextsent>less work has been done on tailoring texts according to the readers literacy.
</nextsent>
<nextsent>perhaps the best-known previous work in this area is pset [devlin et al , 1999], which focused on syntactic and lexical choices in texts intended for aphasic readers.
</nextsent>
<nextsent>unfortunately most of psets adaptation rules were not experimentally validated.
</nextsent>
<nextsent>siddharthan [2003] similarly proposed and implemented system for simplifying texts, but did not evaluate how readable his generated texts were for poor readers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2744">
<title id=" W05-1616.xml">generating readable texts for readers with low basic skills </title>
<section> linguistic choices investigated.  </section>
<citcontext>
<prevsection>
<prevsent>scott and desouza [1990] suggested some psycholinguisti cally-motivated rules for expressing discourse relations, but did not evaluate them at all.
</prevsent>
<prevsent>figure 1 ? extract from typical content plan the document (content) planners of our system produce as output tree, where core messages are related by discourse relations such as explanation or concession; this basically follows the architecture described by reiter and dale [2000].
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
discourse relations are essentially rhetorical structure theory (rst) relations [mann and thompson, 1987], and messages are represented using deep-syntactic representation, which is loosely based on realpro [lavoie and rambow, 1997].<papid> A97-1039 </papid></citsent>
<aftsection>
<nextsent>an example of an extract from typical content plan, with messages shown as text glosses instead of deep syntactic structures, is shown in figure 1.
</nextsent>
<nextsent>our focus to date has been on how discourse relations such as concession and condition in figure 1 are expressed, in particular: ? cue phrases: should cue phrase (or multiple cue phrases) be used to express discourse relation?
</nextsent>
<nextsent>if so, which one(s)?
</nextsent>
<nextsent>for example, should we generate: ? if you practise reading, your skills will improve (one cue, if) ? if you practise reading, then your skills will im prove (two cues, if and then) ? ordering: which order should the constituents related by discourse relation be expressed in?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2745">
<title id=" W05-1616.xml">generating readable texts for readers with low basic skills </title>
<section> choice rules and the micro planner.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 microplanner.
</prevsent>
<prevsent>our micro planner treats the decision-making problem as constraint-satisfaction problem (csp), using the above constraints and optimisation rules.
</prevsent>
</prevsection>
<citsent citstr=" C00-2093 ">
it is in general terms similar to the csp system that power [2000] <papid> C00-2093 </papid>and power et al  [2002] used to make expression choices about rhetorical structures, as discussed above.</citsent>
<aftsection>
<nextsent>however, we make different choices.
</nextsent>
<nextsent>for example, our micro planner decides whether 0, 1, or 2 cue phrases should be used to express discourse relation, whereas power et al assumes that single cue phrase is always used.
</nextsent>
<nextsent>power et al micro planner makes choices about indentation, which our micro planner does not.
</nextsent>
<nextsent>power et al  micro planner also attempts to optimize the document as whole, whereas ours processes each relation separately, and does not consider interactions between the expressions of different relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2746">
<title id=" W05-1616.xml">generating readable texts for readers with low basic skills </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>however, if such models are significantly more effective than generic or subgroup models in terms of generating readable texts, they may be worth exploring, since the benefits of making health information (for example) more accessible to people with limited reading skills could be very large.
</prevsent>
<prevsent>5.1 future work on lexical choice.
</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
including lexical choice in our models will not be easy be cause true synonyms and paraphrases are rare [edmonds and hirst, 2002].<papid> J02-2001 </papid></citsent>
<aftsection>
<nextsent>hence we cannot simply select between different lexicalisations that have exactly the same meaning, instead we have to determine which synonyms or paraphrases are appropriate given the texts content and the systems goals (as well as readability preferences).
</nextsent>
<nextsent>for example, since many people have problems with the technical term grammar, in our pilots we tried paraphrasing problems with grammar as problems writing good sentences.
</nextsent>
<nextsent>however, many subjects interpreted the latter phrase assaying that they had problems with spelling (not gram mar), and this confused students whose spelling was in fact fine.
</nextsent>
<nextsent>hence this paraphrase is probably not appropriate, at least for students with poor grammar but good spelling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2747">
<title id=" W06-0115.xml">the third international chinese language processing bakeoff word segmentation and named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while such tokenization is relativelystraight-forward in languages which use whit espace to delimit words, chinese presents significant challenge since it is typically written with out such separation.
</prevsent>
<prevsent>word segmentation has thus long been the focus of significant research because of its role as necessary pre-processing phase forthe tasks above.
</prevsent>
</prevsection>
<citsent citstr=" I05-3017 ">
however, word segmentation remains significant challenge both for the difficulty of the task itself and because standards for segmentation vary and human segment ers may often disagree.sighan, the special interest group for chinese language processing of the association for computational linguistics, conducted two prior word segmentation bake offs, in 2003 and2005(emerson, 2005), <papid> I05-3017 </papid>which established benchmarks for word segmentation against which other systems are judged.</citsent>
<aftsection>
<nextsent>the bakeoff presentations at sighan workshops highlighted new approaches in the field as well as the crucial importance of handling out-of-vocabulary (oov) words.a significant class of oov words is named entities, such as person, location, and organization names.
</nextsent>
<nextsent>these terms are frequently poorly covered in lexical resources and change over time as new individuals, institutions, or products appear.
</nextsent>
<nextsent>these terms also play particularly crucial role in information retrieval, reference resolution, and question answering.
</nextsent>
<nextsent>as result of this importance, and interest in expanding the scope of the bakeoff expressed at the fourth sighan workshop, in the winter of 2005 it was decided to hold new bake off to evaluate both continued progress in word segmentation (ws) and the state of the art in chinese named entity recognition (ner).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2748">
<title id=" W06-0115.xml">the third international chinese language processing bakeoff word segmentation and named entity recognition </title>
<section> results &amp; discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the topline employed the same procedure, but instead used the test vocabulary.
</prevsent>
<prevsent>these results are shown in tables 3 and 4.
</prevsent>
</prevsection>
<citsent citstr=" W03-1719 ">
for the ws task, we computed the following measures using the score(sproat and emerson,2003) <papid> W03-1719 </papid>program developed for the previous bake offs: recall (r), precision (p), equally weightedf-measure (f = 2pr(p+r) ), the rate of out-ofvocabulary words (oov rate) in the test corpus, the recall on oov (roov), and recall on in vocabulary words (riv).</citsent>
<aftsection>
<nextsent>in and out of vocabulary status are defined relative to the training corpus.
</nextsent>
<nextsent>following previous bake offs, we employ the central limit theorem for bernoulli trials (grin stead and snell, 1997) to compute 95% confidence interval as 2 ?
</nextsent>
<nextsent>(p(1p)n ), assuming the binomialdistribution is appropriate.
</nextsent>
<nextsent>for recall, cr, we assume that recall represents the probability of correct word identification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2749">
<title id=" W06-0105.xml">semantic analysis of chinese garden path sentences </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>fodor and inoue(1998) proposed the principles of attach anyway and adjust to explain how reanalysis processes operate.
</prevsent>
<prevsent>ferreira and christianson(2001) stated that reflexive absolute transitive (rat) verbs, such as wash, bathe, shave, scratch, groom, and so on, are likely to give rise to garden-paths.
</prevsent>
</prevsection>
<citsent citstr=" P84-1104 ">
michael j. pazzani(1984) <papid> P84-1104 </papid>demonstrated how to re analyze one type of garden-path sentence that arises from passive participle and main verb conflicting.however ferreira and henderson(2001) demonstrated that reanalysis is more difficult when the head of the mis analyzed phrase (baby in the baby that was small and cute) is distant from the error signal.</citsent>
<aftsection>
<nextsent>in chinese, there has been little research that directly addresses the problem of garden-paths.
</nextsent>
<nextsent>zhiwei feng(2003) interpreted the temporarily ambiguous verb structure in garden-path in two ways; one is as subordinate clause (mv), the other is reduced relative (rr).
</nextsent>
<nextsent>he defined garden path degree (gpd) as mv/rr.
</nextsent>
<nextsent>he studied some types of temporarily ambiguous verb structures such as np1+vp+np2+de+np3, vp+np1+de+np2, v+adj+de+n and v+v+de+n, and stated that when gpd is larger than 3, the temporarily ambiguous verb structure may give rise to garden-path.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2750">
<title id=" W04-2807.xml">different sense granularities for different applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are also separate senses in wordnet, but wordnet has an additional 26 senses for call, and the current best performance of an automatic word sense disambiguation system this type of polysemous verb is only 60.2% (dang and palmer, 2002).
</prevsent>
<prevsent>is it possible that sense distinctions that are less fine-grained than wordnets distinctions could be made more reliably, and could still benefit this type of nlp application?
</prevsent>
</prevsection>
<citsent citstr=" W00-0103 ">
the idea of under specification as solution to wsd has been proposed in buitelaar 2000 (<papid> W00-0103 </papid>among others), who pointed out that for some applications, such as document categorization, information retrieval, and information extraction it may be sufficient to know if given word belongs to certain class of wordnet senses or underspecified sense.</citsent>
<aftsection>
<nextsent>on the other hand, there is evidence that machine translation of languages as diverse as chinese and english will require all of the fine-grained sense distinctions that wordnet is capable of providing, and even more (ng, et al 2003, <papid> P03-1058 </papid>palmer, et. al., to appear).</nextsent>
<nextsent>an hierarchical approach to verb senses, of the type discussed in this paper, presents obvious advantages for the problem of word sense disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2751">
<title id=" W04-2807.xml">different sense granularities for different applications </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is it possible that sense distinctions that are less fine-grained than wordnets distinctions could be made more reliably, and could still benefit this type of nlp application?
</prevsent>
<prevsent>the idea of under specification as solution to wsd has been proposed in buitelaar 2000 (<papid> W00-0103 </papid>among others), who pointed out that for some applications, such as document categorization, information retrieval, and information extraction it may be sufficient to know if given word belongs to certain class of wordnet senses or underspecified sense.</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
on the other hand, there is evidence that machine translation of languages as diverse as chinese and english will require all of the fine-grained sense distinctions that wordnet is capable of providing, and even more (ng, et al 2003, <papid> P03-1058 </papid>palmer, et. al., to appear).</citsent>
<aftsection>
<nextsent>an hierarchical approach to verb senses, of the type discussed in this paper, presents obvious advantages for the problem of word sense disambiguation.
</nextsent>
<nextsent>the human annotation task is simplified, since there are fewer choices at each level and clearer distinctions between them.
</nextsent>
<nextsent>the automated systems can combine training data from closely related senses to overcome the sparse data problem, and both humans and systems can back off to more coarse-grained choice when fine-grained choices prove too difficult.
</nextsent>
<nextsent>the approach to verb senses presented in this paper assumes three different levels of sense distinctions: propbank frame sets, wordnet groupings, and wordnet senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2755">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this weight is normalised to fall within the range
</prevsent>
<prevsent>0,1  where  indicates that all parses contain the gr.
</prevsent>
</prevsection>
<citsent citstr=" C02-1013 ">
therefore, high precision gr sets can be determined by thresholding on the gr weight (carroll and briscoe, 2002).<papid> C02-1013 </papid></citsent>
<aftsection>
<nextsent>carroll and briscoe compute weighted grs by first unpacking all parses or the n-best subset from the parse forest.
</nextsent>
<nextsent>hence, this approach is either (a) inefficient (and for some examples impracticable) if large number of parses are licensed by the grammar, or (b) inaccurate if the number of parses unpacked is less than the number licensed by the grammar.
</nextsent>
<nextsent>in this paper, we show how to obviate the need to trade off efficiency and accuracy by extracting weighted grs directly from the parse forest using dynamic programming approach based on the inside-outside algorithm (ioa) (baker, 1979; lari and young, 1990).
</nextsent>
<nextsent>this approach enables efficient calculation of weighted grs over all parses and substantially improves the throughput and memory usage of the parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2756">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach enables efficient calculation of weighted grs over all parses and substantially improves the throughput and memory usage of the parser.
</prevsent>
<prevsent>since the parser is unification based, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption.
</prevsent>
</prevsection>
<citsent citstr=" P01-1042 ">
similar dynamic programming techniques thatare variants of the ioa have been applied for related tasks, such as parse selection (johnson, 2001; <papid> P01-1042 </papid>schmid and rooth, 2001; <papid> P01-1060 </papid>geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; kaplan et al, 2004; <papid> N04-1013 </papid>taskar et al, 2004).<papid> W04-3201 </papid></citsent>
<aftsection>
<nextsent>the approach we take is similar to schmid and rooths (2001) <papid> P01-1060 </papid>adaptation of the algorithm, where expected governors?</nextsent>
<nextsent>(similar to our gr specifications?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2757">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach enables efficient calculation of weighted grs over all parses and substantially improves the throughput and memory usage of the parser.
</prevsent>
<prevsent>since the parser is unification based, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption.
</prevsent>
</prevsection>
<citsent citstr=" P01-1060 ">
similar dynamic programming techniques thatare variants of the ioa have been applied for related tasks, such as parse selection (johnson, 2001; <papid> P01-1042 </papid>schmid and rooth, 2001; <papid> P01-1060 </papid>geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; kaplan et al, 2004; <papid> N04-1013 </papid>taskar et al, 2004).<papid> W04-3201 </papid></citsent>
<aftsection>
<nextsent>the approach we take is similar to schmid and rooths (2001) <papid> P01-1060 </papid>adaptation of the algorithm, where expected governors?</nextsent>
<nextsent>(similar to our gr specifications?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2758">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach enables efficient calculation of weighted grs over all parses and substantially improves the throughput and memory usage of the parser.
</prevsent>
<prevsent>since the parser is unification based, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption.
</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
similar dynamic programming techniques thatare variants of the ioa have been applied for related tasks, such as parse selection (johnson, 2001; <papid> P01-1042 </papid>schmid and rooth, 2001; <papid> P01-1060 </papid>geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; kaplan et al, 2004; <papid> N04-1013 </papid>taskar et al, 2004).<papid> W04-3201 </papid></citsent>
<aftsection>
<nextsent>the approach we take is similar to schmid and rooths (2001) <papid> P01-1060 </papid>adaptation of the algorithm, where expected governors?</nextsent>
<nextsent>(similar to our gr specifications?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2759">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach enables efficient calculation of weighted grs over all parses and substantially improves the throughput and memory usage of the parser.
</prevsent>
<prevsent>since the parser is unification based, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption.
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
similar dynamic programming techniques thatare variants of the ioa have been applied for related tasks, such as parse selection (johnson, 2001; <papid> P01-1042 </papid>schmid and rooth, 2001; <papid> P01-1060 </papid>geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; kaplan et al, 2004; <papid> N04-1013 </papid>taskar et al, 2004).<papid> W04-3201 </papid></citsent>
<aftsection>
<nextsent>the approach we take is similar to schmid and rooths (2001) <papid> P01-1060 </papid>adaptation of the algorithm, where expected governors?</nextsent>
<nextsent>(similar to our gr specifications?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2760">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach enables efficient calculation of weighted grs over all parses and substantially improves the throughput and memory usage of the parser.
</prevsent>
<prevsent>since the parser is unification based, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
similar dynamic programming techniques thatare variants of the ioa have been applied for related tasks, such as parse selection (johnson, 2001; <papid> P01-1042 </papid>schmid and rooth, 2001; <papid> P01-1060 </papid>geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; kaplan et al, 2004; <papid> N04-1013 </papid>taskar et al, 2004).<papid> W04-3201 </papid></citsent>
<aftsection>
<nextsent>the approach we take is similar to schmid and rooths (2001) <papid> P01-1060 </papid>adaptation of the algorithm, where expected governors?</nextsent>
<nextsent>(similar to our gr specifications?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2762">
<title id=" W05-1517.xml">efficient extraction of grammatical relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>initially, they create packed parse forest and during second pass the parse forest nodes are split if multiple lexical heads occur.
</prevsent>
<prevsent>theioa is applied over this split data structure.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
similarly, clark and curran (2004) <papid> P04-1014 </papid>alter their packing algorithm so that nodes in the packed chart have thesame semantic head and unfilled?</citsent>
<aftsection>
<nextsent>grs.
</nextsent>
<nextsent>our ap 160proach is novel in that while calculating inside probabilities we allow any node in the parse forest to have multiple semantic heads.clark and curran (2004) <papid> P04-1014 </papid>apply miyao and tsujiis (2002) dynamic programming approach to determine weighted grs.</nextsent>
<nextsent>they outline an alternative parse selection method based on the resulting weighted grs: select the (consistent) gr set with the highest average weighted gr score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2777">
<title id=" W05-0817.xml">combined word alignments </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we briefly describe word alignment system that combines two different methods in bitext correspondences identification.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
the first one is hypotheses testing approach (gale and church, 1991; <papid> H91-1026 </papid>melamed, 2001; tufi?</citsent>
<aftsection>
<nextsent>2002) while the second one is closer to model estimating approach (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>we show that combining the two align ers the results are significantly improved as compared to each individual aligner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2778">
<title id=" W05-0817.xml">combined word alignments </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we briefly describe word alignment system that combines two different methods in bitext correspondences identification.
</prevsent>
<prevsent>the first one is hypotheses testing approach (gale and church, 1991; <papid> H91-1026 </papid>melamed, 2001; tufi?</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
2002) while the second one is closer to model estimating approach (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>we show that combining the two align ers the results are significantly improved as compared to each individual aligner.
</nextsent>
<nextsent>in (tufi?, 2002) we described translation equivalence extraction program called treq the development of which was twofold motivated: to help enriching the synsets of the romanian wordnet (tufi?
</nextsent>
<nextsent>et al 2004a) with new liter als based on bilingual corpora evidence and to check the inter lingual alignment of our wordnet against the princeton wordnet.
</nextsent>
<nextsent>the translation equivalence extractor has been also incorporated into wsd system (tufi?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2779">
<title id=" W05-0817.xml">combined word alignments </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we briefly describe word alignment system that combines two different methods in bitext correspondences identification.
</prevsent>
<prevsent>the first one is hypotheses testing approach (gale and church, 1991; <papid> H91-1026 </papid>melamed, 2001; tufi?</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
2002) while the second one is closer to model estimating approach (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>we show that combining the two align ers the results are significantly improved as compared to each individual aligner.
</nextsent>
<nextsent>in (tufi?, 2002) we described translation equivalence extraction program called treq the development of which was twofold motivated: to help enriching the synsets of the romanian wordnet (tufi?
</nextsent>
<nextsent>et al 2004a) with new liter als based on bilingual corpora evidence and to check the inter lingual alignment of our wordnet against the princeton wordnet.
</nextsent>
<nextsent>the translation equivalence extractor has been also incorporated into wsd system (tufi?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2782">
<title id=" W06-0207.xml">lolo a system based on terminology for multilingual extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>patterns of usage in training corpus.
</prevsent>
<prevsent>the analysis of an english news wire corpus (1,720,142 tokens) and arabic news wire corpus (1,720,154 tokens) show encouraging results.
</prevsent>
</prevsection>
<citsent citstr=" W06-2204 ">
one of the recent trends in (adaptive) ie has been motivated by the empirical argument that annotated corpora, either annotated automatically or annotated manually, can provide sufficient information for creating the knowledge base of an ie system (mclernon and kushmerick, 2006).<papid> W06-2204 </papid></citsent>
<aftsection>
<nextsent>another equally important trend is to use manually selected seed patterns to initiate learn ing: in turn, active-training methods use seed patterns to learn new related patterns from unannotated corpora.
</nextsent>
<nextsent>many of the adaptive ie systems relyon the existing part-of-speech (pos) taggers (debnath and giles, 2005) and/or syntactic parsers (stevenson and greenwood, 2005) <papid> P05-1047 </papid>for analysing and annotating text corpora.</nextsent>
<nextsent>the use of corpora in ie, especially adaptive ie, should, in principle, alleviate the need for manually creating the rules for information extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2783">
<title id=" W06-0207.xml">lolo a system based on terminology for multilingual extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the recent trends in (adaptive) ie has been motivated by the empirical argument that annotated corpora, either annotated automatically or annotated manually, can provide sufficient information for creating the knowledge base of an ie system (mclernon and kushmerick, 2006).<papid> W06-2204 </papid></prevsent>
<prevsent>another equally important trend is to use manually selected seed patterns to initiate learn ing: in turn, active-training methods use seed patterns to learn new related patterns from unannotated corpora.</prevsent>
</prevsection>
<citsent citstr=" P05-1047 ">
many of the adaptive ie systems relyon the existing part-of-speech (pos) taggers (debnath and giles, 2005) and/or syntactic parsers (stevenson and greenwood, 2005) <papid> P05-1047 </papid>for analysing and annotating text corpora.</citsent>
<aftsection>
<nextsent>the use of corpora in ie, especially adaptive ie, should, in principle, alleviate the need for manually creating the rules for information extraction.
</nextsent>
<nextsent>the successful use of pos/syntactic taggers is dependent on the availability of the knowledge of (natural) language used by the authors of documents in given corpus.
</nextsent>
<nextsent>there is wealth of pos taggers and parsers available for english language, as it has been the most widely used language in computational linguistics.
</nextsent>
<nextsent>however, this is not the case for strategically important languages like arabic and chinese; to start with, in chinese one does not have the luxury of separating word-tokens by white space and in arabic complex rules are required to identify morphemes compared to english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2784">
<title id=" W06-0207.xml">lolo a system based on terminology for multilingual extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is wealth of pos taggers and parsers available for english language, as it has been the most widely used language in computational linguistics.
</prevsent>
<prevsent>however, this is not the case for strategically important languages like arabic and chinese; to start with, in chinese one does not have the luxury of separating word-tokens by white space and in arabic complex rules are required to identify morphemes compared to english.
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
the development of segmentation programs in these languages has certainly helped (gao et al, 2005; habash and rambow, 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>more work is needed in understanding these languages such that the knowledge thus derived can be used to power taggers and parsers.
</nextsent>
<nextsent>typically, ie systems are used to analyse news wire corpora, telephone conversations, and more recently in bio-informatics.
</nextsent>
<nextsent>the first two systems deal with language of everyday communications the general language- whereas bio informatics deals with specialist domain and has its own special language?.
</nextsent>
<nextsent>english special languages, for example languages of law, commerce, finance, science &amp; technology, each have limited vocabulary and idiosyncratic syntactic structures when compared with english used in an everyday context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2785">
<title id=" W06-0207.xml">lolo a system based on terminology for multilingual extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this, we believe, can be achieved by looking at the lexical signature of specialist domain and extracting collocational patterns of the individual items of the lexical signature.
</prevsent>
<prevsent>the lexical signature includes key vocabulary items of the domain and names of people, places and things in the do main.
</prevsent>
</prevsection>
<citsent citstr=" P93-1035 ">
there are instances in the part-of-speech tagging literature (brill, 1993) <papid> P93-1035 </papid>and in ie where corpus is used and words within grammatical category help to extract rules and patterns comprising essential information about domain or topic (wilks, 1998; yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>brill, wilks and yangarber induce grammars of universal kind: we focus on inducing local grammar that deals with the patterning of the items in the signature.
</nextsent>
<nextsent>note that in all these cases of grammar induction the intuition of the grammar builder plays critical part whether it be in the choice of syntactic transformation rules (brill 1993), <papid> P93-1035 </papid>or in choosing sense taggers and implicitly semantic rules (wilks, 1998; ciravegna and wilks, 2003), or in choosing user supplied seed patterns (yangarber, 2003).<papid> P03-1044 </papid></nextsent>
<nextsent>most of the work in grammar induction is focussed on english or typo logically similar languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2786">
<title id=" W06-0207.xml">lolo a system based on terminology for multilingual extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this, we believe, can be achieved by looking at the lexical signature of specialist domain and extracting collocational patterns of the individual items of the lexical signature.
</prevsent>
<prevsent>the lexical signature includes key vocabulary items of the domain and names of people, places and things in the do main.
</prevsent>
</prevsection>
<citsent citstr=" P03-1044 ">
there are instances in the part-of-speech tagging literature (brill, 1993) <papid> P93-1035 </papid>and in ie where corpus is used and words within grammatical category help to extract rules and patterns comprising essential information about domain or topic (wilks, 1998; yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>brill, wilks and yangarber induce grammars of universal kind: we focus on inducing local grammar that deals with the patterning of the items in the signature.
</nextsent>
<nextsent>note that in all these cases of grammar induction the intuition of the grammar builder plays critical part whether it be in the choice of syntactic transformation rules (brill 1993), <papid> P93-1035 </papid>or in choosing sense taggers and implicitly semantic rules (wilks, 1998; ciravegna and wilks, 2003), or in choosing user supplied seed patterns (yangarber, 2003).<papid> P03-1044 </papid></nextsent>
<nextsent>most of the work in grammar induction is focussed on english or typo logically similar languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2791">
<title id=" W06-0133.xml">maximum entropy word segmentation of chinese text </title>
<section> segmenter.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" I05-3025 ">
our chinese word segmenter is modification of the system described by low et al  (2005), <papid> I05-3025 </papid>which they entered in the 2005 second international chinese word segmentation bakeoff.</citsent>
<aftsection>
<nextsent>it uses maximum entropy (ratnaparkhi, 1998) model which is trained on the training corpora provided for this years bakeoff.
</nextsent>
<nextsent>the maximum entropy framework used is the python interface of zhang les maximum entropy modeling toolkit (zhang, 2004).
</nextsent>
<nextsent>1.1 properties in common with low et al . as with the system of low et al , our system treats the word segmentation problem as tagging problem.
</nextsent>
<nextsent>when segmenting string of chinese text, each character can be assigned one of four boundary tags: for character that stands alone as word, for character that begins amulti-character word, for character in multi character word which neither starts nor ends theword, and for character that ends multi character word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2796">
<title id=" W06-0504.xml">ontology population from textual mentions task definition and benchmark </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>buitelaar et al 2005); in particular, mentions are well defined and there are systems for automatic mention recognition.
</prevsent>
<prevsent>although there is no univo cally accepted definition for the op task, useful approximation has been suggested by (bontcheva and cunningham, 2005) as ontology driven information extraction with the goal of extracting and classifying instances of concepts and relations defined in ontology, in place of filling template.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
a similar task has been approached in variety of perspectives, including term clustering (lin, 1998 <papid> P98-2127 </papid>and almuhareb and poesio, 2004) <papid> W04-3221 </papid>and term categorization (avancini et al 2003).</citsent>
<aftsection>
<nextsent>a rather different task is ontology learning, where new concepts and relations are supposed to be acquired, with the consequence of changing the definition of the ontology itself (velardi et al 2005).
</nextsent>
<nextsent>however, since mention shave been introduced as an evolution of the traditional named entity recognition task (seetanev and magnini, 2006), <papid> E06-1003 </papid>they guarantee reasonable level of difficulty, which makes optmchallenging both for the computational linguistic side and the knowledge representationcommunity.</nextsent>
<nextsent>second, there already exist annotated data with mentions, delivered under the ace (automatic content extraction) initiative (ferro et al 2005, linguistic data consortium 2004), which makes the exploitation of machine learning based approaches possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2797">
<title id=" W06-0504.xml">ontology population from textual mentions task definition and benchmark </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>buitelaar et al 2005); in particular, mentions are well defined and there are systems for automatic mention recognition.
</prevsent>
<prevsent>although there is no univo cally accepted definition for the op task, useful approximation has been suggested by (bontcheva and cunningham, 2005) as ontology driven information extraction with the goal of extracting and classifying instances of concepts and relations defined in ontology, in place of filling template.
</prevsent>
</prevsection>
<citsent citstr=" W04-3221 ">
a similar task has been approached in variety of perspectives, including term clustering (lin, 1998 <papid> P98-2127 </papid>and almuhareb and poesio, 2004) <papid> W04-3221 </papid>and term categorization (avancini et al 2003).</citsent>
<aftsection>
<nextsent>a rather different task is ontology learning, where new concepts and relations are supposed to be acquired, with the consequence of changing the definition of the ontology itself (velardi et al 2005).
</nextsent>
<nextsent>however, since mention shave been introduced as an evolution of the traditional named entity recognition task (seetanev and magnini, 2006), <papid> E06-1003 </papid>they guarantee reasonable level of difficulty, which makes optmchallenging both for the computational linguistic side and the knowledge representationcommunity.</nextsent>
<nextsent>second, there already exist annotated data with mentions, delivered under the ace (automatic content extraction) initiative (ferro et al 2005, linguistic data consortium 2004), which makes the exploitation of machine learning based approaches possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2798">
<title id=" W06-0504.xml">ontology population from textual mentions task definition and benchmark </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a similar task has been approached in variety of perspectives, including term clustering (lin, 1998 <papid> P98-2127 </papid>and almuhareb and poesio, 2004) <papid> W04-3221 </papid>and term categorization (avancini et al 2003).</prevsent>
<prevsent>a rather different task is ontology learning, where new concepts and relations are supposed to be acquired, with the consequence of changing the definition of the ontology itself (velardi et al 2005).</prevsent>
</prevsection>
<citsent citstr=" E06-1003 ">
however, since mention shave been introduced as an evolution of the traditional named entity recognition task (seetanev and magnini, 2006), <papid> E06-1003 </papid>they guarantee reasonable level of difficulty, which makes optmchallenging both for the computational linguistic side and the knowledge representationcommunity.</citsent>
<aftsection>
<nextsent>second, there already exist annotated data with mentions, delivered under the ace (automatic content extraction) initiative (ferro et al 2005, linguistic data consortium 2004), which makes the exploitation of machine learning based approaches possible.
</nextsent>
<nextsent>finally, having limited scope with respect to olp, theoptm task allows for better estimation of per formance; in particular, it is possible to evaluate more easily the recall of the task, i.e. the proportion of information correctly assigned to an entity out of the total amount of information provided by certain mention.
</nextsent>
<nextsent>in the paper we both define the optm taskand describe an optm benchmark, i.e. document collection annotated with mentions as well as an ontology where information from mention shas been manually extracted.
</nextsent>
<nextsent>the general architecture of the optm task has been sketched above, considering three subtasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2799">
<title id=" W05-0707.xml">part of speech tagging for amharic using conditional random fields </title>
<section> pos tagging of amharic.  </section>
<citcontext>
<prevsection>
<prevsent>in these languages, words usually consist of several bound morphemes that would normally have independent lexical entries in languages like english.
</prevsent>
<prevsent>furthermore, in arabic and hebrew, the 49 description pos tag frequency noun 586 verb 203 auxiliary aux 20 numeral nu 65 adjective aj 31 adverb av 8 adposition ap 30 interject ion 0 punctuation pu 36 residual 15 table 1: distribution of pos tags diacritics that represent most vowels and gemina tion patterns are missing in written texts.
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
although amharic does not have special marker for gem ination, the amharic script fully encodes both the vowels and the consonants, hence it does not suffer from the ambiguity problem that may arise due to the missing vowels.as mentioned briefly in section 1, the morphological complexity of these languages opens up different alternative approaches in developing pos taggers for them (bar-haim et al, 2004; diab et al, 2004).<papid> N04-4038 </papid></citsent>
<aftsection>
<nextsent>bar-haim et al (2004) showed that morpheme-based tagging performs better than word-based tagging; they used hidden markov models (hmms) for developing the tagger.
</nextsent>
<nextsent>on the basis of the idea introduced by bar-haim et al (2004), we formulate the following two related tasks for the analysis of amharic words: segmentation and pos tagging (sequence labeling).
</nextsent>
<nextsent>segmentation refers to the analysis of word into constituting morphemes.
</nextsent>
<nextsent>the pos tagging task, on the other hand, deals with the assignment of pos tags to words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2800">
<title id=" W05-0707.xml">part of speech tagging for amharic using conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>, yt } is the label sequences, fk and are the feature functions and their corresponding weights respectively (lafferty et al, 2001).
</prevsent>
<prevsent>an important property of these models is that probabilities are computed based on set of feature functions, i.e. fk, (usually binary valued), which are defined on both the observation and label sequences . these feature functions describe different aspect of the data and may overlap, providing flexible way of describing the task.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
crfs have been shown to perform well in number of natural language processing applications, such as pos tagging (lafferty et al, 2001), shallow parsing or np chunking (sha and pereira, 2003), <papid> N03-1028 </papid>and named entity recognition (mccallum and li, 2003).<papid> W03-0430 </papid>in pos tagging, context information such assur rounding words and their morphological features,i.e., suffixes and prefixes, significantly improves per formance.</citsent>
<aftsection>
<nextsent>crfs allow us to integrate large set ofsuch features easily.
</nextsent>
<nextsent>therefore, it would be interesting to see to what extent the morphological features help in predicting amharic pos tags.
</nextsent>
<nextsent>we used the minor third implementation of crf (cohen, 2004).
</nextsent>
<nextsent>50
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2801">
<title id=" W05-0707.xml">part of speech tagging for amharic using conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>, yt } is the label sequences, fk and are the feature functions and their corresponding weights respectively (lafferty et al, 2001).
</prevsent>
<prevsent>an important property of these models is that probabilities are computed based on set of feature functions, i.e. fk, (usually binary valued), which are defined on both the observation and label sequences . these feature functions describe different aspect of the data and may overlap, providing flexible way of describing the task.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
crfs have been shown to perform well in number of natural language processing applications, such as pos tagging (lafferty et al, 2001), shallow parsing or np chunking (sha and pereira, 2003), <papid> N03-1028 </papid>and named entity recognition (mccallum and li, 2003).<papid> W03-0430 </papid>in pos tagging, context information such assur rounding words and their morphological features,i.e., suffixes and prefixes, significantly improves per formance.</citsent>
<aftsection>
<nextsent>crfs allow us to integrate large set ofsuch features easily.
</nextsent>
<nextsent>therefore, it would be interesting to see to what extent the morphological features help in predicting amharic pos tags.
</nextsent>
<nextsent>we used the minor third implementation of crf (cohen, 2004).
</nextsent>
<nextsent>50
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2802">
<title id=" W06-0308.xml">towards a validated model for affective classification of texts </title>
<section> experiment 2: classification using.  </section>
<citcontext>
<prevsection>
<prevsent>this strategy is interesting because it constrains all values to belong to the [-1,+1] range, but can be applied only to finite set of indicators and has yet to be tested for the classification of texts.
</prevsent>
<prevsent>(turneyand littman, 2003) use pointwise mutual information - information retrieval (pmi-ir); pmi-iroperates on wider variety of multi-words indicators, allowing for contextual information to be taken into account, has been tested extensively on different types of texts, and the scoring system can be potentially normalized between [-1,+1], as wewill soon see.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
pmi (church and hanks, 1990) <papid> J90-1003 </papid>between two phrases is defined as: log2 prob(ph1 is near ph2) prob(ph1) ? prob(ph2) pmi is positive when two phrases tend to co-occurand negative when they tend to be in complementary distribution.</citsent>
<aftsection>
<nextsent>pmi-ir refers to the fact 5http://wordnet.princeton.edu/.
</nextsent>
<nextsent>58that, as in inform tion retrieval (ir), multiple occurrences in the same document count as just one occurrence: according to (turney and littman, 2003), this seems to yield better measure of semantic similarity, providing some resistance to noise.
</nextsent>
<nextsent>computing probabilities using hit counts from ir, this yields to value for pmi-ir of: logn ?
</nextsent>
<nextsent>(hits(ph1 near ph2) + 1/n) (hits(ph1) + 1) ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2803">
<title id=" W06-0308.xml">towards a validated model for affective classification of texts </title>
<section> experiment 2: classification using.  </section>
<citcontext>
<prevsection>
<prevsent>smoothing values (1/n and 1) are chosen so that pmi-ir will be zero for words that are not in the corpus, two phrases are considered near if they co-occur within window of 20 words, and log2has been replaced by logn, since the natural log ismore common in the literature for log-odds ratio and this makes no difference for the algorithm.
</prevsent>
<prevsent>two crucial aspects of the method are the choice of indicators to be extracted from the text to be classified, as well as the sets of positive and negative words to be used as paradigms for the evaluation and activity dimensions.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
the five part-of speech (pos) patterns from (turney, 2002) <papid> P02-1053 </papid>were used for the extraction of indicators, all involving at least one adjective or adverb.</citsent>
<aftsection>
<nextsent>pos tags we reacquired with tree tagger (schmid, 1994)6.
</nextsent>
<nextsent>ideally, words used as paradigms should be context insensitive, i.e their semantic orientation is either always positive or negative.
</nextsent>
<nextsent>the adjectives good,nice, excellent, positive, fortunate, correct, superior and bad, nasty, poor, negative, unfortunate,wrong, inferior were used as near pure representations of positive and negative evaluation respectively, while fast, alive, noisy, young and slow,dead, quiet, old as near pure representations of active and passive activity (summers, 1970).
</nextsent>
<nextsent>departing from (turney and littman, 2003),who uses the alta vista advanced search with approximately 350 millions web pages, we used the waterloo corpus7, with approximately 46 millions pages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2804">
<title id=" W05-0825.xml">a generalized alignment free phrase extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with longer context than unigram, phrase translation models have flexibilities of modelling local word-reordering, and are less sensitive to the errors made from preprocessing steps including word segment ations and tokenization.
</prevsent>
<prevsent>however, most of the phrase extraction algorithms relyon good word alignments.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
a widely practiced approach explained in details in (koehn, 2004), (och and ney, 2003) <papid> J03-1002 </papid>and (tillmann, 2003) <papid> W03-1001 </papid>is to get word alignments from two directions: source to target and target to source; the intersection or union operation is applied to get refined word alignment with pre-designed heuristics fixing the unaligned words.</citsent>
<aftsection>
<nextsent>with this refined word alignment, the phrase extraction forgiven source phrase is essentially to extract the target candidate phrases in the target sentence by searching the left and right projected boundaries.in (vogel et al, 2004), they treat phrase alignment as sentence splitting problem: given source phrase, find the boundaries of the target phrase such that the overall sentence alignment lexicon probability is optimal.
</nextsent>
<nextsent>we generalize it in various ways, esp. by using fertility model to get better estimation of phrase lengths, and phrase level distortion model.in our proposed algorithm, we do not need explicit word alignment for phrase extraction.
</nextsent>
<nextsent>thereby it avoids the burden of testing and comparing different heuristics especially for some language specificones.
</nextsent>
<nextsent>on the other hand, the algorithm has such flexibilities that one can incorporate word alignment and heuristics in several possible stages within this proposed framework to further improve the quality of phrase pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2805">
<title id=" W05-0825.xml">a generalized alignment free phrase extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with longer context than unigram, phrase translation models have flexibilities of modelling local word-reordering, and are less sensitive to the errors made from preprocessing steps including word segment ations and tokenization.
</prevsent>
<prevsent>however, most of the phrase extraction algorithms relyon good word alignments.
</prevsent>
</prevsection>
<citsent citstr=" W03-1001 ">
a widely practiced approach explained in details in (koehn, 2004), (och and ney, 2003) <papid> J03-1002 </papid>and (tillmann, 2003) <papid> W03-1001 </papid>is to get word alignments from two directions: source to target and target to source; the intersection or union operation is applied to get refined word alignment with pre-designed heuristics fixing the unaligned words.</citsent>
<aftsection>
<nextsent>with this refined word alignment, the phrase extraction forgiven source phrase is essentially to extract the target candidate phrases in the target sentence by searching the left and right projected boundaries.in (vogel et al, 2004), they treat phrase alignment as sentence splitting problem: given source phrase, find the boundaries of the target phrase such that the overall sentence alignment lexicon probability is optimal.
</nextsent>
<nextsent>we generalize it in various ways, esp. by using fertility model to get better estimation of phrase lengths, and phrase level distortion model.in our proposed algorithm, we do not need explicit word alignment for phrase extraction.
</nextsent>
<nextsent>thereby it avoids the burden of testing and comparing different heuristics especially for some language specificones.
</nextsent>
<nextsent>on the other hand, the algorithm has such flexibilities that one can incorporate word alignment and heuristics in several possible stages within this proposed framework to further improve the quality of phrase pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2806">
<title id=" W05-0825.xml">a generalized alignment free phrase extraction </title>
<section> length model: dynamic programming.  </section>
<citcontext>
<prevsection>
<prevsent>translational equivalence.
</prevsent>
<prevsent>given source phrase, we can search for the best possible block with the highest combined scores from the three models.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
given the word fertility definitions in ibm models (brown et al, 1993), <papid> J93-2003 </papid>we can compute probability to predict phrase length: given the candidate target phrase (english) ei1, and source phrase(french) of length , the model gives the estimation of (j |ei1) via dynamic programming algorithm using the source word fertilities.</citsent>
<aftsection>
<nextsent>figure 2shows an example fertility trellis of an english trigram.
</nextsent>
<nextsent>each edge between two nodes represents one english word ei.
</nextsent>
<nextsent>the arc between two nodes represents one candidate non-zero fertility for ei.
</nextsent>
<nextsent>the fertility of zero (i.e. generating null word) corresponds to the direct edge between two nodes, andin this way, the null word is naturally incorporated into this models representation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2808">
<title id=" W04-3004.xml">virtual modality a framework for testing and building multimodal applications </title>
<section> data generation.  </section>
<citcontext>
<prevsection>
<prevsent>first, identification of the location references is not necessarily an easy task.
</prevsent>
<prevsent>it may require complex parsing or keyword-spotting algorithm, depending on the application in question.
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
in our case, the log files include the output of the tina natural language understanding module, meaning that all semantically relevant units present in an input sentence are marked explicitly in the output parse frame (seneff, 1992).<papid> J92-1004 </papid></citsent>
<aftsection>
<nextsent>figure 3 gives an example of the parse frame.
</nextsent>
<nextsent>{c directions :subject 1 :domain  voyager  :input_string   give me directions from harvard to mit   :utterance_id 6 :pred {p from :topic {q university :name  harvard university  } } :pred {p to :topic {q university :name  massachusetts institute of technology  } } } figure 3.
</nextsent>
<nextsent>parse frame for the input sentence give me directions from harvard to mit?.
</nextsent>
<nextsent>the movement and time marker placement step represents no problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2809">
<title id=" W05-0308.xml">annotating attributions and private states </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such as attribution and expectation.
</prevsent>
<prevsent>appraisal theory does not distinguish,as we do, the different ways that private states may be expressed (i.e., directly, or indirectly using expressive subjective elements).
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
it also does not include representation for nested levels of attribution.in addition to appraisal theory, subjectivity annotation of text in context has also been performed in yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>bruce and wiebe (1999), andwiebe et al (2004).<papid> J04-3002 </papid></citsent>
<aftsection>
<nextsent>the annotations in yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>are sentence-level subjective vs. objective and polarity judgments.</nextsent>
<nextsent>the annotation schemes used in bruce and wiebe (1999) and wiebe et al (2004) <papid> J04-3002 </papid>are earlier, much less detailed versions of the annotation scheme presented in this paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2810">
<title id=" W05-0308.xml">annotating attributions and private states </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such as attribution and expectation.
</prevsent>
<prevsent>appraisal theory does not distinguish,as we do, the different ways that private states may be expressed (i.e., directly, or indirectly using expressive subjective elements).
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
it also does not include representation for nested levels of attribution.in addition to appraisal theory, subjectivity annotation of text in context has also been performed in yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>bruce and wiebe (1999), andwiebe et al (2004).<papid> J04-3002 </papid></citsent>
<aftsection>
<nextsent>the annotations in yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>are sentence-level subjective vs. objective and polarity judgments.</nextsent>
<nextsent>the annotation schemes used in bruce and wiebe (1999) and wiebe et al (2004) <papid> J04-3002 </papid>are earlier, much less detailed versions of the annotation scheme presented in this paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2813">
<title id=" W06-0805.xml">exploring semantic constraints for document retrieval </title>
<section> experimental study.  </section>
<citcontext>
<prevsection>
<prevsent>of string constraints 1.4 0 5 no.
</prevsent>
<prevsent>of numerical constraints 1.8 0 4 table 1: summary of the distribution statistics of terms and constraints in the test topics 4.2 relevance judgments.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
instead of using human subjects to give relevance judgments for each document and query combination, we use human annotator to mark up all av pairs in each document, using the gate annotation tool (cunningham et al 2002).<papid> P02-1022 </papid></citsent>
<aftsection>
<nextsent>the attribute set contains the 40 most important attributes for digital cameras based on automatically computed term distributions in our dataset.
</nextsent>
<nextsent>the inter-annotator agreement (without annotator training) as measured by kappa is 0.72, which suggests satisfactory agreement.
</nextsent>
<nextsent>annotating av pairs in all documents gives us the capability of making relevance judgments automatically, based on the number of matches between the av pairs in document and the constraints in topic.
</nextsent>
<nextsent>this automatic approach is reasonable because unlike trec queries which are short and ambiguous, the queries in our application represent very specific information needs and are therefore much longer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2814">
<title id=" W06-0707.xml">duc 2005 evaluation of question focused summarization systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>summaries were manually judged for both content and readability.
</prevsent>
<prevsent>to evaluate content, each peer (human or automatic) summary was compared against single model (human) summary using see (http://www.isi.edu/ cyl/see/) to estimate the percentage of information in the model that was covered in the peer.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
additionally, automatic evaluation of content coverage using rouge (lin, 2004) <papid> W04-1013 </papid>was explored in 2004.</citsent>
<aftsection>
<nextsent>human summaries vary in both writing style and content.
</nextsent>
<nextsent>for example, (harman and over, 2004) <papid> W04-1003 </papid>noted that human summary can vary in its level of granularity, whether the summary has avery high-level analysis or primarily contains details.</nextsent>
<nextsent>they analyzed the effects of human vari aion in the duc evaluations and concluded that despite large variation in model summaries, the rankings of the systems when compared against asingle model for each document set remained stable when averaged over large number of document sets and human assessors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2815">
<title id=" W06-0707.xml">duc 2005 evaluation of question focused summarization systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>additionally, automatic evaluation of content coverage using rouge (lin, 2004) <papid> W04-1013 </papid>was explored in 2004.</prevsent>
<prevsent>human summaries vary in both writing style and content.</prevsent>
</prevsection>
<citsent citstr=" W04-1003 ">
for example, (harman and over, 2004) <papid> W04-1003 </papid>noted that human summary can vary in its level of granularity, whether the summary has avery high-level analysis or primarily contains details.</citsent>
<aftsection>
<nextsent>they analyzed the effects of human vari aion in the duc evaluations and concluded that despite large variation in model summaries, the rankings of the systems when compared against asingle model for each document set remained stable when averaged over large number of document sets and human assessors.
</nextsent>
<nextsent>the use of large test set to smooth over natural human variation is not new technique; it is the approach that has been taken in trec (text retrieval conference) for many years (voorhees and buckley, 2002).while evaluators can achieve stable overall system rankings by averaging scores over large number of document sets, system builders are still faced with the challenge of producing summary forgiven document set that is most likely to satisfy any human user (since they cannot know ahead of time which human will be using or judging the summary).
</nextsent>
<nextsent>thus, system developers desire an evaluation methodology that takes into account human variation in summaries for any given document set.duc 2005 marked major change in direction from previous years.
</nextsent>
<nextsent>the road mapping committee had strongly recommended that new tasks be undertaken that were strongly tied to clear user application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2816">
<title id=" W05-1204.xml">training data modification for smt considering groups of synonymous sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, needless to say, single sentence in the source language can be used to translate several sentences in the target language.
</prevsent>
<prevsent>such various possibilities for translation make mt system development and evaluation very difficult.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
consequently, here we employ multiple references to evaluate mt systems like bleu (papineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</citsent>
<aftsection>
<nextsent>moreover, such variations in translation have negative effect on training in smt because when several sentences of input-side language are translated into the exactly equivalent output-side sentences, the probability of correct translation decreases due to the large number of possible pairs of expressions.
</nextsent>
<nextsent>therefore, if we can restrain or modify the training corpus, the smt system might achieve high accuracy.
</nextsent>
<nextsent>as an example of modification, different output-side sentences paired with the exactly equivalent input-side sentences are replaced with one target sentence.
</nextsent>
<nextsent>these sentence replacements are required for synonymous sentence sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2817">
<title id=" W05-1204.xml">training data modification for smt considering groups of synonymous sentences </title>
<section> smt system and evaluation method.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we describe the smt systems used in these experiments.
</prevsent>
<prevsent>the smt systems?
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
decoder is graph-based decoder (ueffing et al, 2002; <papid> W02-1021 </papid>zhang et al, 2004).<papid> C04-1168 </papid></citsent>
<aftsection>
<nextsent>the first pass of the decoder generates word-graph, compact representation of alternative translation candidates, using beam search based on the scores of the lexicon and language models.
</nextsent>
<nextsent>in the second pass, an a* search traverses the graph.
</nextsent>
<nextsent>the edges of the word-graph, or the phrase translation candidates, are generated by the list of word translations obtained from the inverted lexicon model.
</nextsent>
<nextsent>the phrase translations extracted from the viterbi alignments of the training corpus also constitute the edges.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2818">
<title id=" W05-1204.xml">training data modification for smt considering groups of synonymous sentences </title>
<section> smt system and evaluation method.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we describe the smt systems used in these experiments.
</prevsent>
<prevsent>the smt systems?
</prevsent>
</prevsection>
<citsent citstr=" C04-1168 ">
decoder is graph-based decoder (ueffing et al, 2002; <papid> W02-1021 </papid>zhang et al, 2004).<papid> C04-1168 </papid></citsent>
<aftsection>
<nextsent>the first pass of the decoder generates word-graph, compact representation of alternative translation candidates, using beam search based on the scores of the lexicon and language models.
</nextsent>
<nextsent>in the second pass, an a* search traverses the graph.
</nextsent>
<nextsent>the edges of the word-graph, or the phrase translation candidates, are generated by the list of word translations obtained from the inverted lexicon model.
</nextsent>
<nextsent>the phrase translations extracted from the viterbi alignments of the training corpus also constitute the edges.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2819">
<title id=" W05-1204.xml">training data modification for smt considering groups of synonymous sentences </title>
<section> smt system and evaluation method.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, the edges are also created from dynamically extracted phrase translations from the bilingual sentences (watanabe and sumita, 2003).
</prevsent>
<prevsent>the decoder used the ibm model 4 with trigram language model and five-gram part-of-speech language model.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
training of the ibm model 4 was implemented by the giza++ package (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>all parameters in training and decoding were the same for all experiments.
</nextsent>
<nextsent>most systems with this training can be expected to achieve better accuracy when we run the parameter tuning processes.
</nextsent>
<nextsent>however, our purpose is to compare the difference in results caused by modifying the training corpus.
</nextsent>
<nextsent>we performed experiments for je/ej and jc/cj systems and four types of training corpora: 1) original btec corpus; 2) compressed btec corpus (see 3.2.1); 3) replace both languages (see 3.2.2); 4) replace one side language (see 3.2.3) 4-1) replacement on the input side 4-2) replacement on the output side.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2820">
<title id=" W05-1204.xml">training data modification for smt considering groups of synonymous sentences </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>from the english side, we have an incorrect word pair in the translation model.
</prevsent>
<prevsent>to handle such problem, we would have to arrange method to select the sen 23 tences from group.
</prevsent>
</prevsection>
<citsent citstr=" E03-1029 ">
this problem is discussed in imamura et al (2003).<papid> E03-1029 </papid></citsent>
<aftsection>
<nextsent>as one solution to this problem, we borrowed the measures of literal ness, context freedom, and word translation stability in the sentence-selection process.
</nextsent>
<nextsent>in some cases, the group includes sentences with different meanings, and this problem was mentioned in kashioka (2004).
</nextsent>
<nextsent>in an attempt to solve the problem, he performed secondary decomposition step to produce synonymous group.
</nextsent>
<nextsent>how ever, in the current training corpus, each synonymous group before the decomposition step is small, so there would not be enough difference for modifications after the decomposition step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2821">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this supposed equivalence isthen exploited to derive textual entailment prototype relations.
</prevsent>
<prevsent>for example, the specific fact yahoo bought overture is characterised by the two anchors 37 {yahoo, overture}, that are used to retrieve in the corpus text fragments where they co-occur, e.g. ya hoo purchased overture (july 2003).?, now that overture is completely owned by yahoo!...?.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
these retrieved text fragments are then considered good candidate for paraphrasing bought y. anchor-based learning methods have been used to investigate many semantic relations ranging from very general ones as the isa relation in (morin, 1999) to very specific ones as in (ravichandran and hovy, 2002) <papid> P02-1006 </papid>where paraphrases of question-answer pairs are searched in the web or as in (szpektor et al, 2004) <papid> W04-3206 </papid>where method to scan the web for searching textual entailment prototype relations is presented.these methods are mainly devoted to induce entailment pairs related to the first kind of textual entailment, that is, paraphrasing as their target is mainly to look for the same fact?</citsent>
<aftsection>
<nextsent>in different textual forms.
</nextsent>
<nextsent>incidentally, these methods can come across strict entailment relations whenever specific anchors are used for both fact ft and strictly entailed fact fh.in this work we will investigate specific methods to induce the second kind of textual entailment relations, that is, strict entailment.
</nextsent>
<nextsent>we will focus on entailment between verbs, due to the fact that verbs generally govern the meaning of sentences.the problem we are facing is to look for (or ver ify) entailment relations like vt ? vh (where vt isthe text verb and vh the hypothesis verb).
</nextsent>
<nextsent>our approach is based on an intuition: strict entailment relations among verbs are often clearly expressed in texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2822">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this supposed equivalence isthen exploited to derive textual entailment prototype relations.
</prevsent>
<prevsent>for example, the specific fact yahoo bought overture is characterised by the two anchors 37 {yahoo, overture}, that are used to retrieve in the corpus text fragments where they co-occur, e.g. ya hoo purchased overture (july 2003).?, now that overture is completely owned by yahoo!...?.
</prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
these retrieved text fragments are then considered good candidate for paraphrasing bought y. anchor-based learning methods have been used to investigate many semantic relations ranging from very general ones as the isa relation in (morin, 1999) to very specific ones as in (ravichandran and hovy, 2002) <papid> P02-1006 </papid>where paraphrases of question-answer pairs are searched in the web or as in (szpektor et al, 2004) <papid> W04-3206 </papid>where method to scan the web for searching textual entailment prototype relations is presented.these methods are mainly devoted to induce entailment pairs related to the first kind of textual entailment, that is, paraphrasing as their target is mainly to look for the same fact?</citsent>
<aftsection>
<nextsent>in different textual forms.
</nextsent>
<nextsent>incidentally, these methods can come across strict entailment relations whenever specific anchors are used for both fact ft and strictly entailed fact fh.in this work we will investigate specific methods to induce the second kind of textual entailment relations, that is, strict entailment.
</nextsent>
<nextsent>we will focus on entailment between verbs, due to the fact that verbs generally govern the meaning of sentences.the problem we are facing is to look for (or ver ify) entailment relations like vt ? vh (where vt isthe text verb and vh the hypothesis verb).
</nextsent>
<nextsent>our approach is based on an intuition: strict entailment relations among verbs are often clearly expressed in texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2823">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> the method.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in the player wins?, the action play evocated by the agentive noun player is entailed by win.
</prevsent>
<prevsent>2.2 textual entailment patterns.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
as observed for the isa relations in (hearst, 1992) <papid> C92-2082 </papid>local and simple inter-sentential patterns may carry relevant semantic relations.</citsent>
<aftsection>
<nextsent>as we saw in the previous section, this also happens for entailment relations.
</nextsent>
<nextsent>our aim is thus to search for an initial set of textual patterns that describe possible linguistic forms expressing entailment relations between two verbs (vt, vh).
</nextsent>
<nextsent>by using these patterns, actual pointwise assertions of entailment can be detected or verified in texts.
</nextsent>
<nextsent>we call these prototypical patterns textual entailment patterns.the idea described in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2824">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> the method.  </section>
<citcontext>
<prevsection>
<prevsent>given the possibility of estimating the probabilities through maximum-likelihood principle, the definition is straightforward: smi(vt, vh) = log10 p(ppers(vt, vh)) p(fpers(vt))p(f(vh))where p(x) = fc(x)/fc(.).
</prevsent>
<prevsent>the aim of this measure is to indicate the relatedness between two elements composing pair.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
mutual information hasbeen positively used in many nlp tasks such as collocation analysis (church and hanks, 1989), <papid> P89-1010 </papid>terminology extraction (damerau, 1993), and word sense disambiguation (brown et al, 1991).<papid> P91-1034 </papid></citsent>
<aftsection>
<nextsent>as many other corpus linguistic approaches, our entailment detection model relies partially on some linguistic prior knowledge (the expected structure of the searched collocations, i.e., the textual entailmentpatterns) and partially on some probability distribution estimation.
</nextsent>
<nextsent>only positive combination of both these two ingredients can give good results when applying (and evaluating) the model.
</nextsent>
<nextsent>the aim of the experimental evaluation is then to understand, on the one side, if the proposed textual entailment patterns are useful to detect entailment between verbs and, on the other, if statistical measure is preferable with respect to the other.
</nextsent>
<nextsent>we will here evaluate the capability of our method to recognise entailment between given pairs of verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2825">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> the method.  </section>
<citcontext>
<prevsection>
<prevsent>given the possibility of estimating the probabilities through maximum-likelihood principle, the definition is straightforward: smi(vt, vh) = log10 p(ppers(vt, vh)) p(fpers(vt))p(f(vh))where p(x) = fc(x)/fc(.).
</prevsent>
<prevsent>the aim of this measure is to indicate the relatedness between two elements composing pair.
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
mutual information hasbeen positively used in many nlp tasks such as collocation analysis (church and hanks, 1989), <papid> P89-1010 </papid>terminology extraction (damerau, 1993), and word sense disambiguation (brown et al, 1991).<papid> P91-1034 </papid></citsent>
<aftsection>
<nextsent>as many other corpus linguistic approaches, our entailment detection model relies partially on some linguistic prior knowledge (the expected structure of the searched collocations, i.e., the textual entailmentpatterns) and partially on some probability distribution estimation.
</nextsent>
<nextsent>only positive combination of both these two ingredients can give good results when applying (and evaluating) the model.
</nextsent>
<nextsent>the aim of the experimental evaluation is then to understand, on the one side, if the proposed textual entailment patterns are useful to detect entailment between verbs and, on the other, if statistical measure is preferable with respect to the other.
</nextsent>
<nextsent>we will here evaluate the capability of our method to recognise entailment between given pairs of verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2826">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we will here evaluate the capability of our method to recognise entailment between given pairs of verbs.
</prevsent>
<prevsent>we carried out the experiments using the web asthe corpus where to estimate our two textual entailment measures (sf and smi) and googletm as count estimator.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
the findings described in (kellerand lapata, 2003) <papid> J03-3005 </papid>seem to suggest that count estimations we need in the present study over subject-verb bigrams are highly correlated to corpus counts.as test bed we used existing resources: non trivial set of controlled verb entailment pairs is in fact contained in wordnet (miller, 1995).</citsent>
<aftsection>
<nextsent>there, the entailment relation is semantic relation defined at the synset level, standing in the verb subhierarchy.
</nextsent>
<nextsent>each 40 figure 1: roc curves pair of synsets (st, sh) is an oriented entailment relation between stand sh.
</nextsent>
<nextsent>wordnet contains 415entailed synsets.
</nextsent>
<nextsent>these entailment relations are consequently stated also at the lexical level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2827">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>we have defined method to recognise and extract entailment relations between verb pairs based on what we call textual entailment pattern.
</prevsent>
<prevsent>in this workwe defined first kernel of textual entailment patterns based on subject-verb relations.
</prevsent>
</prevsection>
<citsent citstr=" N04-1020 ">
potentials of the method are still high as different kinds of textual 41 entailment patterns may be defined or discovered investigating relations between sentences and sub sentences as done in (lapata and lascarides, 2004) <papid> N04-1020 </papid>for temporal relations or between near sentences as done in (basili et al, 2003) for cause-effect relations between domain events.</citsent>
<aftsection>
<nextsent>some interesting and simple inter-sentential patters are defined in (chklovskiand pantel, 2004).<papid> W04-3205 </papid></nextsent>
<nextsent>moreover, with respect to anchor based approaches, the method we presented here offers different point of view on the problem of acquiring textual entailment relation prototypes, as textual entailment patterns do not depend on the repetition of similar?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2828">
<title id=" W05-1207.xml">discovering entailment relations using textual entailment patterns </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>in this workwe defined first kernel of textual entailment patterns based on subject-verb relations.
</prevsent>
<prevsent>potentials of the method are still high as different kinds of textual 41 entailment patterns may be defined or discovered investigating relations between sentences and sub sentences as done in (lapata and lascarides, 2004) <papid> N04-1020 </papid>for temporal relations or between near sentences as done in (basili et al, 2003) for cause-effect relations between domain events.</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
some interesting and simple inter-sentential patters are defined in (chklovskiand pantel, 2004).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>moreover, with respect to anchor based approaches, the method we presented here offers different point of view on the problem of acquiring textual entailment relation prototypes, as textual entailment patterns do not depend on the repetition of similar?
</nextsent>
<nextsent>facts.
</nextsent>
<nextsent>this practically independent view may open the possibility to experiment co-training algorithms (blum and mitchell, 1998) also in this area.
</nextsent>
<nextsent>finally, the approach proposed can be useful to define better probability estimations in probabilistic entailment detection methods such as the one described in (glickman et al, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2829">
<title id=" W06-0907.xml">marking time in developmental biology annotating developmental events and their links with molecular events </title>
<section> annotation.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 event time-stamping.
</prevsent>
<prevsent>the relative timing of any biological processes mentioned in the event descriptions first needs to be determined before we can work out when the actual events described are taking place.
</prevsent>
</prevsection>
<citsent citstr=" W01-1309 ">
schilder and habel (2001) <papid> W01-1309 </papid>looked beyond the core temporal expressions and into prepositional phrases that contained temporal relations, i.e. before, during, etc and introduced the notion of noun phrases as event-denoting expressions.</citsent>
<aftsection>
<nextsent>an event that is described as occurring after the election?
</nextsent>
<nextsent>does not have an explicit time-stamp attached to it, but the knowledge about the timing of the election mentioned gives the reader notion of when in absolute time the event occurred.
</nextsent>
<nextsent>this is similar to example 2 above where event-0 is the reference event, thus biological processes can be considered event-denoting expressions.
</nextsent>
<nextsent>while schilder and habel relyon prepositional phrases to designate their event-denoting noun phrases, for this work propositional phrases are not necessarily required.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2830">
<title id=" W06-0907.xml">marking time in developmental biology annotating developmental events and their links with molecular events </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>there is no point extracting events descriptions if we cannot relate the events and their elements toeach other.
</prevsent>
<prevsent>the event-denoting expressions identified need to be normalised so that it can be recognised when two terms are referring to the same element.
</prevsent>
</prevsection>
<citsent citstr=" W02-0307 ">
inconsistent terminology in the biomedical field is known problem (sinclair et al, 2002).<papid> W02-0307 </papid></citsent>
<aftsection>
<nextsent>one gene can have several names (synonymy) just as the same name can be used for more than one gene(homonymy).
</nextsent>
<nextsent>very often the synonyms bear no relation to one another since they were perhaps concurrently discovered in different laboratories and named.
</nextsent>
<nextsent>for example, the gene insomnia can also be known as cheap date, since experiments found that organisms without this gene have tendency to fall asleep and are particularly susceptible to alcohol.
</nextsent>
<nextsent>the same anatomical part can also be referred to by different terms, e.g. the wolff ian duct is also known as the nephric duct, and the metanephros is another name for the kidney.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2831">
<title id=" W06-1313.xml">an information state based dialogue manager for call for fire dialogues </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>training dialogues.
</prevsent>
<prevsent>we describe the training environment, the domain, the features of its novel information state based dialogue manager, the system it is part of, and preliminary evaluation results.
</prevsent>
</prevsection>
<citsent citstr=" P96-1009 ">
dialogue systems are built for many different purposes, including information gathering (e.g., (aust et al, 1995)), performing simple transactions (e.g,(walker and hirschman, 2000)), collaborative interaction (e.g., (allen et al, 1996)), <papid> P96-1009 </papid>tutoring (e.g., (rose et al, 2003)), and training (e.g.</citsent>
<aftsection>
<nextsent>(traum and rickel, 2002)).
</nextsent>
<nextsent>aspects of the purpose, as well as features of the domain itself (e.g., train timetables, air flight bookings, schedule maintenance, physics, and platoon-level military opera tions) will have profound effect on the nature of the dialogue which system will need to engagein.
</nextsent>
<nextsent>issues such as initiative, error correction, flexibility in phrasing and dialogue structure may depend crucially on these factors.
</nextsent>
<nextsent>the information state approach to dialogue managers (larsson and traum, 2000) has been an attempt to cast some of these differences within the same framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2832">
<title id=" W06-1313.xml">an information state based dialogue manager for call for fire dialogues </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>the information state approach to dialogue managers (larsson and traum, 2000) has been an attempt to cast some of these differences within the same framework.
</prevsent>
<prevsent>in this approach, theory of dialogue is constructed by providing information structure elements, set of dialogue moves that can be recognized and produced and are used to modify the nature of these elements, set of update rules that govern the dynamics of how the information is changed as dialogue moves are performed, and an update strategy.
</prevsent>
</prevsection>
<citsent citstr=" A00-2001 ">
many different dialogue systems have been built according to this general approach (e.g., (cooper and larsson, 1999; matheson et al, 2000; <papid> A00-2001 </papid>lemon et al, 2001; johnston et al, 2002; <papid> P02-1048 </papid>traum and rickel, 2002; purver, 2002)).<papid> W02-0222 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present an information-statebased dialogue manager for new domain: training call for fire dialogues.
</nextsent>
<nextsent>like other dialogue systems used as role-players in training applications, the structure of the dialogue is not completely free for dialogue designer to specify based on issues of dialogue efficiency.
</nextsent>
<nextsent>the dialogue system must conform as much as possible to the type of dialogue that trainee would actually encounter in the types of interaction he or she is being trained for.
</nextsent>
<nextsent>in particular, for military radio dialogues, muchof the protocol for interaction is specified by convention (e.g., (army, 2001)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2833">
<title id=" W06-1313.xml">an information state based dialogue manager for call for fire dialogues </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>the information state approach to dialogue managers (larsson and traum, 2000) has been an attempt to cast some of these differences within the same framework.
</prevsent>
<prevsent>in this approach, theory of dialogue is constructed by providing information structure elements, set of dialogue moves that can be recognized and produced and are used to modify the nature of these elements, set of update rules that govern the dynamics of how the information is changed as dialogue moves are performed, and an update strategy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1048 ">
many different dialogue systems have been built according to this general approach (e.g., (cooper and larsson, 1999; matheson et al, 2000; <papid> A00-2001 </papid>lemon et al, 2001; johnston et al, 2002; <papid> P02-1048 </papid>traum and rickel, 2002; purver, 2002)).<papid> W02-0222 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present an information-statebased dialogue manager for new domain: training call for fire dialogues.
</nextsent>
<nextsent>like other dialogue systems used as role-players in training applications, the structure of the dialogue is not completely free for dialogue designer to specify based on issues of dialogue efficiency.
</nextsent>
<nextsent>the dialogue system must conform as much as possible to the type of dialogue that trainee would actually encounter in the types of interaction he or she is being trained for.
</nextsent>
<nextsent>in particular, for military radio dialogues, muchof the protocol for interaction is specified by convention (e.g., (army, 2001)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2834">
<title id=" W06-1313.xml">an information state based dialogue manager for call for fire dialogues </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>the information state approach to dialogue managers (larsson and traum, 2000) has been an attempt to cast some of these differences within the same framework.
</prevsent>
<prevsent>in this approach, theory of dialogue is constructed by providing information structure elements, set of dialogue moves that can be recognized and produced and are used to modify the nature of these elements, set of update rules that govern the dynamics of how the information is changed as dialogue moves are performed, and an update strategy.
</prevsent>
</prevsection>
<citsent citstr=" W02-0222 ">
many different dialogue systems have been built according to this general approach (e.g., (cooper and larsson, 1999; matheson et al, 2000; <papid> A00-2001 </papid>lemon et al, 2001; johnston et al, 2002; <papid> P02-1048 </papid>traum and rickel, 2002; purver, 2002)).<papid> W02-0222 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present an information-statebased dialogue manager for new domain: training call for fire dialogues.
</nextsent>
<nextsent>like other dialogue systems used as role-players in training applications, the structure of the dialogue is not completely free for dialogue designer to specify based on issues of dialogue efficiency.
</nextsent>
<nextsent>the dialogue system must conform as much as possible to the type of dialogue that trainee would actually encounter in the types of interaction he or she is being trained for.
</nextsent>
<nextsent>in particular, for military radio dialogues, muchof the protocol for interaction is specified by convention (e.g., (army, 2001)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2835">
<title id=" W06-1313.xml">an information state based dialogue manager for call for fire dialogues </title>
<section> testbed.  </section>
<citcontext>
<prevsection>
<prevsent>radiobot-cff is composed of several pipe lined components.
</prevsent>
<prevsent>a speech recognition component is implemented using the sonic speech recognition system (pellom, 2001) with custom language and acoustic models.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
an interpreter component tags the asr output with its its dialogue moveand parameter labels using two separate conditional random field (sha and pereira, 2003; <papid> N03-1028 </papid>mccallum, 2002) taggers trained on hand-annotated utterances.</citsent>
<aftsection>
<nextsent>a dialogue manager processes the tagged output, sending reply to the fo (via template-based generator) and, when necessary, message to the artillery simulator firesim xxi1 to make decisions on what type of fire to send.
</nextsent>
<nextsent>the reply to fo and messages to simulator are mediated by guis where the trainer can intervene if 1http://sill-www.army.mil/blab/sims/firesimxxi.htm need be.
</nextsent>
<nextsent>call for fire procedures are specified in an army field manual (army, 2001) with variations basedon units standard operating procedure.
</nextsent>
<nextsent>messages are brief and followed by confirmations, where any misunderstandings are immediately corrected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2836">
<title id=" W06-1315.xml">empirical verification of adjacency pairs using dialogue segmentation </title>
<section> dialogue segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>dialogues taken as whole are very different from each other, so segmentation is necessary to derive meaningful information about their parts.
</prevsent>
<prevsent>the question is, then, how best to segment dialogues so as to reveal dialogue information or to facilitate some language task, such as da classification?
</prevsent>
</prevsection>
<citsent citstr=" P03-2009 ">
various schemes for dialogue segmentation have been tried, including segmentation based on fulfilment of expectation (ludwig et al 1998), and segmenting by propositionality (midgley 2003).<papid> P03-2009 </papid></citsent>
<aftsection>
<nextsent>one answer to the question of how to segment dialogue came from the pioneering work of sacks and schegloff (1973) article.
</nextsent>
<nextsent>a basic rule of adjacency pair operation is: given the recognizable production of first pair part, on its first possible completion its speaker should stop and next speaker should start and produce second pair part from the same pair type of which the first is recognizably member.
</nextsent>
<nextsent>(p. 296, italics mine.)
</nextsent>
<nextsent>thus, if speaker stops speaking, it is likely that such handover has just taken place.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2837">
<title id=" W05-1526.xml">online statistics for a unification based dialogue parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unification parsers have problems with efficiency and selecting the best parse.
</prevsent>
<prevsent>lexically-conditioned statistics as used by collins (1999) may provide solution.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
they have been used in three ways: as post process for parse selection (toutanova et al, 2005; riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002), <papid> P02-1035 </papid>apreprocess to find more probable bracketing structures (swift et al, 2004), <papid> C04-1055 </papid>and online to rank each constituent produced, as in tsuruoka et al (2004) and this experiment.the trips parser (allen et al, 1996) <papid> P96-1009 </papid>is unification parser using an hpsg-inspired grammar and hand-tuned weights for each rule.</citsent>
<aftsection>
<nextsent>in our augmented system (aug-trips), we replaced these weights with lexically-conditioned model based on the adaptation of collins used by bikel (2002), allowing more efficiency and (in some cases) better selection.
</nextsent>
<nextsent>aug-trips retains the same grammar and lexicon as trips, but uses its statistical model to determine the order in which unifications are attempted.
</nextsent>
<nextsent>we tested bracketing accuracy on the monroe corpus (stent, 2001), which contains collaborative emergency-management dialogues.
</nextsent>
<nextsent>aug-trips is comparable to trips inaccuracy, but produces fewer constituents (table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2838">
<title id=" W05-1526.xml">online statistics for a unification based dialogue parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unification parsers have problems with efficiency and selecting the best parse.
</prevsent>
<prevsent>lexically-conditioned statistics as used by collins (1999) may provide solution.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
they have been used in three ways: as post process for parse selection (toutanova et al, 2005; riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002), <papid> P02-1035 </papid>apreprocess to find more probable bracketing structures (swift et al, 2004), <papid> C04-1055 </papid>and online to rank each constituent produced, as in tsuruoka et al (2004) and this experiment.the trips parser (allen et al, 1996) <papid> P96-1009 </papid>is unification parser using an hpsg-inspired grammar and hand-tuned weights for each rule.</citsent>
<aftsection>
<nextsent>in our augmented system (aug-trips), we replaced these weights with lexically-conditioned model based on the adaptation of collins used by bikel (2002), allowing more efficiency and (in some cases) better selection.
</nextsent>
<nextsent>aug-trips retains the same grammar and lexicon as trips, but uses its statistical model to determine the order in which unifications are attempted.
</nextsent>
<nextsent>we tested bracketing accuracy on the monroe corpus (stent, 2001), which contains collaborative emergency-management dialogues.
</nextsent>
<nextsent>aug-trips is comparable to trips inaccuracy, but produces fewer constituents (table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2839">
<title id=" W05-1526.xml">online statistics for a unification based dialogue parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unification parsers have problems with efficiency and selecting the best parse.
</prevsent>
<prevsent>lexically-conditioned statistics as used by collins (1999) may provide solution.
</prevsent>
</prevsection>
<citsent citstr=" C04-1055 ">
they have been used in three ways: as post process for parse selection (toutanova et al, 2005; riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002), <papid> P02-1035 </papid>apreprocess to find more probable bracketing structures (swift et al, 2004), <papid> C04-1055 </papid>and online to rank each constituent produced, as in tsuruoka et al (2004) and this experiment.the trips parser (allen et al, 1996) <papid> P96-1009 </papid>is unification parser using an hpsg-inspired grammar and hand-tuned weights for each rule.</citsent>
<aftsection>
<nextsent>in our augmented system (aug-trips), we replaced these weights with lexically-conditioned model based on the adaptation of collins used by bikel (2002), allowing more efficiency and (in some cases) better selection.
</nextsent>
<nextsent>aug-trips retains the same grammar and lexicon as trips, but uses its statistical model to determine the order in which unifications are attempted.
</nextsent>
<nextsent>we tested bracketing accuracy on the monroe corpus (stent, 2001), which contains collaborative emergency-management dialogues.
</nextsent>
<nextsent>aug-trips is comparable to trips inaccuracy, but produces fewer constituents (table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2840">
<title id=" W05-1526.xml">online statistics for a unification based dialogue parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unification parsers have problems with efficiency and selecting the best parse.
</prevsent>
<prevsent>lexically-conditioned statistics as used by collins (1999) may provide solution.
</prevsent>
</prevsection>
<citsent citstr=" P96-1009 ">
they have been used in three ways: as post process for parse selection (toutanova et al, 2005; riezler et al, 2000; <papid> P00-1061 </papid>riezler et al, 2002), <papid> P02-1035 </papid>apreprocess to find more probable bracketing structures (swift et al, 2004), <papid> C04-1055 </papid>and online to rank each constituent produced, as in tsuruoka et al (2004) and this experiment.the trips parser (allen et al, 1996) <papid> P96-1009 </papid>is unification parser using an hpsg-inspired grammar and hand-tuned weights for each rule.</citsent>
<aftsection>
<nextsent>in our augmented system (aug-trips), we replaced these weights with lexically-conditioned model based on the adaptation of collins used by bikel (2002), allowing more efficiency and (in some cases) better selection.
</nextsent>
<nextsent>aug-trips retains the same grammar and lexicon as trips, but uses its statistical model to determine the order in which unifications are attempted.
</nextsent>
<nextsent>we tested bracketing accuracy on the monroe corpus (stent, 2001), which contains collaborative emergency-management dialogues.
</nextsent>
<nextsent>aug-trips is comparable to trips inaccuracy, but produces fewer constituents (table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2841">
<title id=" W05-1526.xml">online statistics for a unification based dialogue parser </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>reduction - 36.96 0.00table 1: bracketing accuracy for 100 random sentences ? 2 words.
</prevsent>
<prevsent>  7 aug-trips   7 trips recall 73.25 71.00 precision 74.78 73.44 complete match 22.50 37.50 table 2: bracketing accuracy for the 40 sentences   7 words.
</prevsent>
</prevsection>
<citsent citstr=" W04-0214 ">
since our motivation for unification parsing is to reveal semantics as well as syntax, we next evaluated aug-tripss production of correct interpretations at the sentence level, which require complete correctness not only of the bracketing structure but of the sense chosen for each word and the thematic 198 roles of each argument (tetreault et al, 2004).<papid> W04-0214 </papid></citsent>
<aftsection>
<nextsent>for this task, we modified the probability model to condition on the senses in our lexicon rather thanwords.
</nextsent>
<nextsent>for instance, the words two thousand dollars?
</nextsent>
<nextsent>are replaced with the senses number number unit money-unit?.
</nextsent>
<nextsent>this allows us to model lexical disambiguation explicitly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2842">
<title id=" W05-1526.xml">online statistics for a unification based dialogue parser </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this allows us to model lexical disambiguation explicitly.
</prevsent>
<prevsent>the model generates one or more senses from each word with probability (sense|word, tag), and then uses sense statistics rather than word statistics in all other calculations.
</prevsent>
</prevsection>
<citsent citstr=" W00-1320 ">
similar but more complex models were used in thepcfg-sem model of toutanova et al (2005) and using wordnet senses in bikel (2000).<papid> W00-1320 </papid></citsent>
<aftsection>
<nextsent>we used the projector dialogues (835 sentences), which concern purchasing video projectors.
</nextsent>
<nextsent>in this domain, aug-trips makes about 10% more interpretation errors than trips (table 3), but when parsing sentences on which trips itself makes errors, it can correct about 10% (table 4).
</nextsent>
<nextsent>(training=310) trips aug-trips correct 26 21 incorrect 49 54 % reduction in constituents 0% 45%table 3: sentence-level accuracy on 75 random sentences.
</nextsent>
<nextsent>(training=396) trips aug-trips correct 0 8 incorrect 54 46 % reduction in constituents 0% 46% table 4: sentence-level accuracy on 54 trips error sentences our parser makes substantially fewer constituents than baseline trips at only slightly lower accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2843">
<title id=" W05-1602.xml">interactive authoring of logical forms for multilingual generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data to be rendered in textcan be obtained in cost-effective manner, and when the out put?
</prevsent>
<prevsent>requires such variability (multiple styles or languages, or customization to specific users or classes) that producing documents manually becomes prohibitively expensive.the input data can be either derived from an existing application database or it can be authored specifically to producedocuments.
</prevsent>
</prevsection>
<citsent citstr=" W98-1435 ">
applications where the data is available in database include report generators (e.g., ana [kukich, 1983], plandoc [shaw et al, 1994], multimeteo [coch, 1998], <papid> W98-1435 </papid>fog[goldberg et al, 1994]).</citsent>
<aftsection>
<nextsent>in other cases, researchers identified application domains where some of the data is available, but not insufficient detail to produce full documents.
</nextsent>
<nextsent>the wysiwym?
</nextsent>
<nextsent>approach was proposed ([power and scott, 1998],<papid> P98-2173 </papid> [paris and vander linden, 1996]) as system design methodology where users author and manipulate an underlying logical form through user interface that provides feed back in natural language text.</nextsent>
<nextsent>the effort invested in authoring logical forms ? either from scratch or from partial application ontology ? is justified when the logical form can be reused.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2844">
<title id=" W05-1602.xml">interactive authoring of logical forms for multilingual generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other cases, researchers identified application domains where some of the data is available, but not insufficient detail to produce full documents.
</prevsent>
<prevsent>the wysiwym?
</prevsent>
</prevsection>
<citsent citstr=" P98-2173 ">
approach was proposed ([power and scott, 1998],<papid> P98-2173 </papid> [paris and vander linden, 1996]) as system design methodology where users author and manipulate an underlying logical form through user interface that provides feed back in natural language text.</citsent>
<aftsection>
<nextsent>the effort invested in authoring logical forms ? either from scratch or from partial application ontology ? is justified when the logical form can be reused.
</nextsent>
<nextsent>this is the case when documents must be generated in several languages.
</nextsent>
<nextsent>the field of multilingual generation (mlg) has addressed this need ([bateman, 1997], [stede, 1996]).
</nextsent>
<nextsent>when documents must be produced in several versions, adapted to various contexts or users, the flexibility resulting from generation from logical forms is also valuable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2845">
<title id=" W05-1602.xml">interactive authoring of logical forms for multilingual generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the mixing of practical ontology editing perspective with nlg techniques yielded the following benefits:?
</prevsent>
<prevsent>generation tasks such as aggregation and reference planning are easily expressed as operations upon cgs.
</prevsent>
</prevsection>
<citsent citstr=" C92-1038 ">
the construction and maintenance of context according to models of text planning [reiter and dale, 1992], <papid> C92-1038 </papid>allow the author to break complex cg into manageable collection of small utterances.</citsent>
<aftsection>
<nextsent>each utterance links to global context in natural manner.
</nextsent>
<nextsent>we designed compact form to edit textual encoding of cgs taking into account defaults, knowledge of types of concepts, sets and individual instances and context.this format syntactically looks like simple object oriented programming language with objects, methods and attributes.
</nextsent>
<nextsent>we use an editing environment similar toa modern programming language development environment ? with browser of types and instances, intelligent typing completion based on type analysis, and context specific tooltip assistance.
</nextsent>
<nextsent>the simultaneous generation of text in two languages(hebrew and english) is important to distinguish between un-analyzed terms in the ontology and their linguistic counterpart.we evaluate the overall effectiveness of the authoring environment in the specific domain of cooking recipes (inspired by [dale, 1990]).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2847">
<title id=" W05-1602.xml">interactive authoring of logical forms for multilingual generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in an mlg system, users enter datain an interlingua, from which the target languages are gener ated.mlg systems aim to be as domain independent as possible (since development is expensive) but usually refer to narrow domain, since the design of the interlingua refers to domain information.
</prevsent>
<prevsent>mlg systems share common architecture consisting of the following modules:?
</prevsent>
</prevsection>
<citsent citstr=" W94-0308 ">
a language-independent underlying knowledge repre sentation: knowledge represented as ai plans [rosnerand stede, 1994] [delin et al, 1994], [<papid> W94-0308 </papid>paris and vander linden, 1996], knowledge bases (or ontologies) such as loom, the penman upper-model and other (domain-specific) concepts and instances [rosner and stede, 1994].?</citsent>
<aftsection>
<nextsent>micro-structure planning (rhetorical structure) - language independent - this is usually done by the human writers using the mlg application gui.
</nextsent>
<nextsent>sentence planning - different languages can express thesame content in various rhetorical structures, and planning must take it into consideration: either by avoiding the tailoring of structure to specific language [rosner and stede, 1994] or by taking advantage of knowledge on different realizations of rhetorical structures in different languages at the underlying representation [delin et al., 1994].?<papid> W94-0308 </papid></nextsent>
<nextsent>lexical and syntactic realization resources (e.g., english penman/german nigel in [rosner and stede, 1994])as an mlg system, our system also includes similar modules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2849">
<title id=" W05-1602.xml">interactive authoring of logical forms for multilingual generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>lexical and syntactic realization resources (e.g., english penman/german nigel in [rosner and stede, 1994])as an mlg system, our system also includes similar modules.
</prevsent>
<prevsent>we have chosen to use conceptual graphs as an interlingua for encoding document data [sowa, 1987].
</prevsent>
</prevsection>
<citsent citstr=" W00-1428 ">
we use existing generation resources for english ? surge [elhadad,1992] for syntactic realization and the lexical chooser described in [jing et al, 2000] <papid> W00-1428 </papid>and the hugg grammar for syntactic realization in hebrew [netzer, 1997].</citsent>
<aftsection>
<nextsent>for micro planning, we have implemented the algorithm for reference planning described in [reiter and dale, 1992] <papid> C92-1038 </papid>and the aggregation algorithm described in [shaw, 1995].<papid> P95-1053 </papid></nextsent>
<nextsent>the nlg components relyon the c-fuf implementation of the fuf language [kharitonov, 1999] [elhadad, 1991] ? which is fast enough to be used interactively in real time for every single editing modification of the semantic input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2851">
<title id=" W05-1602.xml">interactive authoring of logical forms for multilingual generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we have chosen to use conceptual graphs as an interlingua for encoding document data [sowa, 1987].
</prevsent>
<prevsent>we use existing generation resources for english ? surge [elhadad,1992] for syntactic realization and the lexical chooser described in [jing et al, 2000] <papid> W00-1428 </papid>and the hugg grammar for syntactic realization in hebrew [netzer, 1997].</prevsent>
</prevsection>
<citsent citstr=" P95-1053 ">
for micro planning, we have implemented the algorithm for reference planning described in [reiter and dale, 1992] <papid> C92-1038 </papid>and the aggregation algorithm described in [shaw, 1995].<papid> P95-1053 </papid></citsent>
<aftsection>
<nextsent>the nlg components relyon the c-fuf implementation of the fuf language [kharitonov, 1999] [elhadad, 1991] ? which is fast enough to be used interactively in real time for every single editing modification of the semantic input.
</nextsent>
<nextsent>2.2 wysiwym.
</nextsent>
<nextsent>in an influential series of papers [power and scott, 1998],<papid> P98-2173 </papid>wysiwym (what you see is what you mean) was proposed as method for the authoring of semantic information through direct manipulation of structures rendered in natural language text.</nextsent>
<nextsent>a wysiwym editor enables the user to edit information at the semantic level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2857">
<title id=" W06-1306.xml">multidimensional dialogue management </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>depending on the situation, the agent that is most appropriate forgiven task is selected in process involving several so-called evaluators?.
</prevsent>
<prevsent>injaspis the multi-agent approach is aimed at flexibility and adaptive ness, while our approach focuses more on supporting multi dimensionality in communication.in very general sense, our dialogue management approach follows an information state update approach similar to the dialogue managers that are developed within the trindi framework (lars son and traum, 2000).
</prevsent>
</prevsection>
<citsent citstr=" A00-2001 ">
for example, matheson et al (2000) <papid> A00-2001 </papid>describe the implementation of dialogue management system focusing in the concepts of grounding and discourse obligations.</citsent>
<aftsection>
<nextsent>an approach to dialogue management which identifies several simultaneous processes in the generation of system utterances, is described in(stent, 2002).
</nextsent>
<nextsent>in this approach, which is implemented in the trips dialogue system, dialogue contributions are generated through three core components operating independently and concurrently, using system of conversation acts organised in several levels (traum and hinkelman, 1992).although there are apparent similarities between our approach and that of the trindi based dialogue managers and the trips system, there are clear differences as well, which for an important part stem from the system of dialogue acts used and the way the information state is organised.
</nextsent>
<nextsent>more particularly, the way in which mechanisms for generating dialogue acts along multiple dimensions are modelled and implemented bymeans of multiple agents, differs from existing ap proaches.this paper is organised as follows.
</nextsent>
<nextsent>first we explain the closely connected dit notions of dialogue act and information state, and the multidimensional dialogue act taxonomy and context model (sections 2 and 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2858">
<title id=" W06-1306.xml">multidimensional dialogue management </title>
<section> time management: stalling, pausing;.  </section>
<citcontext>
<prevsection>
<prevsent>the taxonomy is currently being evaluated in annotation experiments, involving several annotators and several dialogue corpora.
</prevsent>
<prevsent>measuring inter-annotator agreement will give an indication of the usability of the taxonomy and annotation scheme.
</prevsent>
</prevsection>
<citsent citstr=" W06-1318 ">
a first analysis has resulted in promising scores (geertzen and bunt, 2006).<papid> W06-1318 </papid></citsent>
<aftsection>
<nextsent>3 the dit context model.
</nextsent>
<nextsent>the information state according to dit is represented by context model, containing all information considered relevant for interpreting user utterances (in terms of dialogue acts) and generating system dialogue acts (leading to system ut terances).
</nextsent>
<nextsent>the contents of the context model are therefore very closely related to the dialogue acttaxonomy; in (bunt and keizer, 2005) it is argued that the context model serves as formal semantics for dialogue annotation, such an annotation being kind of underspecified semantic representation.
</nextsent>
<nextsent>in combination with additional general conceptual considerations, the context model has evolved into five component structure: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2859">
<title id=" W06-1308.xml">resolution of referents groupings in practical dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we introduce the notion of super-domain, representing the access structure to all the plural referents of given type.
</prevsent>
<prevsent>in the course of discourse or dialogue, referents introduced separately could be referenced with single plural expression (pronoun, demonstratives, etc.).
</prevsent>
</prevsection>
<citsent citstr=" E89-1022 ">
the grouping of these referents may depend on many factors: it may be explicit if they were syntactically coordinated or juxtaposed or implicit if they just share common semantic features (eschenbach et al., 1989).<papid> E89-1022 </papid></citsent>
<aftsection>
<nextsent>time is also an important factor while it may be difficult to group old mentioned referents with new ones.
</nextsent>
<nextsent>because of this multiplicity of factors, choosing the right discursive grouping for referential plural expression is ambiguous, and this ambiguity needs to be explicitly described.
</nextsent>
<nextsent>we present model of grouping based on reference domains theory (salmon-alt, 2001) that considers that reference operation consists of extracting referent in domain.
</nextsent>
<nextsent>however the original theory barely takes into account plural reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2860">
<title id=" W05-0306.xml">investigating the characteristics of causal relations in japanese text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the time bank corpus(pustejovsky et al, 2003), the causal relation information is included.
</prevsent>
<prevsent>however, the information is optional for implicit linguistic expressions.
</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
although both explicit expressions and implicit expressions are treated in the penn discourse tree bank (pdtb) corpus (miltsakaki et al, 2004), <papid> W04-2703 </papid>no information on causal relations is contained in this corpus.altenberg (1984) investigated the frequency distribution of causal relation instances from some viewpoints such as document style and the syntactic form in english dialog data.</citsent>
<aftsection>
<nextsent>nishizawa (1997) also conducted similar work using japanese dialog data.
</nextsent>
<nextsent>some parts of their viewpoints are overlapping with ours.
</nextsent>
<nextsent>however, while their studies focused on dialog data, our target is text documents.
</nextsent>
<nextsent>in fact, altenberg treated also english text documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2861">
<title id=" W05-0306.xml">investigating the characteristics of causal relations in japanese text </title>
<section> annotated information.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 causal relation tags.
</prevsent>
<prevsent>we use three tags head, mod, and causal rel to represent the basic causal relation information.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
our annotation scheme for events is similar to that of the propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>an event is regarded as consisting of head element and somemodifiers.
</nextsent>
<nextsent>the tags head and mod are used to represent an event which forms one part of the two events held in causal relation.
</nextsent>
<nextsent>the tag causal rel is used to represent causal relation between two annotated events.
</nextsent>
<nextsent>figure 1 shows an example of attaching the causal relation information to the sentence (2a), in which causal relation is held between two events indicated (2b) and (2c) . hereafter, we denote the former (cause) part of event as e1 and the latter (effect) part of event as e2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2862">
<title id=" W05-1007.xml">frame semantic enhancement of lexical semantic resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, semantic annotation tasks (baker etal., 2004) typically assign semantic roles to the arguments of predicates.
</prevsent>
<prevsent>the benefit of the semantic annotation is constrained by the presence and quality of semantic roles in the lexical-semantic resource(s) used.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
gildea and jurafsky (2002) <papid> J02-3001 </papid>suggest that the availability of semantic annotation of this sort is useful for information extraction, word sense disambiguation, machine translation, text summarization, text mining, and speech recognition.</citsent>
<aftsection>
<nextsent>1http://www.cogsci.princeton.edu/wn 2http://www.cis.upenn.edu/ace 3http://framenet.icsi.berkeley.eduother tasks relyon the identification of semantic relationships to recognize lexical chains (sets of semantically related words that enable text to be cohesive) (morris and hirst, 1991).<papid> J91-1002 </papid></nextsent>
<nextsent>the success of this work is constrained by the set of semantic relationship types and instantiations underlying the recognition of lexical chains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2863">
<title id=" W05-1007.xml">frame semantic enhancement of lexical semantic resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the benefit of the semantic annotation is constrained by the presence and quality of semantic roles in the lexical-semantic resource(s) used.
</prevsent>
<prevsent>gildea and jurafsky (2002) <papid> J02-3001 </papid>suggest that the availability of semantic annotation of this sort is useful for information extraction, word sense disambiguation, machine translation, text summarization, text mining, and speech recognition.</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
1http://www.cogsci.princeton.edu/wn 2http://www.cis.upenn.edu/ace 3http://framenet.icsi.berkeley.eduother tasks relyon the identification of semantic relationships to recognize lexical chains (sets of semantically related words that enable text to be cohesive) (morris and hirst, 1991).<papid> J91-1002 </papid></citsent>
<aftsection>
<nextsent>the success of this work is constrained by the set of semantic relationship types and instantiations underlying the recognition of lexical chains.
</nextsent>
<nextsent>as stokess dissertation (2004) notes, lexical cohesion has been used in discourse analysis, text segmentation, word sense disambiguation, text summarization, topic detection and tracking, and question answering.
</nextsent>
<nextsent>unfortunately, most lexical-semantic resources,including those previously mentioned, are the product of considerable ongoing human effort.
</nextsent>
<nextsent>given the high development costs associated with these resources, the possibility of enhancing them on the basis of complementary resources that are produced automatically is welcome.this paper demonstrates several of the characteristics and benefits of sem frame (green et al, 2004; <papid> P04-1048 </papid>green and dorr, 2004), <papid> W04-0909 </papid>system that produces such resource.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2864">
<title id=" W05-1007.xml">frame semantic enhancement of lexical semantic resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as stokess dissertation (2004) notes, lexical cohesion has been used in discourse analysis, text segmentation, word sense disambiguation, text summarization, topic detection and tracking, and question answering.
</prevsent>
<prevsent>unfortunately, most lexical-semantic resources,including those previously mentioned, are the product of considerable ongoing human effort.
</prevsent>
</prevsection>
<citsent citstr=" P04-1048 ">
given the high development costs associated with these resources, the possibility of enhancing them on the basis of complementary resources that are produced automatically is welcome.this paper demonstrates several of the characteristics and benefits of sem frame (green et al, 2004; <papid> P04-1048 </papid>green and dorr, 2004), <papid> W04-0909 </papid>system that produces such resource.</citsent>
<aftsection>
<nextsent>1.
</nextsent>
<nextsent>sem frame generates semantic frames in form.
</nextsent>
<nextsent>like those of framenet, the ostensible gold standard for semantic frames.
</nextsent>
<nextsent>framenet frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2865">
<title id=" W05-1007.xml">frame semantic enhancement of lexical semantic resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as stokess dissertation (2004) notes, lexical cohesion has been used in discourse analysis, text segmentation, word sense disambiguation, text summarization, topic detection and tracking, and question answering.
</prevsent>
<prevsent>unfortunately, most lexical-semantic resources,including those previously mentioned, are the product of considerable ongoing human effort.
</prevsent>
</prevsection>
<citsent citstr=" W04-0909 ">
given the high development costs associated with these resources, the possibility of enhancing them on the basis of complementary resources that are produced automatically is welcome.this paper demonstrates several of the characteristics and benefits of sem frame (green et al, 2004; <papid> P04-1048 </papid>green and dorr, 2004), <papid> W04-0909 </papid>system that produces such resource.</citsent>
<aftsection>
<nextsent>1.
</nextsent>
<nextsent>sem frame generates semantic frames in form.
</nextsent>
<nextsent>like those of framenet, the ostensible gold standard for semantic frames.
</nextsent>
<nextsent>framenet frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2867">
<title id=" W06-1108.xml">evaluation of string distance algorithms for dialectology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has difficult yin dealing with partial matches of linguistic features and with non-overlapping language patterns.
</prevsent>
<prevsent>therefore seguy (1973) and goebl (1982),  and goebl (1984) advocate using aggregates of linguistic features to analyze dialectal patterns, effectively introducing the perspective of dialectometry.
</prevsent>
</prevsection>
<citsent citstr=" E95-1009 ">
kessler (1995) <papid> E95-1009 </papid>introduced the use of string edit distance measure as means of calculating the distance between the pronunciations of corresponding words in different dialects.</citsent>
<aftsection>
<nextsent>following seguys and goebls lead, he calculated this distance for pairs of pronunciations of many words in manyirish-speaking towns.
</nextsent>
<nextsent>string edit distance is sensitive to the degrees of overlap of strings and allows one to process large amounts of pronunciation data, including that which does not follow other iso glosses neatly.
</nextsent>
<nextsent>heeringa (2004) examines several variants of edit distance applied to norwegian and dutch data, focusing on measures which involve length normalization, and which ignore phonological context, and demonstrating that measures using binary segment differences are no worse than those using feature-based measures of segment difference.this paper inspects range of further refinements in measuring pronunciation differences.
</nextsent>
<nextsent>first, we inspect the role of normalization by length, showing that it actually worsens non normalized measures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2868">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>[reiter and dale, 2000, xvii].
</prevsent>
<prevsent>recently, there is an increased interest in nlg applications that produce meaningful text from meaningful text rather than from abstract meaning representations.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
such applications are sometimes referred to as text-to-text generation applications (e.g., [chandrasekar and bangalore, 1997], [knight andmarcu, 2002], [lapata, 2003]), <papid> P03-1069 </papid>and may be likened to earlier revision-based generation strategies, e.g. [robin, 1994] [callaway and lester, 1997].</citsent>
<aftsection>
<nextsent>text-to-text generation is often motivated from practical applications such as summarization,sentence simplification, and sentence compression.
</nextsent>
<nextsent>one reason for the interest in such generation systems is the possibility to automatically learn text-to-text generation strategies from corpora of parallel text.this work was carried out within the imix-imogen (inter active multimodal output generation) project, sponsored by the netherlands organization of scientific research (nwo).
</nextsent>
<nextsent>in this paper, we take closer look at sentence fusion [barzilay, 2003][barzilay et al, 1999], <papid> P99-1071 </papid>one of the interesting variants in text-to-text generation.</nextsent>
<nextsent>a sentence fusion module takes related sentences as input, and generates single sentence summarizing the input sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2869">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>text-to-text generation is often motivated from practical applications such as summarization,sentence simplification, and sentence compression.
</prevsent>
<prevsent>one reason for the interest in such generation systems is the possibility to automatically learn text-to-text generation strategies from corpora of parallel text.this work was carried out within the imix-imogen (inter active multimodal output generation) project, sponsored by the netherlands organization of scientific research (nwo).
</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
in this paper, we take closer look at sentence fusion [barzilay, 2003][barzilay et al, 1999], <papid> P99-1071 </papid>one of the interesting variants in text-to-text generation.</citsent>
<aftsection>
<nextsent>a sentence fusion module takes related sentences as input, and generates single sentence summarizing the input sentences.
</nextsent>
<nextsent>the general strategy described in [barzilay, 2003] is to first align the dependency structures of the two input sentences to find the common information in both sentences.
</nextsent>
<nextsent>on the basis of this alignment, the common information is framed into an fusion tree (i.e.,capturing the shared information), which is subsequently realized in natural language by generating all travers als of the fusion tree and scoring their probability using an n-gram language model.
</nextsent>
<nextsent>of the sentences thus generated the one with the lowest (length normalized) entropy is selected.barzilay and co-workers apply sentence fusion in the context of multi-document summarization, where the input sentences typically come from multiple documents describing the same event, but sentence fusion seems to be useful for other applications as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2870">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> data collection and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>we then present our ongoing work on sentence fusion, describing the current status and performance of the alignment algorithm (section 3), as well as the fusion and generation components (section 4).we end with discussion and description of future plans in section 5.
</prevsent>
<prevsent>2.1 general approach.
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
alignment has become standard practice in data-driven approaches to machine translation (e.g. [och and ney, 2000]).initially work focused on word-based alignment, but more recent research also addresses alignment at the higher levels (substrings, syntactic phrases or trees), e.g.,[gildea, 2003].<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>the latter approach seems most suitable for current purposes, where we want to express that sequence of words in one sentence is related to non-identical sequence of words in another sentence (a paraphrase, for instance).
</nextsent>
<nextsent>however, if we allow alignment of arbitrary sub strings of two sentences, then the number of possible alignments grows exponentially to the number of tokens in the sentences, and the process of alignment ? either manually or automatically ? may become infeasible.
</nextsent>
<nextsent>an alternative, which seems to occupy the middle ground between word alignment on the one hand and alignment of arbitrary sub strings on the other, is to align syntactic analyses.
</nextsent>
<nextsent>here, following [barzilay, 2003], we will align sentences at the level of dependency structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2871">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> data collection and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>results are shown in table 2, where the measures are weighted precision, recall and f-score.
</prevsent>
<prevsent>for instance, the precision is the weighted sum of the separate precision scores for each of the five relations.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the table also shows the ?-score, which is another commonly used measure for inter-annotator agreement [carletta, 1996].<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>again, the f-score of .97 can be regarded as the upper bound on the relation labeling task.
</nextsent>
<nextsent>we think these numbers indicate that the labeled alignment task is well defined and can be accomplished with high level of inter-annotator agreement.
</nextsent>
<nextsent>in this section, we describe the alignment algorithm that we use (section 3.1), and evaluate its performance (section 3.2).
</nextsent>
<nextsent>3.1 tree alignment algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2872">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> automatic alignment.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we describe the alignment algorithm that we use (section 3.1), and evaluate its performance (section 3.2).
</prevsent>
<prevsent>3.1 tree alignment algorithm.
</prevsent>
</prevsection>
<citsent citstr=" C96-1078 ">
the tree alignment algorithm is based on [meyers et al,1996], <papid> C96-1078 </papid>and similar to that used in [barzilay, 2003].</citsent>
<aftsection>
<nextsent>it calculates the match between each node in dependency tree against each node in dependency tree d?.
</nextsent>
<nextsent>the score for each pair of nodes only depends on the similarity of the words associated with the nodes and, recursively, on the scores of the best matching pairs of their descendants.
</nextsent>
<nextsent>for an efficient implementation, dynamic programming is used to build up ascore matrix, which guarantees that each score will be calculated only once.
</nextsent>
<nextsent>given two dependency trees and d?, the algorithm builds up score function s(v, v?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2874">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> merging and generation.  </section>
<citcontext>
<prevsection>
<prevsent>however, others revealed surprisingly adequate generalizations or specifications.
</prevsent>
<prevsent>examples of good and bad output are given in figure 2.as expected, many of the resulting variants are ungrammatical, because constraints on word order, agreement or subcategorisation are violated.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
following work on statistical surface generation [langkilde and knight, 1998] <papid> P98-1116 </papid>and other workon sentence fusion [barzilay, 2003], we tried to filter ungrammatical variants with an n-gram language model.</citsent>
<aftsection>
<nextsent>the cambridge-cmu statistical modeling toolkit v2 was used to train 3-gram model on over 250m words from the twente news corpus , using back-off and good-turing smoothing.
</nextsent>
<nextsent>variants were ranked in order of increasing entropy.
</nextsent>
<nextsent>wefound, however, that the ranking was often inadequate, showing ungrammatical variants at the top and grammatical variants in the lower regions.
</nextsent>
<nextsent>to gain some insight into the general performance of th emerging and generation strategy, we performed small evaluation test in which the two authors independently judged all generated variants in terms of three categories: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2877">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>wehave therefore introduced five different types of semantic relations between strings, namely equals, restates, specifies, generalizes and intersects.
</prevsent>
<prevsent>this increases the expressiveness of the representation, and supports generating re statements, generalizations and specifications.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
finally, we described and evaluated our first results on sentence realization based on these refined alignments, with promising results.similar work is described in [pang et al, 2003], <papid> N03-1024 </papid>who describe syntax-based algorithm that builds word lattices from parallel translations which can be used to generate new para phrases.</citsent>
<aftsection>
<nextsent>their alignment algorithm is less refined, and thereis only type of alignment and hence output (only restate ments), but their mapping of aligned trees to word lattice (or fsa) seems worthwhile to explore in combination with the approach we have proposed here.
</nextsent>
<nextsent>one of the issues that remains to be addressed in future work is the effect of parsing errors.
</nextsent>
<nextsent>such errors were not manually corrected, but during manual alignment, however, we sometimes found that sub strings could not be properly aligned because the parser failed to identify them as syntactic constituents.
</nextsent>
<nextsent>the repercussions of this for the generation should be investigated by comparing the results obtained here with alignments on perfect parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2878">
<title id=" W05-1612.xml">explorations in sentence fusion </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we intend to address this task with machine learning, initially relying on shallow features such as the length of the respective token strings and the amount of overlap.
</prevsent>
<prevsent>it is also clear that more work is needed on merging and surface realization.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
one possible direction here is to exploit the relatively rich linguistic representation of the input sentences (pos tags, lemmas and dependency structures), for instance, along the lines of [ban galore and rambow, 2000].<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>yet another issue concerns thetype of text material.
</nextsent>
<nextsent>the sentence pairs from our current corpus are relatively close, in the sense that there is usually 1 to-1 mapping between sentences, and both translations more or less convey the same information.
</nextsent>
<nextsent>although this seems good starting point to study alignment, we intend to continue with other types of text material in future work.
</nextsent>
<nextsent>for instance, in extending our work to the actual output of qa system, we expect to encounter sentences with far less overlap.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2888">
<title id=" W05-0503.xml">using morphology and syntax together in unsupervised learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents test conducted on english, and thus can only be considered preliminary step in the 1 see higgins 2002 for study similar in some ways;.
</prevsent>
<prevsent>higgins uses morphology as bootstrap heuristic in one experimental set-up.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
this paper is heavily indebted to prior work on unsupervised learning of position categories such as brown et al 1992, <papid> J92-4003 </papid>schtze 1997, higgins 2002, and others cited there.</citsent>
<aftsection>
<nextsent>eventually development of language independent tool for grammar induction based on morphology.
</nextsent>
<nextsent>nonetheless, the concepts that motivate the process are language-independent, and we are optimistic that similar results would be found in tests based on texts from other languages.
</nextsent>
<nextsent>in section 2 we discuss the notion of signature and signature transform, and section 3 present more explicit formulation of the general problem.
</nextsent>
<nextsent>in section 4 we present our algorithm for signature collapse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2889">
<title id=" W05-0503.xml">using morphology and syntax together in unsupervised learning </title>
<section> signatures and signature transforms.  </section>
<citcontext>
<prevsection>
<prevsent>in section 4 we present our algorithm for signature collapse.
</prevsent>
<prevsent>section 5 describes the experiments we ran to test the signature collapsing algorithm, and section 6 presents and discusses our results.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
we employ the unsupervised learning of morphology developed by goldsmith (goldsmith, 2001).<papid> J01-2001 </papid></citsent>
<aftsection>
<nextsent>regrettably, some of the discussion below depends rather heavily on material presented there, but we attempt to summarize the major points here.
</nextsent>
<nextsent>two critical terms that we employ in this analysis are signature and signature transform.
</nextsent>
<nextsent>a signature found in given corpus is pair of lists: stem-list and suffix-list (or in the appropriate context, prefix-list).
</nextsent>
<nextsent>by definition of signature ?, the concatenation of every stem in the stem-list of ? with every suffix in the suffix-list of ? is found in the corpus, and morphological analysis of corpus can be viewed as set of signatures that uniquely analyze each word in the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2891">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper presents novel approach tothe semi-supervised learning of information extraction patterns.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
the method makes use of more complex patterns than previous approaches and determines their similarity using measure inspired by recent work using kernel methods (culotta and sorensen, 2004).<papid> P04-1054 </papid></citsent>
<aftsection>
<nextsent>experiments show that the proposed similarity measure outperforms previously reported measure based on cosine similarity when used to perform binary relation extraction.
</nextsent>
<nextsent>a recent approach to information extraction (ie) is to make use of machine learning algorithms which allow systems to be rapidly developed or adapted to new extraction problems.
</nextsent>
<nextsent>this reduces the need for manual development which is major bottleneck in the development of ie technologies and can be extremely time consuming (e.g. riloff (1996)).
</nextsent>
<nextsent>a number of machine learning approaches have recently been applied.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2892">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this reduces the need for manual development which is major bottleneck in the development of ie technologies and can be extremely time consuming (e.g. riloff (1996)).
</prevsent>
<prevsent>a number of machine learning approaches have recently been applied.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
one is the use of iterative learning algorithms to infer extraction patterns from small number of seed examples (yangar beret al, 2000; <papid> C00-2136 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches use dependency analysis as the basis of ie patterns.
</nextsent>
<nextsent>training text is parsed and set of candidate patterns extracted.
</nextsent>
<nextsent>these patterns are then compared against the seeds with the most similar being selected and added to the seed set.
</nextsent>
<nextsent>(optionally, user may verify the patterns at thispoint.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2893">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this reduces the need for manual development which is major bottleneck in the development of ie technologies and can be extremely time consuming (e.g. riloff (1996)).
</prevsent>
<prevsent>a number of machine learning approaches have recently been applied.
</prevsent>
</prevsection>
<citsent citstr=" P05-1047 ">
one is the use of iterative learning algorithms to infer extraction patterns from small number of seed examples (yangar beret al, 2000; <papid> C00-2136 </papid>stevenson and greenwood, 2005).<papid> P05-1047 </papid></citsent>
<aftsection>
<nextsent>these approaches use dependency analysis as the basis of ie patterns.
</nextsent>
<nextsent>training text is parsed and set of candidate patterns extracted.
</nextsent>
<nextsent>these patterns are then compared against the seeds with the most similar being selected and added to the seed set.
</nextsent>
<nextsent>(optionally, user may verify the patterns at thispoint.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2898">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, no pattern consisting of verb and its arguments could be constructed which could identify thesame relation in jones was named as smiths suc cessor.?
</prevsent>
<prevsent>others have suggested alternative approaches for generating extraction patterns from dependency trees, each of which allows particular part of the dependency analysis to act as an extractionpattern.
</prevsent>
</prevsection>
<citsent citstr=" P03-1029 ">
for example, sudo et al (2003) <papid> P03-1029 </papid>used patterns consisting of path from verb to any of its descendents (direct or indirect) while bunescu and mooney (2005) <papid> H05-1091 </papid>suggest the shortest path between the items being related.</citsent>
<aftsection>
<nextsent>however, iterative learning algorithms, such as the ones used by yangarber et al (2000) <papid> C00-2136 </papid>and stevenson and greenwood (2005), <papid> P05-1047 </papid>have not made use of these more complex extraction patterns.</nextsent>
<nextsent>part of the reason for this is that these algorithms require way of determining the similarity between patterns (in order to compare candidate patterns with the seeds).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2900">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, no pattern consisting of verb and its arguments could be constructed which could identify thesame relation in jones was named as smiths suc cessor.?
</prevsent>
<prevsent>others have suggested alternative approaches for generating extraction patterns from dependency trees, each of which allows particular part of the dependency analysis to act as an extractionpattern.
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
for example, sudo et al (2003) <papid> P03-1029 </papid>used patterns consisting of path from verb to any of its descendents (direct or indirect) while bunescu and mooney (2005) <papid> H05-1091 </papid>suggest the shortest path between the items being related.</citsent>
<aftsection>
<nextsent>however, iterative learning algorithms, such as the ones used by yangarber et al (2000) <papid> C00-2136 </papid>and stevenson and greenwood (2005), <papid> P05-1047 </papid>have not made use of these more complex extraction patterns.</nextsent>
<nextsent>part of the reason for this is that these algorithms require way of determining the similarity between patterns (in order to compare candidate patterns with the seeds).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2907">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> semi-supervised learning of.  </section>
<citcontext>
<prevsection>
<prevsent>these are extended to include information about lexical similarity derived from wordnet (section 4).
</prevsent>
<prevsent>we present results of using patterns acquired through this similarity function to perform binary relation extraction (sections 5 and 6).
</prevsent>
</prevsection>
<citsent citstr=" P03-1044 ">
extraction pattern swe begin by outlining the general process of learning extraction patterns using semi-supervised algorithm, similar to one presented by yangarber (2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>1.
</nextsent>
<nextsent>forgiven ie scenario we assume the ex-.
</nextsent>
<nextsent>istence of set of documents against which the system can be trained.
</nextsent>
<nextsent>the documents are unannotated and may be either relevant (con tain the description of an event relevant to the scenario) or irrelevant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2922">
<title id=" W06-0204.xml">improving semi supervised acquisition of relation extraction patterns </title>
<section> relation extraction patterns.  </section>
<citcontext>
<prevsection>
<prevsent>(sudo et al, 2003; <papid> P03-1029 </papid>bunescu and mooney, 2005)).<papid> H05-1091 </papid></prevsent>
<prevsent>previous analysis (stevenson and greenwood, 2006a) suggests that the most useful of these is one based on pairs of linked chains from the dependency tree.</prevsent>
</prevsection>
<citsent citstr=" H01-1009 ">
a chain can be defined as path between verb node and any other node in the dependency tree passing through zero or more intermediate nodes (sudoet al, 2001).<papid> H01-1009 </papid></citsent>
<aftsection>
<nextsent>the linked chains model (green wood et al, 2005) represents extraction patterns as pair of chains which share the same verb but no direct descendants.
</nextsent>
<nextsent>it can be shown that linked figure 2: example linked chain patterns chain patterns can represent the majority of relations within dependency analysis (stevenson and greenwood, 2006a).
</nextsent>
<nextsent>for example, the dependency tree shown in figure 1 contains four named entities (acme inc., mr smith, ceo and mr. bloggs)and linked chains patterns can be used to represent the relation between any pair.1 some example patterns extracted from the analysis in figure 1 can be seen in figure 2.
</nextsent>
<nextsent>an additional advantage of linked chain patterns is that they do not cause an unwieldy number of candidate patterns to be generated unlike some other approaches for representing extraction patterns, such as the one proposed by sudo et al (2003) <papid> P03-1029 </papid>where any subtree of the dependency tree can act as potential pattern.when used within ie systems these patterns are generalised by replacing terms which refer to specific entities with general semantic class.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2957">
<title id=" W05-0818.xml">lihla shared task system description </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method has achieved an alignment error rate of 22.72% and 44.49% on english?
</prevsent>
<prevsent>inuktitut and romanian english parallel sentences, respectively.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
alignment of words and multiword units plays an important role in many natural language processing (nlp) applications, such as example-based machine translation (ebmt) (somers, 1999) and statistical machine translation (smt) (ayan et al, 2004; och and ney, 2000), <papid> P00-1056 </papid>transfer rule learning (carl, 2001;<papid> W01-0718 </papid>menezes and richardson, 2001), <papid> W01-1406 </papid>bilingual lexi cography (gomez guinovart and sacau fontenla, 2004), and word sense disambiguation (gale et al, 1992), among others.</citsent>
<aftsection>
<nextsent>aligning two (or more) texts means finding correspondences (translation equivalences) between segments (paragraphs, sentences, words, etc.) of the source text and segments of its translation (the target text).
</nextsent>
<nextsent>following the same idea of many recently proposed approaches on lexical alignment (e.g., wu and wang (2004) and ayan et al (2004)), the method described in this paper, lihla (language independent heuristics lexical aligner) starts from statistical alignments between single words (defined in bilingual lexicons) and applies language independent heuristics to them, aiming at finding the best alignments between words or multiword units.
</nextsent>
<nextsent>although the most frequent alignment category is 1 : 1 (in which one source word is translated exactly as one target word), other categories such as omissions (1 : 0 or 0 : 1) or those involving multiword units (n : m, with and/or ? 1) are also possible.this paper is organized as follows: section 2 explains how lihla works; section 3 describes some experiments carried out with lihla together with their results and, in section 4, some concluding remarks are presented.
</nextsent>
<nextsent>as the first step, lihla uses alignments between single words defined in two bilingual lexicons (sourcetarget and targetsource) generated from sentence-aligned parallel texts using natools.1given two sentence-aligned corpus files, the natools word aligner based on the twenty-one system (hiemstra, 1998)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2958">
<title id=" W05-0818.xml">lihla shared task system description </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method has achieved an alignment error rate of 22.72% and 44.49% on english?
</prevsent>
<prevsent>inuktitut and romanian english parallel sentences, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W01-0718 ">
alignment of words and multiword units plays an important role in many natural language processing (nlp) applications, such as example-based machine translation (ebmt) (somers, 1999) and statistical machine translation (smt) (ayan et al, 2004; och and ney, 2000), <papid> P00-1056 </papid>transfer rule learning (carl, 2001;<papid> W01-0718 </papid>menezes and richardson, 2001), <papid> W01-1406 </papid>bilingual lexi cography (gomez guinovart and sacau fontenla, 2004), and word sense disambiguation (gale et al, 1992), among others.</citsent>
<aftsection>
<nextsent>aligning two (or more) texts means finding correspondences (translation equivalences) between segments (paragraphs, sentences, words, etc.) of the source text and segments of its translation (the target text).
</nextsent>
<nextsent>following the same idea of many recently proposed approaches on lexical alignment (e.g., wu and wang (2004) and ayan et al (2004)), the method described in this paper, lihla (language independent heuristics lexical aligner) starts from statistical alignments between single words (defined in bilingual lexicons) and applies language independent heuristics to them, aiming at finding the best alignments between words or multiword units.
</nextsent>
<nextsent>although the most frequent alignment category is 1 : 1 (in which one source word is translated exactly as one target word), other categories such as omissions (1 : 0 or 0 : 1) or those involving multiword units (n : m, with and/or ? 1) are also possible.this paper is organized as follows: section 2 explains how lihla works; section 3 describes some experiments carried out with lihla together with their results and, in section 4, some concluding remarks are presented.
</nextsent>
<nextsent>as the first step, lihla uses alignments between single words defined in two bilingual lexicons (sourcetarget and targetsource) generated from sentence-aligned parallel texts using natools.1given two sentence-aligned corpus files, the natools word aligner based on the twenty-one system (hiemstra, 1998)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2959">
<title id=" W05-0818.xml">lihla shared task system description </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method has achieved an alignment error rate of 22.72% and 44.49% on english?
</prevsent>
<prevsent>inuktitut and romanian english parallel sentences, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
alignment of words and multiword units plays an important role in many natural language processing (nlp) applications, such as example-based machine translation (ebmt) (somers, 1999) and statistical machine translation (smt) (ayan et al, 2004; och and ney, 2000), <papid> P00-1056 </papid>transfer rule learning (carl, 2001;<papid> W01-0718 </papid>menezes and richardson, 2001), <papid> W01-1406 </papid>bilingual lexi cography (gomez guinovart and sacau fontenla, 2004), and word sense disambiguation (gale et al, 1992), among others.</citsent>
<aftsection>
<nextsent>aligning two (or more) texts means finding correspondences (translation equivalences) between segments (paragraphs, sentences, words, etc.) of the source text and segments of its translation (the target text).
</nextsent>
<nextsent>following the same idea of many recently proposed approaches on lexical alignment (e.g., wu and wang (2004) and ayan et al (2004)), the method described in this paper, lihla (language independent heuristics lexical aligner) starts from statistical alignments between single words (defined in bilingual lexicons) and applies language independent heuristics to them, aiming at finding the best alignments between words or multiword units.
</nextsent>
<nextsent>although the most frequent alignment category is 1 : 1 (in which one source word is translated exactly as one target word), other categories such as omissions (1 : 0 or 0 : 1) or those involving multiword units (n : m, with and/or ? 1) are also possible.this paper is organized as follows: section 2 explains how lihla works; section 3 describes some experiments carried out with lihla together with their results and, in section 4, some concluding remarks are presented.
</nextsent>
<nextsent>as the first step, lihla uses alignments between single words defined in two bilingual lexicons (sourcetarget and targetsource) generated from sentence-aligned parallel texts using natools.1given two sentence-aligned corpus files, the natools word aligner based on the twenty-one system (hiemstra, 1998)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2960">
<title id=" W05-0818.xml">lihla shared task system description </title>
<section> cognates.  </section>
<citcontext>
<prevsection>
<prevsent>then, without changing any default parameter (threshold for lcsr, maximum number of iterations, etc.), lihla aligned the 75 englishinuktitut and the 203 romanian english parallel sentences on test sets.the whole alignment process (bilingual lexicon generation and alignment itself) did not take more than 17 minutes for englishinuktitut (3 iterations per sentence, on average) and 7 minutes for romanian?
</prevsent>
<prevsent>english (4 iterations per sentence, on average).
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
the evaluation was run with respect to precision, recall, -measure, and alignment error rate (aer) considering sure and probable alignments but not null ones (mihalcea and pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>tables 1 and 2 present metric values for englishinuktitut and romanian english alignments, respectively, as provided by the organization of the shared task.
</nextsent>
<nextsent>metric sure probable precision 46.55% 79.53% recall 73.72% 18.71% -measure 57.07% 30.30% aer 22.72% table 1: lihla results for englishinuktitut metric sure probable precision 57.68% 57.68% recall 53.51% 53.51% -measure 55.51% 55.51% aer 44.49% table 2: lihla results for romanian english the results obtained in these experiments were not so good as those achieved by lihla on the language pairs for which it was developed, that is, 92.48% of precision and 88.32% of recall on portuguese spanish parallel texts and 84.35% of precision and 76.39% of recall on portuguese?
</nextsent>
<nextsent>english ones.3 the poor performance in the englishinuktikut task may be partly due to the fact that inuktikut isa poly synthetic language, that is, one in which, unlike in english, words are formed by long strings of concatenated morphemes.
</nextsent>
<nextsent>this makes it difficult for natools to build reasonable dictionaries and lead to predominance of : 1 alignments, which are harder to determine this fact can be confirmed bythe better precision of lihla when probable alignments were considered (see table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2962">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task reported on here is to produce propbank (kingsburyand palmer, 2002) labels, given the features provided for the conll-2005 closed task (carreras and ma`rquez, 2005).we have previously reported on using svm classifiers for semantic role labeling.
</prevsent>
<prevsent>in this work, we formulate the semantic labeling problem as multiclass classification problem using support vector machine (svm) classifiers.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
some of these systems use features based on syntactic constituents produced by charniak parser (pradhan et al, 2003;pradhan et al, 2004) <papid> N04-1030 </papid>and others use only flat syntactic representation produced by syntactic chun ker (hacioglu et al, 2003; hacioglu and ward, 2003; <papid> N03-2009 </papid>hacioglu, 2004; <papid> N04-4037 </papid>hacioglu et al, 2004).<papid> W04-2416 </papid></citsent>
<aftsection>
<nextsent>the latter approach lacks the information provided by the hierarchical syntactic structure, and the former imposes limitation that the possible candidate roles should be one of the nodes already present in the syntax tree.
</nextsent>
<nextsent>we found that, while the chunk based systems are very efficient and robust, the systems that use features based on full syntactic parses are generally more accurate.
</nextsent>
<nextsent>analysis of the source of errors for the parse constituent based systems showed that incorrect parses were major source of error.
</nextsent>
<nextsent>the syntactic parser did not produce any constituent that corresponded to the correct segmentation for the semantic argument.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2963">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task reported on here is to produce propbank (kingsburyand palmer, 2002) labels, given the features provided for the conll-2005 closed task (carreras and ma`rquez, 2005).we have previously reported on using svm classifiers for semantic role labeling.
</prevsent>
<prevsent>in this work, we formulate the semantic labeling problem as multiclass classification problem using support vector machine (svm) classifiers.
</prevsent>
</prevsection>
<citsent citstr=" N03-2009 ">
some of these systems use features based on syntactic constituents produced by charniak parser (pradhan et al, 2003;pradhan et al, 2004) <papid> N04-1030 </papid>and others use only flat syntactic representation produced by syntactic chun ker (hacioglu et al, 2003; hacioglu and ward, 2003; <papid> N03-2009 </papid>hacioglu, 2004; <papid> N04-4037 </papid>hacioglu et al, 2004).<papid> W04-2416 </papid></citsent>
<aftsection>
<nextsent>the latter approach lacks the information provided by the hierarchical syntactic structure, and the former imposes limitation that the possible candidate roles should be one of the nodes already present in the syntax tree.
</nextsent>
<nextsent>we found that, while the chunk based systems are very efficient and robust, the systems that use features based on full syntactic parses are generally more accurate.
</nextsent>
<nextsent>analysis of the source of errors for the parse constituent based systems showed that incorrect parses were major source of error.
</nextsent>
<nextsent>the syntactic parser did not produce any constituent that corresponded to the correct segmentation for the semantic argument.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2964">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task reported on here is to produce propbank (kingsburyand palmer, 2002) labels, given the features provided for the conll-2005 closed task (carreras and ma`rquez, 2005).we have previously reported on using svm classifiers for semantic role labeling.
</prevsent>
<prevsent>in this work, we formulate the semantic labeling problem as multiclass classification problem using support vector machine (svm) classifiers.
</prevsent>
</prevsection>
<citsent citstr=" N04-4037 ">
some of these systems use features based on syntactic constituents produced by charniak parser (pradhan et al, 2003;pradhan et al, 2004) <papid> N04-1030 </papid>and others use only flat syntactic representation produced by syntactic chun ker (hacioglu et al, 2003; hacioglu and ward, 2003; <papid> N03-2009 </papid>hacioglu, 2004; <papid> N04-4037 </papid>hacioglu et al, 2004).<papid> W04-2416 </papid></citsent>
<aftsection>
<nextsent>the latter approach lacks the information provided by the hierarchical syntactic structure, and the former imposes limitation that the possible candidate roles should be one of the nodes already present in the syntax tree.
</nextsent>
<nextsent>we found that, while the chunk based systems are very efficient and robust, the systems that use features based on full syntactic parses are generally more accurate.
</nextsent>
<nextsent>analysis of the source of errors for the parse constituent based systems showed that incorrect parses were major source of error.
</nextsent>
<nextsent>the syntactic parser did not produce any constituent that corresponded to the correct segmentation for the semantic argument.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2965">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task reported on here is to produce propbank (kingsburyand palmer, 2002) labels, given the features provided for the conll-2005 closed task (carreras and ma`rquez, 2005).we have previously reported on using svm classifiers for semantic role labeling.
</prevsent>
<prevsent>in this work, we formulate the semantic labeling problem as multiclass classification problem using support vector machine (svm) classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
some of these systems use features based on syntactic constituents produced by charniak parser (pradhan et al, 2003;pradhan et al, 2004) <papid> N04-1030 </papid>and others use only flat syntactic representation produced by syntactic chun ker (hacioglu et al, 2003; hacioglu and ward, 2003; <papid> N03-2009 </papid>hacioglu, 2004; <papid> N04-4037 </papid>hacioglu et al, 2004).<papid> W04-2416 </papid></citsent>
<aftsection>
<nextsent>the latter approach lacks the information provided by the hierarchical syntactic structure, and the former imposes limitation that the possible candidate roles should be one of the nodes already present in the syntax tree.
</nextsent>
<nextsent>we found that, while the chunk based systems are very efficient and robust, the systems that use features based on full syntactic parses are generally more accurate.
</nextsent>
<nextsent>analysis of the source of errors for the parse constituent based systems showed that incorrect parses were major source of error.
</nextsent>
<nextsent>the syntactic parser did not produce any constituent that corresponded to the correct segmentation for the semantic argument.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2966">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>analysis of the source of errors for the parse constituent based systems showed that incorrect parses were major source of error.
</prevsent>
<prevsent>the syntactic parser did not produce any constituent that corresponded to the correct segmentation for the semantic argument.
</prevsent>
</prevsection>
<citsent citstr=" P05-1072 ">
in pradhan et al (2005), <papid> P05-1072 </papid>we reported on first attempt to overcome this problem by combining semantic role labels produced from different syntactic parses.</citsent>
<aftsection>
<nextsent>the hope is that the syntactic parsers will make different errors, and that combining their outputs will improve on 217either system alone.
</nextsent>
<nextsent>this initial attempt used features from charniak parser, minipar parser and chunk based parser.
</nextsent>
<nextsent>it did show some improvement from the combination, but the method for combining the information was heuristic and sub-optimal.in this paper, we report on what we believe is an improved framework for combining information from different syntactic views.
</nextsent>
<nextsent>our goal is to preserve the robustness and flexibility of the segmentation of thephrase-based chunker, but to take advantage of features from full syntactic parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2967">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>to this end, we use features generated from charniak parser and collins parser, as supplied for the conll-2005 closed task.
</prevsent>
<prevsent>we again formulate the semantic labeling problem as multi-class classification problem using support vector machine (svm) classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
tinysvm1 along with yamcha2 (kudo and matsumoto, 2000; <papid> W00-0730 </papid>kudo and matsumoto, 2001) <papid> N01-1025 </papid>are used to implement the system.</citsent>
<aftsection>
<nextsent>using what is known as the one vs all classification strategy, binary classifiers are trained, where is number of semantic classes including null class.the general framework is to train separate semantic role labeling systems for each of the parse tree views, and then to use the role arguments output by these systems as additional features in semantic role classifier using flat syntactic view.
</nextsent>
<nextsent>the constituent based classifiers walk syntactic parse tree and classify each node as null (no role) or as one of the set of semantic roles.
</nextsent>
<nextsent>chunk based systems classify each base phrase as being the b(eginning) of semantic role, i(nside) semantic role, or o(utside) any semantic role (ie.
</nextsent>
<nextsent>null).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2968">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>to this end, we use features generated from charniak parser and collins parser, as supplied for the conll-2005 closed task.
</prevsent>
<prevsent>we again formulate the semantic labeling problem as multi-class classification problem using support vector machine (svm) classifiers.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
tinysvm1 along with yamcha2 (kudo and matsumoto, 2000; <papid> W00-0730 </papid>kudo and matsumoto, 2001) <papid> N01-1025 </papid>are used to implement the system.</citsent>
<aftsection>
<nextsent>using what is known as the one vs all classification strategy, binary classifiers are trained, where is number of semantic classes including null class.the general framework is to train separate semantic role labeling systems for each of the parse tree views, and then to use the role arguments output by these systems as additional features in semantic role classifier using flat syntactic view.
</nextsent>
<nextsent>the constituent based classifiers walk syntactic parse tree and classify each node as null (no role) or as one of the set of semantic roles.
</nextsent>
<nextsent>chunk based systems classify each base phrase as being the b(eginning) of semantic role, i(nside) semantic role, or o(utside) any semantic role (ie.
</nextsent>
<nextsent>null).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2969">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>chunk based systems classify each base phrase as being the b(eginning) of semantic role, i(nside) semantic role, or o(utside) any semantic role (ie.
</prevsent>
<prevsent>null).
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
this is referred to as an iob representation (ramshaw and marcus, 1995).<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>the constituent level roles are mapped to the iob representation used by the chun ker.
</nextsent>
<nextsent>the iob tags are then used as features for separate base-phase semantic role labeler (chunker), in addition to the standard set of features used by the chunker.
</nextsent>
<nextsent>an n-fold cross-validation paradigm is used to train the constituent based role classifiers 1http://chasen.org/taku/software/tinysvm/ 2http://chasen.org/taku/software/yamcha/ and the chunk based classifier.
</nextsent>
<nextsent>for the system reported here, two full syntactic parsers were used, charniak parser and collins parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2970">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>after both these were trained, we tagged the training data using them and removed all most likely nulls from the data.
</prevsent>
<prevsent>table 1 lists the features used in the constituent based systems.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
they are combination of features introduced by gildea and jurafsky (2002), <papid> J02-3001 </papid>ones proposed in pradhan et al (2004), <papid> N04-1030 </papid>surdeanu et al (2003) <papid> P03-1002 </papid>and the syntactic-frame feature proposed in(xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>these features are extracted from the parse tree being labeled.
</nextsent>
<nextsent>in addition to the features extracted from the parse tree being labeled, five features were extracted from the other parse tree (phrase, head word, head word pos, path 218 predicate lemma path: path from the constituent to the predicate in the parse tree.
</nextsent>
<nextsent>position: whether the constituent is before or after the predicate.
</nextsent>
<nextsent>predicate sub-categorization head word: head word of the constituent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2972">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>after both these were trained, we tagged the training data using them and removed all most likely nulls from the data.
</prevsent>
<prevsent>table 1 lists the features used in the constituent based systems.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
they are combination of features introduced by gildea and jurafsky (2002), <papid> J02-3001 </papid>ones proposed in pradhan et al (2004), <papid> N04-1030 </papid>surdeanu et al (2003) <papid> P03-1002 </papid>and the syntactic-frame feature proposed in(xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>these features are extracted from the parse tree being labeled.
</nextsent>
<nextsent>in addition to the features extracted from the parse tree being labeled, five features were extracted from the other parse tree (phrase, head word, head word pos, path 218 predicate lemma path: path from the constituent to the predicate in the parse tree.
</nextsent>
<nextsent>position: whether the constituent is before or after the predicate.
</nextsent>
<nextsent>predicate sub-categorization head word: head word of the constituent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2973">
<title id=" W05-0634.xml">semantic role chunking combining complementary syntactic views </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>after both these were trained, we tagged the training data using them and removed all most likely nulls from the data.
</prevsent>
<prevsent>table 1 lists the features used in the constituent based systems.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
they are combination of features introduced by gildea and jurafsky (2002), <papid> J02-3001 </papid>ones proposed in pradhan et al (2004), <papid> N04-1030 </papid>surdeanu et al (2003) <papid> P03-1002 </papid>and the syntactic-frame feature proposed in(xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>these features are extracted from the parse tree being labeled.
</nextsent>
<nextsent>in addition to the features extracted from the parse tree being labeled, five features were extracted from the other parse tree (phrase, head word, head word pos, path 218 predicate lemma path: path from the constituent to the predicate in the parse tree.
</nextsent>
<nextsent>position: whether the constituent is before or after the predicate.
</nextsent>
<nextsent>predicate sub-categorization head word: head word of the constituent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2976">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus the only verb person/number distinction made in the brown corpus/penn treebank tagset is vbz(3rd-person-singular-present), with no corresponding person/number distinction in other tenses.
</prevsent>
<prevsent>similarly, adjectives in english pos tagsets typically have no distinctions for person, number or case be cause such properties have no morphological surface distinction, although they do for many other languages.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
this essential limitation of the brown/penn possubtag inventory to morphologically realized distinctions in english dramatically simplifies the problem by reducing the tag entropy per surface form (the adjective tall has only one pos tag (jj) rather than numerous singular, plural, nominative, accusative, etc. variants), increasing both the standalone effectiveness of lexical prior models and word suffix models for part-of-speech tagging.however, for many multilingual applications, including feature-based word alignment in bilingual corpora and machine translation into morphologically richer languages, it is helpful to extract finer grained lexical analyses on the english side that more closely parallel the morphologically realized tagset of the second (source or target) language.in particular, prior work on trans lingual part-ofspeech tagger projection via parallel bilingual corpora (e.g. yarowsky et al, 2001) <papid> H01-1035 </papid>has been limited to inducing part-of-speech taggers in second languages (such as french or czech) that only assign tags at the granularity of their source language (i.e. 49the penn treebank-granularity distinctions from en glish).</citsent>
<aftsection>
<nextsent>the much richer english tagsets achieved here can allow these tagger projection techniques to transfer richer tag distinctions (such as case and verbperson/number) that are important to the full analysis of these languages, using only bilingual corpora with the morphologically impoverished english.
</nextsent>
<nextsent>for quickly retarget able machine translation, the primary focus of effort is overcoming the extreme scarcity of resources for the low density source language.
</nextsent>
<nextsent>sparsity of conditioning events for translation model can be greatly reduced by the availability of automatic source-language analysis.
</nextsent>
<nextsent>in this research we attempt to induce models for the automatic analysis of morphological features such as case, tense, number, and polarity in both the source and target languages with this end in mind.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2977">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>forms the basis of the distinctions used in this paper.
</prevsent>
<prevsent>the other major approach to fine-grained tagging involves using tree-based tags that capture grammatical structure.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
bangalore and joshi (1999) <papid> J99-2004 </papid>have utilized supertags?</citsent>
<aftsection>
<nextsent>based on tree-structures of various complexity in the tree-adjoining grammar model.using such tags, brants (2000) <papid> A00-1031 </papid>has achieved the automated tagging of syntactic-structure-based set of grammatical function tags including phrase-chunk and syntactic-role modifiers trained in supervised mode from treebank of german.</nextsent>
<nextsent>2.2 classifier combination for part-of-speech.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2978">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>the other major approach to fine-grained tagging involves using tree-based tags that capture grammatical structure.
</prevsent>
<prevsent>bangalore and joshi (1999) <papid> J99-2004 </papid>have utilized supertags?</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
based on tree-structures of various complexity in the tree-adjoining grammar model.using such tags, brants (2000) <papid> A00-1031 </papid>has achieved the automated tagging of syntactic-structure-based set of grammatical function tags including phrase-chunk and syntactic-role modifiers trained in supervised mode from treebank of german.</citsent>
<aftsection>
<nextsent>2.2 classifier combination for part-of-speech.
</nextsent>
<nextsent>tagging there has been broad work in classifier combination at the tag-level for supervised pos tagging models.
</nextsent>
<nextsent>for example, ma`rquez and rodrguez (1998) have performed voting over an ensemble of decision tree and hmm-based taggers for supervised english tagging.
</nextsent>
<nextsent>murata et al (2001) have combined neural networks, support vector machines, decision lists and transformation-based-learning approaches for thai part-of-speech tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2981">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>they also used noise-robust supervised training techniques to train stand-alone french and czech pos taggers based on these projected tags.
</prevsent>
<prevsent>their projected tagsets, however, were limited to those distinctions captured in the english penn treebank inventory, and hence failed to make many of the finer grained distinctions traditionally assumed for french and czech pos tagging, such as verb person, number, and polarity and noun/adjective case.
</prevsent>
</prevsection>
<citsent citstr=" W03-0414 ">
probst (2003) <papid> W03-0414 </papid>pursued similar methodology for the purposes of tag projection, using somewhat expanded tagset inventory (e.g. including adjective number but not case), and focusing on target language monolingual modeling using morpheme analysis.</citsent>
<aftsection>
<nextsent>cucerzan and yarowsky (2003)<papid> N03-1006 </papid>addressed the problem of grammatical gender projection via the use of small seed sets based on natural gender.another distinct body of work addresses the problem of parser bootstrapping based on syntactic dependency projection (e.g. hwa et al 2002), often using approaches based in synchronous parsing (e.g. smith and smith, 2004).<papid> W04-3207 </papid></nextsent>
<nextsent>50 word core prsn num.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2982">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>their projected tagsets, however, were limited to those distinctions captured in the english penn treebank inventory, and hence failed to make many of the finer grained distinctions traditionally assumed for french and czech pos tagging, such as verb person, number, and polarity and noun/adjective case.
</prevsent>
<prevsent>probst (2003) <papid> W03-0414 </papid>pursued similar methodology for the purposes of tag projection, using somewhat expanded tagset inventory (e.g. including adjective number but not case), and focusing on target language monolingual modeling using morpheme analysis.</prevsent>
</prevsection>
<citsent citstr=" N03-1006 ">
cucerzan and yarowsky (2003)<papid> N03-1006 </papid>addressed the problem of grammatical gender projection via the use of small seed sets based on natural gender.another distinct body of work addresses the problem of parser bootstrapping based on syntactic dependency projection (e.g. hwa et al 2002), often using approaches based in synchronous parsing (e.g. smith and smith, 2004).<papid> W04-3207 </papid></citsent>
<aftsection>
<nextsent>50 word core prsn num.
</nextsent>
<nextsent>case tns/ pol.
</nextsent>
<nextsent>voi.
</nextsent>
<nextsent>pos asp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2984">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>their projected tagsets, however, were limited to those distinctions captured in the english penn treebank inventory, and hence failed to make many of the finer grained distinctions traditionally assumed for french and czech pos tagging, such as verb person, number, and polarity and noun/adjective case.
</prevsent>
<prevsent>probst (2003) <papid> W03-0414 </papid>pursued similar methodology for the purposes of tag projection, using somewhat expanded tagset inventory (e.g. including adjective number but not case), and focusing on target language monolingual modeling using morpheme analysis.</prevsent>
</prevsection>
<citsent citstr=" W04-3207 ">
cucerzan and yarowsky (2003)<papid> N03-1006 </papid>addressed the problem of grammatical gender projection via the use of small seed sets based on natural gender.another distinct body of work addresses the problem of parser bootstrapping based on syntactic dependency projection (e.g. hwa et al 2002), often using approaches based in synchronous parsing (e.g. smith and smith, 2004).<papid> W04-3207 </papid></citsent>
<aftsection>
<nextsent>50 word core prsn num.
</nextsent>
<nextsent>case tns/ pol.
</nextsent>
<nextsent>voi.
</nextsent>
<nextsent>pos asp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2985">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> tagsets.  </section>
<citcontext>
<prevsection>
<prevsent>titres nn 3 pl. with?
</prevsent>
<prevsent>curieux jj 3 pl. with figure 2: example of fined-grained pos tags projected onto french translation
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
we use penn treebank-style part-of-speech tags asa substrate for further enrichment (for all of the experiments described here, text was first tagged using the fntbl part-of-speech tagger (ngai and florian, 2001)).<papid> N01-1006 </papid></citsent>
<aftsection>
<nextsent>each penn tag is mapped to corepart-of-speech tag, which determines the set of fine grained tags further applicable to each word.
</nextsent>
<nextsent>thefine-grained tags applicable to nouns, verbs, and adjective are shown in table 1.
</nextsent>
<nextsent>this paper concentrates on these most important core parts-of-speech.the example english sentence in figure 1 illustrates several key points about our tagset.
</nextsent>
<nextsent>some ofthe information we are interested in is already expressed by the penn-style tags ? the nn titles is plu ral; the vbd were is in the past tense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2987">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> methods ? english tagging.  </section>
<citcontext>
<prevsection>
<prevsent>figure 3 shows example rules for some of these easier cases.the more difficult features are those whose detection requires some degree of syntactic analysis.
</prevsent>
<prevsent>these include case, which summarizes the relation of each noun with its governor, and the agreement based features: we define person, number, and case for attributive adjectives by agreement with their head nouns, number and person for verbs and predicate adjectives by agreement with their subjects, and tense for some verbs by agreement with their inflected auxiliaries.
</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
we investigated four individual approaches for the syntax-features ? regular-expression-basedquasi-parser, system based on dekang lins mini par (lin, 1993), <papid> P93-1016 </papid>system based on the collins parser (collins, 1999), and one based on the cmu link grammar parser (sleator and temperley, 1993), as well as family of voting-based combination schemes.</citsent>
<aftsection>
<nextsent>4.1 regular-expression quasi-parser.
</nextsent>
<nextsent>the regular-expression quasi-parser?
</nextsent>
<nextsent>takes direct approach, using several dozen heuristics based on regular-expression-like patterns over words, penn part-of-speech tags, and the output of the fntblnoun chunker.
</nextsent>
<nextsent>use of the noun chunker facilitates identification of noun/dependent relationships within chunks, and extends the range of patterns identifying noun/governor relationships across chunks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2991">
<title id=" W05-0807.xml">induction of fine grained partofspeech taggers via classifier combination and cross lingual projection </title>
<section> cross-lingual pos tag projection and.  </section>
<citcontext>
<prevsection>
<prevsent>table 4 shows results under both of these assumptions.
</prevsent>
<prevsent>for french, the training data was 15 million words from the canadian hansards.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
word alignments were produced using giza++ (och and ney, 2000) <papid> P00-1056 </papid>set to produce maximum of one english word link for each french word (i.e., french-to english model).</citsent>
<aftsection>
<nextsent>the test data was 111,000 words of text from the laboratoire de recherche appliquee en linguistique informatique at the universite?
</nextsent>
<nextsent>de montreal, annotated with person, number, and tense.
</nextsent>
<nextsent>suffix pr(plural
</nextsent>
<nextsent>suffix) pr(singular
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2992">
<title id=" W05-0631.xml">semantic role labeling using libsvm </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>instead, we combined the binary classifiers in our own post-processing phase to get labeling satisfying the constraints of the problem.
</prevsent>
<prevsent>2.3 the identifier classifier features.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
one aspect of our work was to use fewer features for the identifier classifier than the basic feature set from (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>the intuition behind the reduction is that whether constituent in the tree is an argument depends primarily on the structure and is independent of the lexical items of the predicate and headword.
</nextsent>
<nextsent>this reduced feature set is: phrase type: the phrase label of the argument.
</nextsent>
<nextsent>position: whether the phrase is before or after the predicate.
</nextsent>
<nextsent>voice: whether the predicate is inactive or passive voice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2993">
<title id=" W06-0306.xml">searching for sentences expressing opinions by using declaratively subjective clues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with open-domain topics, sentences expressing sentiments should not be searched exclusively; other kinds of opinion expressing sentences should be searched as well.
</prevsent>
<prevsent>the goal of our research is to achieve web search engine that locates opinion-expressing sentences about open-domain topics on products, persons, events, projects, and social phenomena.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
sentence-level subjectivity/objectivity classification in some of the previous research (riloff and wiebe, 2003; <papid> W03-1014 </papid>wiebe and riloff, 2005) can identify subjective statements that include speculation in addition to positive/negative evaluations.</citsent>
<aftsection>
<nextsent>in these efforts, the subjectivity/objectivity of current sentence is judged based on the existence of subjective/objective clues in both the sentence itself and the neighboring sentences.
</nextsent>
<nextsent>the subjective clues, some adjective, some noun, and some verb phrases, as well as other collocations, are learned from corpora (wiebe, 2000; wiebe et al, 2001).
</nextsent>
<nextsent>some of the clues express subjective meaning unrestricted to positive/negative measurements.
</nextsent>
<nextsent>the sentence-level subjectivity ap 39 proach suggests way of searching for opinion expressing sentences in the open domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2994">
<title id=" W06-0306.xml">searching for sentences expressing opinions by using declaratively subjective clues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for user to read.
</prevsent>
<prevsent>according to the work of wiebe et al (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
in analyzing opinions (cardie et al, 2003; wilson et al, 2004), judging document-level subjectivity (pang et al, 2002; <papid> W02-1011 </papid>tur ney, 2002), <papid> P02-1053 </papid>and answering opinion questions (cardie et al, 2003; yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>the output of sentence-level subjectivity classification can be used without modification.</citsent>
<aftsection>
<nextsent>however, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that user can survey them without difficulty.
</nextsent>
<nextsent>while it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (kim and hovy, 2004).<papid> C04-1200 </papid></nextsent>
<nextsent>this study introduces the notion of declara tively subjective clues as criterion for judging whether sentence expresses an opinion and proposes method for finding opinion expressing sentences that uses these clues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2995">
<title id=" W06-0306.xml">searching for sentences expressing opinions by using declaratively subjective clues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for user to read.
</prevsent>
<prevsent>according to the work of wiebe et al (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
in analyzing opinions (cardie et al, 2003; wilson et al, 2004), judging document-level subjectivity (pang et al, 2002; <papid> W02-1011 </papid>tur ney, 2002), <papid> P02-1053 </papid>and answering opinion questions (cardie et al, 2003; yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>the output of sentence-level subjectivity classification can be used without modification.</citsent>
<aftsection>
<nextsent>however, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that user can survey them without difficulty.
</nextsent>
<nextsent>while it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (kim and hovy, 2004).<papid> C04-1200 </papid></nextsent>
<nextsent>this study introduces the notion of declara tively subjective clues as criterion for judging whether sentence expresses an opinion and proposes method for finding opinion expressing sentences that uses these clues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2996">
<title id=" W06-0306.xml">searching for sentences expressing opinions by using declaratively subjective clues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for user to read.
</prevsent>
<prevsent>according to the work of wiebe et al (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
in analyzing opinions (cardie et al, 2003; wilson et al, 2004), judging document-level subjectivity (pang et al, 2002; <papid> W02-1011 </papid>tur ney, 2002), <papid> P02-1053 </papid>and answering opinion questions (cardie et al, 2003; yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>the output of sentence-level subjectivity classification can be used without modification.</citsent>
<aftsection>
<nextsent>however, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that user can survey them without difficulty.
</nextsent>
<nextsent>while it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (kim and hovy, 2004).<papid> C04-1200 </papid></nextsent>
<nextsent>this study introduces the notion of declara tively subjective clues as criterion for judging whether sentence expresses an opinion and proposes method for finding opinion expressing sentences that uses these clues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2997">
<title id=" W06-0306.xml">searching for sentences expressing opinions by using declaratively subjective clues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in analyzing opinions (cardie et al, 2003; wilson et al, 2004), judging document-level subjectivity (pang et al, 2002; <papid> W02-1011 </papid>tur ney, 2002), <papid> P02-1053 </papid>and answering opinion questions (cardie et al, 2003; yu and hatzivassiloglou, 2003), <papid> W03-1017 </papid>the output of sentence-level subjectivity classification can be used without modification.</prevsent>
<prevsent>however, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that user can survey them without difficulty.</prevsent>
</prevsection>
<citsent citstr=" C04-1200 ">
while it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (kim and hovy, 2004).<papid> C04-1200 </papid></citsent>
<aftsection>
<nextsent>this study introduces the notion of declara tively subjective clues as criterion for judging whether sentence expresses an opinion and proposes method for finding opinion expressing sentences that uses these clues.
</nextsent>
<nextsent>declaratively subjective clues such as the subjective predicate part of the main clause and subjective sentential adverb phrases suggest that the writer is the source of the opinion.
</nextsent>
<nextsent>we hypothesize that user of such an opinion-expressing sentence?
</nextsent>
<nextsent>search wants to read the writers opinions and that explicitly stated opinions are preferred over quoted or implicational opinions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2998">
<title id=" W05-0822.xml">portage a phrase based machine translation system </title>
<section> portage.  </section>
<citcontext>
<prevsection>
<prevsent>the phrase-based translation model is similar to the one described in (koehn, 2004), and relies on symmetrized ibm model 2 word-alignments for phrase pair induction.
</prevsent>
<prevsent>the distortion model is also very similar to koehns, with the exception of final cost to account for sentence endings.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
sto set weights on the components of the loglinear model, we implemented ochs algorithm (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>this essentially involves generating, in an iterative process, set of nbest translation hypotheses that are representative of the entire search space forgiven set of source sentences.
</nextsent>
<nextsent>once this is accomplished, variant of powells algorithm is used to find weights that optimize bleu score (papineni et al 2002) <papid> P02-1040 </papid>over these hypotheses, compared to reference translations.</nextsent>
<nextsent>unfortunately, our implementation of this algorithm converged only very slowly to satisfactory final nbest list, so we used two different ad hoc strategies for setting weights: choosing the best values encountered during , with the exception of ch as the ability to decode either ards.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB2999">
<title id=" W05-0822.xml">portage a phrase based machine translation system </title>
<section> portage.  </section>
<citcontext>
<prevsection>
<prevsent>sto set weights on the components of the loglinear model, we implemented ochs algorithm (och, 2003).<papid> P03-1021 </papid></prevsent>
<prevsent>this essentially involves generating, in an iterative process, set of nbest translation hypotheses that are representative of the entire search space forgiven set of source sentences.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
once this is accomplished, variant of powells algorithm is used to find weights that optimize bleu score (papineni et al 2002) <papid> P02-1040 </papid>over these hypotheses, compared to reference translations.</citsent>
<aftsection>
<nextsent>unfortunately, our implementation of this algorithm converged only very slowly to satisfactory final nbest list, so we used two different ad hoc strategies for setting weights: choosing the best values encountered during , with the exception of ch as the ability to decode either ards.
</nextsent>
<nextsent>transla rent language pairs of the sha t hared - the iterations of ochs algorithm (french english), and grid search (all other languages).
</nextsent>
<nextsent>to perform the actual translation, we used our decoder, canoe, which implements dynamic programming beam search algorithm based on that of pharaoh (koehn, 2004).
</nextsent>
<nextsent>canoe is input-output compatible with pharaoh few extensions su back ards or forw 2.3 rescoring.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3000">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language parse trees are not readilyrepresentable in this form, and the choice of representation is extremely important for the success of machine learning algorithms.
</prevsent>
<prevsent>for large class of machine learning algorithms, such an explicit representation is not necessary, and it suffices to devise kernel function
</prevsent>
</prevsection>
<citsent citstr=" W03-0402 ">
which measures the similarity between inputs  and  . in addition to achieving efficient computation in high dimensional representation spaces, the use of kernels allows for an alternative view on the modelling problem as defining similarity between inputs rather than set of relevant features.in previous work on discriminative natural language parsing, one approach has been to define features centered around lexicalized local rules in the trees (collins, 2000; shen and joshi, 2003), <papid> W03-0402 </papid>similar to the features of the best performing lexicalized generative parsing models (charniak, 2000; <papid> A00-2018 </papid>collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>additionally non-local features have been defined measuring e.g. parallelism and complexity of phrases in discriminative log-linear parse ranking models (riezler et al, 2000).<papid> P00-1061 </papid></nextsent>
<nextsent>another approach has been to define tree kernels:for example, in (collins and duffy, 2001), the all subtrees representation of parse trees (bod, 1998) is effectively utilized by the application of fast dynamic programming algorithm for computing the number of common subtrees of two trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3001">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language parse trees are not readilyrepresentable in this form, and the choice of representation is extremely important for the success of machine learning algorithms.
</prevsent>
<prevsent>for large class of machine learning algorithms, such an explicit representation is not necessary, and it suffices to devise kernel function
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
which measures the similarity between inputs  and  . in addition to achieving efficient computation in high dimensional representation spaces, the use of kernels allows for an alternative view on the modelling problem as defining similarity between inputs rather than set of relevant features.in previous work on discriminative natural language parsing, one approach has been to define features centered around lexicalized local rules in the trees (collins, 2000; shen and joshi, 2003), <papid> W03-0402 </papid>similar to the features of the best performing lexicalized generative parsing models (charniak, 2000; <papid> A00-2018 </papid>collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>additionally non-local features have been defined measuring e.g. parallelism and complexity of phrases in discriminative log-linear parse ranking models (riezler et al, 2000).<papid> P00-1061 </papid></nextsent>
<nextsent>another approach has been to define tree kernels:for example, in (collins and duffy, 2001), the all subtrees representation of parse trees (bod, 1998) is effectively utilized by the application of fast dynamic programming algorithm for computing the number of common subtrees of two trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3002">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language parse trees are not readilyrepresentable in this form, and the choice of representation is extremely important for the success of machine learning algorithms.
</prevsent>
<prevsent>for large class of machine learning algorithms, such an explicit representation is not necessary, and it suffices to devise kernel function
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
which measures the similarity between inputs  and  . in addition to achieving efficient computation in high dimensional representation spaces, the use of kernels allows for an alternative view on the modelling problem as defining similarity between inputs rather than set of relevant features.in previous work on discriminative natural language parsing, one approach has been to define features centered around lexicalized local rules in the trees (collins, 2000; shen and joshi, 2003), <papid> W03-0402 </papid>similar to the features of the best performing lexicalized generative parsing models (charniak, 2000; <papid> A00-2018 </papid>collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>additionally non-local features have been defined measuring e.g. parallelism and complexity of phrases in discriminative log-linear parse ranking models (riezler et al, 2000).<papid> P00-1061 </papid></nextsent>
<nextsent>another approach has been to define tree kernels:for example, in (collins and duffy, 2001), the all subtrees representation of parse trees (bod, 1998) is effectively utilized by the application of fast dynamic programming algorithm for computing the number of common subtrees of two trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3003">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for large class of machine learning algorithms, such an explicit representation is not necessary, and it suffices to devise kernel function
</prevsent>
<prevsent> which measures the similarity between inputs  and  . in addition to achieving efficient computation in high dimensional representation spaces, the use of kernels allows for an alternative view on the modelling problem as defining similarity between inputs rather than set of relevant features.in previous work on discriminative natural language parsing, one approach has been to define features centered around lexicalized local rules in the trees (collins, 2000; shen and joshi, 2003), <papid> W03-0402 </papid>similar to the features of the best performing lexicalized generative parsing models (charniak, 2000; <papid> A00-2018 </papid>collins, 1997).<papid> P97-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
additionally non-local features have been defined measuring e.g. parallelism and complexity of phrases in discriminative log-linear parse ranking models (riezler et al, 2000).<papid> P00-1061 </papid></citsent>
<aftsection>
<nextsent>another approach has been to define tree kernels:for example, in (collins and duffy, 2001), the all subtrees representation of parse trees (bod, 1998) is effectively utilized by the application of fast dynamic programming algorithm for computing the number of common subtrees of two trees.
</nextsent>
<nextsent>another tree kernel, more broadly applicable to hierarchical directed graphs, was proposed in (suzuki et al,2003).<papid> P03-1005 </papid></nextsent>
<nextsent>many other interesting kernels have been devised for sequences and trees, with application to sequence classification and parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3004">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>additionally non-local features have been defined measuring e.g. parallelism and complexity of phrases in discriminative log-linear parse ranking models (riezler et al, 2000).<papid> P00-1061 </papid></prevsent>
<prevsent>another approach has been to define tree kernels:for example, in (collins and duffy, 2001), the all subtrees representation of parse trees (bod, 1998) is effectively utilized by the application of fast dynamic programming algorithm for computing the number of common subtrees of two trees.</prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
another tree kernel, more broadly applicable to hierarchical directed graphs, was proposed in (suzuki et al,2003).<papid> P03-1005 </papid></citsent>
<aftsection>
<nextsent>many other interesting kernels have been devised for sequences and trees, with application to sequence classification and parsing.
</nextsent>
<nextsent>a good overview of kernels for structured data can be found in (gaert ner et al, 2002).
</nextsent>
<nextsent>here we propose new representation of parse trees which (i) allows the localization of broader useful context, (ii) paves the way for exploring kernels, and (iii) achieves superior disambiguation accuracy compared to models that use tree representations centered around context-free rules.
</nextsent>
<nextsent>compared to the usual notion of discriminative models (placing classes on rich observed data) discriminative pcfg parsing with plain context free rule features may look naive, since most of the features (in particular tree) make no reference to observed input at all.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3005">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this representation of trees as lists of projection imper verb hcompverb hcompverb let v1 let us us hcomp verb plan on v2 plan hcomp prep* on on that deix that figure 1: derivation tree for the sentence let us plan on that.
</prevsent>
<prevsent>paths (strings) allows us to explore string kernels on these paths and combine them into tree kernels.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
we apply these ideas in the context of parse disambiguation for sentence analyses produced by head-driven phrase structure grammar (hpsg), the grammar formalism underlying the redwoods corpus (oepen et al, 2002).<papid> C02-2025 </papid></citsent>
<aftsection>
<nextsent>hpsg is modernconstraint-based lexical ist (or unification?)
</nextsent>
<nextsent>grammar formalism.1 we build discriminative models using support vector machines for ranking(joachims, 1999).
</nextsent>
<nextsent>we compare our proposed representation to previous approaches and show that it leads to substantial improvements inaccuracy.
</nextsent>
<nextsent>trees 2.1 representing hpsg signs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3006">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> the leaf projection paths view of parse.  </section>
<citcontext>
<prevsection>
<prevsent>we compare our proposed representation to previous approaches and show that it leads to substantial improvements inaccuracy.
</prevsent>
<prevsent>trees 2.1 representing hpsg signs.
</prevsent>
</prevsection>
<citsent citstr=" W02-2030 ">
in hpsg, sentence analyses are given in the form of hpsg signs, which are large feature structures containing information about syntactic and semantic properties of the phrases.as in some of the previous work on the redwoods corpus (toutanova et al, 2002; toutanova and manning, 2002), <papid> W02-2030 </papid>we use the derivation trees asthe main representation for disambiguation.</citsent>
<aftsection>
<nextsent>derivation trees record the combining rule schemas of the hpsg grammar which were used to license the sign by combining initial lexical types.
</nextsent>
<nextsent>the derivation tree is also the fundamental data stored in the redwoods treebank, since the full sign canbe reconstructed from it by reference to the grammar. the internal nodes represent, for example, head-complement, head-specifier, and head-adjunct schemas, which were used to license larger signs out of component parts.
</nextsent>
<nextsent>a derivation tree for the 1for an introduction to hpsg, see (pollard and sag, 1994).
</nextsent>
<nextsent>imper verb hcomp verb hcomp verb let v1 let (v sorb) imper verb hcomp verb hcomp verb plan on v2 plan (v p itrs) imper verb hcomp verb hcomp verb hcomp prep* on on (p reg) figure 2: paths to top for three leaves.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3012">
<title id=" W04-3222.xml">the leaf path projection view of parse trees exploring string kernels for hpsg parse selection </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>it is possible to convert the ranking problem into classification problem using pairs of trees as shown in (shen and joshi, 2003).<papid> W03-0402 </papid></prevsent>
<prevsent>we have taken this approach in more recent work using string kernels requiring very expensive feature maps.</prevsent>
</prevsection>
<citsent citstr=" N04-1012 ">
we performed experiments using the version of the redwoods corpus which was also used in thework of (toutanova et al, 2002; osborne and bald bridge, 2004) <papid> N04-1012 </papid>and others.</citsent>
<aftsection>
<nextsent>there are  ffi
</nextsent>
<nextsent>  annotated sentences in total, ffi % of which are ambiguous.
</nextsent>
<nextsent>the average sentence length of the ambiguous sentences is     words and the average number of parses per sentence is
</nextsent>
<nextsent> . we discarded theun ambiguous sentences from the training and test sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3014">
<title id=" W05-0830.xml">deploying partofspeech patterns to enhance statistical phrase based machine translation resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech patterns extracted from parallel corpora have been used to enhance translation resource for statistical phrase-based machine translation.
</prevsent>
<prevsent>the use of structural and syntactic information in language processing implementations in recent years has been producing contradictory results.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
whereas language generation has benefited from syntax [wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000], <papid> J00-1004 </papid>the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003].<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we carry out set of experiments to explore whether heuristic learning of part-of-speech patterns from parallel corpus can be used to enhance phrase-based translation resources.
</nextsent>
<nextsent>the resources used for our experiments are as follows.
</nextsent>
<nextsent>the statistical machine translation giza++ toolkit was used to generate bilingual translation table from the french-english parallel and sen tence-aligned europarl corpus.
</nextsent>
<nextsent>additionally, phrase table generated from the europarl french english corpus, and training test set of 2000 french and english sentences that were made available on the webpage of the acl 2005 workshop1 were also used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3015">
<title id=" W05-0830.xml">deploying partofspeech patterns to enhance statistical phrase based machine translation resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech patterns extracted from parallel corpora have been used to enhance translation resource for statistical phrase-based machine translation.
</prevsent>
<prevsent>the use of structural and syntactic information in language processing implementations in recent years has been producing contradictory results.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
whereas language generation has benefited from syntax [wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000], <papid> J00-1004 </papid>the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003].<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we carry out set of experiments to explore whether heuristic learning of part-of-speech patterns from parallel corpus can be used to enhance phrase-based translation resources.
</nextsent>
<nextsent>the resources used for our experiments are as follows.
</nextsent>
<nextsent>the statistical machine translation giza++ toolkit was used to generate bilingual translation table from the french-english parallel and sen tence-aligned europarl corpus.
</nextsent>
<nextsent>additionally, phrase table generated from the europarl french english corpus, and training test set of 2000 french and english sentences that were made available on the webpage of the acl 2005 workshop1 were also used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3016">
<title id=" W05-0830.xml">deploying partofspeech patterns to enhance statistical phrase based machine translation resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part-of-speech patterns extracted from parallel corpora have been used to enhance translation resource for statistical phrase-based machine translation.
</prevsent>
<prevsent>the use of structural and syntactic information in language processing implementations in recent years has been producing contradictory results.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
whereas language generation has benefited from syntax [wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000], <papid> J00-1004 </papid>the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003].<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we carry out set of experiments to explore whether heuristic learning of part-of-speech patterns from parallel corpus can be used to enhance phrase-based translation resources.
</nextsent>
<nextsent>the resources used for our experiments are as follows.
</nextsent>
<nextsent>the statistical machine translation giza++ toolkit was used to generate bilingual translation table from the french-english parallel and sen tence-aligned europarl corpus.
</nextsent>
<nextsent>additionally, phrase table generated from the europarl french english corpus, and training test set of 2000 french and english sentences that were made available on the webpage of the acl 2005 workshop1 were also used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3020">
<title id=" W05-0830.xml">deploying partofspeech patterns to enhance statistical phrase based machine translation resources </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, it should be clarified that there is no statistical, linguistic, or other reason why we chose to adopt the english version of the penn treebank tagset over the french, as they are both equally conclusive and transparent.
</prevsent>
<prevsent>the overall driving force behind our investigation has been to test whether part-of-speech structures can be of assistance to the enhancement of translation resources for statistical phrase-based machine translation.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
we view our use of part-ofspeech patterns as natural extension to the introduction of structural elements to statistical machine translation by wang [1998] and och et al [1999].<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>165our empirical results suggest that the use of partof-speech pattern correspondences to enhance existing translation resources does not damage machine translation performance.
</nextsent>
<nextsent>what remains to be investigated is how this approach can be optimized, and how it would respond to known statistical machine translation issues, such as mapping nested structures, or the handling of unorthodox?
</nextsent>
<nextsent>language pairs, i.e. agglutinative-fusion languages.
</nextsent>
<nextsent>syntactic and structural language information contained in bilingual parallel corpus has been extracted and used to refine the translation probability values of translation phrase table, using simple heuristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3021">
<title id=" W05-0603.xml">search engine statistics beyond the ngram application to noun compound bracketing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we have evaluated the application of combinations of these features to predict nc bracketing on two distinct collections, one consisting of terms drawn from encyclopedia text, and another drawn from bioscience text.
</prevsent>
<prevsent>the remainder of this paper describes related work, the word association models, the surface features, the paraphrase features and the results.
</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
the syntax and semantics of ncs is an active area ofresearch; the journal of computer speech and language has an upcoming special issue on multiword expressions.the best known early work on automated unsupervised nc bracketing is that of lauer (1995) who introduces the probabilistic dependency model for the syntactic disambiguation of ncs and argues against the adjacency model, proposed by marcus (1980), pustejovsky et al (1993) <papid> J93-2005 </papid>and resnik (1993).lauer collects n-gram statistics from groliers encyclopedia, containing about 8 million words.</citsent>
<aftsection>
<nextsent>to 17overcome data sparsity problems, he estimates probabilities over conceptual categories in taxonomy (rogets thesaurus) rather than for individual words.lauer evaluated his models on set of 244 unambiguous ncs derived from the same encyclopedia (inter-annotator agreement 81.50%) and achieved 77.50% for the dependency model above (baseline 66.80%).
</nextsent>
<nextsent>adding pos and further tuning allowed him to achieve the state-of-the-art result of 80.70%.more recently, keller and lapata (2003) <papid> J03-3005 </papid>evaluate the utility of using web search engines for obtaining frequencies for unseen bigrams.</nextsent>
<nextsent>they then later propose using web counts as baseline unsupervised method for many nlp tasks (lapata and keller, 2004).<papid> N04-1016 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3022">
<title id=" W05-0603.xml">search engine statistics beyond the ngram application to noun compound bracketing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the syntax and semantics of ncs is an active area ofresearch; the journal of computer speech and language has an upcoming special issue on multiword expressions.the best known early work on automated unsupervised nc bracketing is that of lauer (1995) who introduces the probabilistic dependency model for the syntactic disambiguation of ncs and argues against the adjacency model, proposed by marcus (1980), pustejovsky et al (1993) <papid> J93-2005 </papid>and resnik (1993).lauer collects n-gram statistics from groliers encyclopedia, containing about 8 million words.</prevsent>
<prevsent>to 17overcome data sparsity problems, he estimates probabilities over conceptual categories in taxonomy (rogets thesaurus) rather than for individual words.lauer evaluated his models on set of 244 unambiguous ncs derived from the same encyclopedia (inter-annotator agreement 81.50%) and achieved 77.50% for the dependency model above (baseline 66.80%).</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
adding pos and further tuning allowed him to achieve the state-of-the-art result of 80.70%.more recently, keller and lapata (2003) <papid> J03-3005 </papid>evaluate the utility of using web search engines for obtaining frequencies for unseen bigrams.</citsent>
<aftsection>
<nextsent>they then later propose using web counts as baseline unsupervised method for many nlp tasks (lapata and keller, 2004).<papid> N04-1016 </papid></nextsent>
<nextsent>they apply this idea to six nlp tasks,including the syntactic and semantic disambiguation of ncs following lauer (1995), and show that variations on bigram counts perform nearly as wellas more elaborate methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3024">
<title id=" W05-0603.xml">search engine statistics beyond the ngram application to noun compound bracketing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to 17overcome data sparsity problems, he estimates probabilities over conceptual categories in taxonomy (rogets thesaurus) rather than for individual words.lauer evaluated his models on set of 244 unambiguous ncs derived from the same encyclopedia (inter-annotator agreement 81.50%) and achieved 77.50% for the dependency model above (baseline 66.80%).
</prevsent>
<prevsent>adding pos and further tuning allowed him to achieve the state-of-the-art result of 80.70%.more recently, keller and lapata (2003) <papid> J03-3005 </papid>evaluate the utility of using web search engines for obtaining frequencies for unseen bigrams.</prevsent>
</prevsection>
<citsent citstr=" N04-1016 ">
they then later propose using web counts as baseline unsupervised method for many nlp tasks (lapata and keller, 2004).<papid> N04-1016 </papid></citsent>
<aftsection>
<nextsent>they apply this idea to six nlp tasks,including the syntactic and semantic disambiguation of ncs following lauer (1995), and show that variations on bigram counts perform nearly as wellas more elaborate methods.
</nextsent>
<nextsent>they do not use tax onomies and work with the word n-grams directly, achieving 78.68% with much simpler version of the dependency model.
</nextsent>
<nextsent>girju et al (2005) propose supervised model (decision tree) for nc bracketing in context, based on five semantic features (requiring the correct wordnet sense to be given): the top three wordnet semantic classes for each noun, derivationallyrelated forms and whether the noun is nominaliza tion.
</nextsent>
<nextsent>the algorithm achieves accuracy of 83.10%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3034">
<title id=" W05-1208.xml">a probabilistic setting and lexical coocurrence model for textual entailment </title>
<section> harry birthplace is iowa.  </section>
<citcontext>
<prevsection>
<prevsent>d) an important feature of the proposed framework is that forgiven text many hypotheses are likely to be true.
</prevsent>
<prevsent>consequently, forgiven text and hypothesis h, hp(trh=1|t) does not sum to 1.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
this differs from typical generative settings for ir and mt (ponte and croft, 1998; brown et al, 1993), <papid> J93-2003 </papid>where all conditioned events are disjoint by construction.</citsent>
<aftsection>
<nextsent>in the proposed model, it is rather the case that p(trh=1|t) + p(trh=0|t) = 1, as we are interested in the probability that single particular hypothesis is true (or false).
</nextsent>
<nextsent>e) an implemented model that corresponds to our probabilistic setting is expected to produce an estimate for p(trh = 1| t).
</nextsent>
<nextsent>this estimate is expected to reflect all probabilistic aspects involved in the modeling, including inherent uncertainty of the entailment inference itself (as in example 2 of table 1), possible uncertainty regarding the correct disambiguation of the text (example 4), as well as probabilistic estimates that stem from the particular model structure.
</nextsent>
<nextsent>3 lexical entailment model we suggest that the proposed setting above provides the necessary grounding for probabilistic 1 this seems to be the case, when analyzing the results of entering the above text in web search engine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3036">
<title id=" W05-0703.xml">morphological analysis and generation for arabic dialects </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, we add two general requirements for morphological analyzers.
</prevsent>
<prevsent>first, we want both morphological analyzer and morphological generator.second, we want to use representation that is defined in terms of lexeme and attribute-value pairs for morphological features such as aspect or person.this is because we want our component to be usable in natural language processing (nlp) applications such as natural language generation and machine translation, and the lexeme provides usable lexicographic abstraction.
</prevsent>
</prevsection>
<citsent citstr=" J00-1006 ">
we tackle these requirements by implementing the multitape approach of kiraz (2000), <papid> J00-1006 </papid>which we 17extend by adding an additional tape for independently modeling phonology and orthography.</citsent>
<aftsection>
<nextsent>this is the first large-scale implementation of (kiraz, 2000).<papid> J00-1006 </papid></nextsent>
<nextsent>we use the at&t; finite-state toolkit (mohri et al, 1998) for the implementation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3040">
<title id=" W05-0703.xml">morphological analysis and generation for arabic dialects </title>
<section> morphological analysis of arabic.  </section>
<citcontext>
<prevsection>
<prevsent>kataja and koskenniemi (1988) presented system for handling akkadian root-and-pattern morphology by adding additional lexicon component to koskenniemis two-level morphology (1983).
</prevsent>
<prevsent>the first large scale implementation of arabic morphology within the constraints of finite-state methods was that of beesley et al (1989)with detouring?
</prevsent>
</prevsection>
<citsent citstr=" W98-1007 ">
mechanism for access to multiple lexica, which later gave rise to other works by beesley (beesley, 1998) <papid> W98-1007 </papid>and, independently, by buckwalter (2004).the now ubiquitous linguistic approach of mccarthy (1981) to describe root-and-pattern morphol 7this example is transcript of broadcast originally taken from the al-jazeera web site.</citsent>
<aftsection>
<nextsent>it can now be found at http://web.archive.org/web/20030210100557/www.aljazeera.net/ programs/century witness/articles/2003/1/1-24-1.htm . 20ogy under the framework of auto segmental phonology gave rise to number of computational proposals.
</nextsent>
<nextsent>kay (1987) <papid> E87-1002 </papid>devised framework with which each of the auto segmental tiers is assigned tapein multi-tape finite state machine, with an additional tape for the surface form.</nextsent>
<nextsent>kiraz (2000), <papid> J00-1006 </papid>kiraz (2001)extended kays approach and implemented working multi-tape system with pilot grammars for arabic and syriac.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3041">
<title id=" W05-0703.xml">morphological analysis and generation for arabic dialects </title>
<section> morphological analysis of arabic.  </section>
<citcontext>
<prevsection>
<prevsent>mechanism for access to multiple lexica, which later gave rise to other works by beesley (beesley, 1998) <papid> W98-1007 </papid>and, independently, by buckwalter (2004).the now ubiquitous linguistic approach of mccarthy (1981) to describe root-and-pattern morphol 7this example is transcript of broadcast originally taken from the al-jazeera web site.</prevsent>
<prevsent>it can now be found at http://web.archive.org/web/20030210100557/www.aljazeera.net/ programs/century witness/articles/2003/1/1-24-1.htm . 20ogy under the framework of auto segmental phonology gave rise to number of computational propos als.</prevsent>
</prevsection>
<citsent citstr=" E87-1002 ">
kay (1987) <papid> E87-1002 </papid>devised framework with which each of the auto segmental tiers is assigned tapein multi-tape finite state machine, with an additional tape for the surface form.</citsent>
<aftsection>
<nextsent>kiraz (2000), <papid> J00-1006 </papid>kiraz (2001)extended kays approach and implemented working multi-tape system with pilot grammars for arabic and syriac.</nextsent>
<nextsent>other auto segmental approaches (described in more details in kiraz 2001 (chapter 4)) include those of kornai (1995), bird and ellison(1994), pulman and hepple (1993), whose formalism kiraz adopted, and others.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3047">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experimental results show that the proposed model representation drastically improves the efficiency of decoding compared to the dynamic composition of the sub models, which corresponds to conventional approaches.
</prevsent>
<prevsent>recently, research on statistical machine translation has grown along with the increase in computational power as well as the amount of bilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the basic idea of modeling machine translation was proposed by brown et al (1993), <papid> J93-2003 </papid>who assumed that machine translation can be modeled on noisy chan nels.</citsent>
<aftsection>
<nextsent>the source language is encoded from target language by noisy channel, and translation is performed as decoding process from source language to target language.knight (1999) <papid> J99-4005 </papid>showed that the translation problem defined by brown et al (1993) <papid> J93-2003 </papid>is npcomplete.</nextsent>
<nextsent>therefore, with this model it is almost impossible to search for optimal solutions inthe decoding process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3048">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, research on statistical machine translation has grown along with the increase in computational power as well as the amount of bilingual corpora.
</prevsent>
<prevsent>the basic idea of modeling machine translation was proposed by brown et al (1993), <papid> J93-2003 </papid>who assumed that machine translation can be modeled on noisy chan nels.</prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
the source language is encoded from target language by noisy channel, and translation is performed as decoding process from source language to target language.knight (1999) <papid> J99-4005 </papid>showed that the translation problem defined by brown et al (1993) <papid> J93-2003 </papid>is npcomplete.</citsent>
<aftsection>
<nextsent>therefore, with this model it is almost impossible to search for optimal solutions inthe decoding process.
</nextsent>
<nextsent>several studies have proposed methods for searching sub optimal solutions.berger et al (1996) and och et al (2001) <papid> W01-1408 </papid>proposed such depth-first search methods as stack de coders.</nextsent>
<nextsent>wand and waibel (1997) and tillmann and ney (2003) <papid> J03-1005 </papid>proposed breadth-first search methods, i.e. beam search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3050">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the source language is encoded from target language by noisy channel, and translation is performed as decoding process from source language to target language.knight (1999) <papid> J99-4005 </papid>showed that the translation problem defined by brown et al (1993) <papid> J93-2003 </papid>is npcomplete.</prevsent>
<prevsent>therefore, with this model it is almost impossible to search for optimal solutions inthe decoding process.</prevsent>
</prevsection>
<citsent citstr=" W01-1408 ">
several studies have proposed methods for searching sub optimal solutions.berger et al (1996) and och et al (2001) <papid> W01-1408 </papid>proposed such depth-first search methods as stack de coders.</citsent>
<aftsection>
<nextsent>wand and waibel (1997) and tillmann and ney (2003) <papid> J03-1005 </papid>proposed breadth-first search methods, i.e. beam search.</nextsent>
<nextsent>germann (2001) and watanabe and sumita (2003) proposed greedy type decoding methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3051">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, with this model it is almost impossible to search for optimal solutions inthe decoding process.
</prevsent>
<prevsent>several studies have proposed methods for searching sub optimal solutions.berger et al (1996) and och et al (2001) <papid> W01-1408 </papid>proposed such depth-first search methods as stack de coders.</prevsent>
</prevsection>
<citsent citstr=" J03-1005 ">
wand and waibel (1997) and tillmann and ney (2003) <papid> J03-1005 </papid>proposed breadth-first search methods, i.e. beam search.</citsent>
<aftsection>
<nextsent>germann (2001) and watanabe and sumita (2003) proposed greedy type decoding methods.
</nextsent>
<nextsent>in all of these search algorithms, better representation of the statistical model in systems can improve the search efficiency.
</nextsent>
<nextsent>for model representation, search method based on weighted finite-state transducer (wfst) (mohri et al, 2002) has achieved great success in the speech recognition field.
</nextsent>
<nextsent>the basic idea is that each statistical model is represented by wfst and they are composed beforehand; the composed model is optimized by wfst operations such as determiniza tion and minimization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3052">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however,wfst optimization operations such as determinization are nearly impossible to apply to wfsts in machine translation because they are much more ambiguous than speech recognition.
</prevsent>
<prevsent>to reduce the ambiguity, we propose wfst optimization method that considers the statistics of hypotheses while de coding.some approaches have applied wfst to statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" N01-1018 ">
knight and al onaizan (1998) proposed the representation ofibm model 3 with wfsts; bangalore andric cardi (2001) <papid> N01-1018 </papid>studied wfst models in call-routing tasks, and kumar and byrne (2003) <papid> N03-1019 </papid>modeled phrase-based translation by wfsts.</citsent>
<aftsection>
<nextsent>all of these studies mainly focused on the representation of each sub model used in machine translation.
</nextsent>
<nextsent>however, few studies have focued on the integration of each wfst sub model to improve the decoding efficiency of machine translation.
</nextsent>
<nextsent>to this end, we propose method that expands all of the sub models into composition model, reducing the ambiguity of the expanded model by the statistics of hypotheses while decoding.
</nextsent>
<nextsent>first, we explain the translation model (brown et al, 1993; <papid> J93-2003 </papid>knight and al-onaizan, 1998) that we used as abase for our decoding research.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3053">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however,wfst optimization operations such as determinization are nearly impossible to apply to wfsts in machine translation because they are much more ambiguous than speech recognition.
</prevsent>
<prevsent>to reduce the ambiguity, we propose wfst optimization method that considers the statistics of hypotheses while de coding.some approaches have applied wfst to statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1019 ">
knight and al onaizan (1998) proposed the representation ofibm model 3 with wfsts; bangalore andric cardi (2001) <papid> N01-1018 </papid>studied wfst models in call-routing tasks, and kumar and byrne (2003) <papid> N03-1019 </papid>modeled phrase-based translation by wfsts.</citsent>
<aftsection>
<nextsent>all of these studies mainly focused on the representation of each sub model used in machine translation.
</nextsent>
<nextsent>however, few studies have focued on the integration of each wfst sub model to improve the decoding efficiency of machine translation.
</nextsent>
<nextsent>to this end, we propose method that expands all of the sub models into composition model, reducing the ambiguity of the expanded model by the statistics of hypotheses while decoding.
</nextsent>
<nextsent>first, we explain the translation model (brown et al, 1993; <papid> J93-2003 </papid>knight and al-onaizan, 1998) that we used as abase for our decoding research.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3055">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> ambiguity reduction.  </section>
<citcontext>
<prevsection>
<prevsent>if the weight represents probability, thesum of the weights of output transitions may not be 1.0 after merging states, and then the condition of probability may be destroyed.
</prevsent>
<prevsent>since the decoder does not sumup all possible paths but searches for the most appropriate paths, this kind of state merging does not pose serious problem in practice.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
in the following experiment, we measured the association between states by   + in gale and church (1991).<papid> H91-1026 </papid></citsent>
<aftsection>
<nextsent>  + is t + -like statistic that is bounded between 0 and 1.
</nextsent>
<nextsent>if the   + of two states is higher than the specified threshold, these two states are merged.
</nextsent>
<nextsent>the definition of   +is as follows, where u
</nextsent>
<nextsent>v  :  +  , u
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3056">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in the forward beam-search, any hypothesis whose probability is lower than 0dcd0deof the top of the hypothesis list is pruned.
</prevsent>
<prevsent>in this experiment, permutation is restricted, and words can be moved 6 positions at most.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the translation model was trained by giza++ (och and ney, 2003), <papid> J03-1002 </papid>and the trigram was trained by the cmu-cambridge statistical language modeling toolkit v2 (clarkson and rosenfeld, 1997).for the experiment, we used japanese-toenglish bilingual corpus consisting of example sentences for rule-based machine translation system.</citsent>
<aftsection>
<nextsent>each language sentence is aligned in the corpus.
</nextsent>
<nextsent>the total number of sentence pairs is 20,204.
</nextsent>
<nextsent>we used 17,678 pairs for training and 2,526 pairs for the test.
</nextsent>
<nextsent>the average length of japanese sentences was 8.4 words, and that of english sentences was 6.7 words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3057">
<title id=" W04-3255.xml">efficient decoding for statistical machine translation with a fully expanded wfst model </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows the size of the wfsts used in the experiment.
</prevsent>
<prevsent>in these wfsts, special symbols that express beginning and end of sentence are added to the wfsts described in the previous section.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the nist score (doddington, 2002) and bleu score (papineni et al, 2002) <papid> P02-1040 </papid>were used to measure translation accuracy.table 2 shows the experimental results.</citsent>
<aftsection>
<nextsent>the full expansion model provided translations more than 10 times faster than conventional dynamic composition sub models without degrading accuracy.
</nextsent>
<nextsent>however, the nist scores are slightly different.
</nextsent>
<nextsent>in the course of composition, some paths that do not reach the final states are produced.
</nextsent>
<nextsent>in the full-expansion model these paths are trimmed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3058">
<title id=" W06-0102.xml">regional variation of domain specific lexical items toward a pan chinese lexical resource </title>
<section> existing resources and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the collins cobuild english dictionary (sinclair, 1987) is amongst the most well-known lexicographic fruit based on large corpora.
</prevsent>
<prevsent>for natural language applications, much of the information in conventional dictionaries targeted at human readers must be made explicit.
</prevsent>
</prevsection>
<citsent citstr=" C82-2013 ">
lexical resources for computer use thus need considerable manipulation, customisation, and supplementation (e.g. calzolari, 1982).<papid> C82-2013 </papid></citsent>
<aftsection>
<nextsent>wordnet (miller et al , 1990), grouping words into synsets and linking them up with relational pointers, is probably the first broad coverage general computational lexical database.
</nextsent>
<nextsent>in view of the intensive time and effort required in resource building, some researchers have taken an alternative route by extracting information from existing machine readable dictionaries and corpora semi automatically (e.g. vossen et al , 1989; riloff and shepherd, 1999; lin et al  2003).
</nextsent>
<nextsent>compared to the development of thesauri and lexical databases, and research into semantic networks for major languages such as english, similar work for the chinese language is less mature.
</nextsent>
<nextsent>this gap was partly due to the lack of authoritative chinese corpora as basis for analysis, but has been gradually reduced with the recent availability of large chinese corpora including the livac synchronous corpus (tsou and lai, 2003) used in this work and further described below, the sinica corpus (chen et al , 1996), the chinese penn treebank (xia et al , 2000), and the like.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3059">
<title id=" W05-1203.xml">measuring the semantic similarity of texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>measures of text similarity have been used for along time in applications in natural language processing and related areas.
</prevsent>
<prevsent>one of the earliest applications of text similarity is perhaps the vector ial model in information retrieval, where the document most relevant to an input query is determined by ranking documents in collection in reversed order of their similarity to the given query (salton and lesk, 1971).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
text similarity has been also used for relevance feedback and text classification (rocchio, 1971), word sense disambiguation (lesk, 1986), and more recently for extractive summarization (salton et al, 1997b), and methods for automatic evaluation of machine translation (papineni et al, 2002) <papid> P02-1040 </papid>or text summarization (lin and hovy, 2003).<papid> N03-1020 </papid>the typical approach to finding the similarity between two text segments is to use simple lexical matching method, and produce similarity score based on the number of lexical units that occur in both input segments.</citsent>
<aftsection>
<nextsent>improvements to this simple method have considered stemming, stop-word removal, part-of-speech tagging, longest subsequencematching, as well as various weighting and normalization factors (salton et al, 1997a).
</nextsent>
<nextsent>while successful to certain degree, these lexical matching similarity methods fail to identify the semantic similarity of texts.
</nextsent>
<nextsent>for instance, there is an obvious similarity between the text segments own dog and have an animal, but most of the current text similarity metrics will fail in identifying any kind of connection between these texts.
</nextsent>
<nextsent>the only exception to this trend is perhaps the latent semantic analysis (lsa) method (landauer et al, 1998), which represent san improvement over earlier attempts to use measures of semantic similarity for information retrieval (voorhees, 1993), (xu and croft, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3060">
<title id=" W05-1203.xml">measuring the semantic similarity of texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>measures of text similarity have been used for along time in applications in natural language processing and related areas.
</prevsent>
<prevsent>one of the earliest applications of text similarity is perhaps the vector ial model in information retrieval, where the document most relevant to an input query is determined by ranking documents in collection in reversed order of their similarity to the given query (salton and lesk, 1971).
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
text similarity has been also used for relevance feedback and text classification (rocchio, 1971), word sense disambiguation (lesk, 1986), and more recently for extractive summarization (salton et al, 1997b), and methods for automatic evaluation of machine translation (papineni et al, 2002) <papid> P02-1040 </papid>or text summarization (lin and hovy, 2003).<papid> N03-1020 </papid>the typical approach to finding the similarity between two text segments is to use simple lexical matching method, and produce similarity score based on the number of lexical units that occur in both input segments.</citsent>
<aftsection>
<nextsent>improvements to this simple method have considered stemming, stop-word removal, part-of-speech tagging, longest subsequencematching, as well as various weighting and normalization factors (salton et al, 1997a).
</nextsent>
<nextsent>while successful to certain degree, these lexical matching similarity methods fail to identify the semantic similarity of texts.
</nextsent>
<nextsent>for instance, there is an obvious similarity between the text segments own dog and have an animal, but most of the current text similarity metrics will fail in identifying any kind of connection between these texts.
</nextsent>
<nextsent>the only exception to this trend is perhaps the latent semantic analysis (lsa) method (landauer et al, 1998), which represent san improvement over earlier attempts to use measures of semantic similarity for information retrieval (voorhees, 1993), (xu and croft, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3061">
<title id=" W05-1203.xml">measuring the semantic similarity of texts </title>
<section> measuring text semantic similarity.  </section>
<citcontext>
<prevsection>
<prevsent>the leacock &amp; chodorow (leacock and chodorow, 1998) similarity is determined as: simlch = ? log length 2 ? (1)where length is the length of the shortest path between two concepts using node-counting, and is the maximum depth of the taxonomy.
</prevsent>
<prevsent>the lesk similarity of two concepts is defined as function of the overlap between the corresponding definitions, as provided by dictionary.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
it is basedon an algorithm proposed in (lesk, 1986) as solution for word sense disambiguation.the wu and palmer (wu and palmer, 1994) <papid> P94-1019 </papid>similarity metric measures the depth of the two concepts in the wordnet taxonomy, and the depth of the least common subsumer (lcs), and combines these figures into similarity score: simwup = 2 ? depth(lcs) depth(concept1) + depth(concept2) (2) the measure introduced by resnik (resnik, 1995) returns the information content (ic) of the lcs of two concepts: simres = ic(lcs) (3) where ic is defined as: ic(c) = ? log (c) (4)and (c) is the probability of encountering an instance of concept in large corpus.</citsent>
<aftsection>
<nextsent>the next measure we use in our experiments is the metric introduced by lin (lin, 1998), which build son resniks measure of similarity, and adds normalization factor consisting of the information content of the two input concepts: simlin = 2 ? ic(lcs) ic(concept1) + ic(concept2) (5) finally, the last similarity metric we consider is jiang &amp; conrath (jiang and conrath, 1997), which returns score determined by: simjnc = 1 ic(concept1) + ic(concept2) ? 2 ? ic(lcs) (6) 14 2.2 language models.
</nextsent>
<nextsent>in addition to the semantic similarity of words, we also want to take into account the specificity ofwords, so that we can give higher weight to semantic matching identified between two very specific words (e.g. collie and sheepdog), and give less importance to the similarity score measured between generic concepts (e.g. go and be).
</nextsent>
<nextsent>while the specificity of words is already measured to some extent by their depth in the semantic hierarchy, we are reinforcing this factor with corpus-based measure of word specificity, based on distributional information learned from large corpora.
</nextsent>
<nextsent>language models are frequently used in natural language processing applications to account for the distribution of words in language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3062">
<title id=" W05-1203.xml">measuring the semantic similarity of texts </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>unlike traditional similarity measures based on lexical matching, our metric takes into account the semantic similarity of these words, resulting in more precise measure of text similarity.
</prevsent>
<prevsent>to test the effectiveness of the text semantic similarity metric, we use this measure to automatically identify if two text segments are paraphrases ofeach other.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
we use the microsoft paraphrase corpus (dolan et al, 2004), <papid> C04-1051 </papid>consisting of 4,076 training pairs and 1,725 test pairs, and determine the number of correctly identified paraphrase pairs in the corpus using the text semantic similarity measure as the only indicator of paraphrasing.</citsent>
<aftsection>
<nextsent>in addition, we also evaluate the measure using the pascal corpus (da gan et al, 2005), consisting of 1,380 test hypothesis pairs with directional entailment (580 development pairs and 800 test pairs).
</nextsent>
<nextsent>for each of the two datasets, we conduct two evaluations, under two different settings: (1) an unsupervised setting, where the decision on what constitutes paraphrase (entailment) is made using aconstant similarity threshold of 0.5 across all experiments; and (2) supervised setting, where the optimal threshold and weights associated with various similarity metrics are determined through learning on training data.
</nextsent>
<nextsent>in this case, we use voted perceptron algorithm (freund and schapire, 1998)3.
</nextsent>
<nextsent>we evaluate the text similarity metric built on top of the various word-to-word metrics introduced in section 2.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3063">
<title id=" W05-0813.xml">symmetric probabilistic alignment </title>
<section> symmetric probabilistic alignment.  </section>
<citcontext>
<prevsection>
<prevsent>contiguous fragments of source language text.
</prevsent>
<prevsent>are translated into contiguous fragments in the target language text.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
unlike the work of (marcu and wong, 2002), <papid> W02-1018 </papid>our alignment algorithm is not generative and does not use the idea of bag of concepts from which the phrases in the sentence pair arise.</citsent>
<aftsection>
<nextsent>it is, rather, intended to find the corresponding target-languagephrase given specific source-language phrase of interest, as required by our ebmt system after finding match between the input and the training data (brown, 2004).
</nextsent>
<nextsent>1.1 baseline algorithm.
</nextsent>
<nextsent>our baseline algorithm is based on maximizing the probability of bi-directional translations of individual words between selected n-gram in the source language and every possible n-gram in the corresponding paired target language sentence.
</nextsent>
<nextsent>no positional preference assumptions are made, nor are any length preservation assumptions made.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3064">
<title id=" W05-0813.xml">symmetric probabilistic alignment </title>
<section> results and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>the new translation pairs were added to the dictionaries forthe spa(h) condition and the translation probabilities for the existing pairs were increased to reflect the increased confidence in their correctness.
</prevsent>
<prevsent>hadmore time been available, we would have investigated more sophisticated means of integrating the human knowledge into the translation dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
table 1 compares the performance of spa on what is now the development data against the submissions with the best aer values reported by (mihalcea and pedersen, 2003) <papid> W03-0301 </papid>for the participants in the 2003workshop, including cmu, mitre, rali, university of alberta, and xrce 1.</citsent>
<aftsection>
<nextsent>as spa generates only sure alignments, the values in table 1 are sure alignments under the no-null-align scoring condition for all systems except fourday, which did not generate sure alignments.despite the fact that spa was designed specifically for phrase-to-phrase alignments rather than the 1citations for individual participants?
</nextsent>
<nextsent>papers have been omitted for space reasons; all appear in the same proceedings.
</nextsent>
<nextsent>89 method prec% rec% f1% aer spa (c) 64.47 62.68 63.56 36.44 spa (n) 64.38 62.70 63.53 36.47 spa (h) 64.61 62.55 63.56 36.44 fourday 52.83 42.86 47.33 52.67 umd.re.2 58.29 49.99 53.82 46.61 bibr 70.65 55.75 62.32 41.39 ralign 92.00 45.06 60.49 35.24 xrcenolm 82.65 62.44 71.14 28.86table 1: romanian-english alignment results (de vel opment set, no-null-align) word-to-word alignments needed for the shared task and was not tuned for this corpus, its performance is competitive with the best of the systems previously used for the shared task.
</nextsent>
<nextsent>we thus decided to submit runs for the official 2005 evaluation, whose resulting scores are shown in table 2.on the development set, noncontiguous alignments resulted in slightly lower precision than contiguous alignments, which was not unexpected, but recall does not increase enough to improve f1 oraer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3065">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language processing methods producing shallow semantic output are starting to emerge as the next step towards successful developments in natural language understanding.
</prevsent>
<prevsent>incremental, robust parsing systems will be the core enabling technology for interactive, speech-based question answering and dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
in recent years, corpora annotated with semantic and function labels have seen the light (palmer et al, 2005; <papid> J05-1004 </papid>baker et al, 1998) <papid> P98-1013 </papid>and semantic role labelling has taken centre-stage as challenging new task.</citsent>
<aftsection>
<nextsent>state-of-the-art statistical parsers have not yet responded to this challenge.
</nextsent>
<nextsent>state-of-the-art statistical parsers trained on thepenn treebank (ptb) (marcus et al, 1993) <papid> J93-2004 </papid>pro   hhh hh np-sbj  ppp the authority vp      @@ pppp ppp vbd dropped pp-tmp  in at np nn midnight np-tmp nnp tuesday pp-dir  hh to to np qp  ppp $ 2.80 trillion figure 1: sample syntactic structure with function labels.duce trees annotated with bare phrase structure labels (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>the trees of the penn treebank, however, are also decorated with function labels, labels that indicate the grammatical and semantic relationship of phrases to each other in the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3066">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language processing methods producing shallow semantic output are starting to emerge as the next step towards successful developments in natural language understanding.
</prevsent>
<prevsent>incremental, robust parsing systems will be the core enabling technology for interactive, speech-based question answering and dialogue systems.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
in recent years, corpora annotated with semantic and function labels have seen the light (palmer et al, 2005; <papid> J05-1004 </papid>baker et al, 1998) <papid> P98-1013 </papid>and semantic role labelling has taken centre-stage as challenging new task.</citsent>
<aftsection>
<nextsent>state-of-the-art statistical parsers have not yet responded to this challenge.
</nextsent>
<nextsent>state-of-the-art statistical parsers trained on thepenn treebank (ptb) (marcus et al, 1993) <papid> J93-2004 </papid>pro   hhh hh np-sbj  ppp the authority vp      @@ pppp ppp vbd dropped pp-tmp  in at np nn midnight np-tmp nnp tuesday pp-dir  hh to to np qp  ppp $ 2.80 trillion figure 1: sample syntactic structure with function labels.duce trees annotated with bare phrase structure labels (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>the trees of the penn treebank, however, are also decorated with function labels, labels that indicate the grammatical and semantic relationship of phrases to each other in the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3067">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, corpora annotated with semantic and function labels have seen the light (palmer et al, 2005; <papid> J05-1004 </papid>baker et al, 1998) <papid> P98-1013 </papid>and semantic role labelling has taken centre-stage as challenging new task.</prevsent>
<prevsent>state-of-the-art statistical parsers have not yet responded to this challenge.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
state-of-the-art statistical parsers trained on thepenn treebank (ptb) (marcus et al, 1993) <papid> J93-2004 </papid>pro   hhh hh np-sbj  ppp the authority vp      @@ pppp ppp vbd dropped pp-tmp  in at np nn midnight np-tmp nnp tuesday pp-dir  hh to to np qp  ppp $ 2.80 trillion figure 1: sample syntactic structure with function labels.duce trees annotated with bare phrase structure labels (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>the trees of the penn treebank, however, are also decorated with function labels, labels that indicate the grammatical and semantic relationship of phrases to each other in the sentence.
</nextsent>
<nextsent>figure 1 shows the simplified tree representation with function labels for sample sentence from the ptb corpus (section 00) the governments borrowing authority dropped at midnight tuesday to 2.80 trillion from 2.87 trillion.
</nextsent>
<nextsent>unlike phrase structure labels, function labels are context dependent and encode shallow level of phrasal and lexical semantics, as observed first in (blaheta and charniak, 2000).<papid> A00-2031 </papid></nextsent>
<nextsent>for example, while the authority in figure 1 will always be noun phrase, it could be subject, as in the example, or an object, as inthe sentence they questioned his authority, depending on its position in the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3068">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, corpora annotated with semantic and function labels have seen the light (palmer et al, 2005; <papid> J05-1004 </papid>baker et al, 1998) <papid> P98-1013 </papid>and semantic role labelling has taken centre-stage as challenging new task.</prevsent>
<prevsent>state-of-the-art statistical parsers have not yet responded to this challenge.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
state-of-the-art statistical parsers trained on thepenn treebank (ptb) (marcus et al, 1993) <papid> J93-2004 </papid>pro   hhh hh np-sbj  ppp the authority vp      @@ pppp ppp vbd dropped pp-tmp  in at np nn midnight np-tmp nnp tuesday pp-dir  hh to to np qp  ppp $ 2.80 trillion figure 1: sample syntactic structure with function labels.duce trees annotated with bare phrase structure labels (collins, 1999; charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>the trees of the penn treebank, however, are also decorated with function labels, labels that indicate the grammatical and semantic relationship of phrases to each other in the sentence.
</nextsent>
<nextsent>figure 1 shows the simplified tree representation with function labels for sample sentence from the ptb corpus (section 00) the governments borrowing authority dropped at midnight tuesday to 2.80 trillion from 2.87 trillion.
</nextsent>
<nextsent>unlike phrase structure labels, function labels are context dependent and encode shallow level of phrasal and lexical semantics, as observed first in (blaheta and charniak, 2000).<papid> A00-2031 </papid></nextsent>
<nextsent>for example, while the authority in figure 1 will always be noun phrase, it could be subject, as in the example, or an object, as inthe sentence they questioned his authority, depending on its position in the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3072">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the trees of the penn treebank, however, are also decorated with function labels, labels that indicate the grammatical and semantic relationship of phrases to each other in the sentence.
</prevsent>
<prevsent>figure 1 shows the simplified tree representation with function labels for sample sentence from the ptb corpus (section 00) the governments borrowing authority dropped at midnight tuesday to 2.80 trillion from 2.87 trillion.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
unlike phrase structure labels, function labels are context dependent and encode shallow level of phrasal and lexical semantics, as observed first in (blaheta and charniak, 2000).<papid> A00-2031 </papid></citsent>
<aftsection>
<nextsent>for example, while the authority in figure 1 will always be noun phrase, it could be subject, as in the example, or an object, as inthe sentence they questioned his authority, depending on its position in the sentence.
</nextsent>
<nextsent>to some extent, function labels overlap with semantic role labels as defined in propbank (palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>table 1 83 syntactic labels semantic labels dtv dative adv adverbial lgs logical subject bnf benefactive prd predicate dir direction put compl of put ext extent sbj surface subject loc locative voc vocative mnr manner miscellaneous labels nom nominal clf it-cleft prp purpose or reason hln headline tmp temporal ttl title topic labels clr closely related tpc topical ized table 1: complete set of function labels in the penn treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3081">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>illustrates the complete list of function labels in the penn treebank, partitioned into four classes.
</prevsent>
<prevsent>1 current statistical parsers do not use or output this richer information because performance of the parser usually decreases considerably, since more complex task is being solved.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
(klein and manning,2003), <papid> P03-1054 </papid>for instance report reduction in parsing accuracy of an un lexicalised pcfg from 77.8% to 72.9% if using function labels in training.</citsent>
<aftsection>
<nextsent>(blaheta, 2004) also reports decrease in performance when attempting to integrate his function labelling system with full parser.
</nextsent>
<nextsent>conversely, researchers interested in producing richer semantic outputs have concentrated on two-stage systems, where the semantic labelling task is performed on the output of parser, in pipeline architecture divided in several stages (gildea and jurafsky, 2002; <papid> J02-3001 </papid>nielsen and pradhan,2004; <papid> W04-3211 </papid>xue and palmer, 2004).<papid> W04-3212 </papid></nextsent>
<nextsent>see also the common task of (conll, 2004; conll, 2005; senseval, 2004), where parsing has sometimes not been used and has been replaced by chunking.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3082">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(klein and manning,2003), <papid> P03-1054 </papid>for instance report reduction in parsing accuracy of an un lexicalised pcfg from 77.8% to 72.9% if using function labels in training.</prevsent>
<prevsent>(blaheta, 2004) also reports decrease in performance when attempting to integrate his function labelling system with full parser.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
conversely, researchers interested in producing richer semantic outputs have concentrated on two-stage systems, where the semantic labelling task is performed on the output of parser, in pipeline architecture divided in several stages (gildea and jurafsky, 2002; <papid> J02-3001 </papid>nielsen and pradhan,2004; <papid> W04-3211 </papid>xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>see also the common task of (conll, 2004; conll, 2005; senseval, 2004), where parsing has sometimes not been used and has been replaced by chunking.
</nextsent>
<nextsent>in this paper, we present parser that produces richer output using information available in corpusincrementally.
</nextsent>
<nextsent>specifically, the parser outputs additional labels indicating the function of constituent in the tree, such as np-sbj or pp-tmp in the tree 1(blaheta and charniak, 2000) <papid> A00-2031 </papid>talk of function tags.we will instead use the term function label, to indicate function identifiers, as they can decorate any node in the tree.</nextsent>
<nextsent>we keep the word tag to indicate only those labels that decorate pre terminal nodes in tree ? part-of-speech tags ? as is standard use.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3084">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(klein and manning,2003), <papid> P03-1054 </papid>for instance report reduction in parsing accuracy of an un lexicalised pcfg from 77.8% to 72.9% if using function labels in training.</prevsent>
<prevsent>(blaheta, 2004) also reports decrease in performance when attempting to integrate his function labelling system with full parser.</prevsent>
</prevsection>
<citsent citstr=" W04-3211 ">
conversely, researchers interested in producing richer semantic outputs have concentrated on two-stage systems, where the semantic labelling task is performed on the output of parser, in pipeline architecture divided in several stages (gildea and jurafsky, 2002; <papid> J02-3001 </papid>nielsen and pradhan,2004; <papid> W04-3211 </papid>xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>see also the common task of (conll, 2004; conll, 2005; senseval, 2004), where parsing has sometimes not been used and has been replaced by chunking.
</nextsent>
<nextsent>in this paper, we present parser that produces richer output using information available in corpusincrementally.
</nextsent>
<nextsent>specifically, the parser outputs additional labels indicating the function of constituent in the tree, such as np-sbj or pp-tmp in the tree 1(blaheta and charniak, 2000) <papid> A00-2031 </papid>talk of function tags.we will instead use the term function label, to indicate function identifiers, as they can decorate any node in the tree.</nextsent>
<nextsent>we keep the word tag to indicate only those labels that decorate pre terminal nodes in tree ? part-of-speech tags ? as is standard use.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3085">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(klein and manning,2003), <papid> P03-1054 </papid>for instance report reduction in parsing accuracy of an un lexicalised pcfg from 77.8% to 72.9% if using function labels in training.</prevsent>
<prevsent>(blaheta, 2004) also reports decrease in performance when attempting to integrate his function labelling system with full parser.</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
conversely, researchers interested in producing richer semantic outputs have concentrated on two-stage systems, where the semantic labelling task is performed on the output of parser, in pipeline architecture divided in several stages (gildea and jurafsky, 2002; <papid> J02-3001 </papid>nielsen and pradhan,2004; <papid> W04-3211 </papid>xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>see also the common task of (conll, 2004; conll, 2005; senseval, 2004), where parsing has sometimes not been used and has been replaced by chunking.
</nextsent>
<nextsent>in this paper, we present parser that produces richer output using information available in corpusincrementally.
</nextsent>
<nextsent>specifically, the parser outputs additional labels indicating the function of constituent in the tree, such as np-sbj or pp-tmp in the tree 1(blaheta and charniak, 2000) <papid> A00-2031 </papid>talk of function tags.we will instead use the term function label, to indicate function identifiers, as they can decorate any node in the tree.</nextsent>
<nextsent>we keep the word tag to indicate only those labels that decorate pre terminal nodes in tree ? part-of-speech tags ? as is standard use.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3093">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a node bearing the syn-null label is node that does not bear any other syntactic label.
</prevsent>
<prevsent>analogously, the sem-null label completes the set of semantic labels.
</prevsent>
</prevsection>
<citsent citstr=" N03-1014 ">
note that both the syn-null label and the sem-null are necessary, since both asyntactic and semantic label can label given con stituent.we present work to test the hypothesis that current statistical parser (henderson, 2003) <papid> N03-1014 </papid>can out put richer information robustly, that is without any degradation of the parsers accuracy on the original parsing task, by explicitly modelling function label sas the locus where the lexical semantics of the elements in the sentence and syntactic locality domains interact.</citsent>
<aftsection>
<nextsent>briefly, our method consists in augmenting the parser with features and biases that capture both lexical semantics projections and structural regularities underlying the distribution of sequences of function labels in sentence.
</nextsent>
<nextsent>we achieve state-of-the-art results both in parsing and function labelling.
</nextsent>
<nextsent>this result has several consequences.
</nextsent>
<nextsent>on the one hand, we show that it is possible to build single integrated robust system successfully.this is an interesting achievement, as task combining function labelling and parsing is more complex than simple parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3095">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, given current limited availability of annotated treebanks, this more complex task will have to be solved with the same overall amount of data, aggravating the difficulty of estimating the models parameters due to sparse data.
</prevsent>
<prevsent>solving this more complex problem successfully, then, indicates that the models used are robust.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
our results also provide some new insights into the discussion about the necessity of parsing for function or semantic role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>punyakanok et al, 84 2005), showing that parsing is beneficial.on the other hand, function labelling while parsing opens the way to interactive applications that are not possible in two-stage architecture.</citsent>
<aftsection>
<nextsent>because the parser produces richer output incrementally at thesame time as parsing, it can be integrated in speech based applications, as well as be used for languagemodels.
</nextsent>
<nextsent>conversely, output annotated with more informative labels, such as function or semantic labels,underlies all domain-independent question answering (jijkoun et al, 2004) <papid> C04-1188 </papid>or shallow semantic interpretation systems (collins and miller, 1998; <papid> W98-1105 </papid>ge and mooney, 2005).<papid> W05-0602 </papid></nextsent>
<nextsent>to achieve the complex task of assigning function labels while parsing, we use family of statistical parsers, the simple synch rony network (ssn) parsers (henderson, 2003), <papid> N03-1014 </papid>which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3096">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our results also provide some new insights into the discussion about the necessity of parsing for function or semantic role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>punyakanok et al, 84 2005), showing that parsing is beneficial.on the other hand, function labelling while parsing opens the way to interactive applications that are not possible in two-stage architecture.</prevsent>
<prevsent>because the parser produces richer output incrementally at thesame time as parsing, it can be integrated in speech based applications, as well as be used for languagemodels.</prevsent>
</prevsection>
<citsent citstr=" C04-1188 ">
conversely, output annotated with more informative labels, such as function or semantic labels,underlies all domain-independent question answering (jijkoun et al, 2004) <papid> C04-1188 </papid>or shallow semantic interpretation systems (collins and miller, 1998; <papid> W98-1105 </papid>ge and mooney, 2005).<papid> W05-0602 </papid></citsent>
<aftsection>
<nextsent>to achieve the complex task of assigning function labels while parsing, we use family of statistical parsers, the simple synch rony network (ssn) parsers (henderson, 2003), <papid> N03-1014 </papid>which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.</nextsent>
<nextsent>this architecture has shown state of-the-art performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3097">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our results also provide some new insights into the discussion about the necessity of parsing for function or semantic role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>punyakanok et al, 84 2005), showing that parsing is beneficial.on the other hand, function labelling while parsing opens the way to interactive applications that are not possible in two-stage architecture.</prevsent>
<prevsent>because the parser produces richer output incrementally at thesame time as parsing, it can be integrated in speech based applications, as well as be used for languagemodels.</prevsent>
</prevsection>
<citsent citstr=" W98-1105 ">
conversely, output annotated with more informative labels, such as function or semantic labels,underlies all domain-independent question answering (jijkoun et al, 2004) <papid> C04-1188 </papid>or shallow semantic interpretation systems (collins and miller, 1998; <papid> W98-1105 </papid>ge and mooney, 2005).<papid> W05-0602 </papid></citsent>
<aftsection>
<nextsent>to achieve the complex task of assigning function labels while parsing, we use family of statistical parsers, the simple synch rony network (ssn) parsers (henderson, 2003), <papid> N03-1014 </papid>which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.</nextsent>
<nextsent>this architecture has shown state of-the-art performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3098">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our results also provide some new insights into the discussion about the necessity of parsing for function or semantic role labelling (gildea and palmer, 2002; <papid> P02-1031 </papid>punyakanok et al, 84 2005), showing that parsing is beneficial.on the other hand, function labelling while parsing opens the way to interactive applications that are not possible in two-stage architecture.</prevsent>
<prevsent>because the parser produces richer output incrementally at thesame time as parsing, it can be integrated in speech based applications, as well as be used for languagemodels.</prevsent>
</prevsection>
<citsent citstr=" W05-0602 ">
conversely, output annotated with more informative labels, such as function or semantic labels,underlies all domain-independent question answering (jijkoun et al, 2004) <papid> C04-1188 </papid>or shallow semantic interpretation systems (collins and miller, 1998; <papid> W98-1105 </papid>ge and mooney, 2005).<papid> W05-0602 </papid></citsent>
<aftsection>
<nextsent>to achieve the complex task of assigning function labels while parsing, we use family of statistical parsers, the simple synch rony network (ssn) parsers (henderson, 2003), <papid> N03-1014 </papid>which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.</nextsent>
<nextsent>this architecture has shown state of-the-art performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3105">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> the basic architecture.  </section>
<citcontext>
<prevsection>
<prevsent>to bound the number of parameters, standard history-based models partition the set of well formed sequences of transitions into equivalence classes.
</prevsent>
<prevsent>while such partition makes the problem of searching for the most probable parse polyno mial, it introduces hard independence assumptions: derivation move only depends on the equivalence class to which its history belongs.
</prevsent>
</prevsection>
<citsent citstr=" P98-1087 ">
ssn parsers, onthe other hand, do not state any explicit independence assumptions: they use neural network architecture, called simple synch rony network (henderson and lane, 1998), <papid> P98-1087 </papid>to induce finite history representation of an unbounded sequence of moves.</citsent>
<aftsection>
<nextsent>the history representation of parse history d1, . . .
</nextsent>
<nextsent>, di1, which we denote h(d1, . . .
</nextsent>
<nextsent>, di1), is assigned to the constituent that is on the top of the stack before the ith move.
</nextsent>
<nextsent>the representation h(d1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3114">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> learning lexical projection and.  </section>
<citcontext>
<prevsection>
<prevsent>any such non-terminal must not bear either syntactic or semantic function labels, or the clr label.
</prevsent>
<prevsent>in addition, the first child following the head of pp is marked with the obj label.
</prevsent>
</prevsection>
<citsent citstr=" H05-1078 ">
(for more detail on this lexical semantics projection, see (merlo and musillo, 2005).)<papid> H05-1078 </papid></citsent>
<aftsection>
<nextsent>we report the effects of these augmentations on parsing results in the experiments described below.
</nextsent>
<nextsent>s   hhh hh np-sbj  ppp the authority vp        @@ @ pppp pppp vbd dropped pp-tmp  in-tmp at np nn midnight np-tmp nnp-tmp tuesday pp-dir  to-dir to np qp  ppp $ 2.80 trillion figure 3: sample syntactic structure with function labels lowered onto the preterminals.
</nextsent>
<nextsent>to assess the relevance of our fine-grained tags and history representations for functional labelling, we compare two augmented models to two baseline models without these augmentations indicated in table 2 as no-biases and h03.
</nextsent>
<nextsent>the baseline called h03refers to our runs of the parser described in (henderson, 2003), <papid> N03-1014 </papid>which is not trained on input annotated with function labels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3122">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>to provide the augmented models with tagged input sentences, we trained an svm tagger whose features and parameters are described in detail in (gimenez and marquez, 2004).
</prevsent>
<prevsent>trained on section 2-21, the tagger reaches performance of 95.8% on the test set (section 23) of the ptb using our new tag set.
</prevsent>
</prevsection>
<citsent citstr=" C00-2137 ">
both parsing results taking function labels into account in the evaluation (flabel) and results not taking them into account in the evaluation (flabel-less) are reported in table 2, which shows results on the test set, section 23 of the ptb.both the model augmented only with lexical information (through tag splitting) and the one augmented both with finer-grained tags and representations of syntactic locality perform better than our comparison baseline h03, but only the latter is significantly better (p   .01, using (yeh, 2000)<papid> C00-2137 </papid>s ran domised test).</citsent>
<aftsection>
<nextsent>this indicates that while information projected from the lexical items is very important, only combination of lexical semantics information and careful modelling of syntactic domains provides significant improvement.parsing results out putting function labels (flabel columns) reported in table 2 indicate that parsing function labels is more difficult than parsing barephrase-structure labels (compare the flabel column to the flabel-less column).
</nextsent>
<nextsent>they also show that our model including finer-grained tags and locality biases performs better than the one including only finer-grained tags when out putting function labels.
</nextsent>
<nextsent>this suggests that our model with both lexical and structural biases performs better than our no-biases comparison baseline precisely because itis able to learn to parse function labels more accurately.
</nextsent>
<nextsent>comparisons to the baseline without biases indicates clearly that the observed improvements, both on function parsing and on parsing without taking function labels into consideration would not have been obtained without explicit biases.individual performance on syntactic and semantic function labelling compare favourably to previous attempts (blaheta, 2004; blaheta and charniak, 2000).<papid> A00-2031 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3142">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>first, lexicalised head children are not explicitly represented in ourmodel.
</prevsent>
<prevsent>second, we do not discriminate between arguments and adjuncts: we only encode the distinctions between syntactic function labels and semantic ones.
</prevsent>
</prevsection>
<citsent citstr=" E03-1079 ">
as shown in (merlo, 2003; <papid> E03-1079 </papid>merlo andesteve-ferrer, 2004) this difference does not correspond to the difference between arguments and ad juncts.</citsent>
<aftsection>
<nextsent>finally, our model does not implement any distinction between right and left subcategorisationframes.
</nextsent>
<nextsent>in coll inss model, the left and right subcategorisation frames are conditionally independent and arguments occupying complement position (to the right of the head) are independent of arguments occurring in specifier position (to the left of thehead).
</nextsent>
<nextsent>in our model, no such independence assumptions are stated, because the model is biased towards phrases related to each other by the c-command relation.
</nextsent>
<nextsent>such relation could involve both elements at the left and at the right of the head.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3143">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the most important observation, however, is that modelling function labels as the interface between syntax and semantics yields significant improvement on parsing performance, as can be verified in the flabel-less column of table 2.
</prevsent>
<prevsent>this is acrucial observation in the light of the current approaches to function or semantic role labelling and its relation to parsing.
</prevsent>
</prevsection>
<citsent citstr=" W04-0832 ">
an improvement in parsing performance by better modelling of function labels indicates that this complex problem is better solved as single integrated task and that current two-step architectures might be missing on successful ways to improve both the parsing and the labelling task.in particular, recent models of semantic role labelling separate input indicators of the correlation between the structural position in the tree and the semantic label, such as path, from those indicators that encode constraints on the sequence, such as the previously assigned role (kwon et al, 2004).<papid> W04-0832 </papid></citsent>
<aftsection>
<nextsent>in this way, they can never encode directly the constraining power of certain role in given structural position onto following node in its structural position.
</nextsent>
<nextsent>in our augmented model, we attempt to capture these constraints by directly modelling syntactic domains.
</nextsent>
<nextsent>our results confirm the findings in (palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>they take critical look at some commonly used features in the semantic role labelling task, such as the path feature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3146">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>its 90 sparseness is due to the occurrence of intermediate nodes that are not relevant for the syntactic relations between an argument and its predicate.
</prevsent>
<prevsent>our model of domains is less noisy, because it can focus only on c-commanding nodes bearing function labels, thus abstracting away from those nodes that smear the pertinent relations.
</prevsent>
</prevsection>
<citsent citstr=" W05-0639 ">
(yi and palmer, 2005) <papid> W05-0639 </papid>share the motivation of our work, although they apply it to different task.</citsent>
<aftsection>
<nextsent>like the current work, they observe that the distributions of semantic labels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of in formation.our results also confirm the importance of lexical information, the lesson drawn from (thompsonet al, 2004), <papid> W04-0857 </papid>who find that correctly modelling sequence information is not sufficient.</nextsent>
<nextsent>lexical information is very important, as it reflects the lexical semantics of the constituents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3147">
<title id=" W05-1509.xml">lexical and structural biases for function parsing </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>our model of domains is less noisy, because it can focus only on c-commanding nodes bearing function labels, thus abstracting away from those nodes that smear the pertinent relations.
</prevsent>
<prevsent>(yi and palmer, 2005) <papid> W05-0639 </papid>share the motivation of our work, although they apply it to different task.</prevsent>
</prevsection>
<citsent citstr=" W04-0857 ">
like the current work, they observe that the distributions of semantic labels could potentially interact with the distributions of syntactic labels and redefine the boundaries of constituents, thus yielding trees that reflect generalisations over both these sources of in formation.our results also confirm the importance of lexical information, the lesson drawn from (thompsonet al, 2004), <papid> W04-0857 </papid>who find that correctly modelling sequence information is not sufficient.</citsent>
<aftsection>
<nextsent>lexical information is very important, as it reflects the lexical semantics of the constituents.
</nextsent>
<nextsent>both factors, syntactic domains and lexical information, are needed to significantly improve parsing.
</nextsent>
<nextsent>in this paper, we have explored new way to im prove parsing results in current statistical parser while at the same time enriching its output.
</nextsent>
<nextsent>we achieve significant improvements in parsing and function labelling by modelling directly the specific nature of function labels, as both expressions of the lexical semantics properties of constituent and as syntactic elements whose distribution is subject to structural locality constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3148">
<title id=" W06-0109.xml">the role of lexical resources in cjk natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>5.
</prevsent>
<prevsent>accurate word segmentation (emerson 2000.
</prevsent>
</prevsection>
<citsent citstr=" C94-2209 ">
and yu et al 2000) and disambiguating ambiguous segment ations strings (ass) (zhou and yu 1994).<papid> C94-2209 </papid></citsent>
<aftsection>
<nextsent>6.
</nextsent>
<nextsent>the difficulty of lexeme-based retrieval and.
</nextsent>
<nextsent>cjk clir (goto et al 2001).
</nextsent>
<nextsent>7.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3149">
<title id=" W06-0109.xml">the role of lexical resources in cjk natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic recognition of terms and their vari-.
</prevsent>
<prevsent>ants (jacquemin 2001).
</prevsent>
</prevsection>
<citsent citstr=" W97-0316 ">
the various attempts to tackle these tasks by statistical and algorithmic methods (kwok 1997) <papid> W97-0316 </papid>have had only limited success.</citsent>
<aftsection>
<nextsent>an important motivation for such methodology has been the poor availability and high cost of acquiring and maintaining large-scale lexical databases.
</nextsent>
<nextsent>this paper discusses how lexicon-driven approach exploiting large-scale lexical databases can offer reliable solutions to some of the principal issues, based on over decade of experience in building such databases for nlp applications.
</nextsent>
<nextsent>named entity recognition (ner) is useful in nlp applications such as question answering, machine translation and information extraction.
</nextsent>
<nextsent>a major difficulty inner, and strong motivation for using tools based on probabilistic methods, is that the compilation and maintenance of large entity databases is time consuming and expensive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3151">
<title id=" W06-0403.xml">numbat abolishing privileges when licensing new constituents in constraint oriented parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in linguistics, the term gradience is often used to refer to the notion of acceptability as gradient, as opposed to more classical all-or-none notion.the research goal of this project is to build an experimental platform for computing gradience, i.e. for quantifying the degree of acceptability of an input utterance.
</prevsent>
<prevsent>we called this platform numbat.in order to be able to quantify such gradient of acceptability with no priori opinion onthe influence played by different types of linguistic relationships, we want to adopt framework where no one type of (syntactic) relation (e.g. dependency, immediate dominance, or linear prece dence) is preferred over the other ones.
</prevsent>
</prevsection>
<citsent citstr=" C02-1104 ">
althougha constraint-oriented (co) paradigm such as property grammars (blache, 2001) theoretically does not relyon any preferred relations, we observe thatthe parsing strategies implemented so far (moraw ietz and blache, 2002; balfourier et al, 2002; <papid> C02-1104 </papid>dahl and blache, 2004; vanrullen, 2005) do not account for such feature of the formalism.</citsent>
<aftsection>
<nextsent>the strategy we have designed overcomes that problem and allows for constituents to be licensed by any type of relation.
</nextsent>
<nextsent>not only does our approach maintain close connection between implementation and underpinning theory, but it also allows for the decisions made with respect to gradience to be better informed.
</nextsent>
<nextsent>the purpose of the present paper is to present this new parsing strategy, and to emphasise how it abolishes the privilege?
</nextsent>
<nextsent>usually only granted to subset of syntactic relationships.section 2 presents some background information about the co approaches and briefly introduces the property grammars formalism.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3153">
<title id=" W06-0403.xml">numbat abolishing privileges when licensing new constituents in constraint oriented parsing </title>
<section> constraint-oriented approaches.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 then draws the conclusion.
</prevsent>
<prevsent>the main feature common to all constraint oriented approaches is that parsing is modelled as constraint satisfaction problem (csp).
</prevsent>
</prevsection>
<citsent citstr=" P90-1005 ">
maruyamas constraint dependency grammar (cdg) (maruyama, 1990) <papid> P90-1005 </papid>is the first formalism to introduce the parsing process as csp solver.several extensions of cdg have then been proposed (heinecke et al, 1998; <papid> P98-1086 </papid>duchier, 1999; foth et al, 2004).</citsent>
<aftsection>
<nextsent>menzel and colleagues (heinecke et al, 1998; <papid> P98-1086 </papid>foth et al, 2004) developed weighted (orgraded?)</nextsent>
<nextsent>version of cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3154">
<title id=" W06-0403.xml">numbat abolishing privileges when licensing new constituents in constraint oriented parsing </title>
<section> constraint-oriented approaches.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 then draws the conclusion.
</prevsent>
<prevsent>the main feature common to all constraint oriented approaches is that parsing is modelled as constraint satisfaction problem (csp).
</prevsent>
</prevsection>
<citsent citstr=" P98-1086 ">
maruyamas constraint dependency grammar (cdg) (maruyama, 1990) <papid> P90-1005 </papid>is the first formalism to introduce the parsing process as csp solver.several extensions of cdg have then been proposed (heinecke et al, 1998; <papid> P98-1086 </papid>duchier, 1999; foth et al, 2004).</citsent>
<aftsection>
<nextsent>menzel and colleagues (heinecke et al, 1998; <papid> P98-1086 </papid>foth et al, 2004) developed weighted (orgraded?)</nextsent>
<nextsent>version of cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3158">
<title id=" W06-0403.xml">numbat abolishing privileges when licensing new constituents in constraint oriented parsing </title>
<section> constraint-oriented approaches.  </section>
<citcontext>
<prevsection>
<prevsent>indeed, the over generation introduces inconsistencies in the constraint system, which prevents the use of the con 17straint system as set of well-formedness conditions, since even well-formed utterance violatesa subset of constraints.
</prevsent>
<prevsent>consequently it is not possible to distinguish an optimal structure of an illformed utterance from an optimal structure of well-formed utterance.duchier (1999) relies on set constraints and selection constraints1 to axiomatise syntactic well formed ness and provides concurrent constraint programming account of the parsing process.
</prevsent>
</prevsection>
<citsent citstr=" W04-1510 ">
withthe extended dependency grammar (xdg) (de busmann et al, 2004) <papid> W04-1510 </papid>the notion of dependency tree is further extended to multi-dimensional?</citsent>
<aftsection>
<nextsent>dependency graph, where each dimension (e.g. immediate dominance and linear precedence) is associated with its own set of well-formedness conditions (called principles).
</nextsent>
<nextsent>duchier (2000) sees dependency parsing as configuration problem, where given finite set of components (nodes in graph) and set of constraints specifying how these components may be connected, the task consists of finding solution tree.it seems, to the best of our knowledge, that neither of these works around xdg attempts to account for ill-formedness.
</nextsent>
<nextsent>the property grammars (pg), introduced by blache (blache, 2001; blache, 2005)2, step back from dependency grammar.
</nextsent>
<nextsent>solving the constraint system no longer results in dependency structure but in phrase structure, whose granularity may be tailored from shallow one (i.e. collection of disconnected components) to deep one (i.e. single hierarchical structure of constituents)according to application requirements3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3161">
<title id=" W06-0611.xml">corpus annotation by generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, we present the main features of the kpml system (section 2).
</prevsent>
<prevsent>second, we describe the steps involved in annotation by generation, from the generation output (kpml internal generationrecord) to an xml representation and its refinement to an xml multi-layer representation (section 3).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
section 4 concludes the paper with critical assessment of the proposed approach and discussion of the prospects for application in the construction of corpora comparable in size and quality to existing treebanks (such as, for example, the penn treebank for english (marcus et al, 1993) <papid> J93-2004 </papid>or the tiger treebank for german (brants et al, 2002)).</citsent>
<aftsection>
<nextsent>since our description here has the status of progress report of work still in its beginning stages, we cannot yet provide the results of detailed evaluation.
</nextsent>
<nextsent>in the final section, therefore, we emphasize the concrete steps that we are currently taking in order to be able carry out the detailed evaluations necessary.
</nextsent>
<nextsent>kpmlthe kpml system is mature grammar development environment for supporting large-scale grammar engineering work for natural language generation using multilingual systemic-functional grammars (bateman et al, 2005).
</nextsent>
<nextsent>grammars within this framework consist of large lattices of grammatical features, each of which brings constraints on syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3162">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>(lewis, 2000) on which the speakers build their utterances.
</prevsent>
<prevsent>the key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times.
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
it has been equally shown that collocations are useful in range of other applications, such as word sense disambiguation (brown et al, 1991) <papid> P91-1034 </papid>and parsing (alshawi and carter, 1994).<papid> J94-4005 </papid></citsent>
<aftsection>
<nextsent>the nlp community fully acknowledged the need for an appropriate treatment of multi-wordexpressions in general (sag et al, 2002).
</nextsent>
<nextsent>collocations are particularly important because of their prevalence in language, regardless of the domain or genre.
</nextsent>
<nextsent>according to jackendoff (1997), according to jackendoff (156) and melcuk (1998),  and melcuk (24), collocations constitute the bulk of languages lexicon.
</nextsent>
<nextsent>the last decades have witnessed considerable development of collocation extraction techniques,that concern both monolingual and (parallel) multilingual corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3163">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>(lewis, 2000) on which the speakers build their utterances.
</prevsent>
<prevsent>the key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times.
</prevsent>
</prevsection>
<citsent citstr=" J94-4005 ">
it has been equally shown that collocations are useful in range of other applications, such as word sense disambiguation (brown et al, 1991) <papid> P91-1034 </papid>and parsing (alshawi and carter, 1994).<papid> J94-4005 </papid></citsent>
<aftsection>
<nextsent>the nlp community fully acknowledged the need for an appropriate treatment of multi-wordexpressions in general (sag et al, 2002).
</nextsent>
<nextsent>collocations are particularly important because of their prevalence in language, regardless of the domain or genre.
</nextsent>
<nextsent>according to jackendoff (1997), according to jackendoff (156) and melcuk (1998),  and melcuk (24), collocations constitute the bulk of languages lexicon.
</nextsent>
<nextsent>the last decades have witnessed considerable development of collocation extraction techniques,that concern both monolingual and (parallel) multilingual corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3164">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>according to jackendoff (1997), according to jackendoff (156) and melcuk (1998),  and melcuk (24), collocations constitute the bulk of languages lexicon.
</prevsent>
<prevsent>the last decades have witnessed considerable development of collocation extraction techniques,that concern both monolingual and (parallel) multilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" H89-2012 ">
we can mention here only part of this work: (berry-rogghe, 1973; church et al, 1989; <papid> H89-2012 </papid>smadja, 1993; <papid> J93-1007 </papid>lin, 1998; krenn and evert, 2001) for monolingual extraction, and (kupiec, 1993;wu, 1994; smadja et al, 1996; <papid> J96-1001 </papid>kitamura and mat 40sumoto, 1996; melamed, 1997) <papid> P97-1039 </papid>for bilingual extraction via alignment.traditionally, collocation extraction was considered language-independent task.</citsent>
<aftsection>
<nextsent>since collocations are recurrent, typical lexical combinations, wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora.
</nextsent>
<nextsent>among themost often used types of lexical association measures (henceforth ams) we mention: statistical hypothesis tests (e.g., binomial, poisson, fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two words based on contingency table listing their joint and marginal frequency,and information-theoretic measures (mutual information ? henceforth mi ? and its variants),that quantity of information?
</nextsent>
<nextsent>shared by two random variables.
</nextsent>
<nextsent>a detailed review of the statistical methods employed in collocation extraction can befound, for instance, in (evert, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3166">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>according to jackendoff (1997), according to jackendoff (156) and melcuk (1998),  and melcuk (24), collocations constitute the bulk of languages lexicon.
</prevsent>
<prevsent>the last decades have witnessed considerable development of collocation extraction techniques,that concern both monolingual and (parallel) multilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
we can mention here only part of this work: (berry-rogghe, 1973; church et al, 1989; <papid> H89-2012 </papid>smadja, 1993; <papid> J93-1007 </papid>lin, 1998; krenn and evert, 2001) for monolingual extraction, and (kupiec, 1993;wu, 1994; smadja et al, 1996; <papid> J96-1001 </papid>kitamura and mat 40sumoto, 1996; melamed, 1997) <papid> P97-1039 </papid>for bilingual extraction via alignment.traditionally, collocation extraction was considered language-independent task.</citsent>
<aftsection>
<nextsent>since collocations are recurrent, typical lexical combinations, wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora.
</nextsent>
<nextsent>among themost often used types of lexical association measures (henceforth ams) we mention: statistical hypothesis tests (e.g., binomial, poisson, fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two words based on contingency table listing their joint and marginal frequency,and information-theoretic measures (mutual information ? henceforth mi ? and its variants),that quantity of information?
</nextsent>
<nextsent>shared by two random variables.
</nextsent>
<nextsent>a detailed review of the statistical methods employed in collocation extraction can befound, for instance, in (evert, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3170">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>according to jackendoff (1997), according to jackendoff (156) and melcuk (1998),  and melcuk (24), collocations constitute the bulk of languages lexicon.
</prevsent>
<prevsent>the last decades have witnessed considerable development of collocation extraction techniques,that concern both monolingual and (parallel) multilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
we can mention here only part of this work: (berry-rogghe, 1973; church et al, 1989; <papid> H89-2012 </papid>smadja, 1993; <papid> J93-1007 </papid>lin, 1998; krenn and evert, 2001) for monolingual extraction, and (kupiec, 1993;wu, 1994; smadja et al, 1996; <papid> J96-1001 </papid>kitamura and mat 40sumoto, 1996; melamed, 1997) <papid> P97-1039 </papid>for bilingual extraction via alignment.traditionally, collocation extraction was considered language-independent task.</citsent>
<aftsection>
<nextsent>since collocations are recurrent, typical lexical combinations, wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora.
</nextsent>
<nextsent>among themost often used types of lexical association measures (henceforth ams) we mention: statistical hypothesis tests (e.g., binomial, poisson, fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two words based on contingency table listing their joint and marginal frequency,and information-theoretic measures (mutual information ? henceforth mi ? and its variants),that quantity of information?
</nextsent>
<nextsent>shared by two random variables.
</nextsent>
<nextsent>a detailed review of the statistical methods employed in collocation extraction can befound, for instance, in (evert, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3171">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>according to jackendoff (1997), according to jackendoff (156) and melcuk (1998),  and melcuk (24), collocations constitute the bulk of languages lexicon.
</prevsent>
<prevsent>the last decades have witnessed considerable development of collocation extraction techniques,that concern both monolingual and (parallel) multilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" P97-1039 ">
we can mention here only part of this work: (berry-rogghe, 1973; church et al, 1989; <papid> H89-2012 </papid>smadja, 1993; <papid> J93-1007 </papid>lin, 1998; krenn and evert, 2001) for monolingual extraction, and (kupiec, 1993;wu, 1994; smadja et al, 1996; <papid> J96-1001 </papid>kitamura and mat 40sumoto, 1996; melamed, 1997) <papid> P97-1039 </papid>for bilingual extraction via alignment.traditionally, collocation extraction was considered language-independent task.</citsent>
<aftsection>
<nextsent>since collocations are recurrent, typical lexical combinations, wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora.
</nextsent>
<nextsent>among themost often used types of lexical association measures (henceforth ams) we mention: statistical hypothesis tests (e.g., binomial, poisson, fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two words based on contingency table listing their joint and marginal frequency,and information-theoretic measures (mutual information ? henceforth mi ? and its variants),that quantity of information?
</nextsent>
<nextsent>shared by two random variables.
</nextsent>
<nextsent>a detailed review of the statistical methods employed in collocation extraction can befound, for instance, in (evert, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3172">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>shared by two random variables.
</prevsent>
<prevsent>a detailed review of the statistical methods employed in collocation extraction can befound, for instance, in (evert, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P05-2003 ">
a comprehensive list of ams is given (pecina, 2005).<papid> P05-2003 </papid>very often, in addition to the information on cooccurrence frequency, language-specific information is also integrated in collocation extraction system (as it will be seen in section 3): - morphological information, in order to count inflected word forms as instances of the same base form.</citsent>
<aftsection>
<nextsent>for instance, ask questions, asks question, asked question are all instances of the same word pair, ask - question; - syntactic information, in order to recognize aword pair even if subject to (complex) syntactic transformations: ask multiple questions, question asked, questions that one might ask.the language-specific modules thus aim at coping with the problem of morphosyntactic variation, in order to improve the accuracy of frequencyinformation.
</nextsent>
<nextsent>this becomes truly important especially for free-word order and for high-inflectionlanguages, for which the token(form)-based frequency figures become too skewed due to the high lexical dispersion.
</nextsent>
<nextsent>not only the data scattering modify the frequency numbers used by ams, but it also alters the performance of ams, if the the probabilities in the contingency table become very low.
</nextsent>
<nextsent>morphosyntactic information has in fact been shown to significantly improve the extraction results (breidt, 1993; <papid> W93-0309 </papid>smadja, 1993; <papid> J93-1007 </papid>zajac et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3173">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>this becomes truly important especially for free-word order and for high-inflectionlanguages, for which the token(form)-based frequency figures become too skewed due to the high lexical dispersion.
</prevsent>
<prevsent>not only the data scattering modify the frequency numbers used by ams, but it also alters the performance of ams, if the the probabilities in the contingency table become very low.
</prevsent>
</prevsection>
<citsent citstr=" W93-0309 ">
morphosyntactic information has in fact been shown to significantly improve the extraction results (breidt, 1993; <papid> W93-0309 </papid>smadja, 1993; <papid> J93-1007 </papid>zajac et al, 2003).</citsent>
<aftsection>
<nextsent>morphological tools such as lemmatizer sand pos taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (justeson and katz, 1995), asare the ungrammatical combinations in the systems that make use of parsers (church and hanks, 1990; smadja, 1993; <papid> J93-1007 </papid>basili et al, 1994; lin, 1998; goldman et al, 2001; seretan et al, 2004).</nextsent>
<nextsent>given the motivations for performing linguistically-informed extraction ? which were also put forth, among others, by church and hanks (1990), church and hanks (25), smadja (1993),  <papid> J93-1007 </papid>smadja (151) and heid (1994) ? and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3190">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> overview of extraction work.  </section>
<citcontext>
<prevsection>
<prevsent>as one might expect, the bulk of the collocation extraction work concerns the english language: (choueka, 1988; church et al, 1989; <papid> H89-2012 </papid>church and hanks, 1990; smadja, 1993; <papid> J93-1007 </papid>justeson and katz, 1995; kjell mer, 1994; sinclair, 1995; lin, 1998), among many others1.chouekas method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency.</prevsent>
<prevsent>justeson and katz (1995) apply pos-filter on the pairs they extract.</prevsent>
</prevsection>
<citsent citstr=" W02-0909 ">
as in (kjellmer, 1994), the am they use is the simple frequency.smadja (1993) <papid> J93-1007 </papid>employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1e.g., (frantzi et al, 2000; pearce, 2001; goldman et al, 2001; zaiu inkpen and hirst, 2002; <papid> W02-0909 </papid>dias, 2003; seretan et al, 2004; pecina, 2005), <papid> P05-2003 </papid>and the list can be continued.</citsent>
<aftsection>
<nextsent>41 rigid noun phrases and phrasal templates.
</nextsent>
<nextsent>he then uses the parser in order to validate the results.the parsing is shown to lead to an increase in accuracy from 40% to 80%.
</nextsent>
<nextsent>(church et al, 1989) <papid> H89-2012 </papid>and (church and hanks, 1990) use pos information and parser to extract verb-object pairs, which then they rank according to the mutual information (mi) measure they in troduce.</nextsent>
<nextsent>lins (1998) is also hybrid approach that relies on dependency parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3196">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> overview of extraction work.  </section>
<citcontext>
<prevsection>
<prevsent>zinsmeister and heid (2003), zinsmeister and heid (2004) focused on n-v and a-n-v combinations identified using stochastic parser.
</prevsent>
<prevsent>they applied machine learning techniques in combination to the log-likelihood measure (henceforth ll) for distinguishing trivial compounds from lexicalized ones.
</prevsent>
</prevsection>
<citsent citstr=" C04-1141 ">
finally, wermter and hahn (2004) <papid> C04-1141 </papid>identified pp-v combinations using pos tagger and chunker.</citsent>
<aftsection>
<nextsent>they based their method on linguistic criterion (that of limited modifiability) and compared their results with those obtained using the t-score and ll tests.2the following abbreviations are used in this paper: noun, - verb, - adjective, adv - adverb, det - determiner, conj - conjunction, - preposition.
</nextsent>
<nextsent>3.3 french.
</nextsent>
<nextsent>thanks to the outstanding work of gross on lexicon-grammar (1984), french is one of the most studied languages in terms of distributional and transformational potential of words.
</nextsent>
<nextsent>this work has been carried out before the computer eraand the advent of corpus linguistics, while automatic extraction was later performed, for instance, in (lafon, 1984; daille, 1994; bourigault, 1992; goldman et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3197">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> overview of extraction work.  </section>
<citcontext>
<prevsection>
<prevsent>(2001) extracted syntactic collocations by using full parser and applying the ll test.
</prevsent>
<prevsent>3.4 other languages.
</prevsent>
</prevsection>
<citsent citstr=" C90-3010 ">
in addition to english, german and french, other languages for which notable collocation extraction work was performed, are ? as we are aware of ? the following: ? italian: early extraction work was carried out by calzolari and bindi (1990) <papid> C90-3010 </papid>and employed mi.</citsent>
<aftsection>
<nextsent>it was followed by (basili et al, 1994), that made use of parsing information;?
</nextsent>
<nextsent>korean: (shimohata et al, 1997) used an ad jacency n-gram model, and (kim et al, 1999) <papid> W99-0610 </papid>relied on pos-tagging;?</nextsent>
<nextsent>chinese: (huang et al, 2005) <papid> I05-3007 </papid>used pos information, while (lu et al, 2004) applied extraction techniques similar to xtract system (smadja, 1993); ? <papid> J93-1007 </papid>japanese: (ikehara et al, 1995) was based on an improved n-gram method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3198">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> overview of extraction work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to english, german and french, other languages for which notable collocation extraction work was performed, are ? as we are aware of ? the following: ? italian: early extraction work was carried out by calzolari and bindi (1990) <papid> C90-3010 </papid>and employed mi.</prevsent>
<prevsent>it was followed by (basili et al, 1994), that made use of parsing information;?</prevsent>
</prevsection>
<citsent citstr=" W99-0610 ">
korean: (shimohata et al, 1997) used an ad jacency n-gram model, and (kim et al, 1999) <papid> W99-0610 </papid>relied on pos-tagging;?</citsent>
<aftsection>
<nextsent>chinese: (huang et al, 2005) <papid> I05-3007 </papid>used pos information, while (lu et al, 2004) applied extraction techniques similar to xtract system (smadja, 1993); ? <papid> J93-1007 </papid>japanese: (ikehara et al, 1995) was based on an improved n-gram method.</nextsent>
<nextsent>as for multilingual extraction via alignment(where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the english-french language pair, and the hansard corpus of canadian parliament proceed ings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3199">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> overview of extraction work.  </section>
<citcontext>
<prevsection>
<prevsent>it was followed by (basili et al, 1994), that made use of parsing information;?
</prevsent>
<prevsent>korean: (shimohata et al, 1997) used an ad jacency n-gram model, and (kim et al, 1999) <papid> W99-0610 </papid>relied on pos-tagging;?</prevsent>
</prevsection>
<citsent citstr=" I05-3007 ">
chinese: (huang et al, 2005) <papid> I05-3007 </papid>used pos information, while (lu et al, 2004) applied extraction techniques similar to xtract system (smadja, 1993); ? <papid> J93-1007 </papid>japanese: (ikehara et al, 1995) was based on an improved n-gram method.</citsent>
<aftsection>
<nextsent>as for multilingual extraction via alignment(where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the english-french language pair, and the hansard corpus of canadian parliament proceedings.
</nextsent>
<nextsent>wu (1994) signals number of problems 42 that non-indo-european languages pose for the existing alignment methods based on word- and sentence-length: in chinese, for instance, most of the words are just one or two characters long, and there are no word delimiters.
</nextsent>
<nextsent>this result suggests that the portability of existing alignment methods to new language pairs is questionable.
</nextsent>
<nextsent>we are not concerned here with extraction via alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3203">
<title id=" W06-1006.xml">multilingual collocation extraction issues and solutions </title>
<section> a multilingual collocation extractor </section>
<citcontext>
<prevsection>
<prevsent>another peculiarity of our system is that candidate pairs are identified as the parsing goes on; in other approaches, they are extracted by post-processing the output of syntactic tools.
</prevsent>
<prevsent>the candidate pairs identified are classified into syntactically homogenous sets, according to the syntactic relations holding between the two items.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
only certain predefined syntactic relations arekept, that were judged as collocation ally relevant after multiple experiments of extraction and data analysis (e.g., adjective-noun, verb-object, subject-verb, noun-noun, verb-preposition-noun).the sets obtained are then ranked using the log likelihood ratios test (dunning, 1993).<papid> J93-1003 </papid>more details about the system and its performance can be found in (seretan and wehrli, 2006).</citsent>
<aftsection>
<nextsent>the following examples (taken from the extraction experiment we will describe below) illustrate its potential to detect collocation candidates, even ifthese are subject to complex syntactic trans forma tions:1.a) atteindre object if (fr): les objec tifs fixes a` lec helle internationale visant a` reduire les emissions ne peuvent pas etre atteints a` laide de ces seuls programmes.
</nextsent>
<nextsent>1.b) accogliere emendamento (it): 44 posso pertanto accogliere in partee in linea di principio gli emenda menti nn.
</nextsent>
<nextsent>43-46 lemendamento n. 85.1.c) reforzar cooperacion (es): quer emos permitir los pases que lo deseen reforzar, en un contexto unita rio, su cooperacion en cierto numero de sectores.the collocation extractor is part of bigger system (seretan et al, 2004) that integrates concordancer and sentence aligner, and that supports the visualization, the manual validation and the management of multilingual terminology database.
</nextsent>
<nextsent>the validated collocations are used for populating the lexicon of the parser and that of translation system (wehrli, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3204">
<title id=" W04-2802.xml">towards measuring scala bility in natural language understanding tasks </title>
<section> evaluating dialogue-, speech- and.  </section>
<citcontext>
<prevsection>
<prevsent>substitution error rate for filled slots table 1: discourse comprehension measurements these metrics are combined by means of combining the results of an m5 multiple linear regression algorithm and support vector regression approach.
</prevsent>
<prevsent>the resulting weighted sum is compared to human intuitions and paradise-like metrics concerning task completion rates and -times.
</prevsent>
</prevsection>
<citsent citstr=" P92-1004 ">
while this promising approach manage sto combine factors related to speech recognition, interpretation and discourse modeling, there are some shortcomings that stem from the fact that this schema was developed for single-domain systems that employ frame-based attribute value pairs for representing the users intent.recent advances in dialogue management and multi domain systems enable approaches that are more flexible than slot-filling, e.g. using discourse pegs, dialogue games and overlay operations for handling multiple tasks and cross-modal references (luperfoy, 1992; <papid> P92-1004 </papid>lockelt et al., 2002; pfleger et al, 2002; alexandersson and becker, 2003).</citsent>
<aftsection>
<nextsent>more importantly - for the topic of this paper - no means of measuring the priori discourse understanding difficulty is given.
</nextsent>
<nextsent>measuring precision, recall and f-measures: in the realm of semantic analyses the task of word sense disambiguation is usually regarded to be among the difficult ones.
</nextsent>
<nextsent>this means it can only be solved after all other problems involved in language understanding have been resolved as well.
</nextsent>
<nextsent>the hierarchical nature and interdependencies of the various tasks are mirrored in the results of the corresponding competitive evaluation tracts - e.g.the message understanding conference (muc) or senseval competition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3205">
<title id=" W04-2802.xml">towards measuring scala bility in natural language understanding tasks </title>
<section> measuring perplexity and baselines.  </section>
<citcontext>
<prevsection>
<prevsent>what is the corresponding f-measure, if the evaluated component guesses randomly - for chance performance metrics, ? what is the corresponding f-measure if the evaluated component always chooses the most frequent solution - for majority class performance metrics,?
</prevsent>
<prevsent>what is the corresponding f-measure of the estab lisched baseline classification method.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
much like kappa statistics proposed by carletta (1996), <papid> J96-2004 </papid>existing employments of majority class baselines assume an equal set of identical potential mark-ups, i.e. attributes and their values, for all markables.</citsent>
<aftsection>
<nextsent>therefore, they cannot be used in straight forward manner for many tasks that involve disjunct sets of attributes and values in terms of the type and number of attributes and their values involved in the classification task.
</nextsent>
<nextsent>this, however, is exactly what we find in natural language understanding tasks, such as semantic tagging or word sense disambiguation tasks (stevenson, 2003).
</nextsent>
<nextsent>additionally, baseline computed on other methods cannot serve as means for measuring scala bility, because of the circularity involved: as one would need way of measuring the baseline methods scala bility factor in the first place.
</nextsent>
<nextsent>table 3 provides an overview of the existing ways of measuring performance and task difficulty in automatic speech recognition and understanding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3206">
<title id=" W04-2802.xml">towards measuring scala bility in natural language understanding tasks </title>
<section> evaluating the metrics.  </section>
<citcontext>
<prevsection>
<prevsent>difficulty in three potential ways: ? eliminate parts of the corpus so that the number of values of the individual markables is decreased, we will call this vertical pruning; ? eliminate parts of the corpus so that the number of the individual values is decreased, we will call this horizontal pruning; ? eliminate parts of the corpus so that both the number of markables and their respective values is reduced, we will call this diagonal pruning.
</prevsent>
<prevsent>since each of these procedures can increase and reduce the overall task difficulty, we can use them to test if our proposed task entropy measure is able to reflect that in non toy-world example.
</prevsent>
</prevsection>
<citsent citstr=" W04-2312 ">
for our study we employ thesmartkom (wahlster, 2003) sense-tagged corpus employed in the word sense disambiguation study reported by (loos and porzel, 2004).<papid> W04-2312 </papid></citsent>
<aftsection>
<nextsent>an overview of the mark ables and their value distributions is given in appendix 1.
</nextsent>
<nextsent>we can now compute the entropy for the whole task as: htwhole = 1966.18083 2100 ? 0.94 for the horizontal pruning we removed all markables were single value assumed more than 90% of the entire set.
</nextsent>
<nextsent>intuitively that makes the task harder because we took out the easy cases which amounted to about 20% of the entire corpus.
</nextsent>
<nextsent>we can now compute the entropy for the horizontally eased task as: hthorizontal = 1718.07959 1548 ? 1.11 for the vertical pruning we removed all values of bi3 of the entire set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3207">
<title id=" W06-0406.xml">capturing disjunction in lexicalization with extensible dependency grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our subject matter in this paper is solely disjunction in lexicalization as basis for more advanced lexicalization models, andour purpose is precisely to describe constraint based model that (i) captures the disjunctive potential of lexicalization, i.e. allows the generation of all mutually paraphrasing solutions (accordingto given language model) to any given lexicalization task, (ii) ensures well-formedness, especially ruling out over-redundancy (such as found in dancing female dancer/ballerina/woman?)
</prevsent>
<prevsent>and syntactic anomalies (a dancer woman?), anddoes so (iii) modularly, in that not only are concerns neatly separated (e.g. semantics vs. syntax),but also solutions are reusable, and future extensions, likely to be developed with no change to current modules, (iv) efficiently, having an implementation yielding strong propagation and thus prone to keep complexity at acceptable levels, and(v) synergicly, inasmuch as it promotes the interplay between modules (namely syntax and semantics) and seems compatible with the concept of integrated generation architectures (reiter and dale, 2000), i.e. those in which tasks are not executed in pipeline, but are rather interleaved so as to avoid failed or sub optimal choices during search.
</prevsent>
</prevsection>
<citsent citstr=" W04-1510 ">
we build upon the extensible dependency grammar (xdg) (debusmann et al, 2004<papid> W04-1510 </papid>b; debusmann et al, 2004<papid> W04-1510 </papid>a; debusmann et al, 2005) model and its cp implementation in oz (van royand haridi, 2004), namely the xdg development toolkit1 (xdk) (debusmann et al, 2004<papid> W04-1510 </papid>c).</citsent>
<aftsection>
<nextsent>1http://www.ps.uni-sb.de/~rade/xdg.
</nextsent>
<nextsent>41 in fact, all those appealing goals of modularity, efficiency and synergy are innate to xdg and the xdk, and our work can most correctly be regarded as the very first attempts at equipping xdg for generation and fulfilling its bidirectional promise.the paper proceeds as follows.
</nextsent>
<nextsent>section 2 provides background information on xdg and thexdk.
</nextsent>
<nextsent>section 3 motivates our lexicalization disjunction model and describes it both intuitively and formally, while section 4 presents implementation highlights, assuming familiarity with the xdk and focusing on the necessary additions and modifications to it, as well as discussing performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3217">
<title id=" W06-0406.xml">capturing disjunction in lexicalization with extensible dependency grammar </title>
<section> extensible dependency grammar.  </section>
<citcontext>
<prevsection>
<prevsent>according to this technique, whenever node has but one incoming edge with reserved label, say del, on dimension it is considered as virtually deleted ond.
</prevsent>
<prevsent>in addition, one artificial root node is postulated from which emerge as many del edges as required on all dimensions.
</prevsent>
</prevsection>
<citsent citstr=" W04-0408 ">
the trick also comes inhandy when tackling, for instance, multiword expressions (debusmann, 2004), <papid> W04-0408 </papid>which involve worthy syntactic nodes that conceptually have no semantic counterparts.</citsent>
<aftsection>
<nextsent>in xdg generation input.
</nextsent>
<nextsent>having revised the basics of xdg, it is worth mentioning that so far it hasbeen used mostly for parsing, in which case the in put type is usually rather straightforward, namely typewritten sentences or possibly other text units.
</nextsent>
<nextsent>model creation is also very simple in parsing and consists of (i) creating exactly one node for each input token, all nodes being instances of one single homogeneous feature structure type automatically inferred from the grammar definition, (ii)making each node select from all the lexical entries indexed by its respective token, (iii) posing constraints automatically generated from the principles found in the grammar definition and (iv)deterministically assigning values to the order related variables in nodes so as to reflect the actual order of tokens in input.
</nextsent>
<nextsent>as concerns generation, things are not so clear, though.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3218">
<title id=" W06-0406.xml">capturing disjunction in lexicalization with extensible dependency grammar </title>
<section> modelling lexicalization disjunction.  </section>
<citcontext>
<prevsection>
<prevsent>thus, we postulate that every node should now have two new features, namely (i) hook, identifying the referent of the node,i.e. the variable it is about, and (ii) holes, mapping every pa edge label ` into the argument (a variable) every possible `-labelled outgoing edge should be about.
</prevsent>
<prevsent>normally these features should be lexicalized.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
the coincidence with copestake et al.s terminology (copestake et al, 2001) <papid> P01-1019 </papid>is not casual; in fact, our formulation can be regarded as decoupled fragment of theirs, since neither our holes involves syntactic labels nor are scopal issues ever touched.</citsent>
<aftsection>
<nextsent>as usual in xdg, we leave itfor other modules such as mentioned in the previous section to take charge of scope and the relationship between semantic arguments and syntactic roles.
</nextsent>
<nextsent>the role of these new features is depicted in figure 3, in which an arrow does not mean an edge but the possibility of establishing edges.
</nextsent>
<nextsent>completeness and compositionality.
</nextsent>
<nextsent>next we proceed to ensure completeness, i.e. that every so figure 3: for every node and on top of e.g. va lency constraints, features hook and holes further constrain the set of nodes able to receive edges from for each specific edge label.lution should convey the whole intended semantic content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3219">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in this paper we show that it is possible to approach the alignment accuracy of the standard models using algorithms that are much faster, and in some ways simpler, based on basic word-association statistics.
</prevsent>
<prevsent>bilingual word alignment is the first step of most current approaches to statistical machine translation.although the best performing systems are phrase based?
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
(see, for instance, och and ney (2004) or koehn et al (2003)), <papid> N03-1017 </papid>possible phrase translations must first be extracted from word-aligned bilingual text segments.</citsent>
<aftsection>
<nextsent>the standard approach to word alignment makes use of five translation models defined by brown et al (1993), <papid> J93-2003 </papid>sometimes augmented by an hmm-based model or och and neys model6?</nextsent>
<nextsent>(och and ney, 2003).<papid> J03-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3220">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>bilingual word alignment is the first step of most current approaches to statistical machine translation.although the best performing systems are phrase based?
</prevsent>
<prevsent>(see, for instance, och and ney (2004) or koehn et al (2003)), <papid> N03-1017 </papid>possible phrase translations must first be extracted from word-aligned bilingual text segments.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the standard approach to word alignment makes use of five translation models defined by brown et al (1993), <papid> J93-2003 </papid>sometimes augmented by an hmm-based model or och and neys model6?</citsent>
<aftsection>
<nextsent>(och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>the best of these models can produce high accuracy alignments, at least when trained on large parallel corpus of fairly direct translations in closely related languages.there are number of ways in which these standard models are less than ideal, however.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3221">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>(see, for instance, och and ney (2004) or koehn et al (2003)), <papid> N03-1017 </papid>possible phrase translations must first be extracted from word-aligned bilingual text segments.</prevsent>
<prevsent>the standard approach to word alignment makes use of five translation models defined by brown et al (1993), <papid> J93-2003 </papid>sometimes augmented by an hmm-based model or och and neys model6?</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
(och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the best of these models can produce high accuracy alignments, at least when trained on large parallel corpus of fairly direct translations in closely related languages.there are number of ways in which these standard models are less than ideal, however.
</nextsent>
<nextsent>thehigher-accuracy models are mathematically complex, and also difficult to train, as they do not fact orin way that permits dynamic programming solution.
</nextsent>
<nextsent>it can thus take many hours of processing time on current standard computers to train the models and produce an alignment of large parallel corpus.
</nextsent>
<nextsent>in this paper, we take different approach toword alignment, based on the use of bilingual word association statistics rather than the generative probabilistic framework that the ibm and hmm models use.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3223">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> data and methodology for these.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we take different approach toword alignment, based on the use of bilingual word association statistics rather than the generative probabilistic framework that the ibm and hmm models use.
</prevsent>
<prevsent>in the end we obtain alignment algorithms that are much faster, and in some ways simpler, whose accuracy comes surprisingly close to the established probabilistic generative approach.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
experiments the experiments reported here were carried out using data from the workshop on building and using parallel texts held at hlt-naacl 2003 (mihalceaand pedersen, 2003).<papid> W03-0301 </papid></citsent>
<aftsection>
<nextsent>for the majority of our experiments, we used subset of the canadian hansardsbilingual corpus supplied for the workshop, comprising 500,000 english-french sentences pairs, including 37 sentence pairs designated as trial?
</nextsent>
<nextsent>data, and 447 sentence pairs designated as test data.
</nextsent>
<nextsent>the trial and test data have been manually aligned atthe word level, noting particular pairs of words either as sure?
</nextsent>
<nextsent>or possible?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3227">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> the log-likelihood-ratio association.  </section>
<citcontext>
<prevsection>
<prevsent>and the hand alignments of the words in the trial and test data were created by franz och and hermann ney (och and ney, 2003).<papid> J03-1002 </papid></prevsent>
<prevsent>the manual word alignments for the english-romanian test data were created by rada mihalcea and ted pedersen.</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
measure we base all our association-based word-alignmentmethods on the log-likelihood-ratio (llr) statistic introduced to the nlp community by dunning(1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>we chose this statistic because it has previously been found to be effective for automatically constructing translation lexicons (e.g., melamed,2000).<papid> J00-2004 </papid></nextsent>
<nextsent>we compute llr scores using the following formula presented by moore (2004): <papid> W04-3243 </papid>llr(f, e) = ? f??{f,f} ? e??{e,e} c(f?, e?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3228">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> the log-likelihood-ratio association.  </section>
<citcontext>
<prevsection>
<prevsent>the manual word alignments for the english-romanian test data were created by rada mihalcea and ted pedersen.
</prevsent>
<prevsent>measure we base all our association-based word-alignmentmethods on the log-likelihood-ratio (llr) statistic introduced to the nlp community by dunning(1993).<papid> J93-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
we chose this statistic because it has previously been found to be effective for automatically constructing translation lexicons (e.g., melamed,2000).<papid> J00-2004 </papid></citsent>
<aftsection>
<nextsent>we compute llr scores using the following formula presented by moore (2004): <papid> W04-3243 </papid>llr(f, e) = ? f??{f,f} ? e??{e,e} c(f?, e?)</nextsent>
<nextsent>log p(f?|e?)p(f?) in this formula and mean that the words whose degree of association is being measured occur in the respective target and source sentences of an aligned sentence pair, and mean that the corresponding words do not occur in the respective sentences, f?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3229">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> the log-likelihood-ratio association.  </section>
<citcontext>
<prevsection>
<prevsent>measure we base all our association-based word-alignmentmethods on the log-likelihood-ratio (llr) statistic introduced to the nlp community by dunning(1993).<papid> J93-1003 </papid></prevsent>
<prevsent>we chose this statistic because it has previously been found to be effective for automatically constructing translation lexicons (e.g., melamed,2000).<papid> J00-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3243 ">
we compute llr scores using the following formula presented by moore (2004): <papid> W04-3243 </papid>llr(f, e) = ? f??{f,f} ? e??{e,e} c(f?, e?)</citsent>
<aftsection>
<nextsent>log p(f?|e?)p(f?) in this formula and mean that the words whose degree of association is being measured occur in the respective target and source sentences of an aligned sentence pair, and mean that the corresponding words do not occur in the respective sentences, f?
</nextsent>
<nextsent>and e?
</nextsent>
<nextsent>are variables ranging over these values,and c(f?, e?)
</nextsent>
<nextsent>is the observed joint count for the values of f?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3233">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the literature on measures of bilingual word association is too large to review thoroughly, but mostly it concerns extracting bilingual lexicons rather than word alignment.
</prevsent>
<prevsent>we discuss three previous research efforts that seem particularly relevant here.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
gale and church (1991) <papid> H91-1026 </papid>made what may be the first application of word association to word align ment.</citsent>
<aftsection>
<nextsent>their method seems somewhat like our method 1b.
</nextsent>
<nextsent>they use word association score directly, although they use the 2 statistic instead of llr, and they consider forward jumps as well as backward jumps in probability model in place ofour nonmonotonicity measure.
</nextsent>
<nextsent>they report 61% recall at 95% precision on canadian hansa rds data.
</nextsent>
<nextsent>obviously, we are building directly on the work of melamed (2000), <papid> J00-2004 </papid>sharing his use of the llr statistic and adopting his competitive linking algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3235">
<title id=" W05-0801.xml">association based bilingual word alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>moreover,melamed makes no provision for other than one-toone alignments, and he does not deal with the problem of turning word type alignment into word token alignment.
</prevsent>
<prevsent>as table 4 shows, this is crucial to obtaining high accuracy alignments.
</prevsent>
</prevsection>
<citsent citstr=" P03-1012 ">
finally, our work is similar to that of cherry andlin (2003) <papid> P03-1012 </papid>in our use of the conditional probability of link given the co-occurrence of the linkedwords.</citsent>
<aftsection>
<nextsent>cherry and lin generalize this idea to incorporate additional features of the aligned sentence pair into the conditioning information.
</nextsent>
<nextsent>the chief difference between their work and ours, however, is their dependence on having parses for the sentences in one of the languages being aligned.
</nextsent>
<nextsent>they use thisto enforce phrasal coherence constraint, which basically says that word alignments cannot cross constituent boundaries.
</nextsent>
<nextsent>they report excellent alignment 7accuracy using this approach, and one way of comparing our results to theirs is to say that we show it is also possible to get good results (at least for english and french) by using nonmonotonicity information in place of constituency information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3237">
<title id=" W05-1522.xml">from meta grammars to factor ized tagtig parsers </title>
<section> grammar anatomy.  </section>
<citcontext>
<prevsection>
<prevsent>the tree is controlled by 35 guards, governing, for instance, the presence and position of subject and of clitics.such tree covers much more verb subcategorization frames than the number of frames usually attached to given verb.
</prevsent>
<prevsent>the anchoring of tree ? by word is done by unifying two feature structures h?
</prevsent>
</prevsection>
<citsent citstr=" C00-1065 ">
and hw, called hyper tags (kinyon, 2000), <papid> C00-1065 </papid>that list the syntactic properties covered by ? and allowed by w. the link between h?</citsent>
<aftsection>
<nextsent>and the allowed syntactic constructions is done through the variables occurring inh?
</nextsent>
<nextsent>and in the guards and node decorations.
</nextsent>
<nextsent>the resulting french grammar has been compiled, with dyalog, into an hybrid tag/tig parser, by identifying the left and right auxiliary insertion trees.
</nextsent>
<nextsent>following left-to-right top-down tabular parsing strategy, the parser may be used to get either full or partial parses.2 coverage rate for full parsing is around 95% for two test suites (eurotra and tsnlp) and around 42% on various corpora (including more than 300k sentences of raw journalistic corpus).our mg is still very young and needs to be improved to ensure better coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3238">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present classifier-based parser that produces constituent trees in linear time.
</prevsent>
<prevsent>the parser uses basic bottom-up shift reduce algorithm, but employs classifier to determine parser actions instead of grammar.
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
this can be seen as an extension of the deterministic dependency parser of nivre and scholz (2004) <papid> C04-1010 </papid>to full constituent parsing.</citsent>
<aftsection>
<nextsent>we show that, with an appropriate feature set used in classification, very simple one-path greedy parser can perform at the same level of accuracy as more complex parsers.
</nextsent>
<nextsent>we evaluate our parser on section 23 of the wsj section of the penn treebank, and obtain precision and recall of 87.54% and 87.61%, respectively.
</nextsent>
<nextsent>two classifier-based deterministic dependency parsers for english have been proposed recently (nivre and scholz, 2004; <papid> C04-1010 </papid>yamada and matsumoto, 2003).</nextsent>
<nextsent>although they use different parsing algorithms, and differ on whether or not dependencies are labeled, they share the idea of greedily pursuing single path, following parsing decisions made by classifier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3242">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although they use different parsing algorithms, and differ on whether or not dependencies are labeled, they share the idea of greedily pursuing single path, following parsing decisions made by classifier.
</prevsent>
<prevsent>despite their greedy nature, these parsers achieve high accuracy in determining dependencies.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
although state-of-the-art statistical parsers (collins, 1997; <papid> P97-1003 </papid>charniak, 2000) <papid> A00-2018 </papid>are more accurate, the simplicity and efficiency of deterministic parsers make them attractive in number of situations requiring fast, light-weight parsing, or parsing of large amounts of data.</citsent>
<aftsection>
<nextsent>however, dependency analyses lack important information contained in constituent structures.
</nextsent>
<nextsent>for example, the tree-path feature has been shown to be valuable in semantic role labeling (gildea and palmer, 2002).<papid> P02-1031 </papid></nextsent>
<nextsent>we present parser that shares much of the simplicity and efficiency of the deterministic dependency parsers, but produces both dependency and constituent structures simultaneously.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3243">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although they use different parsing algorithms, and differ on whether or not dependencies are labeled, they share the idea of greedily pursuing single path, following parsing decisions made by classifier.
</prevsent>
<prevsent>despite their greedy nature, these parsers achieve high accuracy in determining dependencies.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
although state-of-the-art statistical parsers (collins, 1997; <papid> P97-1003 </papid>charniak, 2000) <papid> A00-2018 </papid>are more accurate, the simplicity and efficiency of deterministic parsers make them attractive in number of situations requiring fast, light-weight parsing, or parsing of large amounts of data.</citsent>
<aftsection>
<nextsent>however, dependency analyses lack important information contained in constituent structures.
</nextsent>
<nextsent>for example, the tree-path feature has been shown to be valuable in semantic role labeling (gildea and palmer, 2002).<papid> P02-1031 </papid></nextsent>
<nextsent>we present parser that shares much of the simplicity and efficiency of the deterministic dependency parsers, but produces both dependency and constituent structures simultaneously.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3244">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although state-of-the-art statistical parsers (collins, 1997; <papid> P97-1003 </papid>charniak, 2000) <papid> A00-2018 </papid>are more accurate, the simplicity and efficiency of deterministic parsers make them attractive in number of situations requiring fast, light-weight parsing, or parsing of large amounts of data.</prevsent>
<prevsent>however, dependency analyses lack important information contained in constituent structures.</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
for example, the tree-path feature has been shown to be valuable in semantic role labeling (gildea and palmer, 2002).<papid> P02-1031 </papid></citsent>
<aftsection>
<nextsent>we present parser that shares much of the simplicity and efficiency of the deterministic dependency parsers, but produces both dependency and constituent structures simultaneously.
</nextsent>
<nextsent>like the parser of nivre and scholz (2004), <papid> C04-1010 </papid>it uses the basic shift-reduce stack-based parsing algorithm, and runs in linear time.</nextsent>
<nextsent>while it may seem that the larger search space of constituent trees (compared to the space of dependency trees) would make it unlikely that accurate parse trees could be built deterministically, we show that the precision and recall of constituents produced by our parser are close to those produced by statistical parsers with higher run-time complexity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3247">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> parser description.  </section>
<citcontext>
<prevsection>
<prevsent>our parser employs basic bottom-up shift-reduce parsing algorithm, requiring only single pass over the input string.
</prevsent>
<prevsent>the algorithm considers only trees with unary and binary branching.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
in order to use trees with arbitrary branching for training, or generating them with the parser, we employ an instance of the transformation/detransformation process described in (johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>in our case, the transformation step involves simply converting each production with children (where   2) into ? 1 binary productions.
</nextsent>
<nextsent>trees must be lexical ized1, so that the newly created internal structure of constituents with previous branching of more than two contains only subtrees with the same lexical head as the original constituent.
</nextsent>
<nextsent>additional nonterminal symbols introduced in this process are clearly marked.
</nextsent>
<nextsent>the transformed (or binarized?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3253">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> similarities to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned before, our parser shares similarities with the dependency parsers of yamada and matsumoto (2003) and nivre and scholz (2004) <papid> C04-1010 </papid>in that it uses classifier to guide the parsing process in deterministic fashion.</prevsent>
<prevsent>while yamada and matsumoto use quadratic run-time algorithm with multiple passes over the input string, nivre and scholz use simplified version of the algorithm described here, which handles only (labeled or unlabeled) dependency structures.</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
additionally, our parser is in some ways similar to the maximum-entropy parser of ratnaparkhi (1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>ratnaparkhis parser uses maximum entropy models to determine the actions of shift reduce-like parser, but it is capable of pursuing several paths and returning the top-k highest scoring parses for sentence.
</nextsent>
<nextsent>its observed time is linear, but parsing is somewhat slow, with sentences of length 20 or more taking more than one second to parse, and sentences of length 40 or more taking more than three seconds.
</nextsent>
<nextsent>our parser only pursues one path per sentence, but it is very fast and of comparable accuracy (see section 4).
</nextsent>
<nextsent>in addition, ratnaparkhis parser uses more involved algorithm that allows it to work with arbitrary branching trees without the need of the binarization transform employed here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3254">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> similarities to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>it breaks the usual reduce actions into smaller pieces (check and build), and uses two separate passes (not including the pos tagging pass) for determining chunks and higher syntactic structures separately.
</prevsent>
<prevsent>finally, there have been other deterministic shift-reduce parsers introduced recently, but their levels of accuracy have been well below the state of-the-art.
</prevsent>
</prevsection>
<citsent citstr=" W04-3203 ">
the parser in kalt (2004) <papid> W04-3203 </papid>uses similar algorithm to the one described here, but the classification task is framed differently.</citsent>
<aftsection>
<nextsent>using decision trees and fewer features, kalts parser has significantly faster training and parsing times, but its accuracy is much lower than that of our parser.
</nextsent>
<nextsent>kalts parser achieves precision and recall of about 77% and 76%, respectively (with automatically tagged text), compared to our parsers 86% (see section 4).
</nextsent>
<nextsent>the parser of wong and wu (1999) uses separate np-chunking step and, like ratnaparkhis parser, does not require binary trans 129 form.
</nextsent>
<nextsent>it achieves about 81% precision and 82% recall with gold-standard tags (78% and 79% with automatically tagged text).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3255">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>wong and wus parser is further differentiated from the other parsers mentioned here in that it does not use lexical items, working only from part-of-speech tags.
</prevsent>
<prevsent>we conducted experiments with the parser described in section 2 using two different classifiers: tinysvm (a support vector machine implementation by taku kudo)2, and the memory-based learner timbl (daelemans et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we trained and tested the parser on the wall street journal corpus of the penn treebank (marcus et al., 1993) <papid> J93-2004 </papid>using the standard split: sections 2-21 were used for training, section 22 was used forde velopment and tuning of parameters and features, and section 23 was used for testing.</citsent>
<aftsection>
<nextsent>every experiment reported here was performed on pentium iv 1.8ghz with 1gb of ram.
</nextsent>
<nextsent>each tree in the training set had empty-node and function tag information removed, and the 2 http://chasen.org/~taku/software/tinysvm trees were lexicalized using similar head-table rules as those mentioned in (collins, 1996).
</nextsent>
<nextsent>the trees were then converted into trees containing only unary and binary branching, using the binari zation transform described in section 2.
</nextsent>
<nextsent>classifier training instances of features paired with classes (parser actions) were extracted from the trees in the training set, as described in section 2.3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3264">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>at the same time, it is significantly more accurate than previously proposed deterministic parsers for constituent structures.
</prevsent>
<prevsent>we have also shown that much of the success of classifier-based parser depends on what classifier is used.
</prevsent>
</prevsection>
<citsent citstr=" P01-1069 ">
while this may seem obvious, the differences observed here are much greater than what would be expected from looking, for example, at results from chunking/shallow parsing (zhang et al., 2001; <papid> P01-1069 </papid>kudo and matsumoto, 2001; <papid> N01-1025 </papid>veenstra and vanden bosch, 2000).</citsent>
<aftsection>
<nextsent>future work includes the investigation of the effects of individual features, the use of additional classification features, and the use of different classifiers.
</nextsent>
<nextsent>in particular, the use of tree features seems appealing.
</nextsent>
<nextsent>this may be accomplished with svms 131 using tree kernel, or the tree boosting classifier bact described in (kudo and matsumoto, 2004).<papid> W04-3239 </papid></nextsent>
<nextsent>additionally, we plan to investigate the use of the beam strategy of ratnaparkhi (1997) <papid> W97-0301 </papid>to pursue multiple parses while keeping the run-time linear.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3265">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>at the same time, it is significantly more accurate than previously proposed deterministic parsers for constituent structures.
</prevsent>
<prevsent>we have also shown that much of the success of classifier-based parser depends on what classifier is used.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
while this may seem obvious, the differences observed here are much greater than what would be expected from looking, for example, at results from chunking/shallow parsing (zhang et al., 2001; <papid> P01-1069 </papid>kudo and matsumoto, 2001; <papid> N01-1025 </papid>veenstra and vanden bosch, 2000).</citsent>
<aftsection>
<nextsent>future work includes the investigation of the effects of individual features, the use of additional classification features, and the use of different classifiers.
</nextsent>
<nextsent>in particular, the use of tree features seems appealing.
</nextsent>
<nextsent>this may be accomplished with svms 131 using tree kernel, or the tree boosting classifier bact described in (kudo and matsumoto, 2004).<papid> W04-3239 </papid></nextsent>
<nextsent>additionally, we plan to investigate the use of the beam strategy of ratnaparkhi (1997) <papid> W97-0301 </papid>to pursue multiple parses while keeping the run-time linear.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3266">
<title id=" W05-1513.xml">a classifier based parser with linear runtime complexity </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>future work includes the investigation of the effects of individual features, the use of additional classification features, and the use of different classifiers.
</prevsent>
<prevsent>in particular, the use of tree features seems appealing.
</prevsent>
</prevsection>
<citsent citstr=" W04-3239 ">
this may be accomplished with svms 131 using tree kernel, or the tree boosting classifier bact described in (kudo and matsumoto, 2004).<papid> W04-3239 </papid></citsent>
<aftsection>
<nextsent>additionally, we plan to investigate the use of the beam strategy of ratnaparkhi (1997) <papid> W97-0301 </papid>to pursue multiple parses while keeping the run-time linear.</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3269">
<title id=" W06-0205.xml">automatic knowledge representation using a graph based algorithm for language independent lexical chaining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as consequence, our methodology can be applied to any language and proposes solution to language dependent lexical chainers.
</prevsent>
<prevsent>lexical chains are powerful representations of documents compared to broadly used bag-of-words representations.
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
in particular, they have successfully been used in the field of automatic text summarization (barzilay and elhadad, 1997).<papid> W97-0703 </papid></citsent>
<aftsection>
<nextsent>however, until now, lexical chaining algorithms have only been proposed for english as they relyon linguistic resources such as thesauri (morris and hirst, 1991) <papid> J91-1002 </papid>or ontologies (barzilay and elhadad, 1997; <papid> W97-0703 </papid>hirst and st-onge, 1997; silber and mccoy, 2002; <papid> J02-4004 </papid>galley and mckeown, 2003).</nextsent>
<nextsent>morris and hirst (1991) <papid> J91-1002 </papid>were the first to propose the concept of lexical chains to explore the discourse structure of text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3270">
<title id=" W06-0205.xml">automatic knowledge representation using a graph based algorithm for language independent lexical chaining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical chains are powerful representations of documents compared to broadly used bag-of-words representations.
</prevsent>
<prevsent>in particular, they have successfully been used in the field of automatic text summarization (barzilay and elhadad, 1997).<papid> W97-0703 </papid></prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
however, until now, lexical chaining algorithms have only been proposed for english as they relyon linguistic resources such as thesauri (morris and hirst, 1991) <papid> J91-1002 </papid>or ontologies (barzilay and elhadad, 1997; <papid> W97-0703 </papid>hirst and st-onge, 1997; silber and mccoy, 2002; <papid> J02-4004 </papid>galley and mckeown, 2003).</citsent>
<aftsection>
<nextsent>morris and hirst (1991) <papid> J91-1002 </papid>were the first to propose the concept of lexical chains to explore the discourse structure of text.</nextsent>
<nextsent>however, at the time of writing their paper, no machine-readable thesaurus was available so they manually generated lexical chains using rogets thesaurus (roget, 1852).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3276">
<title id=" W06-0205.xml">automatic knowledge representation using a graph based algorithm for language independent lexical chaining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical chains are powerful representations of documents compared to broadly used bag-of-words representations.
</prevsent>
<prevsent>in particular, they have successfully been used in the field of automatic text summarization (barzilay and elhadad, 1997).<papid> W97-0703 </papid></prevsent>
</prevsection>
<citsent citstr=" J02-4004 ">
however, until now, lexical chaining algorithms have only been proposed for english as they relyon linguistic resources such as thesauri (morris and hirst, 1991) <papid> J91-1002 </papid>or ontologies (barzilay and elhadad, 1997; <papid> W97-0703 </papid>hirst and st-onge, 1997; silber and mccoy, 2002; <papid> J02-4004 </papid>galley and mckeown, 2003).</citsent>
<aftsection>
<nextsent>morris and hirst (1991) <papid> J91-1002 </papid>were the first to propose the concept of lexical chains to explore the discourse structure of text.</nextsent>
<nextsent>however, at the time of writing their paper, no machine-readable thesaurus was available so they manually generated lexical chains using rogets thesaurus (roget, 1852).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3292">
<title id=" W06-0205.xml">automatic knowledge representation using a graph based algorithm for language independent lexical chaining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second step of the process aims at automatically extracting lexical chains from texts based on our knowledge base.
</prevsent>
<prevsent>for that purpose, we propose anew greedy algorithm which can be seen as an extension of (hirst and st-onge, 1997) and (barzilayand elhadad, 1997) <papid> W97-0703 </papid>algorithms which allows polysemous words to belong to different chains thus breaking the one-word/one-concept per document?</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
paradigm (gale et al, 1992)<papid> H92-1045 </papid>1.</citsent>
<aftsection>
<nextsent>in particular, it imple1this characteristic can be interesting for multi-topic documents like web news stories.
</nextsent>
<nextsent>indeed, in this case, there may be different topics in the same document as different news stories may appear.
</nextsent>
<nextsent>in some way, it follows the idea of (krovetz, 1998).
</nextsent>
<nextsent>ments (lin, 1998) information-theoretic definition of similarity as the relatedness criterion for the attribution of words to lexical chains2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3293">
<title id=" W06-0205.xml">automatic knowledge representation using a graph based algorithm for language independent lexical chaining </title>
<section> building similarity matrix.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 data preparation.
</prevsent>
<prevsent>the context corpus is first pre-processed in order to extract nominal units from it.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the tnt tagger(brants, 2000) <papid> A00-1031 </papid>is first applied to our context corpus to morpho-syntactically mark all the words in it.</citsent>
<aftsection>
<nextsent>once all words have been morpho-syntactically tagged, we apply the statistically-based multiword unit extractor senta (dias et al, 1999) that extracts multiword units based on any input text3.
</nextsent>
<nextsent>for example, multiword units are compound nouns (freekick), compound determinants (an amount of), verbal locutions (to put forward), adjectival locutions (dark blue) or institutionalized phrases (con carne).
</nextsent>
<nextsent>finally, we use set of well-known heuristics (daille, 1995) to retrieve compound nouns using theidea that groups of words that correspond to priori defined syntactical patterns such as adj+noun, noun+noun, noun+prep+noun can be identified as compound nouns.
</nextsent>
<nextsent>indeed, nouns usually convey most of the information in written text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3316">
<title id=" W05-0203.xml">a real time multiple choice question generation for language testing a preliminary study </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we should differentiate the features from the ones which are used to generate, for example, history questions, which require rather background knowledge.
</prevsent>
<prevsent>selecting suitable distrac tors, which is left to future work, would be more important process in generating question.
</prevsent>
</prevsection>
<citsent citstr=" W03-0203 ">
a semantic distance between an alternative and the right answer are suggested (mitkov and ha, 2003), <papid> W03-0203 </papid>to be good measure to evaluate an alternative.</citsent>
<aftsection>
<nextsent>we are investigating on method of measuring those distances and mechanism to retrieve best alternatives automatically.
</nextsent>
<nextsent>we have presented novel application of automatically generating fill-in-the-blank, multiple-choice questions using machine learning techniques, as well as real-time system implemented.
</nextsent>
<nextsent>although it is required to explore more feature settings for the process of determining blank positions, and the process of choosing dis tractors needs more elaboration, the system has proved to be feasible.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3317">
<title id=" W05-1501.xml">efficient and robust lfg parsing sxlfg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this reason, we designed parser that is compatible with linguistic theory, namely lfg, as well as robust and efficient despite the high variability of language production.developing new parser for lfg (lexical functional grammars, see, e.g., (kaplan, 1989)) isnot in itself very original.
</prevsent>
<prevsent>several lfg parsers already exist, including those of (andrews, 1990) or (briffault et al, 1997).
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
however, the most famous lfg system is undoubtedly the xerox linguistics environment (xle) project which is the successor of the grammars writers workbench (kaplan and maxwell, 1994; riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004).<papid> N04-1013 </papid></citsent>
<aftsection>
<nextsent>xle is large project which concentrates lot of linguistic and computational technology, relies on similar point of view on the balance between shallow and deep parsing, and has been successfully used to parse large unrestricted corpora.
</nextsent>
<nextsent>nevertheless, these parsers do not always use inthe most extensive way all existing algorithmic techniques of computation sharing and compact information representation that make it possible to write an efficient lfg parser, despite the fact that the lfgformalism, as many other formalisms relying on unification, is np-hard.
</nextsent>
<nextsent>of course our purpose is not tomake new xle system but to study how robustness and efficiency can be reached in lfg parsing on raw text.
</nextsent>
<nextsent>building constituent structures (c-structures) doesnot raise any particular problem in theory,1 be cause they are described in lfg by context-freegrammar (cfg), called (cf) backbone in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3321">
<title id=" W05-1501.xml">efficient and robust lfg parsing sxlfg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this reason, we designed parser that is compatible with linguistic theory, namely lfg, as well as robust and efficient despite the high variability of language production.developing new parser for lfg (lexical functional grammars, see, e.g., (kaplan, 1989)) isnot in itself very original.
</prevsent>
<prevsent>several lfg parsers already exist, including those of (andrews, 1990) or (briffault et al, 1997).
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
however, the most famous lfg system is undoubtedly the xerox linguistics environment (xle) project which is the successor of the grammars writers workbench (kaplan and maxwell, 1994; riezler et al, 2002; <papid> P02-1035 </papid>kaplan et al, 2004).<papid> N04-1013 </papid></citsent>
<aftsection>
<nextsent>xle is large project which concentrates lot of linguistic and computational technology, relies on similar point of view on the balance between shallow and deep parsing, and has been successfully used to parse large unrestricted corpora.
</nextsent>
<nextsent>nevertheless, these parsers do not always use inthe most extensive way all existing algorithmic techniques of computation sharing and compact information representation that make it possible to write an efficient lfg parser, despite the fact that the lfgformalism, as many other formalisms relying on unification, is np-hard.
</nextsent>
<nextsent>of course our purpose is not tomake new xle system but to study how robustness and efficiency can be reached in lfg parsing on raw text.
</nextsent>
<nextsent>building constituent structures (c-structures) doesnot raise any particular problem in theory,1 be cause they are described in lfg by context-freegrammar (cfg), called (cf) backbone in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3325">
<title id=" W05-1501.xml">efficient and robust lfg parsing sxlfg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, this shared forest is used, as whole, to decide which functional constraints to process.
</prevsent>
<prevsent>for ambiguous cf backbones, this two pass computation is more efficient than inter leaving phrasal and functional constraints.3 another advantage of this two pass vision is that the cf parser may be easily replaced by another one.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
it may also be replaced by more powerful parser.4 we choose to evaluate functional constraints directly on the shared forest since it has been proven (see (maxwell and kaplan, 1993)), <papid> J93-4001 </papid>as one can easily expect, that techniques which evaluate functional constraints on an enumeration of the resulting phrase-structure trees are computational disaster.</citsent>
<aftsection>
<nextsent>this article explores the computation of f-structures directly (without un folding) on shared forests.
</nextsent>
<nextsent>we will see how, in some cases, our parser allows to deal with potential combinatorial explosion.
</nextsent>
<nextsent>moreover, at all levels, error recovering mechanisms turn our system into robust parser.
</nextsent>
<nextsent>our parser, called sxlfg, has been evaluated with two large-coverage grammars for french, on corpora of various genres.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3350">
<title id=" W04-3217.xml">automatic analysis of plot for story rewriting </title>
<section> a minimal event calculus </section>
<citcontext>
<prevsection>
<prevsent>burstein et. al.
</prevsent>
<prevsent>(2003) uses rhetorical structure theory to parse the text into discourse relations based on satellites and nuclei connected by rhetorical relations.
</prevsent>
</prevsection>
<citsent citstr=" J92-4007 ">
moore and pollack (1992) <papid> J92-4007 </papid>note that rhetorical structure theory conflates the informational (the information being conveyed) and intentional (the effects on the readers beliefs or atti tudes) levels of discourse.</citsent>
<aftsection>
<nextsent>narratives are primarily informational, and so tend to degenerate to long sequences of elaboration or sequence relations.
</nextsent>
<nextsent>sincein the story rewriting task the students are attempting to convey information about the narrative, unlike the primarily persuasive task of an essay, our system focuses on the informational level as embodied by simplified event calculus.
</nextsent>
<nextsent>another tutoring system similar to ours is the why physics tutoring system (rose et al, 2002).
</nextsent>
<nextsent>we formulate only three categories to describestories: events, event names, and entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3351">
<title id=" W04-3217.xml">automatic analysis of plot for story rewriting </title>
<section> a minimal event calculus </section>
<citcontext>
<prevsection>
<prevsent>this is because the use of such verbs is an indicator of the presence of anevent in the story.
</prevsent>
<prevsent>in this manner events are relationships labeled with an event name, and entities are arguments to these relationships as in propositionallogic.
</prevsent>
</prevsection>
<citsent citstr=" W03-0907 ">
together these can form events such as be come(boy,elf), and this formulation maps partially onto shana hans event calculus which has been used in other story-understanding models (mueller,2003).<papid> W03-0907 </papid></citsent>
<aftsection>
<nextsent>the key difference between an event calculus and collection of propositions is that time is explicitly represented in the event calculus.
</nextsent>
<nextsent>each story consists of group of events that are present in the story, e1...eh.
</nextsent>
<nextsent>each event consists ofan event name, time variable t, and set of entities arranged in an ordered set n1...na.
</nextsent>
<nextsent>an event must contain one and only one event name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3352">
<title id=" W04-3217.xml">automatic analysis of plot for story rewriting </title>
<section> extracting the event calculus.  </section>
<citcontext>
<prevsection>
<prevsent>for our pipeline we used lt-ttt (language technology text tokenization toolkit) (grover et al, 2000).
</prevsent>
<prevsent>once words are tokenized and sentence boundaries detected by lt-ttt, lt-pos tags the words using the penn treebank tag-set without parsing the sentences.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
while full parse could be generated by astatistical parser, such parses would likely be incorrect for the ungrammatical sentences often generated by the pupils (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>pronouns are resolved using cascading rule-based approach directly inspired by the cogniac algorithm (bald win, 1997) with two variations.
</nextsent>
<nextsent>first, it resolves indistinct cascades for singular and then plural pronouns.
</nextsent>
<nextsent>second, it resolves using only the cogniac rules that can be determined using penn treebank tags.
</nextsent>
<nextsent>the words are lemmatized using an augmented version of the scol toolset and sentences are chunked using the cass chunker (abney, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3353">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in way, the translation of sentences into other natural languages serves as an approximation of (much more costly) manual structural or semantic annotation ? one might speak of automatic indirect supervision in learning.
</prevsent>
<prevsent>the technique will be most useful for low-resource languages and languages for which there is no funding for tree banking activities.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the only requirement will be that parallel corpus exist for the language under consideration and one or more other languages.2 induction of grammars from parallel corpora is rarely viewed as promising task in its own right; in work that has addressed the issue directly (wu,1997; <papid> J97-3002 </papid>melamed, 2003; <papid> N03-1021 </papid>melamed, 2004), <papid> P04-1083 </papid>the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in noisy channel approach to statistical mt.3 in the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given word alignment.</citsent>
<aftsection>
<nextsent>this work represents second pilot study (after (kuhn, 2004))<papid> P04-1060 </papid>for the longer-term ptolemaios project at saarland university4 with the goal of learning linguistic grammars from parallel corpora (compare (kuhn, 2005)).</nextsent>
<nextsent>the grammars should be robust and assign 2in the present paper we use examples from english/german for illustration, but the approach is of course independent of the language pair under consideration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3354">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in way, the translation of sentences into other natural languages serves as an approximation of (much more costly) manual structural or semantic annotation ? one might speak of automatic indirect supervision in learning.
</prevsent>
<prevsent>the technique will be most useful for low-resource languages and languages for which there is no funding for tree banking activities.
</prevsent>
</prevsection>
<citsent citstr=" N03-1021 ">
the only requirement will be that parallel corpus exist for the language under consideration and one or more other languages.2 induction of grammars from parallel corpora is rarely viewed as promising task in its own right; in work that has addressed the issue directly (wu,1997; <papid> J97-3002 </papid>melamed, 2003; <papid> N03-1021 </papid>melamed, 2004), <papid> P04-1083 </papid>the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in noisy channel approach to statistical mt.3 in the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given word alignment.</citsent>
<aftsection>
<nextsent>this work represents second pilot study (after (kuhn, 2004))<papid> P04-1060 </papid>for the longer-term ptolemaios project at saarland university4 with the goal of learning linguistic grammars from parallel corpora (compare (kuhn, 2005)).</nextsent>
<nextsent>the grammars should be robust and assign 2in the present paper we use examples from english/german for illustration, but the approach is of course independent of the language pair under consideration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3355">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in way, the translation of sentences into other natural languages serves as an approximation of (much more costly) manual structural or semantic annotation ? one might speak of automatic indirect supervision in learning.
</prevsent>
<prevsent>the technique will be most useful for low-resource languages and languages for which there is no funding for tree banking activities.
</prevsent>
</prevsection>
<citsent citstr=" P04-1083 ">
the only requirement will be that parallel corpus exist for the language under consideration and one or more other languages.2 induction of grammars from parallel corpora is rarely viewed as promising task in its own right; in work that has addressed the issue directly (wu,1997; <papid> J97-3002 </papid>melamed, 2003; <papid> N03-1021 </papid>melamed, 2004), <papid> P04-1083 </papid>the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in noisy channel approach to statistical mt.3 in the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given word alignment.</citsent>
<aftsection>
<nextsent>this work represents second pilot study (after (kuhn, 2004))<papid> P04-1060 </papid>for the longer-term ptolemaios project at saarland university4 with the goal of learning linguistic grammars from parallel corpora (compare (kuhn, 2005)).</nextsent>
<nextsent>the grammars should be robust and assign 2in the present paper we use examples from english/german for illustration, but the approach is of course independent of the language pair under consideration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3356">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the technique will be most useful for low-resource languages and languages for which there is no funding for tree banking activities.
</prevsent>
<prevsent>the only requirement will be that parallel corpus exist for the language under consideration and one or more other languages.2 induction of grammars from parallel corpora is rarely viewed as promising task in its own right; in work that has addressed the issue directly (wu,1997; <papid> J97-3002 </papid>melamed, 2003; <papid> N03-1021 </papid>melamed, 2004), <papid> P04-1083 </papid>the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in noisy channel approach to statistical mt.3 in the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given word alignment.</prevsent>
</prevsection>
<citsent citstr=" P04-1060 ">
this work represents second pilot study (after (kuhn, 2004))<papid> P04-1060 </papid>for the longer-term ptolemaios project at saarland university4 with the goal of learning linguistic grammars from parallel corpora (compare (kuhn, 2005)).</citsent>
<aftsection>
<nextsent>the grammars should be robust and assign 2in the present paper we use examples from english/german for illustration, but the approach is of course independent of the language pair under consideration.
</nextsent>
<nextsent>3of course, there is related work (e.g., (hwa et al, 2002; lu?
</nextsent>
<nextsent>et al, 2002)) using aligned parallel corpora in order to project?
</nextsent>
<nextsent>bracketings or dependency structures from english to another language and exploit them for training parser for the otherlanguage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3359">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> synchronous grammars.  </section>
<citcontext>
<prevsection>
<prevsent>various recent studies in the field of syntax-based statisticalmt have shown that such an assumption is problematic when based on typical treebank-style analyses.
</prevsent>
<prevsent>as (melamed, 2003) <papid> N03-1021 </papid>discusses for instance, in the context of binary branching structures even simple examples like the english/french pair gift for you from france ? un cadeau de france pour vouz [a gift from france for you] lead to discontinuity of synchronous phrase?</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
in one of the two languages.(gildea, 2003) <papid> P03-1011 </papid>and (galley et al, 2004) <papid> N04-1035 </papid>discuss different ways of generalizing the tree-level cross lin guistic correspondence relation, so it is not confined to single tree nodes, thereby avoiding continuity assumption.</citsent>
<aftsection>
<nextsent>we believe that in order to obtain full coverage on real parallel corpora, some mechanism along these lines will be required.however, if the typical rich phrase structure analyses (with fairly detailed fine structure) are replaced by flat, multiply branching analyses, most of the highly frequent problematic cases are resolved.7 in 6this detail will be relevant for the parsing inference rule (5) below.7compare the systematic study for english-french alignments by (fox, 2002), <papid> W02-1039 </papid>who compared (i) treebank-parser style analyses, (ii) variant with flattened vps, and (iii) dependencystructures.</nextsent>
<nextsent>the degree of cross-linguistic phrasal cohesion increases from (i) to (iii).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3360">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> synchronous grammars.  </section>
<citcontext>
<prevsection>
<prevsent>various recent studies in the field of syntax-based statisticalmt have shown that such an assumption is problematic when based on typical treebank-style analyses.
</prevsent>
<prevsent>as (melamed, 2003) <papid> N03-1021 </papid>discusses for instance, in the context of binary branching structures even simple examples like the english/french pair gift for you from france ? un cadeau de france pour vouz [a gift from france for you] lead to discontinuity of synchronous phrase?</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
in one of the two languages.(gildea, 2003) <papid> P03-1011 </papid>and (galley et al, 2004) <papid> N04-1035 </papid>discuss different ways of generalizing the tree-level cross lin guistic correspondence relation, so it is not confined to single tree nodes, thereby avoiding continuity assumption.</citsent>
<aftsection>
<nextsent>we believe that in order to obtain full coverage on real parallel corpora, some mechanism along these lines will be required.however, if the typical rich phrase structure analyses (with fairly detailed fine structure) are replaced by flat, multiply branching analyses, most of the highly frequent problematic cases are resolved.7 in 6this detail will be relevant for the parsing inference rule (5) below.7compare the systematic study for english-french alignments by (fox, 2002), <papid> W02-1039 </papid>who compared (i) treebank-parser style analyses, (ii) variant with flattened vps, and (iii) dependencystructures.</nextsent>
<nextsent>the degree of cross-linguistic phrasal cohesion increases from (i) to (iii).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3361">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> synchronous grammars.  </section>
<citcontext>
<prevsection>
<prevsent>as (melamed, 2003) <papid> N03-1021 </papid>discusses for instance, in the context of binary branching structures even simple examples like the english/french pair gift for you from france ? un cadeau de france pour vouz [a gift from france for you] lead to discontinuity of synchronous phrase?</prevsent>
<prevsent>in one of the two languages.(gildea, 2003) <papid> P03-1011 </papid>and (galley et al, 2004) <papid> N04-1035 </papid>discuss different ways of generalizing the tree-level cross lin guistic correspondence relation, so it is not confined to single tree nodes, thereby avoiding continuity assumption.</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
we believe that in order to obtain full coverage on real parallel corpora, some mechanism along these lines will be required.however, if the typical rich phrase structure analyses (with fairly detailed fine structure) are replaced by flat, multiply branching analyses, most of the highly frequent problematic cases are resolved.7 in 6this detail will be relevant for the parsing inference rule (5) below.7compare the systematic study for english-french alignments by (fox, 2002), <papid> W02-1039 </papid>who compared (i) treebank-parser style analyses, (ii) variant with flattened vps, and (iii) dependencystructures.</citsent>
<aftsection>
<nextsent>the degree of cross-linguistic phrasal cohesion increases from (i) to (iii).
</nextsent>
<nextsent>with flat clausal trees, we will come close to dependency structures with respect to cohesion.
</nextsent>
<nextsent>18 synchronous grammar rules: s/s ? np:1/np:2 vfin:2/vfin:3 adv:3/adv:1 np:4/pp:5 vinf:5/vinf:4 np/np ? pron:1/pron:1 np/pp ? det:1/det:2 n:2/n:4 nil:0/p:1 nil:0/adj:3 pron/pron ? wir:1/we:1 vfin/vfin ? mussen:1/must:1 adv/adv ? deshalb:1/so:1 nil/p ? nil:0/at:1 det/det ? die:1/the:1 nil/adj ? nil:0/agricultural:1 n/n ? agrarpolitik:1/policy:1 vinf/vinf ? prufen:1/look:1 german tree: np vfin adv np vinf pron det wir mussen deshalb die agrarpolitik prufen we must therefore the agr.
</nextsent>
<nextsent>policy examine english tree: adv np vfin vinf pp pron det adj so we must look at the agricultural policy multitree: s/s np:1/np:2 vfin:2/vfin:3 adv:3/adv:1 np:4/pp:5 vinf:5/vinf:4 pron:1/pron:1 nil:0/p:1 det:1/det:2 nil:0/adj:3 n:2/n:4 wir/we mussen/must deshalb/so nil/at die/the nil/agricultural agrarpolitik/policy prufen/look figure 2: sample rules and analysis for synchronous grammar the flat representation that we assume, clause is represented in single subtree of depth 1, with all verbal elements and the argument/adjunct phrases (nps or pps) as immediate daughters of the clause node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3362">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> alignment-guided synchronous parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we are aware of number of open practical questions, e.g.: will the fact that real parallel corpora often contain rather free translations undermine our idea of using the consensus structure for learning basic syntactic constraints?
</prevsent>
<prevsent>statistical alignments are imperfect ? can the constraints imposed by the word alignment be relaxed accordingly without sacrificing tract ability and the effect of indirect supervision8
</prevsent>
</prevsection>
<citsent citstr=" C88-2128 ">
our dynamic programming algorithm can be described as variant of standard earley-style chart parsing (earley, 1970) and generation (shieber, 1988; <papid> C88-2128 </papid>kay, 1996).<papid> P96-1027 </papid></citsent>
<aftsection>
<nextsent>the chart is data structure which stores all sub-analyses that cover part of the input string (in parsing) or meaning representation (in generation).
</nextsent>
<nextsent>memoizing such partial results has the standard advantage of dynamic programming techniques ? it helps one to avoid unnecessary recomputation of partial results.
</nextsent>
<nextsent>the chart structure for context-free parsing is also exploited directly in dynamic programming algorithms for probabilistic context-free grammars (pcfgs): (i) the inside (oroutside) algorithm for summing over the probabilities for every possible analysis of given string, (ii) the viterbi algorithm for determining the most likely analysis of given string, and (iii) the in 8ultimately, bootstrapping of not only the grammars, but also of the word alignment should be applied.
</nextsent>
<nextsent>19side/outside algorithm for re-estimating the parameters of the pcfg in an expectation-maximization approach (i.e., for iterative training of pcfg on unlabeled data).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3364">
<title id=" W05-0803.xml">parsing word aligned parallel corpora in a grammar induction context </title>
<section> alignment-guided synchronous parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we are aware of number of open practical questions, e.g.: will the fact that real parallel corpora often contain rather free translations undermine our idea of using the consensus structure for learning basic syntactic constraints?
</prevsent>
<prevsent>statistical alignments are imperfect ? can the constraints imposed by the word alignment be relaxed accordingly without sacrificing tract ability and the effect of indirect supervision8
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
our dynamic programming algorithm can be described as variant of standard earley-style chart parsing (earley, 1970) and generation (shieber, 1988; <papid> C88-2128 </papid>kay, 1996).<papid> P96-1027 </papid></citsent>
<aftsection>
<nextsent>the chart is data structure which stores all sub-analyses that cover part of the input string (in parsing) or meaning representation (in generation).
</nextsent>
<nextsent>memoizing such partial results has the standard advantage of dynamic programming techniques ? it helps one to avoid unnecessary recomputation of partial results.
</nextsent>
<nextsent>the chart structure for context-free parsing is also exploited directly in dynamic programming algorithms for probabilistic context-free grammars (pcfgs): (i) the inside (oroutside) algorithm for summing over the probabilities for every possible analysis of given string, (ii) the viterbi algorithm for determining the most likely analysis of given string, and (iii) the in 8ultimately, bootstrapping of not only the grammars, but also of the word alignment should be applied.
</nextsent>
<nextsent>19side/outside algorithm for re-estimating the parameters of the pcfg in an expectation-maximization approach (i.e., for iterative training of pcfg on unlabeled data).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3376">
<title id=" W04-3111.xml">integrated annotation for biomedical information extraction </title>
<section> integrated annotation.  </section>
<citcontext>
<prevsection>
<prevsent>or propbank.
</prevsent>
<prevsent>this newly annotated corpus is then used for training processors that will automatically extract such structures from new examples.in propbank for biomedical text, the types of inhibit examples listed above would consistently have their compounds labeled as arg0 and their enzymes labeled as arg1, for nominal ized forms such as is an inhibitor of b, caused inhibition of b, inhibition of by a, as wellthe standard inhibits b. we would also be able to label adjuncts consistently, such as the with prepositional phrase in cyp3a4 activity was decreased by l, and with ic(50) values of about 200 mm.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
in accordance with other calibra table verbs such as rise, fall, decline, etc.,this phrase would be labeled as an arg2-extent, regardless of its syntactic role.a propbank has been built on top of the penn tree bank, and has been used to train semantic taggers?, for extracting argument roles for the predicates of interest, regardless of the particular syntactic context.1 such semantic taggers have been developed by using machine learning techniques trained on the penn propbank (surdeanu et al, 2003; <papid> P03-1002 </papid>gildea and palmer, 2002;<papid> P02-1031 </papid>kingsbury and palmer, 2002).</citsent>
<aftsection>
<nextsent>however, the penn tree bank and propbank involve the annotation of wall street journal text.
</nextsent>
<nextsent>this text, being financial domain, differs insignificant ways from the biomedical text, and so it is1the penn propbank is complemented by nyus nom bank project (meyers, october 2003), which includes tagging of nominal predicate structure.
</nextsent>
<nextsent>this is particular relevant for the biomedical domain, given the heavy use of nominals such mutation and inhibition.necessary for this approach to have corpus of biomedical texts such as medline articles annotated for both syntactic structure (treebanking) and shallow semantic structure (propbanking).
</nextsent>
<nextsent>in this project, the syntactic and semantic annotation is being done on corpus which is also being annotated for entities, as described in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3377">
<title id=" W04-3111.xml">integrated annotation for biomedical information extraction </title>
<section> integrated annotation.  </section>
<citcontext>
<prevsection>
<prevsent>or propbank.
</prevsent>
<prevsent>this newly annotated corpus is then used for training processors that will automatically extract such structures from new examples.in propbank for biomedical text, the types of inhibit examples listed above would consistently have their compounds labeled as arg0 and their enzymes labeled as arg1, for nominal ized forms such as is an inhibitor of b, caused inhibition of b, inhibition of by a, as wellthe standard inhibits b. we would also be able to label adjuncts consistently, such as the with prepositional phrase in cyp3a4 activity was decreased by l, and with ic(50) values of about 200 mm.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
in accordance with other calibra table verbs such as rise, fall, decline, etc.,this phrase would be labeled as an arg2-extent, regardless of its syntactic role.a propbank has been built on top of the penn tree bank, and has been used to train semantic taggers?, for extracting argument roles for the predicates of interest, regardless of the particular syntactic context.1 such semantic taggers have been developed by using machine learning techniques trained on the penn propbank (surdeanu et al, 2003; <papid> P03-1002 </papid>gildea and palmer, 2002;<papid> P02-1031 </papid>kingsbury and palmer, 2002).</citsent>
<aftsection>
<nextsent>however, the penn tree bank and propbank involve the annotation of wall street journal text.
</nextsent>
<nextsent>this text, being financial domain, differs insignificant ways from the biomedical text, and so it is1the penn propbank is complemented by nyus nom bank project (meyers, october 2003), which includes tagging of nominal predicate structure.
</nextsent>
<nextsent>this is particular relevant for the biomedical domain, given the heavy use of nominals such mutation and inhibition.necessary for this approach to have corpus of biomedical texts such as medline articles annotated for both syntactic structure (treebanking) and shallow semantic structure (propbanking).
</nextsent>
<nextsent>in this project, the syntactic and semantic annotation is being done on corpus which is also being annotated for entities, as described in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3378">
<title id=" W04-3111.xml">integrated annotation for biomedical information extraction </title>
<section> integrated annotation.  </section>
<citcontext>
<prevsection>
<prevsent>a simple example is point mutations at codon 12, containing both the nominal (the type of mutation) and following np (the location).
</prevsent>
<prevsent>note that while in isolation this could also be considered one syntactic constituent, the np and pp together, the actual context is ...point mutations at codon 12 in duodenal lavage fluid....
</prevsent>
</prevsection>
<citsent citstr=" P96-1008 ">
since all pps are attached at the same level, at codon 12 and in duodenal lavage fluid are sisters, and so there is no constituent consisting of just point mutations at codon 12.casting the variation event as relation between different component entities allows the component entities to correspond to tree constituents, while retaining the capacity to annotate and search for more complex events.in this case, one component entity point mutations cor2an influential precursor to this integration is the system described in (miller et al, 1996).<papid> P96-1008 </papid></citsent>
<aftsection>
<nextsent>our work is in much the same spirit, although the representation of the predicate-argument structure via propbank and the linkage to the entities is quite different, as well as of course the domain of annotation.
</nextsent>
<nextsent>3there are cases where the entities are so minimal that they are contained within np, not including the determiner, such as cpg site in the np cpg site.
</nextsent>
<nextsent>entities.
</nextsent>
<nextsent>we are not as concerned about these cases since we expect that such entity information properly contained within base np can be associated with the full base np.responds to (base) np node, and at codon 12 is corresponds to the pp node that is the nps sister.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3379">
<title id=" W04-3111.xml">integrated annotation for biomedical information extraction </title>
<section> annotation process.  </section>
<citcontext>
<prevsection>
<prevsent>figure 4: evaluation of part-of-speech taggers cations and 557 states, we obtained the following results: entity precision recall f-measure type 0.80 0.72 0.76 location 0.85 0.73 0.79 state 0.90 0.80 0.85 overall 0.86 0.75 0.80 an entity is considered correctly identified if and only if it matches the human labeling by both category (type, location or state) and span (from position to position b).
</prevsent>
<prevsent>at this stage we have not distinguished between initial and final states.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
while it is difficult to compare taggers that tag different types of entities (e.g., (friedman et al, 2001; gaizauskas et al, 2003)), crfs have been utilized for state-of-the-art results in np-chunking and gene and protein tagging (sha and pereira, 2003; <papid> N03-1028 </papid>mcdonald and pereira, 2004) currently, we are beginning to investigate methods to identify relations over the variation components that are extracted using the entity tagger.</citsent>
<aftsection>
<nextsent>we have described here an integrated annotation approach for two areas of biomedical information extraction.
</nextsent>
<nextsent>we discussed several issues that have arisen for this integration of annotation layers.
</nextsent>
<nextsent>much effort has been spent on the entity definitions and how they relate to the higher-level concepts which are desired for extraction.
</nextsent>
<nextsent>there are promising initial results for training taggers to extract these entities.next steps in the project include: (1) continued annotation of the layers we are currently doing, (2) integration of the level of predicate-argument annotation, and(3) further development of the statistical taggers, including taggers for identifying relations over their component entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3380">
<title id=" W05-0509.xml">climbing the path to grammar a maximum entropy model of subject object learning </title>
<section> a maximum entropy model of soi  </section>
<citcontext>
<prevsection>
<prevsent>the maximum entropy (me) framework offers mathematically sound way to build probabilistic model for soi, which combines different linguistic cues.
</prevsent>
<prevsent>given linguistic context and an outcome aa that depends on c, in the me framework the conditional probability distribution p(a|c) is estimated on the basis of the assumption that no priori constraints must be met other than those related to set of features j(a,c) of c, whose distribution is derived from the training data.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
it can be proven that the probability distribution satisfying the above assumption is the one with the highest entropy, is unique and has the following exponential form (berger et al 1996): (<papid> J96-1002 </papid>1) ? = = j cajf jcz cap 1 ),( )( 1)|( where z(c) is normalization factor, j(a,c) are the values of features of the pair (a,c) and correspond to the linguistic cues of that are relevant to predict the outcome a. features are extracted from the training data and define the constraints that the probabilistic model must satisfy.</citsent>
<aftsection>
<nextsent>the parameters of the distribution a1, ?, ak correspond to weights associated with the features, and determine the relevance of each feature in the overall model.
</nextsent>
<nextsent>in the experiments reported below feature weights have been estimated with the generative iterative scaling (gis) algorithm implemented in the amis software (miyao and tsujii 2002).
</nextsent>
<nextsent>we model soi as the task of predicting the correct syntactic function ? {subject, object} of noun occurring in given syntactic context s. this is equivalent to build the conditional probability distribution p(f |s) of having syntactic function in syntactic context . adopting the me approach, the distribution can be rewritten in the parametric form of (1), with features corresponding to the linguistic contextual cues relevant to soi.
</nextsent>
<nextsent>the context is pair  vs , ns , where vs is the verbal head and ns its nominal dependent in s. this notion of departs from more traditional ways of describing an soi context as triple of one verb and two nouns in certain syntactic configuration (e.g, sov or vos, etc.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3381">
<title id=" W04-2907.xml">general indexation of weighted automata  application to spoken utterance retrieval </title>
<section> indexation algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 preprocessing.
</prevsent>
<prevsent>when the automata ai are word or phone lattices out put by speech recognition or other natural language processing system, the path weights correspond to jointprobabilities.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
we can apply to ai general weight pushing algorithm in the log semi ring (mohri, 1997) <papid> J97-2003 </papid>which converts these weights into the desired (negative log of) posterior probabilities.</citsent>
<aftsection>
<nextsent>more generally, the path weights in the resulting automata can be interpreted as log-likelihoods.
</nextsent>
<nextsent>we denote by pi the corresponding probability distribution.
</nextsent>
<nextsent>when the input automaton ai is acyclic, the complexity of the weight-pushing algorithm is linear in its size (o(|ai|)).
</nextsent>
<nextsent>figures 1(b)(d) illustrates the application of the algorithm to the automata of figures 1(a)(c).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3382">
<title id=" W05-0905.xml">evaluating automatic summaries of meeting recordings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the field of automatic summarization, it is widely agreed upon that more attention needs to be paid to the development of standardized approaches to summarization evaluation.
</prevsent>
<prevsent>for example, the current incarnation of the document understanding conference is putting its main focus on the development of evaluation schemes, including semiautomatic approaches to evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
one semiautomatic approach to evaluation is rouge (linand hovy, 2003), <papid> N03-1020 </papid>which is primarily based on gram co-occurrence between automatic and humansummaries.</citsent>
<aftsection>
<nextsent>a key question of the research contained herein is how well rouge correlates with human judgments of summaries within the domain of meeting speech.
</nextsent>
<nextsent>if it is determined that the two types of evaluations correlate strongly, then rouge will likely be valuable and robust evaluation tool in the development stage of summarization system, when the cost of frequent human evaluations would be prohibitive.
</nextsent>
<nextsent>three basic approaches to summarization are evaluated and compared below: maximal marginal relevance, latent semantic analysis, and feature based classification.
</nextsent>
<nextsent>the other major comparison sin this paper are between summaries on asr versus manual transcripts, and between manual and automatic extracts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3384">
<title id=" W05-0905.xml">evaluating automatic summaries of meeting recordings </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the annotators were told to construct textual summary of the meeting aimed at someone who is interested in the research being carried out, such as researcher who does similar work elsewhere, using four headings: ? general abstract: why are they meeting and what do they talk about??; ? decisions made by the group; ? progress and achievements; ? problems described the annotators were given 200 word limit for each heading, and told that there must be text for the general abstract, but that the other headings may have null annotations for some meetings.
</prevsent>
<prevsent>immediately after authoring textual summary,annotators were asked to create an extractive summary, using different gui.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
this gui showed both their textual summary and the orthographic transcription, without topic segmentation but with one line per dialogue act based on the pre-existing mrda coding (shriberg et al, 2004) (<papid> W04-2319 </papid>the dialogue act categories themselves were not displayed, just the segmentation).</citsent>
<aftsection>
<nextsent>annotators were told to extract dialogue acts that together would convey the information in the textual summary, and could be used to support the correctness of that summary.
</nextsent>
<nextsent>they were given no specific instructions about the number or percentage of acts to extractor about redundant dialogue act.
</nextsent>
<nextsent>for each dialogue act extracted, they were then required in second pass to choose the sentences from the textual summary supported by the dialogue act, creating many-to-many mapping between the recording and the textual summary.the mmr and lsa approaches are both unsupervised and do not require labelled training data.
</nextsent>
<nextsent>for both feature-based approaches, the gmm classifiers were trained on subset of the training data representing approximately 20 hours of meetings.we performed summarization using both the human transcripts and speech recognizer output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3388">
<title id=" W05-0905.xml">evaluating automatic summaries of meeting recordings </title>
<section> the summary seems disjointed..  </section>
<citcontext>
<prevsection>
<prevsent>though subjective evaluations of summaries are often divided into informative ness and readability questions, only automatic metrics of informative ness have been investigated in-depth by the summarization community.
</prevsent>
<prevsent>we believe that the development of automatic metrics for coherence and read ability should be high priority for researchers in summarization evaluation and plan on pursuing this avenue of research.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
for example, work on coherence in nlg (lapata, 2003) <papid> P03-1069 </papid>could potentially in form summarization evaluation.</citsent>
<aftsection>
<nextsent>mani (mani et al, 36 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 1 2 3 41=fb1, 2=lsa, 3=mmr, 4=fb2 rouge-1-manrouge-2-manrouge-l-manrouge-1-asrrouge-2-asrrouge-l-asrfigure 1: rouge scores for the summarization approaches 1999) is one of the few papers to have discussed measuring summary readability automatically.
</nextsent>
<nextsent>4 results.
</nextsent>
<nextsent>the results of these experiments can be analyzed in various ways: significant differences of rouge results across summarization approaches, deterioration of rouge results on asr versus manual transcripts, significant differences of human evaluations across summarization approaches, deterioration of human evaluations on asr versus manual transcripts, and finally, the correlation between rouge and human evaluations.
</nextsent>
<nextsent>4.1 rouge results across summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3389">
<title id=" W05-0905.xml">evaluating automatic summaries of meeting recordings </title>
<section> the summary seems disjointed..  </section>
<citcontext>
<prevsection>
<prevsent>all of the summarization approaches showed minimal deterioration when used on asr output as compared to manual transcripts, but the lsa approach seemed particularly resilient, as evidenced by figure 1.
</prevsent>
<prevsent>one reason for the relatively small impact of asr output on summarization results is that for each of the 6 meetings, the wer of the summaries was lower than the wer of the meeting as whole.
</prevsent>
</prevsection>
<citsent citstr=" A00-2025 ">
similarly, valenza et al(valenza et al., 1999) and zechner and waibel (zechner and waibel, 2000) <papid> A00-2025 </papid>both observed that the wer of extracted summaries was significantly lower than the overall wer in the case of broadcast news.</citsent>
<aftsection>
<nextsent>the table below demonstrates the discrepancy between summary wer and meeting wer for the six meetings used in this research.
</nextsent>
<nextsent>meeting summary wer meeting wer bed004 27.0 35.7 bed009 28.3 39.8 bed016 39.6 49.8 bmr005 23.9 36.1 bmr019 28.0 36.5 bro018 25.9 35.6 wer% for summaries and meetings there was no improvement in the second feature based approach (adding an lsa sentence score) as compared with the first feature-based approach.
</nextsent>
<nextsent>the sentence score used here relied on reduction to 300 dimensions, which may not have been ideal for this data.the similarity between the mmr and lsa approaches here mirrors gong and lius findings, giving credence to the claim that lsa maximizes relevance and minimizes redundancy, in different and more opaque manner then mmr, but with similar 37 statement fb1 lsa mmr fb2 import.
</nextsent>
<nextsent>points 5.03 4.53 4.67 4.83 no redun.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3391">
<title id=" W06-1314.xml">automatically detecting action items in audio meeting recordings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>although available corpora for action items are not ideal, it is hoped that the feature analysis presented here will be of use to later work on other corpora.
</prevsent>
<prevsent>multi-party meetings have attracted significant amount of recent research attention.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
the creation of the icsi corpus (janin et al, 2003), comprised of 72 hours of meeting recordings with an average of 6 speakers per meeting, with associated transcripts, has spurred further annotations for various types of information, including dialog acts (shriberg et al, 2004), <papid> W04-2319 </papid>topic hierarchies and action items (gruenstein et al, 2005), and hot spots?</citsent>
<aftsection>
<nextsent>(wrede and shriberg, 2003).
</nextsent>
<nextsent>the classification of individual utterances based on their role in the dialog, i.e. as opposed to their semantic payload, has long history, especially in the context of dialog act (da) classification.
</nextsent>
<nextsent>96 research on da classification initially focused on two-party conversational speech (mast et al, 1996; stolcke et al, 1998; shriberg et al, 1998) and, more recently, has extended to multi-party audio recordings like the icsi corpus (shriberg et al, 2004).<papid> W04-2319 </papid></nextsent>
<nextsent>machine learning techniques suchas graphical models (ji and bilmes, 2005), maximum entropy models (ang et al, 2005), and hidden markov models (zimmermann et al, 2005)have been used to classify utterances from multiparty conversations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3393">
<title id=" W06-1314.xml">automatically detecting action items in audio meeting recordings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>svms have been successfully applied to the task of extracting action items from email messages (bennett and carbonell, 2005; corstonoliver et al, 2004).
</prevsent>
<prevsent>bennett and carbonell, in particular, distinguish the task of action item detection in email from the more well-studied task of text classification, noting the finer granularity ofthe action item task and the difference of semantics vs. intent.
</prevsent>
</prevsection>
<citsent citstr=" W04-3240 ">
(although recent work has begun to blur this latter division, e.g. cohen et al (2004).)<papid> W04-3240 </papid></citsent>
<aftsection>
<nextsent>in the audio domain, annotations for action item utterances on several recorded meeting corpora, including the icsi corpus, have recently become available (gruenstein et al, 2005), enabling work on this topic.
</nextsent>
<nextsent>we use action item annotations produced by gruenstein et al (2005).
</nextsent>
<nextsent>this corpus provides topic hierarchy and action item annotations for the icsimeeting corpus as well as other corpora of meet ings; due to the ready availability of other types of annotations for the icsi corpus, we focus solely on the annotations for these meetings.
</nextsent>
<nextsent>figure 1 gives an example of the annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3394">
<title id=" W06-1314.xml">automatically detecting action items in audio meeting recordings </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>for this study we consider only those meetings which contain action items and which are annotated by both annotators.
</prevsent>
<prevsent>as the annotations were produced by small number of untrained annotators, an immediate question is the degree of consistency and reliability.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
inter-annotator agreement is typically measured by the kappa statistic (carletta, 1996), <papid> J96-2004 </papid>de kappa fre qu en cy 0.0 0.2 0.4 0.6 0.8 1.0 0 2 4 6 8figure 2: distribution of ?</citsent>
<aftsection>
<nextsent>(inter-annotator agree ment) across the 54 icsi meetings tagged by two annotators.
</nextsent>
<nextsent>of the two meetings with ? = 1.0, one has only two action items and the other only four.
</nextsent>
<nextsent>fined as: ? = (o) ? (e)1 ? (e) where (o) is the probability of the observed agreement, and (e) the probability of the expected agreement?
</nextsent>
<nextsent>(i.e., under the assumption the two sets of annotations are independent).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3395">
<title id=" W06-1314.xml">automatically detecting action items in audio meeting recordings </title>
<section> experimental methodology.  </section>
<citcontext>
<prevsection>
<prevsent>in this study we did not remove these sections; the net effect is that some portions of the data consist of these fairly atypical utterances.
</prevsent>
<prevsent>we formulate the action item detection task as one of binary classification of utterances.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we apply maximum entropy (maxent) model (berger et al, 1996) <papid> J96-1002 </papid>to this task.maxent models seek to maximize the conditional probability of class given the observations using the exponential form (c|x) = 1z(x) exp [ ? i,c fi,c(x) ] where fi,c(x) is the ith feature of the data in class c, i,c is the corresponding weight, and z(x) is normalization term.</citsent>
<aftsection>
<nextsent>maxent models choose the weights i,c so as to maximize the entropy of the induced distribution while remaining consistent with the data and labels; the intuition isthat such distribution makes the fewest assumptions about the underlying data.
</nextsent>
<nextsent>our maxent model is regularized by quadratic prior and uses quasi-newton parameter optimization.
</nextsent>
<nextsent>due to the limited amount of training data(see section 3) and to avoid over fitting, we employ 10-fold cross validation in each experiment.
</nextsent>
<nextsent>to evaluate system performance, we calculate the measure (f ) of precision (p ) and recall (r), defined as: = |a ? c||a| = |a ? c||c| = 2prp + where is the set of utterances marked as action items by the system, and is the set of (all) correct action item utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3396">
<title id=" W06-1314.xml">automatically detecting action items in audio meeting recordings </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>we extract word unigram and bigram features from the transcript for the previous and next utterances across all speakers in the meeting.
</prevsent>
<prevsent>5.3 syntactic features.
</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
under the hypothesis that action item utterances will exhibit particular syntactic patterns, we use conditional markov model part-of-speech (pos) tagger (toutanova and manning, 2000) <papid> W00-1308 </papid>trained on the switchboard corpus (godfrey et al, 1992) to tag utterance words for part of speech.</citsent>
<aftsection>
<nextsent>we use the following binary pos features: ? presence of uh tag, denoting the presence ofan interjection?
</nextsent>
<nextsent>(including filled pauses, unfilled pauses, and discourse markers).
</nextsent>
<nextsent>presence of md tag, denoting presence of modal verb.
</nextsent>
<nextsent>number of nn* tags, denoting the number of nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3397">
<title id=" W06-1314.xml">automatically detecting action items in audio meeting recordings </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>5.6 general semantic features.
</prevsent>
<prevsent>under the hypothesis that action item utterances will frequently involve temporal expressionse.g. lets have the paper written by next tuesday??
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
we use identifinder (bikel et al, 1997) <papid> A97-1029 </papid>to mark temporal expressions (timex?</citsent>
<aftsection>
<nextsent>tags) in utterance transcripts, and create binary feature denoting 99the existence of temporal expression in each ut terance.note that as identifinder was trained on broadcast news corpora, applying it to the very different domain of multi-party meeting transcripts may not result in optimal behavior.
</nextsent>
<nextsent>5.7 dialog-specific semantic features.
</nextsent>
<nextsent>under the hypothesis that action item utterances may be closely correlated with specific dialog act tags, we use the dialog act annotations from the icsi meeting recorder dialog act corpus.
</nextsent>
<nextsent>(shriberg et al, 2004) <papid> W04-2319 </papid>as these da annotations do not correspond one-to-one with utterances in the icsi corpus, we align them in the most liber alway possible, i.e., if at least one word in an utterance is annotated for particular da, we mark the entirety of that utterance as exhibiting that da.we consider both fine-grained and coarse grained dialog acts.1 the former yields 56 features, indicating occurrence of da tags such as appreciation,?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3399">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose framework in which information about the multi-word expressions can be used in the word-alignment task.
</prevsent>
<prevsent>we have shown that even simple features like point-wise mutual information are useful for word-alignment task inenglish-hindi parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the alignment error rate which we achieve (aer = 0.5040) is significantly better (about 10% decrease in aer) than the alignment error rates of the state-of-art models (och and ney, 2003) (<papid> J03-1002 </papid>best aer = 0.5518) on the english-hindi dataset.</citsent>
<aftsection>
<nextsent>in this paper, we show that measures representing compositionality of multi-word expressions can be useful for tasks such as machine translation,word-alignment to be specific here.
</nextsent>
<nextsent>we use an online learning framework called mira (mcdon ald et al, 2005; <papid> H05-1066 </papid>crammer and singer, 2003) for training discriminative model for the word alignment task (taskar et al, 2005; <papid> H05-1010 </papid>moore, 2005).<papid> H05-1011 </papid></nextsent>
<nextsent>the discriminative model makes use of features which represent the compositionality of multi-word ex pressions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3400">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the alignment error rate which we achieve (aer = 0.5040) is significantly better (about 10% decrease in aer) than the alignment error rates of the state-of-art models (och and ney, 2003) (<papid> J03-1002 </papid>best aer = 0.5518) on the english-hindi dataset.</prevsent>
<prevsent>in this paper, we show that measures representing compositionality of multi-word expressions can be useful for tasks such as machine translation,word-alignment to be specific here.</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
we use an online learning framework called mira (mcdon ald et al, 2005; <papid> H05-1066 </papid>crammer and singer, 2003) for training discriminative model for the word alignment task (taskar et al, 2005; <papid> H05-1010 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>the discriminative model makes use of features which represent the compositionality of multi-word expressions.
</nextsent>
<nextsent>1at present visiting institute for research in cognitive science, university of pennsylvania, pa, usa.
</nextsent>
<nextsent>multi-word expressions (mwes) are those whose structure and meaning cannot be derived from their component words, as they occur independently.
</nextsent>
<nextsent>examples include conjunctions such as as well as?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3401">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the alignment error rate which we achieve (aer = 0.5040) is significantly better (about 10% decrease in aer) than the alignment error rates of the state-of-art models (och and ney, 2003) (<papid> J03-1002 </papid>best aer = 0.5518) on the english-hindi dataset.</prevsent>
<prevsent>in this paper, we show that measures representing compositionality of multi-word expressions can be useful for tasks such as machine translation,word-alignment to be specific here.</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
we use an online learning framework called mira (mcdon ald et al, 2005; <papid> H05-1066 </papid>crammer and singer, 2003) for training discriminative model for the word alignment task (taskar et al, 2005; <papid> H05-1010 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>the discriminative model makes use of features which represent the compositionality of multi-word expressions.
</nextsent>
<nextsent>1at present visiting institute for research in cognitive science, university of pennsylvania, pa, usa.
</nextsent>
<nextsent>multi-word expressions (mwes) are those whose structure and meaning cannot be derived from their component words, as they occur independently.
</nextsent>
<nextsent>examples include conjunctions such as as well as?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3402">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the alignment error rate which we achieve (aer = 0.5040) is significantly better (about 10% decrease in aer) than the alignment error rates of the state-of-art models (och and ney, 2003) (<papid> J03-1002 </papid>best aer = 0.5518) on the english-hindi dataset.</prevsent>
<prevsent>in this paper, we show that measures representing compositionality of multi-word expressions can be useful for tasks such as machine translation,word-alignment to be specific here.</prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
we use an online learning framework called mira (mcdon ald et al, 2005; <papid> H05-1066 </papid>crammer and singer, 2003) for training discriminative model for the word alignment task (taskar et al, 2005; <papid> H05-1010 </papid>moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>the discriminative model makes use of features which represent the compositionality of multi-word expressions.
</nextsent>
<nextsent>1at present visiting institute for research in cognitive science, university of pennsylvania, pa, usa.
</nextsent>
<nextsent>multi-word expressions (mwes) are those whose structure and meaning cannot be derived from their component words, as they occur independently.
</nextsent>
<nextsent>examples include conjunctions such as as well as?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3403">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is mwe but take gift?
</prevsent>
<prevsent>is not.in the past, various measures have been suggested for measuring the compositionality ofmulti-word expressions.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
some of these are mutual information (church and hanks, 1989), <papid> P89-1010 </papid>distributed frequency (tapanainen et al, 1998) <papid> P98-2210 </papid>and latent semantic analysis (lsa) model (baldwin et al, 2003).<papid> W03-1812 </papid></citsent>
<aftsection>
<nextsent>even though, these measures have been shown to represent compositionality quite well, compositionality itself has not been shown to be useful in any application yet.
</nextsent>
<nextsent>in this paper, we explore this possibility of using the information about compositionality of mwes (verb based) for the word alignment task.
</nextsent>
<nextsent>in this preliminary work,we use simple measures (such as point-wise mutual information) to measure compositionality.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3405">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is mwe but take gift?
</prevsent>
<prevsent>is not.in the past, various measures have been suggested for measuring the compositionality ofmulti-word expressions.
</prevsent>
</prevsection>
<citsent citstr=" P98-2210 ">
some of these are mutual information (church and hanks, 1989), <papid> P89-1010 </papid>distributed frequency (tapanainen et al, 1998) <papid> P98-2210 </papid>and latent semantic analysis (lsa) model (baldwin et al, 2003).<papid> W03-1812 </papid></citsent>
<aftsection>
<nextsent>even though, these measures have been shown to represent compositionality quite well, compositionality itself has not been shown to be useful in any application yet.
</nextsent>
<nextsent>in this paper, we explore this possibility of using the information about compositionality of mwes (verb based) for the word alignment task.
</nextsent>
<nextsent>in this preliminary work,we use simple measures (such as point-wise mutual information) to measure compositionality.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3406">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is mwe but take gift?
</prevsent>
<prevsent>is not.in the past, various measures have been suggested for measuring the compositionality ofmulti-word expressions.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
some of these are mutual information (church and hanks, 1989), <papid> P89-1010 </papid>distributed frequency (tapanainen et al, 1998) <papid> P98-2210 </papid>and latent semantic analysis (lsa) model (baldwin et al, 2003).<papid> W03-1812 </papid></citsent>
<aftsection>
<nextsent>even though, these measures have been shown to represent compositionality quite well, compositionality itself has not been shown to be useful in any application yet.
</nextsent>
<nextsent>in this paper, we explore this possibility of using the information about compositionality of mwes (verb based) for the word alignment task.
</nextsent>
<nextsent>in this preliminary work,we use simple measures (such as point-wise mutual information) to measure compositionality.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3413">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>recall f-meas.
</prevsent>
<prevsent>aer + merge pos 0.54 0.45 0.49 0.5101 + mergemi 0.55 0.45 0.50 0.5045 table 6: results using the compositionality based featurespressions of various types.
</prevsent>
</prevsection>
<citsent citstr=" H05-1113 ">
some of them are frequency, point-wise mutual information (church and hanks, 1989), <papid> P89-1010 </papid>distributed frequency of object (tapanainen et al, 1998), <papid> P98-2210 </papid>distributed frequency of object using verb information (venkatapathyand joshi, 2005), <papid> H05-1113 </papid>similarity of object in verb object pair using the lsa model (baldwin et al,2003), (<papid> W03-1812 </papid>venkatapathy and joshi, 2005) <papid> H05-1113 </papid>and lexical and syntactic fixed ness (fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these features have largely been evaluated by the correlation of the compositionality value predicted by these measures with the gold standard value suggested by human judges.
</nextsent>
<nextsent>it has been shown that the correlation of these measure sis higher than simple baseline measures suggesting that these measures represent compositionality quite well.
</nextsent>
<nextsent>but, the compositionality as such has not been used in any specific application yet.
</nextsent>
<nextsent>in this paper, we have suggested framework for using the compositionality of multi-word expressions for the word alignment task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3416">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>recall f-meas.
</prevsent>
<prevsent>aer + merge pos 0.54 0.45 0.49 0.5101 + mergemi 0.55 0.45 0.50 0.5045 table 6: results using the compositionality based featurespressions of various types.
</prevsent>
</prevsection>
<citsent citstr=" E06-1043 ">
some of them are frequency, point-wise mutual information (church and hanks, 1989), <papid> P89-1010 </papid>distributed frequency of object (tapanainen et al, 1998), <papid> P98-2210 </papid>distributed frequency of object using verb information (venkatapathyand joshi, 2005), <papid> H05-1113 </papid>similarity of object in verb object pair using the lsa model (baldwin et al,2003), (<papid> W03-1812 </papid>venkatapathy and joshi, 2005) <papid> H05-1113 </papid>and lexical and syntactic fixed ness (fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these features have largely been evaluated by the correlation of the compositionality value predicted by these measures with the gold standard value suggested by human judges.
</nextsent>
<nextsent>it has been shown that the correlation of these measure sis higher than simple baseline measures suggesting that these measures represent compositionality quite well.
</nextsent>
<nextsent>but, the compositionality as such has not been used in any specific application yet.
</nextsent>
<nextsent>in this paper, we have suggested framework for using the compositionality of multi-word expressions for the word alignment task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3418">
<title id=" W06-1204.xml">using information about multiword expressions for the word alignment task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>but, the compositionality as such has not been used in any specific application yet.
</prevsent>
<prevsent>in this paper, we have suggested framework for using the compositionality of multi-word expressions for the word alignment task.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
state-of-art systems for doing word alignment use generative models like giza++ (och and ney, 2003; <papid> J03-1002 </papid>brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>discriminative models have been tried recently for word-alignment (taskar et al,2005; <papid> H05-1010 </papid>moore, 2005) <papid> H05-1011 </papid>as these models give the ability to harness variety of complex features which cannot be provided in the generative models.</nextsent>
<nextsent>in our work, we have used the compositionality of multi-word expressions to predict how they align with the words in the target language sentence.for parameter optimization for the word alignment task, taskar, simon and klein (taskaret al, 2005) <papid> H05-1010 </papid>used large margin approach by factoring the structure level constraints to constraints at the level of an alignment link.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3427">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we explore the feasibility to employ agen eral purpose ontology for various tasks involved in processing the users utterances.
</prevsent>
<prevsent>we differentiate between controlled single-domain andmore conversational multi-domain spoken dialogue systems (allen et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W03-0903 ">
the transition from the former to the later can be regarded as scaling process, since virtually every processing technique applicable for restricted single domain user utterances has to be adopted to new challenges, i.e., varying context-dependencies (porzel et al., 2004) increasing levels of ambiguity (gurevych et al, 2003<papid> W03-0903 </papid>a; loos and porzel, 2004) <papid> W04-2312 </papid>and less predictable input (loeckelt et al, 2002).</citsent>
<aftsection>
<nextsent>additionally, for conversational multi-domain spoken dialogue systems tasks have to be tackled that were by and large unnecessary in restricted single-domain systems.
</nextsent>
<nextsent>in this exploration, we will focus on subset of these tasks, namely:  hypotheses verification (hv) - i.e. finding the best hypothesis out of set of possible speech recognition hypotheses (srh);  sense disambiguation (sd) - i.e. determining the best mapping of the lexically ambiguous linguistic forms contained therein to their sense-specific semantic representations; relation tagging (rt) - i.e. determining adequate semantic relations between the relevant sense-tagged entities.
</nextsent>
<nextsent>many of these tasks have been addressed in other fields,for example, hypothesis verification in the field of machine translation (tran et al, 1996), sense disambiguation in speech synthesis (yarowsky, 1995), <papid> P95-1026 </papid>and relation tagging in information retrieval (marsh and perzanowski, 1999).</nextsent>
<nextsent>these challenges also apply for spoken dialogue systems and arise when they are scaled up towards multi domain and more conversational settings.in this paper we will address the utility of using on to logically modeled knowledge to assist in solving these tasks in spoken dialogue systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3437">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we explore the feasibility to employ agen eral purpose ontology for various tasks involved in processing the users utterances.
</prevsent>
<prevsent>we differentiate between controlled single-domain andmore conversational multi-domain spoken dialogue systems (allen et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W04-2312 ">
the transition from the former to the later can be regarded as scaling process, since virtually every processing technique applicable for restricted single domain user utterances has to be adopted to new challenges, i.e., varying context-dependencies (porzel et al., 2004) increasing levels of ambiguity (gurevych et al, 2003<papid> W03-0903 </papid>a; loos and porzel, 2004) <papid> W04-2312 </papid>and less predictable input (loeckelt et al, 2002).</citsent>
<aftsection>
<nextsent>additionally, for conversational multi-domain spoken dialogue systems tasks have to be tackled that were by and large unnecessary in restricted single-domain systems.
</nextsent>
<nextsent>in this exploration, we will focus on subset of these tasks, namely:  hypotheses verification (hv) - i.e. finding the best hypothesis out of set of possible speech recognition hypotheses (srh);  sense disambiguation (sd) - i.e. determining the best mapping of the lexically ambiguous linguistic forms contained therein to their sense-specific semantic representations; relation tagging (rt) - i.e. determining adequate semantic relations between the relevant sense-tagged entities.
</nextsent>
<nextsent>many of these tasks have been addressed in other fields,for example, hypothesis verification in the field of machine translation (tran et al, 1996), sense disambiguation in speech synthesis (yarowsky, 1995), <papid> P95-1026 </papid>and relation tagging in information retrieval (marsh and perzanowski, 1999).</nextsent>
<nextsent>these challenges also apply for spoken dialogue systems and arise when they are scaled up towards multi domain and more conversational settings.in this paper we will address the utility of using on to logically modeled knowledge to assist in solving these tasks in spoken dialogue systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3439">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>additionally, for conversational multi-domain spoken dialogue systems tasks have to be tackled that were by and large unnecessary in restricted single-domain systems.
</prevsent>
<prevsent>in this exploration, we will focus on subset of these tasks, namely:  hypotheses verification (hv) - i.e. finding the best hypothesis out of set of possible speech recognition hypotheses (srh);  sense disambiguation (sd) - i.e. determining the best mapping of the lexically ambiguous linguistic forms contained therein to their sense-specific semantic representations; relation tagging (rt) - i.e. determining adequate semantic relations between the relevant sense-tagged entities.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
many of these tasks have been addressed in other fields,for example, hypothesis verification in the field of machine translation (tran et al, 1996), sense disambiguation in speech synthesis (yarowsky, 1995), <papid> P95-1026 </papid>and relation tagging in information retrieval (marsh and perzanowski, 1999).</citsent>
<aftsection>
<nextsent>these challenges also apply for spoken dialogue systems and arise when they are scaled up towards multi domain and more conversational settings.in this paper we will address the utility of using on to logically modeled knowledge to assist in solving these tasks in spoken dialogue systems.
</nextsent>
<nextsent>following an overview of the state of the art in section 2 and the ontology-based coherence scoring system in section 3, we describe its employment in the task of hypotheses verification in section 4.
</nextsent>
<nextsent>in section 5 we describe the systems employment for the task of sense disambiguation and in section 6 we present first results of study examining the performance of the system for the task of relation tagging.
</nextsent>
<nextsent>an analysis of the evaluation results and concluding remarks are given in section 7.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3440">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>employing the task categorization scheme proposed by stevenson (2003), the task of creating adequate semantic representations of the individual entities occurring inthe srhs can be regarded as form of semantic disambiguation.
</prevsent>
<prevsent>since, in our case, fixed inventory of senses is given by the lexicon and only the ambiguous lexical forms have to be disambiguated, our task falls into the corresponding subcategory of sense disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
following ide and veronis (1998) <papid> J98-1001 </papid>we distinguish between data- and knowledge-driven word sense disam biguation.</citsent>
<aftsection>
<nextsent>given the basic distinction between written text and spoken utterances, the only sense disambiguation results performed on speech data stemming from human interactions with dialogue systems have been reported by loos and porzel (2004), <papid> W04-2312 </papid>who compared both data- and knowledge-driven sense disambiguation on the same set of actual speech data.historically, after work on wsd had overcome so called early doubts (ide and veronis, 1998) <papid> J98-1001 </papid>in the 1960s, it was applied to various nlp tasks, such as machine translation, information retrieval, content and grammatical analysis and text processing.</nextsent>
<nextsent>yarowsky (1995)<papid> P95-1026 </papid>used both supervised and unsupervised wsd for correct phonetizitation of words in speech synthesis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3448">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in general, following ide and veronis (1998) <papid> J98-1001 </papid>the various wsd approaches of the past can be divided into two types, i.e., data- and knowledge-based approaches.</prevsent>
<prevsent>data-based methods data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (yarowsky, 1995; <papid> P95-1026 </papid>stevenson, 2003).</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
supervised methods work with given (and therefore limited) set of potential classes in the learning process.for example, yarowsky (1992) <papid> C92-2070 </papid>used thesaurus to generate 1042 statistical models of the most general cate gories.</citsent>
<aftsection>
<nextsent>weiss (1973) already showed that disambiguation rules can successfully be learned from hand-tagged corpora.
</nextsent>
<nextsent>however limited by the small size of his training and test corpus, an accuracy of 90   was achieved.
</nextsent>
<nextsent>even better results on larger corpus were obtained by kelly and stone 1975 who included collocational, syntactic and part of speech information to yield an accuracy of 93   on larger corpus.
</nextsent>
<nextsent>as always, supervised methods require manually annotated learning corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3449">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>even better results on larger corpus were obtained by kelly and stone 1975 who included collocational, syntactic and part of speech information to yield an accuracy of 93   on larger corpus.
</prevsent>
<prevsent>as always, supervised methods require manually annotated learning corpus.
</prevsent>
</prevsection>
<citsent citstr=" N03-4011 ">
unsupervised methods do not determine the set of classes before the learning process, but through analysis of the given data by identifying clusters of similar cases.one example is the algorithm for clustering by committee described by pantel and lin (2003), <papid> N03-4011 </papid>which automatically discovers word senses from text.</citsent>
<aftsection>
<nextsent>generally, unsupervised methods require large amounts of data.
</nextsent>
<nextsent>in the case of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications.knowledge-based methods knowledge-based approaches work with lexica and/or ontologies.
</nextsent>
<nextsent>the kind of knowledge varies widely and machine-readable lexica are employed.
</nextsent>
<nextsent>the knowledge-based approach employed herein (gurevych et al, 2003<papid> W03-0903 </papid>a) operates on an ontology partially derived from framenet data (baker et al, 1998) <papid> P98-1013 </papid>and is described by gurevych et al (2003<papid> W03-0903 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3460">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications.knowledge-based methods knowledge-based approaches work with lexica and/or ontologies.
</prevsent>
<prevsent>the kind of knowledge varies widely and machine-readable lexica are employed.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the knowledge-based approach employed herein (gurevych et al, 2003<papid> W03-0903 </papid>a) operates on an ontology partially derived from framenet data (baker et al, 1998) <papid> P98-1013 </papid>and is described by gurevych et al (2003<papid> W03-0903 </papid>b).</citsent>
<aftsection>
<nextsent>incomparable approach sussna (1993) worked with the lexical reference system wordnet and used similar metric for the calculation of semantic distance of number of input lexemes.
</nextsent>
<nextsent>depending on the type of semantic relation (hyperonymy, synonymy etc.) different weights are given and his metric takes account of the number of arcs of the same type leaving node and the depth of given edge in the overall tree.
</nextsent>
<nextsent>the disambiguation results on textual data reported by sussna (1993) turned out to be significantly better than chance.
</nextsent>
<nextsent>in contrast to many other work on wsd with wordnet he took into account not only the isa hierarchy, but other relational links as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3467">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the fact, that our wsd work is done on srhs makes it difficult to compare the results with methods evaluated on textual data such as in the senseval studies (edmonds, 2002).
</prevsent>
<prevsent>2.3 labeling semantic roles and relations.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the task of representing the semantic relations that hold between the sense tagged entities can be thought of as an extension of the work presented by gildea and jurafsky (2002), <papid> J02-3001 </papid>where the tagset is defined by entities corresponding to framenet frame elements(baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>therein, for example, given the occurrence of commercial transaction frame the task lies in the appropriate labeling of the corresponding roles, such as buyer, seller or goods.additionally the task discussed herein features similarities to the scenario template task of the message understanding conferences (marsh and perzanowski, 1999).
</nextsent>
<nextsent>in this case predefined templates are given (e.g. is-bought-by(company a,company b) which have to instantiated correctly, i.e. in phrase such as stocks sky-rocketed after big blue acquired soft soft . . .
</nextsent>
<nextsent>the specific roles, i.e. big blue as company and soft soft as company have to be put in their adequate places within the overall template.
</nextsent>
<nextsent>now that speech data from the more conversational multi-domain dialogue systems have become available, we present the corresponding annotation experiments an devaluation results of knowledge-driven hypothesis verification, sense disambiguation and relation tagging system, whose knowledge store and algorithm are presented below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3500">
<title id=" W04-2808.xml">making relative sense from word graphs to semantic frames </title>
<section> sense disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 evaluation results.
</prevsent>
<prevsent>for calculating the majority class baselines, all markables in the gold-standards were counted.
</prevsent>
</prevsection>
<citsent citstr=" W04-2802 ">
corresponding to the frequency of each concept of each ambiguous lexeme the percentage of correctly chosen concepts by means of selecting the most frequent meaning without the help of system was calculated by means of the formula given by porzel and malaka (2004).<papid> W04-2802 </papid></citsent>
<aftsection>
<nextsent>this resulted in baseline of 52.48   for the test dataset.
</nextsent>
<nextsent>for this evaluation, onto score transformed thesrh from our corpus into concept representations as described in section 2.
</nextsent>
<nextsent>to perform the wsd task, on toscore calculates coherence score for each of these concept sets.
</nextsent>
<nextsent>the concepts in the highest ranked set are considered to be the ones representing the correct word meaning in this context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3517">
<title id=" W05-0614.xml">intentional context in situated natural language learning </title>
<section> linguistic mapping.  </section>
<citcontext>
<prevsection>
<prevsent>meaningpmeaningutterancep here utterance refers to some linguistic unit (usually sentence) and meaning refers to some node in the tree (represented as semantic frame) inferred during intention recognition4.
</prevsent>
<prevsent>we can use the probability associated with the inferred tree (as given by the pcfg parser) as the source probability.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
further, we can learn the channel probabilities in an unsupervised manner using variant of the em algorithm similar to machine translation (brown et al, 1993), <papid> J93-2003 </papid>and statistical language understanding (epstein, 1996).</citsent>
<aftsection>
<nextsent>4.1 data collection.
</nextsent>
<nextsent>4 ? refers to weighting coefficient.
</nextsent>
<nextsent>in order to avoid the many physical and perceptual problems that complicate work with robots and sensor-grounded data, this work focuses on language learning in virtual environments.
</nextsent>
<nextsent>we focus on multi player video games , which support rich types of social interactions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3518">
<title id=" W05-0614.xml">intentional context in situated natural language learning </title>
<section> pilot experiments.  </section>
<citcontext>
<prevsection>
<prevsent>by applying probabilities to the rules, intention recognition can be treated as probabilistic context free parsing problem, following pynadath, 1999.
</prevsent>
<prevsent>for these initial experiments we have hand annotated the training data in order to generate the grammar used for intention recognition, estimating their maximum likelihood probabilities over the training set.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
in future work, we intend to examine how such grammars can be learned in conjunction with the language itself; extending research on learning task models (nicolescu and mataric, 2003) and work on learning pcfgs (klein and manning, 2004) <papid> P04-1061 </papid>with our own work on unsupervised language learning.</citsent>
<aftsection>
<nextsent>given the pcfg, we use probabilistic earley parser (stolcke, 1994), modified slightly to output 6 we use 65 different frames, comprised of 35 unique.
</nextsent>
<nextsent>role fillers.
</nextsent>
<nextsent>107 partial trees (with probabilities) as each action is observed.
</nextsent>
<nextsent>figure 4 shows time slice of an inferred intention tree after player mouse clicked on lever in the game.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3520">
<title id=" W05-0619.xml">investigating the effects of selective sampling on the annotation task </title>
<section> bootstrapping ner.  </section>
<citcontext>
<prevsection>
<prevsent>without class information, we get an f-score of 92.22 (accuracy of 98.49), indicating that most of our errors are due to boundary problems.
</prevsent>
<prevsent>these numbers suggest that our task is more difficult than the generic ner tasks from the muc and hub evaluations.
</prevsent>
</prevsection>
<citsent citstr=" J97-1002 ">
another common agreement metric is the kappa coefficient which normalises token level accuracy by chance, e.g. carletta et al (1997).<papid> J97-1002 </papid></citsent>
<aftsection>
<nextsent>this metric showed that the human annotators distinguish the four categories with reproducibility of k=.925 (n=44775, k=2; where is the kappa coefficient, is the number of tokens and is the number of annotators).
</nextsent>
<nextsent>2.3 active learning.
</nextsent>
<nextsent>we have already mentioned that there are two main approaches in the literature to assessing the informa tivity of an example: the degree of uncertainty of asingle learner and the disagreement between committee of learners.
</nextsent>
<nextsent>for the current work, we employ query-by-committee (qbc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3521">
<title id=" W05-0619.xml">investigating the effects of selective sampling on the annotation task </title>
<section> bootstrapping ner.  </section>
<citcontext>
<prevsection>
<prevsent>we have already mentioned that there are two main approaches in the literature to assessing the informa tivity of an example: the degree of uncertainty of asingle learner and the disagreement between committee of learners.
</prevsent>
<prevsent>for the current work, we employ query-by-committee (qbc).
</prevsent>
</prevsection>
<citsent citstr=" W03-0428 ">
we use conditional markov model (cmm) tagger (klein et al, 2003; <papid> W03-0428 </papid>finkel et al, 2005) to train two different models onthe same data by splitting the feature set.</citsent>
<aftsection>
<nextsent>in this section we discuss several parameters of this approach for the current task.
</nextsent>
<nextsent>level of annotation for the manual annotation of named entity examples, we needed to decide on the level of granularity.
</nextsent>
<nextsent>the question arises of what constitutes an example that will be submitted to the annotators.
</nextsent>
<nextsent>possible levels include the document level,the sentence level and the token level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3522">
<title id=" W05-0619.xml">investigating the effects of selective sampling on the annotation task </title>
<section> bootstrapping ner.  </section>
<citcontext>
<prevsection>
<prevsent>in order to turn this into sentence score, we need to combine the individual kl-divergences for the tokens within sentence into one single score.
</prevsent>
<prevsent>we employed mean and max.
</prevsent>
</prevsection>
<citsent citstr=" P00-1016 ">
the f-complement has been suggested for active learning in the context of np chunking as structural comparison between the different analyses of committee (ngai and yarowsky, 2000).<papid> P00-1016 </papid></citsent>
<aftsection>
<nextsent>it is the pairwise f-measure comparison between the multiple analyses forgiven sentence: fmcomp = 1 2 ? m,m (1?
</nextsent>
<nextsent>f1(m(t),m ?(t))) (2) where f1 is the balanced f-measure of m(t) andm ?(t), the preferred analyses of data point according to different members m,m ? of ensemble m. we take the complement so that it is oriented the same as kl-divergence with high values indicating high disagreement.
</nextsent>
<nextsent>this is equivalent to taking the inter-annotator agreement between |m| classifiers.
</nextsent>
<nextsent>146 69 70 71 72 73 74 75 76 77 78 79 80 10000 15000 20000 25000 30000 35000 40000 45000f sc or number of tokens in training data ave kl-divergence random sampling figure 1: learning curve of the real al experiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3523">
<title id=" W05-0619.xml">investigating the effects of selective sampling on the annotation task </title>
<section> evaluating selective sampling.  </section>
<citcontext>
<prevsection>
<prevsent>this represents substantial reduction in tokens annotated of 38.5%.
</prevsent>
<prevsent>in addition, at 39000 tokens, selectively sampling offers an error reduction of 21.4% with 3 point improvement in f-score.
</prevsent>
</prevsection>
<citsent citstr=" N04-1012 ">
standardly, the evaluation of active learning methods and the comparison of sample selection metrics draws on experiments over gold-standard annotated corpora, where set of annotated data is at our disposal, e.g. mccallum and nigam (1998), osborne and baldridge (2004).<papid> N04-1012 </papid></citsent>
<aftsection>
<nextsent>this assumes implicitly that annotators will always produce gold-standard quality annotations, which is typically not the case, as we discussed in section 2.2.
</nextsent>
<nextsent>what is more, we speculate that annotators might have an even higher error rate on the supposedly more informative, but possibly also more difficult examples.
</nextsent>
<nextsent>however, this would not be reflected in the carefully annotated and verified examples of gold standard corpus.
</nextsent>
<nextsent>in the following analysis, we leverage information from doubly annotated data to explore the effects on annotation of selectively sampled examples.to evaluate the practicality and usefulness of active learning as generally applicable methodology, it is desirable to be able to observe the behaviour of the annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3524">
<title id=" W04-3245.xml">from machine translation to computer assisted translation using finite state models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nowadays, this lack of translation excellence is common characteristic in all machine translation systems.
</prevsent>
<prevsent>therefore, the human-machine synergy represented by the cat paradigm seems to be more promising than fully-automatic translation in the near future.the cat paradigm has two important aspects: the models need to provide adequate completions and they have to do so efficiently to perform under usability constrains.
</prevsent>
</prevsection>
<citsent citstr=" N01-1018 ">
to fulfill these two requirements, stochastic finite state transducers (sfst) have been selected since they have proved in the past to be able to provide adequate translations (vidal, 1997; knight and al-onaizan, 1998; amengual et al, 2000; casacuberta et al, 2001; bangalore and ricardi, 2001).<papid> N01-1018 </papid></citsent>
<aftsection>
<nextsent>in addition, efficient parsing algorithms can be easily adapted in order to provide completions.
</nextsent>
<nextsent>the rest of the paper is structured as follows.
</nextsent>
<nextsent>the following section introduces the general setting for machine translation and finite state models.
</nextsent>
<nextsent>in section 3, the search procedure for an interactive translation is presented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3525">
<title id=" W04-3245.xml">from machine translation to computer assisted translation using finite state models </title>
<section> transforming the inferred regular grammar.  </section>
<citcontext>
<prevsection>
<prevsent>this joining is done taking care not to invert the order of the output words.
</prevsent>
<prevsent>the third step is trivial with this arrangement.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
in our experiments, the alignments are obtained using the giza software (och and ney, 2000; <papid> P00-1056 </papid>al-onaizan etal., 1999), which implements ibm statistical models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>3 interactive search.
</nextsent>
<nextsent>the concept of interactive search is closely related to the cat paradigm.
</nextsent>
<nextsent>this paradigm introduces the new factor t into the general machine translation equation (equation 1).
</nextsent>
<nextsent>t represents prefix in the target language obtained as result of the interaction between the human translator and the machine translation system.as side effect of this reformulation, the optimization defined in equation 3 is performed overthe set of target suffixes rather than the set of complete target sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3526">
<title id=" W04-3245.xml">from machine translation to computer assisted translation using finite state models </title>
<section> transforming the inferred regular grammar.  </section>
<citcontext>
<prevsection>
<prevsent>this joining is done taking care not to invert the order of the output words.
</prevsent>
<prevsent>the third step is trivial with this arrangement.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
in our experiments, the alignments are obtained using the giza software (och and ney, 2000; <papid> P00-1056 </papid>al-onaizan etal., 1999), which implements ibm statistical models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>3 interactive search.
</nextsent>
<nextsent>the concept of interactive search is closely related to the cat paradigm.
</nextsent>
<nextsent>this paradigm introduces the new factor t into the general machine translation equation (equation 1).
</nextsent>
<nextsent>t represents prefix in the target language obtained as result of the interaction between the human translator and the machine translation system.as side effect of this reformulation, the optimization defined in equation 3 is performed overthe set of target suffixes rather than the set of complete target sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3527">
<title id=" W04-3245.xml">from machine translation to computer assisted translation using finite state models </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>4.
</prevsent>
<prevsent>bilingual evaluation understudy (bleu).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
(papineni et al, 2002): <papid> P02-1040 </papid>basically is function of the k-substrings that appear in the hypothesized target sentence and in the reference target sentence.these experiments were perfomed with 3 gram transducers based on the giati technique.</citsent>
<aftsection>
<nextsent>onthe left most column appears the language pair employed for each experiment, english (en), spanish (es), french (fr) and german (de).
</nextsent>
<nextsent>the main two central columns compare the results obtained with 1-best translation to 5-best translations.
</nextsent>
<nextsent>when using 5-best translations, that target sentence out of these five, that minimizes most the correspondent error measure is selected.
</nextsent>
<nextsent>the results are shown in table 2.the best results were obtained between english and spanish language pairs, in which the human translator would need to type less than 25% of the total reference sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3528">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on one side of the spectrum lie integrated systems, with all linguistic decisions being handled within single process(e.g. [appelt, 1985]).
</prevsent>
<prevsent>such architectures are theoretically attractive, as they assume close coordination of different types of linguistic decisions, which are known to be dependent on one another (cf.
</prevsent>
</prevsection>
<citsent citstr=" P84-1107 ">
e.g. [danlos, 1984]).<papid> P84-1107 </papid></citsent>
<aftsection>
<nextsent>a major disadvantage of integrated models is the complexity that they necessarily involve, which results in poor portability and scalability.
</nextsent>
<nextsent>on the other side of the spectrum there are highly modular ized pipeline architectures.
</nextsent>
<nextsent>a prominent example of this second case is the consensus pipeline architecture recognized by [re iter, 1994] <papid> W94-0319 </papid>and further elaborated in [reiter and dale, 2000].</nextsent>
<nextsent>the modular ization of reiters model occurs at two levels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3530">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a major disadvantage of integrated models is the complexity that they necessarily involve, which results in poor portability and scalability.
</prevsent>
<prevsent>on the other side of the spectrum there are highly modular ized pipeline architectures.
</prevsent>
</prevsection>
<citsent citstr=" W94-0319 ">
a prominent example of this second case is the consensus pipeline architecture recognized by [re iter, 1994] <papid> W94-0319 </papid>and further elaborated in [reiter and dale, 2000].</citsent>
<aftsection>
<nextsent>the modular ization of reiters model occurs at two levels.
</nextsent>
<nextsent>first, individual linguistic decisions of the same type (e.g. involving lexical or syntactic choice) are grouped together within single low level tasks, such as lexicalization, aggregation or ordering.
</nextsent>
<nextsent>second, tasks are allocated to three high level generation stages, i.e. document planning, micro plan ning and surface realization.
</nextsent>
<nextsent>the processing flow in the pipeline architecture is sequential, with individual tasks being executed in predetermined order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3531">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> classification-based generation.  </section>
<citcontext>
<prevsection>
<prevsent>adjunction operations are marked with dashed arrows.tor.
</prevsent>
<prevsent>in recent years supervised machine learning methods relying on pre-classified training data have been applied in various areas of nlp to solve tasks formulated as classification problems.
</prevsent>
</prevsection>
<citsent citstr=" N01-1002 ">
in nlg machine learning methods have been used to solve single tasks such as content selection and ordering (e.g. [duboue, 2004; dimitromanolaki and androutsopoulos, 2003]), lexicalization (e.g. [reiter and sripada, 2004]) and referring expressions generation (e.g. [cheng et al, 2001]).<papid> N01-1002 </papid></citsent>
<aftsection>
<nextsent>in these applications classifiers trained on labeled data have proven more robust and efficient than approaches using explicit expert knowledge.
</nextsent>
<nextsent>the difficulty of formalizing the linguistic knowledge involved in the development of knowledge-based system (a.k.a. knowledge-acquisition bottleneck) has been replaced with an effort of obtaining the right kind of data, which typically involves annotating manually corpus of relevant texts with the required linguistic information (cf.
</nextsent>
<nextsent>[daelemans, 1993]).the classification-based generation framework that we introduced in [marciniak and strube, 2004] is based on simple idea that the linguistic form of an expression can be decomposed into set of discrete form elements (fes) representing both its syntactic and lexical properties.
</nextsent>
<nextsent>the generation process is then modeled as series of classification tasks that realize individual fes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3532">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> classification-based generation.  </section>
<citcontext>
<prevsection>
<prevsent>to specify an inventory of fes that would become objects of the low-level generation tasks, we first apply the lexicalized tree adjoining grammar (ltag) formalism (see e.g. [joshi and schabes, 1991]) to model the linguistic form of the texts.
</prevsent>
<prevsent>in ltag, the derivation of linguistic structure starts with selection of elementary trees, anchored by lexical items, suchas verbs or prepositions at the clause level and discourse connectives at the discourse level (cf.
</prevsent>
</prevsection>
<citsent citstr=" W98-0315 ">
[webber and joshi, 1998]).<papid> W98-0315 </papid></citsent>
<aftsection>
<nextsent>in the next step, elementary trees are put together by means of adjunction operations that follow the dependency structure provided by the derivation tree.
</nextsent>
<nextsent>we take the temporal structure from figure 2 to constitute the discourse level derivation tree, with the temporal relationships corresponding to the syntactic dependencies.
</nextsent>
<nextsent>at the clause level, the derivation tree is isomorphic with the frame-based onto logical representation of individual situations (see [marciniak and strube, 2005]).
</nextsent>
<nextsent>the clause- and discourse-level derivation of discourse unit (c) from the above example in the context of (a) and (b) is depicted in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3533">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> classification-based generation.  </section>
<citcontext>
<prevsection>
<prevsent>arguably, the above fes and the corresponding tasks are independent of the underlying grammatical model.
</prevsent>
<prevsent>in this work we use the abstraction of the grammatical structure provided by ltag, but the same or similar set of fes can be readily derived from other formalisms (cf.
</prevsent>
</prevsection>
<citsent citstr=" W90-0109 ">
e.g. [meteer, 1990]).<papid> W90-0109 </papid></citsent>
<aftsection>
<nextsent>the role of the grammatical theory in defining form elements is twofold.
</nextsent>
<nextsent>first, it specifies the exact position of individual fes in the grammatical structure, making it clear how they should be assembled.
</nextsent>
<nextsent>second, it ensures wide coverage: although the linguistic structures that we consider here are relatively simple, the use of ltag as the underlying grammatical formalism guarantees that our generation framework can be applied to producing much more complex constructions, both at the clause and discourse levels.
</nextsent>
<nextsent>apparently, this would require richer feature vector representation of the initial trees, and hence larger number of fes and the corresponding generation tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3536">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> discrete optimization model.  </section>
<citcontext>
<prevsection>
<prevsent>the goal is to find an assignment that minimizes the overall cost function q(f) which has two components: assignment costs,i.e. the costs of selecting particular label for individual objects, and separation costs, i.e. the costs of selecting pairof labels for two related objects2.
</prevsent>
<prevsent>[chekuri et al, 2001] proposed an integer linear programming (ilp) formulation of the metric labeling problem, with both assignment cost and separation costs being modeled as binary variables of the linear cost function.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
recently, [roth and yih, 2004] <papid> W04-2401 </papid>applied an ilp model to the task of the simultaneous assignment of semantic roles to the entities mentioned in sentence and recognition of the relations holding between them.</citsent>
<aftsection>
<nextsent>the assignment costs were calculated on the basis of predictions of basic classifiers, i.e.trained for both tasks individually with no access to the outcomes of the other task.
</nextsent>
<nextsent>the separation costs were formulated in terms of binary constraints which specified whether specific semantic role could occur in given relation, or not.
</nextsent>
<nextsent>in the remainder of this paper, we present more general model, which we apply to the generation tasks presented in section 2.
</nextsent>
<nextsent>we put no limits on the number of tasks being solved, and express the separation costs as stochastic constraints, which can be calculated off-line from the available linguistic data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3537">
<title id=" W05-1611.xml">discrete optimization as an alternative to sequential processing in nlg </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>this can be attributed partially to the limitations of retrieval measures which do not allow for the fact, that in agiven semantic content more than one lexical form can be appropriate.
</prevsent>
<prevsent>in this paper we showed that the pipeline architecture in annlg application can be successfully replaced with an integrated ilp-based model which is better suited to handling correlated generation decisions.
</prevsent>
</prevsection>
<citsent citstr=" P04-1051 ">
to the best of our knowledge, linear programming has been used in an nlg related work only by [althaus et al, 2004] <papid> P04-1051 </papid>to solve single task of determining the order of discourse constituents.</citsent>
<aftsection>
<nextsent>in some what related context [dras, 1999] used ilp to optimize the task of text paraphrasing, given global constraints such as text and sentence length, readibilty, etc.in contrast, in this work we use an ilp model to organize the entire process of generating the surface form from an underlying semantic representation, which involves an integration of different types of nlg tasks.
</nextsent>
<nextsent>although inour system we use machine learning as the primary decision making mechanism, we believe that the ilp model can also be used with knowledge-based systems that observe the classification-oriented formulation of the nlg tasks.
</nextsent>
<nextsent>finally, we are convinced that an adequate evaluation of an nlg system must at some stage go beyond the application of quantitative measures.
</nextsent>
<nextsent>nevertheless, it is reasonable to expect that the improvement that we reached with the ilp system, especially the increase of the overall phi score, must correlate to some extent with the quality improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3538">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1in phrase-structure parse, if phrase headed by word token is sub constituent of phrase headed by word token 6= x, then is said to depend on y. in more powerful compositional formalism like ltag or ccg, dependencies can be extracted from the derivation tree.
</prevsent>
<prevsent>2it has recently been questioned whether these bilexical?
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
features actually contribute much to parsing performance (klein and manning, 2003; <papid> P03-1054 </papid>bikel, 2004), <papid> W04-3224 </papid>at least when one has only million words of training.typical parsing features in that they cannot be determined from tree-local information.</citsent>
<aftsection>
<nextsent>though lengths are not usually considered, we will see that bilexicaldynamic-programming parsing algorithms can easily consider them as they build the parse.
</nextsent>
<nextsent>soft constraints.
</nextsent>
<nextsent>like any other feature of trees,dependency lengths can be explicitly used as features in probability model that chooses amongtrees.
</nextsent>
<nextsent>such model will tend to disfavor long dependencies (at least of some kinds), as these are empirically rare.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3539">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1in phrase-structure parse, if phrase headed by word token is sub constituent of phrase headed by word token 6= x, then is said to depend on y. in more powerful compositional formalism like ltag or ccg, dependencies can be extracted from the derivation tree.
</prevsent>
<prevsent>2it has recently been questioned whether these bilexical?
</prevsent>
</prevsection>
<citsent citstr=" W04-3224 ">
features actually contribute much to parsing performance (klein and manning, 2003; <papid> P03-1054 </papid>bikel, 2004), <papid> W04-3224 </papid>at least when one has only million words of training.typical parsing features in that they cannot be determined from tree-local information.</citsent>
<aftsection>
<nextsent>though lengths are not usually considered, we will see that bilexicaldynamic-programming parsing algorithms can easily consider them as they build the parse.
</nextsent>
<nextsent>soft constraints.
</nextsent>
<nextsent>like any other feature of trees,dependency lengths can be explicitly used as features in probability model that chooses amongtrees.
</nextsent>
<nextsent>such model will tend to disfavor long dependencies (at least of some kinds), as these are empirically rare.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3540">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> short dependencies in langugage.  </section>
<citcontext>
<prevsection>
<prevsent>we assume that correct parses exhibit short dependency preference?: words dependents tendto be close to it in the string.3 if the th word of sentence depends on the ith word, then |ij| tends to beness?: the number of intervening words.
</prevsent>
<prevsent>other distance measures could be substituted or added (following the literature onheavy-shift and sentence comprehension), including the phonological, morphological, syntactic, or referential (given/new)complexity of the intervening material (gibson, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in parsing, the most relevant previous work is due to collins (1997),<papid> P97-1003 </papid>who considered three binary features of the intervening mate rial: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons?</citsent>
<aftsection>
<nextsent>note that (b) is effective because it measures the length of dependency in terms of the number of alternative attachment sites that the dependent skipped over, notion that could be generalized.
</nextsent>
<nextsent>similarly, mcdonald et al (2005) <papid> P05-1012 </papid>separately considered each of the intervening pos tags.</nextsent>
<nextsent>30 small.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3541">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> short dependencies in langugage.  </section>
<citcontext>
<prevsection>
<prevsent>in parsing, the most relevant previous work is due to collins (1997),<papid> P97-1003 </papid>who considered three binary features of the intervening mate rial: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons?</prevsent>
<prevsent>note that (b) is effective because it measures the length of dependency in terms of the number of alternative attachment sites that the dependent skipped over, notion that could be generalized.</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
similarly, mcdonald et al (2005) <papid> P05-1012 </papid>separately considered each of the intervening pos tags.</citsent>
<aftsection>
<nextsent>30 small.
</nextsent>
<nextsent>this implies that neither nor is modified by complex phrases that fall between and j. in termsof phrase structure, it implies that the phrases modifying word from given side tend to be (1) few in number, (2) ordered so that the longer phrases fall farther from i, and (3) internally structured so that the bulk of each phrase falls on the side of away from i.these principles can be blamed for several linguistic phenomena.
</nextsent>
<nextsent>(1) helps explain the late clo sure?
</nextsent>
<nextsent>or attach low?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3543">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> short dependencies in langugage.  </section>
<citcontext>
<prevsection>
<prevsent>(1) helps explain the late clo sure?
</prevsent>
<prevsent>or attach low?
</prevsent>
</prevsection>
<citsent citstr=" C90-3029 ">
heuristic (e.g., frazier, 1979; hobbs and bear, 1990): <papid> C90-3029 </papid>modifier such as pp is more likely to attach to the closest appropriate head.</citsent>
<aftsection>
<nextsent>(2) helps account for heavy-shift: when an np islong and complex, take np out, put np on theta ble, and give np to mary are likely to be rephrased as take out np, put on the table np, and give mary np.
</nextsent>
<nextsent>(3) explains certain non-canonical word orders: in english, nouns left modifier must become right modifier if and only if it is right-heavy (a taller politician vs. politician taller than all her rivals4),and verbs left modifier may extra pose its right heavy portion (an aardvark walked in who had cir cum navigated the globe5).
</nextsent>
<nextsent>why should sentences prefer short dependencies?
</nextsent>
<nextsent>such sentences may be easier for humans to produce and comprehend.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3544">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> soft constraints on dependency length.  </section>
<citcontext>
<prevsection>
<prevsent>our techniques could be straightforwardly adapted to (bi)lexicalizedparsers on actual word sequences, though not necessarily with the same success.
</prevsent>
<prevsent>3.1 grammar formalism.
</prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
throughout this paper we will use split bilexical grammars, or sbgs (eisner, 2000), notation ally simpler variant of split head-automaton grammars, or shags (eisner and satta, 1999).<papid> P99-1059 </papid></citsent>
<aftsection>
<nextsent>the formalism is context-free.
</nextsent>
<nextsent>we define here probabilistic ver sion,6 which we use for the baseline models in our experiments.
</nextsent>
<nextsent>they are only baselines because thesbg generative process does not take note of dependency length.
</nextsent>
<nextsent>an sbg is an tuple = (?, $, l,r).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3546">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> soft constraints on dependency length.  </section>
<citcontext>
<prevsection>
<prevsent>this is accomplished by using automata }??}
</prevsent>
<prevsent> ff as in model c, which allows the stopping probabilities p(stop | q0) andp(stop | q1) to differ, but tying the conditional dis 7it is equivalent to the dependency model with valence?
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
of klein and manning (2004).<papid> P04-1061 </papid></citsent>
<aftsection>
<nextsent>tributions p(q0 wq1 | q0,stop) and p(q1 wq1 | q1,stop).
</nextsent>
<nextsent>finally, in 3, l$ and r$ are restricted as above, so r$ gives probability distribution over ? only.
</nextsent>
<nextsent>3.3 length-sensitive models.
</nextsent>
<nextsent>none of the baseline models ac explicitly model the distance between head and child.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3550">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> soft constraints on dependency length.  </section>
<citcontext>
<prevsection>
<prevsent>2a, we use prioritized agenda.
</prevsent>
<prevsent>derived items such as @ ,   ,  , and are prioritized by their viterbi-inside probabilities.
</prevsent>
</prevsection>
<citsent citstr=" J03-1006 ">
this is known as uniform-cost search or shortest-hyperpath search (nederhof, 2003).<papid> J03-1006 </papid></citsent>
<aftsection>
<nextsent>we halt as soon as full parse (the accept item) pops from the agenda, since uniform-cost search (as special case of the aalgorithm) guarantees this to be the maximum probability parse.
</nextsent>
<nextsent>no other pruning is done.11confusion-set parsing may be regarded as parsing particular lattice with states and ng arcs.
</nextsent>
<nextsent>the algorithm can be generalized to lattice parsing, in which case it has runtime o(m2(n + t?)t) for lattice of states and arcs.
</nextsent>
<nextsent>roughly, : is replaced by an arc, while is replaced by state and i?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3551">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> hard dependency-length constraints.  </section>
<citcontext>
<prevsection>
<prevsent>a log-linear or discriminative model would be trained to correct for overlapping penalties and would avoid this risk.
</prevsent>
<prevsent>non-deficient generative models are also possible to design, along lines similar to footnote 16.
</prevsent>
</prevsection>
<citsent citstr=" J00-1003 ">
16one proof is to construct strongly equivalent cfg without center-embedding (nederhof, 2000).<papid> J00-1003 </papid></citsent>
<aftsection>
<nextsent>each nonterminal has the form w, q, i, j?, where ? ?, is state of lw or rw, and i, ? {0, 1, . . .
</nextsent>
<nextsent>k1,?
</nextsent>
<nextsent>k}.
</nextsent>
<nextsent>we leave the details as an exercise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3552">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> hard dependency-length constraints.  </section>
<citcontext>
<prevsection>
<prevsent>the tighter the bound on dependency length, the fewer parse trees we allow and the faster we can find them using the algorithm of fig.
</prevsent>
<prevsent>2a.
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
if the boundis too tight to allow the correct parse of some sentence, we would still like to allow an accurate partialparse: sequence of accurate parse fragments (hin dle, 1990; <papid> P90-1034 </papid>abney, 1991; appelt et al, 1993; chen, 1995; <papid> P95-1031 </papid>grefenstette, 1996).</citsent>
<aftsection>
<nextsent>furthermore, we would like to use the fact that some fragment sequences are presumably more likely than others.
</nextsent>
<nextsent>our partial parses will look like the one in fig.
</nextsent>
<nextsent>1b.
</nextsent>
<nextsent>where 4 subtrees rather than 1 are dependent on $.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3553">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> hard dependency-length constraints.  </section>
<citcontext>
<prevsection>
<prevsent>the tighter the bound on dependency length, the fewer parse trees we allow and the faster we can find them using the algorithm of fig.
</prevsent>
<prevsent>2a.
</prevsent>
</prevsection>
<citsent citstr=" P95-1031 ">
if the boundis too tight to allow the correct parse of some sentence, we would still like to allow an accurate partialparse: sequence of accurate parse fragments (hin dle, 1990; <papid> P90-1034 </papid>abney, 1991; appelt et al, 1993; chen, 1995; <papid> P95-1031 </papid>grefenstette, 1996).</citsent>
<aftsection>
<nextsent>furthermore, we would like to use the fact that some fragment sequences are presumably more likely than others.
</nextsent>
<nextsent>our partial parses will look like the one in fig.
</nextsent>
<nextsent>1b.
</nextsent>
<nextsent>where 4 subtrees rather than 1 are dependent on $.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3559">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> hard dependency-length constraints.  </section>
<citcontext>
<prevsection>
<prevsent>(b) if th at ta h ru le sa re re st ric te to ap pl o ly he ca se |h ? ? | ? , an th c m pl t ru le o ly he |h ? i|   , th en th ad di tio na ru le in (b) ill as se bl th re su lti ng fra gm en ts in to v in pa rs e. in th is ca se , at ta h ig t sh ou ld al so be re st ric te to   0, to pr ev en du pl ic at de riv at io ns . th ru tim is (n (k + t?
</prevsent>
<prevsent>)t g2 ), do in at ed by th at ta h ru le s; th ru le in (b) re qu ire n ly (n tg 2 + gt t?
</prevsent>
</prevsection>
<citsent citstr=" H05-1036 ">
) tim e. ea ch al go rit hm is sp ec ifi ed as colle ct io o de du ct iv in fe re nc er le s. nc eo e ha sd er iv ed al an te ce de nt ite sa bo e th eh or iz on ta ll in ea d an sid ec n di tions to th er ig ht ft he lin e, n m ay de riv th co se qu en ti te be lo th lin e. ei gh te ag en da -b as ed de du ct io is ha nd le in th u su al ay (n ed erh of, 20 03 ;<papid> J03-1006 </papid>e isn er et al ., 20 05 ).<papid> H05-1036 </papid></citsent>
<aftsection>
<nextsent>th ep ro ba bi lit ie sg ov er in th ea to at on w , am el p( st ar ta tq ), p( w ? ?
</nextsent>
<nextsent>r | q) , an p( st op | q) , ar re sp ec tiv el as so ci at edith th ax io at ic ite s ? in it( w ), w ? ?
</nextsent>
<nextsent>r ? w , an q ? fin al( w ).
</nextsent>
<nextsent>a ac u st ic sc re p( bs er va tio at | ) co ld be as so ci at edith th ite w ? h .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3564">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>subset and superset approximations of (weighted) cflsby (weighted) regular languages, usually by preventing center-embedding, have been widely ex plored; nederhof (2000) <papid> J00-1003 </papid>gives thorough review.we limit all dependency lengths (not just center embedding).27 further, we derive weights from modified treebank rather than by approximating thetrue weights.</prevsent>
<prevsent>and though regular grammar approximations are useful for other purposes, we argue thatfor parsing it is more efficient to perform the approximation in the parser, not in the grammar.</prevsent>
</prevsection>
<citsent citstr=" E99-1016 ">
brants (1999) <papid> E99-1016 </papid>described parser that encoded the grammar as set of cascaded markov models.</citsent>
<aftsection>
<nextsent>the decoder was applied iteratively, with each iteration transforming the best (or n-best) output from the previous one until only the root symbol remained.
</nextsent>
<nextsent>this is greedy variant of cfg parsing where the grammar is in backus-naur form.
</nextsent>
<nextsent>bertsch and nederhof (1999) gave linear-timerecognition algorithm for the recognition of the regular closure of deterministic context-free languages.our result is related; instead of closure of deterministic cfls, we deal in closure of cfls that are assumed (by the parser) to obey some constraint on trees (like maximum dependency length).
</nextsent>
<nextsent>the simple pos-sequence models we used as an experimental baseline are certainly not among the best parsers available today.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3565">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>| d, h, c)-augmented model from 3.
</prevsent>
<prevsent>40 second, fast approximate parsing may play role in more accurate parsing.
</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
it might be used to rapidly compute approximate outside-probability estimates to prioritize best-first search (e.g., caraballo and charniak, 1998).<papid> J98-2004 </papid></citsent>
<aftsection>
<nextsent>it might also be used to speed up the early iterations of training weighted parsing model, which for modern training methods tends to require repeated parsing (either for the best parse, as by taskar et al, 2004, <papid> W04-3201 </papid>or all parses, as by miyao and tsujii, 2002).third, it would be useful to investigate algorith mic techniques and empirical benefits for limiting dependency length in more powerful grammar for malisms.</nextsent>
<nextsent>our runtime reduction from o(n3) ? o(nk2) for length-k bound applies only to asplit?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3566">
<title id=" W05-1504.xml">parsing with soft and hard constraints on dependency length </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>40 second, fast approximate parsing may play role in more accurate parsing.
</prevsent>
<prevsent>it might be used to rapidly compute approximate outside-probability estimates to prioritize best-first search (e.g., caraballo and charniak, 1998).<papid> J98-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
it might also be used to speed up the early iterations of training weighted parsing model, which for modern training methods tends to require repeated parsing (either for the best parse, as by taskar et al, 2004, <papid> W04-3201 </papid>or all parses, as by miyao and tsujii, 2002).third, it would be useful to investigate algorith mic techniques and empirical benefits for limiting dependency length in more powerful grammar for malisms.</citsent>
<aftsection>
<nextsent>our runtime reduction from o(n3) ? o(nk2) for length-k bound applies only to asplit?
</nextsent>
<nextsent>bilexical grammar.28 various kinds of synchronous grammars, in particular, are becoming important in statistical machine translation.
</nextsent>
<nextsent>their high runtime complexity might be reduced by limiting monolingual dependency length (for related idea see schafer and yarowsky, 2003).finally, consider the possibility of limiting dependency length during grammar induction.
</nextsent>
<nextsent>we reason that learner might start with simple structures that focus on local relationships, and gradually relax this restriction to allow more complex models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3569">
<title id=" W06-1002.xml">the role of lexical resources in cjk natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>5.
</prevsent>
<prevsent>accurate word segmentation (emerson 2000.
</prevsent>
</prevsection>
<citsent citstr=" C94-2209 ">
and yu et al 2000) and disambiguating ambiguous segment ations strings (ass) (zhou and yu 1994).<papid> C94-2209 </papid></citsent>
<aftsection>
<nextsent>6.
</nextsent>
<nextsent>the difficulty of lexeme-based retrieval and.
</nextsent>
<nextsent>cjk clir (goto et al 2001).
</nextsent>
<nextsent>7.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3570">
<title id=" W06-1002.xml">the role of lexical resources in cjk natural language processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic recognition of terms and their vari-.
</prevsent>
<prevsent>ants (jacquemin 2001).
</prevsent>
</prevsection>
<citsent citstr=" W97-0316 ">
the various attempts to tackle these tasks by statistical and algorithmic methods (kwok 1997) <papid> W97-0316 </papid>have had only limited success.</citsent>
<aftsection>
<nextsent>an important motivation for such methodology has been the poor availability and high cost of acquiring and maintaining large-scale lexical databases.
</nextsent>
<nextsent>this paper discusses how lexicon-driven approach exploiting large-scale lexical databases can offer reliable solutions to some of the principal issues, based on over decade of experience in building such databases for nlp applications.
</nextsent>
<nextsent>named entity recognition (ner) is useful in nlp applications such as question answering, machine translation and information extraction.
</nextsent>
<nextsent>a major difficulty inner, and strong motivation for using tools based on probabilistic methods, is that the compilation and maintenance of large entity databases is time consuming and expensive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3572">
<title id=" W05-0616.xml">an ana logical learner for morphological analysis </title>
<section> an algebraic framework for ana logical.  </section>
<citcontext>
<prevsection>
<prevsent>td = such that i, (yi, zi) ? {(xi, ti), (ti, xi)}.
</prevsent>
<prevsent>an example of analogy between words is: viewing : reviewer :: searching : researcher with x1 = ?, x2 = view, x3 = ing and t1 = re, t2 = search, t3 = er.
</prevsent>
</prevsection>
<citsent citstr=" P98-1120 ">
this definition generalizes the proposal of (lepage, 1998).<papid> P98-1120 </papid></citsent>
<aftsection>
<nextsent>it does not ensure the existence of solution to an ana logical equation, nor its uniqueness when it exists.
</nextsent>
<nextsent>(lepage, 1998) <papid> P98-1120 </papid>gives set of necessary conditions for solution toexist.</nextsent>
<nextsent>these conditions also apply here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3577">
<title id=" W05-0616.xml">an ana logical learner for morphological analysis </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>denotes irrelevant features.
</prevsent>
<prevsent>lexical analysis is useful for many applications: pos tagger, for instance, needs to guess?
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
the possible part(s)-of-speech of unknown words (mikheev,1997).<papid> J97-3003 </papid></citsent>
<aftsection>
<nextsent>for this task, we use the definition of ana logical proportions for flat?
</nextsent>
<nextsent>feature vectors (see section 3.1) and for word strings (section 3.2).
</nextsent>
<nextsent>the training data is list of fully informed lexical en tries; the test data is list of isolated word forms not represented in the lexicon.
</nextsent>
<nextsent>bins are constructed based on inflectional families.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3578">
<title id=" W06-1007.xml">structural properties of lexical systems monolingual and multilingual perspectives </title>
<section> structure of lexical systems.  </section>
<citcontext>
<prevsection>
<prevsent>consequently, dictionary-like databases are before all huge texts, consisting of collection of much smaller texts (i.e. entries).
</prevsent>
<prevsent>it seems natural to consider electronic versions of standard dictionaries as texts.
</prevsent>
</prevsection>
<citsent citstr=" W04-2209 ">
however, formal lexical databases such as the multilingual xml based jmdict (breen, 2004) <papid> W04-2209 </papid>are also textual in nature.</citsent>
<aftsection>
<nextsent>there are collections of entries, each entry consisting of structured text that tells ussomething?
</nextsent>
<nextsent>about word.
</nextsent>
<nextsent>even databases encoding relational models of the lexicon can be 100% textual, and therefore dictionary-like.
</nextsent>
<nextsent>such is the case of the french dico database (polgure,2000), that we have used for compiling our lexical system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3579">
<title id=" W05-0610.xml">using uneven margins svm and perceptron for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the former induces set of rules from training examples.
</prevsent>
<prevsent>there are many rule based learning systems, e.g. srv (freitag, 1998), rapier (califf, 1998), whisk (soderland, 1999), bwi (freitag and kushmerick, 2000), and (lp )2(ciravegna, 2001).
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
statistical systems learn statistical model or classifiers, such as hmms (freigtag and mccallum, 1999), maximal entropy (chieu and ng., 2002), the svm (isozaki and kazawa, 2002; <papid> C02-1054 </papid>mayfield et al, 2003), <papid> W03-0429 </papid>and perceptron (carreras et al., 2003).<papid> W03-0422 </papid></citsent>
<aftsection>
<nextsent>ie systems also differ from each other in the nlp features that they use.
</nextsent>
<nextsent>these include simple features such as token form and capitalisation information, linguistic features such as part-of speech, semantic information from gazetteer lists, and genre-specific information such as document structure.
</nextsent>
<nextsent>in general, the more features the system uses, the better performance it can achieve.this paper concentrates on classifier-based learning for ie, which typically converts the recognition of each information entity into set of classificationproblems.
</nextsent>
<nextsent>in the framework discussed here, two binary classifiers are trained for each type of information entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3580">
<title id=" W05-0610.xml">using uneven margins svm and perceptron for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the former induces set of rules from training examples.
</prevsent>
<prevsent>there are many rule based learning systems, e.g. srv (freitag, 1998), rapier (califf, 1998), whisk (soderland, 1999), bwi (freitag and kushmerick, 2000), and (lp )2(ciravegna, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W03-0429 ">
statistical systems learn statistical model or classifiers, such as hmms (freigtag and mccallum, 1999), maximal entropy (chieu and ng., 2002), the svm (isozaki and kazawa, 2002; <papid> C02-1054 </papid>mayfield et al, 2003), <papid> W03-0429 </papid>and perceptron (carreras et al., 2003).<papid> W03-0422 </papid></citsent>
<aftsection>
<nextsent>ie systems also differ from each other in the nlp features that they use.
</nextsent>
<nextsent>these include simple features such as token form and capitalisation information, linguistic features such as part-of speech, semantic information from gazetteer lists, and genre-specific information such as document structure.
</nextsent>
<nextsent>in general, the more features the system uses, the better performance it can achieve.this paper concentrates on classifier-based learning for ie, which typically converts the recognition of each information entity into set of classificationproblems.
</nextsent>
<nextsent>in the framework discussed here, two binary classifiers are trained for each type of information entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3581">
<title id=" W05-0610.xml">using uneven margins svm and perceptron for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the former induces set of rules from training examples.
</prevsent>
<prevsent>there are many rule based learning systems, e.g. srv (freitag, 1998), rapier (califf, 1998), whisk (soderland, 1999), bwi (freitag and kushmerick, 2000), and (lp )2(ciravegna, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W03-0422 ">
statistical systems learn statistical model or classifiers, such as hmms (freigtag and mccallum, 1999), maximal entropy (chieu and ng., 2002), the svm (isozaki and kazawa, 2002; <papid> C02-1054 </papid>mayfield et al, 2003), <papid> W03-0429 </papid>and perceptron (carreras et al., 2003).<papid> W03-0422 </papid></citsent>
<aftsection>
<nextsent>ie systems also differ from each other in the nlp features that they use.
</nextsent>
<nextsent>these include simple features such as token form and capitalisation information, linguistic features such as part-of speech, semantic information from gazetteer lists, and genre-specific information such as document structure.
</nextsent>
<nextsent>in general, the more features the system uses, the better performance it can achieve.this paper concentrates on classifier-based learning for ie, which typically converts the recognition of each information entity into set of classificationproblems.
</nextsent>
<nextsent>in the framework discussed here, two binary classifiers are trained for each type of information entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3587">
<title id=" W05-0610.xml">using uneven margins svm and perceptron for information extraction </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in the experiments we adopted classifier-basedframework for applying the svm and paum algorithms to ie.
</prevsent>
<prevsent>the framework consists of three stages: pre-processing of the documents to obtain feature vectors, learning classifiers or applying classifiers totest documents, and finally post-processing there sults to tag the documents.the aim of the preprocessing is to form input vectors from documents.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
each document is first processed using the open-source annie system, which is part of gate2 (cunningham et al, 2002).<papid> P02-1022 </papid></citsent>
<aftsection>
<nextsent>this produces number of linguistic (nlp) features, including token form, capitalisation information, token kind, lemma, part-of-speech (pos) tag, semantic classes from gazette ers, and named entity types according to annies rule-based recogniser.
</nextsent>
<nextsent>based on the linguistic information, an input vector is constructed for each token, as we iterate through the tokens in each document (includ ing word, number, punctuation and other symbols) to see if the current token belongs to an information entity or not.
</nextsent>
<nextsent>since in ie the context of the token is usually as important as the token itself, the features in the input vector come not only from the current token, but also from preceding and following ones.
</nextsent>
<nextsent>as the input vector incorporates information from the context surrounding the current token, features from different tokens can be weighted differently,based on their position in the context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3588">
<title id=" W05-0610.xml">using uneven margins svm and perceptron for information extraction </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the parameter settings for paum described in li et al (2002), e.g. ?+ = 50, ??
</prevsent>
<prevsent>= 1, were adopted in all experiments with paum, unless otherwise stated.
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
table 1 presents the results of our system using three learning algorithms, the uneven margins svm,the standard svm and the paum on the conll 2003 test set, together with the results of three participating systems in the conll-2003 shared task: the best system (florian et al, 2003), <papid> W03-0425 </papid>the svm-based system (mayfield et al, 2003) <papid> W03-0429 </papid>and the perceptron-based system (carreras et al, 2003).<papid> W03-0422 </papid>firstly, our uneven margins svm system performed significantly better than the other svm based system.</citsent>
<aftsection>
<nextsent>as the two systems are different from each other in not only the svm models used but also other aspects such as the nlp features and the framework, in order to make fair comparison between the uneven margins svm and the standard svm, we also present the results of the two learning algorithms implemented in our framework.
</nextsent>
<nextsent>we can see from table 1 that, under the same experimental settings, the uneven margins svm again performed better than the standard svm.
</nextsent>
<nextsent>secondly, our paum-based system performed slightly better than the system based on voted perceptron, but there is no significant difference between them.
</nextsent>
<nextsent>note that they adopted different mechanisms to deal with the imbalanced data in ie (refer 75 table 1: comparison to other systems on conll-2003 corpus: -measure(%) on each entity type and the overall micro-averaged f-measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3593">
<title id=" W05-1610.xml">narratological knowledge for natural language generation </title>
<section> story generation and nlg.  </section>
<citcontext>
<prevsection>
<prevsent>less energy is spent on other tasks, especially at discourse and surface level.
</prevsent>
<prevsent>in fact, most implemented sg systems use templates of different varieties for nlg.
</prevsent>
</prevsection>
<citsent citstr=" W94-0319 ">
document structuring and micro planning as nlg processing stages [reiter, 1994; <papid> W94-0319 </papid>reiter and dale, 2000:60] are usually skipped in sg, so that sg and nlg architectures can be confronted as in figure 1.</citsent>
<aftsection>
<nextsent>figure 1: story generation and natural language generation narratological knowledge for natural language generation birte lnneker narratology research group hamburg institut fr germanistik ii, university of hamburg von-melle-park 6, d-20146 hamburg birte.loenneker@uni-hamburg.de content det. doc.
</nextsent>
<nextsent>structuring document planner micro planner surface realizer communicative goal document plan (abstract) text specification surface text determine content (story), directly associated with structure (discourse) template filling of given genre (abstract) content specification surface narrative implicit goal: write coherent narrative tr ad ition al g general lg 2.2 storybook.
</nextsent>
<nextsent>the existence of gap between sg and nlg has also been discussed by callaway and lester [2002].
</nextsent>
<nextsent>to remedy the situation, they implemented storybook, an architecture for narrative prose generation?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3595">
<title id=" W05-1610.xml">narratological knowledge for natural language generation </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>for example, certain values of focal ization and point of view can cause unusual?
</prevsent>
<prevsent>referring expressions: personal pronouns might be used for initial reference [harweg, 1968: 163?
</prevsent>
</prevsection>
<citsent citstr=" P88-1016 ">
166], or indefinite referring expressions for subsequent reference [ushie, 1986; wiebe and rapaport, 1988].<papid> P88-1016 </papid></citsent>
<aftsection>
<nextsent>the choice of vocabulary, tense, and syntactic complexity can as well depend on narratological factors.
</nextsent>
<nextsent>the surface realizer turns the micro planner output into natural language text.
</nextsent>
<nextsent>see [callaway and lester, 2002:224] for narrative-related issues in surface realization.
</nextsent>
<nextsent>the narrative levels parameter will be used to illustrate the kind of knowledge that can be acquired from narratology for integration into narratologically enhanced nlg system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3596">
<title id=" W05-1610.xml">narratological knowledge for natural language generation </title>
<section> representing narrative levels.  </section>
<citcontext>
<prevsection>
<prevsent>figure 11 shows the corresponding graph, in which the segment representing narration is nucleus of two relations.7 this corresponds to schema?
</prevsent>
<prevsent>identified by mann and thompson [1988:247].
</prevsent>
</prevsection>
<citsent citstr=" W04-2324 ">
danlos [2004:<papid> W04-2324 </papid>130] presents similar double-nuclear structures (factorized?</citsent>
<aftsection>
<nextsent>nuclei) at the sentence level.
</nextsent>
<nextsent>both presented graphs are plausible.
</nextsent>
<nextsent>the final choice forgiven global narrative depends not on narratological discourse description alone, but on story contents as well.
</nextsent>
<nextsent>6.4 processing examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3597">
<title id=" W06-1112.xml">a structural similarity measure </title>
<section> imperfections of measures based.  </section>
<citcontext>
<prevsection>
<prevsent>they serve very well for example for tasks like spell checking (where the choice of the best candidates for correction of spelling error is typically based upon the levenshtein metrics) or estimating the similarity of new source sentence to those stored in the translation memory of machine aided translation system.
</prevsent>
<prevsent>they are bit controversial in proper?
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
machine translation, where the popular bleu score (papineni et al, 2002), <papid> P02-1040 </papid>although widely accepted as measure of translation accuracy, seems to favor stochastic approaches based on 91 an n-gram model over other mt methods (see the results in (nist, 2001)).</citsent>
<aftsection>
<nextsent>the controversies the bleu score seems to provoke arise due to the fact that the evaluation of mt systems can be, in general, performed from two different viewpoints.
</nextsent>
<nextsent>the first one is that of developer of such system, who needs to get reliable feedback in the process of development and debugging of the system.
</nextsent>
<nextsent>the primary interest of such person is the grammar or dictionary coverage and system performance and he needs cheap, fast and simple evaluation method in order toallow frequent routine tests indicating the improvements of the system during the development of the system.
</nextsent>
<nextsent>the second viewpoint is that of user, who is primarily concerned with the capability ofthe system to provide fast and reliable translation requiring as few post-editing efforts as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3598">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical parsers for natural language are based on probabilistic grammars acquired from transformed tree-banks.
</prevsent>
<prevsent>the method of transforming the tree-bank is of major influence on the accuracy and coverage of the statistical parser.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
themost important tree-bank transformation in the literature is lexicalization: each node in tree is labeled with its head word, the most important word of the constituent under the node (magerman (1995), <papid> P95-1037 </papid>collins (1996), <papid> P96-1025 </papid>charniak (1997), collins (1997),<papid> P97-1003 </papid>carroll and rooth (1998), etc.).</citsent>
<aftsection>
<nextsent>it turns out, how ever, that lexicalization is not unproblematic: first, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (dubey and keller, 2003).<papid> P03-1013 </papid></nextsent>
<nextsent>second, full lexicalization leads to serious sparse-data problem, which can only be solved by sophisticated smoothing and pruning techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3600">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical parsers for natural language are based on probabilistic grammars acquired from transformed tree-banks.
</prevsent>
<prevsent>the method of transforming the tree-bank is of major influence on the accuracy and coverage of the statistical parser.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
themost important tree-bank transformation in the literature is lexicalization: each node in tree is labeled with its head word, the most important word of the constituent under the node (magerman (1995), <papid> P95-1037 </papid>collins (1996), <papid> P96-1025 </papid>charniak (1997), collins (1997),<papid> P97-1003 </papid>carroll and rooth (1998), etc.).</citsent>
<aftsection>
<nextsent>it turns out, how ever, that lexicalization is not unproblematic: first, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (dubey and keller, 2003).<papid> P03-1013 </papid></nextsent>
<nextsent>second, full lexicalization leads to serious sparse-data problem, which can only be solved by sophisticated smoothing and pruning techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3603">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>state-of-the-art statistical parsers for natural language are based on probabilistic grammars acquired from transformed tree-banks.
</prevsent>
<prevsent>the method of transforming the tree-bank is of major influence on the accuracy and coverage of the statistical parser.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
themost important tree-bank transformation in the literature is lexicalization: each node in tree is labeled with its head word, the most important word of the constituent under the node (magerman (1995), <papid> P95-1037 </papid>collins (1996), <papid> P96-1025 </papid>charniak (1997), collins (1997),<papid> P97-1003 </papid>carroll and rooth (1998), etc.).</citsent>
<aftsection>
<nextsent>it turns out, how ever, that lexicalization is not unproblematic: first, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (dubey and keller, 2003).<papid> P03-1013 </papid></nextsent>
<nextsent>second, full lexicalization leads to serious sparse-data problem, which can only be solved by sophisticated smoothing and pruning techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3604">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method of transforming the tree-bank is of major influence on the accuracy and coverage of the statistical parser.
</prevsent>
<prevsent>themost important tree-bank transformation in the literature is lexicalization: each node in tree is labeled with its head word, the most important word of the constituent under the node (magerman (1995), <papid> P95-1037 </papid>collins (1996), <papid> P96-1025 </papid>charniak (1997), collins (1997),<papid> P97-1003 </papid>carroll and rooth (1998), etc.).</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
it turns out, how ever, that lexicalization is not unproblematic: first, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>second, full lexicalization leads to serious sparse-data problem, which can only be solved by sophisticated smoothing and pruning techniques.
</nextsent>
<nextsent>recently, klein and manning (2003) <papid> P03-1054 </papid>showed thata carefully performed linguistic mark-up of the tree bank leads to almost the same performance results aslexicalization.</nextsent>
<nextsent>this result is attractive since unlexi calized grammars are easy to estimate, easy to parse with, and time- and space-efficient: klein and manning (2003) <papid> P03-1054 </papid>do not smooth grammar-rule probabilities, except unknown-word probabilities, and they do not prune since they are able to determine the most probable parse of each full parse forest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3605">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it turns out, how ever, that lexicalization is not unproblematic: first, there is evidence that full lexicalization does not carry over across different tree-banks for other languages, annotations or domains (dubey and keller, 2003).<papid> P03-1013 </papid></prevsent>
<prevsent>second, full lexicalization leads to serious sparse-data problem, which can only be solved by sophisticated smoothing and pruning techniques.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
recently, klein and manning (2003) <papid> P03-1054 </papid>showed thata carefully performed linguistic mark-up of the tree bank leads to almost the same performance results aslexicalization.</citsent>
<aftsection>
<nextsent>this result is attractive since unlexi calized grammars are easy to estimate, easy to parse with, and time- and space-efficient: klein and manning (2003) <papid> P03-1054 </papid>do not smooth grammar-rule probabilities, except unknown-word probabilities, and they do not prune since they are able to determine the most probable parse of each full parse forest.</nextsent>
<nextsent>both facts are noteworthy in the context of statistical parsing with tree-bank grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3623">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>clearly, this estimation method uses the original tree-bank, where each node can be thought of annotated with the most probable latent head.
</prevsent>
<prevsent>this section presents empirical results across our models and estimation methods.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
data and parameters to facilitate comparison with previous work, we trained our models on sections 2-21 of the wsj section of the penn tree-bank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>all trees were modified such that: the empty top node got the category top, node labels consisted solely of syntactic category information, empty nodes (i.e. nodes dominating the empty string) were deleted, and words in rules occurring less than 3 times in the tree-bank were replaced by (word-suffix based) 121 baseline l=2 l=5 l=10 estimation from most probable heads model 1 (completely latent) (15 400) 73.5 (17 900) 76.3 (22 800) 80.7 (28 100) 83.3 ?=9.8 model 2 (pos+latent) (25 000) 78.9 (32 300) 81.1 (46 200) 83.3 (58 900) 82.6 ?=4.4 estimation from head distributions model 1 (completely latent) (15 400) 73.5 (25 900) 76.9 (49 200) 82.0 (79 200) 84.6 ?=11.1 model 2 (pos+latent) (25 000) 78.9 (49 500) 81.6 (116 300) 84.9 (224 300) 85.7 ?=6.8 table 2: parsing results in lp/lr f1 (the baseline is = 1) unknown-word symbols.
</nextsent>
<nextsent>no other changes were made.on this tree-bank, we trained several head lexicalized cfgs with latent-heads as described in section 3, but smoothed the grammar rules using deleted interpolation; we also performed some preliminary experiments without smoothing, but after observing that about 3000 trees of our training corpus were allocated zero-probability (resulting fromthe fact that too many grammar rules got zeroprobability), we decided to smooth all rule proba bilities.we tried to find optimal starting parameters by repeating the whole training process multiple times,but we observed that starting parameters affect final results only up to 0.5%.
</nextsent>
<nextsent>we also tried to find optimal iteration numbers by evaluating our models after each iteration step on held-out corpus, and observed that the best results were obtained with 70 to 130 iterations.
</nextsent>
<nextsent>within wide range from 50 to200 iteration, however, iteration numbers affect final results only up to 0.5% empirical result swe evaluated on parsing task performed on section 22 of the wsj section of the penn tree-bank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3624">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also tried to find optimal iteration numbers by evaluating our models after each iteration step on held-out corpus, and observed that the best results were obtained with 70 to 130 iterations.
</prevsent>
<prevsent>within wide range from 50 to200 iteration, however, iteration numbers affect final results only up to 0.5% empirical result swe evaluated on parsing task performed on section 22 of the wsj section of the penn tree-bank.
</prevsent>
</prevsection>
<citsent citstr=" C04-1024 ">
for parsing, we mapped all unknown words to unknown word symbols, and applied the viterbi algorithm as implemented in schmid (2004), <papid> C04-1024 </papid>exploiting its ability to deal with highly-ambiguous grammars.</citsent>
<aftsection>
<nextsent>that is, we did not use any pruning or smoothing routines for parsing sentences.
</nextsent>
<nextsent>we then de-transformed the resulting maximum-probability parses to the format described in the previous sub-section.
</nextsent>
<nextsent>that is, we deleted the heads, the dependencies, and the starting rules.
</nextsent>
<nextsent>all grammars were able to exhaustively parse the evaluation corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3640">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>to start with performance values, table 3 displays previous results on parsing section 23 of the wsj section of the penn tree-bank.
</prevsent>
<prevsent>comparison indicates that our best model is already better than the early lexicalized model of magerman (1995).<papid> P95-1037 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
it is bit worse than the un lexicalized pcfgs of klein and manning (2003) <papid> P03-1054 </papid>and matsuzaki et al (2005), <papid> P05-1010 </papid>and of course, it is also worse than state-of-the-art lexicalized parsers (experience shows that evaluation results on sections 22 and 23 do not differ much).beyond performance values, we believe our formalism and methodology have the following attractive features: first, our models incorporate context and lexical information collected from the whole tree-bank.</citsent>
<aftsection>
<nextsent>information is bundled into abstract heads of higher-order information, which results in drastically reduced parameter space.
</nextsent>
<nextsent>in terms of section 2, our approach does not aim at improving the approximation of rule probabilities p(r|c, h) and dependency probabilities p(d|d,c, h) by smoothing.
</nextsent>
<nextsent>rather, our approach induces head classes for the words and from the tree-bankand aims at exact calculation of rule probabilities p(r|c, class(h)) and dependency probabilities p(class(d)|d,c, class(h)).
</nextsent>
<nextsent>this is in sharp contrast to the smoothed fixed-word statistics in most lexicalized parsing models derived from sparse data (magerman (1995), <papid> P95-1037 </papid>collins (1996), <papid> P96-1025 </papid>charniak (1997), etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3651">
<title id=" W05-1512.xml">head driven pcfgs with latent head statistics </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>particularly, class-based dependency probabilities p(class(d)|d,c, class(h)) induced from the tree-bank are not exploited by most of these parsers.second, our method results in an automatic linguistic mark-up of tree-bank grammars.
</prevsent>
<prevsent>in contrast, manual linguistic mark-up of the tree-bank like in klein and manning (2003) <papid> P03-1054 </papid>is based on individual linguistic intuition and might be cost and time in tensive.third, our method can be thought of as new lexicalization scheme of cfg based on the notion of latent head-information, or as successful attempt to incorporate lexical classes into parsers, combined with new word clustering method based on the context represented by tree structure.</prevsent>
</prevsection>
<citsent citstr=" C02-1126 ">
it thus complements and extends the approach of chiang and bikel (2002), <papid> C02-1126 </papid>who aim at discovering latent head markers in tree-banks to improve manually written head-percolation rules.finally, the method can also be viewed as an extension of facto rial hmms (ghahramani and jordan,1995) to pcfgs: the node labels on trees are enriched with latent variable and the latent variables are learned by em.</citsent>
<aftsection>
<nextsent>matsuzaki et al (2005) <papid> P05-1010 </papid>independently introduce similar approach and present empirical results that rival ours.</nextsent>
<nextsent>in contrast to us, 123 they do not use an explicit linguistic grammar, andthey do not attempt to constrain the space of latent variables by linguistic principles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3653">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>analysis of the types of dependency errors made by these parsers on aczech corpus show that the correct governor is likely to be found within local neighborhood of the governor proposed by the parser.
</prevsent>
<prevsent>our model, based on amaxent classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
statistical parsing models have been shown to be successful in recovering labeled constituencies (collins, 2003; <papid> J03-4003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>roark and collins, 2004) and have also been shown to be adequate in recovering dependency relationships (collins et al, 1999; <papid> P99-1065 </papid>levy and manning, 2004;<papid> P04-1042 </papid>dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>the most successful models are based on lexicalized probabilistic context free grammars (pcfgs) induced from constituency based treebanks.
</nextsent>
<nextsent>the linear-precedence constraint of these grammars restricts the types of dependency structures that can be encoded in such trees.1 shortcoming of the constituency-based paradigm for parsing is that it is inherently incapable of representing non-projective dependencies trees (we define non-projectivity in the following section).
</nextsent>
<nextsent>thisis particularly problematic when parsing free word order languages, such as czech, due to the frequency of sentences with non-projective constructions.
</nextsent>
<nextsent>in this work, we explore corrective model which recovers non-projective dependency structures by training classifier to select correct dependency pairs from set of candidates based on parses generated by constituency-based parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3655">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>analysis of the types of dependency errors made by these parsers on aczech corpus show that the correct governor is likely to be found within local neighborhood of the governor proposed by the parser.
</prevsent>
<prevsent>our model, based on amaxent classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
statistical parsing models have been shown to be successful in recovering labeled constituencies (collins, 2003; <papid> J03-4003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>roark and collins, 2004) and have also been shown to be adequate in recovering dependency relationships (collins et al, 1999; <papid> P99-1065 </papid>levy and manning, 2004;<papid> P04-1042 </papid>dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>the most successful models are based on lexicalized probabilistic context free grammars (pcfgs) induced from constituency based treebanks.
</nextsent>
<nextsent>the linear-precedence constraint of these grammars restricts the types of dependency structures that can be encoded in such trees.1 shortcoming of the constituency-based paradigm for parsing is that it is inherently incapable of representing non-projective dependencies trees (we define non-projectivity in the following section).
</nextsent>
<nextsent>thisis particularly problematic when parsing free word order languages, such as czech, due to the frequency of sentences with non-projective constructions.
</nextsent>
<nextsent>in this work, we explore corrective model which recovers non-projective dependency structures by training classifier to select correct dependency pairs from set of candidates based on parses generated by constituency-based parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3656">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>analysis of the types of dependency errors made by these parsers on aczech corpus show that the correct governor is likely to be found within local neighborhood of the governor proposed by the parser.
</prevsent>
<prevsent>our model, based on amaxent classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.
</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
statistical parsing models have been shown to be successful in recovering labeled constituencies (collins, 2003; <papid> J03-4003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>roark and collins, 2004) and have also been shown to be adequate in recovering dependency relationships (collins et al, 1999; <papid> P99-1065 </papid>levy and manning, 2004;<papid> P04-1042 </papid>dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>the most successful models are based on lexicalized probabilistic context free grammars (pcfgs) induced from constituency based treebanks.
</nextsent>
<nextsent>the linear-precedence constraint of these grammars restricts the types of dependency structures that can be encoded in such trees.1 shortcoming of the constituency-based paradigm for parsing is that it is inherently incapable of representing non-projective dependencies trees (we define non-projectivity in the following section).
</nextsent>
<nextsent>thisis particularly problematic when parsing free word order languages, such as czech, due to the frequency of sentences with non-projective constructions.
</nextsent>
<nextsent>in this work, we explore corrective model which recovers non-projective dependency structures by training classifier to select correct dependency pairs from set of candidates based on parses generated by constituency-based parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3657">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>analysis of the types of dependency errors made by these parsers on aczech corpus show that the correct governor is likely to be found within local neighborhood of the governor proposed by the parser.
</prevsent>
<prevsent>our model, based on amaxent classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.
</prevsent>
</prevsection>
<citsent citstr=" P04-1042 ">
statistical parsing models have been shown to be successful in recovering labeled constituencies (collins, 2003; <papid> J03-4003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>roark and collins, 2004) and have also been shown to be adequate in recovering dependency relationships (collins et al, 1999; <papid> P99-1065 </papid>levy and manning, 2004;<papid> P04-1042 </papid>dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>the most successful models are based on lexicalized probabilistic context free grammars (pcfgs) induced from constituency based treebanks.
</nextsent>
<nextsent>the linear-precedence constraint of these grammars restricts the types of dependency structures that can be encoded in such trees.1 shortcoming of the constituency-based paradigm for parsing is that it is inherently incapable of representing non-projective dependencies trees (we define non-projectivity in the following section).
</nextsent>
<nextsent>thisis particularly problematic when parsing free word order languages, such as czech, due to the frequency of sentences with non-projective constructions.
</nextsent>
<nextsent>in this work, we explore corrective model which recovers non-projective dependency structures by training classifier to select correct dependency pairs from set of candidates based on parses generated by constituency-based parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3658">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>analysis of the types of dependency errors made by these parsers on aczech corpus show that the correct governor is likely to be found within local neighborhood of the governor proposed by the parser.
</prevsent>
<prevsent>our model, based on amaxent classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.
</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
statistical parsing models have been shown to be successful in recovering labeled constituencies (collins, 2003; <papid> J03-4003 </papid>charniak and johnson, 2005; <papid> P05-1022 </papid>roark and collins, 2004) and have also been shown to be adequate in recovering dependency relationships (collins et al, 1999; <papid> P99-1065 </papid>levy and manning, 2004;<papid> P04-1042 </papid>dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>the most successful models are based on lexicalized probabilistic context free grammars (pcfgs) induced from constituency based treebanks.
</nextsent>
<nextsent>the linear-precedence constraint of these grammars restricts the types of dependency structures that can be encoded in such trees.1 shortcoming of the constituency-based paradigm for parsing is that it is inherently incapable of representing non-projective dependencies trees (we define non-projectivity in the following section).
</nextsent>
<nextsent>thisis particularly problematic when parsing free word order languages, such as czech, due to the frequency of sentences with non-projective constructions.
</nextsent>
<nextsent>in this work, we explore corrective model which recovers non-projective dependency structures by training classifier to select correct dependency pairs from set of candidates based on parses generated by constituency-based parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3663">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for the nodes with incorrect dependency links in the parser output, the correct governor of node is often found within local context of the proposed governor.
</prevsent>
<prevsent>by considering alternative dependencies based on local deviations of the parser output we constrain the set of candidate governors for each node during the corrective procedure.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
we examine two state-of-the-art constituency based parsers in this work: the collins czech parser (1999) and version of the charniak parser (2001) that was modified to parse czech.alternative efforts to recover dependency structure from english are based on reconstructing the movement traces encoded in constituency trees (collins, 2003; <papid> J03-4003 </papid>levy and manning, 2004;<papid> P04-1042 </papid> johnson,2002; <papid> P02-1018 </papid>dubey and keller, 2003).<papid> P03-1013 </papid></citsent>
<aftsection>
<nextsent>in fact, the fea1in order to correctly capture the dependency structure, co indexed movement traces are used in form similar to government and binding theory, gpsg, etc. 42 wc wa wb ca wc ca wa wb wc wa wb cafigure 1: examples of projective and non-projective trees.
</nextsent>
<nextsent>the trees on the left and center are both projective.
</nextsent>
<nextsent>the tree on the right is non-projective.
</nextsent>
<nextsent>tures we use in the current model are similar to those proposed by levy and manning (2004).<papid> P04-1042 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3668">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the primary reason for such an approach is that we allow dependency structures which would never be hypothesized by the parser.
</prevsent>
<prevsent>specifically, we allow for non-projective dependencies.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the corrective algorithm proposed in this paper shares the motivation of the transformation-based learning work (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>we do consider local transformations of the dependency trees; however, the technique presented here is based on generative model that maximizes the likelihood of good dependents.
</nextsent>
<nextsent>we consider finite set of local perturbations of the tree and use fixed model to select the best tree by independently choosing optimal dependency links.in the remainder of the paper we provide definition of dependency tree and the motivation for using such trees as well as description of the particular dataset that we use in our experiments, the prague dependency treebank (pdt).
</nextsent>
<nextsent>in section 3 we describe the techniques used to adapt constituency based parsers to train from and generate dependency trees.
</nextsent>
<nextsent>section 4 describes corrective modeling asused in this work and section 4.2 describes the particular features with which we have experimented.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3670">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> constituency parsing for dependency.  </section>
<citcontext>
<prevsection>
<prevsent>this directly leads to efficient parsing algorithms such asthe cky algorithm and related agenda-based parsing algorithms (manning and schutze, 1999).
</prevsent>
<prevsent>additionally, this allows for the efficient computation ofthe scores for the dynamic-programming state variables (i.e., the inside and outside probabilities) thatare used inefficient statistical parsers.
</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
the computational complexity advantages of dynamic programming techniques along with efficient search techniques (caraballo and charniak, 1998; <papid> J98-2004 </papid>klein and manning, 2003) allow for richer predictive models which include local contextual information.in an attempt to extend constituency-based parsing model to train on dependency trees, collins transforms the pdt dependency trees into constituency trees (collins et al, 1999).<papid> P99-1065 </papid></citsent>
<aftsection>
<nextsent>in order to accomplish this task, he first normalizes the treesto remove non-projectivities.
</nextsent>
<nextsent>then, he creates artificial constituents based on the parts-of-speech of the words associated with each dependency node.
</nextsent>
<nextsent>the mapping from dependency tree to constituency tree is not one-to-one.
</nextsent>
<nextsent>collins describes heuristic for choosing trees that work well with his parsing model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3673">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> constituency parsing for dependency.  </section>
<citcontext>
<prevsection>
<prevsent>the first is based on word-reordering and is the model that was used with the collins parser.
</prevsent>
<prevsent>this algorithm identifies non-projective structures and deterministically re orders the wordsof the sentence to create projective trees.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
an alternative method, used by charniak in the adaptation of his parser for czech6 and used by nivre and nilsson (2005), <papid> P05-1013 </papid>alters the dependency links by raising the governor to higher node in the tree whenever 5bilexical dependencies are components of both the collin sand charniak parsers and effectively model the types of syntactic subordination that we wish to extract in dependency tree.</citsent>
<aftsection>
<nextsent>(bilexical models were also proposed by eisner (eisner, 1996)).<papid> C96-1058 </papid></nextsent>
<nextsent>in the absence of lexicalization, both parsers have dependency features that are encoded as head-constituent to sibling features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3674">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> constituency parsing for dependency.  </section>
<citcontext>
<prevsection>
<prevsent>this algorithm identifies non-projective structures and deterministically re orders the wordsof the sentence to create projective trees.
</prevsent>
<prevsent>an alternative method, used by charniak in the adaptation of his parser for czech6 and used by nivre and nilsson (2005), <papid> P05-1013 </papid>alters the dependency links by raising the governor to higher node in the tree whenever 5bilexical dependencies are components of both the collin sand charniak parsers and effectively model the types of syntactic subordination that we wish to extract in dependency tree.</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
(bilexical models were also proposed by eisner (eisner, 1996)).<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>in the absence of lexicalization, both parsers have dependency features that are encoded as head-constituent to sibling features.
</nextsent>
<nextsent>6this information was provided by eugene charniak in personal communication.
</nextsent>
<nextsent>44 en si ty 0.
</nextsent>
<nextsent>0 0.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3678">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> corrective modeling.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we compute the is that maximize the objective function: ? ?
</prevsent>
<prevsent>xx p?(x) log z?(x) + ? ip?(x, y)fi(x, y)a number of algorithms have been proposed to efficiently compute the optimization described in thisderivation.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
for more detailed introduction to maximum entropy estimation see (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>4.2 proposed model.
</nextsent>
<nextsent>given the above formulation of the maxent estimation procedure, we define features over pairs of observations and outcomes.
</nextsent>
<nextsent>in our case, the observations are simply wi, wc, and (wgh i) and the out come is binary variable indicating whether = gi (i.e., wc is the correct governor).
</nextsent>
<nextsent>in order to limit the dimensionality of the feature space, we consider feature functions over the outcome, the current node wi, the candidate governor node wc and the node proposed as the governor by the parser wgh . table 2 describes the general classes of features used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3682">
<title id=" W05-1505.xml">corrective modeling for non projective dependency parsing </title>
<section> corrective modeling.  </section>
<citcontext>
<prevsection>
<prevsent>while it is true that we are improving upon the output of the automatic parser, we are not considering multiple alternate parses.
</prevsent>
<prevsent>instead, we consider complete set of alternate trees that are minimal perturbations of the best tree generated by the parser.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
in the context of dependency parsing, we do this in order to generate structures that constituency-based parsers are incapable of generating (i.e., non-projectivities).recent work by smith and eisner (2005) <papid> P05-1044 </papid>on contrastive estimation suggests similar techniques to generate local neighborhoods of parse; however,the purpose in their work is to define an approximation to the partition function for log-linear estimation (i.e., the normalization factor in maxent model).</citsent>
<aftsection>
<nextsent>in this section we report results from experiments on the pdt czech dataset.
</nextsent>
<nextsent>approximately 1.9% of the words?
</nextsent>
<nextsent>dependencies are non-projective inversion 1.0 of this corpus and these occur in 23.2% of the sentences (hajicova?
</nextsent>
<nextsent>et al, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3683">
<title id=" W05-1613.xml">natural language directed inference in the presentation of ontologies </title>
<section> introduction: content determination in.  </section>
<citcontext>
<prevsection>
<prevsent>for these problems text coherence is more imporant than which particular arguments or points are made.
</prevsent>
<prevsent>for instance, the ilex project aimed to emulate museum curator telling good story to link togethera sequence of selected exhibits.
</prevsent>
</prevsection>
<citsent citstr=" W98-1404 ">
it was argued that more opportunistic approach to content determination was needed for this sort of application [mellish et al , 1998].<papid> W98-1404 </papid></citsent>
<aftsection>
<nextsent>in this paper, we concentrate primarily on the bottom-uptype of content determination problem.
</nextsent>
<nextsent>but what makes content determination hard in either case is largely the fact that two different worlds?
</nextsent>
<nextsent>are involved ? the domain model andthe linguistic world.
</nextsent>
<nextsent>content determination is selecting material from the (not necessarily very linguistic) domain model, e.g. facts, rules and numbers, in the hope that it will permit coherent realisation as text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3684">
<title id=" W05-1613.xml">natural language directed inference in the presentation of ontologies </title>
<section> introduction: content determination in.  </section>
<citcontext>
<prevsection>
<prevsent>in the worst case will mean that content is formulated which is not expressible in language at all.
</prevsent>
<prevsent>this is also related to the problem of logical form equivalence?
</prevsent>
</prevsection>
<citsent citstr=" J93-1008 ">
[shieber, 1993] <papid> J93-1008 </papid>which arises because from domain point of view two logically equivalent formulae are interchangeable and so it is matter of chance which of the many logically equivalent formulae is given to realiser.</citsent>
<aftsection>
<nextsent>must therefore be able to choose between realisations corresponding to all formulae logically equivalent to its input.the problems raised by meteer and shieber do not, however, always arise in practice.
</nextsent>
<nextsent>in many applications, the possible forms of ? are restricted enough and close enough to linguistic representation that one can be sure that there will always be at least one value for ?.
</nextsent>
<nextsent>also ? doesnt have tomap onto all possible texts ? one can artificially limit the extent to which realisation diverges from what is suggested by the surface form of the input.
</nextsent>
<nextsent>all nlg systems adopt these sorts of simplications.in the next two sections, we show how realisation and content determination initially worked in our project to present ontologies in natural language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3685">
<title id=" W05-1613.xml">natural language directed inference in the presentation of ontologies </title>
<section> natural language directed inference.  </section>
<citcontext>
<prevsection>
<prevsent>repetitive sentences: on the other hand, the axioms may give rise to sentences that are short and repetitive.
</prevsent>
<prevsent>thus, rather than using three sentences to express: student person student unemployed student supervisor.academic one could combine them all into formula realised as student is an unemployed person with at least one academic supervisor?.
</prevsent>
</prevsection>
<citsent citstr=" P95-1053 ">
in nlg, the process of building such complex sentences is known as aggregation?[shaw, 1995].<papid> P95-1053 </papid></citsent>
<aftsection>
<nextsent>this kind of aggregation could be implemented by combining the axioms together before realisation is performed, but success can only be measured by looking at the linguistic complexity of the result.
</nextsent>
<nextsent>inappropriate focus: an axiom may be expressed in way that, when realised, places inappropriate emphasis onentities.
</nextsent>
<nextsent>for instance, an axiom v could be realised by an is kind of y?, whereas the equivalent w could be realised by ys include xs?.
</nextsent>
<nextsent>the latter would be much better than the former at point in text that is discussing the properties of y. the above example of weakening?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3686">
<title id=" W05-1613.xml">natural language directed inference in the presentation of ontologies </title>
<section> techniques for nldi.  </section>
<citcontext>
<prevsection>
<prevsent>perhaps the closest approach we are aware of is meta-level control of inference, where factors outside of the logic (e.g. other kinds of descriptions of the shapes of logical formulae) are used to guide inference [bundy and welham, 1981].one advantage of nldi is that it does not have to be complete inference procedure, though in general the more logical consequences of the original axioms it can find, the more possible texts will be considered and the higher the quality of the one chosen.
</prevsent>
<prevsent>realisation evaluation inference ontology axioms text feedback score final result possible sequence of formulae figure 3: over generation architecture the approach to nldi we are currently working on is inspired by the idea of overgeneration?
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
approaches to nlg, asused, for instance, by those using statistical models [langk ilde and knight, 1998] <papid> P98-1116 </papid>and instance-based search [varges and mellish, 2001].<papid> N01-1001 </papid></citsent>
<aftsection>
<nextsent>in this approach, instead of attempting to intelligently order the relevant choices to come up with an optimal text, an nlg system consciously enumerates large number of possible texts (in cheap way) and then chooses between them using linguistically-aware evaluation function of some kind (the eval of nldi).
</nextsent>
<nextsent>our approach differs from these others, however, in that, whereas the other systems implement over generation of surface forms, we consider over generation of possible content.figure 3 shows the architecture of our system under development.
</nextsent>
<nextsent>the simple inference system implements beam search among possible sets of content for generating texts,where each state in the search space is sequence of formulae.
</nextsent>
<nextsent>in logical terms, each sequence represents conjunction that follows from the input axioms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3687">
<title id=" W05-1613.xml">natural language directed inference in the presentation of ontologies </title>
<section> techniques for nldi.  </section>
<citcontext>
<prevsection>
<prevsent>perhaps the closest approach we are aware of is meta-level control of inference, where factors outside of the logic (e.g. other kinds of descriptions of the shapes of logical formulae) are used to guide inference [bundy and welham, 1981].one advantage of nldi is that it does not have to be complete inference procedure, though in general the more logical consequences of the original axioms it can find, the more possible texts will be considered and the higher the quality of the one chosen.
</prevsent>
<prevsent>realisation evaluation inference ontology axioms text feedback score final result possible sequence of formulae figure 3: over generation architecture the approach to nldi we are currently working on is inspired by the idea of overgeneration?
</prevsent>
</prevsection>
<citsent citstr=" N01-1001 ">
approaches to nlg, asused, for instance, by those using statistical models [langk ilde and knight, 1998] <papid> P98-1116 </papid>and instance-based search [varges and mellish, 2001].<papid> N01-1001 </papid></citsent>
<aftsection>
<nextsent>in this approach, instead of attempting to intelligently order the relevant choices to come up with an optimal text, an nlg system consciously enumerates large number of possible texts (in cheap way) and then chooses between them using linguistically-aware evaluation function of some kind (the eval of nldi).
</nextsent>
<nextsent>our approach differs from these others, however, in that, whereas the other systems implement over generation of surface forms, we consider over generation of possible content.figure 3 shows the architecture of our system under development.
</nextsent>
<nextsent>the simple inference system implements beam search among possible sets of content for generating texts,where each state in the search space is sequence of formulae.
</nextsent>
<nextsent>in logical terms, each sequence represents conjunction that follows from the input axioms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3688">
<title id=" W05-1613.xml">natural language directed inference in the presentation of ontologies </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>although nlg lacks general account of content determination, one area of content determination that has been well formalised is the problem of generating referring expressions.here the task is to find distinguishing description of an entity that it is true of the entity but not of any of the distrac tors?
</prevsent>
<prevsent>in some current context.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
recent work has formalised nlg algorithms for referring expression generation in terms of algorithms for finding an appropriate subgraph of graph representing the domain knowledge [krahmer et al , 2003].<papid> J03-1003 </papid>given that the graphs involved are very similar to conceptual graphs [sowa, 1984] and that the projection relation between conceptual graphs (an extended notion of subgraph) is kind of inference, it follows that these referring expression algorithms can also be viewed as performing inference.</citsent>
<aftsection>
<nextsent>as work considers an increasing range of referring expressions (e.g. using relations, logical connectives, plurals and evenquantifiers), the complexity of the inference required is forcing researchers increasingly to depart from the original graph matching approach.
</nextsent>
<nextsent>we believe that it may well prove productive to view this as case of nldi, especially as (in spite of the assumptions of most current work) logical complexity and linguistic complexity are not always the same.
</nextsent>
<nextsent>there are many issues to be addressed in the development of convincing approach to nldi.
</nextsent>
<nextsent>for instance, it is necessary to determine what kinds of inference steps are relevant to the optimisation of linguistic properties.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3689">
<title id=" W06-0905.xml">evaluating knowledge based approaches to the multilingual extension of a temporal expression normalizer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is confirmed by the outcomes of the tern 2004 evaluation, which provide clear picture of the situation.
</prevsent>
<prevsent>inspite of the good results obtained in the te recognition task (hacioglu et al, 2005), the normalization by means of ml techniques has not been tackled yet, and still remains an unresolved problem.
</prevsent>
</prevsection>
<citsent citstr=" W06-2001 ">
considering the inadequacy of ml technique sto deal with the normalization problem, and focusing on portability across languages, this paper extends and completes the previous work presented in (saquete et al, 2006<papid> W06-2001 </papid>b) and (saquete etal., 2006<papid> W06-2001 </papid>a).</citsent>
<aftsection>
<nextsent>more specifically, we address the following crucial issue: how to minimize the costs of building rule-based te recognition system for new language, given an already existing system for another language.
</nextsent>
<nextsent>our goal is to experiment with different automatic porting procedure sto build temporal models for new languages, starting from previously defined ones.
</nextsent>
<nextsent>still adhering to the rule-based paradigm, we analyse different porting methodologies that automatically learn the te recognition model used by the system in one language, adjusting the set of normalization rules for the new target language.in order to provide clear and comprehensive overview of the challenge, an incremental approach is proposed.
</nextsent>
<nextsent>starting from the architecture of an existing system developed for spanish (saquete et al, 2005), we present bunch of experiments which take advantage of different knowledge sources to build an homologous system foritalian.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3691">
<title id=" W05-0808.xml">a hybrid approach to align sentences and words in english hindi parallel corpora </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>we present simple sentence length approach to align english-hindi sentences and hybrid approach with local word grouping and dictionary lookup as the primary techniques to align words.
</prevsent>
<prevsent>sentence alignment techniques vary from simple character-length or word-length techniques to more sophisticated techniques which involve lexical constraints and correlations or even cognates (wu 2000).
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
examples of such alignment techniques are brown et al (1991), <papid> P91-1022 </papid>kay and roscheisen (1993), <papid> J93-1006 </papid>warwick et al (1989), and the align?</citsent>
<aftsection>
<nextsent>programme by gale and church (1993).
</nextsent>
<nextsent>2.1 length-based methods.
</nextsent>
<nextsent>length-based approaches are computationally better, while lexical methods are more resource 57 hungry.
</nextsent>
<nextsent>brown et al (1991) <papid> P91-1022 </papid>and gale and church (1993) are amongst the most cited works in text alignment work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3692">
<title id=" W05-0808.xml">a hybrid approach to align sentences and words in english hindi parallel corpora </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>we present simple sentence length approach to align english-hindi sentences and hybrid approach with local word grouping and dictionary lookup as the primary techniques to align words.
</prevsent>
<prevsent>sentence alignment techniques vary from simple character-length or word-length techniques to more sophisticated techniques which involve lexical constraints and correlations or even cognates (wu 2000).
</prevsent>
</prevsection>
<citsent citstr=" J93-1006 ">
examples of such alignment techniques are brown et al (1991), <papid> P91-1022 </papid>kay and roscheisen (1993), <papid> J93-1006 </papid>warwick et al (1989), and the align?</citsent>
<aftsection>
<nextsent>programme by gale and church (1993).
</nextsent>
<nextsent>2.1 length-based methods.
</nextsent>
<nextsent>length-based approaches are computationally better, while lexical methods are more resource 57 hungry.
</nextsent>
<nextsent>brown et al (1991) <papid> P91-1022 </papid>and gale and church (1993) are amongst the most cited works in text alignment work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3700">
<title id=" W05-0808.xml">a hybrid approach to align sentences and words in english hindi parallel corpora </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>in their algorithm, they consider the most reliable pair of source and target sentences, i.e. those that contain many possible lexical correspondences.
</prevsent>
<prevsent>they achieved 96% coverage on scientific american articles after four passes of the algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P93-1002 ">
other examples of lexical methods are warwick et al (1989), mayers et al (1998), chen (1993) <papid> P93-1002 </papid>and haruno and yamazaki (1996).<papid> P96-1018 </papid></citsent>
<aftsection>
<nextsent>warwick et al (1989) calculate the probability of word pairings on the basis of frequency of source word and the number of possible translations appearing in target segments.
</nextsent>
<nextsent>they suggest using bilingual dictionary to build word-pairs.
</nextsent>
<nextsent>mayers et al (1998) propose method that is based on machine readable dictionary.
</nextsent>
<nextsent>since bilingual dictionaries contain base forms, they pre-process the text to find the base form for each word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3702">
<title id=" W05-0808.xml">a hybrid approach to align sentences and words in english hindi parallel corpora </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>in their algorithm, they consider the most reliable pair of source and target sentences, i.e. those that contain many possible lexical correspondences.
</prevsent>
<prevsent>they achieved 96% coverage on scientific american articles after four passes of the algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P96-1018 ">
other examples of lexical methods are warwick et al (1989), mayers et al (1998), chen (1993) <papid> P93-1002 </papid>and haruno and yamazaki (1996).<papid> P96-1018 </papid></citsent>
<aftsection>
<nextsent>warwick et al (1989) calculate the probability of word pairings on the basis of frequency of source word and the number of possible translations appearing in target segments.
</nextsent>
<nextsent>they suggest using bilingual dictionary to build word-pairs.
</nextsent>
<nextsent>mayers et al (1998) propose method that is based on machine readable dictionary.
</nextsent>
<nextsent>since bilingual dictionaries contain base forms, they pre-process the text to find the base form for each word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3712">
<title id=" W05-0808.xml">a hybrid approach to align sentences and words in english hindi parallel corpora </title>
<section> future works.  </section>
<citcontext>
<prevsection>
<prevsent>we aim to implement or use local word grouping rules for the english text and improve our existing word grouping rules for the hindi texts.
</prevsent>
<prevsent>the nearest aligned neighbours approach suggests possible alignments, but we are trying to integrate some statistical ranking algorithms in order to suggest more reliable pairs of alignment.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
yarowsky et al (2001) <papid> H01-1035 </papid>introduced new method for developing part-of-speech tagger by projecting tags across aligned corpora.</citsent>
<aftsection>
<nextsent>they used this technique to supply data for supervised learning technique to acquire french part-of-speech tagger.
</nextsent>
<nextsent>we aim to use our english-hindi word alignment results to bootstrap part-of-speech tagger for the hindi language.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3713">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>news articles typically contain mixture of information presented from several different perspectives, and often in complex ways.
</prevsent>
<prevsent>writers may present information as known to them, or from some other individuals perspective, while further distinguishing between, for example, whether that perspective involves an assertion or belief.
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
recent work has shown the importance of recognizing such perspectivization of information for several nlp applications, such as information extraction, summarization, question answering (wiebe et al, 2004; <papid> J04-3002 </papid>stoyanov et al, 2005; <papid> H05-1116 </papid>riloff et al, 2005) and generation (prasad et al, 2005).</citsent>
<aftsection>
<nextsent>part ofthe goal of such applications is to distinguish between factual and non-factual information, and to identify the source of the information.
</nextsent>
<nextsent>annotation schemes (wiebe et al, 2005; wilson and wiebe,2005; <papid> W05-0308 </papid>pdtb-group, 2006) encode such distinctions to facilitate accurate recognition and representation of such perspectivization of information.</nextsent>
<nextsent>this paper describes an extended annotation scheme for marking the attribution of discourse relations and their arguments annotated in the penn discourse treebank (pdtb) (miltsakaki et al, 2004; <papid> W04-2703 </papid>prasad et al, 2004; <papid> W04-0212 </papid>webber et al, 2005), the primary goal being to capture the source and degrees of factuality of abstract objects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3715">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>news articles typically contain mixture of information presented from several different perspectives, and often in complex ways.
</prevsent>
<prevsent>writers may present information as known to them, or from some other individuals perspective, while further distinguishing between, for example, whether that perspective involves an assertion or belief.
</prevsent>
</prevsection>
<citsent citstr=" H05-1116 ">
recent work has shown the importance of recognizing such perspectivization of information for several nlp applications, such as information extraction, summarization, question answering (wiebe et al, 2004; <papid> J04-3002 </papid>stoyanov et al, 2005; <papid> H05-1116 </papid>riloff et al, 2005) and generation (prasad et al, 2005).</citsent>
<aftsection>
<nextsent>part ofthe goal of such applications is to distinguish between factual and non-factual information, and to identify the source of the information.
</nextsent>
<nextsent>annotation schemes (wiebe et al, 2005; wilson and wiebe,2005; <papid> W05-0308 </papid>pdtb-group, 2006) encode such distinctions to facilitate accurate recognition and representation of such perspectivization of information.</nextsent>
<nextsent>this paper describes an extended annotation scheme for marking the attribution of discourse relations and their arguments annotated in the penn discourse treebank (pdtb) (miltsakaki et al, 2004; <papid> W04-2703 </papid>prasad et al, 2004; <papid> W04-0212 </papid>webber et al, 2005), the primary goal being to capture the source and degrees of factuality of abstract objects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3716">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work has shown the importance of recognizing such perspectivization of information for several nlp applications, such as information extraction, summarization, question answering (wiebe et al, 2004; <papid> J04-3002 </papid>stoyanov et al, 2005; <papid> H05-1116 </papid>riloff et al, 2005) and generation (prasad et al, 2005).</prevsent>
<prevsent>part ofthe goal of such applications is to distinguish between factual and non-factual information, and to identify the source of the information.</prevsent>
</prevsection>
<citsent citstr=" W05-0308 ">
annotation schemes (wiebe et al, 2005; wilson and wiebe,2005; <papid> W05-0308 </papid>pdtb-group, 2006) encode such distinctions to facilitate accurate recognition and representation of such perspectivization of information.</citsent>
<aftsection>
<nextsent>this paper describes an extended annotation scheme for marking the attribution of discourse relations and their arguments annotated in the penn discourse treebank (pdtb) (miltsakaki et al, 2004; <papid> W04-2703 </papid>prasad et al, 2004; <papid> W04-0212 </papid>webber et al, 2005), the primary goal being to capture the source and degrees of factuality of abstract objects.</nextsent>
<nextsent>the scheme captures four salient properties of attribution: (a) source, distinguishing between different types of agents to whom aos are attributed, (b) type, reflecting the degree of factuality of the ao, (c) scopal polarity of attribution, indicating polarity reversals of attributed aos due to surface negated attributions, and (d) determinacy of attribution, indicating the presence of contexts canceling the entailment of attribution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3717">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part ofthe goal of such applications is to distinguish between factual and non-factual information, and to identify the source of the information.
</prevsent>
<prevsent>annotation schemes (wiebe et al, 2005; wilson and wiebe,2005; <papid> W05-0308 </papid>pdtb-group, 2006) encode such distinctions to facilitate accurate recognition and representation of such perspectivization of information.</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
this paper describes an extended annotation scheme for marking the attribution of discourse relations and their arguments annotated in the penn discourse treebank (pdtb) (miltsakaki et al, 2004; <papid> W04-2703 </papid>prasad et al, 2004; <papid> W04-0212 </papid>webber et al, 2005), the primary goal being to capture the source and degrees of factuality of abstract objects.</citsent>
<aftsection>
<nextsent>the scheme captures four salient properties of attribution: (a) source, distinguishing between different types of agents to whom aos are attributed, (b) type, reflecting the degree of factuality of the ao, (c) scopal polarity of attribution, indicating polarity reversals of attributed aos due to surface negated attributions, and (d) determinacy of attribution, indicating the presence of contexts canceling the entailment of attribution.
</nextsent>
<nextsent>the scheme also describes annotation of the text spans signaling the attribution.
</nextsent>
<nextsent>the proposed scheme is an extension of the core scheme used for annotating attribution in the first release of the pdtb (dinesh et al, 2005; <papid> W05-0305 </papid>pdtb-group, 2006).</nextsent>
<nextsent>section 2 gives an overview of the pdtb, section 3 presents the extended annotation scheme for attribution, and section 4 presents the summary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3718">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>part ofthe goal of such applications is to distinguish between factual and non-factual information, and to identify the source of the information.
</prevsent>
<prevsent>annotation schemes (wiebe et al, 2005; wilson and wiebe,2005; <papid> W05-0308 </papid>pdtb-group, 2006) encode such distinctions to facilitate accurate recognition and representation of such perspectivization of information.</prevsent>
</prevsection>
<citsent citstr=" W04-0212 ">
this paper describes an extended annotation scheme for marking the attribution of discourse relations and their arguments annotated in the penn discourse treebank (pdtb) (miltsakaki et al, 2004; <papid> W04-2703 </papid>prasad et al, 2004; <papid> W04-0212 </papid>webber et al, 2005), the primary goal being to capture the source and degrees of factuality of abstract objects.</citsent>
<aftsection>
<nextsent>the scheme captures four salient properties of attribution: (a) source, distinguishing between different types of agents to whom aos are attributed, (b) type, reflecting the degree of factuality of the ao, (c) scopal polarity of attribution, indicating polarity reversals of attributed aos due to surface negated attributions, and (d) determinacy of attribution, indicating the presence of contexts canceling the entailment of attribution.
</nextsent>
<nextsent>the scheme also describes annotation of the text spans signaling the attribution.
</nextsent>
<nextsent>the proposed scheme is an extension of the core scheme used for annotating attribution in the first release of the pdtb (dinesh et al, 2005; <papid> W05-0305 </papid>pdtb-group, 2006).</nextsent>
<nextsent>section 2 gives an overview of the pdtb, section 3 presents the extended annotation scheme for attribution, and section 4 presents the summary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3719">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the scheme captures four salient properties of attribution: (a) source, distinguishing between different types of agents to whom aos are attributed, (b) type, reflecting the degree of factuality of the ao, (c) scopal polarity of attribution, indicating polarity reversals of attributed aos due to surface negated attributions, and (d) determinacy of attribution, indicating the presence of contexts canceling the entailment of attribution.
</prevsent>
<prevsent>the scheme also describes annotation of the text spans signaling the attribution.
</prevsent>
</prevsection>
<citsent citstr=" W05-0305 ">
the proposed scheme is an extension of the core scheme used for annotating attribution in the first release of the pdtb (dinesh et al, 2005; <papid> W05-0305 </papid>pdtb-group, 2006).</citsent>
<aftsection>
<nextsent>section 2 gives an overview of the pdtb, section 3 presents the extended annotation scheme for attribution, and section 4 presents the summary.
</nextsent>
<nextsent>the pdtb contains annotations of discourse relations and their arguments on the wall street journal corpus (marcus et al, 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>following the approach towards discourse structure in (webberet al, 2003), <papid> J03-4002 </papid>the pdtb takes lexicalized ap 31proach towards the annotation of discourse relations, treating discourse connectives as the anchors of the relations, and thus as discourse-level predicates taking two abstract objects (aos) astheir arguments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3720">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> the penn discourse treebank (pdtb).  </section>
<citcontext>
<prevsection>
<prevsent>the proposed scheme is an extension of the core scheme used for annotating attribution in the first release of the pdtb (dinesh et al, 2005; <papid> W05-0305 </papid>pdtb-group, 2006).</prevsent>
<prevsent>section 2 gives an overview of the pdtb, section 3 presents the extended annotation scheme for attribution, and section 4 presents the summary.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the pdtb contains annotations of discourse relations and their arguments on the wall street journal corpus (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>following the approach towards discourse structure in (webberet al, 2003), <papid> J03-4002 </papid>the pdtb takes lexicalized ap 31proach towards the annotation of discourse relations, treating discourse connectives as the anchors of the relations, and thus as discourse-level predicates taking two abstract objects (aos) astheir arguments.</nextsent>
<nextsent>for example, in (1), the subordinating conjunction since is discourse connective that anchors temporal relation between the event of the earthquake hitting and state whereno music is played by certain woman.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3721">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> the penn discourse treebank (pdtb).  </section>
<citcontext>
<prevsection>
<prevsent>section 2 gives an overview of the pdtb, section 3 presents the extended annotation scheme for attribution, and section 4 presents the summary.
</prevsent>
<prevsent>the pdtb contains annotations of discourse relations and their arguments on the wall street journal corpus (marcus et al, 1993).<papid> J93-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-4002 ">
following the approach towards discourse structure in (webberet al, 2003), <papid> J03-4002 </papid>the pdtb takes lexicalized ap 31proach towards the annotation of discourse relations, treating discourse connectives as the anchors of the relations, and thus as discourse-level predicates taking two abstract objects (aos) astheir arguments.</citsent>
<aftsection>
<nextsent>for example, in (1), the subordinating conjunction since is discourse connective that anchors temporal relation between the event of the earthquake hitting and state whereno music is played by certain woman.
</nextsent>
<nextsent>(the 4 digit number in parentheses at the end of examples gives the wsj file number of the example.)
</nextsent>
<nextsent>(1) she hasnt played any music since the earthquake hit.
</nextsent>
<nextsent>(0766) there are primarily two types of connectives in the pdtb: explicit?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3723">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> annotation of attribution.  </section>
<citcontext>
<prevsection>
<prevsent>recent work (wiebe et al, 2005; prasad et al, 2005; riloff et al, 2005; stoyanov et al, 2005),<papid> H05-1116 </papid>has shown the importance of recognizing and representing the source and factuality of information in certain nlp applications.</prevsent>
<prevsent>information extraction systems, for example, would perform better 32by prioritizing the presentation of factual information, and multi-perspective question answering systems would benefit from presenting information from different perspectives.</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
most of the annotation approaches tackling these issues, however, are aimed at performing classifications at either the document level (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>or the sentence or word level (wiebe et al, 2004; <papid> J04-3002 </papid>yu and hatzivassiloglou,2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>in addition, these approaches focus primarily on sentiment classification, and use the samefor getting at the classification of facts vs. opinions.
</nextsent>
<nextsent>in contrast to these approaches, the focus here is on marking attribution on more analytic semantic units, namely the abstract objects (aos)associated with predicate-argument discourse relations annotated in the pdtb, with the aim of providing compositional classification of the factuality of aos.
</nextsent>
<nextsent>the scheme isolates four key properties of attribution, to be annotated as features: (1) source, which distinguishes between different types of agents (section 3.1); (2) type, which encodes the nature of relationship between agents and aos, reflecting the degree of factuality of the ao (section 3.2); (3) scopal polarity, which is marked when surface negated attribution reverses the polarity of the attributed ao (section 3.3), and (4) determinacy, which indicates the presence of contexts due to which the entailment of attribution gets cancelled (section 3.4).
</nextsent>
<nextsent>in addition, to further facilitate the task of identifying attribution, the scheme also aims to annotate the text span complex signaling attribution (section 3.5)results from annotations using the earlier attribution scheme (pdtb-group, 2006) show that asignificant proportion (34%) of the annotated discourse relations have some non-writer agent asthe source for either the relation or one or both arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3724">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> annotation of attribution.  </section>
<citcontext>
<prevsection>
<prevsent>recent work (wiebe et al, 2005; prasad et al, 2005; riloff et al, 2005; stoyanov et al, 2005),<papid> H05-1116 </papid>has shown the importance of recognizing and representing the source and factuality of information in certain nlp applications.</prevsent>
<prevsent>information extraction systems, for example, would perform better 32by prioritizing the presentation of factual information, and multi-perspective question answering systems would benefit from presenting information from different perspectives.</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
most of the annotation approaches tackling these issues, however, are aimed at performing classifications at either the document level (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>or the sentence or word level (wiebe et al, 2004; <papid> J04-3002 </papid>yu and hatzivassiloglou,2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>in addition, these approaches focus primarily on sentiment classification, and use the samefor getting at the classification of facts vs. opinions.
</nextsent>
<nextsent>in contrast to these approaches, the focus here is on marking attribution on more analytic semantic units, namely the abstract objects (aos)associated with predicate-argument discourse relations annotated in the pdtb, with the aim of providing compositional classification of the factuality of aos.
</nextsent>
<nextsent>the scheme isolates four key properties of attribution, to be annotated as features: (1) source, which distinguishes between different types of agents (section 3.1); (2) type, which encodes the nature of relationship between agents and aos, reflecting the degree of factuality of the ao (section 3.2); (3) scopal polarity, which is marked when surface negated attribution reverses the polarity of the attributed ao (section 3.3), and (4) determinacy, which indicates the presence of contexts due to which the entailment of attribution gets cancelled (section 3.4).
</nextsent>
<nextsent>in addition, to further facilitate the task of identifying attribution, the scheme also aims to annotate the text span complex signaling attribution (section 3.5)results from annotations using the earlier attribution scheme (pdtb-group, 2006) show that asignificant proportion (34%) of the annotated discourse relations have some non-writer agent asthe source for either the relation or one or both arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3727">
<title id=" W06-0305.xml">annotating attribution in the penn discourse treebank </title>
<section> annotation of attribution.  </section>
<citcontext>
<prevsection>
<prevsent>recent work (wiebe et al, 2005; prasad et al, 2005; riloff et al, 2005; stoyanov et al, 2005),<papid> H05-1116 </papid>has shown the importance of recognizing and representing the source and factuality of information in certain nlp applications.</prevsent>
<prevsent>information extraction systems, for example, would perform better 32by prioritizing the presentation of factual information, and multi-perspective question answering systems would benefit from presenting information from different perspectives.</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
most of the annotation approaches tackling these issues, however, are aimed at performing classifications at either the document level (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002), <papid> P02-1053 </papid>or the sentence or word level (wiebe et al, 2004; <papid> J04-3002 </papid>yu and hatzivassiloglou,2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>in addition, these approaches focus primarily on sentiment classification, and use the samefor getting at the classification of facts vs. opinions.
</nextsent>
<nextsent>in contrast to these approaches, the focus here is on marking attribution on more analytic semantic units, namely the abstract objects (aos)associated with predicate-argument discourse relations annotated in the pdtb, with the aim of providing compositional classification of the factuality of aos.
</nextsent>
<nextsent>the scheme isolates four key properties of attribution, to be annotated as features: (1) source, which distinguishes between different types of agents (section 3.1); (2) type, which encodes the nature of relationship between agents and aos, reflecting the degree of factuality of the ao (section 3.2); (3) scopal polarity, which is marked when surface negated attribution reverses the polarity of the attributed ao (section 3.3), and (4) determinacy, which indicates the presence of contexts due to which the entailment of attribution gets cancelled (section 3.4).
</nextsent>
<nextsent>in addition, to further facilitate the task of identifying attribution, the scheme also aims to annotate the text span complex signaling attribution (section 3.5)results from annotations using the earlier attribution scheme (pdtb-group, 2006) show that asignificant proportion (34%) of the annotated discourse relations have some non-writer agent asthe source for either the relation or one or both arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3728">
<title id=" W04-2705.xml">the nombank project an interim report </title>
<section> error analysis and error detection.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample in they didnt want the company to fall into the hands of rival, there is an implication that the company is an arg1 of rival, i.e., rival should be interpreted as rival of the company.7 the connection between riv aland the company is called bridging?
</prevsent>
<prevsent>relation (a process akin to coreference, cf.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
(poesio and vieira, 1998))<papid> J98-2001 </papid>in other words, fall into the hands of does not link ri val?</citsent>
<aftsection>
<nextsent>with the company by means of support.
</nextsent>
<nextsent>the fact that discourse relation is responsible for this connection becomes evident when you see that the link between rival and company can cross sentence boundaries, e.g., the company was losing money.
</nextsent>
<nextsent>this was because rival had come up with really clever marketing strategy.
</nextsent>
<nextsent>6.2 pre nominal adjectives and error detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3729">
<title id=" W04-2705.xml">the nombank project an interim report </title>
<section> error analysis and error detection.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the same argument role should not appear more than once (the stratal uniqueness condition in relational grammar or the theta criterion in principles and parameters, etc.).
</prevsent>
<prevsent>furthermore, it is unlikely for the first word of sentence to be an argument unless the main predicate is nearby (within three words) or unless there is nearby support verb.
</prevsent>
</prevsection>
<citsent citstr=" W01-1511 ">
finally, it is unlikely that there is an empty category that is an argument of predicate noun unless the empty category is linked to some real np.8 wrong-pos we use procedures that are part of our systems for generating glarf, predicate argument framework discussed in (meyers et al, 2001<papid> W01-1511 </papid>a; meyers et al, 2001<papid> W01-1511 </papid>b), to detect incorrect parts of speech in the penn treebank.</citsent>
<aftsection>
<nextsent>if an instance is predicted to be part of speech other than common noun, but it is still tagged, that instance is flagged.
</nextsent>
<nextsent>for example, if word tagged as singular common noun is the first word in vp, it is probably tagged with the wrong part of speech.
</nextsent>
<nextsent>6.4 the results of error detection.
</nextsent>
<nextsent>the processes described in the previous subsections are used to create list of annotation instances to check along with short standardized descriptions of what was wrong,e.g., wrong-pos, non-functional (if there were two identical argument roles), etc. annotators do second pass8empty categories mark invisible?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3737">
<title id=" W04-2705.xml">the nombank project an interim report </title>
<section> future research: automatic annotation.  </section>
<citcontext>
<prevsection>
<prevsent>we will conduct formal evaluation of this procedure over the next month.
</prevsent>
<prevsent>we are just starting new phase in this project: the creation of an automatic annotator.
</prevsent>
</prevsection>
<citsent citstr=" W98-0604 ">
using techniques similar to those described in (meyers et al, 1998) <papid> W98-0604 </papid>in combination with our work on glarf (meyers et al, 2001<papid> W01-1511 </papid>a; meyers et al, 2001<papid> W01-1511 </papid>b), we expect to build hand-codedpropbanker program designed to produce prop bank/nombank style analysis from penn treebank styleinput.</citsent>
<aftsection>
<nextsent>although the prop banker should work with input in the form of either treebank annotation or treebank based parser output, this project only requires application to the penn treebank itself.
</nextsent>
<nextsent>while previous programs with similar goals (gildea and jurafsky, 2002) <papid> J02-3001 </papid>were statistics-based, this tool will be based completely on hand-coded rules and lexical resources.depending on its accuracy, automatically produced annotation should be useful as either pre processor or asan error detector.</nextsent>
<nextsent>we expect high precision for very simple frames, e.g., nouns like lot as in figure 10.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3746">
<title id=" W04-2705.xml">the nombank project an interim report </title>
<section> future research: automatic annotation.  </section>
<citcontext>
<prevsection>
<prevsent>using techniques similar to those described in (meyers et al, 1998) <papid> W98-0604 </papid>in combination with our work on glarf (meyers et al, 2001<papid> W01-1511 </papid>a; meyers et al, 2001<papid> W01-1511 </papid>b), we expect to build hand-codedpropbanker program designed to produce prop bank/nombank style analysis from penn treebank styleinput.</prevsent>
<prevsent>although the prop banker should work with input in the form of either treebank annotation or treebank based parser output, this project only requires application to the penn treebank itself.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
while previous programs with similar goals (gildea and jurafsky, 2002) <papid> J02-3001 </papid>were statistics-based, this tool will be based completely on hand-coded rules and lexical resources.depending on its accuracy, automatically produced annotation should be useful as either pre processor or asan error detector.</citsent>
<aftsection>
<nextsent>we expect high precision for very simple frames, e.g., nouns like lot as in figure 10.
</nextsent>
<nextsent>annotators will have the opportunity to judge whether particular automatic annotation is good enough?
</nextsent>
<nextsent>to serve as apreprocessor.
</nextsent>
<nextsent>we hypothesize that comparison of automatic annotation that fails this level of accuracy against the hand annotation will still be useful for detecting errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3747">
<title id=" W06-0118.xml">voting between dictionary based and subword tagging models for chinese word segmentation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>participating in the third sighan chinese word segmentation bakeoff in 2006, our system is tested on the closed track of cityu, msra andupuc corpora.
</prevsent>
<prevsent>the sections below provide detailed description of the system and our experimental results.
</prevsent>
</prevsection>
<citsent citstr=" C92-1019 ">
in our segmentation system, hybrid strategy is applied (figure 1): first, forward maximum matching (chen and liu, 1992), <papid> C92-1019 </papid>which is dictionary-based method, is used to generate asegmentation result.</citsent>
<aftsection>
<nextsent>also, the crf model using maximum subword-based tagging (zhang et al ., 2006) <papid> N06-2049 </papid>and the crf model using minimumsubword-based tagging, both of which are statistical methods, are used individually to solve the problem.</nextsent>
<nextsent>in the next step, the solutions from these three methods are combined via the hanzilevel majority voting algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3748">
<title id=" W06-0118.xml">voting between dictionary based and subword tagging models for chinese word segmentation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the sections below provide detailed description of the system and our experimental results.
</prevsent>
<prevsent>in our segmentation system, hybrid strategy is applied (figure 1): first, forward maximum matching (chen and liu, 1992), <papid> C92-1019 </papid>which is dictionary-based method, is used to generate asegmentation result.</prevsent>
</prevsection>
<citsent citstr=" N06-2049 ">
also, the crf model using maximum subword-based tagging (zhang et al ., 2006) <papid> N06-2049 </papid>and the crf model using minimumsubword-based tagging, both of which are statistical methods, are used individually to solve the problem.</citsent>
<aftsection>
<nextsent>in the next step, the solutions from these three methods are combined via the hanzilevel majority voting algorithm.
</nextsent>
<nextsent>then, postprocessing procedure is applied in order to to getthe final output.
</nextsent>
<nextsent>this procedure merges adjoining words to match the dictionary entries and then splits words which are inconsistent with entries in the training corpus.
</nextsent>
<nextsent>forward postprocessing majority voting result input sentence tagging subwordbased minimum crf with tagging subwordbased maximum crf with matching maximum figure 1: outline of the segmentation process 2.1 forward maximum matching.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3751">
<title id=" W06-0108.xml">cluster based language model for sentence retrieval in chinese question answering </title>
<section> experiments and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the testing questions are collected via four different approaches which has 7050 chinese questions currently.
</prevsent>
<prevsent>in this section, we randomly select 807 testing questions which are fact-based short-answer questions.
</prevsent>
</prevsection>
<citsent citstr=" H05-1054 ">
moreover, the answers of all testing questions are named entities identified by [youzheng wu, et al 2005].<papid> H05-1054 </papid></citsent>
<aftsection>
<nextsent>figure 2 gives the details.
</nextsent>
<nextsent>note that, loc, org, per, num and tim denote the questions which answer types are location, organization, person, number and time respectively, sum means all question types.
</nextsent>
<nextsent>165 311 28 168 135 0 100 200 300 400 per loc org tim num figure 2 the distribution of various question types over testing questions chinese question answering system is to return ranked list of five answer sentences per question and will be strictly evaluated (unsup ported answers counted as wrong) using mean reciprocal rank (mrr).
</nextsent>
<nextsent>4.1 baseline: standard language model for.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3752">
<title id=" W04-3239.xml">a boosting algorithm for classification of semi structured text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to be identified.
</prevsent>
<prevsent>at present, ntt communication science laboratories, 2-4, hikaridai, seika-cho, soraku, kyoto, 619-0237 japan taku@cslab.kecl.ntt.co.jpgiven that number of successes have been reported in the field of traditional text classification,the focus of recent research has expanded from simple topic identification to more challenging tasks such as opinion/modality identification.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
example includes categorization of customer e-mails and reviews by types of claims, modalities or subjectivities (turney, 2002; <papid> P02-1053 </papid>wiebe, 2000).</citsent>
<aftsection>
<nextsent>for the latter, the traditional bag-of-words representation isnot sufficient, and richer, structural representation is required.
</nextsent>
<nextsent>a straightforward way to extend the traditional bag-of-words representation is to heuristic ally add new types of features to the original bag-of-words features, such as fixed-lengthn-grams (e.g., word bi-gram or tri-gram) or fixed length syntactic relations (e.g., modifier-head relations).
</nextsent>
<nextsent>these ad-hoc solutions might give us reasonable performance, however, they are highly task dependent and require careful design to create the optimal?
</nextsent>
<nextsent>feature set for each task.generally speaking, by using text processing systems, text can be converted into semi-structuredtext annotated with parts-of-speech, base-phrase information or syntactic relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3753">
<title id=" W04-3239.xml">a boosting algorithm for classification of semi structured text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, we describe the details of our boosting algorithm inwhich the subtree-based decision stumps are applied as weak learners.
</prevsent>
<prevsent>second, we show an implementation issue related to constructing an efficient learning algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
we also discuss the relation between our algorithm and svms (boser et al, 1992) with tree kernel (collins and duffy, 2002; <papid> P02-1034 </papid>kashima and koyanagi, 2002).</citsent>
<aftsection>
<nextsent>two experiments on the opinion and modality classification tasks are employed to confirm that subtree features are important.
</nextsent>
<nextsent>we first assume that text to be classified is represented as labeled ordered tree.
</nextsent>
<nextsent>the focused problem can be formalized as general problem, called the tree classification problem.
</nextsent>
<nextsent>the tree classification problem is to induce mapping f(x) : ? {1}, from given training examples = {xi, yi?}li=1, where xi ? is labeled ordered tree and yi ? {1} is class label associated with each training data (we focus hereon the problem of binary classification.).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3764">
<title id=" W05-1625.xml">answer generation with temporal data integration </title>
<section> motivations.  </section>
<citcontext>
<prevsection>
<prevsent>in the following sections, we present related works and general typology of relations between candidate answers.
</prevsent>
<prevsent>2.1 related works.
</prevsent>
</prevsection>
<citsent citstr=" N03-1022 ">
most of existing systems on the web produce set of answers to question in the form of hyper links or page extracts, ranked according to relevance score (for example, cogex[moldovan et al, 2003]).<papid> N03-1022 </papid></citsent>
<aftsection>
<nextsent>other systems also define relationships between web page extracts or texts containing possible answers ([harabagiu et al, 2004], [radev et al, 1998]).for example, [webber et al, 2002] defines 4 relationships between possible answers:   equivalence: equivalent answers which entail mutually,   inclusion: one-way entailment of answers,   aggregation: answers that are mutually consistent butnot entailing, and that can be replaced by their conjunction,   alternative: answers that are inconsistent or alternatives and that can be replaced by their disjunction.
</nextsent>
<nextsent>most of question-answering systems generate answers which take into account neither information given by all candidate answers nor their inconsistency.
</nextsent>
<nextsent>this is the point we focus on in the following section.
</nextsent>
<nextsent>2.2 general typology of integration mechanisms to better characterise our problem, we collected, via google or qristal [qristal], corpus of around 100 question answer pairs in french that reflect different inconsistencyproblems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3765">
<title id=" W05-0207.xml">using syntactic information to identify plagiarism </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we hypothesize that syntax plays role in capturing expression of content.
</prevsent>
<prevsent>our approach to recognizing paraphrased works is based on phrase structure of sentences in general, and structure of verb phrases in particular.most approaches to similarity detection use computationally cheap but linguistically less informed features (peng and hen gartner, 2002; sichel, 1974; williams, 1975) such as keywords, function words, word lengths, and sentence lengths; approaches that include deeper linguistic information, such as syntactic information, usually incur significant computational costs (uzuner et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
our approach identifies useful linguistic information without incurring the computational cost of full text parsing; it uses context-free grammars to perform high level syntactic analysis of part-of-speech tagged text (brill, 1992).<papid> A92-1021 </papid></citsent>
<aftsection>
<nextsent>it turns out that such level of analysis is sufficient to capture syntactic information related to creative aspects of writing; this inturn helps improve recognition of paraphrased documents.
</nextsent>
<nextsent>the results presented here show that extraction of useful linguistic information for text classification purposes does not have to be computationally prohibitively expensive, and that despite the tradeoff between the accuracy of features and computational efficiency, we can extract linguistically informed features without full parsing.
</nextsent>
<nextsent>in this paper, we first identify linguistic elements of expression and then study patterns in the use of these elements to recognize work even when it isparaphrased.
</nextsent>
<nextsent>translated literary works provide examples of linguistic elements that differ in expression but convey similar content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3766">
<title id=" W05-0207.xml">using syntactic information to identify plagiarism </title>
<section> identifying creative aspects of writing.  </section>
<citcontext>
<prevsection>
<prevsent>np + + np + np.
</prevsent>
<prevsent>semantics of verbs in general, and levins verb classes in particular, have previously been used for evaluating content and genre similarity (hatzivassiloglou et al, 1999).
</prevsent>
</prevsection>
<citsent citstr=" C88-1065 ">
in addition, similar semantic classes of verbs were used in natural language processing applications: start was the first natural language question answering system to use such verb classes (katz and levin, 1988).<papid> C88-1065 </papid></citsent>
<aftsection>
<nextsent>we use 39levins semantic verb classes to describe the expression of an author in particular work.
</nextsent>
<nextsent>we assume that semantically similar verbs are often used in semantically similar syntactic alternations; we describe part of an authors expression in particular work in terms of the semantic classes ofverbs she uses and the particular argument structures, e.g., np + + np + pp, she prefers for them.
</nextsent>
<nextsent>as many verbs belong to multiple semantic classes, to capture the dominant semantic verb classes in each document we credit all semantic classes of all observed verbs.
</nextsent>
<nextsent>we extract the argument structures from part of speech tagged text, using context-free grammars (uzuner, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3767">
<title id=" W05-0104.xml">a core tools statistical nlp course </title>
<section> topics.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned above, organized the lectures around linguistic topics rather than mathematical methods.
</prevsent>
<prevsent>however, given the degree to which the course focused on such foundational methods, this order was perhaps mistake.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
for example, it meant that simple word alignment models like ibm models 1 and 2 (brown et al., 1990) <papid> J90-2002 </papid>and the hmm model (vogel et al,1996) <papid> C96-2141 </papid>came many weeks after hmms were introduced in the context of part-of-speech tagging.</citsent>
<aftsection>
<nextsent>i also separated unsupervised learning into itsown sub-sequence, where now wish had presented the unsupervised approaches to each task along with the supervised ones.i assigned readings from jurafsky and martin (2000) and manning and schutze (1999) for the first half of the course, but the second halfwas almost entirely based on papers from there search literature.
</nextsent>
<nextsent>this reflected both increasing sophistication on the part of the students and insufficient coverage of the latter topics in the textbooks.
</nextsent>
<nextsent>the key component which characterized this course was the assignments.
</nextsent>
<nextsent>each assignment is described below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3768">
<title id=" W05-0104.xml">a core tools statistical nlp course </title>
<section> topics.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned above, organized the lectures around linguistic topics rather than mathematical methods.
</prevsent>
<prevsent>however, given the degree to which the course focused on such foundational methods, this order was perhaps mistake.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
for example, it meant that simple word alignment models like ibm models 1 and 2 (brown et al., 1990) <papid> J90-2002 </papid>and the hmm model (vogel et al,1996) <papid> C96-2141 </papid>came many weeks after hmms were introduced in the context of part-of-speech tagging.</citsent>
<aftsection>
<nextsent>i also separated unsupervised learning into itsown sub-sequence, where now wish had presented the unsupervised approaches to each task along with the supervised ones.i assigned readings from jurafsky and martin (2000) and manning and schutze (1999) for the first half of the course, but the second halfwas almost entirely based on papers from there search literature.
</nextsent>
<nextsent>this reflected both increasing sophistication on the part of the students and insufficient coverage of the latter topics in the textbooks.
</nextsent>
<nextsent>the key component which characterized this course was the assignments.
</nextsent>
<nextsent>each assignment is described below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3769">
<title id=" W05-0104.xml">a core tools statistical nlp course </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>first, perplexity on held out wsj text was calculated.
</prevsent>
<prevsent>in this evaluation, reserving the correct mass for unknown words was important.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
second, their language models were used to rescore n-best speech lists (suppliedby brian roark, see roark (2001)).<papid> J01-2004 </papid></citsent>
<aftsection>
<nextsent>finally, random sentences were generatively sampled from their models, giving students concrete feedback on how their models did (or did not) capture information about english.
</nextsent>
<nextsent>the support code in tially provided an un smoothed unigram model to get students started.
</nextsent>
<nextsent>they were then askedto build several more complex language models, including at least one higher-order interpolated model, and at least one model using good turing or held-out smoothing.
</nextsent>
<nextsent>beyond these requirements, students were encouraged to acheive the best possible word error rate and perplexity figures by whatever means they chose.1 they were also asked to identify ways in which their language models missed important trends of en1after each assignment, presented in class an honors list, consisting of the students who won on any measure or who had simply built something clever.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3770">
<title id=" W05-0104.xml">a core tools statistical nlp course </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>25 ning, first on small toy problem and then onthe proper-name identification problem from assignment 1.
</prevsent>
<prevsent>the support code provided optimization code (an l-bfgs optimizer) and feature indexing machinery, so students only wrote code to calculate the maxent objective function and its derivatives.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the original intention of assignment 2 was that students then use this maxent classifier as building block of maxent part-of-speech tagger like that of ratnaparkhi (1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the support code supplied most-frequent-tag baseline tagger and greedy lattice decoder.
</nextsent>
<nextsent>the students first improved the local scoring function (keep ing the greedy decoder) using either an hmm or maxent model for each timeslice.
</nextsent>
<nextsent>once this was complete, they upgraded the greedy decoder to viterbi decoder.
</nextsent>
<nextsent>since students were, in practice, generally only willing to wait about 20 minutes for an experiment to run, most chose to discard their maxent classifiers and build generative hmm taggers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3771">
<title id=" W05-0104.xml">a core tools statistical nlp course </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>about half of the students final taggers exceeded 96% per-word tagging accuracy, which found very impressive.
</prevsent>
<prevsent>students were only required to build trigram tagger of some kind.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
however, many chose to have smoothed hmms with complex emission models like brants (2000), <papid> A00-1031 </papid>while others built maxent taggers.</citsent>
<aftsection>
<nextsent>because of the slowness of maxent taggers?
</nextsent>
<nextsent>training, will just ask students to build hmm taggers next time.
</nextsent>
<nextsent>moreover, with the relation between the two parts of this assignment gone, will separate out the proper-name classification part into its own assignment.
</nextsent>
<nextsent>4.4 assignment 3: parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3772">
<title id=" W05-0104.xml">a core tools statistical nlp course </title>
<section> assignments.  </section>
<citcontext>
<prevsection>
<prevsent>a baseline left branching parser was provided.
</prevsent>
<prevsent>students wrote an agenda-based uniform-cost parser essentially from scratch.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
once the parser parsed correctly with the supplied treebank grammar, students experimented with horizontal and vertical markov ization (see klein and manning (2003)) <papid> P03-1054 </papid>to improve parsing accuracy.</citsent>
<aftsection>
<nextsent>students were then free to experiment with speed-ups to the parser, more complex annotation schemes, and so on.
</nextsent>
<nextsent>most students?
</nextsent>
<nextsent>parsers ran at reasonable speeds (around minute for 40 word sentences) and got final f1 measures over 82%, which is substantially higher than an unannotated treebank grammar will produce.
</nextsent>
<nextsent>while this assignment would appear to be more work than the others, it actually got the least overload-related complaints of all the assignments.in the future, may instead have students implement an array-based cky parser (kasami, 1965), since better understanding of cky would have been more useful than knowing about agenda-based methods for later parts of the course.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3773">
<title id=" W04-2804.xml">ends based dialogue processing </title>
<section> a number of projects </section>
<citcontext>
<prevsection>
<prevsent>in the mobile scenario speech input can be combined with pen-based pointing.all functional ities, modality combinations and technical realizations including wide variety of hardware options for the periphery are addressed by the same core dialogue system with common shared knowledge sources.
</prevsent>
<prevsent>the processing relies on knowledge based, configurableapproach: we provide general solutions based on declarative knowledge sources in favour for special solutionsand/or shortcuts or application specific procedural processing steps within the dialogue core of the system.
</prevsent>
</prevsection>
<citsent citstr=" W03-0903 ">
the interaction processing is based on m3l (multimodal markup language), complete xml language designed in the context of smartkom that covers all data interfaces within the complex multimodal dialogue system (gurevych et al, 2003<papid> W03-0903 </papid>a).</citsent>
<aftsection>
<nextsent>the technical realization is based on the multi platform testbed (herzog etal., 2004), an integration platform that provides distributed component architecture.
</nextsent>
<nextsent>multi platform is implemented on the basis of the scalable and efficientpublish/subscribe approach that decouples data producers and data consumers.
</nextsent>
<nextsent>software modules communicate via so-called data pools that correspond to named message queues.
</nextsent>
<nextsent>every data pool can be linked to an individual data type specification in order to define admissible message contents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3775">
<title id=" W04-2804.xml">ends based dialogue processing </title>
<section> a number of modules </section>
<citcontext>
<prevsection>
<prevsent>at least since (reiter, 1995) the use of templates and deep rep resentations?
</prevsent>
<prevsent>is not seen as contradiction.
</prevsent>
</prevsection>
<citsent citstr=" W98-1422 ">
picking up on this idea, the generation component in smartkom isbased on fully lexicalized generation (becker, 1998), <papid> W98-1422 </papid>using partial derivation trees of tree-adjoining grammar(tag).</citsent>
<aftsection>
<nextsent>right from the beginning of development, derivation trees which are seen as reflecting syntactic dependencies have been an explicitly represented layer in the template rules.
</nextsent>
<nextsent>thus the higher level planning rules decide content selection, sentence plans and lexicalization, leaving syntactic realization to tag-based second step.
</nextsent>
<nextsent>during development, we have enriched the syntactic trees with nested feature structures and have just finish eda transformation of the phrasal templates to fully lexicalized tag, where every lexical item has its unique tree.
</nextsent>
<nextsent>one of the most important constraints when building afunctioning system has been the domain of the application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3778">
<title id=" W06-1206.xml">automated multiword expression prediction for grammar engineering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, the task is to distinguish the mwes from the other cases.
</prevsent>
<prevsent>to do this, first we propose to use the world wide web as very large corpus from which we collect evidence that enables us torule out noisy cases (due to spelling errors, for in stance), following grefenstette (1999), keller et al.
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
(2002), kilgarriff and grefenstette (2003) <papid> J03-3001 </papid>and villavicencio (2005).</citsent>
<aftsection>
<nextsent>the candidates that are keptcan be semi-automatically included in the grammar, by employing lexical type predictor, whose output we use in order to add lexical entries to the lexicon, with possible manual check by grammar writer.
</nextsent>
<nextsent>this procedure significantly speeds up the process of grammar development, relieving the grammar developer of some of the burden by automatically detecting parse failures and providing semi-automatic means for handling them.
</nextsent>
<nextsent>the paper starts with discussion of mwes and of some of the characteristics that make them so challenging for nlp, in section 2.
</nextsent>
<nextsent>this is followed by more detailed discussion of the technique employed for error detection, in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3779">
<title id=" W06-1206.xml">automated multiword expression prediction for grammar engineering </title>
<section> detection of mwes and related.  </section>
<citcontext>
<prevsection>
<prevsent>n-gram count professionals 248 the flat 62 indication of 21 tone of voice 19 as always is 7 table 3: some examples of the n-grams in error mining results in order to distinguish those n-grams that canbe added into the grammar as mwe lexical entries from the other cases, we propose to validate them using evidence collected from the world wide web.
</prevsent>
<prevsent>3it has later been confirmed with the grammar developer that almost all of the errors detected by these low pars ability uni-grams can be fixed by adding correct lexical entries.
</prevsent>
</prevsection>
<citsent citstr=" W02-1030 ">
constructions recently, many researchers have started using the world wide web as an extremely large corpus, since, as pointed out by grefenstette (1999), the web is the largest dataset available for nlp((grefenstette, 1999), (keller et al, 2002), (<papid> W02-1030 </papid>kilgarriff and grefenstette, 2003) <papid> J03-3001 </papid>and (villavicencio, 2005)).</citsent>
<aftsection>
<nextsent>for instance, grefenstette employs the web to do example-based machine translation of compounds from french into english.
</nextsent>
<nextsent>the method he employs would suffer considerably from data sparseness, if it were to rely only on corpus data.
</nextsent>
<nextsent>so for compounds that are sparse in the bnc he also obtains frequencies from the web.
</nextsent>
<nextsent>the scale of the web can help to minimise the problem of data sparseness, that is especially acute for mwes,and villavicencio (2005) uses the web to find evidence to verify automatically generated vpcs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3781">
<title id=" W06-1206.xml">automated multiword expression prediction for grammar engineering </title>
<section> automated deep lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>given that the lexicon of deep grammars can be modelled by mapping from word stems to atomic lexical types, we now go on designing the statistical methods that can automatically guess?
</prevsent>
<prevsent>such mappings for unknown words.
</prevsent>
</prevsection>
<citsent citstr=" W05-1008 ">
similar to baldwin (2005), <papid> W05-1008 </papid>we also treat the problem as classification task.</citsent>
<aftsection>
<nextsent>but there is an important difference.
</nextsent>
<nextsent>while baldwin (2005) <papid> W05-1008 </papid>makes predictions for each unknown word, we create anew lexical entry for each occurrence of theun known word.</nextsent>
<nextsent>the assumption behind this is that there should be exactly one lexical entry that corresponds to the occurrence of the word in the given context5.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3783">
<title id=" W06-1206.xml">automated multiword expression prediction for grammar engineering </title>
<section> automated deep lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>we choose the maximum entropy-based model because it can easily handle thousands of features and large number of possible outputs.
</prevsent>
<prevsent>it also has the advantages of general feature representation and no independence assumption between features.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
withthe efficient parameter estimation algorithms discussed by malouf (2002), <papid> W02-2018 </papid>the training of the model is now very fast.</citsent>
<aftsection>
<nextsent>for our prediction model, the probability of alexical type given an unknown word and its context is: p(t|c) = exp( ? ifi(t, c)) ? tt exp( ? ifi(t?, c)) (3)where feature fi(t, c) may encode arbitrary characteristics of the context.
</nextsent>
<nextsent>the parameters   1, 2, . . .
</nextsent>
<nextsent>  can be evaluated by maximising the pseudo-likelihood on training corpus (malouf,2002).<papid> W02-2018 </papid></nextsent>
<nextsent>the detailed design and feature selection for the lexical type predictor are described in zhang and kordoni (2006).5lexical ambiguity is not considered here for the unknowns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3785">
<title id=" W06-0502.xml">multilingual ontology acquisition from multiple mrds </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the information contained in ontologies is important for number of tasks, for example word sense disambiguation, question answering and machine translation.
</prevsent>
<prevsent>in this paper, we present the results of experiments conducted in automatic onto logical acquisition over two languages, english and japanese, and from three different machine-readable dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" C04-1111 ">
useful semantic relations can be extracted from large corpora using relatively simple patterns (e.g., (pantel et al , 2004)).<papid> C04-1111 </papid></citsent>
<aftsection>
<nextsent>while large corpora often contain information not found in lexicons, even very large corpus may not include all the familiar words of language, let al ne those words occur ring in useful patterns (amano and kondo, 1999).
</nextsent>
<nextsent>therefore it makes sense to also extract data from machine readable dictionaries (mrds).
</nextsent>
<nextsent>there is great deal of work on the creation of ontologies from machine readable dictionaries (a good summary is (wilkes et al , 1996)), mainly for english.
</nextsent>
<nextsent>recently, there has also been interest in japanese (tokunaga et al , 2001; nichol set al , 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3786">
<title id=" W06-0502.xml">multilingual ontology acquisition from multiple mrds </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>advances in the state-of-the-art in parsing have made it practical to use deep processing systems that produce rich syntactic and semantic analyses to parse lexicons.
</prevsent>
<prevsent>this high level of semantic information makes it easy to identify the relations between words that make up an ontology.
</prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
such an approach was taken by the mindnet project (richardson et al , 1998).<papid> P98-2180 </papid></citsent>
<aftsection>
<nextsent>however, deep parsing systems often suffer from small lexicons and large amounts of parse ambiguity, making it difficult to apply this knowledge broadly.
</nextsent>
<nextsent>our ontology extraction system uses robust minimal recur sion semantics (rmrs), formalism that provides high level of detail while, atthe same time, allowing for the flexibility of underspecification.
</nextsent>
<nextsent>rmrs encodes syntactic information in general enough manner to make processing of and extraction from syntactic phenomena including coordination, relative clause analy 10 sis and the treatment of argument structure from verbs and verbal nouns.
</nextsent>
<nextsent>it provides common format for naming semantic relations, allowing them to be generalized over languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3787">
<title id=" W06-0502.xml">multilingual ontology acquisition from multiple mrds </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>we used robust minimal recur sion semantics (rmrs) designed as part of the deep thought project (callmeier et al , 2004) as the formalism for our onto logical relation extraction engine.
</prevsent>
<prevsent>we used deep-processing tools from the deep linguistic processing with hpsg initiative (delph-in: http://www.delph-in.net/) as well as medium- and shallow-processing tools for japanese processing (the morphological analyzer 11 chasen and the dependency parser cabocha) from the matsumoto laboratory.
</prevsent>
</prevsection>
<citsent citstr=" C04-1185 ">
2.4.1 robust minimal recur sion semantics robust minimal recur sion semantics is form of flat semantics which is designed to allow deepand shallow processing to use compatible semantic representation, with fine-grained atomic components of semantic content so shallow methods can contribute just what they know, yet with enough expressive power for rich semantic content including generalized quantifiers (frank, 2004).<papid> C04-1185 </papid></citsent>
<aftsection>
<nextsent>the architecture of the representation is based on minimal recur sion semantics (copestake et al ,2005), including bag of labeled elementary predicates (eps) and their arguments, list of scoping constraints which enable scope underspecification,and handle that provides hook into the representation.
</nextsent>
<nextsent>the representation can be underspecified in three ways: relationships can be omitted (such as quantifiers, messages, conjunctions and so on); predicate-argument relations can be omitted; and predicate names can be simplified.
</nextsent>
<nextsent>predicate names are defined in such way as to be as compatible (predictable) as possible among different analysis engines, using lemma pos sub sense naming convention, where the sub sense is optional and the part-of-speech (pos) for coarse-grainedsense distinctions is drawn from small set of general types (noun, verb, sahen (verbal noun), . . .
</nextsent>
<nextsent>the predicate unten (u unten drive?), for example, is less specific than unten 2 and thus subsumes it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3788">
<title id=" W06-0502.xml">multilingual ontology acquisition from multiple mrds </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>these first 10,000 sentences were parsed andthen manually tree-banked to provide the training material for constructing the stochastic model used for best-only parsing of the rest of the definition sentences.
</prevsent>
<prevsent>using pos-based unknown-word guessing for missing lexical entries, mrses were obtained for about 75% of the first 100,000 definition sentences.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
2.4.3 medium parser (cabocha-rmrs)for japanese, we produce rmrs from the dependency parser cabocha (kudo and matsumoto, 2002).<papid> W02-2016 </papid></citsent>
<aftsection>
<nextsent>the method is similar to that of spreyer and frank (2005), <papid> I05-6001 </papid>who produce rmrs from detailed german dependencies.</nextsent>
<nextsent>cabocha provides fairly minimal dependencies: there are three links (dependent, parallel, apposition) and they link base phrases (japanese bunsetsu), marked withthe syntactic and semantic head.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3789">
<title id=" W06-0502.xml">multilingual ontology acquisition from multiple mrds </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>using pos-based unknown-word guessing for missing lexical entries, mrses were obtained for about 75% of the first 100,000 definition sentences.
</prevsent>
<prevsent>2.4.3 medium parser (cabocha-rmrs)for japanese, we produce rmrs from the dependency parser cabocha (kudo and matsumoto, 2002).<papid> W02-2016 </papid></prevsent>
</prevsection>
<citsent citstr=" I05-6001 ">
the method is similar to that of spreyer and frank (2005), <papid> I05-6001 </papid>who produce rmrs from detailed german dependencies.</citsent>
<aftsection>
<nextsent>cabocha provides fairly minimal dependencies: there are three links (dependent, parallel, apposition) and they link base phrases (japanese bunsetsu), marked withthe syntactic and semantic head.
</nextsent>
<nextsent>the cabocha rmrs parser uses this information, along with heuristics based on the parts-of-speech, to produce underspecified rmrss.
</nextsent>
<nextsent>cabocha-rmrs is capable of making use of hpsg resources, including verbal case frames, to further enrich its output.
</nextsent>
<nextsent>this allows it to produce rmrs that approaches the granularity of the analyses given by hpsg parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3790">
<title id=" W06-0502.xml">multilingual ontology acquisition from multiple mrds </title>
<section> results and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>if at least one of the index words classes is subsumed by at least one of the genus?
</prevsent>
<prevsent>classes, then we consider the relationship confirmed (1).
</prevsent>
</prevsection>
<citsent citstr=" W04-2209 ">
?(ch,cg) : {ch ? cg;ch c(wh);cg c(wg)} (1) to test cross-linguistically, we looked up the headwords in translation lexicon (alt-j/e (ike hara et al , 1991) and edict (breen, 2004)) <papid> W04-2209 </papid>and then did the confirmation on the set of translation sci ? c(t (wi)).</citsent>
<aftsection>
<nextsent>although looking up the translation adds noise, the additional filter of the relationship triple effectively filters it out again.
</nextsent>
<nextsent>the total figures given in table 3 do not match the totals given in table 2.
</nextsent>
<nextsent>these totals represent the number of relations where both the definition word and semantic head were found in at least one of the ontologies being used in this comparison.
</nextsent>
<nextsent>by comparing these numbers to the totals given in section 4, we can get an idea of the coverage of the ontologies being used in comparison.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3791">
<title id=" W05-0903.xml">preprocessing and normalization for automatic evaluation of machine translation </title>
<section> automatic evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>( sm+ ? ? em1 ek min ( nem1 ,k , nem1 ,k )) } with the geometric mean gm and brevity penalty lpbleu := min ( 1 , exp ( 1 ? i??
</prevsent>
<prevsent>i? )) in the original bleu definition, the smoothing term sm is zero.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
to allow for sentence-wise evaluation, lin and och (2004) <papid> C04-1072 </papid>define the bleu-s measure with s1 := 1 and sm 1 := 0.</citsent>
<aftsection>
<nextsent>we have adopted this technique for this study.
</nextsent>
<nextsent>2.1.4 nist the nist score (doddington, 2002) extends the bleu score by taking information weights of the m-grams into account.
</nextsent>
<nextsent>the nist information weight is defined as info(em1 ) := ?
</nextsent>
<nextsent>( log2 nem1 ? log2 nem11 ) with nem1 := ? k,r nen1 ,k,r. note that the weight of phrase occurring in many references sentence for candidate is considered to be lower than the weight of phrase occurring only once!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3795">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also demonstrate how the models learned through our unsupervised method can be used as features in supervised pronoun resolution system.
</prevsent>
<prevsent>pronoun resolution typically employs some combination of constraints and preferences to select the antecedent from preceding noun phrase candidates.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
constraints filter the candidate list of improbable antecedents, while preferences encourage selection of antecedents that are more recent, frequent, etc. implementation of constraints and preference scan be based on empirical insight (lappin and leass, 1994), <papid> J94-4002 </papid>or machine learning from reference 88 annotated corpus (ge et al , 1998).<papid> W98-1119 </papid></citsent>
<aftsection>
<nextsent>the majority of pronoun resolution approaches have thus far relied on manual intervention in the resolution process, such as using manually-parsed corpus, or manually removing difficult non-anaphoric cases; we follow mitkov et al approach (2002) with afully-automatic pronoun resolution method.
</nextsent>
<nextsent>parsing, noun-phrase identification, and non-anaphoric pronoun removal are all done automatically.
</nextsent>
<nextsent>machine-learned, fully-automatic systems aremore common in noun phrase coreference resolution, where the method of choice has been decision trees (soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></nextsent>
<nextsent>these systems generally handle pronouns as subset of all noun phrases, but with limited features compared to systems devoted solely to pronouns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3796">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also demonstrate how the models learned through our unsupervised method can be used as features in supervised pronoun resolution system.
</prevsent>
<prevsent>pronoun resolution typically employs some combination of constraints and preferences to select the antecedent from preceding noun phrase candidates.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
constraints filter the candidate list of improbable antecedents, while preferences encourage selection of antecedents that are more recent, frequent, etc. implementation of constraints and preference scan be based on empirical insight (lappin and leass, 1994), <papid> J94-4002 </papid>or machine learning from reference 88 annotated corpus (ge et al , 1998).<papid> W98-1119 </papid></citsent>
<aftsection>
<nextsent>the majority of pronoun resolution approaches have thus far relied on manual intervention in the resolution process, such as using manually-parsed corpus, or manually removing difficult non-anaphoric cases; we follow mitkov et al approach (2002) with afully-automatic pronoun resolution method.
</nextsent>
<nextsent>parsing, noun-phrase identification, and non-anaphoric pronoun removal are all done automatically.
</nextsent>
<nextsent>machine-learned, fully-automatic systems aremore common in noun phrase coreference resolution, where the method of choice has been decision trees (soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></nextsent>
<nextsent>these systems generally handle pronouns as subset of all noun phrases, but with limited features compared to systems devoted solely to pronouns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3798">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the majority of pronoun resolution approaches have thus far relied on manual intervention in the resolution process, such as using manually-parsed corpus, or manually removing difficult non-anaphoric cases; we follow mitkov et al approach (2002) with afully-automatic pronoun resolution method.
</prevsent>
<prevsent>parsing, noun-phrase identification, and non-anaphoric pronoun removal are all done automatically.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
machine-learned, fully-automatic systems aremore common in noun phrase coreference resolution, where the method of choice has been decision trees (soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>these systems generally handle pronouns as subset of all noun phrases, but with limited features compared to systems devoted solely to pronouns.
</nextsent>
<nextsent>kehlerused maximum entropy to assign probability distribution over possible noun phrase coreference relationships (1997).
</nextsent>
<nextsent>like his approach, our system does not make hard coreference decisions, but returns distribution over candidates.the above learning approaches require annotated training data for supervised learning.
</nextsent>
<nextsent>cardie and wagstaff developed an unsupervised approach that partitions noun phrases into co referent groups through clustering (1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3799">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the majority of pronoun resolution approaches have thus far relied on manual intervention in the resolution process, such as using manually-parsed corpus, or manually removing difficult non-anaphoric cases; we follow mitkov et al approach (2002) with afully-automatic pronoun resolution method.
</prevsent>
<prevsent>parsing, noun-phrase identification, and non-anaphoric pronoun removal are all done automatically.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
machine-learned, fully-automatic systems aremore common in noun phrase coreference resolution, where the method of choice has been decision trees (soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>these systems generally handle pronouns as subset of all noun phrases, but with limited features compared to systems devoted solely to pronouns.
</nextsent>
<nextsent>kehlerused maximum entropy to assign probability distribution over possible noun phrase coreference relationships (1997).
</nextsent>
<nextsent>like his approach, our system does not make hard coreference decisions, but returns distribution over candidates.the above learning approaches require annotated training data for supervised learning.
</nextsent>
<nextsent>cardie and wagstaff developed an unsupervised approach that partitions noun phrases into co referent groups through clustering (1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3801">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>cardie and wagstaff developed an unsupervised approach that partitions noun phrases into co referent groups through clustering (1999).
</prevsent>
<prevsent>however, the partitions they generate for particular document are not useful for processing new documents, while our approach learns distributions that can be used on unseen data.
</prevsent>
</prevsection>
<citsent citstr=" N04-1038 ">
there are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (ge et al , 1998), <papid> W98-1119 </papid>or contextual role-knowledge (bean and riloff, 2004).<papid> N04-1038 </papid></citsent>
<aftsection>
<nextsent>co-training can also leverage unlabeled data through weakly-supervised reference resolution learning (muller et al , 2002).
</nextsent>
<nextsent>as an alternative to co-training, ng and cardie (2003) <papid> N03-1023 </papid>use em to augment supervised coreference system with unlabeled data.</nextsent>
<nextsent>their feature set is quite different, as it is designed to generalize from the data in labeled set, while our system models individual words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3802">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (ge et al , 1998), <papid> W98-1119 </papid>or contextual role-knowledge (bean and riloff, 2004).<papid> N04-1038 </papid></prevsent>
<prevsent>co-training can also leverage unlabeled data through weakly-supervised reference resolution learning (muller et al , 2002).</prevsent>
</prevsection>
<citsent citstr=" N03-1023 ">
as an alternative to co-training, ng and cardie (2003) <papid> N03-1023 </papid>use em to augment supervised coreference system with unlabeled data.</citsent>
<aftsection>
<nextsent>their feature set is quite different, as it is designed to generalize from the data in labeled set, while our system models individual words.
</nextsent>
<nextsent>we suspect that the two approaches can be combined.
</nextsent>
<nextsent>our approach is inspired by the use of em in bilingual word alignment, which finds word-to-wordcorrespondences between sentence and its translation.
</nextsent>
<nextsent>the prominent statistical methods in this field are unsupervised.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3803">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our approach is inspired by the use of em in bilingual word alignment, which finds word-to-wordcorrespondences between sentence and its translation.
</prevsent>
<prevsent>the prominent statistical methods in this field are unsupervised.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
our methods are most influenced by ibms model 1 (brown et al , 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>3.1 problem formulation.
</nextsent>
<nextsent>we will consider our training set to consist of (p, k, c) triples: one for each pronoun, where isthe pronoun to be resolved, is the pronouns context, and is candidate list containing the nouns could potentially be resolved to.
</nextsent>
<nextsent>initially, we take to be the parsed sentence that appears in.
</nextsent>
<nextsent>c consists of all nouns and pronouns that precede p, looking back through the current sentence and the sentence immediately preceding it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3808">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>we use the syntactic constraints from binding theory to eliminate candidates (haegeman, 1994).for the reflex ives himself, herself, itself and themselves, this allows immediate syntactic identification of the antecedent.
</prevsent>
<prevsent>these cases become unambigu ous; only the indicated antecedent is included in c.we improve the quality of our training set by removing known noisy cases before passing the set to em.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
for example, we anticipate that sentences with quotation marks will be problematic, as other researchers have observed that quoted text requires special handling for pronoun resolution (kennedy and boguraev, 1996).<papid> C96-1021 </papid></citsent>
<aftsection>
<nextsent>thus we remove pronouns occurring in the same sentences as quotes from the learning process.
</nextsent>
<nextsent>also, we exclude triples where the constraints removed all possible antecedents, or where the pronoun was deemed to be pleonastic.
</nextsent>
<nextsent>performing these exclusions is justified for training, but in testing we state results for all pronouns.
</nextsent>
<nextsent>3.5 em initialization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3809">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>a pru (p|l) model constructed from only unambiguous examples covers far fewer words than learned model, but it rarely makes poor gen der/number choices.
</prevsent>
<prevsent>furthermore, it can be obtained without em.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
training on unambiguous cases is similar in spirit to (hindle and rooth, 1993).<papid> J93-1005 </papid></citsent>
<aftsection>
<nextsent>we found in our development and test sets that, after applying filters, roughly 9% of pronouns occur with unambiguous antecedents.
</nextsent>
<nextsent>when optimizing probability function that is not concave, the em algorithm is only guaranteed to find local maximum; therefore, it can be helpful to start the process near the desired end-point in parameter space.
</nextsent>
<nextsent>the unambiguous pronoun model described above can provide such starting point.when using this initializer, we perform our initial e-step by weighting candidates according to pru (p|l), instead of weighting them uniformly.
</nextsent>
<nextsent>this biases the initial e-step probabilities so that strong indication of the gender/number of candidate from unambiguous cases will either boost the candidates chances or remove it from competition, depending on whether or not the predicted category matches that of the pronoun being resolved.to deal with the sparseness of the pru (p|l) distribution, we use add-1 smoothing (jeffreys, 1961).the resulting effect is that words with few unambiguous occurrences receive near-uniform gender/number distribution, while those observed frequently will closely match the observed distribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3810">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 supervised extension.
</prevsent>
<prevsent>even though we have justified equation 5 with reasonable independence assumptions, our four models may not be combined optimally for our pronoun resolution task, as the models are only approximations of the true distributions they are intended to represent.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
following the approach in (och and ney,2002), <papid> P02-1038 </papid>we can view the right-hand-side of equation 5 as special case of: exp ( 1 log pr(p|l) + 2 log pr(k|l)+ 3 log pr(l) + 4 log pr(j) ) (8)where : = 1.</citsent>
<aftsection>
<nextsent>effectively, the log probabilities of our models become feature functions in log-linear model.
</nextsent>
<nextsent>when labeled training data is available, we can use the maximum entropy principle (berger et al , 1996) <papid> J96-1002 </papid>to optimize the ? weights.this provides us with an optional supervised extension to the unsupervised system.</nextsent>
<nextsent>given small set of data that has the correct candidates indicated,such as the set we used while developing our unsupervised system, we can re-weight the final models provided by em to maximize the probability of observing the indicated candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3811">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>following the approach in (och and ney,2002), <papid> P02-1038 </papid>we can view the right-hand-side of equation 5 as special case of: exp ( 1 log pr(p|l) + 2 log pr(k|l)+ 3 log pr(l) + 4 log pr(j) ) (8)where : = 1.</prevsent>
<prevsent>effectively, the log probabilities of our models become feature functions in log-linear model.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
when labeled training data is available, we can use the maximum entropy principle (berger et al , 1996) <papid> J96-1002 </papid>to optimize the ? weights.this provides us with an optional supervised extension to the unsupervised system.</citsent>
<aftsection>
<nextsent>given small set of data that has the correct candidates indicated,such as the set we used while developing our unsupervised system, we can re-weight the final models provided by em to maximize the probability of observing the indicated candidates.
</nextsent>
<nextsent>to this end, we follow the approach of (och and ney, 2002) <papid> P02-1038 </papid>very closely, including their handling of multiple correctanswers.</nextsent>
<nextsent>we use the limited memory variable metric method as implemented in maloufs maximum entropy package (2002) to set our weights.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3813">
<title id=" W05-0612.xml">an expectation maximization approach to pronoun resolution </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>all of the results reported in section 5 are determined using the test key.
</prevsent>
<prevsent>92 4.2 implementation details.
</prevsent>
</prevsection>
<citsent citstr=" C94-1079 ">
to get the context values and implement the syntactic filters, we parsed our corpora with minipar (lin,1994).<papid> C94-1079 </papid></citsent>
<aftsection>
<nextsent>experiments on the development set indicated that em generally began to overfit after 2 iterations, so we stop em after the second iteration,using the models from the second m-step for testing.
</nextsent>
<nextsent>during testing, ties in likelihood are broken by taking the candidate closest to the pronoun.
</nextsent>
<nextsent>the em-produced models need to be smoothed, as there will be unseen words and unobserved (p, l)or (k, l) pairs in the test set.
</nextsent>
<nextsent>this is because problematic cases are omitted from the training set, while all pronouns are included in the key.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3814">
<title id=" W04-3252.xml">text rank bringing order into texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in short, graph-based ranking algorithm is way of deciding on the importance of vertex within graph, by taking into account global information recursively computed from the entire graph, rather than relying only on local vertex-specific information.
</prevsent>
<prevsent>applying similar line of thinking to lexical or semantic graphs extracted from natural language documents, results in graph-based ranking model that can be applied to variety of natural language processing applications, where knowledge drawn from an entire text is used in making local rank ing/selection decisions.
</prevsent>
</prevsection>
<citsent citstr=" C04-1162 ">
such text-oriented ranking methods can be applied to tasks ranging from automated extraction of key phrases, to extractive summarization and word sense disambiguation (mihalcea et al., 2004).<papid> C04-1162 </papid>in this paper, we introduce the text rank graph based ranking model for graphs extracted from natural language texts.</citsent>
<aftsection>
<nextsent>we investigate and evaluate the application of text rank to two language processing tasks consisting of unsupervised keyword and sentence extraction, and show that the results obtained with text rank are competitive with state-of-the-art systems developed in these areas.
</nextsent>
<nextsent>graph-based ranking algorithms are essentially way of deciding the importance of vertex within graph, based on global information recursively drawn from the entire graph.
</nextsent>
<nextsent>the basic idea implemented by graph-based ranking model is thatof voting?
</nextsent>
<nextsent>or recommendation?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3815">
<title id=" W04-3252.xml">text rank bringing order into texts </title>
<section> the text rank model.  </section>
<citcontext>
<prevsection>
<prevsent>of the vertex within the graph.
</prevsent>
<prevsent>notice that the final values obtained after text rank runs to completion are not affected by the choice of the initial value, only the number of iterations to convergence may be different.
</prevsent>
</prevsection>
<citsent citstr=" P04-3020 ">
it is important to notice that although the textrankapplications described in this paper relyon an algorithm derived from googles page rank (brin and page, 1998), other graph-based ranking algorithms such as e.g. hits (kleinberg, 1999) or positional function (herings et al, 2001) can be easily integrated into the text rank model (mihalcea, 2004).<papid> P04-3020 </papid></citsent>
<aftsection>
<nextsent>2.1 undirected graphs.
</nextsent>
<nextsent>although traditionally applied on directed graphs, recursive graph-based ranking algorithm can be also applied to undirected graphs, in which case the out degree of vertex is equal to the in-degree of the vertex. for loosely connected graphs, with the number of edges proportional with the number of vertices,undirected graphs tend to have more gradual convergence curves.figure 1 plots the convergence curves for randomly generated graph with 250 vertices and 250 edges, for convergence threshold of 0.0001.
</nextsent>
<nextsent>as the connectivity of the graph increases (i.e. larger number of edges), convergence is usually achieved after fewer iterations, and the convergence curves for directed and undirected graphs practically overlap.
</nextsent>
<nextsent>2.2 weighted graphs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3816">
<title id=" W04-3252.xml">text rank bringing order into texts </title>
<section> keyword extraction.  </section>
<citcontext>
<prevsection>
<prevsent>this approach was first suggested in (turney, 1999), where parametrized heuristic rules are combined with genetic algorithm into system for key phrase extraction - genex - that automatically identifies keywords in document.
</prevsent>
<prevsent>a different learning algorithm was used in (frank et al, 1999), where naive bayes learning scheme is applied onthe document collection, with improved results observed on the same dataset as used in (turney, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W03-1028 ">
neither turney nor frank report on the recall oftheir systems, but only on precision: 29.0% precision is achieved with genex (turney, 1999) for fivekeyphrases extracted per document, and 18.3% precision achieved with kea (frank et al, 1999) for fifteen key phrases per document.more recently, (hulth, 2003) <papid> W03-1028 </papid>applies supervised learning system to keyword extraction from abstracts, using combination of lexical and syntactic features, proved to improve significantly over previously published results.</citsent>
<aftsection>
<nextsent>as hulth suggests, keyword extraction from abstracts is more widely applicable than from full texts, since many documents on the internet are not available as full-texts, but only as abstracts.
</nextsent>
<nextsent>in her work, hulth experiments with the approach proposed in (turney, 1999), and new approach that integrates part of speech information into the learning process, and shows that the accuracy of the system is almost doubled by adding linguistic knowledge to the term representation.
</nextsent>
<nextsent>in this section, we report on our experiments in keyword extraction using text rank, and show that the graph-based ranking model outperforms the best published results in this problem.
</nextsent>
<nextsent>similar to (hulth, 2003), <papid> W03-1028 </papid>we are evaluating our algorithm on keyword extraction from abstracts, mainly for the purpose of allowing for direct comparison with the results she reports with her key phrase extraction system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3842">
<title id=" W04-3252.xml">text rank bringing order into texts </title>
<section> sentence extraction.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 evaluation.
</prevsent>
<prevsent>we evaluate the text rank sentence extraction algorithm on single-document summarization task, using 567 news articles provided during the document understanding evaluations 2002 (duc, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
foreach article, text rank generates an 100-words summary ? the task undertaken by other systems participating in this single document summarization task.for evaluation, we are using the rouge evaluation toolkit, which is method based on ngramstatistics, found to be highly correlated with human evaluations (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>two manually produced reference summaries are provided, and used in the evaluation process5 .4weights are listed to the right or above the edge they correspond to.
</nextsent>
<nextsent>similar weights are computed for each edge in the graph, but are not displayed due to space restrictions.
</nextsent>
<nextsent>5rouge is available at http://www.isi.edu/cyl/rouge/.
</nextsent>
<nextsent>fifteen different systems participated in this task, and we compare the performance of text rank with the top five performing systems, as well as with the baseline proposed by the duc evaluators ? consisting of 100-word summary constructed by taking the first sentences in each article.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3843">
<title id=" W05-0824.xml">rali smt shared task system description </title>
<section> the core system.  </section>
<citcontext>
<prevsection>
<prevsent>the translation engine we used is the one suggested within the shared task: pharaoh (koehn, 2004).the input of this decoder is composed of phrase based model (pbm), trigram language model and an optional set of coefficients and thresholds 1what we mean by this is nothing more than we were mostly able to infer the original meaning of the source sentence by reading its automatic translation.
</prevsent>
<prevsent>137 pair wer ser nist bleu fi-en 66.53 99.20 5.3353 18.73 de-en 60.70 98.40 5.8411 21.11 fr-en 53.77 98.20 6.4717 27.69 es-en 53.84 98.60 6.5571 28.08 table 1: baseline performances measured on the 500 top sentences of the dev corpus in terms of wer (word error rate), ser (sentence error rate), nist and bleu scores.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
which control the decoder.for acquiring pbm, we followed the approach described by koehn et al (2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in brief, we relied on bi-directional word alignment of the training corpus to acquire the parameters ofthe model.
</nextsent>
<nextsent>we used the word alignment produced by giza (och and ney, 2000) <papid> P00-1056 </papid>out of an ibm model 2.</nextsent>
<nextsent>we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3845">
<title id=" W05-0824.xml">rali smt shared task system description </title>
<section> the core system.  </section>
<citcontext>
<prevsection>
<prevsent>which control the decoder.for acquiring pbm, we followed the approach described by koehn et al (2003).<papid> N03-1017 </papid></prevsent>
<prevsent>in brief, we relied on bi-directional word alignment of the training corpus to acquire the parameters ofthe model.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we used the word alignment produced by giza (och and ney, 2000) <papid> P00-1056 </papid>out of an ibm model 2.</citsent>
<aftsection>
<nextsent>we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003).<papid> N03-1017 </papid></nextsent>
<nextsent>each parameter in pbm can be scored in several ways.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3848">
<title id=" W05-0824.xml">rali smt shared task system description </title>
<section> the german-english task.  </section>
<citcontext>
<prevsection>
<prevsent>for the second problem, we segmented german words before training the translation models.
</prevsent>
<prevsent>empirical methods for compound splitting applied to 139 system wer ser nist bleu baseline 60.70 98.40 5.8411 21.11 swap 60.73 98.60 5.9643 22.58 split 60.67 98.60 5.7511 21.99 swap+split 60.57 98.40 5.9685 23.10 table 2: performances of the swapping and the compound splitting approaches on the top 500 sentences of the development set.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
german have been studied by koehn and knight(2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>they found that simple splitting strategy based on the frequency of german words was the most efficient method of the ones they tested,when embedded in phrase-based translation engine.
</nextsent>
<nextsent>therefore, we applied such strategy to split german words in our corpora.
</nextsent>
<nextsent>the results of this approach are shown in table 2.note: both the swapping strategy and the compound splitting yielded improvements in terms of bleu score.
</nextsent>
<nextsent>only after the deadline did we find time to train new models with combination of both techniques; the results of which are reported in the last line of table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3849">
<title id=" W05-1621.xml">using a corpus of sentence orderings defined by many experts to evaluate metrics of coherence for text structuring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>research in nlg focused on problems related to ts from very early on, [mckeown, 1985] being classic example.
</prevsent>
<prevsent>nowadays, ts continues to be an extremely fruitful field of diverse active research.
</prevsent>
</prevsection>
<citsent citstr=" P04-1050 ">
in this paper, we assume the so called search-based approach to ts [karamanis et al, 2004]<papid> P04-1050 </papid>which employs metric of coherence to select text structure among various alternatives.</citsent>
<aftsection>
<nextsent>the ts module is hypothe sised to simply order pre selected set of information-bearing items such as sentences [barzilay et al, 2002; lapata, 2003; <papid> P03-1069 </papid>barzilay and lee, 2004] <papid> N04-1015 </papid>or database facts [dimitromanolaki and androutsopoulos, 2003; karamanis et al, 2004]<papid> P04-1050 </papid>.empirical work on the evaluation of ts has become increasingly automatic and corpus-based.</nextsent>
<nextsent>as pointed out by [karamanis, 2003; barzilay and lee, 2004] <papid> N04-1015 </papid>inter alia, using corpora for automatic evaluation is motivated by the fact that employing human informants in extended psycholinguisticexperiments is often simply unfeasible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3851">
<title id=" W05-1621.xml">using a corpus of sentence orderings defined by many experts to evaluate metrics of coherence for text structuring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nowadays, ts continues to be an extremely fruitful field of diverse active research.
</prevsent>
<prevsent>in this paper, we assume the so called search-based approach to ts [karamanis et al, 2004]<papid> P04-1050 </papid>which employs metric of coherence to select text structure among various alternatives.</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
the ts module is hypothe sised to simply order pre selected set of information-bearing items such as sentences [barzilay et al, 2002; lapata, 2003; <papid> P03-1069 </papid>barzilay and lee, 2004] <papid> N04-1015 </papid>or database facts [dimitromanolaki and androutsopoulos, 2003; karamanis et al, 2004]<papid> P04-1050 </papid>.empirical work on the evaluation of ts has become increasingly automatic and corpus-based.</citsent>
<aftsection>
<nextsent>as pointed out by [karamanis, 2003; barzilay and lee, 2004] <papid> N04-1015 </papid>inter alia, using corpora for automatic evaluation is motivated by the fact that employing human informants in extended psycholinguisticexperiments is often simply unfeasible.</nextsent>
<nextsent>by contrast, large scale automatic corpus-based experimentation takes place much more easily.[lapata, 2003] <papid> P03-1069 </papid>was the first to present an experimental setting which employs the distance between two orderings to estimate automatically how close sentence ordering produced 1chapter 9 of [karamanis, 2003] reports the study in more detail.by her probabilistic ts model stands in comparison to order ings provided by several human judges.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3852">
<title id=" W05-1621.xml">using a corpus of sentence orderings defined by many experts to evaluate metrics of coherence for text structuring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nowadays, ts continues to be an extremely fruitful field of diverse active research.
</prevsent>
<prevsent>in this paper, we assume the so called search-based approach to ts [karamanis et al, 2004]<papid> P04-1050 </papid>which employs metric of coherence to select text structure among various alternatives.</prevsent>
</prevsection>
<citsent citstr=" N04-1015 ">
the ts module is hypothe sised to simply order pre selected set of information-bearing items such as sentences [barzilay et al, 2002; lapata, 2003; <papid> P03-1069 </papid>barzilay and lee, 2004] <papid> N04-1015 </papid>or database facts [dimitromanolaki and androutsopoulos, 2003; karamanis et al, 2004]<papid> P04-1050 </papid>.empirical work on the evaluation of ts has become increasingly automatic and corpus-based.</citsent>
<aftsection>
<nextsent>as pointed out by [karamanis, 2003; barzilay and lee, 2004] <papid> N04-1015 </papid>inter alia, using corpora for automatic evaluation is motivated by the fact that employing human informants in extended psycholinguisticexperiments is often simply unfeasible.</nextsent>
<nextsent>by contrast, large scale automatic corpus-based experimentation takes place much more easily.[lapata, 2003] <papid> P03-1069 </papid>was the first to present an experimental setting which employs the distance between two orderings to estimate automatically how close sentence ordering produced 1chapter 9 of [karamanis, 2003] reports the study in more detail.by her probabilistic ts model stands in comparison to order ings provided by several human judges.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3902">
<title id=" W05-1621.xml">using a corpus of sentence orderings defined by many experts to evaluate metrics of coherence for text structuring </title>
<section> metrics of coherence.  </section>
<citcontext>
<prevsection>
<prevsent>[karamanis, 2003] discusses how few basic notions of coherence captured by centering theory (ct) can be used to define large range of metrics which might be useful for tsin our domain of interest.3 the metrics employed in the experiments of [karamanis et al, 2004]<papid> P04-1050 </papid> include: m.nocb which penalises nocbs, i.e. pairs of adjacent facts without any arguments in common [karamanis and manurung, 2002].</prevsent>
<prevsent>because of its simplicity m.nocbserves as the first baseline in the experiments of [kara manis et al, 2004].<papid> P04-1050 </papid></prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
pf.nocb, second baseline, which enhances m.nocb with global constraint on coherence that [karamanis, 2003] calls the page focus (pf).pf.bfp which is based on pf as well as the original formulation of ct in [brennan et al, 1987].<papid> P87-1022 </papid>pf.kp which makes use of pf as well as the recent reformulation of ct in [kibble and power, 2000].[karamanis et al, 2004]<papid> P04-1050 </papid> report that pf.nocb outperformed m.nocb but was overtaken by pf.bfp and pf.kp.</citsent>
<aftsection>
<nextsent>the two metrics beating pf.nocb were not found to differ significantly from each other.
</nextsent>
<nextsent>this study employs pf.bfp and pf.kp, i.e. two of the best performing metrics of the experiments in [karamanis et al, 2004]<papid> P04-1050 </papid>, as well as m.nocb and pf.nocb, the two previously used baselines.</nextsent>
<nextsent>an additional random baseline is also defined following [lapata, 2003].<papid> P03-1069 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3936">
<title id=" W04-3240.xml">learning to classify email into speech acts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a limitation of their approach is that these hand-coded linguistic clues?
</prevsent>
<prevsent>are language-specific (and in fact limited to japanese text.)
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
prior research on machine learning for text classification has primarily considered classification of documents by topic (lewis, 1992; yang, 1999), but also has addressed sentiment detection (pang et al, 2002; <papid> W02-1011 </papid>weibe et al, 2001) and authorship attribution (e.g., argamon et al 2003).</citsent>
<aftsection>
<nextsent>there has been some previous use of machine learning to classify email messages (cohen 1996; sahami et al, 1998; rennie, 2000; segal &amp; kephart, 2000).
</nextsent>
<nextsent>however, to our knowledge, none of these systems has investigated learning methods for assigning email speech acts.
</nextsent>
<nextsent>instead, email is generally classified into folders (i.e., according to topic) or according to whether or not it is spam?.
</nextsent>
<nextsent>learning systems have been previously used to automatically detect acts in conversational speech (e.g. finke et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3937">
<title id=" W04-3240.xml">learning to classify email into speech acts </title>
<section> categorization results.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 inter-annotator agreement.
</prevsent>
<prevsent>each message may be annotated with several labels, as it may contain several speech acts.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
to evaluate inter-annotator agreement, we double labeled n03f2 for the verbs deliver, commit, request, amend, and propose, and the noun, meeting, and computed the kappa statistic (car letta, 1996) <papid> J96-2004 </papid>for each of these, defined as ra ? ?</citsent>
<aftsection>
<nextsent>= 1 ? where is the empirical probability of agreement on category, and is the probability of agreement for two annotators that label documents at random (with the empirically observed frequency of each label).
</nextsent>
<nextsent>hence kappa ranges from -1 to +1.
</nextsent>
<nextsent>the results in table 1 show that agreement is good, but not perfect.
</nextsent>
<nextsent>email act kappa meeting 0.82 deliver 0.75 commit 0.72 request 0.81 amend 0.83 propose 0.72 table 1 - inter-annotator agreement on n03f2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3939">
<title id=" W05-0625.xml">generalized inference with multiple semantic role labeling systems </title>
<section> srl system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>1.1 pruning.
</prevsent>
<prevsent>only the constituents in the parse tree are consider edas argument candidates.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
in addition, our system exploits the heuristic introduced by (xue and palmer, 2004) <papid> W04-3212 </papid>to filter out very unlikely constituents.</citsent>
<aftsection>
<nextsent>the heuristic is recursive process starting from the verb whose arguments are to be identified.
</nextsent>
<nextsent>it first returns the siblings of the verb; then it moves to the parent of the verb, and collects the siblings again.
</nextsent>
<nextsent>the process goes on until it reaches the root.
</nextsent>
<nextsent>in addition, if constituent is pp (propositional phrase), its children are also collected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3941">
<title id=" W05-0625.xml">generalized inference with multiple semantic role labeling systems </title>
<section> srl system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>or each verb takes at most one argument of each type.?
</prevsent>
<prevsent>this knowledge isused to resolve any inconsistencies of argument classification in order to generate final legitimate predictions.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
we use the inference process introduced by (punyakanok et al, 2004).<papid> C04-1197 </papid></citsent>
<aftsection>
<nextsent>the process is formulated as an integer linear programming (ilp) problem that takes as inputs the confidences over each type of the arguments supplied by the argument classifier.
</nextsent>
<nextsent>the output is the optimal solution that maximizes the linear sum of the confidence scores (e.g.,the conditional probabilities estimated by the argument classifier), subject to the constraints that encode the domain knowledge.formally speaking, the argument classifier attempts to assign labels to set of arguments, s1:m , indexed from 1 to . each argument si can take any label from set of argument labels, , and the indexed set of arguments can take set of labels,c1:m ? pm . if we assume that the argument classifier returns an estimated conditional probability distribution, prob(si = ci), then, given sentence, the inference procedure seeks an global assignment that maximizes the following objective function, c1:m = argmax c1:mpm ? i=1 prob(si = ci), subject to linguistic and structural constraints.
</nextsent>
<nextsent>inother words, this objective function reflects the expected number of correct argument predictions, subject to the constraints.
</nextsent>
<nextsent>the constraints are encoded as the followings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3942">
<title id=" W05-0625.xml">generalized inference with multiple semantic role labeling systems </title>
<section> learning and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>identification, and argument classification.
</prevsent>
<prevsent>then ajoint inference stage is used to resolve the inconsistency of the output of argument classification in these systems.
</prevsent>
</prevsection>
<citsent citstr=" C02-1151 ">
the learning algorithm used is variation of the winnow update rule incorporated in snow (roth,1998; roth and yih, 2002), <papid> C02-1151 </papid>multi-class classifier that is tailored for large scale learning tasks.</citsent>
<aftsection>
<nextsent>snow learns sparse network of linear functions, in which the targets (argument border prediction sor argument type predictions, in this case) are represented as linear functions over common feature space.
</nextsent>
<nextsent>it improves the basic winnow multiplicative update rule with regularization term, which has the effect of trying to separate the data with large margin separator (grove and roth, 2001; hang et al, 2002) and voted (averaged) weight vector (freund and schapire, 1999).softmax function (bishop, 1995) is used to convert raw activation to conditional probabilities.
</nextsent>
<nextsent>if there are classes and the raw activation of class is acti, the posterior estimation for class is prob(i) = acti ? 1jn eactj . in summary, training used both full and partial syntactic information as described in section 1.
</nextsent>
<nextsent>in training, snows default parameters were used with the exception of the separator thickness 1.5, the use of average weight vector, and 5 training cycles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3943">
<title id=" W05-0408.xml">automatic identification of sentiment vocabulary exploiting low association with known sentiment terms </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P02-1053 ">
we describe an extension to the technique for the automatic identification and labeling of sentiment terms described in tur ney (2002) <papid> P02-1053 </papid>and turney and littman (2002).</citsent>
<aftsection>
<nextsent>their basic assumption is that sentiment terms of similar orientation tend to co-occur at the document level.
</nextsent>
<nextsent>we add second assumption, namely that sentiment terms of opposite orientation tend not to co-occur at the sentence level.
</nextsent>
<nextsent>this additional assumption allows us to identify sentiment-bearing terms very reliably.
</nextsent>
<nextsent>we then use these newly identified terms in various scenarios for the sentiment classification of sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3945">
<title id=" W05-0408.xml">automatic identification of sentiment vocabulary exploiting low association with known sentiment terms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combining our approach with naive bayes bootstrapping method yields further small improvement of classifier performance.
</prevsent>
<prevsent>we finally compare our results to precision and recall figures that can be obtained on the same dataset with labeled data.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
the field of sentiment classification has received considerable attention from researchers in recent years (pang and lee 2002, pang et al  2004, tur ney 2002, <papid> P02-1053 </papid>turney and littman 2002, wiebe et al  2001, bai et al  2004, yu and hatzivassiloglou 2003 <papid> W03-1017 </papid>and many others).</citsent>
<aftsection>
<nextsent>the identification and classification of sentiment constitutes problem that is orthogonal to the usual task of text classification.
</nextsent>
<nextsent>whereas in traditional text classification the focus is on topic identification, in sentiment classification the focus is on the assessment of the writers sentiment toward the topic.
</nextsent>
<nextsent>movie and product reviews have been the main focus of many of the recent studies in this area (pang and lee 2002, pang et al  2004, turney 2002, <papid> P02-1053 </papid>turney and littman 2002).</nextsent>
<nextsent>typically, these reviews are classified at the document level, and the class labels are positive?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3973">
<title id=" W05-0408.xml">automatic identification of sentiment vocabulary exploiting low association with known sentiment terms </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>recall 500 .4878 .4967 1000 .5161 .5105 2000 .5297 .5256 2500 .5017 .5083 table 6: average precision and recall for svms for small numbers of labeled examples 4.5.
</prevsent>
<prevsent>results on the movie domain.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
we also performed small set of experiments on the movie domain using pang and lees 2004 <papid> P04-1035 </papid>data set.</citsent>
<aftsection>
<nextsent>this set consists of 2000 reviews, 1000 each of very positive and very negative reviews.
</nextsent>
<nextsent>since this dataset is balanced and the task is only two-way classification between positive and negative reviews, we only report accuracy numbers here.
</nextsent>
<nextsent>accuracy training data turney (2002) <papid> P02-1053 </papid>66% unsupervised pang &amp; lee (2004) <papid> P04-1035 </papid>87.15% supervised aue &amp; ga mon (2005) 91.4% supervised so 73.95% unsupervised sm+so to increase seed words, then so 74.85% weakly supervised table 7: classification accuracy on the movie review domain turney (2002) <papid> P02-1053 </papid>achieves 66% accuracy on the movie review domain using the pmi-ir algorithm to gather association scores from the web.</nextsent>
<nextsent>pang and lee (2004) <papid> P04-1035 </papid>report 87.15% accuracy using unigram-based svm classifier combined with subjectivity detection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3988">
<title id=" W05-0408.xml">automatic identification of sentiment vocabulary exploiting low association with known sentiment terms </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 note on statistical significance we used the mcnemar test to assess whether two classifiers are performing significantly differently.
</prevsent>
<prevsent>this test establishes whether the accuracy of two classifiers differs significantly - it does not guarantee significance for precision and recall differences.
</prevsent>
</prevsection>
<citsent citstr=" M95-1004 ">
for the latter, other tests have been proposed (e.g. chinchor 1995), <papid> M95-1004 </papid>but time constraints prohibited us from implementing any of those more computationally costly tests.</citsent>
<aftsection>
<nextsent>for the results presented in the previous sections the mcnemar test established statistical significance at the 0.99 level over baseline (i.e. the so results in table 1) for the multiple iterations results (table 4) and the bootstrapping approach (table 5), but not for the sm+so approach (table 2).
</nextsent>
<nextsent>5.2 future work.
</nextsent>
<nextsent>this exploratory set of experiments indicates number of interesting directions for future work.
</nextsent>
<nextsent>a shortcoming of the present work is the manual tuning of cutoff parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3989">
<title id=" W05-0638.xml">exploiting full parsing information to label semantic roles using an ensemble of me and svm via integer linear programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their experimental results show that using other constituents?
</prevsent>
<prevsent>information increases the f-score by 6%.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
punyakanok et al (2004) <papid> C04-1197 </papid>represent full parsing information as constraints in integer linear programs.</citsent>
<aftsection>
<nextsent>their experimental results show that using such information increases the argument classification accuracy by 1%.
</nextsent>
<nextsent>in this paper, we not only add more full parsing features to argument classification models, but also represent full parsing information as constraints in integer linear programs (ilp) to resolve label inconsistencies.
</nextsent>
<nextsent>we also build an ensemble of two argument classification models: maximum entropy and svm by combining their argument classification results and applying them to the abovementioned ilps.
</nextsent>
<nextsent>our srl system is comprised of four stages: pruning, argument classification, classification model incorporation, and integer linear programming.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3990">
<title id=" W05-0638.xml">exploiting full parsing information to label semantic roles using an ensemble of me and svm via integer linear programming </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 pruning.
</prevsent>
<prevsent>233when the full parsing tree of sentence is available, only the constituents in the tree are considered as argument candidates.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
in conll-2005, full parsing trees are provided by two full parsers: the collins parser (collins, 1999) and the charniak parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>according to punyakanok et al (2005), the boundary agreement of charniak is higher than that of collins; therefore, we choose the charniak parsers results.
</nextsent>
<nextsent>however, there are two million nodes on the full parsing trees in the training corpus, which makes the training time of machine learning algorithms extremely long.
</nextsent>
<nextsent>besides, noisy information from unrelated parts of sentence could also affect the training of machine learning models.
</nextsent>
<nextsent>therefore, our system exploits the heuristic rules introduced by xue and palmer (2004) <papid> W04-3212 </papid>to filter out simple constituents that are unlikely to be arguments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3991">
<title id=" W05-0638.xml">exploiting full parsing information to label semantic roles using an ensemble of me and svm via integer linear programming </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>however, there are two million nodes on the full parsing trees in the training corpus, which makes the training time of machine learning algorithms extremely long.
</prevsent>
<prevsent>besides, noisy information from unrelated parts of sentence could also affect the training of machine learning models.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
therefore, our system exploits the heuristic rules introduced by xue and palmer (2004) <papid> W04-3212 </papid>to filter out simple constituents that are unlikely to be arguments.</citsent>
<aftsection>
<nextsent>applying pruning heuristics to the output of charniaks parser effectively eliminates 61% of the training data and 61.3% of the development data, while still achieves 93% and 85.5% coverage of the correct arguments in the training and development sets, respectively.
</nextsent>
<nextsent>2.2 argument classification.
</nextsent>
<nextsent>this stage assigns the final labels to the candidates derived in section 2.1.
</nextsent>
<nextsent>a multi-class classifier is trained to classify the types of the arguments supplied by the pruning stage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3993">
<title id=" W06-1301.xml">adaptive help for speech dialogue systems based on learning and forgetting of speech commands </title>
<section> summary and future work.  </section>
<citcontext>
<prevsection>
<prevsent>with this information, we developed an algorithm for an adaptive options list.
</prevsent>
<prevsent>it provides help on unfamiliar speech commands.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
future work focuses on usability tests of the prototype system, e.g. using the paradise evaluation framework to evaluate the general usabil 7 ity of the system (walker et al, 1997).<papid> P97-1035 </papid></citsent>
<aftsection>
<nextsent>one main question that arises in the context of an adaptive help system is if the adaption will be judged useful on the one hand and be accepted by the user on the other hand.
</nextsent>
<nextsent>depending on user behaviour the help system could shift its contents very fast, which may cause some irritation.
</nextsent>
<nextsent>the test results will show whether people get irritated and whether the general approach for the options lists appears to be useful.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3994">
<title id=" W06-0129.xml">character language models for chinese word segmentation and named entity recognition </title>
<section> ling pipe.  </section>
<citcontext>
<prevsection>
<prevsent>is zero) and matching character is 100% likely, with any other operation being 0% likely (infinite cost).
</prevsent>
<prevsent>this makes any segmentation equally likely according to the channel model, reducing decoding to finding the highest likelihood hypothesis consisting of the test string with spaces inserted.
</prevsent>
</prevsection>
<citsent citstr=" J00-3004 ">
this approach reduces to the cross-entropy/compression-based approach of (teahan et al 2000).<papid> J00-3004 </papid></citsent>
<aftsection>
<nextsent>experiments showed that skewing these space-insertion/matching probabilities reduces decoding accuracy.
</nextsent>
<nextsent>3.3 ling pipes named entity recognition.
</nextsent>
<nextsent>ling pipe 2.1 introduced hidden markov model interface with several decoders: first-best (viterbi), n-best (viterbi forward, a* backward with exact viterbi estimates), and confidence based (forward-backward).lingpipe 2.2 introduced chunking implementation that codes chunking problem as an hmm tagging problem using refinement of the standard bio coding.
</nextsent>
<nextsent>the refinement both introduces context and greatly simplifies confidence estimation over the approach using standard bio coding in (culotta and mccallum 2004).<papid> N04-4028 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3995">
<title id=" W06-0129.xml">character language models for chinese word segmentation and named entity recognition </title>
<section> ling pipe.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 ling pipes named entity recognition.
</prevsent>
<prevsent>ling pipe 2.1 introduced hidden markov model interface with several decoders: first-best (viterbi), n-best (viterbi forward, a* backward with exact viterbi estimates), and confidence based (forward-backward).lingpipe 2.2 introduced chunking implementation that codes chunking problem as an hmm tagging problem using refinement of the standard bio coding.
</prevsent>
</prevsection>
<citsent citstr=" N04-4028 ">
the refinement both introduces context and greatly simplifies confidence estimation over the approach using standard bio coding in (culotta and mccallum 2004).<papid> N04-4028 </papid></citsent>
<aftsection>
<nextsent>the tags are b-t for the first character in multi-character entity of type t, m-t for middle character in multi-character entity, e-t for the end character ina multi-character entity, and w-t for single character entity.
</nextsent>
<nextsent>the out tags are similarly contextual ized, with additional information on the start/end tags to model their context.
</nextsent>
<nextsent>specifically, the tags used are b-o-t for character not in an entity following an entity of type t, i-o for any middle character not in an entity, and e-o-t for acharacter not in an entity but preceding character in an entity of type t, and finally, w-o-t for character that is single character between two entities, the following entity being of type t. finally, the first tag is conditioned on the begin-ofsentence tag (bos) and after the last tag, the endof-sentence tag (eos) is generated.
</nextsent>
<nextsent>thus the probabilities normalize to model string/tag joint probabilities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3996">
<title id=" W06-0608.xml">the hinoki sense bank  a largescale word sense tagged corpus of japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this makes it difficult to carry out research on the interaction between syntax and semantics.
</prevsent>
<prevsent>projects such as the penn propbank are adding structural semantics (i.e. predicate argument structure) to syntactically annotated corpora, but not lexical semantic information (i.e. word senses).
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
other corpora, such as the english redwoods corpus (oepen et al, 2002), <papid> C02-2025 </papid>combine both syntactic and structural semantics in monostratal representation, but still have no lexical semantics.</citsent>
<aftsection>
<nextsent>in this paper we discuss the (lexical) semantic annotation for the hinoki corpus, which is part of larger project in psycho-linguistic and computational linguistics ultimately aimed at language understanding (bond et al, 2004).<papid> W04-1901 </papid></nextsent>
<nextsent>in this section we describe the overall design of the corpus, and is constituent corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3997">
<title id=" W06-0608.xml">the hinoki sense bank  a largescale word sense tagged corpus of japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>projects such as the penn propbank are adding structural semantics (i.e. predicate argument structure) to syntactically annotated corpora, but not lexical semantic information (i.e. word senses).
</prevsent>
<prevsent>other corpora, such as the english redwoods corpus (oepen et al, 2002), <papid> C02-2025 </papid>combine both syntactic and structural semantics in monostratal representation, but still have no lexical semantics.</prevsent>
</prevsection>
<citsent citstr=" W04-1901 ">
in this paper we discuss the (lexical) semantic annotation for the hinoki corpus, which is part of larger project in psycho-linguistic and computational linguistics ultimately aimed at language understanding (bond et al, 2004).<papid> W04-1901 </papid></citsent>
<aftsection>
<nextsent>in this section we describe the overall design of the corpus, and is constituent corpora.
</nextsent>
<nextsent>the basic aim is to combine structural semantic and lexical semantic markup in single corpus.
</nextsent>
<nextsent>in order to make the first phase self contained, we started with dictionary definition and example sentences.
</nextsent>
<nextsent>we are currently adding other genre, to make the lan gauge description more general, starting with newspaper text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB3998">
<title id=" W06-0608.xml">the hinoki sense bank  a largescale word sense tagged corpus of japanese </title>
<section> 2040 </section>
<citcontext>
<prevsection>
<prevsent>common nouns are classified into about 2,700 semantic classes which are organized into 63 semantic hierarchy.
</prevsent>
<prevsent>2.4 hinoki treebank.
</prevsent>
</prevsection>
<citsent citstr=" P05-1041 ">
lexeed definition and example sentences are syntactically and semantically parsed with hpsg and correct results are manually selected (tanaka et al, 2005).<papid> P05-1041 </papid></citsent>
<aftsection>
<nextsent>the grammatical coverage over all sentences is 86%.
</nextsent>
<nextsent>around 12% of the parsed sentences were rejected by the tree bankers due to an incomplete semantic representation.
</nextsent>
<nextsent>this process had been done independently of word sense annotation.
</nextsent>
<nextsent>2.5 target corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4002">
<title id=" W06-0608.xml">the hinoki sense bank  a largescale word sense tagged corpus of japanese </title>
<section> inter-annotator agreement.  </section>
<citcontext>
<prevsection>
<prevsent>the average numbers of word senses in the newspapers are lower than the ones in the dictionary and, therefore, the token agreement of the newspapers is higher than those of the dictionary sentences.
</prevsent>
<prevsent>%unanimous indicates the ratio of tokens vs types for which all annotators (normally five) choose the same sense.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
snyder and palmer (2004) <papid> W04-0811 </papid>report 62% of all word types on the english all-words task at senseval-3 were labelled unanimously.</citsent>
<aftsection>
<nextsent>it is hard to directly compare with our task since their corpus has only 2,212 words tagged by two or three annotators.
</nextsent>
<nextsent>4.1 familiarity.
</nextsent>
<nextsent>as seen in table 5, the agreement per type does not vary much by familiarity.
</nextsent>
<nextsent>this was an unexpected result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4004">
<title id=" W06-0601.xml">challenges for annotating images for sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>building this dataset exposes important sense phenomena which not only involve natural language but also vision.
</prevsent>
<prevsent>the context of our work is image sense discrimination (isd), where the task is to assign one of several senses to web image retrieved by an ambiguous keyword.
</prevsent>
</prevsection>
<citsent citstr=" P06-2071 ">
a companion paper introduces the task, presents an unsupervised isd model, drawing on web page text and image features, and shows experimental results(loeff et al, 2006).<papid> P06-2071 </papid></citsent>
<aftsection>
<nextsent>the data was subject to single annotator labeling, with verification judgement son part of the dataset as step toward studying agreement.
</nextsent>
<nextsent>besides test bed for isd, the dataset may be applicable to e.g. multimodal word sense disambiguation and cross-language image retrieval.
</nextsent>
<nextsent>the issues discussed concern concepts, and involve insights into semantics, perception, and knowledge representation, while opening up bridge for interdisciplinary work involving vision and nlp.
</nextsent>
<nextsent>the complex relationship between annotation sand images has been explored by the library community, who study management practices for image collections, and by the computervision community, who would like to provide automated image retrieval tools and possibly learn object recognition methods.commercial picture collections are typically annotated by hand, e.g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4005">
<title id=" W06-1106.xml">sentence comparison using robust minimal recur sion semantics and an ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sequence matching on the other hand requires exact word order matching and hence the game began quietly and the game quietly began are not considered match.
</prevsent>
<prevsent>neither method allows for synonym matching.
</prevsent>
</prevsection>
<citsent citstr=" C04-1064 ">
hirao et al (2004) <papid> C04-1064 </papid>showed that they could get much more robust comparison using dependency information rather than bag-of words, since they could abstract away from word order but still compare the important elements of sentence.</citsent>
<aftsection>
<nextsent>using deep parsing information, such as dependencies, but also deep lexical resources where available, enablesa much more informative and robust comparison, which goes beyond lexical similarity.
</nextsent>
<nextsent>we use the rmrs framework as our comparison format because it has the descriptive power to encode the full semantics, including argument structure.
</nextsent>
<nextsent>it also enables easy combination of deep and shallow information and, due to its at structure, is easy to manage computationally.
</nextsent>
<nextsent>1.1 robust minimal recursion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4006">
<title id=" W06-1106.xml">sentence comparison using robust minimal recur sion semantics and an ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it also enables easy combination of deep and shallow information and, due to its at structure, is easy to manage computationally.
</prevsent>
<prevsent>1.1 robust minimal recursion.
</prevsent>
</prevsection>
<citsent citstr=" C04-1185 ">
semantics robust minimal recur sion semantics (rmrs) is form of at semantics which is designed to allow deep and shallow processing to use compatible semantic representation,while being rich enough to support generalized quanti ers (frank, 2004).<papid> C04-1185 </papid></citsent>
<aftsection>
<nextsent>the main component of an rmrs representation is bag of elementary predicates and their arguments.
</nextsent>
<nextsent>an elementary predicate always has unique label, relation type, relation nameand an arg0 feature.
</nextsent>
<nextsent>the example in figure 1 has label of h5 which uniquely identi es this predicate.
</nextsent>
<nextsent>relation types can either be realpred for predicate that relates directly to content word from the input text, or gpred for grammatical predicates which maynot have direct referent in the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4007">
<title id=" W06-1106.xml">sentence comparison using robust minimal recur sion semantics and an ontology </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 parsing.
</prevsent>
<prevsent>japanese language processing tools are freely available.
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
we used the japanese grammar jacy (siegel and bender, 2002), <papid> W02-1210 </papid>deep parsing hpsg grammar that produces rmrss for our primary input source.when parsing with jacy failed, comparisons could still be made with rmrs produced from shallow tools such as chasen (mat sumoto et al, 2000), morphological analyser or cabocha (kudo and matsumoto, 2002), <papid> W02-2016 </papid>japanese dependency parser.</citsent>
<aftsection>
<nextsent>tools have been built to produced rmrs from the standard output of both those tools.the cabocha output supplies similar dependency information to that of the basic elements (be) tool used by hovy et al (2005b) for multi-document summarization.
</nextsent>
<nextsent>even this intermediate level of parsing gives better comparisons than either word or sequence overlap,since it is easier to compare meaningful elements (hovy et al, 2005a).
</nextsent>
<nextsent>3.2 lexical resources.
</nextsent>
<nextsent>whilst deep lexical resources are not available for every language, where they are available, they should be used to make comparisons moreinformative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4008">
<title id=" W06-1106.xml">sentence comparison using robust minimal recur sion semantics and an ontology </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 parsing.
</prevsent>
<prevsent>japanese language processing tools are freely available.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
we used the japanese grammar jacy (siegel and bender, 2002), <papid> W02-1210 </papid>deep parsing hpsg grammar that produces rmrss for our primary input source.when parsing with jacy failed, comparisons could still be made with rmrs produced from shallow tools such as chasen (mat sumoto et al, 2000), morphological analyser or cabocha (kudo and matsumoto, 2002), <papid> W02-2016 </papid>japanese dependency parser.</citsent>
<aftsection>
<nextsent>tools have been built to produced rmrs from the standard output of both those tools.the cabocha output supplies similar dependency information to that of the basic elements (be) tool used by hovy et al (2005b) for multi-document summarization.
</nextsent>
<nextsent>even this intermediate level of parsing gives better comparisons than either word or sequence overlap,since it is easier to compare meaningful elements (hovy et al, 2005a).
</nextsent>
<nextsent>3.2 lexical resources.
</nextsent>
<nextsent>whilst deep lexical resources are not available for every language, where they are available, they should be used to make comparisons moreinformative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4009">
<title id=" W04-3220.xml">verb sense and subcategorization using joint inference to improve performance on complementary tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jurafsky (1998) proposes us ? np pp nppp vpto vping 2:30:00 4 1 0 0 20 33 2:30:01 1 7 0 4 0 0 2:42:04 12 0 3 0 0 1 table 2: the learned joint distribution over the senses and subcategorizations of the verb begin (in percentprobability).
</prevsent>
<prevsent>low probability senses and subcategoriza tions have been omitted.ing probabilistic framework to represent subcategorization preferences, where each lexical item has corresponding distribution over the possible sets of arguments.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
modeling these distributions may beuseful: collins (2003) <papid> J03-4003 </papid>has shown that verb subcategorization information can be used to improve syntactic parsing performance.it has also been recognized that much more accurate prediction of verb subcategorization preference can be made if conditioned on the sense of the verb.</citsent>
<aftsection>
<nextsent>roland and jurafsky (2002) conclude that forgiven lexical token in english, verb sense is the best determiner of scf, far outweighing either genre or dialect.
</nextsent>
<nextsent>demonstrating the utility of this,korhonen and preiss (2003) <papid> P03-1007 </papid>achieve significant improvement at verb subcategorization acquisition task by conditioning on the verb sense as predicted by statistical word sense disambiguation system.conversely, if different senses have distinct subcategorization preferences, it is reasonable to expect that information about the way verb sub categorizes in particular case may be of significant utility in determining the verbs sense.</nextsent>
<nextsent>as an example,yarowsky (2000) makes use of rich syntactic features to improve the performance of supervised wsd system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4010">
<title id=" W04-3220.xml">verb sense and subcategorization using joint inference to improve performance on complementary tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modeling these distributions may beuseful: collins (2003) <papid> J03-4003 </papid>has shown that verb subcategorization information can be used to improve syntactic parsing performance.it has also been recognized that much more accurate prediction of verb subcategorization preference can be made if conditioned on the sense of the verb.</prevsent>
<prevsent>roland and jurafsky (2002) conclude that forgiven lexical token in english, verb sense is the best determiner of scf, far outweighing either genre or dialect.</prevsent>
</prevsection>
<citsent citstr=" P03-1007 ">
demonstrating the utility of this,korhonen and preiss (2003) <papid> P03-1007 </papid>achieve significant improvement at verb subcategorization acquisition task by conditioning on the verb sense as predicted by statistical word sense disambiguation system.conversely, if different senses have distinct subcategorization preferences, it is reasonable to expect that information about the way verb sub categorizes in particular case may be of significant utility in determining the verbs sense.</citsent>
<aftsection>
<nextsent>as an example,yarowsky (2000) makes use of rich syntactic features to improve the performance of supervised wsd system.
</nextsent>
<nextsent>as an illustration of this correlation, table 2 shows learned joint distribution over sense and scf for the common verb begin.1 its common senses, taken from wordnet, are as follows: sense 2:30:00, to initiate an action or activity, (begin working?), sense 2:30:01, to set in motion or cause to start, (to begin war?), and sense 2:42:04, to have beginning, (the day began?).
</nextsent>
<nextsent>the scfs shown here are subset of the complete set of scfs, described in table 3.
</nextsent>
<nextsent>note that the sense and scf variables are highly correlated for this verb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4011">
<title id=" W04-3220.xml">verb sense and subcategorization using joint inference to improve performance on complementary tasks </title>
<section> model structure and inference.  </section>
<citcontext>
<prevsection>
<prevsent>a pcfg is created for each possible scf: each pcfg yields only parse trees in which the distinguished verb sub categorizes in the specified manner (but other verbs can parsefreely).
</prevsent>
<prevsent>given scf-specific pcfg, we can determine the probability of the sentence using the inside algorithm, which sums the probabilities of all possible trees in the grammar producing the sentence.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
to do this, we modified the exact pcfg parser of klein and manning (2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>in the independent scf model, to infer the most likely scf given sentence p(c|s), we just find the that maximizes p(s|c)p(c).
</nextsent>
<nextsent>(for the independent model, the scf prior is estimated using mle from the training ex amples.)
</nextsent>
<nextsent>inference in the joint model over sense and scf is more complex, and is described below.
</nextsent>
<nextsent>learning this model, scf-specific pcfgs, from our scf-annotated training data, requires some care.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4012">
<title id=" W04-3220.xml">verb sense and subcategorization using joint inference to improve performance on complementary tasks </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>one way this could be done would be to use parser only to estimate the probability of the sequence of word tags (i.e., parts of speech) in the sentence, then touse sense-specific lexicon to estimate the probability of finding the words under the tags.
</prevsent>
<prevsent>although we chose wsd and scf determination as test case, the approach of this paper is applicable to other pairs of tasks.
</prevsent>
</prevsection>
<citsent citstr=" W00-1320 ">
it may also be possible to improve parsing accuracy on verb phrases or other phrases, by simultaneously resolving word sense ambiguities, as attempted unsuccessfully by bikel (2000).<papid> W00-1320 </papid></citsent>
<aftsection>
<nextsent>this work is intended to introduce general methodology for combining disjoint nlp tasks that is of use outside of these specific tasks.
</nextsent>
<nextsent>this paper is based on work supported in part by the advanced research and development activity(arda)s advanced question answering for intelligence (aquaint) program, and by the national science foundation under grant no.
</nextsent>
<nextsent>iis-0085896,as part of the knowledge discovery and dissemination program.
</nextsent>
<nextsent>we additionally thank the reviewers for their insightful comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4013">
<title id=" W06-0307.xml">exploitation in affect detection in open ended improvisational text </title>
<section> affect via metaphor.  </section>
<citcontext>
<prevsection>
<prevsent>thus, metaphoricity signals (as in goatly, 1997; wallington et al, 2003) signal the use of metaphor in some cases.
</prevsent>
<prevsent>such 52 signals include phrases such as: so to speak, sort of, almost, picture as.
</prevsent>
</prevsection>
<citsent citstr=" J04-1002 ">
furthermore, semantic restriction violations (wilks, 1978; fass, 1997; mason, 2004), <papid> J04-1002 </papid>as in my car drinks petrol,?</citsent>
<aftsection>
<nextsent>often indicate metaphor, although not all metaphors violate semantic restrictions.
</nextsent>
<nextsent>to determine whether semantic restrictions are being violated, domain information from ontologies/thesauri such as wordnet could be used and/or statistical techniques as used by mason (2004).<papid> J04-1002 </papid></nextsent>
<nextsent>we conducted two-day pilot user test with 39 secondary school students in may 2005, in order to try out and refine testing methodology.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4015">
<title id=" W04-2704.xml">proposition bank ii delving deeper </title>
<section> propbank i.  </section>
<citcontext>
<prevsection>
<prevsent>verbs can take any of set of general, adjunct-like arguments (argms), such as loc (location), tmp (time), dis (discourse connectives), prp (purpose) or dir (direc tion).
</prevsent>
<prevsent>neg ations (neg) and modals (mod) are also marked.
</prevsent>
</prevsection>
<citsent citstr=" W03-1707 ">
the same annotation philosophy has been extended to the penn chinese proposition bank (xue and palmer, 2003).<papid> W03-1707 </papid></citsent>
<aftsection>
<nextsent>the chinese propbank annotation is performed on smaller (250k words) and yet growing corpus annotated with syntactic structures (xue et al 2004).
</nextsent>
<nextsent>the same syntactic alternations that form the basis for the english propbank annotation also exist in robust quantities in chinese, even though it may not be the case that the same exact verbs (meaning verbs that are close translations of one another) have the exact same range of syntactic realization for chinese and english.
</nextsent>
<nextsent>for example, in (1),  xin-nian/new year zhao-dai hui/reception  plays the same role in (a) and (b), which is the event or activity held, even though it occurs in different syntactic positions.
</nextsent>
<nextsent>assigning the same argument label, arg1, to both instances, captures this regularity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4019">
<title id=" W04-2704.xml">proposition bank ii delving deeper </title>
<section> linking to the penn discourse treebank.  </section>
<citcontext>
<prevsection>
<prevsent>and other anaphor elements and definite nps referring to non-nps as antecedents, as in (21).
</prevsent>
<prevsent>this will most likely be done by referring to the eventuality variable associated with the antecedent.
</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
(pdtb) the penn discourse treebank (pdtb) is currently being built by the pdtb team at the university of pennsylvania, providing the next appropriate level of annotation: the annotation of the predicate argument structure of connectives (miltsakaki et al 2004<papid> W04-2703 </papid>a/b).</citsent>
<aftsection>
<nextsent>the pdtb project is based on the idea that discourse connectives can be thought of as predicates with their associated argument structure.
</nextsent>
<nextsent>this perspective of discourse is based on series of papers extending lexicalized tree adjoining grammar (ltag) to discourse (dltag), beginning with webber and joshi (1998).<papid> W98-0315 </papid>2 this level of annotation is quite complex for variety of reasons, such as the lack of available literature describing discourse connectives and frequent occurrences of empty (lexically null) connectives between two sentences that cannot be ignored.</nextsent>
<nextsent>also, unlike the predicates at the sentence level, some of the discourse connectives, especially discourse adverbials, take their arguments ana phorically and not structurally, requiring an intimate association with event variable representation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4022">
<title id=" W04-2704.xml">proposition bank ii delving deeper </title>
<section> linking to the penn discourse treebank.  </section>
<citcontext>
<prevsection>
<prevsent>(pdtb) the penn discourse treebank (pdtb) is currently being built by the pdtb team at the university of pennsylvania, providing the next appropriate level of annotation: the annotation of the predicate argument structure of connectives (miltsakaki et al 2004<papid> W04-2703 </papid>a/b).</prevsent>
<prevsent>the pdtb project is based on the idea that discourse connectives can be thought of as predicates with their associated argument structure.</prevsent>
</prevsection>
<citsent citstr=" W98-0315 ">
this perspective of discourse is based on series of papers extending lexicalized tree adjoining grammar (ltag) to discourse (dltag), beginning with webber and joshi (1998).<papid> W98-0315 </papid>2 this level of annotation is quite complex for variety of reasons, such as the lack of available literature describing discourse connectives and frequent occurrences of empty (lexically null) connectives between two sentences that cannot be ignored.</citsent>
<aftsection>
<nextsent>also, unlike the predicates at the sentence level, some of the discourse connectives, especially discourse adverbials, take their arguments ana phorically and not structurally, requiring an intimate association with event variable representation.
</nextsent>
<nextsent>the long-range goal of the pdtb project is to develop large scale and reliably annotated corpus that will encode coherence relations associated with discourse connectives, including their argument structure and anaphoric links, thus exposing clearly defined level of discourse structure and supporting the extraction of range of inferences associated with discourse connectives.
</nextsent>
<nextsent>this annotation will reference the penn treebank (ptb) annotations as well as propbank.
</nextsent>
<nextsent>in pdtb, variety of connectives are considered, such as subordinate and coordinate conjunctions, adverbial connectives and implicit connectives amounting to total of approximately 20,000 annotations; 10,000 im 2 the pdtb annotations are deliberately kept independ-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4029">
<title id=" W04-2704.xml">proposition bank ii delving deeper </title>
<section> annotation of word senses.  </section>
<citcontext>
<prevsection>
<prevsent>the distinctions made by the frame sets are very coarse, and each one would map to several standard dictionary entries for the lemma in question.
</prevsent>
<prevsent>more fine-grained sense distinctions could be useful for automatic content extraction, yet it remains to be determined exactly which distinctions are necessary and what methodology should be followed to provide additional word sense annotation.
</prevsent>
</prevsection>
<citsent citstr=" W04-2807 ">
palmer et al (2004<papid> W04-2807 </papid>b) present an hierarchical approach to verb senses, where different levels of sense distinctions, from propbank frame sets to wordnet senses, form continuum of granularity.</citsent>
<aftsection>
<nextsent>at the intermediate level of sense hierarchy we are considering manual groupings of the senseval-2 verb senses (palmer, et.al., 2004<papid> W04-2807 </papid>a), developed in separate project.</nextsent>
<nextsent>given large disagreement rate between annotators (average inter-annotator agreement rate for senseval-2 verbs was only 71%), verbs were grouped by two or more people into sets of closely related senses, with grouping differences being reconciled, and the sense groups were used for coarse grained scoring of the systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4032">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> word segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>as first step in our investigation, we built chinese word segmenter capable of performing word segmentation without using pos tag information.
</prevsent>
<prevsent>since errors in word segmentation will propagate to the subsequent pos tagging phase in the one-at-a-time approach, in order for our study to give relevant findings, it is important that the word segmenter we use gives state-of the-art accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W03-1728 ">
the word segmenter we built is similar to the maximum entropy word segmenter of (xue and shen, 2003).<papid> W03-1728 </papid></citsent>
<aftsection>
<nextsent>our word segmenter uses maximum entropy framework and is trained on manually segmented sentences.
</nextsent>
<nextsent>it classifies each chinese character given the features derived from its surrounding context.
</nextsent>
<nextsent>each character can be assigned one of 4 possible boundary tags: b? for character that begins word and is followed by another character, m? for character that occurs in the middle of word, e? for character that ends word, and s? for character that occurs as single-character word.
</nextsent>
<nextsent>2.1 word segmenter features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4037">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> word segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>the average training time taken to train on 90% of the 250k-word ctb was 12 minutes, while testing on 10% of ctb took about 1 minute.
</prevsent>
<prevsent>the running times reported in this paper were all obtained on an intel xeon 2.4ghz computer with 2gb ram.
</prevsent>
</prevsection>
<citsent citstr=" W03-1719 ">
93.5 94.0 94.5 95.0 95.5 96.0 96.5 97.0 1 2 3 4 5 6 7 8 9 10 experiment number o rd e f -m a u re (% )figure 1: ctb 10-fold cv word segmentation measure for our word segmenter as further evaluation, we tested our word segmenter on all the 4 test corpora (ctb, academia sinica (as), hongkong cityu (hk), and peking university (pk)) of the closed track of the 2003 acl-sighan-sponsored first international chinese word segmentation bakeoff (sproat and emerson, 2003).<papid> W03-1719 </papid></citsent>
<aftsection>
<nextsent>for each of the 4 corpora, we trained our word segmenter on only the official released training data of that corpus.
</nextsent>
<nextsent>training was conducted with feature cutoff of 2 and 100 iterations (these parameters were obtained by cross validation on the training set), except for the as corpus where we used cutoff 3 since the as training corpus was too big to train with cutoff 2.
</nextsent>
<nextsent>figure 2 shows our word segment ers measure (based on the official word segmentation scorer of 2003 sighan bakeoff) compared to those reported by all the 2003 sighan participants in the four closed tracks (asc, hkc, pkc, ctbc).
</nextsent>
<nextsent>our word segmenter achieved higher f-measure than the best reported f-measure in the sighan bakeoff on the asc, hkc, and pkc corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4039">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> word segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>for ctbc, due to the 2 based on visual inspection of figure 3 of (luo,.
</prevsent>
<prevsent>2003) exceptionally high out-of-vocabulary (oov) rate of the test data (18.1%), our word segment ers measure ranked in the third position.
</prevsent>
</prevsection>
<citsent citstr=" W03-1730 ">
(note that the top participant of ctbc (zhang et al, 2003) <papid> W03-1730 </papid>used additional named entity knowledge/data in their word segmenter).</citsent>
<aftsection>
<nextsent>82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 0 1 2 3 4 5 6 or se f ea su re (% ) sighan paticipants our word segmenter hkcasc pkc ctbc ctbofigure 2: comparison of word segmentation measure for sighan bakeoff3 tasks we also compared the f-measure of our word segmenter on ctbo, the open category of the ctb corpus, where participants were free to use any available resources and were not restricted to only the official released training data of ctb.
</nextsent>
<nextsent>on this ctbo task, we used as additional training data the as training corpus provided by sighan, after converting the as training corpus to gb encoding.
</nextsent>
<nextsent>we found that with this additional as training data added to the original
</nextsent>
<nextsent>with f-measure 73.2% is not shown in figure 2 due to space constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4040">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> last ranked participant of sighan ctb (closed).  </section>
<citcontext>
<prevsection>
<prevsent>3 one-at-a-time, word-based pos tagger.
</prevsent>
<prevsent>now that we have successfully built state-of the-art chinese word segmenter, we are ready to explore issues of processing architecture and feature representation for chinese pos tagging.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
an english pos tagger based on maximum entropy modeling was built by (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>as first attempt, we investigated whether simply porting the method used by (ratnaparkhi, 1996) <papid> W96-0213 </papid>for english pos tagging would work equally well for chinese.</nextsent>
<nextsent>applying it in the context of chinese pos tagging, ratnaparkhis method assumes that words are pre-segmented, and it assigns pos tags on word-by-word basis, making use of word features in the surrounding context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4048">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one-at-a-time or all-at-once?
</prevsent>
<prevsent>the all-at-once approach, which considers all aspects of available information in an integrated, unified framework, can make better informed decisions, but incurs higher computational cost.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
much previous research on chinese language processing focused on word segmentation (sproat et al, 1996; <papid> J96-3004 </papid>teahan et al, 2000; <papid> J00-3004 </papid>sproat and emerson, 2003).<papid> W03-1719 </papid></citsent>
<aftsection>
<nextsent>relatively less work has been done on chinese pos tagging.
</nextsent>
<nextsent>kwong and tsou (2003) <papid> E03-1081 </papid>discussed the implications of pos ambiguity in chinese and the possible approaches to tackle this problem when tagging corpus for nlp tasks.</nextsent>
<nextsent>zhou and su (2003) <papid> W03-1711 </papid>investigated an approach to build chinese analyzer that integrated word segmentation, pos tagging and parsing, based on hidden markov model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4049">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one-at-a-time or all-at-once?
</prevsent>
<prevsent>the all-at-once approach, which considers all aspects of available information in an integrated, unified framework, can make better informed decisions, but incurs higher computational cost.
</prevsent>
</prevsection>
<citsent citstr=" J00-3004 ">
much previous research on chinese language processing focused on word segmentation (sproat et al, 1996; <papid> J96-3004 </papid>teahan et al, 2000; <papid> J00-3004 </papid>sproat and emerson, 2003).<papid> W03-1719 </papid></citsent>
<aftsection>
<nextsent>relatively less work has been done on chinese pos tagging.
</nextsent>
<nextsent>kwong and tsou (2003) <papid> E03-1081 </papid>discussed the implications of pos ambiguity in chinese and the possible approaches to tackle this problem when tagging corpus for nlp tasks.</nextsent>
<nextsent>zhou and su (2003) <papid> W03-1711 </papid>investigated an approach to build chinese analyzer that integrated word segmentation, pos tagging and parsing, based on hidden markov model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4052">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>much previous research on chinese language processing focused on word segmentation (sproat et al, 1996; <papid> J96-3004 </papid>teahan et al, 2000; <papid> J00-3004 </papid>sproat and emerson, 2003).<papid> W03-1719 </papid></prevsent>
<prevsent>relatively less work has been done on chinese pos tagging.</prevsent>
</prevsection>
<citsent citstr=" E03-1081 ">
kwong and tsou (2003) <papid> E03-1081 </papid>discussed the implications of pos ambiguity in chinese and the possible approaches to tackle this problem when tagging corpus for nlp tasks.</citsent>
<aftsection>
<nextsent>zhou and su (2003) <papid> W03-1711 </papid>investigated an approach to build chinese analyzer that integrated word segmentation, pos tagging and parsing, based on hidden markov model.</nextsent>
<nextsent>jing et al (2003) <papid> W03-1026 </papid>focused on chinese named entity recognition, considering issues like character-based versus word-based approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4053">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>relatively less work has been done on chinese pos tagging.
</prevsent>
<prevsent>kwong and tsou (2003) <papid> E03-1081 </papid>discussed the implications of pos ambiguity in chinese and the possible approaches to tackle this problem when tagging corpus for nlp tasks.</prevsent>
</prevsection>
<citsent citstr=" W03-1711 ">
zhou and su (2003) <papid> W03-1711 </papid>investigated an approach to build chinese analyzer that integrated word segmentation, pos tagging and parsing, based on hidden markov model.</citsent>
<aftsection>
<nextsent>jing et al (2003) <papid> W03-1026 </papid>focused on chinese named entity recognition, considering issues like character-based versus word-based approaches.</nextsent>
<nextsent>to our knowledge, our work is the first to systematically investigate issues of processing architecture and feature representation for chinese pos tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4054">
<title id=" W04-3236.xml">chinese partofspeech tagging oneatatime or allatonce word based or character based </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>kwong and tsou (2003) <papid> E03-1081 </papid>discussed the implications of pos ambiguity in chinese and the possible approaches to tackle this problem when tagging corpus for nlp tasks.</prevsent>
<prevsent>zhou and su (2003) <papid> W03-1711 </papid>investigated an approach to build chinese analyzer that integrated word segmentation, pos tagging and parsing, based on hidden markov model.</prevsent>
</prevsection>
<citsent citstr=" W03-1026 ">
jing et al (2003) <papid> W03-1026 </papid>focused on chinese named entity recognition, considering issues like character-based versus word-based approaches.</citsent>
<aftsection>
<nextsent>to our knowledge, our work is the first to systematically investigate issues of processing architecture and feature representation for chinese pos tagging.
</nextsent>
<nextsent>our maximum entropy word segmenter is similar to that of (xue and shen, 2003), <papid> W03-1728 </papid>but the additional features we used and the postprocessing step gave improved word segmentation accuracy.</nextsent>
<nextsent>the research most similar to ours is (luo, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4057">
<title id=" W06-1205.xml">detecting complex predicates in hindi using pos projection across parallel corpora </title>
<section> cps from parallel projection.  </section>
<citcontext>
<prevsection>
<prevsent>however, this does not actually reflect cp usage, and is better parsed as: (6) [s [np raam ne] [vp [np sitaa ko] [vp kaam karne] [v diyaa] vp] s] another challenge for cp identification is that the constituents may be separated ? sometimes quite widely.
</prevsent>
<prevsent>identifying mwes from corpora is clearly an area of increasing research emphasis.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
for resource-rich languages, one may use parse tree and look for mutual information statistics in head-complement collocations, and also compare it with other  similar  collocations to determine if something is unusual about given construct (lin, 1999).<papid> P99-1041 </papid></citsent>
<aftsection>
<nextsent>as of now however, even pos-tagging remains challenge for languages such as hindi, thereby making it necessary to seek alternate methods.
</nextsent>
<nextsent>parallel corpus based approaches to inducing monolingual part-of-speech taggers, base noun-phrase bracket ers, named-entity taggers and morphological analyzers for french, chinese and other languages have shown quite promising results (yarowsky et al., 2001).
</nextsent>
<nextsent>these approaches use minimal linguistic input and have been increasingly effective with the growth in the availability of large parallel corpuses.
</nextsent>
<nextsent>the algorithm essentially attempts to word-align the target language sentences with the source language sentences and then use probabilistic model try to project the linguistic information from the source language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4058">
<title id=" W06-1205.xml">detecting complex predicates in hindi using pos projection across parallel corpora </title>
<section> hindi-english pos projection.  </section>
<citcontext>
<prevsection>
<prevsent>now (e | h) = (e) * (h | e) / (h) argmax-e p(e | h) = argmax-e p(e) * p(h | e).
</prevsent>
<prevsent>p (e) is modeled by the n-gram model .we are interested in (h | e).
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we used the giza++ toolkit (och and ney, 2000), <papid> P00-1056 </papid>based on the expectation maximization (em) algorithm, to calculate these probability measures.</citsent>
<aftsection>
<nextsent>at the end of this step, we have word-to-word mapping between the english and hindi sentences.
</nextsent>
<nextsent>a  null  is used in the english sentences to account for the unaligned hindi words from the corresponding hindi sentence.
</nextsent>
<nextsent>1 http://bowland-files.lancs.ac.uk/corplang/emille/ 31 figure 1.
</nextsent>
<nextsent>example of projection of pos tags from english to hindi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4059">
<title id=" W06-1205.xml">detecting complex predicates in hindi using pos projection across parallel corpora </title>
<section> hindi-english pos projection.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel projection method may have the potential for discovering discontinuous cps as well.
</prevsent>
<prevsent>constituents.
</prevsent>
</prevsection>
<citsent citstr=" W04-0411 ">
how these structures are to be encoded in computational lexicon is complex matter that takes us beyond cp identification (villavicencio et al 2004).<papid> W04-0411 </papid></citsent>
<aftsection>
<nextsent>but while rule-based identification of such constructs is problematic, we feel that pos-tag projection holds considerable promise in this direction.
</nextsent>
<nextsent>in the algorithm above we have only considered the target language (hindi) tags after the parallel tagging is completed.
</nextsent>
<nextsent>if in addition, we also consider the source language tag and its radiation the cp probabilities may be redefined in manner that helps capture some discontinuous cps as well.
</nextsent>
<nextsent>thus, if english complain?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4060">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>identification of generic semantic categories in text such as mentions of people, organizations, locations, and temporal and numeric expression sis necessary first step in many applications of information extraction, information retrieval, and question answering.
</prevsent>
<prevsent>to large extent, knowledge-poor methods suffice to yield good recognition performance.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
in particular, supervised learning can be used to produce system with performance at or near the state of the art (bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>in the supervised learning framework, corpus of (typically) few hundred documents is annotated by hand to identify the entities of interest.
</nextsent>
<nextsent>features of local context are then used to train system to distinguish instances from non-instances in novel texts.
</nextsent>
<nextsent>such features may include literal word tests,patterns of orthography, parts of speech, semantic categories, or membership in special-purpose gazetteers.
</nextsent>
<nextsent>while supervised training greatly facilitates the development of robust ner system, there quirement of substantial training corpus remains an impediment to the rapid deployment of ner in new domains or new languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4061">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number bush peters reagan noriega ... john robert james david ... president chairman head owner ... japan california london chicago ...
</prevsent>
<prevsent>table 1: sample members of four clusters from the wall street journal corpus.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
of researchers have therefore sought to exploit the availability of unlabeled documents, typically by bootstrapping classifier using automatic la bel lings (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999; <papid> W99-0612 </papid>thelen and riloff, 2002).<papid> W02-1028 </papid>here, we investigate different approach.</citsent>
<aftsection>
<nextsent>using distributional clustering technique called co clustering, we produce clusters which, intuitively,should be useful for ner.
</nextsent>
<nextsent>table 1 shows example terms from several sample clusters induced using collection of documents from the wall street journal (wsj).
</nextsent>
<nextsent>several papers have shown that distributional clustering yields categories that have high agreement with part of speech (schutze, 1995;clark, 2000).<papid> W00-0717 </papid></nextsent>
<nextsent>as the table illustrates, these clusters also tend to have useful semantic dimension.clustering on the wsj portion of the north american news corpus yields two clusters that clearly correspond to personal names, one for first names and one for last names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4062">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number bush peters reagan noriega ... john robert james david ... president chairman head owner ... japan california london chicago ...
</prevsent>
<prevsent>table 1: sample members of four clusters from the wall street journal corpus.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
of researchers have therefore sought to exploit the availability of unlabeled documents, typically by bootstrapping classifier using automatic la bel lings (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999; <papid> W99-0612 </papid>thelen and riloff, 2002).<papid> W02-1028 </papid>here, we investigate different approach.</citsent>
<aftsection>
<nextsent>using distributional clustering technique called co clustering, we produce clusters which, intuitively,should be useful for ner.
</nextsent>
<nextsent>table 1 shows example terms from several sample clusters induced using collection of documents from the wall street journal (wsj).
</nextsent>
<nextsent>several papers have shown that distributional clustering yields categories that have high agreement with part of speech (schutze, 1995;clark, 2000).<papid> W00-0717 </papid></nextsent>
<nextsent>as the table illustrates, these clusters also tend to have useful semantic dimension.clustering on the wsj portion of the north american news corpus yields two clusters that clearly correspond to personal names, one for first names and one for last names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4063">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number bush peters reagan noriega ... john robert james david ... president chairman head owner ... japan california london chicago ...
</prevsent>
<prevsent>table 1: sample members of four clusters from the wall street journal corpus.
</prevsent>
</prevsection>
<citsent citstr=" W02-1028 ">
of researchers have therefore sought to exploit the availability of unlabeled documents, typically by bootstrapping classifier using automatic la bel lings (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999; <papid> W99-0612 </papid>thelen and riloff, 2002).<papid> W02-1028 </papid>here, we investigate different approach.</citsent>
<aftsection>
<nextsent>using distributional clustering technique called co clustering, we produce clusters which, intuitively,should be useful for ner.
</nextsent>
<nextsent>table 1 shows example terms from several sample clusters induced using collection of documents from the wall street journal (wsj).
</nextsent>
<nextsent>several papers have shown that distributional clustering yields categories that have high agreement with part of speech (schutze, 1995;clark, 2000).<papid> W00-0717 </papid></nextsent>
<nextsent>as the table illustrates, these clusters also tend to have useful semantic dimension.clustering on the wsj portion of the north american news corpus yields two clusters that clearly correspond to personal names, one for first names and one for last names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4064">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using distributional clustering technique called co clustering, we produce clusters which, intuitively,should be useful for ner.
</prevsent>
<prevsent>table 1 shows example terms from several sample clusters induced using collection of documents from the wall street journal (wsj).
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
several papers have shown that distributional clustering yields categories that have high agreement with part of speech (schutze, 1995;clark, 2000).<papid> W00-0717 </papid></citsent>
<aftsection>
<nextsent>as the table illustrates, these clusters also tend to have useful semantic dimension.clustering on the wsj portion of the north american news corpus yields two clusters that clearly correspond to personal names, one for first names and one for last names.
</nextsent>
<nextsent>as an experiment, we scanned the muc6 ner dataset for token sequences consisting of zero or more members of the first name cluster (or an initial followed by period), followed by one or more members of the last name cluster.
</nextsent>
<nextsent>this simple procedure identified 64% of personal names with 77% precision.
</nextsent>
<nextsent>in this paper, we attempt to improve on this result by converting the clusters into features tobe exploited by general-purpose machine learning algorithm for information extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4065">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> bwi.  </section>
<citcontext>
<prevsection>
<prevsent>although this is the first application of bwi toner, boosting has previously been shown to work well on this problem.
</prevsent>
<prevsent>differing from bwi in the details of the application, two recent papers nevertheless demonstrate the effectiveness of the boosting cap initial capital allcap all capitals uncap initial lowercase alpha entirely alphabetic characters anum entirely alpha-numeric characters punc punctuation num entirely numeric characters schar single alphabetic character any anything table 2: default wild cards used in these experiments.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
paradigm for ner in several languages (carreraset al, 2002; <papid> W02-2004 </papid>wu et al, 2002), <papid> W02-2035 </papid>one of them achieving the best overall performance in comparison of several systems (sang, 2002).</citsent>
<aftsection>
<nextsent>2.2 boundary detectors.
</nextsent>
<nextsent>the output of single invocation of the weak learner in bwi is always an individual pattern, called boundary detector.
</nextsent>
<nextsent>a detector has two parts, one to match the text leading up to boundary, the other for trailing text.
</nextsent>
<nextsent>each part is list of zero or more elements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4066">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> bwi.  </section>
<citcontext>
<prevsection>
<prevsent>although this is the first application of bwi toner, boosting has previously been shown to work well on this problem.
</prevsent>
<prevsent>differing from bwi in the details of the application, two recent papers nevertheless demonstrate the effectiveness of the boosting cap initial capital allcap all capitals uncap initial lowercase alpha entirely alphabetic characters anum entirely alpha-numeric characters punc punctuation num entirely numeric characters schar single alphabetic character any anything table 2: default wild cards used in these experiments.
</prevsent>
</prevsection>
<citsent citstr=" W02-2035 ">
paradigm for ner in several languages (carreraset al, 2002; <papid> W02-2004 </papid>wu et al, 2002), <papid> W02-2035 </papid>one of them achieving the best overall performance in comparison of several systems (sang, 2002).</citsent>
<aftsection>
<nextsent>2.2 boundary detectors.
</nextsent>
<nextsent>the output of single invocation of the weak learner in bwi is always an individual pattern, called boundary detector.
</nextsent>
<nextsent>a detector has two parts, one to match the text leading up to boundary, the other for trailing text.
</nextsent>
<nextsent>each part is list of zero or more elements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4067">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> co-clustering.  </section>
<citcontext>
<prevsection>
<prevsent>in informal experiments, we found that this procedure tended to increase f1 performance by several points on range of tasks.
</prevsent>
<prevsent>we adopt it uniformly in the experiments reported here.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
as in brown, et al(1992), <papid> J92-4003 </papid>we seek partition ofthe vocabulary that maximizes the mutual information between term categories and their contexts.to achieve this, we use information theoretic co clustering (dhillon et al, 2003), in which space of entities, on the one hand, and their contexts, onthe other, are alternately clustered to maximize mutual information between the two spaces.</citsent>
<aftsection>
<nextsent>3.1 background.
</nextsent>
<nextsent>the input to our algorithm is two finite sets of symbols, say ffflfiffi!
</nextsent>
<nextsent># $ffi&amp;% ( ( ( ) $ffi!*,+.- (e.g., terms) and / fi01 # $02%( ( ( ( ) $03*546- (e.g., term contexts), together with set of co-occurrence count data consisting of non-negative integer 798:;=  for every pair of symbols  ffi@a $0)b)c from  and / . the out put is two partitions:    fiffi   (ddd $ffi  * +fe - and /  gfi0   (ddd $0  * 4he - , where each ffi  ? is subset of  (a cluster?), and each 0  ? subset of / . the co-clustering algorithm chooses the partitions   and / to (locally) maximize the mutual information between them, under constraint limiting the total number of clusters in each partition.
</nextsent>
<nextsent>recall that the entropy or shannon information of discrete distribution is: ikj mlon 8qp  ffi,csrut  ffi5cvd (1) this quantifies average improvement in ones knowledge upon learning the specific value of an event drawn from  . it is large or small depending on whether  has many or few probable values.the mutual information between random variables  and / can be written: wxjzy [n 8(;  ffif $0\csr]t  ffif $0\c  ffi,c  0\c (2) this quantifies the amount that one expects to learn indirectly about  upon learning the value of / , or vice versa.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4072">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, performance of cluster-enhanced bwi at the low end of the horizontal axis compares favorably with the english f1 performance of 0.543 they report using 190 seed words.
</prevsent>
<prevsent>and, arguably, annotating 10-20documents is no more labor intensive than assembling list of 190 seed words.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
strong corroboration for the approach advocated in this paper is provided by miller, et al(2004), <papid> N04-1043 </papid>in which cluster-based features are combined with sequential maximum entropy model proposed in collins (2002) <papid> W02-1001 </papid>to advance the state of the art.</citsent>
<aftsection>
<nextsent>in addition, using active learning, the authors are able to reduce human labeling effort by an order of magni tude.miller, et al use proprietary dataset for training and testing, so it is difficult to make close comparison of outcomes.
</nextsent>
<nextsent>at roughly comparable training set sizes, they appear to achieve score of about 0.89 (f1) with conventional?
</nextsent>
<nextsent>hmm, versus 0.93 using the discriminative learner trained with cluster features (compared with 0.86 reached by bwi).
</nextsent>
<nextsent>both the hmm and collins model are constrained to account for an entire sentence in tagging it, making determinations for all fields simultaneously, in contrast to the individual, local boundary detections made by bwi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4073">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, performance of cluster-enhanced bwi at the low end of the horizontal axis compares favorably with the english f1 performance of 0.543 they report using 190 seed words.
</prevsent>
<prevsent>and, arguably, annotating 10-20documents is no more labor intensive than assembling list of 190 seed words.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
strong corroboration for the approach advocated in this paper is provided by miller, et al(2004), <papid> N04-1043 </papid>in which cluster-based features are combined with sequential maximum entropy model proposed in collins (2002) <papid> W02-1001 </papid>to advance the state of the art.</citsent>
<aftsection>
<nextsent>in addition, using active learning, the authors are able to reduce human labeling effort by an order of magni tude.miller, et al use proprietary dataset for training and testing, so it is difficult to make close comparison of outcomes.
</nextsent>
<nextsent>at roughly comparable training set sizes, they appear to achieve score of about 0.89 (f1) with conventional?
</nextsent>
<nextsent>hmm, versus 0.93 using the discriminative learner trained with cluster features (compared with 0.86 reached by bwi).
</nextsent>
<nextsent>both the hmm and collins model are constrained to account for an entire sentence in tagging it, making determinations for all fields simultaneously, in contrast to the individual, local boundary detections made by bwi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4075">
<title id=" W04-3234.xml">trained named entity recognition using distributional clusters </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>ultimately,it is left to future research to determine how sensitive, if at all, the ner gains are to the details of the clustering.
</prevsent>
<prevsent>there are several ways in which this work might be extended and improved, both in its particular form and in general:   bwi models initial and terminal boundaries, but ignores characteristics of the extracted phrase other than its length.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
we are exploring mechanisms for modeling relevant phrasal structure.  while global statistical approaches, such as sequential averaged perceptrons or crfs (mc callum and li, 2003), <papid> W03-0430 </papid>appear better suited to the ner problem than local symbolic learners, the two approaches search different hypothesisspaces.</citsent>
<aftsection>
<nextsent>based on the surmise that, by combining them, we can realize improvements over either in isolation, we are exploring mechanisms for integration.  the distributional clusters we find are independent of the problem to which we want to apply them and may sometimes be inappropriate or have the wrong granularity.
</nextsent>
<nextsent>we are exploring ways to produce groupings that are sensitive to the task at hand.
</nextsent>
<nextsent>our results clearly establish that an unsupervised distributional analysis of text corpus can produce features that lead to enhanced precision and, especially, recall in information extraction.
</nextsent>
<nextsent>we have successfully used these features in lieu of domain specific, labor-intensive resources, such as syntactic analysis and special-purpose gazetteers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4076">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the area of sentiment analysis has been the subject of much recent research interest driven by two primary motivations.
</prevsent>
<prevsent>first, there is desire to provide applications that can extract, represent, and allow the exploration of opinions in the commercial, government, and political domains.
</prevsent>
</prevsection>
<citsent citstr=" H05-1116 ">
second, effective sentiment analysis might be used to enhance and improve existing nlp applications such as information extraction, question answering, summarization, and clustering (e.g. riloff et al (2005), stoyanov et al (2005)).<papid> H05-1116 </papid></citsent>
<aftsection>
<nextsent>several research efforts (e.g. riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al (2004), wilson et al (2004), yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>wiebe and riloff (2005)) have shown that sentiment information can be extracted at the sentence, clause, or individual opinion expression level (fine-grained opinion information).</nextsent>
<nextsent>however, little has been done to develop methods for combining fine-grained opinion information to form summary representation in which expressions of opinions from thesame source/target1 are grouped together, multiple opinions from source toward the same target are accumulated into an aggregated opinion, and cumulative statistics are computed for each source/target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4077">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, there is desire to provide applications that can extract, represent, and allow the exploration of opinions in the commercial, government, and political domains.
</prevsent>
<prevsent>second, effective sentiment analysis might be used to enhance and improve existing nlp applications such as information extraction, question answering, summarization, and clustering (e.g. riloff et al (2005), stoyanov et al (2005)).<papid> H05-1116 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
several research efforts (e.g. riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al (2004), wilson et al (2004), yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>wiebe and riloff (2005)) have shown that sentiment information can be extracted at the sentence, clause, or individual opinion expression level (fine-grained opinion information).</citsent>
<aftsection>
<nextsent>however, little has been done to develop methods for combining fine-grained opinion information to form summary representation in which expressions of opinions from thesame source/target1 are grouped together, multiple opinions from source toward the same target are accumulated into an aggregated opinion, and cumulative statistics are computed for each source/target.
</nextsent>
<nextsent>a simple opinion summary2 is shown in figure 1.
</nextsent>
<nextsent>being able to create opinion summaries is important both for stand-alone applications of sentiment analysis as well as for the potential uses of sentiment analysis as part of other nlp applications.in this work we address the dearth of approaches for summarizing opinion information.
</nextsent>
<nextsent>in particular, we focus on the problem of source coreference resolution, i.e. deciding which source mentions are associated with opinions that belong to the same real-world entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4080">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, there is desire to provide applications that can extract, represent, and allow the exploration of opinions in the commercial, government, and political domains.
</prevsent>
<prevsent>second, effective sentiment analysis might be used to enhance and improve existing nlp applications such as information extraction, question answering, summarization, and clustering (e.g. riloff et al (2005), stoyanov et al (2005)).<papid> H05-1116 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
several research efforts (e.g. riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al (2004), wilson et al (2004), yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>wiebe and riloff (2005)) have shown that sentiment information can be extracted at the sentence, clause, or individual opinion expression level (fine-grained opinion information).</citsent>
<aftsection>
<nextsent>however, little has been done to develop methods for combining fine-grained opinion information to form summary representation in which expressions of opinions from thesame source/target1 are grouped together, multiple opinions from source toward the same target are accumulated into an aggregated opinion, and cumulative statistics are computed for each source/target.
</nextsent>
<nextsent>a simple opinion summary2 is shown in figure 1.
</nextsent>
<nextsent>being able to create opinion summaries is important both for stand-alone applications of sentiment analysis as well as for the potential uses of sentiment analysis as part of other nlp applications.in this work we address the dearth of approaches for summarizing opinion information.
</nextsent>
<nextsent>in particular, we focus on the problem of source coreference resolution, i.e. deciding which source mentions are associated with opinions that belong to the same real-world entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4085">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we focus on the problem of source coreference resolution, i.e. deciding which source mentions are associated with opinions that belong to the same real-world entity.
</prevsent>
<prevsent>in the example from figure 1 performing source coreference resolution amounts to determining that stanishev, he, and he refer to the same real-world entities.
</prevsent>
</prevsection>
<citsent citstr=" H05-1045 ">
given the associated opinion expressions and their polarity, this source coreference information is the critical knowledge needed to produce the summary of figure 1 (although the two target mentions, bulgaria and our country, would also need to be identified as coreferent).our work is concerned with fine-grained expressions of opinions and assumes that system can relyon the results of effective opinion and source extractors such as those described in riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al (2004), wiebe and riloff (2005) and choi et al (2005).<papid> H05-1045 </papid></citsent>
<aftsection>
<nextsent>presented with sources of opinions, we approach the problem of source coreference resolution as the closely 1we use source to denote an opinion holder and target to denote the entity toward which the opinion is directed.
</nextsent>
<nextsent>2for simplicity, the example summary does not contain any source/target statistics or combination of multiple opinions from the same source to the same target.
</nextsent>
<nextsent>9 ? [target delaying of bulgarias accession to the eu] would be serious mistake?
</nextsent>
<nextsent>[source bulgarian prime minister sergey stanishev] said in an interview for the german daily suddeutsche zeitung.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4086">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the summary graph, + stands for positive opinion and - for negative.related task of noun phrase coreference resolution.
</prevsent>
<prevsent>however, source coreference resolution differs from traditional noun phrase (np) coreference resolution in two important aspects discussed in section 4.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
nevertheless, as first attempt at source coreference resolution, we employ state-of-the art machine learning approach to np coreference resolution developed by ng and cardie (2002).<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>using corpus of manually annotated opinions, we perform an extensive evaluation and obtain strong initial results for the task of source coreference resolution.
</nextsent>
<nextsent>sentiment analysis has been subject of much recent research.
</nextsent>
<nextsent>several efforts have attempted to automatically extract opinions, emotions, and sentiment from text.
</nextsent>
<nextsent>the problem of sentiment extraction at the document level (sentiment clas sifi cation) has been tackled as text categorization task in which the goal is to assign to document either positive (thumbs up?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4088">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of sentiment extraction at the document level (sentiment clas sifi cation) has been tackled as text categorization task in which the goal is to assign to document either positive (thumbs up?)
</prevsent>
<prevsent>or negative (thumbs down?)
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
polarity (e.g. das and chen (2001), pang et al (2002), <papid> W02-1011 </papid>turney (2002), <papid> P02-1053 </papid>dave et al (2003), pang and lee (2004)).<papid> P04-1035 </papid></citsent>
<aftsection>
<nextsent>in contrast, the problem of fine-grained opinion extraction has concentrated on recognizing opinions at the sentence, clause, or individual opinion expression level.
</nextsent>
<nextsent>recent work has shown that systems can be trained to recognize opinions, their polarity, and their strength at reasonable degree of accuracy (e.g. dave et al.
</nextsent>
<nextsent>(2003), riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al.</nextsent>
<nextsent>(2004), pang and lee (2004), <papid> P04-1035 </papid>wilson et al (2004), yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>wiebe and riloff (2005)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4089">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of sentiment extraction at the document level (sentiment clas sifi cation) has been tackled as text categorization task in which the goal is to assign to document either positive (thumbs up?)
</prevsent>
<prevsent>or negative (thumbs down?)
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
polarity (e.g. das and chen (2001), pang et al (2002), <papid> W02-1011 </papid>turney (2002), <papid> P02-1053 </papid>dave et al (2003), pang and lee (2004)).<papid> P04-1035 </papid></citsent>
<aftsection>
<nextsent>in contrast, the problem of fine-grained opinion extraction has concentrated on recognizing opinions at the sentence, clause, or individual opinion expression level.
</nextsent>
<nextsent>recent work has shown that systems can be trained to recognize opinions, their polarity, and their strength at reasonable degree of accuracy (e.g. dave et al.
</nextsent>
<nextsent>(2003), riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al.</nextsent>
<nextsent>(2004), pang and lee (2004), <papid> P04-1035 </papid>wilson et al (2004), yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>wiebe and riloff (2005)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4090">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the problem of sentiment extraction at the document level (sentiment clas sifi cation) has been tackled as text categorization task in which the goal is to assign to document either positive (thumbs up?)
</prevsent>
<prevsent>or negative (thumbs down?)
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
polarity (e.g. das and chen (2001), pang et al (2002), <papid> W02-1011 </papid>turney (2002), <papid> P02-1053 </papid>dave et al (2003), pang and lee (2004)).<papid> P04-1035 </papid></citsent>
<aftsection>
<nextsent>in contrast, the problem of fine-grained opinion extraction has concentrated on recognizing opinions at the sentence, clause, or individual opinion expression level.
</nextsent>
<nextsent>recent work has shown that systems can be trained to recognize opinions, their polarity, and their strength at reasonable degree of accuracy (e.g. dave et al.
</nextsent>
<nextsent>(2003), riloff and wiebe (2003), <papid> W03-1014 </papid>bethard et al.</nextsent>
<nextsent>(2004), pang and lee (2004), <papid> P04-1035 </papid>wilson et al (2004), yu and hatzivassiloglou (2003), <papid> W03-1017 </papid>wiebe and riloff (2005)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4100">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> source coreference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, this proper noun might be critical in establishing coreference of the final source reference he with the other mentions of the source stanishev.
</prevsent>
<prevsent>single match multiple matches no match total 7811 3461 50 exact 6242 1303 0 table 1: statistics for matching sources to noun phrases.mapped (source noun phrases).
</prevsent>
</prevsection>
<citsent citstr=" W06-1640 ">
the latter problem of developing methods that can work with in complete supervisory information is addressed in subsequent effort (stoyanov and cardie, 2006).<papid> W06-1640 </papid>our general approach to source coreference resolution consists of the following steps: 1.</citsent>
<aftsection>
<nextsent>preprocessing: we pre process the corpus by running.
</nextsent>
<nextsent>nlp components such as tokenizer, sentence splitter, pos tagger, parser, and base np finder.
</nextsent>
<nextsent>subsequently, we augment the set of the base nps foundby the base np finder with the help of named entity finder.
</nextsent>
<nextsent>the preprocessing is done following the np coreference work by ng and cardie (2002).<papid> P02-1014 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4104">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> source coreference resolution as.  </section>
<citcontext>
<prevsection>
<prevsent>the source.
</prevsent>
<prevsent>in half of the cases we are dealing with the word who, which typically refers to the last preceding np.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
coreference resolution once we isolate the source nps, we apply coreference resolution using the standard combination of classification and single-link clustering (e.g. soon et al (2001) <papid> J01-4004 </papid>and ng and cardie (2002)).<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>we compute vector of 57 features for every pair of source noun phrases from the preprocessedcorpus.
</nextsent>
<nextsent>we use the training set of pairwise instances to train classifier to predict whether source np pair should be classified as positive (the nps refer to the same entity) or negative (differententities).
</nextsent>
<nextsent>during testing, we use the trained classifier to predict whether source np pair is positive and single-link clustering to group together sources that belong to the same entity.
</nextsent>
<nextsent>for evaluation we randomly split the mpqa corpus into training set consisting of 400 documents 12and test set consisting of the remaining 135 documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4108">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 lists the results of the best performingruns.
</prevsent>
<prevsent>the upper half of the table gives the results for the runs that were trained on 400 documents and the lower half contains the results forthe 200-document training set.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
we evaluated using the two widely used performance measures for coreference resolution ? muc score (vilain et al,1995) <papid> M95-1005 </papid>and b3 (bagga and baldwin, 1998).<papid> P98-1012 </papid></citsent>
<aftsection>
<nextsent>in addition, we used performance metrics (precision,recall and f1) on the identification of the positive class.
</nextsent>
<nextsent>we compute the latter in two different ways ? either by using the pairwise decisions as the classifiers outputs them or by performing the clustering of the source nps and then considering pairwise decision to be positive if the two source nps belong to the same cluster.
</nextsent>
<nextsent>the second option(marked actual in table 2) should be more representative of good clustering, since coreference decisions are important only in the context of the clusters that they create.table 2 shows the performance of the best ripper and svm runs for each of the four evaluation metrics.
</nextsent>
<nextsent>the table also lists the rank for each run among the rest of the runs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4109">
<title id=" W06-0302.xml">toward opinion summarization linking the sources </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 lists the results of the best performingruns.
</prevsent>
<prevsent>the upper half of the table gives the results for the runs that were trained on 400 documents and the lower half contains the results forthe 200-document training set.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
we evaluated using the two widely used performance measures for coreference resolution ? muc score (vilain et al,1995) <papid> M95-1005 </papid>and b3 (bagga and baldwin, 1998).<papid> P98-1012 </papid></citsent>
<aftsection>
<nextsent>in addition, we used performance metrics (precision,recall and f1) on the identification of the positive class.
</nextsent>
<nextsent>we compute the latter in two different ways ? either by using the pairwise decisions as the classifiers outputs them or by performing the clustering of the source nps and then considering pairwise decision to be positive if the two source nps belong to the same cluster.
</nextsent>
<nextsent>the second option(marked actual in table 2) should be more representative of good clustering, since coreference decisions are important only in the context of the clusters that they create.table 2 shows the performance of the best ripper and svm runs for each of the four evaluation metrics.
</nextsent>
<nextsent>the table also lists the rank for each run among the rest of the runs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4112">
<title id=" W05-0607.xml">a bayesian mixture model for term reoccurrence and burst iness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>neither does it consider whether the term occurs many times in close succession or whether it occurs uniformly through out the document.
</prevsent>
<prevsent>it also assumes that additional positional information does not provide any extra leverage to the performance of the nlp and ir applications based on it.
</prevsent>
</prevsection>
<citsent citstr=" P97-1024 ">
this assumption has been shown to be wrong in certain applications (franz, 1997).<papid> P97-1024 </papid></citsent>
<aftsection>
<nextsent>existing models for term distribution are based on the above assumption, so they can merely estimate the terms frequency in document or terms topical behavior for content term.
</nextsent>
<nextsent>the occurrence of content word is classified as topical or non-topical based on whether it occurs once or many times in the document (katz, 1996).
</nextsent>
<nextsent>we are not aware of any existing model that makes less stringent assumptions and models the distribution of occurrences of term.in this paper we describe model for term reoccurrence in text based on the gaps between successive occurrences of the term and the position of its first occurrence in document.
</nextsent>
<nextsent>the gaps are modeled by mixture of exponential distributions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4113">
<title id=" W05-0607.xml">a bayesian mixture model for term reoccurrence and burst iness </title>
<section> existing work.  </section>
<citcontext>
<prevsection>
<prevsent>for = 0, 1, 2, . . .
</prevsent>
<prevsent>estimates based on this model are good for non-content, non-informative terms, but not for the more informative content terms (manning and schutze, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W95-0110 ">
the two-poisson model is suggested as variation of the poisson distribution (bookstein and swanson,1974; church and gale, 1995<papid> W95-0110 </papid>b).</citsent>
<aftsection>
<nextsent>this model assumes that there are two classes of documents associated with term, one class with low average number of occurrences and the other with high average number of occurrences.
</nextsent>
<nextsent>p(k) = e1 1 k!
</nextsent>
<nextsent>+ (1 ? ?)e2 2 k!
</nextsent>
<nextsent>, where ? and (1 ? ?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4116">
<title id=" W05-0607.xml">a bayesian mixture model for term reoccurrence and burst iness </title>
<section> existing work.  </section>
<citcontext>
<prevsection>
<prevsent>the popular bag of words?
</prevsent>
<prevsent>assumption for text states that terms occurrence is uniform and homogeneous throughout.
</prevsent>
</prevsection>
<citsent citstr=" W97-0122 ">
a measure of homogeneity or self-similarity of corpus can be calculated, by dividing the corpus into two frequency lists based on the term frequency and then calculating the 2 statistic between them (kilgarriff, 1997).<papid> W97-0122 </papid></citsent>
<aftsection>
<nextsent>various schemes for dividing the corpus were used (de roeck et al, 2004a) to detect homogeneity of terms at document level, within-document level and by choosing text chunks of various sizes.
</nextsent>
<nextsent>their work revealed that homogeneity increases by nullifying the within document term distribution pattern and homogeneity decreases when chunks of larger sizeare chosen as it incorporates more document structure in it.
</nextsent>
<nextsent>other work based on the same methodology (de roeck et al, 2004b) reveals that even very frequent function words do not distribute ho mogeneously over corpus or document.
</nextsent>
<nextsent>these (de roeck et al, 2004a; de roeck et al, 2004b) provide evidence of the fact that the bag of words?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4120">
<title id=" W05-0607.xml">a bayesian mixture model for term reoccurrence and burst iness </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 data.
</prevsent>
<prevsent>we choose for evaluation, terms from the associated press (ap) newswire articles, as this is standard corpus for language research.
</prevsent>
</prevsection>
<citsent citstr=" C00-1027 ">
we picked terms which had been used previously in the literature (church and gale, 1995<papid> W95-0110 </papid>a; church, 2000; <papid> C00-1027 </papid>manning 52</citsent>
<aftsection>
<nextsent>1 small
</nextsent>
<nextsent>1 large
</nextsent>
<nextsent>? 2small frequently occur ring and common function word topical content word occurring in bursts
</nextsent>
<nextsent>? 2 large comparatively frequent but well spaced function word infrequent and scattered function word table 1: heuristics for inference, based on the parameter estimates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4122">
<title id=" W05-0607.xml">a bayesian mixture model for term reoccurrence and burst iness </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>? 2small frequently occur ring and common function word topical content word occurring in bursts
</prevsent>
<prevsent>? 2 large comparatively frequent but well spaced function word infrequent and scattered function word table 1: heuristics for inference, based on the parameter estimates.
</prevsent>
</prevsection>
<citsent citstr=" W00-1315 ">
and schutze, 1999; umemura and church, 2000) <papid> W00-1315 </papid>with respect to modeling different distribution, so as to present comparative picture.</citsent>
<aftsection>
<nextsent>for building the model we randomly selected 1% of the documents from the corpus, as the software (spiegelhalter et al, 2003) we used is windows pc based and could not handle enormous volume of data with our available hardware resources.
</nextsent>
<nextsent>as stated earlier, our model can handle both frequent function terms and rare content terms.
</nextsent>
<nextsent>we chose terms suitable for demonstrating this.
</nextsent>
<nextsent>we also used some medium frequency terms to demonstrate their characteristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4141">
<title id=" W05-1607.xml">a context dependent algorithm for generating locative expressions in physically situated environments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most gre algorithms deal with the same problem: given domain description and target object generate description of the target object that distinguishes it from the other objects in the do main.
</prevsent>
<prevsent>the term dis tractor objects is used to describe the objects in the context excluding the trajector that at given point in processing fulfil the description of the target object that has been generated.
</prevsent>
</prevsection>
<citsent citstr=" E91-1028 ">
the description generated is said to be distinguishing when the set of dis tractor objects is empty.several gre algorithms have addressed the issue of generating locative expressions [dale and haddock, 1991; <papid> E91-1028 </papid>horacek, 1997; <papid> P97-1027 </papid>gardent, 2002; <papid> P02-1013 </papid>krahmer and theune, 2002; varges, 2004].</citsent>
<aftsection>
<nextsent>however, all these algorithms assume the gre component has access to predefined scene model.
</nextsent>
<nextsent>for an embodied conversational robot functioning in dynamic partially known environments this assumption is seriousdrawback.
</nextsent>
<nextsent>if an agent wishes to generate contextually appropriate reference it cannot assume the availability of domain model, rather it must dynamically construct one.
</nextsent>
<nextsent>however, constructing model containing all the relationships between all the entities in the domain is prone to combinatorial explosion, both in terms of the number of objects in the context (the location of each object in the scene must be checked against all the other objects in the scene) and number of inter object spatial relations (as greater number of spatial relations will require greater number of comparisons between each pair of objects.1 moreover, the context free priori construction of such an exhaustive scene model is cognitively implausible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4142">
<title id=" W05-1607.xml">a context dependent algorithm for generating locative expressions in physically situated environments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most gre algorithms deal with the same problem: given domain description and target object generate description of the target object that distinguishes it from the other objects in the do main.
</prevsent>
<prevsent>the term dis tractor objects is used to describe the objects in the context excluding the trajector that at given point in processing fulfil the description of the target object that has been generated.
</prevsent>
</prevsection>
<citsent citstr=" P97-1027 ">
the description generated is said to be distinguishing when the set of dis tractor objects is empty.several gre algorithms have addressed the issue of generating locative expressions [dale and haddock, 1991; <papid> E91-1028 </papid>horacek, 1997; <papid> P97-1027 </papid>gardent, 2002; <papid> P02-1013 </papid>krahmer and theune, 2002; varges, 2004].</citsent>
<aftsection>
<nextsent>however, all these algorithms assume the gre component has access to predefined scene model.
</nextsent>
<nextsent>for an embodied conversational robot functioning in dynamic partially known environments this assumption is seriousdrawback.
</nextsent>
<nextsent>if an agent wishes to generate contextually appropriate reference it cannot assume the availability of domain model, rather it must dynamically construct one.
</nextsent>
<nextsent>however, constructing model containing all the relationships between all the entities in the domain is prone to combinatorial explosion, both in terms of the number of objects in the context (the location of each object in the scene must be checked against all the other objects in the scene) and number of inter object spatial relations (as greater number of spatial relations will require greater number of comparisons between each pair of objects.1 moreover, the context free priori construction of such an exhaustive scene model is cognitively implausible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4143">
<title id=" W05-1607.xml">a context dependent algorithm for generating locative expressions in physically situated environments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most gre algorithms deal with the same problem: given domain description and target object generate description of the target object that distinguishes it from the other objects in the do main.
</prevsent>
<prevsent>the term dis tractor objects is used to describe the objects in the context excluding the trajector that at given point in processing fulfil the description of the target object that has been generated.
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
the description generated is said to be distinguishing when the set of dis tractor objects is empty.several gre algorithms have addressed the issue of generating locative expressions [dale and haddock, 1991; <papid> E91-1028 </papid>horacek, 1997; <papid> P97-1027 </papid>gardent, 2002; <papid> P02-1013 </papid>krahmer and theune, 2002; varges, 2004].</citsent>
<aftsection>
<nextsent>however, all these algorithms assume the gre component has access to predefined scene model.
</nextsent>
<nextsent>for an embodied conversational robot functioning in dynamic partially known environments this assumption is seriousdrawback.
</nextsent>
<nextsent>if an agent wishes to generate contextually appropriate reference it cannot assume the availability of domain model, rather it must dynamically construct one.
</nextsent>
<nextsent>however, constructing model containing all the relationships between all the entities in the domain is prone to combinatorial explosion, both in terms of the number of objects in the context (the location of each object in the scene must be checked against all the other objects in the scene) and number of inter object spatial relations (as greater number of spatial relations will require greater number of comparisons between each pair of objects.1 moreover, the context free priori construction of such an exhaustive scene model is cognitively implausible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4145">
<title id=" W05-0832.xml">gaming fluency evaluating the bounds and expectations of segment based translation memory </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>tms can add value to computer assisted translation services (drugan, 2004).
</prevsent>
<prevsent>machine translation (mt) developers make use of similar historical archives (parallel texts, bitexts), to produce systems that perform task very similar to tms.
</prevsent>
</prevsection>
<citsent citstr=" P01-1050 ">
but while tm system sand mt systems can appear strikingly similar, (marcu, 2001) <papid> P01-1050 </papid>key differences exist in how they are used.</citsent>
<aftsection>
<nextsent>tms often need to be fast because they are typically used interactively.
</nextsent>
<nextsent>they aim to produce highly readable, fluent output, usable in document production settings.
</nextsent>
<nextsent>in this setting, errors of omission are more easily forgiven than errors of commission so, just like mt, tm out put must look good to users who have no access to the information in source texts.mt, on the other hand, is often used in assimilation settings, where batch job can of ten be run on multiple processors.
</nextsent>
<nextsent>this permits variable rate output and allows slower systems that produce better translations to play part.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4146">
<title id=" W05-0832.xml">gaming fluency evaluating the bounds and expectations of segment based translation memory </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>batch mt serving single user only needs to run at roughly the same rate the reader can consume its output.
</prevsent>
<prevsent>simple tms operate on an entire translation segment, roughly the size of sentence or two, while more sophisticated tms operate on units of varying size: word, phrase, or an entire segment (callison-burch et al , 2004).
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
modern approaches to mt, especially statistical mt, typically operate on more fine-grained units,words and phrases (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>there lationship between whole segment tm and mt can be viewed as continuum of translation granularity: 175 -ff segments simple tm words mthybrid tm simple tm systems, focusing on segment-levelgranularity, lie at one extreme, and word for-word, ibm-model mt systems on theother.
</nextsent>
<nextsent>example-based mt (ebmt), phrase based, and commercial tm systems likely lie somewhere in between.
</nextsent>
<nextsent>this classification motivates our work here.mt systems have well-studied and popular evaluation techniques such as bleu (papineni et al , 2001).
</nextsent>
<nextsent>in this paper we lay out methodology for evaluating tms along the lines of mt evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4147">
<title id=" W05-0832.xml">gaming fluency evaluating the bounds and expectations of segment based translation memory </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the score that their engine associates with each segment is retained and marked as tf-idf in this experiment.
</prevsent>
<prevsent>naturally, bleu (papineni et al , 2001) was the first choice metric, as itwas well-matched to the target language evaluation function.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
rouge was reimplementationof rouge-l from (lin and och, 2004).<papid> C04-1072 </papid></citsent>
<aftsection>
<nextsent>it computes an f-measure from precision and recall that are both based on the longest common sub sequence of the hypothesis and reference strings.
</nextsent>
<nextsent>wer-g is variation on traditional word error rate that was found to correlate very well with human judgments (foster et al , 2003), and per is the traditional position-independent error rate that was also shown to correlate well with human judgments (leusch et al , 2003).
</nextsent>
<nextsent>finally, random metric was added to show the bleu value one could achieve by selecting from the top strictly by chance.
</nextsent>
<nextsent>after the individual metrics are calculated for these segments, uniform-weight log-linear combination of the metrics is calculated and used to produce new rank ordering under the belief that the different metrics will make predictions that are constructive in aggregate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4148">
<title id=" W05-1604.xml">real time stochastic language generation for dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>slow runtime is two-fold problem: the word-forest that is generated is extremely large and often not linguistically constrained, and second, the algorithm has not been efficiently implemented.
</prevsent>
<prevsent>these issues must be addressed before stochastic approaches can besuited for dialogue.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
langk ilde [langkilde, 2000] <papid> A00-2023 </papid>provides an evaluation of coverage of halogen and shows run times around 28 seconds for sentences with average lengths of 22 words.</citsent>
<aftsection>
<nextsent>callaway [call away, 2003] later commented on the runtime that halogen is anywhere from 6.5 to 16 times slower than the symbolic real izer fuf/surge (which may also be too slow for dialogue).
</nextsent>
<nextsent>this paper shows that more work can be done in stochastic generation to reduce the runtime by constraining the grammar and making simple algorithm improvements.
</nextsent>
<nextsent>run times of only fraction of one second are presented.the next section provides brief background on stochastic generation, followed by description of acorn in section 3.
</nextsent>
<nextsent>the description presents several new grammar additions to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4150">
<title id=" W05-1604.xml">real time stochastic language generation for dialogue systems </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the first phase uses hand written grammar that over-generates possible wordorderings into word forest.
</prevsent>
<prevsent>the second phase uses an gram language model to choose the highest probability path through the forest, returning this path as the generated sentence.
</prevsent>
</prevsection>
<citsent citstr=" W04-2302 ">
this approach was first used in dialogue system in [chambers and allen, 2004] <papid> W04-2302 </papid>as an attempt to create domain independent surface realizer.</citsent>
<aftsection>
<nextsent>a human evaluation showed slight decline in naturalness when moved to new domain.
</nextsent>
<nextsent>the stochastic approach was shown in [langkilde, 2000] <papid> A00-2023 </papid>to produce good coverage of the penn treebank, but its runtimewas significantly slow and others have suggested the stochastic approach is not feasible for dialogue.</nextsent>
<nextsent>3.1 input form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4155">
<title id=" W05-1604.xml">real time stochastic language generation for dialogue systems </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>thema jority are grounding/acknowledgements (661 utterances out of 986).
</prevsent>
<prevsent>we only evaluated those of length 3 or more, 325 utterances.string accuracy metric was also applied to provide comparison against studies that may not use the generation metric; however, the generation metric intuitively repairs some of the formers failings, namely double penal ization for word movement.
</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
more on these and other metrics can be found in [bangalore et al, 2000].<papid> W00-1401 </papid></citsent>
<aftsection>
<nextsent>4.3 domain independent evaluation.
</nextsent>
<nextsent>acorn was evaluated using the monroe corpus [stent, 2000], collection of 20 dialogues.
</nextsent>
<nextsent>each dialogue is conversation between two english speakers who were given map of monroe county, ny and description of task that needed to be solved.
</nextsent>
<nextsent>there were eight different disaster scenarios ranging from bomb attack to broken leg, and the participants were to act as emergency dispatchers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4156">
<title id=" W05-1604.xml">real time stochastic language generation for dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>even though 85% from semantic input is good result, modifiers tend to be the one area that falls behind.
</prevsent>
<prevsent>several examples of this can be seen in appendix where some poor generations are shown.
</prevsent>
</prevsection>
<citsent citstr=" C02-1138 ">
stochastic work on the fergus system [chen et al, 2002] <papid> C02-1138 </papid>uses tag grammar to produce word lattice of possible realizations.</citsent>
<aftsection>
<nextsent>the lattice is traversed to find the most likely path.
</nextsent>
<nextsent>the work in [chen et al, 2002] <papid> C02-1138 </papid>generated sentences in 0.28 seconds for an air-travel domain.</nextsent>
<nextsent>this paper differ sin that the input to fergus is shallow syntactic tree, containing all lexemes and function words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4162">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, the translation task can be divided in two parts: define an adequate probability distribution that answers to the question given this english sentence, which is the probability that it is good translation of that spanish sentence??; and use that distribution in order to find the most likely translation of your input sentence.
</prevsent>
<prevsent>work partially supported by ban caixa through the project sistemas inductivos, estadsticos estructurales, para la tra duccion auto matica (siesta)?.this approach is referred to as the statistical approach to machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the usual approach is to define an statistical model and train its parameters from training corpus consisting in pairs of sentences that are known to be translation of each other.different models have been presented in the literature, see for instance (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2004; <papid> J04-4002 </papid>vidal et al, 1993; vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>most of them relyon the concept of alignment: amapping from words or groups of words in sentence into words or groups in the other (in the case of (vidal et al, 1993) the mapping goes from rules in grammar for language into rules of grammar for the other language).
</nextsent>
<nextsent>this concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (dagan et al, 1993).<papid> W93-0301 </papid>a new statistical model is proposed in this paper, which was initially introduced in (vilar torres,1998).</nextsent>
<nextsent>this model is designed so that the alignment between two sentences can be seen in an structured manner: each sentence is divided in two parts and they are put in correspondence; then each of those parts is similarly divided and related to its translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4163">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, the translation task can be divided in two parts: define an adequate probability distribution that answers to the question given this english sentence, which is the probability that it is good translation of that spanish sentence??; and use that distribution in order to find the most likely translation of your input sentence.
</prevsent>
<prevsent>work partially supported by ban caixa through the project sistemas inductivos, estadsticos estructurales, para la tra duccion auto matica (siesta)?.this approach is referred to as the statistical approach to machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
the usual approach is to define an statistical model and train its parameters from training corpus consisting in pairs of sentences that are known to be translation of each other.different models have been presented in the literature, see for instance (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2004; <papid> J04-4002 </papid>vidal et al, 1993; vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>most of them relyon the concept of alignment: amapping from words or groups of words in sentence into words or groups in the other (in the case of (vidal et al, 1993) the mapping goes from rules in grammar for language into rules of grammar for the other language).
</nextsent>
<nextsent>this concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (dagan et al, 1993).<papid> W93-0301 </papid>a new statistical model is proposed in this paper, which was initially introduced in (vilar torres,1998).</nextsent>
<nextsent>this model is designed so that the alignment between two sentences can be seen in an structured manner: each sentence is divided in two parts and they are put in correspondence; then each of those parts is similarly divided and related to its translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4164">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, the translation task can be divided in two parts: define an adequate probability distribution that answers to the question given this english sentence, which is the probability that it is good translation of that spanish sentence??; and use that distribution in order to find the most likely translation of your input sentence.
</prevsent>
<prevsent>work partially supported by ban caixa through the project sistemas inductivos, estadsticos estructurales, para la tra duccion auto matica (siesta)?.this approach is referred to as the statistical approach to machine translation.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the usual approach is to define an statistical model and train its parameters from training corpus consisting in pairs of sentences that are known to be translation of each other.different models have been presented in the literature, see for instance (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2004; <papid> J04-4002 </papid>vidal et al, 1993; vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>most of them relyon the concept of alignment: amapping from words or groups of words in sentence into words or groups in the other (in the case of (vidal et al, 1993) the mapping goes from rules in grammar for language into rules of grammar for the other language).
</nextsent>
<nextsent>this concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (dagan et al, 1993).<papid> W93-0301 </papid>a new statistical model is proposed in this paper, which was initially introduced in (vilar torres,1998).</nextsent>
<nextsent>this model is designed so that the alignment between two sentences can be seen in an structured manner: each sentence is divided in two parts and they are put in correspondence; then each of those parts is similarly divided and related to its translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4165">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the usual approach is to define an statistical model and train its parameters from training corpus consisting in pairs of sentences that are known to be translation of each other.different models have been presented in the literature, see for instance (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2004; <papid> J04-4002 </papid>vidal et al, 1993; vogel et al, 1996).<papid> C96-2141 </papid></prevsent>
<prevsent>most of them relyon the concept of alignment: amapping from words or groups of words in sentence into words or groups in the other (in the case of (vidal et al, 1993) the mapping goes from rules in grammar for language into rules of grammar for the other language).</prevsent>
</prevsection>
<citsent citstr=" W93-0301 ">
this concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (dagan et al, 1993).<papid> W93-0301 </papid>a new statistical model is proposed in this paper, which was initially introduced in (vilar torres,1998).</citsent>
<aftsection>
<nextsent>this model is designed so that the alignment between two sentences can be seen in an structured manner: each sentence is divided in two parts and they are put in correspondence; then each of those parts is similarly divided and related to its translation.
</nextsent>
<nextsent>this way, the alignment can be seen as tree structure which aligns progressively smaller segments of the sentences.
</nextsent>
<nextsent>this recursive procedure gives its name to the model: mar, which comes from modelo de alineamiento recursivo?, which is spanish for recursive alignment model?.the rest of the paper is structured as follows: after comment on previous works, we introduce the notation that we will use throughout the paper, then we briefly explain the model 1 from ibm, next we 199 introduce our model, then we explain the process of parameter estimation, and how to use the model to translate new test sentences.
</nextsent>
<nextsent>finally, we present some experiments and results, together with conclusions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4166">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> previous works.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we present some experiments and results, together with conclusions.
</prevsent>
<prevsent>the initial formulation of the proposed model, including the training procedures, was presentedin (vilar torres, 1998), along with preliminary experiments in small translation task which provided encouraging results.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
this model shares some similarities with the stochastic inversion transduction grammars (sitg) presented by wu in (wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>the main pointin common is the type of possible alignments considered in both models.
</nextsent>
<nextsent>some of the properties of these alignments are studied in (zens and ney, 2003).<papid> P03-1019 </papid></nextsent>
<nextsent>however, the parametrizations of sitgs and the mar are completely different.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4167">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> previous works.  </section>
<citcontext>
<prevsection>
<prevsent>this model shares some similarities with the stochastic inversion transduction grammars (sitg) presented by wu in (wu, 1997).<papid> J97-3002 </papid></prevsent>
<prevsent>the main pointin common is the type of possible alignments considered in both models.</prevsent>
</prevsection>
<citsent citstr=" P03-1019 ">
some of the properties of these alignments are studied in (zens and ney, 2003).<papid> P03-1019 </papid></citsent>
<aftsection>
<nextsent>however, the parametrizations of sitgs and the mar are completely different.
</nextsent>
<nextsent>the generative process of sitgs produces simultaneously the in put and output sentences and the parameters of the model refer to the rules of the nonterminals.
</nextsent>
<nextsent>this provides symmetry to both input and output sentences.
</nextsent>
<nextsent>in contrast, our model clearly distinguishes the input and output sentences and the parameters are based on observable properties of the strings (their lengths and the words composing them).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4169">
<title id=" W05-0835.xml">a recursive statistical translation model </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the original sentence pairs were split ted using the techniques discussed in section 7.3.
</prevsent>
<prevsent>the total number of sentences after the split is presented in table 2.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
two different alignments were used: (a) the one provided in the definition of the task and (b) one obtained using giza++ (och and ney, 2003) <papid> J03-1002 </papid>to train an ibms model 4.</citsent>
<aftsection>
<nextsent>as it can be seen, the number of parts is very similar in both cases.
</nextsent>
<nextsent>the 205 table 2: number of training pairs after splitting to maximum length of ten.
</nextsent>
<nextsent>provided?
</nextsent>
<nextsent>refers to the alignment provided in the task, giza++?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4170">
<title id=" W04-2809.xml">hyper bug a scalable natural language generation approach </title>
<section> scala bility in tactical generation.  </section>
<citcontext>
<prevsection>
<prevsent>the third group, modern?
</prevsent>
<prevsent>generation5 systems ideally avoid the shortcomings of both of the above mentioned classical approaches.
</prevsent>
</prevsection>
<citsent citstr=" W00-0306 ">
we distinguish between three types here: nlg with xslt (wilcock, 2003), which is basically template-based generation from xml input; stochastic approaches like (oh and rudnicky, 2000), <papid> W00-0306 </papid>where the deep generation grammar is replaced by stochastic language model, and hybrid generation approaches like d2s (theune et al, 2000), which bridges the gap between nlg and speech synthesis by prosody module.</citsent>
<aftsection>
<nextsent>4 dale and reiter distinguish between linguistic and struc-.
</nextsent>
<nextsent>ture realization, the former corresponding to the content and the latter to the structural part of tactical generation.
</nextsent>
<nextsent>we find this distinction somewhat artificial, because the content must be already determined for realization, but want to use it anyway to further clarify the task carried out by our system.
</nextsent>
<nextsent>the literature, but we want to spare it for hybridization between shallow and deep generation; see 4.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4171">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we train probabilistic tree transduction model on large automatically parsed chinese-english corpus, and evaluate results against human-annotated word level alignments.
</prevsent>
<prevsent>we find that constituent-based model performs better than similar probability model trained on the same trees converted to dependency representation.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
statistical approaches to machine translation, pioneered by brown et al  (1990), <papid> J90-2002 </papid>estimate parameters for probabilistic model of word-to-word correspondences and word re-orderings directly from large corpora of parallel bilingual text.</citsent>
<aftsection>
<nextsent>in recent years, number of syntactically motivated approaches to statistical machine translation have been proposed.
</nextsent>
<nextsent>these approaches assign parallel tree structure to the two sides of each sentence pair, and model the translation process with reordering operations defined on the tree structure.
</nextsent>
<nextsent>the tree-basedapproach allows us to represent the fact that syntactic constituents tend to move as unit, as well as systematic differences in word order in the grammars of the two languages.
</nextsent>
<nextsent>furthermore, the tree structure allows us to make probabilistic independence assumptions that result in polynomial time algorithms for estimating translation model from parallel training data, and for finding the highest probability translation given new sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4172">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tree-basedapproach allows us to represent the fact that syntactic constituents tend to move as unit, as well as systematic differences in word order in the grammars of the two languages.
</prevsent>
<prevsent>furthermore, the tree structure allows us to make probabilistic independence assumptions that result in polynomial time algorithms for estimating translation model from parallel training data, and for finding the highest probability translation given new sentence.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu (1997) <papid> J97-3002 </papid>modeled the reordering process with binary branching trees, where each production could be either in the same or in reverse order going from source to target language.</citsent>
<aftsection>
<nextsent>the trees of wus inversion transduction grammar were derived by synchronously parsing parallel corpus, using grammar with lexical translation probabilities at the leaves and simple grammar with single nonterminal providing the tree structure.
</nextsent>
<nextsent>while this grammar did not represent traditional syntactic categories such as verb phrases and noun phrases, it served to restrict the word-level alignments considered by the system to those allowable by reordering operations on binary trees.
</nextsent>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters for similar model which represents translation as sequence of re-ordering operations over children of nodes in syntactic tree, using automatic parser output for the initial tree structures.</nextsent>
<nextsent>this gives the translation model more information about the structure of the source language, and further constrains the reorderings to match not just possible bracketing as in wu (1997), <papid> J97-3002 </papid>but the specific bracketing of the parse tree provided.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4173">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the trees of wus inversion transduction grammar were derived by synchronously parsing parallel corpus, using grammar with lexical translation probabilities at the leaves and simple grammar with single nonterminal providing the tree structure.
</prevsent>
<prevsent>while this grammar did not represent traditional syntactic categories such as verb phrases and noun phrases, it served to restrict the word-level alignments considered by the system to those allowable by reordering operations on binary trees.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
yamada and knight (2001) <papid> P01-1067 </papid>present an algorithm for estimating probabilistic parameters for similar model which represents translation as sequence of re-ordering operations over children of nodes in syntactic tree, using automatic parser output for the initial tree structures.</citsent>
<aftsection>
<nextsent>this gives the translation model more information about the structure of the source language, and further constrains the reorderings to match not just possible bracketing as in wu (1997), <papid> J97-3002 </papid>but the specific bracketing of the parse tree provided.</nextsent>
<nextsent>recent models of alignment have attempted to exploit syntactic information from both languages by aligning pair of parse trees for the same sentence in either language node by node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4175">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this gives the translation model more information about the structure of the source language, and further constrains the reorderings to match not just possible bracketing as in wu (1997), <papid> J97-3002 </papid>but the specific bracketing of the parse tree provided.</prevsent>
<prevsent>recent models of alignment have attempted to exploit syntactic information from both languages by aligning pair of parse trees for the same sentence in either language node by node.</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
eisner (2003) <papid> P03-2041 </papid>presented such system for transforming semantic-level dependecy trees into syntactic-level dependency trees for text generation.</citsent>
<aftsection>
<nextsent>gildea (2003) <papid> P03-1011 </papid>trained system on parallel constituent trees from the korean-english treebank, evaluating agreement with hand-annotated word alignments.</nextsent>
<nextsent>ding and palmer (2004) align parallel dependency trees with divide and conquer strategy, choosing highly likely word-pair as splitting point in each tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4176">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent models of alignment have attempted to exploit syntactic information from both languages by aligning pair of parse trees for the same sentence in either language node by node.
</prevsent>
<prevsent>eisner (2003) <papid> P03-2041 </papid>presented such system for transforming semantic-level dependecy trees into syntactic-level dependency trees for text generation.</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
gildea (2003) <papid> P03-1011 </papid>trained system on parallel constituent trees from the korean-english treebank, evaluating agreement with hand-annotated word alignments.</citsent>
<aftsection>
<nextsent>ding and palmer (2004) align parallel dependency trees with divide and conquer strategy, choosing highly likely word-pair as splitting point in each tree.
</nextsent>
<nextsent>in addition to providing deeper level of representation for the transformations of the translation modelto work with, tree-to-tree models have the advantage that they are much less computationally costly to train than models which must induce tree structure on one or both sides of the translation pair.
</nextsent>
<nextsent>because expectation maximization for tree-to-tree models ite rates over pairs of nodes in the two trees, it is o(n2) in the sentence length, rather than o(n6) for wus inversion transduction grammar or o(n4) for the yamada and knight tree-to-string model.in this paper, we make comparison of two tree to-tree models, one trained on the trees produced by automatic parsers for both our english and chinese corpora, and one trained on the same parser output converted to dependency representation.
</nextsent>
<nextsent>the trees are converted using set of deterministic head rules for each language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4181">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> dependency tree-to-tree alignments.  </section>
<citcontext>
<prevsection>
<prevsent>or not, the probability of clone operation can be computed under the same dynamic programming assumptions as the basic tree-to-tree model.
</prevsent>
<prevsent>as with the tree-to-string cloning operation, this independence assumption is essential to keep the complexity polynomial in the size of the input sentences.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
dependencies were found to be more consistent than constituent structure between french and english by fox (2002), <papid> W02-1039 </papid>though this study used tree representation on the english side only.</citsent>
<aftsection>
<nextsent>we wish to investigate whether dependency trees are also more suited to tree-to-tree alignment.figure 1 shows typical xinhua newswire sentence with the chinese parser output, and the sentences english translation with its parse tree.
</nextsent>
<nextsent>the conversion to dependency representation is shown below the original parse trees.
</nextsent>
<nextsent>examination of the trees shows both cases where the dependency representation is more similar across the two languages, as well as its potential pitfalls.
</nextsent>
<nextsent>the initial noun phrase, 14 chinese open border cities?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4182">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> dependency tree-to-tree alignments.  </section>
<citcontext>
<prevsection>
<prevsent>the initial noun phrase, 14 chinese open border cities?
</prevsent>
<prevsent>has two subphrases with level of constituent structure (the qp and the lower np) not found in the english parse.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in this case, the difference in constituent structure derives primarily from differences in the annotation style between the original english and chinese treebanks (marcuset al , 1993; <papid> J93-2004 </papid>xue and xia, 2000; levy and manning, 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>these differences disappear in the constituent representation.
</nextsent>
<nextsent>in general, the number of levels of constituent structure in tree can be relatively arbitrary, while it is easier for people (whether professional syn tacticians or not) to agree on the word-to-word dependencies.
</nextsent>
<nextsent>in some cases, differences in the number of level may be handled by the tree-to-tree model, forex ample by grouping the subject np and its base npchild together as single elementary tree.
</nextsent>
<nextsent>how ever, this introduces unnecessary variability into the alignment process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4183">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> dependency tree-to-tree alignments.  </section>
<citcontext>
<prevsection>
<prevsent>the initial noun phrase, 14 chinese open border cities?
</prevsent>
<prevsent>has two subphrases with level of constituent structure (the qp and the lower np) not found in the english parse.
</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
in this case, the difference in constituent structure derives primarily from differences in the annotation style between the original english and chinese treebanks (marcuset al , 1993; <papid> J93-2004 </papid>xue and xia, 2000; levy and manning, 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>these differences disappear in the constituent representation.
</nextsent>
<nextsent>in general, the number of levels of constituent structure in tree can be relatively arbitrary, while it is easier for people (whether professional syn tacticians or not) to agree on the word-to-word dependencies.
</nextsent>
<nextsent>in some cases, differences in the number of level may be handled by the tree-to-tree model, forex ample by grouping the subject np and its base npchild together as single elementary tree.
</nextsent>
<nextsent>how ever, this introduces unnecessary variability into the alignment process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4184">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we replace words occurring only once with an unknown word token, resulting in chinese vocabulary of 23,783 words and an english vocabulary of 27,075 words.
</prevsent>
<prevsent>chinese data was parsed using the parser of bikel (2002), and english data was parsed using collins (1999).
</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
our hand-aligned test data were those used in hwa et al  (2002), <papid> P02-1050 </papid>and consisted of 48 sentence pairs also with less than 25 words in either language, for total of 788 english words and 580 chinese words.</citsent>
<aftsection>
<nextsent>the hand aligned data consisted of 745 individual aligned word pairs.
</nextsent>
<nextsent>words could be aligned one-to-many in either direction.
</nextsent>
<nextsent>this limits the performance achievable by our models; the ibm models allow one-to-many alignments in one direction only, while the tree-based models allow only one-to-one alignment unless the cloning operation is used.
</nextsent>
<nextsent>a separate set of 49 hand-aligned sentence pairs was used to control over fitting in training our models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4185">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>a separate set of 49 hand-aligned sentence pairs was used to control over fitting in training our models.
</prevsent>
<prevsent>we evaluate our translation models in terms of agreement with human-annotated word-level alignments between the sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
for scoring the viterbi alignments of each system against gold standard annotated alignments, we use the alignment error rate (aer) of och and ney (2000), <papid> P00-1056 </papid>which measures agreement at the level of pairs of words:1 aer = 1 ? 2|a ? g||a| + |g|where is the set of word pairs aligned by the automatic system, and the set al gned in the gold stan dard.</citsent>
<aftsection>
<nextsent>for better understanding of how the models 1while och and ney (2000) <papid> P00-1056 </papid>differentiate between sure and possible hand-annotated alignments, our gold standard alignments come in only one variety.</nextsent>
<nextsent>differ, we break this figure down into precision: = |a ? g||a| and recall: = |a ? g||g|since none of the systems presented in this comparison make use of hand-aligned data, they may differ in the overall proportion of words that are aligned, rather than inserted or deleted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4187">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this affects the precision/recall tradeoff; better results with respect to human alignments may be possible by adjusting an overall insertion probability in order to optimize aer.
</prevsent>
<prevsent>table 2 provides comparison of results using the tree-based models with the word-level ibm models.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
ibm models 1 and 4 refer to brown et al  (1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>we used the giza++ package, including the hmm model of och and ney (2000).<papid> P00-1056 </papid></nextsent>
<nextsent>we trained each model until aer began to increase on our held-out cross validation data, resulting in running model 1 for three iterations, then the hmm model for three iterations, and finally model 4 for two iterations (the optimal number of iterations for models 2 and 3 was zero).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4190">
<title id=" W04-3228.xml">dependencies vs constituents for tree based alignment </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>has no consistently aligned constituent in the chinese sentence.
</prevsent>
<prevsent>we found that of the 2623constituents in our english parse trees (not counting unary consituents, which have the same boundaries as their children), for 1044, or 40%, there exists some constituent in the chinese parse tree that is consistently aligned.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
this confirms the results offox (2002) <papid> W02-1039 </papid>and galley et al  (2004) <papid> N04-1035 </papid>that many translation operations must span more than one parse tree node.</citsent>
<aftsection>
<nextsent>for each of our consistently aligned pairs, we then found the head word of both the chinese and english constituents according to our head rules.
</nextsent>
<nextsent>the two headwords correspond in the annotated alignments 67% of the time (700 out of 1044 consistently aligned constituent pairs).
</nextsent>
<nextsent>while the head swapping operation of our translation model will be able to handle some cases of differing heads, it can only do so if the two heads are adjacent in both tree structures.
</nextsent>
<nextsent>our system is trained and test on automatically generated parse trees, which may contribute to the mismatches in the tree structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4191">
<title id=" W06-0121.xml">chinese word segmentation with maximum entropy and ngram language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>especially, in the closed track on msra, our system ranks 1st.
</prevsent>
<prevsent>chinese word segmentation is one of the core techniques in chinese language processing and attract slots of research interests in recent years.
</prevsent>
</prevsection>
<citsent citstr=" I05-3025 ">
several promising methods are proposed by previous researchers, in which maximum entropy (me) model has turned out to be successful way for this task (hwee tou ng et al, 2004; jin kiatlow et al, 2005).<papid> I05-3025 </papid></citsent>
<aftsection>
<nextsent>by employing maximum entropy (me) model, the chinese word segmentation task is regarded as classification problem, where each character will be classified to one of the four classes, i.e., the beginning, middle, end of multi character word and single-character word.
</nextsent>
<nextsent>however, in high degree, me model pays its emphasis on chinese characters while debases the consideration on the relationship of the context words.
</nextsent>
<nextsent>motivated by this view, several strategies used for reflecting the context words?
</nextsent>
<nextsent>relationship and integrating more linguistics information, are employed in our systems.as known, an n-gram language model could express the relationship of the context words well, it therefore as desirable choice is imported in our system to modify the scoring of the me model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4194">
<title id=" W04-3216.xml">a phrase based hmm approach to document abstract alignment </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we describe model for creating word-to-word and phrase-to-phrase alignments between documents and their human written abstracts.
</prevsent>
<prevsent>such alignments are critical for the development of statistical summarization systems that can be trained on large corpora of document/abstract pairs.
</prevsent>
</prevsection>
<citsent citstr=" J02-4006 ">
our model, whichis based on novel phrase-based hmm, outperforms both the cut &amp; paste alignment model (jing,2002) <papid> J02-4006 </papid>and models developed in the context of machine translation (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>there are wealth of document/abstract pairs that statistical summarization systems could leverage tolearn how to create novel abstracts.
</nextsent>
<nextsent>detailed studies of such pairs (jing, 2002) <papid> J02-4006 </papid>show that human abs tractors perform range of very sophisticated operations when summarizing texts, which include reordering, fusion, and paraphrasing.</nextsent>
<nextsent>unfortunately, existing document/abstract alignment models are not powerful enough to capture these operations.to get around directly tackling this problem, researchers in text summarization have employed one of several techniques.some researchers (banko et al, 2000) <papid> P00-1041 </papid>have developed simple statistical models for aligning documents and headlines.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4195">
<title id=" W04-3216.xml">a phrase based hmm approach to document abstract alignment </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we describe model for creating word-to-word and phrase-to-phrase alignments between documents and their human written abstracts.
</prevsent>
<prevsent>such alignments are critical for the development of statistical summarization systems that can be trained on large corpora of document/abstract pairs.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
our model, whichis based on novel phrase-based hmm, outperforms both the cut &amp; paste alignment model (jing,2002) <papid> J02-4006 </papid>and models developed in the context of machine translation (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>there are wealth of document/abstract pairs that statistical summarization systems could leverage tolearn how to create novel abstracts.
</nextsent>
<nextsent>detailed studies of such pairs (jing, 2002) <papid> J02-4006 </papid>show that human abs tractors perform range of very sophisticated operations when summarizing texts, which include reordering, fusion, and paraphrasing.</nextsent>
<nextsent>unfortunately, existing document/abstract alignment models are not powerful enough to capture these operations.to get around directly tackling this problem, researchers in text summarization have employed one of several techniques.some researchers (banko et al, 2000) <papid> P00-1041 </papid>have developed simple statistical models for aligning documents and headlines.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4197">
<title id=" W04-3216.xml">a phrase based hmm approach to document abstract alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are wealth of document/abstract pairs that statistical summarization systems could leverage tolearn how to create novel abstracts.
</prevsent>
<prevsent>detailed studies of such pairs (jing, 2002) <papid> J02-4006 </papid>show that human abs tractors perform range of very sophisticated operations when summarizing texts, which include reordering, fusion, and paraphrasing.</prevsent>
</prevsection>
<citsent citstr=" P00-1041 ">
unfortunately, existing document/abstract alignment models are not powerful enough to capture these operations.to get around directly tackling this problem, researchers in text summarization have employed one of several techniques.some researchers (banko et al, 2000) <papid> P00-1041 </papid>have developed simple statistical models for aligning documents and headlines.</citsent>
<aftsection>
<nextsent>these models, which implement ibm model 1 (brown et al, 1993), <papid> J93-2003 </papid>treat documents and headlines as simple bags of words and learn probabilistic word-based mappings between the words in the documents and the words in the headlines.</nextsent>
<nextsent>as our results show, these models aretoo weak for capturing the operations that are employed by humans in summarizing texts beyond the headline level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4199">
<title id=" W04-3216.xml">a phrase based hmm approach to document abstract alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some abstract words do not have direct correspondents in the document, and some document words are never used.
</prevsent>
<prevsent>it is thus desirable to be able to automatically construct alignments between documents and their abstracts, so that the correspondences between the pairs are obvious.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
one might be initially tempted to use readily-available machine translation systems like giza++ (och and ney, 2003) <papid> J03-1002 </papid>to perform such connecting point has become the single largest mac retailer after tripling it macintosh sales since january 1989 . connecting point systems tripled it sales of apple macintosh systems since last january . it is now the single largest seller of macintosh . figure 1: example abstract/text alignment.alignments.</citsent>
<aftsection>
<nextsent>however, as we will show, the alignments produced by such system are inadequate for this task.
</nextsent>
<nextsent>the solution that we propose to this problem is an alignment model based on novel mathematical structure we call the phrase-based hmm.
</nextsent>
<nextsent>as observed in figure 1, our model needs to be able to account for phrase-to-phrase alignments.
</nextsent>
<nextsent>it also needs to be able to align abstract phrases with arbitrary parts of the document, and not require monotonic, left-to-right alignment.1 2.1 the generative story.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4204">
<title id=" W04-3237.xml">adaptation of maximum entropy capitalizer little data can help a lot </title>
<section> capitalization as sequence tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the detailed mathematical derivation is presented in appendix a. the experimental results are presented in section 5, followed by conclusions and suggestions for future work.
</prevsent>
<prevsent>automatic capitalization can be seen as sequence tagging problem: each lower-case word receives tag that describes its capitalization form.
</prevsent>
</prevsection>
<citsent citstr=" P03-1020 ">
similar to the work in (lita et al, 2003), <papid> P03-1020 </papid>we tag each word in sentence with one of the tags: ? loc lowercase ? cap capitalized ? mxc mixed case; no further guess is made as to the capitalization of such words.</citsent>
<aftsection>
<nextsent>a possibility is to use the most frequent one encountered in the training data.
</nextsent>
<nextsent>auc all upper case?
</nextsent>
<nextsent>pnc punctuation; we decided to have separate tag for punctuation since it is quite frequent and models well the syntactic context in parsimonious way for training given capitalizer one needs to convert running text into uniform case text accompanied by the above capitalization tags.
</nextsent>
<nextsent>for example, primetime continues on abc .period now ,comma from los angeles ,comma diane sawyer .period becomes primetime_mxc continues_loc on_loc abc_auc .period_pnc now_cap ,comma_pnc from_loc los_cap angeles_cap ,comma_pnc diane_cap sawyer_cap .period_pnc the text is assumed to be already segmented into sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4207">
<title id=" W04-3237.xml">adaptation of maximum entropy capitalizer little data can help a lot </title>
<section> capitalization as sequence tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the same idea is explored in (kim and woodland, 2004) in the larger context of automatic punctuation generation and capitalization from speech recognition output.
</prevsent>
<prevsent>a second approach they consider for capitalization is the use rule-based tagger as described by (brill, 1994), which they show to outperform the case sensitive language modeling approach and be quite robust to speech recognition errors and punctuation generation errors.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
departing from their work, our approach builds on standard technique for sequence tagging,namely memms, which has been successfully applied to part-of-speech tagging (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the memm approach models the tag sequence conditionally on the word sequence , which has few substantial advantages over the 1-gram tagging approach: ? discriminative training of probability modelp (t |w ) using conditional maximum likelihood is well correlated with tagging accuracy?
</nextsent>
<nextsent>ability to use rich set of word-level features in parsimonious way: sub-word features such as prefixes and suffixes, as well as future words3 are easily incorporated in the probability model?
</nextsent>
<nextsent>no concept of out-of-vocabulary?
</nextsent>
<nextsent>word: sub word features are very useful in dealing with words not seen in the training data ? ability to integrate rich contextual features into the mod elmore recently, certain drawbacks of memm models have been addressed by the conditional random field (crf) approach (lafferty et al, 2001) which slightly outperforms memms on standard part of-speech tagging task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4208">
<title id=" W04-3237.xml">adaptation of maximum entropy capitalizer little data can help a lot </title>
<section> capitalization as sequence tagging.  </section>
<citcontext>
<prevsection>
<prevsent>no concept of out-of-vocabulary?
</prevsent>
<prevsent>word: sub word features are very useful in dealing with words not seen in the training data ? ability to integrate rich contextual features into the mod elmore recently, certain drawbacks of memm models have been addressed by the conditional random field (crf) approach (lafferty et al, 2001) which slightly outperforms memms on standard part of-speech tagging task.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
in similar vein, the work3relative to the current word, whose tag is assigned probability value by the memm.of (collins, 2002) <papid> W02-1001 </papid>explores the use of discriminatively trained hmms for sequence labeling problems, fair baseline for such cases that is often overlooked in favor of the inadequate maximum likelihood hmms.the work on adapting the memm model parameters using map smoothing builds on the gaussian prior model used for smoothing maxent models, as presented in (chen and rosenfeld, 2000).</citsent>
<aftsection>
<nextsent>we arenot aware of any previous work on map adaptation of maxent models using prior, be it gaussian or different one, such as the exponential prior of (goodman, 2004).<papid> N04-1039 </papid></nextsent>
<nextsent>although we do not have formal derivation, the adaptation technique should easily extend to the crf scenario.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4209">
<title id=" W04-3237.xml">adaptation of maximum entropy capitalizer little data can help a lot </title>
<section> capitalization as sequence tagging.  </section>
<citcontext>
<prevsection>
<prevsent>word: sub word features are very useful in dealing with words not seen in the training data ? ability to integrate rich contextual features into the mod elmore recently, certain drawbacks of memm models have been addressed by the conditional random field (crf) approach (lafferty et al, 2001) which slightly outperforms memms on standard part of-speech tagging task.
</prevsent>
<prevsent>in similar vein, the work3relative to the current word, whose tag is assigned probability value by the memm.of (collins, 2002) <papid> W02-1001 </papid>explores the use of discriminatively trained hmms for sequence labeling problems, fair baseline for such cases that is often overlooked in favor of the inadequate maximum likelihood hmms.the work on adapting the memm model parameters using map smoothing builds on the gaussian prior model used for smoothing maxent models, as presented in (chen and rosenfeld, 2000).</prevsent>
</prevsection>
<citsent citstr=" N04-1039 ">
we arenot aware of any previous work on map adaptation of maxent models using prior, be it gaussian or different one, such as the exponential prior of (goodman, 2004).<papid> N04-1039 </papid></citsent>
<aftsection>
<nextsent>although we do not have formal derivation, the adaptation technique should easily extend to the crf scenario.
</nextsent>
<nextsent>a final remark contrasts rule-based approaches to sequence tagging such as (brill, 1994) with the probabilistic approach taken in (ratnaparkhi,1996): <papid> W96-0213 </papid>having weight on each feature in the max ent model and sound probabilistic model allows for principled way of adapting the model to new domain; performing such adaptation in rule-based model is unclear, if at all possible.</nextsent>
<nextsent>a simple approach to sequence labeling is the maximum entropy markov model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4212">
<title id=" W04-3237.xml">adaptation of maximum entropy capitalizer little data can help a lot </title>
<section> memm for sequence labeling.  </section>
<citcontext>
<prevsection>
<prevsent>we note that the probability model is causal in the sequencing of tags (theprobability assignment for ti only depends on previous tags ti1, ti2) which allows for efficient algorithms that search for the most likely tag sequence ?(w ) = arg maxt (t |w ) as well as ensures properly normalized conditional probability model (t |w ).
</prevsent>
<prevsent>the probability (ti|xi(w,t i1 1 )) is modeled using maximum entropy model.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the next section briefly describes the training procedure; for details the reader is referred to (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>3.1 maximum entropy state transition model.
</nextsent>
<nextsent>the sufficient statistics that are extracted from the training data are tuples (y,#, x) = (ti,#, xi(w,t i1 1 )) where ti is the tag assigned in context xi(w,t i1 1 ) = {wi, wi1, wi+1, ti1, ti2} and # denotes the count with which this event has been observed in the training data.
</nextsent>
<nextsent>by way of example, the event associated with the first word in the example in section 2 is (*bdw* denotes special boundary type): mxc 1 currentword=primetime previousword=*bdw* nextword=continues t1=*bdw* t1,2=*bdw*,*bdw* prefix1=p prefix2=pr prefix3=pri suffix1=e suffix2=me suffix3=ime the maximum entropy probability model (y|x) uses features which are indicator functions of the type: f(y, x) = {1, 0, if = mxc and x.w = primetime o/w assuming set of features whose cardinality is , the probability assignment is made according to: ?
</nextsent>
<nextsent>(y|x) = z1(x,?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4213">
<title id=" W04-3237.xml">adaptation of maximum entropy capitalizer little data can help a lot </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, the difference in performance between this latter approach and ours could be quite large since the cardinalityof fbackground is typically several orders of magnitude larger than that of fadapt and our approach also updates the weights corresponding to features in fbackground \ fadapt.
</prevsent>
<prevsent>further experiments are needed to compare the performance of the two approaches.
</prevsent>
</prevsection>
<citsent citstr=" H92-1073 ">
the baseline 1-gram and the background memm capitalizer were trained on various amounts of wsj (paul and baker, 1992) <papid> H92-1073 </papid>data from 1987 ? files ws87_{001-126}.</citsent>
<aftsection>
<nextsent>the in-domain test data used was file ws94_000 (8.7kwds).
</nextsent>
<nextsent>as for the adaptation experiments, two different sets of bn data were used, whose sizes are summarized in table 1: 1.
</nextsent>
<nextsent>bn cnn/npr data.
</nextsent>
<nextsent>the train-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4214">
<title id=" W06-0137.xml">chinese word segmentation based on an approach of maximum entropy modeling </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the following sections described how our system works and presented the results and analysis.
</prevsent>
<prevsent>finally, the conclusion is presented with discussions of the system.
</prevsent>
</prevsection>
<citsent citstr=" W03-1728 ">
using maximum entropy approach for chinese word segmentation is not fresh idea, some previous works (xue and shen, 2003; <papid> W03-1728 </papid>low, ng and guo, 2005) have got good performance in this field.</citsent>
<aftsection>
<nextsent>but what we consider in the process of segmentation is another way.
</nextsent>
<nextsent>we treat the input text which need to be segmented as sequence of the chinese characters, the segment process is, infact, to find where we should split the character sequence.
</nextsent>
<nextsent>the point is to get the segment probability between 2 chinese characters, which is different from dealing with the character itself.in this section, training and segmentation process of the system is described to show how our system works.
</nextsent>
<nextsent>2.1 pre-process of training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4215">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in second experiment, we show that frame uniformity, which measures argument structure variation, correlates well with the performance figures, effectively explaining the variance.
</prevsent>
<prevsent>recent years have witnessed growing interest in corpora with semantic annotation, especially on the semantic role (or argument structure) level.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
a number of projects are working on producing such corpora through manual annotation, among which are framenet (baker et al , 1998), <papid> P98-1013 </papid>the prague dependency treebank (hajicov?, 1998), propbank (kingsbury et al , 2002), and salsa (erk et al ., 2003).<papid> P03-1068 </papid></citsent>
<aftsection>
<nextsent>for semantic role annotation to be widely useful for nlp, however, robust and accurate methods for automatic semantic role assignment are necessary.starting with gildea and jurafsky (2000), <papid> P00-1065 </papid>number of studies have developed (almost exclusively statistical) models of this task, e.g. thompson et al .</nextsent>
<nextsent>(2003) and fleischman et al  (2003)<papid> W03-1007 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4216">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in second experiment, we show that frame uniformity, which measures argument structure variation, correlates well with the performance figures, effectively explaining the variance.
</prevsent>
<prevsent>recent years have witnessed growing interest in corpora with semantic annotation, especially on the semantic role (or argument structure) level.
</prevsent>
</prevsection>
<citsent citstr=" P03-1068 ">
a number of projects are working on producing such corpora through manual annotation, among which are framenet (baker et al , 1998), <papid> P98-1013 </papid>the prague dependency treebank (hajicov?, 1998), propbank (kingsbury et al , 2002), and salsa (erk et al ., 2003).<papid> P03-1068 </papid></citsent>
<aftsection>
<nextsent>for semantic role annotation to be widely useful for nlp, however, robust and accurate methods for automatic semantic role assignment are necessary.starting with gildea and jurafsky (2000), <papid> P00-1065 </papid>number of studies have developed (almost exclusively statistical) models of this task, e.g. thompson et al .</nextsent>
<nextsent>(2003) and fleischman et al  (2003)<papid> W03-1007 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4217">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent years have witnessed growing interest in corpora with semantic annotation, especially on the semantic role (or argument structure) level.
</prevsent>
<prevsent>a number of projects are working on producing such corpora through manual annotation, among which are framenet (baker et al , 1998), <papid> P98-1013 </papid>the prague dependency treebank (hajicov?, 1998), propbank (kingsbury et al , 2002), and salsa (erk et al ., 2003).<papid> P03-1068 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
for semantic role annotation to be widely useful for nlp, however, robust and accurate methods for automatic semantic role assignment are necessary.starting with gildea and jurafsky (2000), <papid> P00-1065 </papid>number of studies have developed (almost exclusively statistical) models of this task, e.g. thompson et al .</citsent>
<aftsection>
<nextsent>(2003) and fleischman et al  (2003)<papid> W03-1007 </papid></nextsent>
<nextsent>this year (2004), semantic role labelling served as the shared task at two conferences, conll1 and senseval2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4218">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of projects are working on producing such corpora through manual annotation, among which are framenet (baker et al , 1998), <papid> P98-1013 </papid>the prague dependency treebank (hajicov?, 1998), propbank (kingsbury et al , 2002), and salsa (erk et al ., 2003).<papid> P03-1068 </papid></prevsent>
<prevsent>for semantic role annotation to be widely useful for nlp, however, robust and accurate methods for automatic semantic role assignment are necessary.starting with gildea and jurafsky (2000), <papid> P00-1065 </papid>number of studies have developed (almost exclusively statistical) models of this task, e.g. thompson et al .</prevsent>
</prevsection>
<citsent citstr=" W03-1007 ">
(2003) and fleischman et al  (2003)<papid> W03-1007 </papid></citsent>
<aftsection>
<nextsent>this year (2004), semantic role labelling served as the shared task at two conferences, conll1 and senseval2.
</nextsent>
<nextsent>however, almost all studies have concentrated onthe technical aspects of the models ? identifying informative feature sets and suitable statistical frameworks ? with the goal of optimising the performance of the models on the complete dataset.
</nextsent>
<nextsent>the only study we are aware of with more detailed evaluation is fleischman et al  (2003)<papid> W03-1007 </papid>who nevertheless come to the conclusion that either new features?, 1http://www.lsi.upc.es/~conll04st/ 2http://www.clres.com/senssemroles.html more data?, or more sophisticated models?</nextsent>
<nextsent>are needed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4223">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> framenet.  </section>
<citcontext>
<prevsection>
<prevsent>note that the frame-specificity of semantic roles in framenet has important consequences for semantic role assignment, since there is no direct way to generalise across frames.
</prevsent>
<prevsent>therefore, the learning for automatic assignment of semantic roles has to proceed frame-wise.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
thus, the data sparseness problem is especially acute, and automatic assignment for frames with no training data is very difficult (see gildea and jurafsky (2002)).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>of semantic role assignment in our first experiment, we perform detailed(frame-wise) evaluation of semantic role assignment to discover general patterns in the data.
</nextsent>
<nextsent>our aim is not to outperform existing models, but to replicate the workings of existing models so that our findings are representative for the task as it is currently addressed.
</nextsent>
<nextsent>to this end, we (a) use standard dataset, the framenet data, (b) model the task with two different statistical frameworks, and (c) keep our models as generic as possible.
</nextsent>
<nextsent>3.1 data and experimental setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4227">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> experiment 1: frame-wise evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>gildea and jurafsky (2000) <papid> P00-1065 </papid>and fleischman et al  (2003)<papid> W03-1007 </papid>used previous release of the dataset with less annotated instances, but covered all predicates (verbs, nouns and adjectives).</prevsent>
<prevsent>data preparation.</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
after tagging the data with tnt (brants, 2000), <papid> A00-1031 </papid>we parse them using the collins parsing model 3 (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>we consider only 3from the definition of the frame at http://www.icsi.
</nextsent>
<nextsent>berkeley.edu/~framenet/.
</nextsent>
<nextsent>examples adapted from the framenet data, release 2.the most probable parse for each sentence and simplify the resulting parse tree by removing all unary nodes.
</nextsent>
<nextsent>we lemmatise the head of each constituent with tree tagger (schmid, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4228">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> experiment 1: frame-wise evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>gildea and jurafsky (2000) <papid> P00-1065 </papid>and fleischman et al  (2003)<papid> W03-1007 </papid>used previous release of the dataset with less annotated instances, but covered all predicates (verbs, nouns and adjectives).</prevsent>
<prevsent>data preparation.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
after tagging the data with tnt (brants, 2000), <papid> A00-1031 </papid>we parse them using the collins parsing model 3 (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>we consider only 3from the definition of the frame at http://www.icsi.
</nextsent>
<nextsent>berkeley.edu/~framenet/.
</nextsent>
<nextsent>examples adapted from the framenet data, release 2.the most probable parse for each sentence and simplify the resulting parse tree by removing all unary nodes.
</nextsent>
<nextsent>we lemmatise the head of each constituent with tree tagger (schmid, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4233">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> experiment 1: frame-wise evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we perform the classification twice, with two learners from different statistical frameworks, in order to make our results more representative for the different statistical models employed so far for the task.
</prevsent>
<prevsent>the first learner uses the maximum entropy (maxent) framework, which has been applied e.g. by fleischman et al  (2003)<papid> W03-1007 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
the model is trained with the estimate software, which implements the lmvm algorithm (malouf, 2002)<papid> W02-2018 </papid>4.</citsent>
<aftsection>
<nextsent>the second learner is an instance of amemory-based learning (mbl) algorithm, the   nearest neighbour algorithm.
</nextsent>
<nextsent>we use the implementation provided by timbl (daelemans et al , 2003) with the recommended parameters, namely
</nextsent>
<nextsent> , adopting modified value difference with gain ratio feature weighting as similarity metric.
</nextsent>
<nextsent>3.2 features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4237">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> argument structure and frame.  </section>
<citcontext>
<prevsection>
<prevsent>in order to obtain an actual measure for frame uniformity, we take two further steps.
</prevsent>
<prevsent>first, we in stantiate with the cosine similarity
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
, which has been found to be appropriate for wide range of linguistic tasks (see e.g. lee (1999)) <papid> P99-1004 </papid>and ranges between 0 (least similar) and 1 (identity):</citsent>
<aftsection>
<nextsent>                       second, we normalise the values of  , which grow in  fiff  , the number of vectors, to fl  ffi !
</nextsent>
<nextsent>, to make them interpret able analogously to values of the cosine similarity.
</nextsent>
<nextsent>since this is possible in two different ways, we obtain two different measures for frame uniformity.
</nextsent>
<nextsent>the first one, which we call normalised quality-based uniformity (  # ), simply divides the values by ff :  #
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4238">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> experiment 2: explaining the variance.  </section>
<citcontext>
<prevsection>
<prevsent>with argument structure with two measures for the uniformity of argument structure at hand, we now proceed to test our main hypothesis.
</prevsent>
<prevsent>5.1 data and experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
as argued in section 3.4, our aim in this experiment is to control for the most plausible sources of performance variance and isolate the influence of argument structure.to meet this condition, we perform both the experiments and the uniformity measure calculation on controlled subset of the data, with the condition that both the number of verbs and the number of sentences are the same for each frame.following the methodology in keller and lapata (2003), <papid> J03-3005 </papid>we divide the verbs into four frequency bands, frequency being absolute number of annotated sentences: low (5), medium-low (12),medium-high (22), and high (38).</citsent>
<aftsection>
<nextsent>we set the boundaries between the bands as the quart iles of all the verbs containing at least 5 annotated examples7 . for each frame, 2 verbs in each frequency band are randomly chosen.
</nextsent>
<nextsent>this reduces our frame sample from 196 to 40.
</nextsent>
<nextsent>we furthermore randomly select number of sentences for each verb which matches the boundaries between frequency bands, that is, all verbs in each frequency bands are artificially set to have the same number of annotated sentences.
</nextsent>
<nextsent>this method assures that all frames in the experiment have 8 verbs and 154 sentences, so that both the performance figures and the uniformity measures were acquired under equal conditions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4240">
<title id=" W04-3214.xml">the influence of argument structure on semantic role assignment </title>
<section> conclusion and outlook.  </section>
<citcontext>
<prevsection>
<prevsent>there are several possible approaches to do so.first, the classic statistical approach: combining evidence from different frame-specific roles to alleviate data sparseness.
</prevsent>
<prevsent>to this end, gildea and jurafsky (2002) <papid> J02-3001 </papid>developed mapping from frame specific to syntactic roles, but results did not im prove much.</prevsent>
</prevsection>
<citsent citstr=" W04-0817 ">
baldewein et al  (2004) <papid> W04-0817 </papid>experiment with em-driven generalisation, and obtain also only modest improvements.</citsent>
<aftsection>
<nextsent>a second approach is to identify other levels, different from frames, at which regularities can be learnt better.
</nextsent>
<nextsent>one possibility is to identify smaller units within frames which have more uniform structure and which can be learnt more easily.
</nextsent>
<nextsent>since uniformity is defined in terms of quality function, clustering would be the natural method to employ for this task.
</nextsent>
<nextsent>however, this method is only viable for frames with large amount of annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4241">
<title id=" W05-0629.xml">semantic role labeling using support vector machines </title>
<section> support vector machines.  </section>
<citcontext>
<prevsection>
<prevsent>this algorithm has achieved good performance in many classification tasks, e.g.named entity recognition and document classification.
</prevsent>
<prevsent>there are some advantages to svms in that(i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with combination of multiple feature sis possible by using the polynomial kernel function (yamada and matsumoto, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
svms were used in the conll-2004 shred task and achieved good performance (hacioglu et al, 2004) <papid> W04-2416 </papid>kyung mi park and rim, 2004).</citsent>
<aftsection>
<nextsent>we used yamcha (yet another multipurpose chunk annotator) 1 (kudo and matsumoto, 2001), <papid> N01-1025 </papid>which is general purpose svm-based chunker.</nextsent>
<nextsent>we also used tinysvm2 as package for svms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4243">
<title id=" W05-0629.xml">semantic role labeling using support vector machines </title>
<section> support vector machines.  </section>
<citcontext>
<prevsection>
<prevsent>there are some advantages to svms in that(i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with combination of multiple feature sis possible by using the polynomial kernel function (yamada and matsumoto, 2003).
</prevsent>
<prevsent>svms were used in the conll-2004 shred task and achieved good performance (hacioglu et al, 2004) <papid> W04-2416 </papid>kyung mi park and rim, 2004).</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
we used yamcha (yet another multipurpose chunk annotator) 1 (kudo and matsumoto, 2001), <papid> N01-1025 </papid>which is general purpose svm-based chunker.</citsent>
<aftsection>
<nextsent>we also used tinysvm2 as package for svms.
</nextsent>
<nextsent>3.1 data representation.
</nextsent>
<nextsent>we changed the representation of original data according to hacioglu et al (hacioglu et al, 2004) <papid> W04-2416 </papid>in our system.</nextsent>
<nextsent>1http://chasen.org/?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4247">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although researchers have demonstrated that users can read summaries faster than full text (mani et al, 2002) with some loss of accuracy, researchers have found it difficult todraw strong conclusions about the usefulness of summarization due to the low level of inter annotator agreement in the gold standards that they have used.
</prevsent>
<prevsent>definitive conclusions about the usefulness of summaries would provide justification for continued research and development of new summarization methods.to investigate the question of whether text summarization is useful in an extrinsic task, we examined human performance in relevance assessment task using human text surrogate (i.e. text intended to stand in the placeof document).
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
we use single-document english summaries as these are sufficient for investigating task-basedusefulness, although more elaborate surrogates are possible, e.g., those that span more than one document (radev and mckeown, 1998; <papid> J98-3005 </papid>mani and bloedorn, 1998).the next section motivates the need for developing new framework for measuring task-based useful ness.</citsent>
<aftsection>
<nextsent>section 3 presents novel extrinsic measure called relevance-prediction.
</nextsent>
<nextsent>section 4 demonstrates that this isa more reliable measure than that of previous gold standard methods, e.g., the ldc-agreement method used forsummac-style evaluations, and that this reliability allows us to make stronger statistical statements about the benefits of summarization.
</nextsent>
<nextsent>we expect these findings to be important for future summarization evaluations.
</nextsent>
<nextsent>section 5 presents the results of correlation between task usefulness and the recall oriented understudy for gisting evaluation (rouge) metric (lin and hovy, 2003).<papid> N03-1020 </papid>1 while we show that rouge correlates with task usefulness (using our relevance-prediction measure), we detect slight difference between informative, extractive headlines (containing words from the full document) andless informative, non-extractive eye-catchers?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4248">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 4 demonstrates that this isa more reliable measure than that of previous gold standard methods, e.g., the ldc-agreement method used forsummac-style evaluations, and that this reliability allows us to make stronger statistical statements about the benefits of summarization.
</prevsent>
<prevsent>we expect these findings to be important for future summarization evaluations.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
section 5 presents the results of correlation between task usefulness and the recall oriented understudy for gisting evaluation (rouge) metric (lin and hovy, 2003).<papid> N03-1020 </papid>1 while we show that rouge correlates with task usefulness (using our relevance-prediction measure), we detect slight difference between informative, extractive headlines (containing words from the full document) andless informative, non-extractive eye-catchers?</citsent>
<aftsection>
<nextsent>(contain ing words that might not appear in the full document, and intended to entice reader to read the entire document).
</nextsent>
<nextsent>section 6 further highlights the importance of this point and discusses the implications for automatic evaluation of non-extractive summaries.
</nextsent>
<nextsent>to evaluate non extractive summaries reliably, an automatic measure may require knowledge of sophisticated meaning units.2 it is our hope that the conclusions drawn herein will prompt investigation into more sophisticated automatic metric sas researchers shift their focus to non-extractive summaries.
</nextsent>
<nextsent>1rouge has been previously used as the primary automatic evaluation metric by nist in the 2003 and 2004 duc evaluations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4249">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to evaluate non extractive summaries reliably, an automatic measure may require knowledge of sophisticated meaning units.2 it is our hope that the conclusions drawn herein will prompt investigation into more sophisticated automatic metric sas researchers shift their focus to non-extractive summaries.
</prevsent>
<prevsent>1rouge has been previously used as the primary automatic evaluation metric by nist in the 2003 and 2004 duc evaluations.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
2the content units proposed in recent methods (nenkova and passonneau, 2004) <papid> N04-1019 </papid>are first step in this direction.</citsent>
<aftsection>
<nextsent>1
</nextsent>
<nextsent>in the past, assessments of usefulness involved wide range of both intrinsic and extrinsic (task-based) measures (sparck-jones and gallier, 1996).
</nextsent>
<nextsent>intrinsic evaluations focus on coherence and informative ness (jing et al., 1998) and often involve quality comparisons between automatic summaries and reference summaries that are pre-determined to be of high quality.
</nextsent>
<nextsent>human intrinsic measures determine quality by assessing document accuracy, fluency, and clarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4250">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>although these judgments were supposed to represent the correct relevance judgments for each of the documents associated with an event, both studies reported that annotators?
</prevsent>
<prevsent>judgments varied greatly and that this was significant issue for the evaluations.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
in the summac experiments, the kappa score (carletta, 1996; <papid> J96-2004 </papid>eugenio and glass, 2004) <papid> J04-1005 </papid>for in ter annotator agreement was reported to be 0.38 (mani et al., 2002).</citsent>
<aftsection>
<nextsent>in fact, large variations have been found in the initial summary scoring of an individual participant and subsequent scoring that occurs few weeks later (mani, 2001; van halteren and teufel, 2003).this paper attempts to overcome the problem of inter annotator inconsistency by measuring summary effectiveness in an extrinsic task using much more consistent form of user judgment instead of gold standard.
</nextsent>
<nextsent>using relevance-prediction increases the confidence in our results and strengthens the statistical statements we can make about the benefits of summarization.
</nextsent>
<nextsent>the next section describes an alternative approach to measuring task-based usefulness, where the usage of external judgments as gold standard is replaced by the3a topic is an event or activity, along with all directly related events and activities.
</nextsent>
<nextsent>an event is something that happen sat some specific time and place, and the unavoidable consequences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4251">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>although these judgments were supposed to represent the correct relevance judgments for each of the documents associated with an event, both studies reported that annotators?
</prevsent>
<prevsent>judgments varied greatly and that this was significant issue for the evaluations.
</prevsent>
</prevsection>
<citsent citstr=" J04-1005 ">
in the summac experiments, the kappa score (carletta, 1996; <papid> J96-2004 </papid>eugenio and glass, 2004) <papid> J04-1005 </papid>for in ter annotator agreement was reported to be 0.38 (mani et al., 2002).</citsent>
<aftsection>
<nextsent>in fact, large variations have been found in the initial summary scoring of an individual participant and subsequent scoring that occurs few weeks later (mani, 2001; van halteren and teufel, 2003).this paper attempts to overcome the problem of inter annotator inconsistency by measuring summary effectiveness in an extrinsic task using much more consistent form of user judgment instead of gold standard.
</nextsent>
<nextsent>using relevance-prediction increases the confidence in our results and strengthens the statistical statements we can make about the benefits of summarization.
</nextsent>
<nextsent>the next section describes an alternative approach to measuring task-based usefulness, where the usage of external judgments as gold standard is replaced by the3a topic is an event or activity, along with all directly related events and activities.
</nextsent>
<nextsent>an event is something that happen sat some specific time and place, and the unavoidable consequences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4252">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>an event is something that happen sat some specific time and place, and the unavoidable consequences.
</prevsent>
<prevsent>users own decisions on the full text.
</prevsent>
</prevsection>
<citsent citstr=" W00-0407 ">
following the lead of earlier evaluations (oka and ueda, 2000; <papid> W00-0407 </papid>mani et al,2002; sakai and sparck-jones, 2001), we focus on relevance assessment as our extrinsic task.</citsent>
<aftsection>
<nextsent>we define new extrinsic measure of task-based usefulness called relevance-prediction, where we compare asummary-based decision to the subjects own full-text decision rather than to different subjects decision.
</nextsent>
<nextsent>our findings differ from that of the summac results (maniet al, 2002) in that using relevance-prediction as an alternative to comparision to gold standard is more realistic agreement measure for assessing usefulness in arelevance assessment task.
</nextsent>
<nextsent>for example, users performing browsing tasks must examine document surrogates, but open the full-text only if they expect the document to be interesting to them.
</nextsent>
<nextsent>they are not trying to decide if the document will be interesting to someone else.to determine the usefulness of summarization, we focus on two questions: ? can users make judgments on summaries that are consistent with their full-text judgments?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4253">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> correlation with intrinsic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>is the average agreement score.
</prevsent>
<prevsent>pearsons statistics is commonly used in summarization and machine translation evaluation, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
(lin, 2004; <papid> W04-1013 </papid>lin and och, 2004).<papid> C04-1072 </papid></citsent>
<aftsection>
<nextsent>as one might expect, there is some variability in the correlation between rouge and human judgments for 9we also computed rouge 2-gram, rouge and rouge w, but the trend for these did not differ from rouge 1.
</nextsent>
<nextsent>figure 1: distribution of the correlation variation for relevance-prediction on head and hum the different partitions.
</nextsent>
<nextsent>however, the box plots for both head and hum indicate that the first and third quartile were relatively close to the median (see figure 1).table 5 shows the pearson correlations with rouge 1 using relevance-prediction and ldc-agreement.
</nextsent>
<nextsent>for relevance-prediction, we observed positive correlation for both surrogate types, with slightly higher correlation for head than hum.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4254">
<title id=" W05-0901.xml">a methodology for extrinsic evaluation of text summarization does rouge correlate </title>
<section> correlation with intrinsic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>is the average agreement score.
</prevsent>
<prevsent>pearsons statistics is commonly used in summarization and machine translation evaluation, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
(lin, 2004; <papid> W04-1013 </papid>lin and och, 2004).<papid> C04-1072 </papid></citsent>
<aftsection>
<nextsent>as one might expect, there is some variability in the correlation between rouge and human judgments for 9we also computed rouge 2-gram, rouge and rouge w, but the trend for these did not differ from rouge 1.
</nextsent>
<nextsent>figure 1: distribution of the correlation variation for relevance-prediction on head and hum the different partitions.
</nextsent>
<nextsent>however, the box plots for both head and hum indicate that the first and third quartile were relatively close to the median (see figure 1).table 5 shows the pearson correlations with rouge 1 using relevance-prediction and ldc-agreement.
</nextsent>
<nextsent>for relevance-prediction, we observed positive correlation for both surrogate types, with slightly higher correlation for head than hum.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4255">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one goal of information extraction tasks is to identify important conceptual information in discourse.
</prevsent>
<prevsent>these task shave applications in summarization, information retrieval (one can get al hits for washington/personand not the ones for washington/state or washing ton/city), data mining, question answering, language understanding, etc. in this paper we focus on the entity detection and recognition task (edr) for arabicas described in ace 2004 framework (ace, 2004).
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
the edr has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of several recent investigations (bikel et al, 1997; <papid> A97-1029 </papid>miller et al, 1998; borthwick, 1999; mikheev et al, 1999; <papid> E99-1001 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>florian et al, 2004), <papid> N04-1001 </papid>and have been at the center of evaluations such as: muc-6, muc-7, and the conll02and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistics literature, named entity is an instance of location, person, or an organization, and the ner task consists of identifying each of theseoccurrences.
</nextsent>
<nextsent>instead, we will adopt the nomenclature of the automatic content extraction program (nist, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. john mayor), nominal (the president) or pronominal (she, it).
</nextsent>
<nextsent>an entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {john smith, he}.we separate the edr task into two parts: mention detection step, which identifies and classifies all the mentions in text ? and coreference resolution step, which combi nines the detected mentions into groups that refer to the same object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4256">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one goal of information extraction tasks is to identify important conceptual information in discourse.
</prevsent>
<prevsent>these task shave applications in summarization, information retrieval (one can get al hits for washington/personand not the ones for washington/state or washing ton/city), data mining, question answering, language understanding, etc. in this paper we focus on the entity detection and recognition task (edr) for arabicas described in ace 2004 framework (ace, 2004).
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
the edr has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of several recent investigations (bikel et al, 1997; <papid> A97-1029 </papid>miller et al, 1998; borthwick, 1999; mikheev et al, 1999; <papid> E99-1001 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>florian et al, 2004), <papid> N04-1001 </papid>and have been at the center of evaluations such as: muc-6, muc-7, and the conll02and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistics literature, named entity is an instance of location, person, or an organization, and the ner task consists of identifying each of theseoccurrences.
</nextsent>
<nextsent>instead, we will adopt the nomenclature of the automatic content extraction program (nist, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. john mayor), nominal (the president) or pronominal (she, it).
</nextsent>
<nextsent>an entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {john smith, he}.we separate the edr task into two parts: mention detection step, which identifies and classifies all the mentions in text ? and coreference resolution step, which combi nines the detected mentions into groups that refer to the same object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4257">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one goal of information extraction tasks is to identify important conceptual information in discourse.
</prevsent>
<prevsent>these task shave applications in summarization, information retrieval (one can get al hits for washington/personand not the ones for washington/state or washing ton/city), data mining, question answering, language understanding, etc. in this paper we focus on the entity detection and recognition task (edr) for arabicas described in ace 2004 framework (ace, 2004).
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the edr has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of several recent investigations (bikel et al, 1997; <papid> A97-1029 </papid>miller et al, 1998; borthwick, 1999; mikheev et al, 1999; <papid> E99-1001 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>florian et al, 2004), <papid> N04-1001 </papid>and have been at the center of evaluations such as: muc-6, muc-7, and the conll02and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistics literature, named entity is an instance of location, person, or an organization, and the ner task consists of identifying each of theseoccurrences.
</nextsent>
<nextsent>instead, we will adopt the nomenclature of the automatic content extraction program (nist, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. john mayor), nominal (the president) or pronominal (she, it).
</nextsent>
<nextsent>an entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {john smith, he}.we separate the edr task into two parts: mention detection step, which identifies and classifies all the mentions in text ? and coreference resolution step, which combi nines the detected mentions into groups that refer to the same object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4258">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one goal of information extraction tasks is to identify important conceptual information in discourse.
</prevsent>
<prevsent>these task shave applications in summarization, information retrieval (one can get al hits for washington/personand not the ones for washington/state or washing ton/city), data mining, question answering, language understanding, etc. in this paper we focus on the entity detection and recognition task (edr) for arabicas described in ace 2004 framework (ace, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
the edr has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of several recent investigations (bikel et al, 1997; <papid> A97-1029 </papid>miller et al, 1998; borthwick, 1999; mikheev et al, 1999; <papid> E99-1001 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>florian et al, 2004), <papid> N04-1001 </papid>and have been at the center of evaluations such as: muc-6, muc-7, and the conll02and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistics literature, named entity is an instance of location, person, or an organization, and the ner task consists of identifying each of theseoccurrences.
</nextsent>
<nextsent>instead, we will adopt the nomenclature of the automatic content extraction program (nist, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. john mayor), nominal (the president) or pronominal (she, it).
</nextsent>
<nextsent>an entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {john smith, he}.we separate the edr task into two parts: mention detection step, which identifies and classifies all the mentions in text ? and coreference resolution step, which combi nines the detected mentions into groups that refer to the same object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4259">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one goal of information extraction tasks is to identify important conceptual information in discourse.
</prevsent>
<prevsent>these task shave applications in summarization, information retrieval (one can get al hits for washington/personand not the ones for washington/state or washing ton/city), data mining, question answering, language understanding, etc. in this paper we focus on the entity detection and recognition task (edr) for arabicas described in ace 2004 framework (ace, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N04-1001 ">
the edr has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of several recent investigations (bikel et al, 1997; <papid> A97-1029 </papid>miller et al, 1998; borthwick, 1999; mikheev et al, 1999; <papid> E99-1001 </papid>soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>florian et al, 2004), <papid> N04-1001 </papid>and have been at the center of evaluations such as: muc-6, muc-7, and the conll02and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistics literature, named entity is an instance of location, person, or an organization, and the ner task consists of identifying each of theseoccurrences.
</nextsent>
<nextsent>instead, we will adopt the nomenclature of the automatic content extraction program (nist, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. john mayor), nominal (the president) or pronominal (she, it).
</nextsent>
<nextsent>an entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {john smith, he}.we separate the edr task into two parts: mention detection step, which identifies and classifies all the mentions in text ? and coreference resolution step, which combi nines the detected mentions into groups that refer to the same object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4261">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, most arabic words are morphologically derived from list of base forms or stems, to which prefixes and suffixes can be attached to form arabic surface forms(blank-delimited words).
</prevsent>
<prevsent>in addition to the different forms of the arabic word that result from the 63derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the arabic surface word.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
it is these orthographic variations and complex morphological structure that make arabic language processing challenging (xu et al, 2001; xu et al, 2002).both tasks are performed with statistical frame work: the mention detection system is similar to the one presented in (florian et al, 2004) <papid> N04-1001 </papid>and the coreference resolution system is similar to the one described in (luo et al, 2004).<papid> P04-1018 </papid></citsent>
<aftsection>
<nextsent>both systems are built around from the maximum-entropy technique (berger et al, 1996).<papid> J96-1002 </papid></nextsent>
<nextsent>we formulate the mention detection task as sequence classification prob lem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4265">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the different forms of the arabic word that result from the 63derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the arabic surface word.
</prevsent>
<prevsent>it is these orthographic variations and complex morphological structure that make arabic language processing challenging (xu et al, 2001; xu et al, 2002).both tasks are performed with statistical frame work: the mention detection system is similar to the one presented in (florian et al, 2004) <papid> N04-1001 </papid>and the coreference resolution system is similar to the one described in (luo et al, 2004).<papid> P04-1018 </papid></prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
both systems are built around from the maximum-entropy technique (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>we formulate the mention detection task as sequence classification problem.
</nextsent>
<nextsent>while this approach is language independent, it must be modified to accomodate the particulars ofthe arabic language.
</nextsent>
<nextsent>the arabic words may be composed of zero or more prefixes, followed by stem and zero or more suffixes.
</nextsent>
<nextsent>we begin with segmentation of the written text before starting the classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4268">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> arabic segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>as an example, consider the word d jkaj. ??
</prevsent>
<prevsent>(and to her researchers) which contains two prefixes and one suffix ( ? + ? kak. + ? + ?).
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
lee et al (2003) <papid> P03-1051 </papid>demonstrates technique for segmenting arabic text and uses it as morphological processing step in machine translation.</citsent>
<aftsection>
<nextsent>a trigram language model was used to score and select among hypothesized segment ations determined by set of prefix and suffix expansion rules.
</nextsent>
<nextsent>in our latest implementation of this algorithm, wehave recast this segmentation strategy as the composition of three distinct finite state machines.
</nextsent>
<nextsent>the first machine, illustrated in figure 1 encodes the prefix and suffix expansion rules, producing lattice of possible segmentations.
</nextsent>
<nextsent>the second machine is dictionary that accepts characters and produces identifiers corresponding to dictionary entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4270">
<title id=" W05-0709.xml">the impact of morphological stemming on arabic mention detection and coreference resolution </title>
<section> arabic segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>using 0.5m words from the combined arabic treebanks 1v2, 2v2 and 3v1, the dictionary based segmenter achieves exact word match 97.8% correct segmentation.
</prevsent>
<prevsent>sep/epsilon a/a# epsilon/# a/epsilon a/epsilon b/epsilon b/b unk/epsilon c/c b/epsilon c/bc e/+e epsilon/+ d/epsilon d/epsilon epsilon/epsilon b/ab# b/a#b# e/+de c/epsilon d/bcd e/+d+efigure 1: illustration of dictionary based segmentation finite state transducer 3.1 bootstrapping.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
in addition to the model based upon dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for chinese segmentation (sproat et al, 1996).<papid> J96-3004 </papid></citsent>
<aftsection>
<nextsent>for these models, both arabic characters and spaces, and the inserted prefix and suffix markers appear on the arcs of the finite state machine.
</nextsent>
<nextsent>here, the language model is conditioned to insert prefix and suffix markers based upon the frequency of their appearance inn-gram character contexts that appear in the training data.
</nextsent>
<nextsent>the character based model alone achievesa 94.5% exact match segmentation accuracy, considerably less accurate then the dictionary based model.
</nextsent>
<nextsent>however, an analysis of the errors indicated that the character based model is more effective at segmenting words that do not appear in the training data.we seeked to exploit this ability to generalize to im prove the dictionary based model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4292">
<title id=" W05-0630.xml">hierarchical semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to achieve this, wehave split the classification step by grouping together roles which share linguistic properties (e.g. core roles versus adjuncts).
</prevsent>
<prevsent>the results show that the non optimized hierarchical approach is computationally more efficient than the traditional systems and it preserves their accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
for accomplishing the conll 2005 shared task on semantic role labeling (carreras and ma`rquez,2005), we capitalized on our experience on these mantic shallow parsing by extending our system, widely experimented on propbank and framenet(giuglea and moschitti, 2004) <papid> P04-1043 </papid>data, with two step boundary detection and hierarchical argument classification strategy.</citsent>
<aftsection>
<nextsent>currently, the system can work in both basic and enhanced configuration.
</nextsent>
<nextsent>given the parse tree of aninput sentence, the basic system applies (1) boundary classifier to select the nodes associated with correct arguments and (2) multi-class labeler to assign the role type.
</nextsent>
<nextsent>for such models, we used some of the linear (e.g.
</nextsent>
<nextsent>(gildea and jurasfky, 2002; pradhan et al., 2005)) and structural (moschitti, 2004) <papid> P04-1043 </papid>features developed in previous studies.in the enhanced configuration, the boundary annotation is subdivided in two steps: first pass in which we label argument boundary and second pass in which we apply simple heuristic to eliminate the argument overlaps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4300">
<title id=" W05-0630.xml">hierarchical semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(gildea and jurasfky, 2002; pradhan et al., 2005)) and structural (moschitti, 2004) <papid> P04-1043 </papid>features developed in previous studies.in the enhanced configuration, the boundary annotation is subdivided in two steps: first pass in which we label argument boundary and second pass in which we apply simple heuristic to eliminate the argument overlaps.</prevsent>
<prevsent>we have also tried some strategies to learn such heuristics automatically.</prevsent>
</prevsection>
<citsent citstr=" W05-0407 ">
in order to do this we used tree kernel to classify the subtrees associated with correct predicate argument structures (see (moschitti et al, 2005)).<papid> W05-0407 </papid></citsent>
<aftsection>
<nextsent>the rationale behind such an attempt was to exploit the correlation among potential arguments.
</nextsent>
<nextsent>also, the role labeler is divided into two steps:(1) we assign to the arguments one out of four possible class labels: core roles, adjuncts, continuation arguments and co-referring arguments, and (2) ineach of the above class we apply the set of its specific classifiers, e.g. a0,..,a5 within the core roleclass.
</nextsent>
<nextsent>as such grouping is relatively new, the traditional features may not be sufficient to characterize each class.
</nextsent>
<nextsent>thus, to generate large set of features automatically, we again applied tree kernels.since our srl system exploits the propbank formalism for internal data representation, we developed ad-hoc procedures to convert back and forth to the conll shared task format.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4301">
<title id=" W05-0630.xml">hierarchical semantic role labeling </title>
<section> the basic semantic role labeler.  </section>
<citcontext>
<prevsection>
<prevsent>sets and the role labeler on the t+i , i.e. its positive examples and ti , i.e. its negative examples,where t+ = t+i ? ti , according to the one-vs.all scheme.
</prevsent>
<prevsent>to implement the multi-class classifiers we select the argument associated with the maximum among the svm scores.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
to represent the fp,a pairs we used the following features: - the phrase type, predicate word, head word, governing category, position and voice defined in (gildea and jurasfky, 2002); - the partial path, compressed path, no direction path, constituent tree distance, head word pos,first and last word/pos in constituent, subcategorization and head word of prepositional phrases proposed in (pradhan et al, 2005); and - the syntactic frame designed in (xue and palmer, 2004).<papid> W04-3212 </papid>figure 1: architecture of the hierarchical semantic role la beler.</citsent>
<aftsection>
<nextsent>having two phases for argument labeling provides two main advantages: (1) the efficiency is increas edas the negative boundary examples, which are almost all parse-tree nodes, are used with one classifier only (i.e. the boundary classifier), and (2) as arguments share common features that do not occur in the non-arguments, preliminary classification between arguments and non-arguments advantages the boundary detection of roles with fewer training examples (e.g. a4).
</nextsent>
<nextsent>moreover, it may be simpler to classify the type of roles when the not-argument nodes are absent.
</nextsent>
<nextsent>following this idea, we generalized the above two level strategy to four-step role labeling by grouping together the arguments sharing similar properties.
</nextsent>
<nextsent>figure 1, shows the hierarchy employed for argument classification: during the first phase, we select the parse tree nodes which are likely predicate arguments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4311">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we also suggest some guidelines for using these algorithms for actual alignment.
</prevsent>
<prevsent>sentence alignment approaches can be categorized as based on sentence length, word correspondence, and composite (where more than one approaches arecombined), though other techniques, such as cog 99 nate matching (simard et al, 1992) were also tried.
</prevsent>
</prevsection>
<citsent citstr=" J93-1006 ">
word correspondence was used by kay (kay, 1991; kay and roscheisen, 1993).<papid> J93-1006 </papid></citsent>
<aftsection>
<nextsent>it was based on the idea that words which are translations of each other will have similar distributions in the sl and tl texts.
</nextsent>
<nextsent>sentence length methods were based on the intuition that the length of translated sentence is likely to be similar to that of the source sentence.
</nextsent>
<nextsent>brown, lai and mercer (brown et al, 1991) <papid> P91-1022 </papid>used word count as the sentence length, whereas gale and church (gale and church, 1991) <papid> P91-1023 </papid>used character count.</nextsent>
<nextsent>brown, lai and mercer assumed prior alignment of paragraphs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4312">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>it was based on the idea that words which are translations of each other will have similar distributions in the sl and tl texts.
</prevsent>
<prevsent>sentence length methods were based on the intuition that the length of translated sentence is likely to be similar to that of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
brown, lai and mercer (brown et al, 1991) <papid> P91-1022 </papid>used word count as the sentence length, whereas gale and church (gale and church, 1991) <papid> P91-1023 </papid>used character count.</citsent>
<aftsection>
<nextsent>brown, lai and mercer assumed prior alignment of paragraphs.
</nextsent>
<nextsent>gale and church relied on some previously aligned sentences as anchors?.
</nextsent>
<nextsent>wu (wu, 1994) <papid> P94-1012 </papid>also used lexical cues from corpus-specific bilingual lexicon for better alignment.</nextsent>
<nextsent>word correspondence was further developed in ibm model-1 (brown et al, 1993) <papid> J93-2003 </papid>for statistical machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4313">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>it was based on the idea that words which are translations of each other will have similar distributions in the sl and tl texts.
</prevsent>
<prevsent>sentence length methods were based on the intuition that the length of translated sentence is likely to be similar to that of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
brown, lai and mercer (brown et al, 1991) <papid> P91-1022 </papid>used word count as the sentence length, whereas gale and church (gale and church, 1991) <papid> P91-1023 </papid>used character count.</citsent>
<aftsection>
<nextsent>brown, lai and mercer assumed prior alignment of paragraphs.
</nextsent>
<nextsent>gale and church relied on some previously aligned sentences as anchors?.
</nextsent>
<nextsent>wu (wu, 1994) <papid> P94-1012 </papid>also used lexical cues from corpus-specific bilingual lexicon for better alignment.</nextsent>
<nextsent>word correspondence was further developed in ibm model-1 (brown et al, 1993) <papid> J93-2003 </papid>for statistical machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4314">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>brown, lai and mercer assumed prior alignment of paragraphs.
</prevsent>
<prevsent>gale and church relied on some previously aligned sentences as anchors?.
</prevsent>
</prevsection>
<citsent citstr=" P94-1012 ">
wu (wu, 1994) <papid> P94-1012 </papid>also used lexical cues from corpus-specific bilingual lexicon for better alignment.</citsent>
<aftsection>
<nextsent>word correspondence was further developed in ibm model-1 (brown et al, 1993) <papid> J93-2003 </papid>for statistical machine translation.</nextsent>
<nextsent>melamed (melamed, 1996)also used word correspondence in different (geo metric correspondence) way for sentence alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4315">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>gale and church relied on some previously aligned sentences as anchors?.
</prevsent>
<prevsent>wu (wu, 1994) <papid> P94-1012 </papid>also used lexical cues from corpus-specific bilingual lexicon for better alignment.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
word correspondence was further developed in ibm model-1 (brown et al, 1993) <papid> J93-2003 </papid>for statistical machine translation.</citsent>
<aftsection>
<nextsent>melamed (melamed, 1996)also used word correspondence in different (geo metric correspondence) way for sentence alignment.
</nextsent>
<nextsent>simard and plamondon (simard and plamondon, 1998) used composite method in which the first pass does alignment at the level of characters asin (church, 1993) (<papid> P93-1001 </papid>itself based on cognate matching) and the second pass uses ibm model-1, following chen (chen, 1993).<papid> P93-1002 </papid></nextsent>
<nextsent>the method used by moore (moore, 2002) also had two passes, the first one being based on sentence length (word count) and the second on ibm model-1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4316">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>word correspondence was further developed in ibm model-1 (brown et al, 1993) <papid> J93-2003 </papid>for statistical machine translation.</prevsent>
<prevsent>melamed (melamed, 1996)also used word correspondence in different (geo metric correspondence) way for sentence alignment.</prevsent>
</prevsection>
<citsent citstr=" P93-1001 ">
simard and plamondon (simard and plamondon, 1998) used composite method in which the first pass does alignment at the level of characters asin (church, 1993) (<papid> P93-1001 </papid>itself based on cognate matching) and the second pass uses ibm model-1, following chen (chen, 1993).<papid> P93-1002 </papid></citsent>
<aftsection>
<nextsent>the method used by moore (moore, 2002) also had two passes, the first one being based on sentence length (word count) and the second on ibm model-1.
</nextsent>
<nextsent>composite methods are used so that different approaches can compliment each other.
</nextsent>
<nextsent>as stated above, the performance of sentence alignment algorithm depends on some identifiable factors.
</nextsent>
<nextsent>we can even make predictions about whether the performance will increase or decrease.however, as the results given later show, the algorithms dont always behave in predictable way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4317">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> sentence alignment methods.  </section>
<citcontext>
<prevsection>
<prevsent>word correspondence was further developed in ibm model-1 (brown et al, 1993) <papid> J93-2003 </papid>for statistical machine translation.</prevsent>
<prevsent>melamed (melamed, 1996)also used word correspondence in different (geo metric correspondence) way for sentence alignment.</prevsent>
</prevsection>
<citsent citstr=" P93-1002 ">
simard and plamondon (simard and plamondon, 1998) used composite method in which the first pass does alignment at the level of characters asin (church, 1993) (<papid> P93-1001 </papid>itself based on cognate matching) and the second pass uses ibm model-1, following chen (chen, 1993).<papid> P93-1002 </papid></citsent>
<aftsection>
<nextsent>the method used by moore (moore, 2002) also had two passes, the first one being based on sentence length (word count) and the second on ibm model-1.
</nextsent>
<nextsent>composite methods are used so that different approaches can compliment each other.
</nextsent>
<nextsent>as stated above, the performance of sentence alignment algorithm depends on some identifiable factors.
</nextsent>
<nextsent>we can even make predictions about whether the performance will increase or decrease.however, as the results given later show, the algorithms dont always behave in predictable way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4318">
<title id=" W05-0816.xml">comparison selection and use of sentence alignment algorithms for new language pairs </title>
<section> evaluation in previous work.  </section>
<citcontext>
<prevsection>
<prevsent>some algorithms, like those based on cognate matching, may even be sensitive to the encoding or notation used for the text.
</prevsent>
<prevsent>one of the algorithms tested (melamed, 1996) gave worse performance when we used notation called itrans for the hindi text, instead of the wx-notation.1
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
there have been attempts to systematically evaluate and compare word alignment algorithms (och and ney, 2003) <papid> J03-1002 </papid>but, surprisingly, there has been lack of such evaluation for sentence alignment algorithms.</citsent>
<aftsection>
<nextsent>one obvious problem is the lack of manually aligned and checked parallel corpora.two cases where systematic evaluation was performed are the arcade project (langlais et al, 1996) and simard et al (simard et al, 1992).
</nextsent>
<nextsent>in the arcade project, six alignment systems were evaluated on several different text types.
</nextsent>
<nextsent>simard et al performed an evaluation on several corpus types and 1in this notation, capitalization roughly means aspiration for consonants and longer length for vowels.
</nextsent>
<nextsent>in addition, w? represents t? as in french entre and x? means something similar to d? in french de, hence the name of the notation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4322">
<title id=" W05-1004.xml">automatically learning qualia structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the approach isbased on the idea of matching certain lexico syntactic patterns conveying certain semantic relation on the world wide web using standard search engines.
</prevsent>
<prevsent>we evaluate our approach qualitatively by comparing our automatically learned qualia structures with the ones from the literature, but also quantitatively by presenting results of human evaluation.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
qualia structures have been originally introduced by (pustejovsky, 1991) <papid> J91-4003 </papid>and are used for variety of purposes in natural language processing such as the analysis of compounds (johnston and busa, 1996), <papid> W96-0309 </papid>co-composition and coercion (pustejovsky, 1991) <papid> J91-4003 </papid>as well as for bridging reference resolution (bos et al, 1995).</citsent>
<aftsection>
<nextsent>further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (voorhees, 1994; pustejovsky et al, 1993).<papid> J93-2005 </papid></nextsent>
<nextsent>one major bottleneck however is that currently qualia structures need to be created by hand, which is probably also the reason why there are no practical system using qualiastructures, but lot of systems using globally available resources such as wordnet (fellbaum, 1998) or framenet1 1http://framenet.icsi.berkeley.edu/as source of lexical/world knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4325">
<title id=" W05-1004.xml">automatically learning qualia structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the approach isbased on the idea of matching certain lexico syntactic patterns conveying certain semantic relation on the world wide web using standard search engines.
</prevsent>
<prevsent>we evaluate our approach qualitatively by comparing our automatically learned qualia structures with the ones from the literature, but also quantitatively by presenting results of human evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W96-0309 ">
qualia structures have been originally introduced by (pustejovsky, 1991) <papid> J91-4003 </papid>and are used for variety of purposes in natural language processing such as the analysis of compounds (johnston and busa, 1996), <papid> W96-0309 </papid>co-composition and coercion (pustejovsky, 1991) <papid> J91-4003 </papid>as well as for bridging reference resolution (bos et al, 1995).</citsent>
<aftsection>
<nextsent>further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (voorhees, 1994; pustejovsky et al, 1993).<papid> J93-2005 </papid></nextsent>
<nextsent>one major bottleneck however is that currently qualia structures need to be created by hand, which is probably also the reason why there are no practical system using qualiastructures, but lot of systems using globally available resources such as wordnet (fellbaum, 1998) or framenet1 1http://framenet.icsi.berkeley.edu/as source of lexical/world knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4329">
<title id=" W05-1004.xml">automatically learning qualia structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate our approach qualitatively by comparing our automatically learned qualia structures with the ones from the literature, but also quantitatively by presenting results of human evaluation.
</prevsent>
<prevsent>qualia structures have been originally introduced by (pustejovsky, 1991) <papid> J91-4003 </papid>and are used for variety of purposes in natural language processing such as the analysis of compounds (johnston and busa, 1996), <papid> W96-0309 </papid>co-composition and coercion (pustejovsky, 1991) <papid> J91-4003 </papid>as well as for bridging reference resolution (bos et al, 1995).</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
further, it has also been argued that qualia structures and lexical semantic relations in general have applications in information retrieval (voorhees, 1994; pustejovsky et al, 1993).<papid> J93-2005 </papid></citsent>
<aftsection>
<nextsent>one major bottleneck however is that currently qualia structures need to be created by hand, which is probably also the reason why there are no practical system using qualiastructures, but lot of systems using globally available resources such as wordnet (fellbaum, 1998) or framenet1 1http://framenet.icsi.berkeley.edu/as source of lexical/world knowledge.
</nextsent>
<nextsent>the work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the web.
</nextsent>
<nextsent>the approach is inspired in recent work on using the web to identify instances of relation of interest such as in (markert et al, 2003) and (cimiano and staab, 2004).
</nextsent>
<nextsent>these approaches are in essence combination of the usage of lexico-syntactic pattens conveying certain relation of interest such as in (hearst, 1992), <papid> C92-2082 </papid>charniak and berland, 1999), (iwanskaet al, 2000) or (poesio et al, 2002) with the idea of using the web as big corpus (resnik and smith, 2003), (<papid> J03-3002 </papid>grefenstette, 1999), (keller et al, 2002).<papid> W02-1030 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4330">
<title id=" W05-1004.xml">automatically learning qualia structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the web.
</prevsent>
<prevsent>the approach is inspired in recent work on using the web to identify instances of relation of interest such as in (markert et al, 2003) and (cimiano and staab, 2004).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
these approaches are in essence combination of the usage of lexico-syntactic pattens conveying certain relation of interest such as in (hearst, 1992), <papid> C92-2082 </papid>charniak and berland, 1999), (iwanskaet al, 2000) or (poesio et al, 2002) with the idea of using the web as big corpus (resnik and smith, 2003), (<papid> J03-3002 </papid>grefenstette, 1999), (keller et al, 2002).<papid> W02-1030 </papid></citsent>
<aftsection>
<nextsent>the idea of learning qualia structures from the web is not only very practical, it is in fact principled one.while single lexicographers creating qualia structures or lexicon entries in general - might take very subjective decisions, the structures learned from the web do not mirror the view of single person, but of the whole world as represented on the world wide web.
</nextsent>
<nextsent>thus, an approach learning qualia structures from the web is in principle more reliable than letting lexicographers craft lexical entries on their own.
</nextsent>
<nextsent>obviously, on the other hand, usingan automatic web based approach yields also lot of inappropriate results which are due to 1) errors produced by the linguistic analysis (e.g. part-of-speech tagging), 2) idiosyncrasies of ranking algorithms of search machines, 3) the fact that the web or in particular search engines are to great extent commercially biased, 4) the fact that people also publish erroneous information on the web, and 5) lexical ambiguities.
</nextsent>
<nextsent>because of these reasons our aim is in fact not to replace lexicographers, but to support them in the task of creating qualia structures on the basisof the automatically learned qualia structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4333">
<title id=" W05-1004.xml">automatically learning qualia structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the web.
</prevsent>
<prevsent>the approach is inspired in recent work on using the web to identify instances of relation of interest such as in (markert et al, 2003) and (cimiano and staab, 2004).
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
these approaches are in essence combination of the usage of lexico-syntactic pattens conveying certain relation of interest such as in (hearst, 1992), <papid> C92-2082 </papid>charniak and berland, 1999), (iwanskaet al, 2000) or (poesio et al, 2002) with the idea of using the web as big corpus (resnik and smith, 2003), (<papid> J03-3002 </papid>grefenstette, 1999), (keller et al, 2002).<papid> W02-1030 </papid></citsent>
<aftsection>
<nextsent>the idea of learning qualia structures from the web is not only very practical, it is in fact principled one.while single lexicographers creating qualia structures or lexicon entries in general - might take very subjective decisions, the structures learned from the web do not mirror the view of single person, but of the whole world as represented on the world wide web.
</nextsent>
<nextsent>thus, an approach learning qualia structures from the web is in principle more reliable than letting lexicographers craft lexical entries on their own.
</nextsent>
<nextsent>obviously, on the other hand, usingan automatic web based approach yields also lot of inappropriate results which are due to 1) errors produced by the linguistic analysis (e.g. part-of-speech tagging), 2) idiosyncrasies of ranking algorithms of search machines, 3) the fact that the web or in particular search engines are to great extent commercially biased, 4) the fact that people also publish erroneous information on the web, and 5) lexical ambiguities.
</nextsent>
<nextsent>because of these reasons our aim is in fact not to replace lexicographers, but to support them in the task of creating qualia structures on the basisof the automatically learned qualia structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4334">
<title id=" W05-1004.xml">automatically learning qualia structures from the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper addresses this issue and presents an approach to automatically learning qualia structures for nominals from the web.
</prevsent>
<prevsent>the approach is inspired in recent work on using the web to identify instances of relation of interest such as in (markert et al, 2003) and (cimiano and staab, 2004).
</prevsent>
</prevsection>
<citsent citstr=" W02-1030 ">
these approaches are in essence combination of the usage of lexico-syntactic pattens conveying certain relation of interest such as in (hearst, 1992), <papid> C92-2082 </papid>charniak and berland, 1999), (iwanskaet al, 2000) or (poesio et al, 2002) with the idea of using the web as big corpus (resnik and smith, 2003), (<papid> J03-3002 </papid>grefenstette, 1999), (keller et al, 2002).<papid> W02-1030 </papid></citsent>
<aftsection>
<nextsent>the idea of learning qualia structures from the web is not only very practical, it is in fact principled one.while single lexicographers creating qualia structures or lexicon entries in general - might take very subjective decisions, the structures learned from the web do not mirror the view of single person, but of the whole world as represented on the world wide web.
</nextsent>
<nextsent>thus, an approach learning qualia structures from the web is in principle more reliable than letting lexicographers craft lexical entries on their own.
</nextsent>
<nextsent>obviously, on the other hand, usingan automatic web based approach yields also lot of inappropriate results which are due to 1) errors produced by the linguistic analysis (e.g. part-of-speech tagging), 2) idiosyncrasies of ranking algorithms of search machines, 3) the fact that the web or in particular search engines are to great extent commercially biased, 4) the fact that people also publish erroneous information on the web, and 5) lexical ambiguities.
</nextsent>
<nextsent>because of these reasons our aim is in fact not to replace lexicographers, but to support them in the task of creating qualia structures on the basisof the automatically learned qualia structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4374">
<title id=" W04-2801.xml">robustness versus fidelity in natural language understanding </title>
<section> spelling correction.  </section>
<citcontext>
<prevsection>
<prevsent>in section 7, we discuss how we calculate global confidence scores andlink references to simulated objects back to the users referring expression.
</prevsent>
<prevsent>nubee domain reasoner (beer) dialogue history response generation figure 1: nlu-centric diagram of beetle
</prevsent>
</prevsection>
<citsent citstr=" P98-1059 ">
nubees spelling corrector (elmi and evens, 1998) <papid> P98-1059 </papid>and robust parser are both part of the carmel workbench and the interface between the two is predefined.</citsent>
<aftsection>
<nextsent>the spelling corrector uses the parsers lexicon as its dictionary and attempts to fix spelling and typing errors in known words.
</nextsent>
<nextsent>since the parsers lexicon is typically much smaller than lexical database such as wordnet (miller, 1990), thereis reduction in token ambiguity (i.e., the number of possible replacements to consider) but the spelling of unknown words will not be corrected.
</nextsent>
<nextsent>the simplification is also made that known words are never misspelled versions of other known words (e.g., typing their?
</nextsent>
<nextsent>instead of there?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4375">
<title id=" W04-2801.xml">robustness versus fidelity in natural language understanding </title>
<section> carmel workbench.  </section>
<citcontext>
<prevsection>
<prevsent>semantic constructor functions are compiled automatically from this specification and then linked into lexical entries?
</prevsent>
<prevsent>(rose?, 2000, p. 311).
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
carmel comes with wide-coverage english grammar that is compatible with the wide-coverage comlex lexicon (grishman et al, 1994).<papid> C94-1042 </papid></citsent>
<aftsection>
<nextsent>for each comlex entry that we wanted to add into nubees lexicon, we specified its meaning as shown below for the words connect?, battery?, and wire?.
</nextsent>
<nextsent>connect: connect?, subject- agent, object- theme, modifier- destination battery: battery?
</nextsent>
<nextsent>wire: wire?
</nextsent>
<nextsent>this simplified example of the meaning specification assigns predicate to each word, and in the case of averb such as connect?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4376">
<title id=" W04-2801.xml">robustness versus fidelity in natural language understanding </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>however, carmels two-stage interpretation process (i.e., domain-independent parsing stage and domain-dependent predicate mapping stage) is not idiosyncratic to the carmel workbench.
</prevsent>
<prevsent>dzikovska et al (2002) adopt such two stage approach because their nlu sub-system is used in multiple domains (e.g., transportation planning, medication advice) necessitating reuse of resources wherever possible.
</prevsent>
</prevsection>
<citsent citstr=" P00-1018 ">
milward (2000)<papid> P00-1018 </papid>uses two stage approach because it increases robust ness.</citsent>
<aftsection>
<nextsent>when the parser is not able to build parse tree covering the entire input, there will still be semantic chart composed of partial parses and their associated semantic feature values.
</nextsent>
<nextsent>for the domain of airline flight information, milward defines post-processing rules that scan this semantic chart looking for information such as departure times.
</nextsent>
<nextsent>our goal in this paper was to highlight the architectural trade-offs of such features on controlling fidelity.
</nextsent>
<nextsent>our search process for unknown word handling is rudimentary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4377">
<title id=" W04-2801.xml">robustness versus fidelity in natural language understanding </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>such distance metrics take into account factors such asthe overall depth of the wordnet taxonomy and the frequency of synsets in corpus, and will allow us to better control the search process.
</prevsent>
<prevsent>although we know of no work on using wordnet to handle unknown words during interpretation, there iswork on using wordnet for lexical variation during generation.
</prevsent>
</prevsection>
<citsent citstr=" W98-0718 ">
jing (1998) <papid> W98-0718 </papid>presents an algorithm for converting wordnet into domain-specific taxonomy of replaceable words.</citsent>
<aftsection>
<nextsent>first, words and synsets are removed that do not appear in corpus representative of the domain.the senses of verb arguments in the corpus are disam biguated based on the intuition that words appearing as the same argument to the same verb should have senses close to each other in wordnet.
</nextsent>
<nextsent>consider an example from jings domain of generating basketball news reports.
</nextsent>
<nextsent>the verb add?
</nextsent>
<nextsent>takes words such as rebound?,throw?, and shot?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4378">
<title id=" W05-0826.xml">combining linguistic data views for phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main motivation behind our work is to introduce linguistic information, other than lexical units,to the process of building word and phrase alignments.
</prevsent>
<prevsent>many other authors have tried to do so.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
see (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>koehn and knight, 2002), (koehn et al, 2003), (<papid> N03-1017 </papid>schafer and yarowsky, 2003) <papid> W03-1002 </papid>and (gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>far from full syntactic complexity, we suggest togo back to the simpler alignment methods first described by (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words)and shallow parsing (chunks).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4379">
<title id=" W05-0826.xml">combining linguistic data views for phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main motivation behind our work is to introduce linguistic information, other than lexical units,to the process of building word and phrase alignments.
</prevsent>
<prevsent>many other authors have tried to do so.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
see (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>koehn and knight, 2002), (koehn et al, 2003), (<papid> N03-1017 </papid>schafer and yarowsky, 2003) <papid> W03-1002 </papid>and (gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>far from full syntactic complexity, we suggest togo back to the simpler alignment methods first described by (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words)and shallow parsing (chunks).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4380">
<title id=" W05-0826.xml">combining linguistic data views for phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main motivation behind our work is to introduce linguistic information, other than lexical units,to the process of building word and phrase alignments.
</prevsent>
<prevsent>many other authors have tried to do so.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
see (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>koehn and knight, 2002), (koehn et al, 2003), (<papid> N03-1017 </papid>schafer and yarowsky, 2003) <papid> W03-1002 </papid>and (gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>far from full syntactic complexity, we suggest togo back to the simpler alignment methods first described by (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words)and shallow parsing (chunks).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4381">
<title id=" W05-0826.xml">combining linguistic data views for phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main motivation behind our work is to introduce linguistic information, other than lexical units,to the process of building word and phrase alignments.
</prevsent>
<prevsent>many other authors have tried to do so.
</prevsent>
</prevsection>
<citsent citstr=" W03-1002 ">
see (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>koehn and knight, 2002), (koehn et al, 2003), (<papid> N03-1017 </papid>schafer and yarowsky, 2003) <papid> W03-1002 </papid>and (gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>far from full syntactic complexity, we suggest togo back to the simpler alignment methods first described by (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words)and shallow parsing (chunks).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4382">
<title id=" W05-0826.xml">combining linguistic data views for phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main motivation behind our work is to introduce linguistic information, other than lexical units,to the process of building word and phrase alignments.
</prevsent>
<prevsent>many other authors have tried to do so.
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
see (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>koehn and knight, 2002), (koehn et al, 2003), (<papid> N03-1017 </papid>schafer and yarowsky, 2003) <papid> W03-1002 </papid>and (gildea, 2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>far from full syntactic complexity, we suggest togo back to the simpler alignment methods first described by (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words)and shallow parsing (chunks).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4383">
<title id=" W05-0826.xml">combining linguistic data views for phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many other authors have tried to do so.
</prevsent>
<prevsent>see (och and ney, 2000), (<papid> P00-1056 </papid>yamada and knight, 2001), (<papid> P01-1067 </papid>koehn and knight, 2002), (koehn et al, 2003), (<papid> N03-1017 </papid>schafer and yarowsky, 2003) <papid> W03-1002 </papid>and (gildea, 2003).<papid> P03-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
far from full syntactic complexity, we suggest togo back to the simpler alignment methods first described by (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words)and shallow parsing (chunks).
</nextsent>
<nextsent>in order to avoid confusion so forth we will talk about tokens instead of words as the minimal alignment unit.
</nextsent>
<nextsent>apart from redefining the scope of the alignment unit, we may use different degrees of linguistic annotation.
</nextsent>
<nextsent>we introduce the general concept of data view, which is defined as any possible representation of the information contained in bitext.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4384">
<title id=" W05-1614.xml">computational mechanisms for pun generation </title>
<section> previous work: self-contained puns.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 discussion of the mechanisms.
</prevsent>
<prevsent>the mechanisms summarised here were designed solely to produce puns, but the notions of schema?
</prevsent>
</prevsection>
<citsent citstr=" P83-1022 ">
and template are not radically (or interestingly) different from those established within mainstream nlg (e.g. [mckeown, 1985], [ku kich, 1983]).<papid> P83-1022 </papid></citsent>
<aftsection>
<nextsent>however, the way that this whole architecture is deployed is unusual.
</nextsent>
<nextsent>normally in nlg, we can reasonably make distinction between some background knowledge base (e.g. linguistic rules, lexicon, general facts about the domain) and some message which is to be conveyed.
</nextsent>
<nextsent>a typical schema-based system then matches its schemas against the message to determine applicability, with the background knowledge being called upon only as needed in the match.
</nextsent>
<nextsent>in contrast, the pun generators have only knowledge base, and do not start from message to be conveyed: they are random generators of arbitrary puns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4385">
<title id=" W05-1614.xml">computational mechanisms for pun generation </title>
<section> computing contextually integrated puns.  </section>
<citcontext>
<prevsection>
<prevsent>the definition also has few dis junctions, to further increase the search.
</prevsent>
<prevsent>hence, even non-constructive check(section 6.2) would involve significant amount of searching, particularly if navely implemented.some of the simpler cases considered below (e.g. substituting contextually-linked homophone) might fit naturally into nlg system based on constraint-satisfaction (cs) (cf.
</prevsent>
</prevsection>
<citsent citstr=" C00-2093 ">
[power, 2000]).<papid> C00-2093 </papid></citsent>
<aftsection>
<nextsent>however, cs methods would not completely remove the complexity problems involved in implementing the entire definition from section 5.
</nextsent>
<nextsent>cs reduces processing in cases where the possible values of the variables arewell-defined and easily enumerable, and evaluating individual constraints is relatively cheap; i.e. where the main computational load is in testing compatibility among chains of values.
</nextsent>
<nextsent>here, the main work is elsewhere.
</nextsent>
<nextsent>conditions such as testing whether some substring of some possible output string is similar to some well-known phrase would require computationally expensive enumeration of the basic values (possible sub strings of possible output texts), and non-trivial conditions (phonetic similarity) involving very large sets (all words and well-known phrases).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4386">
<title id=" W05-1614.xml">computational mechanisms for pun generation </title>
<section> computing contextually integrated puns.  </section>
<citcontext>
<prevsection>
<prevsent>hence, it may be difficult for high-level (early) stages of pipeline generator to make syntactic or lexical decisions which will result in puns, nor is it simple to effect revisions?
</prevsent>
<prevsent>to surface text which has been the outcome of much high-level processing.
</prevsent>
</prevsection>
<citsent citstr=" J00-2005 ">
there isnot space here to explore the large issue of surface-level constraints and their consequences for nlg architecture, but see [reiter, 2000] <papid> J00-2005 </papid>for some discussion.</citsent>
<aftsection>
<nextsent>puns are not the only forms in which surface constraints are central: poetry generation [manurung et al, 2000; gervas, 2002] makes comparably awkward demands.
</nextsent>
<nextsent>6.4 some possible devices.
</nextsent>
<nextsent>we can consider some possible ways in which an nlg system might include contextually integrated puns.
</nextsent>
<nextsent>substitution with identity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4387">
<title id=" W06-0119.xml">bmmbased chinese word segment or with word support model for the sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our cws is based on backward maximum matching with word support model (wsm) and con textual-based chinese unknown word identification.
</prevsent>
<prevsent>from the scored results and our experimental results, it shows wsm can improve our previous cws, which was reported at the sighan bakeoff 2005, about 1% of f-measure.
</prevsent>
</prevsection>
<citsent citstr=" I05-6003 ">
a high-performance chinese word segment or (cws) is critical processing stage to produce an intermediate result for later processes, such as search engines, text mining, word spell checking, text-to-speech and speech recognition, etc. as per (lin et al 1993; tsai et al 2003; tsai, 2005), <papid> I05-6003 </papid>the bottleneck for developing high performance cws is to comprise of high performance chinese unknown word identification (uwi).</citsent>
<aftsection>
<nextsent>it is because chinese is written without any separation between words and more than 50% words of the chinese texts in web corpus are out-of-vocabulary (tsai et al 2003).
</nextsent>
<nextsent>in our report for the sighan bakeoff 2005 (tsai, 2005), <papid> I05-6003 </papid>we have shown that highly performance of 99.1% f-measure can be achieved while bmm-based cws using perfect system dictionary (tsai, 2005).<papid> I05-6003 </papid></nextsent>
<nextsent>a perfect system dictionary means all word types of the dictionary are extracted from training and testing gold standard corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4394">
<title id=" W06-0119.xml">bmmbased chinese word segment or with word support model for the sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our report for the sighan bakeoff 2005 (tsai, 2005), <papid> I05-6003 </papid>we have shown that highly performance of 99.1% f-measure can be achieved while bmm-based cws using perfect system dictionary (tsai, 2005).<papid> I05-6003 </papid></prevsent>
<prevsent>a perfect system dictionary means all word types of the dictionary are extracted from training and testing gold standard corpus.</prevsent>
</prevsection>
<citsent citstr=" C96-1035 ">
conventionally, there are four approaches to develop cws: (1) dictionary-based approach (cheng et al 1999), especial forward and backward maximum matching (wong and chan, 1996); (<papid> C96-1035 </papid>2) linguistic approach based on syntax-semantic knowledge (chen et al 2002); (3) statistical approach based on statistical language model (slm) (sproat and shih, 1990; teahan et al 2000; <papid> J00-3004 </papid>gao et al 2003); <papid> P03-1035 </papid>and (4) hybrid approach trying to combine the benefits of dictionary-based, linguistic and statistical approaches (tsai et al 2003; ma and chen, 2003).<papid> W03-1726 </papid></citsent>
<aftsection>
<nextsent>in practice, statistical approaches are most widely used because their effective and reasonable performance.
</nextsent>
<nextsent>to develop uwi, there are three approaches: (1) statistical approach, researchers use common statistical features, such as maximum entropy (chieu et al 2002), association strength, mutual information, ambiguous matching, and multi-statistical features for unknown word detection and extraction; (2) linguistic approach, three major types of linguistic rules (knowledge): morphology, syntax, and semantics, are used to identify unknown words; and (3) hybrid approach, recently, one important trend of uwi follows hybrid approach so as to take advantage of both merits of statistical and linguistic approaches.
</nextsent>
<nextsent>statistical approaches are simple and efficient whereas linguistic approaches are effective in identifying low frequency unknown words (chen et al 2002).
</nextsent>
<nextsent>to develop wsd, there are two major types of word segmentation ambiguities while there are no unknown word problems with them: (1) overlap ambiguity (oa).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4395">
<title id=" W06-0119.xml">bmmbased chinese word segment or with word support model for the sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our report for the sighan bakeoff 2005 (tsai, 2005), <papid> I05-6003 </papid>we have shown that highly performance of 99.1% f-measure can be achieved while bmm-based cws using perfect system dictionary (tsai, 2005).<papid> I05-6003 </papid></prevsent>
<prevsent>a perfect system dictionary means all word types of the dictionary are extracted from training and testing gold standard corpus.</prevsent>
</prevsection>
<citsent citstr=" J00-3004 ">
conventionally, there are four approaches to develop cws: (1) dictionary-based approach (cheng et al 1999), especial forward and backward maximum matching (wong and chan, 1996); (<papid> C96-1035 </papid>2) linguistic approach based on syntax-semantic knowledge (chen et al 2002); (3) statistical approach based on statistical language model (slm) (sproat and shih, 1990; teahan et al 2000; <papid> J00-3004 </papid>gao et al 2003); <papid> P03-1035 </papid>and (4) hybrid approach trying to combine the benefits of dictionary-based, linguistic and statistical approaches (tsai et al 2003; ma and chen, 2003).<papid> W03-1726 </papid></citsent>
<aftsection>
<nextsent>in practice, statistical approaches are most widely used because their effective and reasonable performance.
</nextsent>
<nextsent>to develop uwi, there are three approaches: (1) statistical approach, researchers use common statistical features, such as maximum entropy (chieu et al 2002), association strength, mutual information, ambiguous matching, and multi-statistical features for unknown word detection and extraction; (2) linguistic approach, three major types of linguistic rules (knowledge): morphology, syntax, and semantics, are used to identify unknown words; and (3) hybrid approach, recently, one important trend of uwi follows hybrid approach so as to take advantage of both merits of statistical and linguistic approaches.
</nextsent>
<nextsent>statistical approaches are simple and efficient whereas linguistic approaches are effective in identifying low frequency unknown words (chen et al 2002).
</nextsent>
<nextsent>to develop wsd, there are two major types of word segmentation ambiguities while there are no unknown word problems with them: (1) overlap ambiguity (oa).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4396">
<title id=" W06-0119.xml">bmmbased chinese word segment or with word support model for the sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our report for the sighan bakeoff 2005 (tsai, 2005), <papid> I05-6003 </papid>we have shown that highly performance of 99.1% f-measure can be achieved while bmm-based cws using perfect system dictionary (tsai, 2005).<papid> I05-6003 </papid></prevsent>
<prevsent>a perfect system dictionary means all word types of the dictionary are extracted from training and testing gold standard corpus.</prevsent>
</prevsection>
<citsent citstr=" P03-1035 ">
conventionally, there are four approaches to develop cws: (1) dictionary-based approach (cheng et al 1999), especial forward and backward maximum matching (wong and chan, 1996); (<papid> C96-1035 </papid>2) linguistic approach based on syntax-semantic knowledge (chen et al 2002); (3) statistical approach based on statistical language model (slm) (sproat and shih, 1990; teahan et al 2000; <papid> J00-3004 </papid>gao et al 2003); <papid> P03-1035 </papid>and (4) hybrid approach trying to combine the benefits of dictionary-based, linguistic and statistical approaches (tsai et al 2003; ma and chen, 2003).<papid> W03-1726 </papid></citsent>
<aftsection>
<nextsent>in practice, statistical approaches are most widely used because their effective and reasonable performance.
</nextsent>
<nextsent>to develop uwi, there are three approaches: (1) statistical approach, researchers use common statistical features, such as maximum entropy (chieu et al 2002), association strength, mutual information, ambiguous matching, and multi-statistical features for unknown word detection and extraction; (2) linguistic approach, three major types of linguistic rules (knowledge): morphology, syntax, and semantics, are used to identify unknown words; and (3) hybrid approach, recently, one important trend of uwi follows hybrid approach so as to take advantage of both merits of statistical and linguistic approaches.
</nextsent>
<nextsent>statistical approaches are simple and efficient whereas linguistic approaches are effective in identifying low frequency unknown words (chen et al 2002).
</nextsent>
<nextsent>to develop wsd, there are two major types of word segmentation ambiguities while there are no unknown word problems with them: (1) overlap ambiguity (oa).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4397">
<title id=" W06-0119.xml">bmmbased chinese word segment or with word support model for the sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our report for the sighan bakeoff 2005 (tsai, 2005), <papid> I05-6003 </papid>we have shown that highly performance of 99.1% f-measure can be achieved while bmm-based cws using perfect system dictionary (tsai, 2005).<papid> I05-6003 </papid></prevsent>
<prevsent>a perfect system dictionary means all word types of the dictionary are extracted from training and testing gold standard corpus.</prevsent>
</prevsection>
<citsent citstr=" W03-1726 ">
conventionally, there are four approaches to develop cws: (1) dictionary-based approach (cheng et al 1999), especial forward and backward maximum matching (wong and chan, 1996); (<papid> C96-1035 </papid>2) linguistic approach based on syntax-semantic knowledge (chen et al 2002); (3) statistical approach based on statistical language model (slm) (sproat and shih, 1990; teahan et al 2000; <papid> J00-3004 </papid>gao et al 2003); <papid> P03-1035 </papid>and (4) hybrid approach trying to combine the benefits of dictionary-based, linguistic and statistical approaches (tsai et al 2003; ma and chen, 2003).<papid> W03-1726 </papid></citsent>
<aftsection>
<nextsent>in practice, statistical approaches are most widely used because their effective and reasonable performance.
</nextsent>
<nextsent>to develop uwi, there are three approaches: (1) statistical approach, researchers use common statistical features, such as maximum entropy (chieu et al 2002), association strength, mutual information, ambiguous matching, and multi-statistical features for unknown word detection and extraction; (2) linguistic approach, three major types of linguistic rules (knowledge): morphology, syntax, and semantics, are used to identify unknown words; and (3) hybrid approach, recently, one important trend of uwi follows hybrid approach so as to take advantage of both merits of statistical and linguistic approaches.
</nextsent>
<nextsent>statistical approaches are simple and efficient whereas linguistic approaches are effective in identifying low frequency unknown words (chen et al 2002).
</nextsent>
<nextsent>to develop wsd, there are two major types of word segmentation ambiguities while there are no unknown word problems with them: (1) overlap ambiguity (oa).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4398">
<title id=" W06-0119.xml">bmmbased chinese word segment or with word support model for the sighan bakeoff 2006 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are: (1) lack of unknown word (luw), it means segmentation error occurred by lack of an unknown word in the system dictionary, and (2) error identified word (eiw), it means segmentation error occurred by an error identified unknown words.
</prevsent>
<prevsent>the goal of this paper is to report the approach and experiment results of our backward maximum matching-based (bmm-based) cws with word support model (wsm) for the sighan bakeoff 2006.
</prevsent>
</prevsection>
<citsent citstr=" P06-2108 ">
in (tsai, 2006), <papid> P06-2108 </papid>wsm has been shown effectively to improve chinese input system.</citsent>
<aftsection>
<nextsent>in the third bakeoff, our cws is mainly addressed on improving its performance of oa/ca disambiguation by wsm.
</nextsent>
<nextsent>we show that wsm is able to improve our bmm-based cws, which reported at the sighan bakeoff 2005, about 1% of f-measure.
</nextsent>
<nextsent>the remainder of this paper is arranged as follows.
</nextsent>
<nextsent>in section 2, we present the details of our bmm-based cws comprised of wsm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4410">
<title id=" W05-0811.xml">models for inuktitutenglish word alignment </title>
<section> alignment by weighted finite-state.  </section>
<citcontext>
<prevsection>
<prevsent>english alignment.
</prevsent>
<prevsent>our weighted finite-state transducer(wfst) alignment model, illustrated in figure 1, structurally enforces monotonicity and 1-to-n cardinality, and exploits sub lexical information by incorporating association scores between english words and inuktitut word sub strings, based on co-occurrence in aligned sentences.for each english word, an association score was computed not only with each inuktitut word, but also with each inuktitut character string of length ranging from2 to 10 characters.
</prevsent>
</prevsection>
<citsent citstr=" W03-0320 ">
this is similar to the technique described in martinet al (2003) <papid> W03-0320 </papid>as part of their construction of bilingual glossary from english-inuktitut bi text.</citsent>
<aftsection>
<nextsent>however, our goal is different and we keep all the english-inuktitut associations, rather than selecting onlythe best?
</nextsent>
<nextsent>ones using greedy method, as do they.
</nextsent>
<nextsent>additionally, before extracting all sub strings from each inuk titut word, we added special character to the words beginning and end (e.g., makkuttut ? makkuttut ), in order to exploit any preferences for word-initial or -final placement.
</nextsent>
<nextsent>the heuristic association score chosen was p(worde |wordi) ? p(wordi |worde), computed over allthe aligned sentence pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4411">
<title id=" W05-0811.xml">models for inuktitutenglish word alignment </title>
<section> english-inuktitut transliteration.  </section>
<citcontext>
<prevsection>
<prevsent>and common two-vowel sequences were also mapped to unique single characters to elicit higher-quality results from the memo ryless transduction model employed.
</prevsent>
<prevsent>some results of the transducer training are displayed in table 2(b).
</prevsent>
</prevsection>
<citsent citstr=" P04-3032 ">
probabilistic fst weight training was accomplished using thedyna modeling language and dynamite parameter optimization toolkit (eisner et al 2004).<papid> P04-3032 </papid></citsent>
<aftsection>
<nextsent>the transliteration modeling described here differs from such previous transliteration work as stalls and knight (1998) in that there is no explicit modeling of pronunciation, only direct transduction between written forms.
</nextsent>
<nextsent>in applying transliteration on trial/test data, the following criteria were used to select english words for transliteration: (1) word is capitalized (2) word is not in the exclusion list.4 for the top-ranked transliteration of the english word present in the inuktitut sentence, all occurrences of that word in that sentence are marked as aligned to the english word.we have yet to evaluate english-inuktitut transliteration in isolation on large test set.
</nextsent>
<nextsent>however, accuracy on the workshop trial data was 4/4 hypotheses correct, and on test data 2/6 correct.
</nextsent>
<nextsent>of the 4 incorrect test hypotheses, 2 were mistakes in identifying the correct transliteration, and 2 mistakes resulted from attempting to trans literate an english word such as councillors which should not be transliterated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4412">
<title id=" W05-0811.xml">models for inuktitutenglish word alignment </title>
<section> ibm model 4 alignments.  </section>
<citcontext>
<prevsection>
<prevsent>even with relatively low accuracy, the transliteration model, which is used only as an individual voter in combination systems,is unlikely to vote for the incorrect choice of another system.
</prevsent>
<prevsent>its purpose under system combination is to push good alignment link hypothesis up to the required vote threshold.5
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
as baseline and contributor to our combination systems, we ran giza++ (och and ney, 2000), <papid> P00-1056 </papid>to produce alignments based on ibm model 4.</citsent>
<aftsection>
<nextsent>the ibm alignment models are asymmetric, requiring that one language be idenitifed as the e? language, whose words are allowed many links each, and the other as the f? language, whose words are allowed at most one link each.
</nextsent>
<nextsent>although the observed alignment cardinal ities naturally suggest identifying inuktitut as the e? language and english as the f? language, we ran both directions for com pleteness.as crude first attempt to capture sub lexical correspondences in the absence of method for morpheme segmentation, we developed rough syllable segmenter (spending approximately 2 person-hours), ran giza++ to produce alignments treating the syllables as words, and chose, for each english word, the inuktitut word or words the largest number of whose syllables were linked to it.in the nomenclature of our results tables, giza++ syllabized refers to the latter system, giza++ e(1)-i(n) represents giza++ run with english as the e? language, and giza++ e(n)-i(1) sets english as the f? language.
</nextsent>
<nextsent>methods we observed the 4 main systems (3 giza++ variants andwfst) to have significantly different performance profiles in terms of precision and recall.
</nextsent>
<nextsent>consistently, wfst 4exclusion list was compiled as follows: (a) capitalized words in 2000 randomly selected english training sentences were examined, words such as clerk, federation, and fisheries, which are frequently capitalized but should not be transliterated, were put into the exclusion list; in addition, any word with frequency   50 in the training corpus was excluded, on the rationale that common-enough words would have well-estimated translation probabilities already.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4413">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, there are efficientdynamic-programming versions of the em algorithm for several classes of models that are important in computational linguistics, such as the forward backward algorithm for training hidden markov models (hmms) and the inside-outside algorithm for training probabilistic context-free grammars (pcfgs).
</prevsent>
<prevsent>despite the advantages of maximum likelihood estimation and its implementation via various instantiations of the em algorithm, it is widely regarded as ineffective for unsupervised language learning.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
merialdo (1994) <papid> J94-2001 </papid>showed that with only tiny amount of tagged training data, supervised training of an hmm part-of-speech tagger outperformed unsupervised em training.</citsent>
<aftsection>
<nextsent>later results (e.g. brill (1995)) <papid> W95-0101 </papid>seemed to indicate that other methods of unsupervised learning could be more effective (although the work of banko and moore (2004) suggests that the difference may be far less than previ 112 ously assumed).</nextsent>
<nextsent>klein and manning (2001), <papid> W01-0714 </papid>klein and manning (2002) <papid> P02-1017 </papid>recently achieved more encouraging results using an em-like algorithm to induce syntactic constituent grammars, based on deficient probability model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4414">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite the advantages of maximum likelihood estimation and its implementation via various instantiations of the em algorithm, it is widely regarded as ineffective for unsupervised language learning.
</prevsent>
<prevsent>merialdo (1994) <papid> J94-2001 </papid>showed that with only tiny amount of tagged training data, supervised training of an hmm part-of-speech tagger outperformed unsupervised em training.</prevsent>
</prevsection>
<citsent citstr=" W95-0101 ">
later results (e.g. brill (1995)) <papid> W95-0101 </papid>seemed to indicate that other methods of unsupervised learning could be more effective (although the work of banko and moore (2004) suggests that the difference may be far less than previ 112 ously assumed).</citsent>
<aftsection>
<nextsent>klein and manning (2001), <papid> W01-0714 </papid>klein and manning (2002) <papid> P02-1017 </papid>recently achieved more encouraging results using an em-like algorithm to induce syntactic constituent grammars, based on deficient probability model.</nextsent>
<nextsent>it has been suggested that em often yield poor results because it is overly sensitive to initial parameter values and tends to converge on likelihood maxima that are local, but not global (carroll and charniak, 1992).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4415">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>merialdo (1994) <papid> J94-2001 </papid>showed that with only tiny amount of tagged training data, supervised training of an hmm part-of-speech tagger outperformed unsupervised em training.</prevsent>
<prevsent>later results (e.g. brill (1995)) <papid> W95-0101 </papid>seemed to indicate that other methods of unsupervised learning could be more effective (although the work of banko and moore (2004) suggests that the difference may be far less than previ 112 ously assumed).</prevsent>
</prevsection>
<citsent citstr=" W01-0714 ">
klein and manning (2001), <papid> W01-0714 </papid>klein and manning (2002) <papid> P02-1017 </papid>recently achieved more encouraging results using an em-like algorithm to induce syntactic constituent grammars, based on deficient probability model.</citsent>
<aftsection>
<nextsent>it has been suggested that em often yield poor results because it is overly sensitive to initial parameter values and tends to converge on likelihood maxima that are local, but not global (carroll and charniak, 1992).
</nextsent>
<nextsent>in this paper, we present series of experiments indicating that for the task of learning syllable structure grammar, the initial parameter weights are not crucial.
</nextsent>
<nextsent>rather, it is the choice of the model class, i.e., the representational bias, that makes the difference between successful and unsuccessful learning.
</nextsent>
<nextsent>in the remainder of this paper, we first describe the task itself and the structure of the two different classes of models we experimented with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4416">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>merialdo (1994) <papid> J94-2001 </papid>showed that with only tiny amount of tagged training data, supervised training of an hmm part-of-speech tagger outperformed unsupervised em training.</prevsent>
<prevsent>later results (e.g. brill (1995)) <papid> W95-0101 </papid>seemed to indicate that other methods of unsupervised learning could be more effective (although the work of banko and moore (2004) suggests that the difference may be far less than previ 112 ously assumed).</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
klein and manning (2001), <papid> W01-0714 </papid>klein and manning (2002) <papid> P02-1017 </papid>recently achieved more encouraging results using an em-like algorithm to induce syntactic constituent grammars, based on deficient probability model.</citsent>
<aftsection>
<nextsent>it has been suggested that em often yield poor results because it is overly sensitive to initial parameter values and tends to converge on likelihood maxima that are local, but not global (carroll and charniak, 1992).
</nextsent>
<nextsent>in this paper, we present series of experiments indicating that for the task of learning syllable structure grammar, the initial parameter weights are not crucial.
</nextsent>
<nextsent>rather, it is the choice of the model class, i.e., the representational bias, that makes the difference between successful and unsuccessful learning.
</nextsent>
<nextsent>in the remainder of this paper, we first describe the task itself and the structure of the two different classes of models we experimented with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4417">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> statistical parsing of syllable structure.  </section>
<citcontext>
<prevsection>
<prevsent>we conclude with discussion of the implications of our experiments.
</prevsent>
<prevsent>knowledge of syllable structure is important for correct pronunciation of spoken words, since certain phonemes may be pronounced differently depending on their position in the syllable.
</prevsent>
</prevsection>
<citsent citstr=" P01-1053 ">
a number of different supervised machine learning techniques have been applied to the task of automatic syllable boundary detection, including decision-tree classifiers (van den bosch et al, 1998), weighted finite state transducers (kiraz and mobius, 1998),and pcfgs (muller, 2001; <papid> P01-1053 </papid>muller, 2002).<papid> W02-0608 </papid></citsent>
<aftsection>
<nextsent>there searchers presenting these systems have generally argued from the engineering standpoint that syllable boundary detection is useful for pronunciation of unknown words in text-to-speech systems.
</nextsent>
<nextsent>our motivation is more scientific one: we are interested in the kinds of procedures and representations that can lead to successful unsupervised language learning in both computers and humans.
</nextsent>
<nextsent>our work has some similarity to that of muller, who trains pcfg of syllable structure from corpus of words with syllable boundaries marked.we, too, use model defined by grammar to describe syllable structure.1 however, our work differs from mullers in that it focuses on how to learn the models parameters in an unsupervised manner.
</nextsent>
<nextsent>several researchers have worked on unsupervised learning of phonotactic constraints and word segmentation (elman, 2003; brent, 1999; venkataraman, 2001), <papid> J01-3002 </papid>but to our knowledge there is no previously published work on unsupervised learning of syllable structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4418">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> statistical parsing of syllable structure.  </section>
<citcontext>
<prevsection>
<prevsent>we conclude with discussion of the implications of our experiments.
</prevsent>
<prevsent>knowledge of syllable structure is important for correct pronunciation of spoken words, since certain phonemes may be pronounced differently depending on their position in the syllable.
</prevsent>
</prevsection>
<citsent citstr=" W02-0608 ">
a number of different supervised machine learning techniques have been applied to the task of automatic syllable boundary detection, including decision-tree classifiers (van den bosch et al, 1998), weighted finite state transducers (kiraz and mobius, 1998),and pcfgs (muller, 2001; <papid> P01-1053 </papid>muller, 2002).<papid> W02-0608 </papid></citsent>
<aftsection>
<nextsent>there searchers presenting these systems have generally argued from the engineering standpoint that syllable boundary detection is useful for pronunciation of unknown words in text-to-speech systems.
</nextsent>
<nextsent>our motivation is more scientific one: we are interested in the kinds of procedures and representations that can lead to successful unsupervised language learning in both computers and humans.
</nextsent>
<nextsent>our work has some similarity to that of muller, who trains pcfg of syllable structure from corpus of words with syllable boundaries marked.we, too, use model defined by grammar to describe syllable structure.1 however, our work differs from mullers in that it focuses on how to learn the models parameters in an unsupervised manner.
</nextsent>
<nextsent>several researchers have worked on unsupervised learning of phonotactic constraints and word segmentation (elman, 2003; brent, 1999; venkataraman, 2001), <papid> J01-3002 </papid>but to our knowledge there is no previously published work on unsupervised learning of syllable structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4419">
<title id=" W05-0615.xml">representational bias in unsupervised learning of syllable structure </title>
<section> statistical parsing of syllable structure.  </section>
<citcontext>
<prevsection>
<prevsent>our motivation is more scientific one: we are interested in the kinds of procedures and representations that can lead to successful unsupervised language learning in both computers and humans.
</prevsent>
<prevsent>our work has some similarity to that of muller, who trains pcfg of syllable structure from corpus of words with syllable boundaries marked.we, too, use model defined by grammar to describe syllable structure.1 however, our work differs from mullers in that it focuses on how to learn the models parameters in an unsupervised manner.
</prevsent>
</prevsection>
<citsent citstr=" J01-3002 ">
several researchers have worked on unsupervised learning of phonotactic constraints and word segmentation (elman, 2003; brent, 1999; venkataraman, 2001), <papid> J01-3002 </papid>but to our knowledge there is no previously published work on unsupervised learning of syllable structure.</citsent>
<aftsection>
<nextsent>in the work described here, we experimented with two different classes of models of syllable structure.
</nextsent>
<nextsent>both of these model classes are presented as pcfgs.
</nextsent>
<nextsent>the first model class, described in muller (2002), <papid> W02-0608 </papid>encodes information about the positions within word or syllable in which each phoneme is likely to appear.</nextsent>
<nextsent>in this positional model, each syllable is labeled as initial (i), medial (m), final (f), or asthe one syllable in monosyllabic word (o).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4423">
<title id=" W05-1503.xml">switch graphs for parsing type logical grammars </title>
<section> parsing with switch graphs.  </section>
<citcontext>
<prevsection>
<prevsent>the planar connection of all liter als into proof structure is straightforward to implement.
</prevsent>
<prevsent>axiom links are simply added in such way that planarity is maintained until complete linkage is found.
</prevsent>
</prevsection>
<citsent citstr=" J00-3002 ">
in our shift-reduce-style parser, planarity is maintained by stack in the usual way (morrill 2000).<papid> J00-3002 </papid></citsent>
<aftsection>
<nextsent>for dynamic programming, we combine switch graphs in the cells in cocke-kasami-younger (cky) parser (morrill 1996).
</nextsent>
<nextsent>the main challenge is enforcing dr-acyclicity, and this is the main focus of the rest of the paper.
</nextsent>
<nextsent>we introduce switch graphs, which not only maintain dr-acyclicity, but also lead the wayto normal form for well-formed sub sequence fragments of partial proof structure.
</nextsent>
<nextsent>this normal form underlies the packing of ambiguities in subderiva tions in exactly the same way as usual in dynamic programming parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4424">
<title id=" W04-2708.xml">prague czech english dependency treebank any hopes for a common annotation scheme </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the prague czech-english dependency treebank (pcedt) is project of creating czech-english syntactically annotated parallel corpus motivated by research in the field of machine translation.
</prevsent>
<prevsent>parallel data are needed for designing, training, and evaluation of both statistical and rule-based machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
since czech is language with relatively high degree of word-order freedom, and its sentences contain certain syntactic phenomena, such as discontinuous constituents(non-projective constructions), which cannot be straightforwardly handled using the annotation scheme of penn treebank (marcus et al, 1993; <papid> J93-2004 </papid>linguistic data consortium, 1999), based on phrase-structure trees, we decided to adopt for the pcedt the dependency-based annotation scheme of the prague dependency treebank ? pdt (lin guistic data consortium, 2001).</citsent>
<aftsection>
<nextsent>the pdt is annotated on three levels: morphological layer (lowest), analytic layer (middle) ? surface syntactic annotation, and tectogrammatical layer (highest) ? level of linguistic meaning.
</nextsent>
<nextsent>dependency trees, representing the sentence structure as concentrated around the verb and its valency, are used for the analytical and tectogrammatical levels, as proposed by functional generative description (sgall et al., 1986).
</nextsent>
<nextsent>in section 2, we describe the process of translating thepenn treebank into czech.
</nextsent>
<nextsent>section 3 sketches the general procedure for transforming phrase topology of penn treebank into dependency structure and describes the specific conversions into analytical and tectogrammatical representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4425">
<title id=" W04-2708.xml">prague czech english dependency treebank any hopes for a common annotation scheme </title>
<section> transformation of penn treebank.  </section>
<citcontext>
<prevsection>
<prevsent>dt an np-sbj-1 nn earthquake vbd struck jj northern np nnp california vp , , np-sbj-none *-1 s-adv vbg killing jjr more vp qp in than cd 50 np nns people . . figure 1: penn treebank annotation of the sentence an earthquake struck northern california, killing more than 50 people.?
</prevsent>
<prevsent>for the purpose of quantitative evaluation methods, such as nist or bleu, for measuring performance of translation systems, we selected test set of 515 sentences and had them re translated from czech into english by 4 different translator offices, two of them from the czech republic and two of them from the u.s.a.
</prevsent>
</prevsection>
<citsent citstr=" H01-1014 ">
phrase trees into dependency structure the transformation algorithm from phrase-structure topology into dependency one, similar to transformations described by xia and palmer (2001), <papid> H01-1014 </papid>works as follows: ? terminal nodes of the phrase are converted to nodes of the dependency tree.?</citsent>
<aftsection>
<nextsent>dependencies between nodes are established recursively: the root node of the dependency tree transformed from the head constituent of phrase becomes the governing node.
</nextsent>
<nextsent>the root nodes of the dependency trees transformed from the right and left siblings of the head constituent are attached as theleft and right children (dependent nodes) of the governing node, respectively.
</nextsent>
<nextsent>nodes representing traces are removed and their children are reattached to the parent of the trace.
</nextsent>
<nextsent>3.1 preprocessing of penn treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4426">
<title id=" W04-2708.xml">prague czech english dependency treebank any hopes for a common annotation scheme </title>
<section> automatic annotation of czech.  </section>
<citcontext>
<prevsection>
<prevsent>and hladka?
</prevsent>
<prevsent>(1998) tagging tools.
</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
czech analytical parsing consists of statistical dependency parser for czech ? either collins parser (collins et al, 1999) <papid> P99-1065 </papid>or charniak parser (charniak, 1999), both adapted to dependency grammar ? and module for automatic analytical function assignment ( zabokrtsky?</citsent>
<aftsection>
<nextsent>et al, 2002).
</nextsent>
<nextsent>when building the tectogrammatical structure, the analytical tree structure is converted into the tectogrammatical one.
</nextsent>
<nextsent>these transformations are described by linguistic rules (bohmova?, 2001).
</nextsent>
<nextsent>then, tectogrammatical functors are assigned by c4.5 classifier ( zabokrtsky?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4427">
<title id=" W04-2708.xml">prague czech english dependency treebank any hopes for a common annotation scheme </title>
<section> other resources included in pcedt.  </section>
<citcontext>
<prevsection>
<prevsent>the pcedt comprises also translation dictionary compiled from three different czech-english manual dictio naries: two of them were downloaded form the web andone was extracted from czech and english euro word nets.
</prevsent>
<prevsent>entry-translation pairs were filtered and weighed taking into account the reliability of the source dictionary, the frequencies of the translations in czech and english monolingual corpora, and the correspondence of the czech and english pos tags.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
furthermore, by training giza++ (och and ney, 2003) <papid> J03-1002 </papid>translation model on the training part of the pcedt extended by the manual dictionaries, we obtained probabilistic czech-english dictionary, more sensitive to the domain of financial news specific for the wall street journal.</citsent>
<aftsection>
<nextsent>the resulting czech-english probabilistic dictionary _ _ _ _ sanfrancisk?
</nextsent>
<nextsent>rstr san_francisco marketingov?
</nextsent>
<nextsent>rstr co marketing conj and distribu
</nextsent>
<nextsent>n?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4428">
<title id=" W04-2708.xml">prague czech english dependency treebank any hopes for a common annotation scheme </title>
<section> other resources included in pcedt.  </section>
<citcontext>
<prevsection>
<prevsent>6.3 tools.
</prevsent>
<prevsent>smt quick run is package of scripts and instructions for building statistical machine translation system from the pcedt or any other parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
the system uses models giza++ and isi rewrite decoder (germann et al., 2001).<papid> P01-1030 </papid></citsent>
<aftsection>
<nextsent>tred is graphical editor and viewer of tree structures.
</nextsent>
<nextsent>its modular architecture allows easy handling of diverse annotation schemes, it has been used as the principal annotation environment for the pdt and pcedt.
</nextsent>
<nextsent>net graph is multi-platform client-server application for browsing, querying and viewing analytical and tec to grammatical dependency trees, either over the internet or locally.
</nextsent>
<nextsent>we have described the process of building the first version of parallel treebank for two relatively distant languages, czech and english, during which we have also attempted to reconcile two fairly incompatible linguistic theories used for their description.the resulting data collection contains data syntactically annotated on several layers of analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4429">
<title id=" W04-2708.xml">prague czech english dependency treebank any hopes for a common annotation scheme </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we have described the process of building the first version of parallel treebank for two relatively distant languages, czech and english, during which we have also attempted to reconcile two fairly incompatible linguistic theories used for their description.the resulting data collection contains data syntactically annotated on several layers of analysis.
</prevsent>
<prevsent>there have already been experimental machine translation systems magenta (hajic?
</prevsent>
</prevsection>
<citsent citstr=" E03-1004 ">
et al, 2002) and dbmt ( cmejrek et al, 2003) <papid> E03-1004 </papid>confirming the exploit ability of the corpus and showing that we are capable of performing automatic transformations from phrase structures to dependency representation with an acceptable, though still not impeccable quality.however, for both languages, we have presented examples of phenomena, for which the native?</citsent>
<aftsection>
<nextsent>annotation scheme does not provide sufficiently fine-grained analysis.
</nextsent>
<nextsent>in such cases, automatic conversion between annotation schemes is not possible, and the less we can hope for success full machine translation.
</nextsent>
<nextsent>the question of enhancing the annotation schemes to allow for loss less transformation between them remains still open, and its difficulty presents yet unfathomed depth.
</nextsent>
<nextsent>this research was supported by the following grants: msmt cr grants no.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4430">
<title id=" W06-0141.xml">designing special postprocessing rules for svm based chinese word segmentation </title>
<section> svm-based chinese word segmenter.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W03-1728 ">
we built out segmentation system following (xueand shen, 2003), <papid> W03-1728 </papid>regarding chinese word segmentation as problem of character-based tagging.instead of maximum entropy, we utilized support vector machines as an alternate.</citsent>
<aftsection>
<nextsent>svms are state-of-the-art learning algorithm, owing their success mainly to the ability in control of generalization error upper-bound, and the smooth integration with kernel methods.
</nextsent>
<nextsent>see details in (vapnik, 1995).
</nextsent>
<nextsent>we adopted svm-light1 as the specific implementation of the model.
</nextsent>
<nextsent>1.1 problem formalization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4431">
<title id=" W06-0141.xml">designing special postprocessing rules for svm based chinese word segmentation </title>
<section> svm-based chinese word segmenter.  </section>
<citcontext>
<prevsection>
<prevsent>?, the character is assigned to the category word-prefix, indicating the beginning of word;is assigned to the category word-stem, indicating the middle position of word; belongs to the category word-suffix, meaning the ending of chinese word; and last,is assigned to the category single-character, indicating that the single character itself is word.
</prevsent>
<prevsent>1.2 feature templates.
</prevsent>
</prevsection>
<citsent citstr=" I05-3025 ">
we utilized four of the five basic feature templates suggested in (low et al , 2005), <papid> I05-3025 </papid>described as follows: ? cn(n = 2,1, 0, 1, 2) ? cncn+ 1(n = 2,1, 0, 1) ? pu(c0) ? (c2)t (c1)t (c0)t (c1)t (c2) where refers to chinese character.</citsent>
<aftsection>
<nextsent>the first two templates specify context window with the size of five characters, where c0 stands for the current character: the former describes individual characters and the latter presents bigrams within the context window.
</nextsent>
<nextsent>the third template checks if current character is punctuation or not, and the last one encodes characters?
</nextsent>
<nextsent>type, including four types: numbers, dates, english letters andthe type representing other characters.
</nextsent>
<nextsent>see detail description and the example in (low et al , 2005).<papid> I05-3025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4436">
<title id=" W06-0141.xml">designing special postprocessing rules for svm based chinese word segmentation </title>
<section> post-processing rules.  </section>
<citcontext>
<prevsection>
<prevsent>analogously, the collection ss(uffix) of suffixes is brought upin the same way.
</prevsent>
<prevsent>obviously not all the prefixes (suffixes) are good indicators for name entities.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
partly inheriting from (brill, 1995),<papid> J95-4004 </papid>we applied error-driven learning to filter prefixes in sp and suffixes in ss.</citsent>
<aftsection>
<nextsent>specifically, if prefix and suffix are both matched in sequence, all the characters between them, together with the prefix and the suffix, are merged into single segmentation unit.
</nextsent>
<nextsent>the resulted unit is compared with corresponding sequence in training data.
</nextsent>
<nextsent>if they were not exactly matched, the prefix and suffix were removed from collections respectively.
</nextsent>
<nextsent>finally resulted sp and ss are utilized to recognize name entities in the initial segmentation results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4437">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is well-suited for hand built grammars because during the construction phase the covered cases can be recorded.
</prevsent>
<prevsent>however, it has problems with capturing complexities occuring from the interaction of covered cases.the most widely used corpus-based evaluation methods are: (1) the constituent based (phrase structure) method, and (2) the dependency/gr-based method.
</prevsent>
</prevsection>
<citsent citstr=" A92-1022 ">
the former has its roots in the grammar evaluation interest group (geig) scheme (grishman et al, 1992)<papid> A92-1022 </papid>developed to compare parsers with different underlying grammatical formalisms.</citsent>
<aftsection>
<nextsent>it promoted the use of phrase-structure bracketed information and defined precision, recall, and crossing brackets measures.
</nextsent>
<nextsent>the geig measures were extended later to constituent information (bracketing information plus label) and have since become the standard for reporting automated syntactic parsing performance.
</nextsent>
<nextsent>among the advantages of constituent-based evaluation are generality (less parser specificity) and fine grain size of the measures.
</nextsent>
<nextsent>on the other hand,the measures of the method are weaker than exact sentence measures (full identity), and it is not clear if they properly measure how well parser identifies the true structure of sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4438">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> evaluated parsers.  </section>
<citcontext>
<prevsection>
<prevsent>it extracts the grammar and probabilities and with standard context-freechart-parsing mechanism generates set of possible parses for each sentence retaining the one with the highest probability (probabilities arenot computed for all possible parses).
</prevsent>
<prevsent>the probabilities of an entire tree are computed bottomup.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
in (charniak, 2000), <papid> A00-2018 </papid>he proposes generative model based on markov-grammar.</citsent>
<aftsection>
<nextsent>ituses standard bottom-up, best-first probabilistic parser to first generate possible parses before ranking them with probabilistic model.
</nextsent>
<nextsent>2.3 coll inss (bikels) parser.
</nextsent>
<nextsent>coll inss statistical parser (cbp; (collins, 1997)), <papid> P97-1003 </papid>improved by bikel (bikel, 2004), <papid> J04-4004 </papid>is based on the probabilities between head-words in parsetrees.</nextsent>
<nextsent>it explicitly represents the parse probabilities in terms of basic syntactic relationships of these lexical heads.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4439">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> evaluated parsers.  </section>
<citcontext>
<prevsection>
<prevsent>ituses standard bottom-up, best-first probabilistic parser to first generate possible parses before ranking them with probabilistic model.
</prevsent>
<prevsent>2.3 coll inss (bikels) parser.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
coll inss statistical parser (cbp; (collins, 1997)), <papid> P97-1003 </papid>improved by bikel (bikel, 2004), <papid> J04-4004 </papid>is based on the probabilities between head-words in parsetrees.</citsent>
<aftsection>
<nextsent>it explicitly represents the parse probabilities in terms of basic syntactic relationships of these lexical heads.
</nextsent>
<nextsent>collins defines mapping from parse trees to sets of dependencies, on which he defines his statistical model.
</nextsent>
<nextsent>a set of rules defines head-child for each nodein the tree.
</nextsent>
<nextsent>the lexical head of the head child of each node becomes the lexical head of the parent node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4440">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> evaluated parsers.  </section>
<citcontext>
<prevsection>
<prevsent>ituses standard bottom-up, best-first probabilistic parser to first generate possible parses before ranking them with probabilistic model.
</prevsent>
<prevsent>2.3 coll inss (bikels) parser.
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
coll inss statistical parser (cbp; (collins, 1997)), <papid> P97-1003 </papid>improved by bikel (bikel, 2004), <papid> J04-4004 </papid>is based on the probabilities between head-words in parsetrees.</citsent>
<aftsection>
<nextsent>it explicitly represents the parse probabilities in terms of basic syntactic relationships of these lexical heads.
</nextsent>
<nextsent>collins defines mapping from parse trees to sets of dependencies, on which he defines his statistical model.
</nextsent>
<nextsent>a set of rules defines head-child for each nodein the tree.
</nextsent>
<nextsent>the lexical head of the head child of each node becomes the lexical head of the parent node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4441">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> evaluated parsers.  </section>
<citcontext>
<prevsection>
<prevsent>the parser is cyk style dynamic programming chart parser.
</prevsent>
<prevsent>2.4 stanford parser.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
the stanford parser (sp) is an un lexicalized parser that rivals state-of-the-art lexicalized ones (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it uses context-free grammar with state splits.
</nextsent>
<nextsent>the parsing algorithm is simpler, the grammar smaller and fewer parameters are needed for the estimation.
</nextsent>
<nextsent>it uses cky chart parser which exhaustively generates all possible parses for asentence before it selects the highest probability tree.
</nextsent>
<nextsent>here we used the default lexicalized version.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4442">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>also speed results in table 5).
</prevsent>
<prevsent>butwe assume that the difference in average sentence length obscures any genre differences in our small sample.
</prevsent>
</prevsection>
<citsent citstr=" W99-0606 ">
the most common non-fatal problems (typeone) involved the well-documented adjunct attachment site issue, in particular for prepositional phrases ((abney et al, 1999), (<papid> W99-0606 </papid>brill and resnik, 1994), (<papid> C94-2195 </papid>collins and brooks, 1995)) <papid> W95-0103 </papid>as well as adjectival phrases (table 8)3.</citsent>
<aftsection>
<nextsent>similarmisattachment issues for adjuncts are encountered with adverbial phrases, but they were rare 3pp = wrong attachment site for prepositional phrase; adv = wrong attachment site for an adverbial phrase; cnp = mis parsed complex noun phrase; &x; = wrong coordination table 7: correlation of average performance per text for all parsers and average sentence length (directed evaluation).
</nextsent>
<nextsent>text perf.
</nextsent>
<nextsent>(%) length (#words) heat 92.31 7.54 plants 90.76 9.96 orlando 93.46 6.86 moving 90.91 13.12 barron17 76.92 22.15 betty03 71.43 18.21 olga91 60.42 25.92 in our corpus.
</nextsent>
<nextsent>another common problem are deverbal nouns and denom inal verbs, as well as -ing/vbgforms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4443">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>also speed results in table 5).
</prevsent>
<prevsent>butwe assume that the difference in average sentence length obscures any genre differences in our small sample.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
the most common non-fatal problems (typeone) involved the well-documented adjunct attachment site issue, in particular for prepositional phrases ((abney et al, 1999), (<papid> W99-0606 </papid>brill and resnik, 1994), (<papid> C94-2195 </papid>collins and brooks, 1995)) <papid> W95-0103 </papid>as well as adjectival phrases (table 8)3.</citsent>
<aftsection>
<nextsent>similarmisattachment issues for adjuncts are encountered with adverbial phrases, but they were rare 3pp = wrong attachment site for prepositional phrase; adv = wrong attachment site for an adverbial phrase; cnp = mis parsed complex noun phrase; &x; = wrong coordination table 7: correlation of average performance per text for all parsers and average sentence length (directed evaluation).
</nextsent>
<nextsent>text perf.
</nextsent>
<nextsent>(%) length (#words) heat 92.31 7.54 plants 90.76 9.96 orlando 93.46 6.86 moving 90.91 13.12 barron17 76.92 22.15 betty03 71.43 18.21 olga91 60.42 25.92 in our corpus.
</nextsent>
<nextsent>another common problem are deverbal nouns and denom inal verbs, as well as -ing/vbgforms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4444">
<title id=" W05-0211.xml">evaluating stateoftheart treebank style parsers for cohmetrix and other learning technology environments </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>also speed results in table 5).
</prevsent>
<prevsent>butwe assume that the difference in average sentence length obscures any genre differences in our small sample.
</prevsent>
</prevsection>
<citsent citstr=" W95-0103 ">
the most common non-fatal problems (typeone) involved the well-documented adjunct attachment site issue, in particular for prepositional phrases ((abney et al, 1999), (<papid> W99-0606 </papid>brill and resnik, 1994), (<papid> C94-2195 </papid>collins and brooks, 1995)) <papid> W95-0103 </papid>as well as adjectival phrases (table 8)3.</citsent>
<aftsection>
<nextsent>similarmisattachment issues for adjuncts are encountered with adverbial phrases, but they were rare 3pp = wrong attachment site for prepositional phrase; adv = wrong attachment site for an adverbial phrase; cnp = mis parsed complex noun phrase; &x; = wrong coordination table 7: correlation of average performance per text for all parsers and average sentence length (directed evaluation).
</nextsent>
<nextsent>text perf.
</nextsent>
<nextsent>(%) length (#words) heat 92.31 7.54 plants 90.76 9.96 orlando 93.46 6.86 moving 90.91 13.12 barron17 76.92 22.15 betty03 71.43 18.21 olga91 60.42 25.92 in our corpus.
</nextsent>
<nextsent>another common problem are deverbal nouns and denom inal verbs, as well as -ing/vbgforms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4445">
<title id=" W04-3254.xml">evaluating information content by factoid analysis human annotation and stability </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper,we show that factoid annotation is highly reproducible, introduce weighted factoid score, estimate how many summaries are required for stable system rankings, and show that the fac toid scores cannot be sufficiently approximated by unigrams and the duc information overlap measure.
</prevsent>
<prevsent>many researchers in summarisation believe thatthe best way to evaluate summary is extrinsic evaluation (sparck jones, 1999): to measure the quality of the summary on the basis of degree of success in executing specific task with that summary.
</prevsent>
</prevsection>
<citsent citstr=" E99-1011 ">
the summary evaluation performed in summac (mani et al, 1999) <papid> E99-1011 </papid>followed that strategy.</citsent>
<aftsection>
<nextsent>however, extrinsic evaluations are time-consuming to set up and can thus not be used for the day-to-day evaluation needed during system development.
</nextsent>
<nextsent>so in practice, method for intrinsic evaluation is needed, where the properties of the summary itself are examined, independently of its application.intrinsic evaluation of summary quality is undeniably hard, as there are two subtasks of summarisation which need to be evaluated, information selection and text production ? in fact these two subtasks are often separated in evaluation (mani, 2001).
</nextsent>
<nextsent>if we restrict our attention to information selection, systems are tested by way of comparison against gold standard?, manually produced result which is supposed to be the correct?, true?
</nextsent>
<nextsent>or best?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4446">
<title id=" W04-3254.xml">evaluating information content by factoid analysis human annotation and stability </title>
<section> agreement.  </section>
<citcontext>
<prevsection>
<prevsent>in the kappa calculation should be.
</prevsent>
<prevsent>possibly the use of krippendorffs alpha will prov idea better approach (cf.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
nenkova and passonneau (2004)), <papid> N04-1019 </papid>but for now we measure using the better-known kappa, in the following way: for each equivalence between facto ids and c, create items { ? ? | ? } (wheres is the set of all summaries).</citsent>
<aftsection>
<nextsent>for each fac toid subsumed by set of facto ids, create items { ? ? | ? b, ? s}.
</nextsent>
<nextsent>for example, given 5 summaries a, b, c, d, e, annotatora1 assigns p30 to summaries a, and e. annotator a2 (who has split p30 into f9.21 and f9.22), assigns to f9.21 and and to f9.22.
</nextsent>
<nextsent>this creates the 10 items for kappa calculation given in figure 2.
</nextsent>
<nextsent>results for our dataset are given in figure 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4448">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> introduction and prior work.  </section>
<citcontext>
<prevsection>

<prevsent>noun phrase bracketing (np bracketing) is the taskof identifying any and all noun phrases in sentence.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
it is strictly more difficult problem than np chunking (ramshaw and marcus, 1995), <papid> W95-0107 </papid>in which only non-recursive (or base?)</citsent>
<aftsection>
<nextsent>noun phrases are identified.
</nextsent>
<nextsent>it is simultaneously strictly more simple than either full parsing (collins, 2003; <papid> J03-4003 </papid>charniak, 2000) <papid> A00-2018 </papid>or super tagging (bangalore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
<nextsent>np bracketing is both useful first step toward full parsing and also meaningful task in its own right; for instance as an initial step toward co-reference resolution and noun-phrase translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4449">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> introduction and prior work.  </section>
<citcontext>
<prevsection>
<prevsent>it is strictly more difficult problem than np chunking (ramshaw and marcus, 1995), <papid> W95-0107 </papid>in which only non-recursive (or base?)</prevsent>
<prevsent>noun phrases are identified.</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
it is simultaneously strictly more simple than either full parsing (collins, 2003; <papid> J03-4003 </papid>charniak, 2000) <papid> A00-2018 </papid>or super tagging (bangalore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>np bracketing is both useful first step toward full parsing and also meaningful task in its own right; for instance as an initial step toward co-reference resolution and noun-phrase translation.
</nextsent>
<nextsent>while existing np bracket ers (including the one described in this paper) tend to achieve worse over all f-measures than full statistical parser (eg.,(collins, 2003; <papid> J03-4003 </papid>charniak, 2000)), <papid> A00-2018 </papid>they can be significantly more computationally efficient.</nextsent>
<nextsent>statistical parsers tend to scale exponentially in sentence length, unless narrow beam is employed, which leads to globally poorer parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4451">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> introduction and prior work.  </section>
<citcontext>
<prevsection>
<prevsent>it is strictly more difficult problem than np chunking (ramshaw and marcus, 1995), <papid> W95-0107 </papid>in which only non-recursive (or base?)</prevsent>
<prevsent>noun phrases are identified.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
it is simultaneously strictly more simple than either full parsing (collins, 2003; <papid> J03-4003 </papid>charniak, 2000) <papid> A00-2018 </papid>or super tagging (bangalore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>np bracketing is both useful first step toward full parsing and also meaningful task in its own right; for instance as an initial step toward co-reference resolution and noun-phrase translation.
</nextsent>
<nextsent>while existing np bracket ers (including the one described in this paper) tend to achieve worse over all f-measures than full statistical parser (eg.,(collins, 2003; <papid> J03-4003 </papid>charniak, 2000)), <papid> A00-2018 </papid>they can be significantly more computationally efficient.</nextsent>
<nextsent>statistical parsers tend to scale exponentially in sentence length, unless narrow beam is employed, which leads to globally poorer parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4452">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> introduction and prior work.  </section>
<citcontext>
<prevsection>
<prevsent>it is strictly more difficult problem than np chunking (ramshaw and marcus, 1995), <papid> W95-0107 </papid>in which only non-recursive (or base?)</prevsent>
<prevsent>noun phrases are identified.</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
it is simultaneously strictly more simple than either full parsing (collins, 2003; <papid> J03-4003 </papid>charniak, 2000) <papid> A00-2018 </papid>or super tagging (bangalore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>np bracketing is both useful first step toward full parsing and also meaningful task in its own right; for instance as an initial step toward co-reference resolution and noun-phrase translation.
</nextsent>
<nextsent>while existing np bracket ers (including the one described in this paper) tend to achieve worse over all f-measures than full statistical parser (eg.,(collins, 2003; <papid> J03-4003 </papid>charniak, 2000)), <papid> A00-2018 </papid>they can be significantly more computationally efficient.</nextsent>
<nextsent>statistical parsers tend to scale exponentially in sentence length, unless narrow beam is employed, which leads to globally poorer parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4459">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> introduction and prior work.  </section>
<citcontext>
<prevsection>
<prevsent>an example bracketed sentence is in figure 1.
</prevsent>
<prevsent>there have been several successful approaches reported in the literature to solve this task.
</prevsent>
</prevsection>
<citsent citstr=" P00-1007 ">
tjongkim sang (1999) first used repeated chunking to attain an f-score of 82.98 during the conll competition and subsequently (sang, 2002) an f-score of 83.79 using combination of two different systems.krymolowski and dagan (2000) <papid> P00-1007 </papid>have obtained similar results using more training data and lexicaliza tion.</citsent>
<aftsection>
<nextsent>brandts (1999) has used cascaded hmms tosolve the np bracketing problem; however, he evaluated his system only on german nps, so his results cannot be directly compared.obviously, the difficulty that arises in np bracketing that differentiates it from np chunking is the issue of embedded nps, thus requiring output in the 5 10 15 20 25 30 35 40 45 50 55 0 5 10 15 20 25 30 sentence length se co nd to ar se (n orm ali ze d) charniak collins bracketer+svm bracketer figure 2: speed of different systems form of tree structure.
</nextsent>
<nextsent>most solutions to problems involving building trees from sequences build in to the model concept of depth (in parsing, this is typically in the form of chart; in bracketing and shallow parsing, this is typically in the form of embedded finite-state automata).
</nextsent>
<nextsent>we elect to take completely different approach.
</nextsent>
<nextsent>the model we useis agnostic to any sort of depth: it hypothesizes underspecified tags and allows the matching bracket constraint to select solution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4460">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> bracketing as tagging problem.  </section>
<citcontext>
<prevsection>
<prevsent>(1) where zti1,w? is normalizing factor.
</prevsent>
<prevsent>like other maximum entropy approaches, this distribution is uni modal and optimal values for the can be found through various algorithms; we use gis.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
a good introduction to maximum entropy models can be found in (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>in our approach, we use tag set of exactly five tags: {open, close, in, out, sing}.
</nextsent>
<nextsent>an open tag is assigned to all words that open bracketing (regard less of the number of brackets opened) and do not also close bracketing.
</nextsent>
<nextsent>a close tag is assigned to all words that close bracketing and do not also open one.
</nextsent>
<nextsent>an in tag is assigned to all words enclosed in an np, but which neither open nor close one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4462">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> hypothesis reranking.  </section>
<citcontext>
<prevsection>
<prevsent>in the previous section, we described tagging model for np bracketing that can produce n-bestlists.
</prevsent>
<prevsent>in this section, we describe machine learning method for reranking these lists in an attempt to choose hypothesis which is superior to the first best output of the decoder.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
reranking of n-best list shas recently become popular in several natural language problems, including parsing (collins, 2003), <papid> J03-4003 </papid>machine translation (och and ney, 2002) <papid> P02-1038 </papid>and web search (joachims, 2002).</citsent>
<aftsection>
<nextsent>each of these researchers takes different approach to reranking.
</nextsent>
<nextsent>collins(2003) <papid> J03-4003 </papid>uses both markov random fields and boosting, och and ney (2002) <papid> P02-1038 </papid>use maximum entropy ranking scheme, and joachims (2002) uses support vector approach.</nextsent>
<nextsent>as svms tend to exhibit less problems with over-fitting than other competing approaches in noisy scenarios, we also adopt the support vector approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4468">
<title id=" W04-3233.xml">np bracketing by maximum entropy tagging and svm reranking </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>however, since this hypothetical system only chunks base nps, it misses all non-basenps and thus achieves recall of only 73.0, yielding an overall f-score below our systems performance.
</prevsent>
<prevsent>note also that no chunker will perform this well.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
current systems attain approximately 94% precision and recall on the chunking task (sha and pereira, 2002; kudo and matsumoto, 2001), <papid> N01-1025 </papid>so the3collins independently reports recall of 91.2 and precision of 90.3 for nps (collins, 2003); <papid> J03-4003 </papid>however, these numbers are based on training on all the data and testing on section 0.</citsent>
<aftsection>
<nextsent>moreover, it is possible that his evaluation of np bracketing is not identical to our own.
</nextsent>
<nextsent>the results in row col03full are therefore perhaps more relevant.actual performance for real system would be substantially lower.
</nextsent>
<nextsent>the four criteria these systems are evaluated on are bracketing recall (br), bracketing precision (bp), bracketing f-score (bf) and average crossing brackets (cb).
</nextsent>
<nextsent>some systems do not report their crossing bracket rate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4470">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, after providing some background, we will examine some properties of the widely used bleu metric, discuss experimental design, introduce bootstrap re sampling methods for statistical significance estimation and report on experimental results that demonstrate the accuracy of the methods.
</prevsent>
<prevsent>2.1 statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
statistical machine translation was introduced by work at ibm [brown et al, 1990, <papid> J90-2002 </papid>1993].</citsent>
<aftsection>
<nextsent>currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at time [och, 2002; zens et al, 2002; koehn et al, 2003; <papid> N03-1017 </papid>vogel et al, 2003; tillmann, 2003] <papid> W03-1001 </papid>phrase-based machine translation systems makeuse of language model trained for the target language and translation model trained from parallel corpus.</nextsent>
<nextsent>the translation model is typically broken down into several components, e.g., reordering model, phrase translation model, and word translation model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4471">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 statistical machine translation.
</prevsent>
<prevsent>statistical machine translation was introduced by work at ibm [brown et al, 1990, <papid> J90-2002 </papid>1993].</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at time [och, 2002; zens et al, 2002; koehn et al, 2003; <papid> N03-1017 </papid>vogel et al, 2003; tillmann, 2003] <papid> W03-1001 </papid>phrase-based machine translation systems makeuse of language model trained for the target language and translation model trained from parallel corpus.</citsent>
<aftsection>
<nextsent>the translation model is typically broken down into several components, e.g., reordering model, phrase translation model, and word translation model.
</nextsent>
<nextsent>2.2 automatic evaluation.
</nextsent>
<nextsent>to adequately evaluate the quality of any translation is difficult, since it is not entirely clear what the focus of the evaluation should be.
</nextsent>
<nextsent>surely, good translation has to adequately capture the meaning of the foreign original.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4473">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 statistical machine translation.
</prevsent>
<prevsent>statistical machine translation was introduced by work at ibm [brown et al, 1990, <papid> J90-2002 </papid>1993].</prevsent>
</prevsection>
<citsent citstr=" W03-1001 ">
currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at time [och, 2002; zens et al, 2002; koehn et al, 2003; <papid> N03-1017 </papid>vogel et al, 2003; tillmann, 2003] <papid> W03-1001 </papid>phrase-based machine translation systems makeuse of language model trained for the target language and translation model trained from parallel corpus.</citsent>
<aftsection>
<nextsent>the translation model is typically broken down into several components, e.g., reordering model, phrase translation model, and word translation model.
</nextsent>
<nextsent>2.2 automatic evaluation.
</nextsent>
<nextsent>to adequately evaluate the quality of any translation is difficult, since it is not entirely clear what the focus of the evaluation should be.
</nextsent>
<nextsent>surely, good translation has to adequately capture the meaning of the foreign original.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4474">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>these two goals, adequacy and fluency, are the main criteria in machine translation evaluation.
</prevsent>
<prevsent>system 1-gram 4-gram %bleu spanish 62.6% 14.7% 28.9% portuguese 60.9% 13.4% 27.4% danish 60.8% 13.3% 26.9% greek 59.4% 12.1% 25.3% german 58.3% 9.8% 22.6% finnish 56.1% 7.8% 20.2%table 1: translation quality of three systems, measured by the bleu score and n-gram precision human judges may be asked to evaluate the adequacy and fluency of translation output, but this is laborious and expensive task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
papineni et al[2002] <papid> P02-1040 </papid>addressed the evaluation problem by introducing an automatic scoring metric, called bleu,which allowed the automatic calculation of translation quality.</citsent>
<aftsection>
<nextsent>the system output is compared against reference translation of the same source text.
</nextsent>
<nextsent>2.3 bleu: closer look.
</nextsent>
<nextsent>formally, the bleu metric is computed as follows.
</nextsent>
<nextsent>given the precision
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4475">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>to illustrate this point, see figure 1.
</prevsent>
<prevsent>bleu scores for both spanish and portuguese system drop off when large word penalty is introduced into the translation model, forcing shorter output.
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
this is not the case for similar metric, gtm, an n-gram precision/recall metric proposed by melamed et al [2003] <papid> N03-2021 </papid>that does not have an explicit brevity penalty.the bleu metric also works with multiple reference translations.</citsent>
<aftsection>
<nextsent>however, we often do not have the luxury of having multiple translations of the same source material.
</nextsent>
<nextsent>fortunately, it has not been shown so far that having only single reference translation causes serious problems.while bleu has become the most popular metric for machine translation evaluation, some of its short-comings have become apparent: it does not work on single sentences, since 4-gram precision is often 0.
</nextsent>
<nextsent>it is also hard to interpret.
</nextsent>
<nextsent>what bleu score of 28.9% means is not intuitive and depends, e.g., on the number of reference translation used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4478">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> bootstrap re sampling.  </section>
<citcontext>
<prevsection>
<prevsent>(or p-level      ! ) that the true bleu score lies in an interval fl   ffifi  ffi . instead of using an analytical method to compute confidence intervals for the bleu score, we resort to randomized method, called bootstrap resampling.
</prevsent>
<prevsent>bootstrap re sampling has long tradition in the field of statistics, refer to efron and tibshirani [1994] for general introduction and press et al [2002] for typical implementation.some recent papers on statistical machine translation hinton the use of bootstrap re sampling for significance test sample size level 100 300 600  99% 2.6259 2.5923 2.5841 2.5759 95% 1.9849 1.9679 1.9639 1.9600 90% 1.6602 1.6499 1.6474 1.6449table 2: values for
</prevsent>
</prevsection>
<citsent citstr=" N03-1010 ">
for different sizes and significance levels (formula 5)assessing statistical significance of test results [ger mann, 2003; <papid> N03-1010 </papid>och, 2003; <papid> P03-1021 </papid>kumar and byrne, 2004], <papid> N04-1022 </papid>but do not lay out their methodology.</citsent>
<aftsection>
<nextsent>the intuition behind bootstrap re sampling goesas follows: assume that we can only test translation performance on test set of     sentences.
</nextsent>
<nextsent>these 300 sentences are randomly drawn from the world.
</nextsent>
<nextsent>given test set, we can compute bleu score.
</nextsent>
<nextsent>then, we draw second test set of 300 sentences, and compute its bleu score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4479">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> bootstrap re sampling.  </section>
<citcontext>
<prevsection>
<prevsent>(or p-level      ! ) that the true bleu score lies in an interval fl   ffifi  ffi . instead of using an analytical method to compute confidence intervals for the bleu score, we resort to randomized method, called bootstrap resampling.
</prevsent>
<prevsent>bootstrap re sampling has long tradition in the field of statistics, refer to efron and tibshirani [1994] for general introduction and press et al [2002] for typical implementation.some recent papers on statistical machine translation hinton the use of bootstrap re sampling for significance test sample size level 100 300 600  99% 2.6259 2.5923 2.5841 2.5759 95% 1.9849 1.9679 1.9639 1.9600 90% 1.6602 1.6499 1.6474 1.6449table 2: values for
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for different sizes and significance levels (formula 5)assessing statistical significance of test results [ger mann, 2003; <papid> N03-1010 </papid>och, 2003; <papid> P03-1021 </papid>kumar and byrne, 2004], <papid> N04-1022 </papid>but do not lay out their methodology.</citsent>
<aftsection>
<nextsent>the intuition behind bootstrap re sampling goesas follows: assume that we can only test translation performance on test set of     sentences.
</nextsent>
<nextsent>these 300 sentences are randomly drawn from the world.
</nextsent>
<nextsent>given test set, we can compute bleu score.
</nextsent>
<nextsent>then, we draw second test set of 300 sentences, and compute its bleu score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4480">
<title id=" W04-3250.xml">statistical significance tests for machine translation evaluation </title>
<section> bootstrap re sampling.  </section>
<citcontext>
<prevsection>
<prevsent>(or p-level      ! ) that the true bleu score lies in an interval fl   ffifi  ffi . instead of using an analytical method to compute confidence intervals for the bleu score, we resort to randomized method, called bootstrap resampling.
</prevsent>
<prevsent>bootstrap re sampling has long tradition in the field of statistics, refer to efron and tibshirani [1994] for general introduction and press et al [2002] for typical implementation.some recent papers on statistical machine translation hinton the use of bootstrap re sampling for significance test sample size level 100 300 600  99% 2.6259 2.5923 2.5841 2.5759 95% 1.9849 1.9679 1.9639 1.9600 90% 1.6602 1.6499 1.6474 1.6449table 2: values for
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
for different sizes and significance levels (formula 5)assessing statistical significance of test results [ger mann, 2003; <papid> N03-1010 </papid>och, 2003; <papid> P03-1021 </papid>kumar and byrne, 2004], <papid> N04-1022 </papid>but do not lay out their methodology.</citsent>
<aftsection>
<nextsent>the intuition behind bootstrap re sampling goesas follows: assume that we can only test translation performance on test set of     sentences.
</nextsent>
<nextsent>these 300 sentences are randomly drawn from the world.
</nextsent>
<nextsent>given test set, we can compute bleu score.
</nextsent>
<nextsent>then, we draw second test set of 300 sentences, and compute its bleu score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4481">
<title id=" W04-3104.xml">a study of text categorization for model organism databases </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>an nbl classifier chooses the category with the highest conditional probability forgiven feature vector; while the computation of conditional probabilities is based on the nave bayes assumption: the presence of one feature is independent of another when conditioned on the category variable.
</prevsent>
<prevsent>the training of the nave bayes classifier consists of estimating the prior probabilities for different categories as well as the probabilities of each category for each feature.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 19 65 19 68 19 71 19 74 19 77 19 80 19 83 19 86 19 89 19 92 19 95 19 98 20 01 year um be of ita tions yeast fly worm mouse 0 0.02 0.04 0.06 0.08 0.1 0.12 19 65 19 68 19 71 19 74 19 77 19 80 19 83 19 86 19 89 19 92 19 95 19 98 20 01 year ro or tio yeast fly worm mouse the decision list method (dll) (yarowsky, 1994) <papid> P94-1013 </papid>is equivalent to simple case statements in most programming languages.</citsent>
<aftsection>
<nextsent>in dll classifier, sequence of tests is applied to each feature vector.
</nextsent>
<nextsent>if test succeeds, then the sense associated with that test is returned.
</nextsent>
<nextsent>if the test fails, then the next test in the sequence is applied.
</nextsent>
<nextsent>this continues until the end of the list, where default test simply returns the majority sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4482">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>figure1.
</prevsent>
<prevsent>parallel sentence and lexicon extraction via bootstrapping and em the most challenging task is to extract bilingual sentences and lexicon from very-non-parallel data.
</prevsent>
</prevsection>
<citsent citstr=" N04-1034 ">
recent work (munteanu et al, 2004, <papid> N04-1034 </papid>zhao and vogel, 2002) on extracting parallel sentences from comparable data, and others on extracting paraphrasing sentences from monolingual corpora (barzilay and elhadad 2003) are based on the find-topic-extract-sentence?</citsent>
<aftsection>
<nextsent>principle which claims that parallel sentences only exist in document pairs with high similarity.
</nextsent>
<nextsent>they all use lexical information (e.g. word overlap, cosine similarity) to match documents first, before extracting sentences from these documents.
</nextsent>
<nextsent>parallel sentences are important resources for training and improving statistical machine translation and cross-lingual information retrieval systems.
</nextsent>
<nextsent>various methods have been previously proposed to extract parallel sentences from multilingual corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4486">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also apply the ibm model 4 em lexical learning to find unknown word translations from the extracted parallel sentences from our system.
</prevsent>
<prevsent>the ibm models are commonly used for word alignment in statistical mt systems.
</prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
this em method differs from some previous work, which used seed-word lexicon to extract new word translations or word senses from comparable corpora (rapp 1995, <papid> P95-1050 </papid>fung &amp; mckeown 1997, <papid> W97-0119 </papid>grefenstette 1998, fung and lo 1998, <papid> P98-1069 </papid>kikui 1999, <papid> W99-0905 </papid>kaji 2003).<papid> N03-1015 </papid></citsent>
<aftsection>
<nextsent>there have been conflicting definitions of the term comparable corpora?
</nextsent>
<nextsent>in the research community.
</nextsent>
<nextsent>in this paper, we contrast and analyze different bilingual corpora, ranging from the parallel, noisy parallel, comparable, to very-non-parallel corpora.
</nextsent>
<nextsent>a parallel corpus is sentence-aligned corpus containing bilingual translations of the same document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4487">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also apply the ibm model 4 em lexical learning to find unknown word translations from the extracted parallel sentences from our system.
</prevsent>
<prevsent>the ibm models are commonly used for word alignment in statistical mt systems.
</prevsent>
</prevsection>
<citsent citstr=" W97-0119 ">
this em method differs from some previous work, which used seed-word lexicon to extract new word translations or word senses from comparable corpora (rapp 1995, <papid> P95-1050 </papid>fung &amp; mckeown 1997, <papid> W97-0119 </papid>grefenstette 1998, fung and lo 1998, <papid> P98-1069 </papid>kikui 1999, <papid> W99-0905 </papid>kaji 2003).<papid> N03-1015 </papid></citsent>
<aftsection>
<nextsent>there have been conflicting definitions of the term comparable corpora?
</nextsent>
<nextsent>in the research community.
</nextsent>
<nextsent>in this paper, we contrast and analyze different bilingual corpora, ranging from the parallel, noisy parallel, comparable, to very-non-parallel corpora.
</nextsent>
<nextsent>a parallel corpus is sentence-aligned corpus containing bilingual translations of the same document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4488">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also apply the ibm model 4 em lexical learning to find unknown word translations from the extracted parallel sentences from our system.
</prevsent>
<prevsent>the ibm models are commonly used for word alignment in statistical mt systems.
</prevsent>
</prevsection>
<citsent citstr=" P98-1069 ">
this em method differs from some previous work, which used seed-word lexicon to extract new word translations or word senses from comparable corpora (rapp 1995, <papid> P95-1050 </papid>fung &amp; mckeown 1997, <papid> W97-0119 </papid>grefenstette 1998, fung and lo 1998, <papid> P98-1069 </papid>kikui 1999, <papid> W99-0905 </papid>kaji 2003).<papid> N03-1015 </papid></citsent>
<aftsection>
<nextsent>there have been conflicting definitions of the term comparable corpora?
</nextsent>
<nextsent>in the research community.
</nextsent>
<nextsent>in this paper, we contrast and analyze different bilingual corpora, ranging from the parallel, noisy parallel, comparable, to very-non-parallel corpora.
</nextsent>
<nextsent>a parallel corpus is sentence-aligned corpus containing bilingual translations of the same document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4489">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also apply the ibm model 4 em lexical learning to find unknown word translations from the extracted parallel sentences from our system.
</prevsent>
<prevsent>the ibm models are commonly used for word alignment in statistical mt systems.
</prevsent>
</prevsection>
<citsent citstr=" W99-0905 ">
this em method differs from some previous work, which used seed-word lexicon to extract new word translations or word senses from comparable corpora (rapp 1995, <papid> P95-1050 </papid>fung &amp; mckeown 1997, <papid> W97-0119 </papid>grefenstette 1998, fung and lo 1998, <papid> P98-1069 </papid>kikui 1999, <papid> W99-0905 </papid>kaji 2003).<papid> N03-1015 </papid></citsent>
<aftsection>
<nextsent>there have been conflicting definitions of the term comparable corpora?
</nextsent>
<nextsent>in the research community.
</nextsent>
<nextsent>in this paper, we contrast and analyze different bilingual corpora, ranging from the parallel, noisy parallel, comparable, to very-non-parallel corpora.
</nextsent>
<nextsent>a parallel corpus is sentence-aligned corpus containing bilingual translations of the same document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4491">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also apply the ibm model 4 em lexical learning to find unknown word translations from the extracted parallel sentences from our system.
</prevsent>
<prevsent>the ibm models are commonly used for word alignment in statistical mt systems.
</prevsent>
</prevsection>
<citsent citstr=" N03-1015 ">
this em method differs from some previous work, which used seed-word lexicon to extract new word translations or word senses from comparable corpora (rapp 1995, <papid> P95-1050 </papid>fung &amp; mckeown 1997, <papid> W97-0119 </papid>grefenstette 1998, fung and lo 1998, <papid> P98-1069 </papid>kikui 1999, <papid> W99-0905 </papid>kaji 2003).<papid> N03-1015 </papid></citsent>
<aftsection>
<nextsent>there have been conflicting definitions of the term comparable corpora?
</nextsent>
<nextsent>in the research community.
</nextsent>
<nextsent>in this paper, we contrast and analyze different bilingual corpora, ranging from the parallel, noisy parallel, comparable, to very-non-parallel corpora.
</nextsent>
<nextsent>a parallel corpus is sentence-aligned corpus containing bilingual translations of the same document.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4502">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> extracting bilingual sentences from.  </section>
<citcontext>
<prevsection>
<prevsent>document preprocessing.
</prevsent>
<prevsent>the documents are word segmented with the language data consortium (ldc) chinese-english dictionary 2.0.then the chinese document is glossed using all the dictionary entries.
</prevsent>
</prevsection>
<citsent citstr=" P99-1043 ">
when chinese word has multiple possible translations in english, it is disambiguated by method extended from (fung et al 1999).<papid> P99-1043 </papid></citsent>
<aftsection>
<nextsent>5.2.
</nextsent>
<nextsent>initial document matching.
</nextsent>
<nextsent>this initial step is based on the same find-topic-extract-sentence?
</nextsent>
<nextsent>principle as in earlier works.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4503">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> extracting bilingual sentences from.  </section>
<citcontext>
<prevsection>
<prevsent>pairs this step updates the bilingual lexicon according to the intermediate results of parallel sentence extraction.
</prevsent>
<prevsent>new bilingual word pairs are learned from the extracted sentence pairs based on an em learning method.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we use the giza++ (och and ney, 2000) <papid> P00-1056 </papid>implementation of the ibm statistical translation lexicon model 4 (brown et al, 1993) <papid> J93-2003 </papid>for this purpose.</citsent>
<aftsection>
<nextsent>this model is based on the conditional probability of source word being generated by the target word in the other language, based on em estimation from aligned sentences.
</nextsent>
<nextsent>zhao and vogel (2002) showed that this model lends itself to adaptation and can provide better vocabulary coverage and better sentence alignment probability estimation.
</nextsent>
<nextsent>in our work, we use this model on the intermediate results of parallel sentence extraction, i.e. on set of aligned sentence pairs that may or may not truly correspond to each other.
</nextsent>
<nextsent>we found that sentence pairs with high alignment scores are not necessarily more similar than others.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4504">
<title id=" W04-3208.xml">mining verynonparallel corpora parallel sentence and lexicon extraction via bootstrapping and em </title>
<section> extracting bilingual sentences from.  </section>
<citcontext>
<prevsection>
<prevsent>pairs this step updates the bilingual lexicon according to the intermediate results of parallel sentence extraction.
</prevsent>
<prevsent>new bilingual word pairs are learned from the extracted sentence pairs based on an em learning method.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use the giza++ (och and ney, 2000) <papid> P00-1056 </papid>implementation of the ibm statistical translation lexicon model 4 (brown et al, 1993) <papid> J93-2003 </papid>for this purpose.</citsent>
<aftsection>
<nextsent>this model is based on the conditional probability of source word being generated by the target word in the other language, based on em estimation from aligned sentences.
</nextsent>
<nextsent>zhao and vogel (2002) showed that this model lends itself to adaptation and can provide better vocabulary coverage and better sentence alignment probability estimation.
</nextsent>
<nextsent>in our work, we use this model on the intermediate results of parallel sentence extraction, i.e. on set of aligned sentence pairs that may or may not truly correspond to each other.
</nextsent>
<nextsent>we found that sentence pairs with high alignment scores are not necessarily more similar than others.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4508">
<title id=" W05-0311.xml">the reliability of anaphoric annotation reconsidered taking ambiguity into account </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>we tackle three limitations with the current state of the art in the annotation of anaphoric relations.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
the first problem is the lack of truly systematic study of agreement on anaphoric annotation in the literature: none of the studies we are aware of (hirschman,1998; poesio and vieira, 1998; <papid> J98-2001 </papid>byron, 2003; poe sio, 2004) <papid> W04-2327 </papid>is completely satisfactory, either because only small number of coders was involved, or because agreement beyond chance couldnt be assessed for lack of an appropriate statistic, situation recently corrected by passonneau (2004).</citsent>
<aftsection>
<nextsent>the second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (webber, 1991; eckert and strube, 2001).
</nextsent>
<nextsent>the third shortcoming is problem that affects all types of semantic annotation.
</nextsent>
<nextsent>in all annotation studies we are aware of,1 the fact that an expression may not have unique interpretation in the context of its 1the one exception is rosenberg and binkowski (2004).<papid> N04-4020 </papid>occurrence is viewed as problem with the annotation scheme, to be fixed by, e.g., developing suitably underspecified representations, as done particularly in work on word sense annotation (buitelaar, 1998; palmer et al, 2005), but also on dialogue acttagging.</nextsent>
<nextsent>unfortunately, the under specification solution only genuinely applies to cases of polysemy, nothomonymy (poesio, 1996), and anaphoric ambiguity is not case of polysemy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4509">
<title id=" W05-0311.xml">the reliability of anaphoric annotation reconsidered taking ambiguity into account </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>we tackle three limitations with the current state of the art in the annotation of anaphoric relations.
</prevsent>
</prevsection>
<citsent citstr=" W04-2327 ">
the first problem is the lack of truly systematic study of agreement on anaphoric annotation in the literature: none of the studies we are aware of (hirschman,1998; poesio and vieira, 1998; <papid> J98-2001 </papid>byron, 2003; poe sio, 2004) <papid> W04-2327 </papid>is completely satisfactory, either because only small number of coders was involved, or because agreement beyond chance couldnt be assessed for lack of an appropriate statistic, situation recently corrected by passonneau (2004).</citsent>
<aftsection>
<nextsent>the second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (webber, 1991; eckert and strube, 2001).
</nextsent>
<nextsent>the third shortcoming is problem that affects all types of semantic annotation.
</nextsent>
<nextsent>in all annotation studies we are aware of,1 the fact that an expression may not have unique interpretation in the context of its 1the one exception is rosenberg and binkowski (2004).<papid> N04-4020 </papid>occurrence is viewed as problem with the annotation scheme, to be fixed by, e.g., developing suitably underspecified representations, as done particularly in work on word sense annotation (buitelaar, 1998; palmer et al, 2005), but also on dialogue acttagging.</nextsent>
<nextsent>unfortunately, the under specification solution only genuinely applies to cases of polysemy, nothomonymy (poesio, 1996), and anaphoric ambiguity is not case of polysemy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4510">
<title id=" W05-0311.xml">the reliability of anaphoric annotation reconsidered taking ambiguity into account </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>the second limitation, which is particularly serious when working on dialogue, is our still limited understanding of the degree of agreement on references to abstract objects, as in discourse deixis (webber, 1991; eckert and strube, 2001).
</prevsent>
<prevsent>the third shortcoming is problem that affects all types of semantic annotation.
</prevsent>
</prevsection>
<citsent citstr=" N04-4020 ">
in all annotation studies we are aware of,1 the fact that an expression may not have unique interpretation in the context of its 1the one exception is rosenberg and binkowski (2004).<papid> N04-4020 </papid>occurrence is viewed as problem with the annotation scheme, to be fixed by, e.g., developing suitably underspecified representations, as done particularly in work on word sense annotation (buitelaar, 1998; palmer et al, 2005), but also on dialogue acttagging.</citsent>
<aftsection>
<nextsent>unfortunately, the under specification solution only genuinely applies to cases of polysemy, nothomonymy (poesio, 1996), and anaphoric ambiguity is not case of polysemy.
</nextsent>
<nextsent>consider the dialogue excerpt in (1):2 its not clear to us (nor was to our annotators, as well see below) whether the demonstrative that in utterance unit 18.1 refers to the badwheel?
</nextsent>
<nextsent>or the boxcar?; as result, annotators?
</nextsent>
<nextsent>judgments may disagree ? but this doesnt mean that the annotation scheme is faulty; only that what is being said is genuinely ambiguous.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4511">
<title id=" W05-0311.xml">the reliability of anaphoric annotation reconsidered taking ambiguity into account </title>
<section> annotating anaphora.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the implications of this work.
</prevsent>
<prevsent>it is not our goal at this stage to propose new scheme for annotating anaphora.
</prevsent>
</prevsection>
<citsent citstr=" W99-0309 ">
for this study we simply developed coding manual for the purposes of our experiment, broadly based on the approach adopted inmate (poesio et al, 1999) <papid> W99-0309 </papid>and gnome(poesio, 2004), <papid> W04-2327 </papid>but introducing new types of annotation (ambiguous anaphora, and simple form of discourse deixis) while simplifying other aspects (e.g., by not annotating bridging references).</citsent>
<aftsection>
<nextsent>the task of anaphoric annotation?
</nextsent>
<nextsent>discussed hereis related, although different from, the task of annotating coreference?
</nextsent>
<nextsent>in the sense of the so-called mucss scheme for the muc-7 initiative (hirschman, 1998).
</nextsent>
<nextsent>this scheme, while often criticized, is still widely used, and has been the basis of coreference annotation for the ace initiative in the past twoyears.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4518">
<title id=" W04-3253.xml">sentiment analysis using support vector machines with diverse information sources </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper introduces an approach to sentiment analysis which uses support vector machines(svms) to bring together diverse sources of potentially pertinent information, including several fa vor ability measures for phrases and adjectives and, where available, knowledge of the topic of thetext.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
models using the features introduced are further combined with unigram models which have been shown to be effective in the past (pang et al ., 2002) <papid> W02-1011 </papid>and lemmatized versions of the unigram models.</citsent>
<aftsection>
<nextsent>experiments on movie review data from epinions.com demonstrate that hybrid svms which combine unigram-style feature-based svms with those based on real-valued favor ability measures obtain superior performance, producing the best results yet published using this data.
</nextsent>
<nextsent>further experiments using feature set enriched with topic information on smaller dataset of music reviews hand annotated for topic are also reported, the results of which suggest that incorporating topic information into such models may also yield improvement.
</nextsent>
<nextsent>recently an increasing amount of research has been devoted to investigating methods of recognizing favorable and unfavorable sentiments towards specific subjects within natural language texts.
</nextsent>
<nextsent>areas of application for such analysis are numerous and varied,ranging from news group flame filtering and informative augmentation of search engine responses to analysis of public opinion trends and customer feed back.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4520">
<title id=" W04-3253.xml">sentiment analysis using support vector machines with diverse information sources </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of the latter,results indicate that our approach may allow for further improvements to be gained given knowledge of the topic of the text.
</prevsent>
<prevsent>a continual challenge in the task of sentiment analysis of text is to home in on those aspects of the text which are in some way representative of the tone of the whole text.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
in the past, work has been done in the area of characterizing words and phrases according to their emotive tone (turney and littman, 2003; turney, 2002; <papid> P02-1053 </papid>kamps et al ,2002; hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>hatzivassiloglou and mckeown, 2002; wiebe, 2000),but in many domains of text, the values of individual phrases may bear little relation to the over all sentiment expressed by the text.</citsent>
<aftsection>
<nextsent>pang et al (2002)<papid> W02-1011 </papid>s treatment of the task as analogous to topic classification underscores the difference between the two tasks.</nextsent>
<nextsent>sources of misleading phrases include what pang et al  (2002) <papid> W02-1011 </papid>refer to as thwartedexpectations?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4521">
<title id=" W04-3253.xml">sentiment analysis using support vector machines with diverse information sources </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of the latter,results indicate that our approach may allow for further improvements to be gained given knowledge of the topic of the text.
</prevsent>
<prevsent>a continual challenge in the task of sentiment analysis of text is to home in on those aspects of the text which are in some way representative of the tone of the whole text.
</prevsent>
</prevsection>
<citsent citstr=" C00-1044 ">
in the past, work has been done in the area of characterizing words and phrases according to their emotive tone (turney and littman, 2003; turney, 2002; <papid> P02-1053 </papid>kamps et al ,2002; hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>hatzivassiloglou and mckeown, 2002; wiebe, 2000),but in many domains of text, the values of individual phrases may bear little relation to the over all sentiment expressed by the text.</citsent>
<aftsection>
<nextsent>pang et al (2002)<papid> W02-1011 </papid>s treatment of the task as analogous to topic classification underscores the difference between the two tasks.</nextsent>
<nextsent>sources of misleading phrases include what pang et al  (2002) <papid> W02-1011 </papid>refer to as thwartedexpectations?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4529">
<title id=" W04-3253.xml">sentiment analysis using support vector machines with diverse information sources </title>
<section> nn or nns jj not nn or nns.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the features employed with the first dataset, this dataset al ows the use those features described in 3.3 which make use of topic information, namely the broader pmi derived so values and the topic sentence osgood values.
</prevsent>
<prevsent>due to the relatively small size of this dataset, test suites were created using100, 20, 10, and 5-fold cross validation, to maximize the amount of data available for training andthe accuracy of the results.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
text length normalization appeared to harm performance on this dataset, and so the models reported here for this dataset were not normalized for length.svms were built using kudos tinysvm soft 2we employ the conexor fdg parser (tapanainen and jarvinen, 1997) <papid> A97-1011 </papid>for pos tagging and lemmatization 3http://www.pitchforkmedia.com model 3 folds 10 folds pang et al  2002 <papid> W02-1011 </papid>82.9% na turney values only 68.4% 68.3% osgood only 56.2% 56.4% turney values and osgood 69.0% 68.7% unigrams 82.8% 83.5% unigrams and osgood 82.8% 83.5% unigrams and turney 83.2% 85.1% unigrams, turney, osgood 82.8% 85.1% lemmas 84.1% 85.7% lemmas and osgood 83.1 % 84.7% lemmas and turney 84.2% 84.9% lemmas, turney, osgood 83.8% 84.5% hybrid svm (turney and lemmas) 84.4% 86.0% hybrid svm (turney/osgood and lemmas) 84.6% 86.0% figure 2: accuracy results for 3 and 10-fold cross-validation tests on epinions.com movie review data using linear kernel.ware implementation.4 several kernel types, kernel parameters, and optimization parameters were investigated, but no appreciable and consistent benefits were gained by deviating from the the default linear kernel with all parameter values set to their default, so only these results are reported here, with the exception of the turney values-only model on the pitchfork dataset.</citsent>
<aftsection>
<nextsent>this single-featured model caused segmentation faults on some partitions with the linear kernel, and so the results for this model only, seen in figure 3, were obtained using poly nomial kernel with parameter   set to 2 (default is 1) and the constraints violation penalty set at 2 (default is 1).
</nextsent>
<nextsent>several hybrid svm models were further tested using the results from the previously described models as features.
</nextsent>
<nextsent>in these models, the feature values for each event represent the distance from the dividing hyper plane for each constituent model.
</nextsent>
<nextsent>the accuracy value represents the percentage of test texts which were classified correctly by the model.results on the first dataset, without topic information, are shown in figure 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4533">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>model annotation in corpora used for ranking in nlg in recent years, ranking approaches to natural language generation (nlg) have become increasingly popular.they abandon the idea of generation as deterministic decision-making process in favour of approaches that combine over generation with ranking at some stage inprocessing.
</prevsent>
<prevsent>a major motivation is the potential reduction of manual development costs and increased adaptability and robustness.several approaches to sentence realization use ranking models trained on corpora of human-authored texts to judge the fluency of the candidates produced by the generation system.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
the work of [langkilde and knight, 1998; <papid> P98-1116 </papid>langkilde, 2002] describes sentence realizer that uses word ngram models trained on corpus of 250 million words to rank candidates.</citsent>
<aftsection>
<nextsent>[varges and mellish, 2001] <papid> N01-1001 </papid>present an approach to sentence realization that employ san instance-based ranker trained on semantically annotated subset of the penn treebank ii (whos news?</nextsent>
<nextsent>texts).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4534">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>a major motivation is the potential reduction of manual development costs and increased adaptability and robustness.several approaches to sentence realization use ranking models trained on corpora of human-authored texts to judge the fluency of the candidates produced by the generation system.
</prevsent>
<prevsent>the work of [langkilde and knight, 1998; <papid> P98-1116 </papid>langkilde, 2002] describes sentence realizer that uses word ngram models trained on corpus of 250 million words to rank candidates.</prevsent>
</prevsection>
<citsent citstr=" N01-1001 ">
[varges and mellish, 2001] <papid> N01-1001 </papid>present an approach to sentence realization that employ san instance-based ranker trained on semantically annotated subset of the penn treebank ii (whos news?</citsent>
<aftsection>
<nextsent>texts).
</nextsent>
<nextsent>[ratnaparkhi, 2000] <papid> A00-2026 </papid>describes sentence realizer that had been trained on domain-specific corpus (in theair travel domain) augmented with semantic attribute value pairs.</nextsent>
<nextsent>[bangalore and rambow, 2000] <papid> P00-1059 </papid>describe realizer that uses word ngram model combined with tree-based stochastic model trained on version of the penn treebank annotated in xtag grammar format.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4535">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>[varges and mellish, 2001] <papid> N01-1001 </papid>present an approach to sentence realization that employ san instance-based ranker trained on semantically annotated subset of the penn treebank ii (whos news?</prevsent>
<prevsent>texts).</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
[ratnaparkhi, 2000] <papid> A00-2026 </papid>describes sentence realizer that had been trained on domain-specific corpus (in theair travel domain) augmented with semantic attribute value pairs.</citsent>
<aftsection>
<nextsent>[bangalore and rambow, 2000] <papid> P00-1059 </papid>describe realizer that uses word ngram model combined with tree-based stochastic model trained on version of the penn treebank annotated in xtag grammar format.</nextsent>
<nextsent>[karamanis et al, 2004] <papid> P04-1050 </papid>discuss centering-based metrics of coherence that could be used for choosing among competing text structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4536">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>texts).
</prevsent>
<prevsent>[ratnaparkhi, 2000] <papid> A00-2026 </papid>describes sentence realizer that had been trained on domain-specific corpus (in theair travel domain) augmented with semantic attribute value pairs.</prevsent>
</prevsection>
<citsent citstr=" P00-1059 ">
[bangalore and rambow, 2000] <papid> P00-1059 </papid>describe realizer that uses word ngram model combined with tree-based stochastic model trained on version of the penn treebank annotated in xtag grammar format.</citsent>
<aftsection>
<nextsent>[karamanis et al, 2004] <papid> P04-1050 </papid>discuss centering-based metrics of coherence that could be used for choosing among competing text structures.</nextsent>
<nextsent>the metrics are derived from the gnome corpus [poesio et al, 2004].<papid> J04-3003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4537">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>[ratnaparkhi, 2000] <papid> A00-2026 </papid>describes sentence realizer that had been trained on domain-specific corpus (in theair travel domain) augmented with semantic attribute value pairs.</prevsent>
<prevsent>[bangalore and rambow, 2000] <papid> P00-1059 </papid>describe realizer that uses word ngram model combined with tree-based stochastic model trained on version of the penn treebank annotated in xtag grammar format.</prevsent>
</prevsection>
<citsent citstr=" P04-1050 ">
[karamanis et al, 2004] <papid> P04-1050 </papid>discuss centering-based metrics of coherence that could be used for choosing among competing text structures.</citsent>
<aftsection>
<nextsent>the metrics are derived from the gnome corpus [poesio et al, 2004].<papid> J04-3003 </papid></nextsent>
<nextsent>in sum, these approaches use corpora with various types of annotation: syntactic trees, semantic roles, text structure, or no annotation at all (for word-based ngram models).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4538">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>[bangalore and rambow, 2000] <papid> P00-1059 </papid>describe realizer that uses word ngram model combined with tree-based stochastic model trained on version of the penn treebank annotated in xtag grammar format.</prevsent>
<prevsent>[karamanis et al, 2004] <papid> P04-1050 </papid>discuss centering-based metrics of coherence that could be used for choosing among competing text structures.</prevsent>
</prevsection>
<citsent citstr=" J04-3003 ">
the metrics are derived from the gnome corpus [poesio et al, 2004].<papid> J04-3003 </papid></citsent>
<aftsection>
<nextsent>in sum, these approaches use corpora with various types of annotation: syntactic trees, semantic roles, text structure, or no annotation at all (for word-based ngram models).
</nextsent>
<nextsent>however, what they all have in common, even when dealing with higher-level text structures, is the absence of any domain model annotation, i.e. information about the available knowledge pool from which the content was chosen.
</nextsent>
<nextsent>this seems to be un problematic for surface realization where the semantic input has been determined beforehand.
</nextsent>
<nextsent>this paper asks what the lack of domain information means for ranking in the context of content determination, focusing on the generation of referring expressions (gre).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4539">
<title id=" W05-1627.xml">spatial descriptions as referring expressions in the maptask domain </title>
<section> introduction, or: the lack of domain.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the red car?
</prevsent>
<prevsent>does not necessarily presuppose the existence of another car of differentcolour.
</prevsent>
</prevsection>
<citsent citstr=" P04-1052 ">
furthermore, there are likely to be large number of domain models/knowledge bases that could have motivated the production of referring expression.[siddharthan and copestake, 2004] <papid> P04-1052 </papid>take corpus based perspective and essentially regard text as aknowledge base from which descriptions of domain objects can be extracted.</citsent>
<aftsection>
<nextsent>some nps are descriptions of the same object (for example if they have the same head noun and share attributes and relations in certain ways), others are deemed distractors.
</nextsent>
<nextsent>it seems that, in contrast to [stone, 2003], this approach cannot recover those domain objects or properties that are never mentioned be cause it only extracts what is explicitly stated in the text.both the work reported in [stone, 2003] and in [sid dhar than and copestake, 2004] <papid> P04-1052 </papid>can be seen as attempts to deal with the lack of domain model information in situations where only the surface forms of referring expressions are given.</nextsent>
<nextsent>obtaining such domain model is highly desirable in order to establish which part ofa larger knowledge pool is actually selected for realiza tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4541">
<title id=" W05-0815.xml">experiments using mar for aligning corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the basic idea of the model is that the translation of sentence can be obtained in three steps: first, the sentence is divided in two parts; second, each part is translated separately using the same process; and work partially supported by ban caixa through the project sistemas inductivos, estadsticos estructurales, para la tra duccion auto matica (siesta)?.third, the two translations are joined.
</prevsent>
<prevsent>the high computational costs associated with the training of the model made it necessary to split the training pairs in smaller parts using simple heuristic.initial work with this model can be seen in (vi lar torres, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W05-0835 ">
a detailed presentation can be found in (vilar and vidal, 2005).<papid> W05-0835 </papid></citsent>
<aftsection>
<nextsent>this model shares some similarities with the stochastic inversion transduction grammars (sitg) presented by wu in (wu,1997).<papid> J97-3002 </papid></nextsent>
<nextsent>the main point in common is the number of possible alignments between the two models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4543">
<title id=" W05-0815.xml">experiments using mar for aligning corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the high computational costs associated with the training of the model made it necessary to split the training pairs in smaller parts using simple heuristic.initial work with this model can be seen in (vi lar torres, 1998).
</prevsent>
<prevsent>a detailed presentation can be found in (vilar and vidal, 2005).<papid> W05-0835 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
this model shares some similarities with the stochastic inversion transduction grammars (sitg) presented by wu in (wu,1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>the main point in common is the number of possible alignments between the two models.
</nextsent>
<nextsent>on the other hand, the parametrizations of sitgsand the mar are completely different.
</nextsent>
<nextsent>the generative process of sitgs produces simultaneously the input and output sentences and the parameters of the model refer to the rules of the nonterminals.
</nextsent>
<nextsent>this gives clear symmetry to both input and output sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4546">
<title id=" W05-0815.xml">experiments using mar for aligning corpora </title>
<section> the mar.  </section>
<citcontext>
<prevsection>
<prevsent>into sentence y?
</prevsent>
<prevsent>can be performed in the following steps1: (a) if x?
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
is small enough, ibms model 1 (brown et al., 1993) <papid> J93-2003 </papid>is employed for the translation.</citsent>
<aftsection>
<nextsent>(b) if not, cut point is selected in x?
</nextsent>
<nextsent>yielding two parts that are independently translated applying the same procedure recursively.
</nextsent>
<nextsent>(c) the two translations are concatenated either inthe same order that they were produced or second first.
</nextsent>
<nextsent>2.1 model parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4548">
<title id=" W05-0815.xml">experiments using mar for aligning corpora </title>
<section> splitting the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>that maximizes the sum of scores is computed by dynamic programming.
</prevsent>
<prevsent>the training material was split in parts up to ten words in length.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for this, an alignment was obtained by training an ibm model 4 using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the test pairs were split in parts up to twenty words.
</nextsent>
<nextsent>after the split, there were 141 945 training pairs and 337 test pairs.
</nextsent>
<nextsent>information was stored about the partition in order to be able to recover the correct alignments later.
</nextsent>
<nextsent>the parameters of the mar were trained as explained above: first ten ibm model 1 iterations we reused forgiving initial values to the dictionary probabilities and then ten more iterations for retraining the dictionary together with the rest of the parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4549">
<title id=" W05-0105.xml">web based interfaces for natural language processing tools </title>
<section> what we have built.  </section>
<citcontext>
<prevsection>
<prevsent>none of this knowledge is terribly difficult but the amount accumulates quickly and such information does not help the student understand how cass works.
</prevsent>
<prevsent>to date, we have built web interfaces to nine nlp related technologies: ? the cass parser (abney, 1997),?
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
the monty tagger brill-style part-of-speech tagger (liu, 2004), ? the nltk statistical part-of-speech tagger, ? nltk context-free grammar parser (loper and bird, 2002),?<papid> W02-0109 </papid></citsent>
<aftsection>
<nextsent>the gsearch context-free grammar parser (cor ley et al, 2001), ? the sense relate word sense disambiguation system (pedersen et al, 2005), ? perl regular expression evaluator, ? linguistic feature annotator, ? and decision tree classifier (witten and frank, 1999).
</nextsent>
<nextsent>these interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course.
</nextsent>
<nextsent>prior tothe interface construction, no hands-on lab assignments were given; instead all assignments were pencil and paper.
</nextsent>
<nextsent>the nlp technologies listed above were chosen because they fit into the material of the course and because of their availability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4550">
<title id=" W05-0504.xml">refining the sed heuristic for morpheme discovery another look at swahili </title>
<section> sed-based heuristic.  </section>
<citcontext>
<prevsection>
<prevsent>in such pf-trie, each node dominates all strings that share common string suffix.
</prevsent>
<prevsent>in general, we expect sf to work best in suffixing language, and pf to work best in pre fixing language; swahili, like all the bantu languages, is primarily pre fixing language, but it has significant number of important suffixes in both the verbal and the nominal systems.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
goldsmith (2001) <papid> J01-2001 </papid>argues for using the discovery of signatures as the bootstrapping heuristic, where signature is maximal set of stems and suffixes with the property that all combinations of stems and suffixes are found in the corpus in question.</citsent>
<aftsection>
<nextsent>we interpret goldsmiths signatures as extensions of fsas as in (1) to computer science sense: string is string prefix of string iff there exists string such that = s.t, where ?.?
</nextsent>
<nextsent>is the string concatenation operator; under such conditions, is likewise string suffix of x. otherwise, we use the terms prefix and suffix in the linguistic sense, and string prefix (e.g., jump) may be linguistic stem, as in jump-ing.
</nextsent>
<nextsent>fsas as in (2); (2) characterizes goldsmiths notion of signature in term of fsas.
</nextsent>
<nextsent>in particular, signature is set of forms that can be characterized by an fsa of 3 states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4551">
<title id=" W05-0702.xml">a finite state morphological grammar of hebrew </title>
<section> finite-state technology.  </section>
<citcontext>
<prevsection>
<prevsent>such expression scan then be compiled into finite-state networks (automata and transducers), on which efficient algorithms can be applied to implement both analysis and generation.
</prevsent>
<prevsent>using this methodology, computational linguist can design rules which closely follow standard linguistic notation, and automatically ob 10 tain highly efficient morphological processor.
</prevsent>
</prevsection>
<citsent citstr=" C88-1064 ">
while the original two-level formulation (koskenniemi, 1983) of finite-state technology for morphology was not particularly well suited to semitic languages (lavie et al, 1988), modifications of the two-level paradigm and more advanced finite-state implementations have been applied successfully to variety of semitic languages, including ancient akkadian (kataja and koskenniemi, 1988), <papid> C88-1064 </papid>syriac (kiraz, 2000) <papid> J00-1006 </papid>and arabic.</citsent>
<aftsection>
<nextsent>in number of works, beesley (1996; <papid> C96-1017 </papid>1998; 2001) describes finite-state morphological analyzer of modern standard arabic which handles both inflectional and derivational morphology, including interdigitation.</nextsent>
<nextsent>in the following section we focus on particular finite-state toolbox which was successfully used for arabic.in this work we use xfst (beesley and karttunen, 2003), an extended regular expression language augmented by sophisticated implementation of several finite-state algorithms, which can be usedto compactly store and process very large-scale net works.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4552">
<title id=" W05-0702.xml">a finite state morphological grammar of hebrew </title>
<section> finite-state technology.  </section>
<citcontext>
<prevsection>
<prevsent>such expression scan then be compiled into finite-state networks (automata and transducers), on which efficient algorithms can be applied to implement both analysis and generation.
</prevsent>
<prevsent>using this methodology, computational linguist can design rules which closely follow standard linguistic notation, and automatically ob 10 tain highly efficient morphological processor.
</prevsent>
</prevsection>
<citsent citstr=" J00-1006 ">
while the original two-level formulation (koskenniemi, 1983) of finite-state technology for morphology was not particularly well suited to semitic languages (lavie et al, 1988), modifications of the two-level paradigm and more advanced finite-state implementations have been applied successfully to variety of semitic languages, including ancient akkadian (kataja and koskenniemi, 1988), <papid> C88-1064 </papid>syriac (kiraz, 2000) <papid> J00-1006 </papid>and arabic.</citsent>
<aftsection>
<nextsent>in number of works, beesley (1996; <papid> C96-1017 </papid>1998; 2001) describes finite-state morphological analyzer of modern standard arabic which handles both inflectional and derivational morphology, including interdigitation.</nextsent>
<nextsent>in the following section we focus on particular finite-state toolbox which was successfully used for arabic.in this work we use xfst (beesley and karttunen, 2003), an extended regular expression language augmented by sophisticated implementation of several finite-state algorithms, which can be usedto compactly store and process very large-scale net works.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4553">
<title id=" W05-0702.xml">a finite state morphological grammar of hebrew </title>
<section> finite-state technology.  </section>
<citcontext>
<prevsection>
<prevsent>using this methodology, computational linguist can design rules which closely follow standard linguistic notation, and automatically ob 10 tain highly efficient morphological processor.
</prevsent>
<prevsent>while the original two-level formulation (koskenniemi, 1983) of finite-state technology for morphology was not particularly well suited to semitic languages (lavie et al, 1988), modifications of the two-level paradigm and more advanced finite-state implementations have been applied successfully to variety of semitic languages, including ancient akkadian (kataja and koskenniemi, 1988), <papid> C88-1064 </papid>syriac (kiraz, 2000) <papid> J00-1006 </papid>and arabic.</prevsent>
</prevsection>
<citsent citstr=" C96-1017 ">
in number of works, beesley (1996; <papid> C96-1017 </papid>1998; 2001) describes finite-state morphological analyzer of modern standard arabic which handles both inflectional and derivational morphology, including interdigitation.</citsent>
<aftsection>
<nextsent>in the following section we focus on particular finite-state toolbox which was successfully used for arabic.in this work we use xfst (beesley and karttunen, 2003), an extended regular expression language augmented by sophisticated implementation of several finite-state algorithms, which can be usedto compactly store and process very large-scale networks.
</nextsent>
<nextsent>xfst grammars define binary relation (a transduction) on sets of strings: grammar maps each member of (possibly infinite) set of strings, known as the surface, or lower language, to set of strings (the lexical, or upper language).
</nextsent>
<nextsent>the idea is that the surface language defines all and only the grammatical words in the language; and each grammatical word is associated with set of lexical strings which constitutes its analyses.
</nextsent>
<nextsent>as an example, the surface string ebth may be associated by the grammar with the set of lexical strings, or analyses, depicted in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4554">
<title id=" W05-1003.xml">identifying concept attributes using a classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are carrying out systematic analysis of the sets of features used in work such as (vinson et al  2003) (see discussion).
</prevsent>
<prevsent>our disposal, wordnet (fellbaum, 1998) contains very little information that would be considered as being about attributes only information about parts, not about qualities such as height, or even to the values of such attributes in the adjective net workand this information is still very sparse.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
on the other hand, the only work on the extraction of lexical semantic relations we are aware of has concentrated on the type of relations found in word net: hyponymy (hearst, 1998; caraballo, 1999) <papid> P99-1016 </papid>and meronymy (berland and charniak, 1999; <papid> P99-1008 </papid>poe sio et al  2002).2 the work discussed here could be perhaps best described as an example of empirical ontology: using linguistics and philosophical ideas to improve the results of empirical work on lexical / ontology acquisition, and vice versa, using findings from empirical analysis to question some of the assumptions of theoretical work on ontology and the lexicon.</citsent>
<aftsection>
<nextsent>specifically, we discuss work on the acquisition of (nominal) concept attributes whose goal is twofold: on the one hand, to clarify the notion of attribute?
</nextsent>
<nextsent>and its role in lexical semantics, if any; on the other, to develop methods to acquire such information automatically (e.g., to supplement wordnet).
</nextsent>
<nextsent>the structure of the paper is as follows.
</nextsent>
<nextsent>after short review of relevant literature on extracting semantic relations and on attributes in the lexicon, we discuss our classification of attributes, followed by the features we used to classify them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4555">
<title id=" W05-1003.xml">identifying concept attributes using a classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are carrying out systematic analysis of the sets of features used in work such as (vinson et al  2003) (see discussion).
</prevsent>
<prevsent>our disposal, wordnet (fellbaum, 1998) contains very little information that would be considered as being about attributes only information about parts, not about qualities such as height, or even to the values of such attributes in the adjective net workand this information is still very sparse.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
on the other hand, the only work on the extraction of lexical semantic relations we are aware of has concentrated on the type of relations found in word net: hyponymy (hearst, 1998; caraballo, 1999) <papid> P99-1016 </papid>and meronymy (berland and charniak, 1999; <papid> P99-1008 </papid>poe sio et al  2002).2 the work discussed here could be perhaps best described as an example of empirical ontology: using linguistics and philosophical ideas to improve the results of empirical work on lexical / ontology acquisition, and vice versa, using findings from empirical analysis to question some of the assumptions of theoretical work on ontology and the lexicon.</citsent>
<aftsection>
<nextsent>specifically, we discuss work on the acquisition of (nominal) concept attributes whose goal is twofold: on the one hand, to clarify the notion of attribute?
</nextsent>
<nextsent>and its role in lexical semantics, if any; on the other, to develop methods to acquire such information automatically (e.g., to supplement wordnet).
</nextsent>
<nextsent>the structure of the paper is as follows.
</nextsent>
<nextsent>after short review of relevant literature on extracting semantic relations and on attributes in the lexicon, we discuss our classification of attributes, followed by the features we used to classify them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4556">
<title id=" W05-1003.xml">identifying concept attributes using a classifier </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we then discuss our training methods and the results we achieved.
</prevsent>
<prevsent>2 in work on the acquisition of lexical information about verbs.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
there has been some work on the acquisition of thematic roles, (e.g., merlo and stevenson, 2001).<papid> J01-3003 </papid></citsent>
<aftsection>
<nextsent>18
</nextsent>
<nextsent>2.1 using patterns to extract semantic rela-.
</nextsent>
<nextsent>tions the work discussed here belongs to line of research attempting to acquire information about lexical and other semantic relations other than similarity / synonymy by identifying syntactic constructions that are often (but not always!)
</nextsent>
<nextsent>used to express such relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4558">
<title id=" W05-1003.xml">identifying concept attributes using a classifier </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a similar approach was used by berland and charniak (1999) <papid> P99-1008 </papid>and poesio et al (2002) to extract information about part-of relations using patterns such as the of the is ?.</prevsent>
<prevsent>(as in the wheel of the car is) and by girju and moldovan (2002) and sanchez-graillet and poesio (2004) to extract causal relations.</prevsent>
</prevsection>
<citsent citstr=" W04-3221 ">
in previous work (almuhareb and poesio, 2004) <papid> W04-3221 </papid>we used this same approach to extract attributes, using the pattern the * of the [is|was]?</citsent>
<aftsection>
<nextsent>(suggested by, e.g., (woods, 1975) as test for attributehood?)
</nextsent>
<nextsent>to search for attributes of concept in the web, using the google api.
</nextsent>
<nextsent>although the information extracted this way proved useful addition to our lexical representations from clustering perspective, from the point of view of lexicon building this approach results in too many false positives, as very few syntactic constructions are used to express exclusively one type of semantic relation.
</nextsent>
<nextsent>for example, the attributes?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4563">
<title id=" W05-1003.xml">identifying concept attributes using a classifier </title>
<section> information used to classify attributes.  </section>
<citcontext>
<prevsection>
<prevsent>are considered to be derived from adjectives.
</prevsent>
<prevsent>a noun not found to be derived from verb or an adjective is assumed to be basic noun root.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
in addition to derivational morphology, we used the brill tagger (brill, 1995) <papid> J95-4004 </papid>to filter out adjectives and other types of words that can occasionally be used as nouns such as better, first, and whole before training.</citsent>
<aftsection>
<nextsent>only nouns, base form verbs, and gerund form verbs were kept in the candidate attribute list.
</nextsent>
<nextsent>4.2 clustering attributes.
</nextsent>
<nextsent>attributes are themselves concepts, at least in the sense that they have their own attributes: forex ample, part of car, such as wheel, has its own parts (the tyre) its qualities (weight, diameter) etc. this observation suggests that it should be possible to find similar attributes in an unsupervised fashion by looking at their attributes, just as we did earlier for concepts (almuhareb and poesio, 2004).<papid> W04-3221 </papid></nextsent>
<nextsent>in order to do this, we used our text patterns for finding attributes to collect from the web up to 500 pattern instances for each of the candidate attributes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4573">
<title id=" W05-0802.xml">cross language text categorization by acquiring multilingual domain models from comparable corpora </title>
<section> comparable corpora.  </section>
<citcontext>
<prevsection>
<prevsent>, tin} be collection of texts expressed in the language li ? l, and let ?(tjh, tiz) be function that returns 1 if tiz is the translation of tjh and 0 otherwise.
</prevsent>
<prevsent>a multilingual corpus is the collection of texts defined by ? = ? t i. if the function ? exists for every text tiz ? ? and for every language lj , and is known, then the corpus is parallel and aligned at document level.for the purpose of this paper it is enough to assume that two corpora are comparable, i.e. they are composed by documents about the same topics and produced in the same period (e.g. possibly from different news agencies), and it is not known if function ? exists, even if in principle it could exist and return 1 for strict subset of document pairs.there exist many interesting works about using parallel corpora for multilingual applications (melamed, 2001), such as machine translation, cross language information retrieval (littman et al., 1998), lexical acquisition, and so on.however it is not always easy to find or build parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" P04-1067 ">
this is the main reason because the weaker notion of comparable corpora is matter recent interest in the field of computational linguistics (gaussier et al, 2004).<papid> P04-1067 </papid></citsent>
<aftsection>
<nextsent>the texts inside comparable corpora, being about the same topics (i.e. about the same semantic do mains), should refer to the same concepts by using various expressions in different languages.
</nextsent>
<nextsent>on the other hand, most of the proper nouns, relevant entities and words that are not yet lexicalized in the language, are expressed by using their original terms.
</nextsent>
<nextsent>as consequence the same entities will be denoted with the same words in different languages, allowing to automatically detect couples of translation pairs just by looking at the word shape (koehn and knight, 2002).<papid> W02-0902 </papid></nextsent>
<nextsent>our hypothesis is that comparable corpora contain large amount of such words, just because texts, referring to the same topics in different languages, will often adopt the same terms to denote the same entities1 . however, the simple presence of these shared words is not enough to get significant results in tctasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4574">
<title id=" W05-0802.xml">cross language text categorization by acquiring multilingual domain models from comparable corpora </title>
<section> comparable corpora.  </section>
<citcontext>
<prevsection>
<prevsent>the texts inside comparable corpora, being about the same topics (i.e. about the same semantic do mains), should refer to the same concepts by using various expressions in different languages.
</prevsent>
<prevsent>on the other hand, most of the proper nouns, relevant entities and words that are not yet lexicalized in the language, are expressed by using their original terms.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
as consequence the same entities will be denoted with the same words in different languages, allowing to automatically detect couples of translation pairs just by looking at the word shape (koehn and knight, 2002).<papid> W02-0902 </papid></citsent>
<aftsection>
<nextsent>our hypothesis is that comparable corpora contain large amount of such words, just because texts, referring to the same topics in different languages, will often adopt the same terms to denote the same entities1 . however, the simple presence of these shared words is not enough to get significant results in tctasks.
</nextsent>
<nextsent>as we will see, we need to exploit these common words to induce second-order similarity for the other words in the lexicons.
</nextsent>
<nextsent>let = {t1, t2, . . .
</nextsent>
<nextsent>, tn} be corpus, and ={w1, w2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4575">
<title id=" W05-0802.xml">cross language text categorization by acquiring multilingual domain models from comparable corpora </title>
<section> multilingual domain models.  </section>
<citcontext>
<prevsection>
<prevsent>in the next section,we will show how to use such words as seeds to induce multilingual domain vsm, in which second order relations among terms and documents in different languages are considered to improve the similarity estimation.
</prevsent>
<prevsent>a mdm is multilingual extension of the concept of domain model.
</prevsent>
</prevsection>
<citsent citstr=" W04-0856 ">
in the literature, domain models have been introduced to represent ambiguity and variability (gliozzo et al, 2004) and successfully exploited in many nlp applications, such us word sense disambiguation (strapparava et al, 2004), <papid> W04-0856 </papid>text categorization and term categorization.</citsent>
<aftsection>
<nextsent>a domain model is composed by soft clusters of terms.
</nextsent>
<nextsent>each cluster represents semantic domain,i.e. set of terms that often co-occur in texts having similar topics.
</nextsent>
<nextsent>such clusters identifies groups of words belonging to the same semantic field, and thus highly paradigmatically related.
</nextsent>
<nextsent>mdms are domain models containing terms in more than one language.a mdm is represented by matrix d, containing the degree of association among terms in all the languages and domains, as illustrated in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4576">
<title id=" W04-3243.xml">on loglikelihoodratios and the significance of rare events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we address the issue of judging the significance ofrare events as it typically arises in statistical natural language processing.
</prevsent>
<prevsent>we first define general approach to the problem, and we empirically compare results obtained using log-likelihood-ratios and fishers exact test, applied to measuring strength of bilingual word associations.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
since it was first introduced to the nlp community by dunning (1993), <papid> J93-1003 </papid>the g2 log-likelihood-ratio statistic1 has been widely used in statistical nlp as measure of strength of association, particularly lexical associations.</citsent>
<aftsection>
<nextsent>nevertheless, its use remains controversial on the grounds that it may be unreliable when applied to rare events.
</nextsent>
<nextsent>for instance pedersen, et al (1996) present data showing that significance values for rare bigrams estimated with g2 can differ substantially from the true values as computed by fishers exact test.
</nextsent>
<nextsent>although dunning argues that g2 is superior to the chi-square statistic2 x2 for dealing with rare events, agresti (1990, p. 246)cites studies showing x2 is valid with smaller sample sizes and more sparse tables than g2,?
</nextsent>
<nextsent>and eitherx2 or g2 can be unreliable when expected frequencies of less than 5 are involved, depending on circumstances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4577">
<title id=" W04-3243.xml">on loglikelihoodratios and the significance of rare events </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and eitherx2 or g2 can be unreliable when expected frequencies of less than 5 are involved, depending on circumstances.
</prevsent>
<prevsent>the problem of rare events invariably arises whenever we deal with individual words because of the zipfian phenomenon that, typically, no matter how large corpus one has, most of the distinct words in it will occur only small number of times.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
for example, in 500,000 english sentences sampled from the canadian hansa rds data supplied for the bilingual word alignment workshop held at hlt naacl 2003 (mihalcea and pedersen, 2003), <papid> W03-0301 </papid>there are 52,921 distinct word types, of which 60.5% oc 1dunning did not use the name g2, but this appears to be its preferred name among statisticians (e.g., agresti, 1990).</citsent>
<aftsection>
<nextsent>2following agresti, we use x2 to denote the test statistic and 2 to denote the distribution it approximates.
</nextsent>
<nextsent>cur five or fewer times, and 32.8% occur only once.
</nextsent>
<nextsent>the g2 statistic has been most often used in nlp as measure of the strength of association between words, but when we consider pairs of words, the sparse data problem becomes even worse.
</nextsent>
<nextsent>if welook at the 500,000 french sentences corresponding to the english sentences described above, wefind 19,460,068 english-french word pairs that occur in aligned sentences more often than would be expected by chance, given their monolingual frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4578">
<title id=" W04-3243.xml">on loglikelihoodratios and the significance of rare events </title>
<section> how to estimate significance for rare.  </section>
<citcontext>
<prevsection>
<prevsent>any statistical measure that is unreliable for expected frequencies of less than 5 would be totally unusable with such data.
</prevsent>
<prevsent>eventsa wide variety of statistics have been used to measure strength of word association.
</prevsent>
</prevsection>
<citsent citstr=" W02-0909 ">
in one paper alone (inkpen and hirst, 2002), <papid> W02-0909 </papid>pointwise mutual information, the dice coefficient, x2, g2, and fishers exact test statistic were all computed and combined to aid in learning collocations.</citsent>
<aftsection>
<nextsent>despite the fact that many of these statistics arise from significance testing, the usual practice in applying them in nlp is to choose threshold heuristic ally for the value of the statistic being used and discard all the pairs below the threshold.
</nextsent>
<nextsent>indeed, inkpen and hirst say (p. 70) there is no principled way of choosing these thresholds.this may seem an odd statement about the measures that arise directly from significance testing, but it is clear that if standard statistical tests are used naively, the results make no sense in these applications.
</nextsent>
<nextsent>one might suppose that this is merely there sult of the statistics in question not being applicable to the rare events that predominate in nlp, but it is easy to show this is not so.
</nextsent>
<nextsent>2.1 when is something seen only once.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4581">
<title id=" W05-0636.xml">joint parsing and semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a promising approach to this problem is to perform both parsing and the higher-level task in single, joint probabilistic model.
</prevsent>
<prevsent>this not only allows uncertainty about the parser output to be carried upward, suchas through an k-best list, but also allows information from higher-level processing to improve parsing.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
for example, miller et al (2000) <papid> A00-2030 </papid>showed that performing parsing and information extraction in joint model improves performance on both tasks.</citsent>
<aftsection>
<nextsent>in particular, one suspects that attachment decisions,which are both notoriously hard and extremely important for semantic analysis, could benefit greatly from input from higher-level semantic analysis.the recent interest in semantic role labeling provides an opportunity to explore how higher-level semantic information can inform syntactic parsing.
</nextsent>
<nextsent>in previous work, it has been shown that srl systems that use full parse information perform better than those that use shallow parse information, but that machine-generated parses still perform much worse than human-corrected gold parses.
</nextsent>
<nextsent>the goal of this investigation is to narrow the gap between srl results from gold parses and from automatic parses.
</nextsent>
<nextsent>we aim to do this by jointly performing parsing and semantic role labeling in single probabilistic model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4582">
<title id=" W05-0636.xml">joint parsing and semantic role labeling </title>
<section> base srl system.  </section>
<citcontext>
<prevsection>
<prevsent>our base srl system is acas cade of maximum-entropy classifiers which select the semantic argument label for each constituent of full parse tree.
</prevsent>
<prevsent>as in other systems, we use three stages: pruning, identification, and classification.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
first, in pruning, we use deterministic preprocessing procedure introduced by xue and palmer (2004) <papid> W04-3212 </papid>to prune many constituents which are almost certainly not arguments.</citsent>
<aftsection>
<nextsent>second, in identification,a binary maxent classifier is used to prune remaining constituents which are predicted to be null with 225 base features [gj02] path to predicate constituent type head word position predicate head pos [shwa03] all conjunctions of above table 1: features used in base identification classi fier.high probability.
</nextsent>
<nextsent>finally, in classification, multiclass maxent classifier is used to predict the argument type of the remaining constituents.
</nextsent>
<nextsent>this clas sifer also has the option to output null.it can happen that the returned semantic arguments overlap, because the local classifiers take no global constraints into account.
</nextsent>
<nextsent>this is undesirable,because no overlaps occur in the gold semantic annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4583">
<title id=" W05-0636.xml">joint parsing and semantic role labeling </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>but such features depend globally on the entire frame, and cannot be represented by local classifiers.
</prevsent>
<prevsent>one way to train these global features is to learn linear classifier that selects parse / frame pair from the ranked list, in the manner of collins (2000).
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
reranking has previously been applied to semantic role labeling by toutanova et al (2005), <papid> P05-1073 </papid>from which we use several features.</citsent>
<aftsection>
<nextsent>the difference between this paper and toutanova et al is that instead of reranking k-best srl frames of single parse tree, we are reranking 1-best srl frames from the k-best parse trees.
</nextsent>
<nextsent>because of the the computational expense of training on k-best parse tree lists for each of 30,000 sentences, we train the reranker only on sections 1518 of the treebank (the same subset used in previous conll competitions).
</nextsent>
<nextsent>we train the reranker using logloss, rather than the boosting loss used by collins.
</nextsent>
<nextsent>we also restrict the reranker to consider only the top 25 parse trees.this globally-trained reranker uses all of the features from the local model, and the following globalfeatures: (a) sequence features, i.e., the linear sequence of argument labels in the sentence (e.g. a0_v_a1), (b) the log probability of the parse tree, (c) has-arg features, that is, for each argument type binary feature indicating whether it appears in the frame, (d) the conjunction of the predicate and has arg feature, and (e) the number of nodes in the tree classified as each argument type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4584">
<title id=" W05-0636.xml">joint parsing and semantic role labeling </title>
<section> conclusion and related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we have considered several methods for reranking parse trees using information from semantic role labeling.
</prevsent>
<prevsent>so far, we have not been able to show improvement over selecting the 1-best parse tree.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
gildea and jurafsky (gildea and jurafsky, 2002) <papid> J02-3001 </papid>also report results on reranking parses using an srl system, with negative results.</citsent>
<aftsection>
<nextsent>in this paper, we confirm these results with maxent-trained srl model, and we extend them to show that weighting the probabilities does not help either.
</nextsent>
<nextsent>our results with collins-style reranking are too preliminary to draw definite conclusions, but the potential improvement does not appear to be great.
</nextsent>
<nextsent>in future work, we will explore the max-sum approach, which has promise to avoid the pitfalls of max-max reranking approaches.
</nextsent>
<nextsent>acknowledgements this work was supported in part by the center for intelligent information retrieval, in part by national science foundation under nsf grants #iis-0326249 ond #iis-0427594, and in part by the defense advanced research projects agency (darpa),through the department of the interior, nbc, acquisition services division, under contract number nbchd030010.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4585">
<title id=" W05-1508.xml">treebank transfer </title>
<section> sampling from the latent tree posterior.  </section>
<citcontext>
<prevsection>
<prevsent>it is easy to see (by telescoping product argument) that by multiplying together the probabilities of each such choice we obtain the posterior probability of alatent tree.
</prevsent>
<prevsent>we thus have method for sampling latent trees efficiently from their posterior distribution.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
the sampling procedure described here is very similar to the lattice-based generation procedure with n-gram rescoring developed by langkilde (2000), <papid> A00-2023 </papid>and is in fact based on the same intersection construction (langkilde seems to be unaware that the cfg-intersection construction from (bar-hillelet al, 1961) is involved).</citsent>
<aftsection>
<nextsent>however, langkilde is interested in optimization (finding the best tree in theforest), which allows her to prune away less probable trees from the composed forest in procedure that combines composition, rescoring, and pruning.
</nextsent>
<nextsent>alternatively, for somewhat different but related formulation of the probability model, the sampling method developed by market al (1992) <papid> H92-1028 </papid>can be used.</nextsent>
<nextsent>however, its efficiency is not well understood.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4586">
<title id=" W05-1508.xml">treebank transfer </title>
<section> sampling from the latent tree posterior.  </section>
<citcontext>
<prevsection>
<prevsent>the sampling procedure described here is very similar to the lattice-based generation procedure with n-gram rescoring developed by langkilde (2000), <papid> A00-2023 </papid>and is in fact based on the same intersection construction (langkilde seems to be unaware that the cfg-intersection construction from (bar-hillelet al, 1961) is involved).</prevsent>
<prevsent>however, langkilde is interested in optimization (finding the best tree in theforest), which allows her to prune away less probable trees from the composed forest in procedure that combines composition, rescoring, and pruning.</prevsent>
</prevsection>
<citsent citstr=" H92-1028 ">
alternatively, for somewhat different but related formulation of the probability model, the sampling method developed by market al (1992) <papid> H92-1028 </papid>can be used.</citsent>
<aftsection>
<nextsent>however, its efficiency is not well understood.
</nextsent>
<nextsent>the approach described in this paper was illustrated using very simple examples.
</nextsent>
<nextsent>the simplicity of the exposition should not obscure the full generality ofour approach: it is applicable in the following situa tions: ? prior over latent trees is defined in terms of stochastic finite automata.
</nextsent>
<nextsent>we have described the special case of bigram models, and pointed out how our approach will generalize to higher-order n-gram models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4587">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it therefore requires high computational cost to estimate probabilistic model for awide-coverage grammar because there are consider able ambiguities and the alternative realizations are hard to enumerate explicitly.
</prevsent>
<prevsent>moreover, even after the model has been estimated, to explore all possible candidates in runtime is also expensive.
</prevsent>
</prevsection>
<citsent citstr=" P05-1011 ">
the same problems also arise with hpsg parsing, and recent studies (tsuruoka et al, 2004; miyao and tsujii, 2005; <papid> P05-1011 </papid>ninomiya et al, 2005) <papid> W05-1511 </papid>proposed number of solutions including the methods of estimating loglinear models using packed forests of parse trees and pruning improbable candidates during parsing.</citsent>
<aftsection>
<nextsent>the aim of this paper is to apply these techniques to generation.
</nextsent>
<nextsent>since parsing and generation both output the best probable tree under some constraints, we expect that techniques that work effectively in parsing are also beneficial for generation.
</nextsent>
<nextsent>first, we enabled estimation of log-linear models with less cost by representing set of generation trees in apacked forest.
</nextsent>
<nextsent>the forest representation was obtained by adopting chart generation (kay, 1996; <papid> P96-1027 </papid>car 93 roll et al, 1999) where ambiguous candidates are packed into an equivalence class and mapping achart into forest in the same way as parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4588">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it therefore requires high computational cost to estimate probabilistic model for awide-coverage grammar because there are consider able ambiguities and the alternative realizations are hard to enumerate explicitly.
</prevsent>
<prevsent>moreover, even after the model has been estimated, to explore all possible candidates in runtime is also expensive.
</prevsent>
</prevsection>
<citsent citstr=" W05-1511 ">
the same problems also arise with hpsg parsing, and recent studies (tsuruoka et al, 2004; miyao and tsujii, 2005; <papid> P05-1011 </papid>ninomiya et al, 2005) <papid> W05-1511 </papid>proposed number of solutions including the methods of estimating loglinear models using packed forests of parse trees and pruning improbable candidates during parsing.</citsent>
<aftsection>
<nextsent>the aim of this paper is to apply these techniques to generation.
</nextsent>
<nextsent>since parsing and generation both output the best probable tree under some constraints, we expect that techniques that work effectively in parsing are also beneficial for generation.
</nextsent>
<nextsent>first, we enabled estimation of log-linear models with less cost by representing set of generation trees in apacked forest.
</nextsent>
<nextsent>the forest representation was obtained by adopting chart generation (kay, 1996; <papid> P96-1027 </papid>car 93 roll et al, 1999) where ambiguous candidates are packed into an equivalence class and mapping achart into forest in the same way as parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4589">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since parsing and generation both output the best probable tree under some constraints, we expect that techniques that work effectively in parsing are also beneficial for generation.
</prevsent>
<prevsent>first, we enabled estimation of log-linear models with less cost by representing set of generation trees in apacked forest.
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
the forest representation was obtained by adopting chart generation (kay, 1996; <papid> P96-1027 </papid>car 93 roll et al, 1999) where ambiguous candidates are packed into an equivalence class and mapping achart into forest in the same way as parsing.</citsent>
<aftsection>
<nextsent>second, we reduced the search space in runtime by adopting iterative beam search (tsuruoka and tsujii, 2004) that efficiently pruned improbable candidates.
</nextsent>
<nextsent>we evaluated the generator on the penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>which is highly reliable corpus consisting of real-world texts.</nextsent>
<nextsent>through series of experiments, we compared the performance of several disambiguation models following an existing study (velldal and oepen, 2005) and examined how the performance changed according to the size of training data, the feature set, and the beam width.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4590">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the forest representation was obtained by adopting chart generation (kay, 1996; <papid> P96-1027 </papid>car 93 roll et al, 1999) where ambiguous candidates are packed into an equivalence class and mapping achart into forest in the same way as parsing.</prevsent>
<prevsent>second, we reduced the search space in runtime by adopting iterative beam search (tsuruoka and tsujii, 2004) that efficiently pruned improbable candidates.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we evaluated the generator on the penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>which is highly reliable corpus consisting of real-world texts.</citsent>
<aftsection>
<nextsent>through series of experiments, we compared the performance of several disambiguation models following an existing study (velldal and oepen, 2005) and examined how the performance changed according to the size of training data, the feature set, and the beam width.
</nextsent>
<nextsent>comparing the latter half of the experimental results with those on parsing (miyao and tsujii, 2005), <papid> P05-1011 </papid>we investigated similarities and differences between probabilistic models for parsing and generation.</nextsent>
<nextsent>the results indicated that the techniques exported from parsing to generation worked well while the effects were slightly different in de tail.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4593">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparing the latter half of the experimental results with those on parsing (miyao and tsujii, 2005), <papid> P05-1011 </papid>we investigated similarities and differences between probabilistic models for parsing and generation.</prevsent>
<prevsent>the results indicated that the techniques exported from parsing to generation worked well while the effects were slightly different in de tail.</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
the nitrogen system (langkilde and knight, 1998; <papid> P98-1116 </papid>langkilde, 2000) <papid> A00-2023 </papid>maps semantic relations to packed forest containing all realizations and selects the best one with bigram model.</citsent>
<aftsection>
<nextsent>our method extends their approach in that we can utilize syntactic features in the disambiguation model in addition to the bigram.from the perspective of using lexicalized grammar developed for parsing and importing parsing techniques, our method is similar to the following approaches.
</nextsent>
<nextsent>the fergus system (banga lore and rambow, 2000) <papid> C00-1007 </papid>uses ltag (lexicalized tree adjoining grammar (schabes et al, 1988)) <papid> C88-2121 </papid>for generating word lattice containing realizations and selects the best one using trigram model.white and baldridge (2003) developed chart generator for ccg (combinatory categorial grammar (steedman, 2000)) and proposed several techniques for efficient generation such as best-first search, beam thresholding and chunking the input logical forms (white, 2004).</nextsent>
<nextsent>although some of the techniques look effective, the models to rank candidates are still limited to simple language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4594">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparing the latter half of the experimental results with those on parsing (miyao and tsujii, 2005), <papid> P05-1011 </papid>we investigated similarities and differences between probabilistic models for parsing and generation.</prevsent>
<prevsent>the results indicated that the techniques exported from parsing to generation worked well while the effects were slightly different in de tail.</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
the nitrogen system (langkilde and knight, 1998; <papid> P98-1116 </papid>langkilde, 2000) <papid> A00-2023 </papid>maps semantic relations to packed forest containing all realizations and selects the best one with bigram model.</citsent>
<aftsection>
<nextsent>our method extends their approach in that we can utilize syntactic features in the disambiguation model in addition to the bigram.from the perspective of using lexicalized grammar developed for parsing and importing parsing techniques, our method is similar to the following approaches.
</nextsent>
<nextsent>the fergus system (banga lore and rambow, 2000) <papid> C00-1007 </papid>uses ltag (lexicalized tree adjoining grammar (schabes et al, 1988)) <papid> C88-2121 </papid>for generating word lattice containing realizations and selects the best one using trigram model.white and baldridge (2003) developed chart generator for ccg (combinatory categorial grammar (steedman, 2000)) and proposed several techniques for efficient generation such as best-first search, beam thresholding and chunking the input logical forms (white, 2004).</nextsent>
<nextsent>although some of the techniques look effective, the models to rank candidates are still limited to simple language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4595">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the nitrogen system (langkilde and knight, 1998; <papid> P98-1116 </papid>langkilde, 2000) <papid> A00-2023 </papid>maps semantic relations to packed forest containing all realizations and selects the best one with bigram model.</prevsent>
<prevsent>our method extends their approach in that we can utilize syntactic features in the disambiguation model in addition to the bigram.from the perspective of using lexicalized grammar developed for parsing and importing parsing techniques, our method is similar to the following approaches.</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
the fergus system (banga lore and rambow, 2000) <papid> C00-1007 </papid>uses ltag (lexicalized tree adjoining grammar (schabes et al, 1988)) <papid> C88-2121 </papid>for generating word lattice containing realizations and selects the best one using trigram model.white and baldridge (2003) developed chart generator for ccg (combinatory categorial grammar (steedman, 2000)) and proposed several techniques for efficient generation such as best-first search, beam thresholding and chunking the input logical forms (white, 2004).</citsent>
<aftsection>
<nextsent>although some of the techniques look effective, the models to rank candidates are still limited to simple language models.
</nextsent>
<nextsent>carroll et al (1999) developed chart generator using hpsg.
</nextsent>
<nextsent>after the generator outputs allthe sentences the grammar allows, the ranking mod ??????
</nextsent>
<nextsent>xh eindexr el??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4596">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the nitrogen system (langkilde and knight, 1998; <papid> P98-1116 </papid>langkilde, 2000) <papid> A00-2023 </papid>maps semantic relations to packed forest containing all realizations and selects the best one with bigram model.</prevsent>
<prevsent>our method extends their approach in that we can utilize syntactic features in the disambiguation model in addition to the bigram.from the perspective of using lexicalized grammar developed for parsing and importing parsing techniques, our method is similar to the following approaches.</prevsent>
</prevsection>
<citsent citstr=" C88-2121 ">
the fergus system (banga lore and rambow, 2000) <papid> C00-1007 </papid>uses ltag (lexicalized tree adjoining grammar (schabes et al, 1988)) <papid> C88-2121 </papid>for generating word lattice containing realizations and selects the best one using trigram model.white and baldridge (2003) developed chart generator for ccg (combinatory categorial grammar (steedman, 2000)) and proposed several techniques for efficient generation such as best-first search, beam thresholding and chunking the input logical forms (white, 2004).</citsent>
<aftsection>
<nextsent>although some of the techniques look effective, the models to rank candidates are still limited to simple language models.
</nextsent>
<nextsent>carroll et al (1999) developed chart generator using hpsg.
</nextsent>
<nextsent>after the generator outputs allthe sentences the grammar allows, the ranking mod ??????
</nextsent>
<nextsent>xh eindexr el??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4600">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>we adopted kays simple solution in the current ongoing work, but logical form chunking proposed by white is also applicable to our system.
</prevsent>
<prevsent>2.3 probabilistic models for generation with.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
hpsg some existing studies on probabilistic models for hpsg parsing (malouf and van noord, 2004; miyao and tsujii, 2005) <papid> P05-1011 </papid>adopted log-linear models (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>since log-linear models allow us to1to introduce an edge with no semantic relations as mentioned in the previous section, we need to combine the edges with edges having no relations.
</nextsent>
<nextsent>95 ??????
</nextsent>
<nextsent>xh eindexr el ??
</nextsent>
<nextsent>past x b y tense r 2 r 1i nd ex el ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4601">
<title id=" W05-1510.xml">probabilistic models for disambiguation of an hpsg based chart generator </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>generates paraphrase treebank, where $%  fi , fi # ,  &amp; are enumerated.
</prevsent>
<prevsent>then, log-linear model is trained with this treebank, i.e., each  is estimated so as to maximize the likelihood of training data.
</prevsent>
</prevsection>
<citsent citstr=" W02-2030 ">
as well as features used in their previous work on statistical parsing (toutanova and manning, 2002), <papid> W02-2030 </papid>an additional feature that represents sentence probabilities of 4-gram model is incorporated.</citsent>
<aftsection>
<nextsent>they showed that the combined model outperforms the model without the 4-gram feature.
</nextsent>
<nextsent>generation 3.1 packed representation of chart.
</nextsent>
<nextsent>as mentioned in section 2.3, to estimate log-linearmodels for hpsg generation, we need all alternative derivation trees ( , generated from the input , . however, the size of ( ,is exponential to the cardi nality of , and they cannot be enumerated explicitly.
</nextsent>
<nextsent>this problem is especially serious in wide-coverage grammars because such grammars are designed to cover wide variety of linguistic phenomena, and thus produce many realizations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4613">
<title id=" W06-0116.xml">chinese named entity recognition with conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 the model.
</prevsent>
<prevsent>conditional random fields(crfs), statistical sequence modeling framework, was first introduced by lafferty et al lafferty et al , 2001).
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
the model has been used for chunking(sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>we only describe the model briefly since full details are presented in the pa per(lafferty et al , 2001).in this paper, we regard chinese ner as sequence labeling problem.
</nextsent>
<nextsent>for our sequence labeling problem, we create linear-chain crfs based on an undirected graph = (v,e), where is the set of random variables = {yi|1 ? ? n}, for each of tokens in an input sentence and = {(yi1, yi)|1 ? ? n} is the set of ? 1 edges forming linear chain.
</nextsent>
<nextsent>for each sentence x, we define two non-negative factors: exp(kk=1 kfk(yi1, yi, x)) for each edge exp(kk=1 ? ?
</nextsent>
<nextsent>kf ? k(yi, x)) for each node where fk is binary feature function, and and ? are the number of features defined for edges and nodes respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4614">
<title id=" W05-0622.xml">semantic role labelling with tree conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>crfs are undirected graphical models which define conditional distribution over label lings given an observation (lafferty et al, 2001).
</prevsent>
<prevsent>these models allow for the use of very large sets of arbitrary, overlapping and non-independent features.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
crfs have been applied with impressive empirical results to the tasks of named entity recognition (mccallum and li, 2003; <papid> W03-0430 </papid>cohn et al, 2005), <papid> P05-1002 </papid>part-of-speech (pos)tagging (lafferty et al, 2001), noun phrase chunking (sha and pereira, 2003) <papid> N03-1028 </papid>and extraction of table data (pinto et al, 2003), among other tasks.</citsent>
<aftsection>
<nextsent>while crfs have not been used to date for srl, their close cousin, the maximum entropy model has been, with strong generalisation performance (xue and palmer, 2004; <papid> W04-3212 </papid>lim et al, 2004).<papid> W04-2419 </papid></nextsent>
<nextsent>most crf implementations have been specialised to work with chain structures, where the labels and observations form linear sequence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4615">
<title id=" W05-0622.xml">semantic role labelling with tree conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>crfs are undirected graphical models which define conditional distribution over label lings given an observation (lafferty et al, 2001).
</prevsent>
<prevsent>these models allow for the use of very large sets of arbitrary, overlapping and non-independent features.
</prevsent>
</prevsection>
<citsent citstr=" P05-1002 ">
crfs have been applied with impressive empirical results to the tasks of named entity recognition (mccallum and li, 2003; <papid> W03-0430 </papid>cohn et al, 2005), <papid> P05-1002 </papid>part-of-speech (pos)tagging (lafferty et al, 2001), noun phrase chunking (sha and pereira, 2003) <papid> N03-1028 </papid>and extraction of table data (pinto et al, 2003), among other tasks.</citsent>
<aftsection>
<nextsent>while crfs have not been used to date for srl, their close cousin, the maximum entropy model has been, with strong generalisation performance (xue and palmer, 2004; <papid> W04-3212 </papid>lim et al, 2004).<papid> W04-2419 </papid></nextsent>
<nextsent>most crf implementations have been specialised to work with chain structures, where the labels and observations form linear sequence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4616">
<title id=" W05-0622.xml">semantic role labelling with tree conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>crfs are undirected graphical models which define conditional distribution over label lings given an observation (lafferty et al, 2001).
</prevsent>
<prevsent>these models allow for the use of very large sets of arbitrary, overlapping and non-independent features.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
crfs have been applied with impressive empirical results to the tasks of named entity recognition (mccallum and li, 2003; <papid> W03-0430 </papid>cohn et al, 2005), <papid> P05-1002 </papid>part-of-speech (pos)tagging (lafferty et al, 2001), noun phrase chunking (sha and pereira, 2003) <papid> N03-1028 </papid>and extraction of table data (pinto et al, 2003), among other tasks.</citsent>
<aftsection>
<nextsent>while crfs have not been used to date for srl, their close cousin, the maximum entropy model has been, with strong generalisation performance (xue and palmer, 2004; <papid> W04-3212 </papid>lim et al, 2004).<papid> W04-2419 </papid></nextsent>
<nextsent>most crf implementations have been specialised to work with chain structures, where the labels and observations form linear sequence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4617">
<title id=" W05-0622.xml">semantic role labelling with tree conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these models allow for the use of very large sets of arbitrary, overlapping and non-independent features.
</prevsent>
<prevsent>crfs have been applied with impressive empirical results to the tasks of named entity recognition (mccallum and li, 2003; <papid> W03-0430 </papid>cohn et al, 2005), <papid> P05-1002 </papid>part-of-speech (pos)tagging (lafferty et al, 2001), noun phrase chunking (sha and pereira, 2003) <papid> N03-1028 </papid>and extraction of table data (pinto et al, 2003), among other tasks.</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
while crfs have not been used to date for srl, their close cousin, the maximum entropy model has been, with strong generalisation performance (xue and palmer, 2004; <papid> W04-3212 </papid>lim et al, 2004).<papid> W04-2419 </papid></citsent>
<aftsection>
<nextsent>most crf implementations have been specialised to work with chain structures, where the labels and observations form linear sequence.
</nextsent>
<nextsent>framing srl as linear tagging task is awkward, as there is no easy model of adjacency between the candidate constituent phrases.our approach simultaneously performs both constituent selection and labelling, by defining an undirected random field over the parse tree.
</nextsent>
<nextsent>this allows the modelling of interactions between parent and child constituents, and the prediction of an optimal argument labelling for all constituents in one pass.
</nextsent>
<nextsent>the parse tree forms an acyclic graph, meaning that efficient exact inference in crf is possible using belief propagation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4618">
<title id=" W05-0622.xml">semantic role labelling with tree conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these models allow for the use of very large sets of arbitrary, overlapping and non-independent features.
</prevsent>
<prevsent>crfs have been applied with impressive empirical results to the tasks of named entity recognition (mccallum and li, 2003; <papid> W03-0430 </papid>cohn et al, 2005), <papid> P05-1002 </papid>part-of-speech (pos)tagging (lafferty et al, 2001), noun phrase chunking (sha and pereira, 2003) <papid> N03-1028 </papid>and extraction of table data (pinto et al, 2003), among other tasks.</prevsent>
</prevsection>
<citsent citstr=" W04-2419 ">
while crfs have not been used to date for srl, their close cousin, the maximum entropy model has been, with strong generalisation performance (xue and palmer, 2004; <papid> W04-3212 </papid>lim et al, 2004).<papid> W04-2419 </papid></citsent>
<aftsection>
<nextsent>most crf implementations have been specialised to work with chain structures, where the labels and observations form linear sequence.
</nextsent>
<nextsent>framing srl as linear tagging task is awkward, as there is no easy model of adjacency between the candidate constituent phrases.our approach simultaneously performs both constituent selection and labelling, by defining an undirected random field over the parse tree.
</nextsent>
<nextsent>this allows the modelling of interactions between parent and child constituents, and the prediction of an optimal argument labelling for all constituents in one pass.
</nextsent>
<nextsent>the parse tree forms an acyclic graph, meaning that efficient exact inference in crf is possible using belief propagation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4621">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, in language modelling,there are more than 1.7 billion words corpora avail able: english gigaword by (graff, 2003).
</prevsent>
<prevsent>however, for machine translation tasks, there are typically less than 10 million words of training data.bilingual word clustering is process of forming corresponding word clusters suitable forma chine translation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
previous work from (wang et al, 1996) showed improvements in perplexity-oriented measures using mixture-based translation lexicon (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>a later study by (och,1999) <papid> E99-1010 </papid>showed improvements on perplexity of bilingual corpus, and word translation accuracy using template-based translation model.</nextsent>
<nextsent>both approaches are optimizing the maximum likelihood of parallel corpus, in which data point is sentence pair: an english sentence and its translation in another language such as french.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4622">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, for machine translation tasks, there are typically less than 10 million words of training data.bilingual word clustering is process of forming corresponding word clusters suitable forma chine translation.
</prevsent>
<prevsent>previous work from (wang et al, 1996) showed improvements in perplexity-oriented measures using mixture-based translation lexicon (brown et al, 1993).<papid> J93-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
a later study by (och,1999) <papid> E99-1010 </papid>showed improvements on perplexity of bilingual corpus, and word translation accuracy using template-based translation model.</citsent>
<aftsection>
<nextsent>both approaches are optimizing the maximum likelihood of parallel corpus, in which data point is sentence pair: an english sentence and its translation in another language such as french.
</nextsent>
<nextsent>these algorithms are essentially the same as monolingual word clusterings (kneser and ney, 1993)an iterative local search.in each iteration, two-level loop over every possible word-cluster assignment is tested for better likelihood change.
</nextsent>
<nextsent>this kind of approach has two drawbacks: first it is easily to get stuck in local op tima; second, the clustering of english and the other language are basically two separated optimization processes, and cluster-level translation is modelled loosely.
</nextsent>
<nextsent>these drawbacks make their approaches generally not very effective in improving translation models.in this paper, we propose variant of the spectral clustering algorithm (ng et al, 2001) for bilingual word clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4623">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the translation model is the key component, which is the focus in this paper.
</prevsent>
<prevsent>2.1 hmm-based translation model.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
hmm is one of the effective translation models (vo gel et al, 1996), <papid> C96-2141 </papid>which is easily scalable to very large training corpus.</citsent>
<aftsection>
<nextsent>to model word-to-word translation, we introduce the mapping ? aj , which assigns french word fj in position to english word ei in position = aj denoted as eaj . each french word fj is an observation, and it is generated by hmm state defined as [eaj , aj], where the alignment aj for position is considered to have dependency on the previous alignment aj1.
</nextsent>
<nextsent>thus the first-order hmm is defined as follows: (fj1 |ei1) = ? aj1 j?
</nextsent>
<nextsent>j=1 (fj |eaj )p (aj |aj1), (2) where (aj |aj1) is the transition probability.
</nextsent>
<nextsent>this model captures the assumption that words close in the source sentence are aligned to words close in the target sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4624">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>an additional pseudo word ofnull?
</prevsent>
<prevsent>is used as the beginning of english sentence for hmm to start with.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the (och and ney,2003) <papid> J03-1002 </papid>model includes other refinements such as special treatment of jump to null word, and uniform smoothing prior.</citsent>
<aftsection>
<nextsent>the hmm with these refinements is used as our baseline.
</nextsent>
<nextsent>motivated by the work in both (och and ney, 2000) <papid> C00-2163 </papid>and (toutanova et al,2002), <papid> W02-1012 </papid>we propose the two following simplest versions of extended hmms to utilize bilingual word clusters.</nextsent>
<nextsent>2.2 extensions to hmm with word clusters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4625">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the (och and ney,2003) <papid> J03-1002 </papid>model includes other refinements such as special treatment of jump to null word, and uniform smoothing prior.</prevsent>
<prevsent>the hmm with these refinements is used as our baseline.</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
motivated by the work in both (och and ney, 2000) <papid> C00-2163 </papid>and (toutanova et al,2002), <papid> W02-1012 </papid>we propose the two following simplest versions of extended hmms to utilize bilingual word clusters.</citsent>
<aftsection>
<nextsent>2.2 extensions to hmm with word clusters.
</nextsent>
<nextsent>let denote the cluster mapping fj ? f(fj), which assigns french word fj to its cluster id fj = f(fj).
</nextsent>
<nextsent>similarly maps english word ei to its cluster id of ei = e(ei).
</nextsent>
<nextsent>in this paper, we assume each word belongs to one cluster only.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4626">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the (och and ney,2003) <papid> J03-1002 </papid>model includes other refinements such as special treatment of jump to null word, and uniform smoothing prior.</prevsent>
<prevsent>the hmm with these refinements is used as our baseline.</prevsent>
</prevsection>
<citsent citstr=" W02-1012 ">
motivated by the work in both (och and ney, 2000) <papid> C00-2163 </papid>and (toutanova et al,2002), <papid> W02-1012 </papid>we propose the two following simplest versions of extended hmms to utilize bilingual word clusters.</citsent>
<aftsection>
<nextsent>2.2 extensions to hmm with word clusters.
</nextsent>
<nextsent>let denote the cluster mapping fj ? f(fj), which assigns french word fj to its cluster id fj = f(fj).
</nextsent>
<nextsent>similarly maps english word ei to its cluster id of ei = e(ei).
</nextsent>
<nextsent>in this paper, we assume each word belongs to one cluster only.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4633">
<title id=" W05-0804.xml">bilingual word spectral clustering for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>our pilot word alignment on unseen data showed improvements.
</prevsent>
<prevsent>however, we find it more effective in our phrase extraction, in which three key scores 31 are computed: phrase level fertilities, distortions,and lexicon scores.
</prevsent>
</prevsection>
<citsent citstr=" W05-0825 ">
these scores are used in local greedy search to extract phrase pairs (zhao and vogel, 2005).<papid> W05-0825 </papid></citsent>
<aftsection>
<nextsent>this phrase extraction is more sensitive to the differences in (fj |ei) than the hmm viterbi word aligner.
</nextsent>
<nextsent>the evaluation conditions are defined in nist 2003 small track.
</nextsent>
<nextsent>around 247k test set (919 chi-.
</nextsent>
<nextsent>nese sentences) specific phrase pairs are extracted with up to 7-gram in source phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4634">
<title id=" W04-2803.xml">a little goes a long way quick authoring of semantic knowledge sources for interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, carmel-tools offers greater flexibility in output representation than the context-free rewrite rules produced by previous semantic authoring tools, allowing authors to design their own predicate language representations that are not constrained to follow the structure of the input text (see figure 1 for simple example and figure 2 for more complex example.).
</prevsent>
<prevsent>see section 3 and (rose?, 2000; rose?
</prevsent>
</prevsection>
<citsent citstr=" P85-1008 ">
et al, 2002) for more details about carmels knowledge source representa tion.note that the predicate language representation utilized by carmel-tools is in the style of davidson ian event based semantics (hobbs, 1985).<papid> P85-1008 </papid></citsent>
<aftsection>
<nextsent>for example, in figure 1 notice that the first argument of each predicate is an identification token that represents the whole predicate.these identification tokens can then be bound to arguments of other predicates, and in that way be used to represent relationships between predicates.
</nextsent>
<nextsent>for example, therel-value predicate expresses the idea that the predicates indicated by id1 and id2 are equal in value.
</nextsent>
<nextsent>while language understanding systems with this style of analysis are not new idea, the contribution of this work is set of authoring tools that simplify the semantic knowledge sources authoring process.
</nextsent>
<nextsent>while the technology presented in this paper is not specific to any particular application area, this work is motivated by need within growing community of researchers working on educational applications of natural language processing to extract detailed information from student language input to be used for formulating specific feedback directed at the details of what the student has uttered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4635">
<title id=" W04-2803.xml">a little goes a long way quick authoring of semantic knowledge sources for interpretation </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>while the technology presented in this paper is not specific to any particular application area, this work is motivated by need within growing community of researchers working on educational applications of natural language processing to extract detailed information from student language input to be used for formulating specific feedback directed at the details of what the student has uttered.
</prevsent>
<prevsent>such applications include tutorial dialogue systems (zinn et al, 2002; popes cue et al, 2003) and writing coaches that perform detailed assessments of writing content (rose?
</prevsent>
</prevsection>
<citsent citstr=" P98-1032 ">
et al, 2003; wiemer-hastings etal., 1998; mala testa et al, 2002) as opposed to just grammar (lonsdale and strong-krause, 2003), and provide detailed feedback rather than just letter grades (burstein et al, 1998;<papid> P98-1032 </papid>foltz et al, 1998).</citsent>
<aftsection>
<nextsent>because of the important role of language in the learning process (chi et al, 2001),and because of the unique demands educational applications place on the technology, especially where detailed feedback based on student language input is offered to students, educational applications present interesting opportunities for this community.
</nextsent>
<nextsent>the area of automated essay grading has enjoyed agreat deal of success at applying shallow language processing techniques to the problem of assigning general quality measures to student essays (burstein et al, 1998;<papid> P98-1032 </papid>foltz et al, 1998).</nextsent>
<nextsent>the problem of providing reliable, detailed, content-based feedback to students is more difficult problem, however, that involves identifying individual pieces of content (christie, 2003), sometimes called answer aspects?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4638">
<title id=" W04-2803.xml">a little goes a long way quick authoring of semantic knowledge sources for interpretation </title>
<section> carmel-tools interpretation framework.  </section>
<citcontext>
<prevsection>
<prevsent>predicate language representation: ((rel-time id0 id1 id2 equal) (body-state id1 elevator freefall) (and id2 id3 id4) (rel-value id3 id5 id7 equal) (rel-value id4 id6 id6 equal) (acceleration id5 man down constant non-zero) (acceleration id6 keys down constant non-zero) (acceleration id7 elevator down constant non-zero)) gloss: the elevator is in state of freefall at the same time when there is an equivalence between the elevators acceleration and the constant downward nonzero acceleration of both the man and the keys figure 2: example of how deep syntactic analysis facilitates uncovering complex relationships encoded syntactically within sentence one of the goals behind the design of carmel-tools isto leverage off of the normalization over surface syntactic variation that deep syntactic analysis provides.
</prevsent>
<prevsent>while our approach is not specific to particular framework for deep syntactic analysis, we have chosen to build upon the publicly available lcflex robust parser (rose?
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
et al,2002), the carmel grammar and semantic interpretation framework (rose?, 2000), and the comlex lexicon(grishman et al, 1994).<papid> C94-1042 </papid></citsent>
<aftsection>
<nextsent>this same broad coverage, do main general interpretation framework has already been used in number of educational applications including (zinn et al, 2002; vanlehn et al, 2002).
</nextsent>
<nextsent>syntactic feature structures produced by the carmel grammar normalize those aspects of syntax that modify the surface realization of sentence but do not change its deep functional analysis.
</nextsent>
<nextsent>these aspects include tense, negation, mood, modality, and syntactic transformations such as passivization and extraction.
</nextsent>
<nextsent>thus, sentence and its otherwise equivalent passive counterpart would be encoded with the same set of functional relationships, but the passive feature would be negative for the active version of the sentence and positive for the passive version.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4640">
<title id=" W05-1507.xml">machine translation as lexicalized parsing with hooks </title>
<section> machine translation using inversion.  </section>
<citcontext>
<prevsection>
<prevsent>we present background onthis translation model as well as the use of the technique in bilexicalized parsing before describing thenew algorithm in detail.
</prevsent>
<prevsent>we then extend the algorithm to general m-gram language models, and to general synchronous context-free grammars for translation.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
transduction grammar the inversion transduction grammar (itg) of wu (1997) <papid> J97-3002 </papid>is type of context-free grammar (cfg) for generating two languages synchronously.</citsent>
<aftsection>
<nextsent>to model the translational equivalence within sentence pair, itg employs synchronous rewriting mechanism to relate two sentences recursively.
</nextsent>
<nextsent>to deal with the syntactic divergence between two languages, itg allows the inversion of rewriting order going from one language to another at any recursive level.
</nextsent>
<nextsent>itgin chomsky normal form consists of unary production rules that are responsible for generating word pairs: ? e/f ? e/ ? /fwhere is source language word, is foreign language word, and  means the null token, and binary production rules in two forms that are responsible for generating syntactic subtree pairs: ? [y z] 65 and ? z?
</nextsent>
<nextsent>the rules with square brackets enclosing the right-hand side expand the left-hand side symbol into the two symbols on the right-hand side in the same order in the two languages, whereas the rules with angled brackets expand the left hand side symbol into the two right-hand side symbols in reverse order in the two languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4642">
<title id=" W05-1507.xml">machine translation as lexicalized parsing with hooks </title>
<section> machine translation using inversion.  </section>
<citcontext>
<prevsection>
<prevsent>using itg, decoding is form of parsing.
</prevsent>
<prevsent>2.1 itg decoding.
</prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
wu (1996) <papid> P96-1021 </papid>presented polynomial-time algorithm for decoding itg combined with an m-gram language model.</citsent>
<aftsection>
<nextsent>such language models are commonly used in noisy channel models of translation, which find the best english translation of foreign sentence by finding the sentence that maximizes the product of the translation model (f |e) and the language model (e).
</nextsent>
<nextsent>it is worth noting that since we have specified itg as joint model generating both and , language model is not theoretically necessary.
</nextsent>
<nextsent>given foreign sentence , one can find the best translation e?: e?
</nextsent>
<nextsent>= argmax p (e, f) = argmax ? p (e, f, q) by approximating the sum over parses with the probability of the viterbi parse: e?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4643">
<title id=" W05-1507.xml">machine translation as lexicalized parsing with hooks </title>
<section> hook trick for bilexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>nonterminals can be made more specific tothe actual sub strings they are covering by associating representative word from the nonterminals yield.
</prevsent>
<prevsent>when the maximum number of lexicalized nonterminals in any rule is two, cfg is bilexical.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
a typical bilexical cfg in chomsky normal form has two types of rule templates: a[h] ? b[h]c[h?] or a[h] ? b[h?]c[h] depending on which child is the head child that agrees with the parent on head word selection.bilexical cfg is at the heart of most modern statistical parsers (collins, 1997; <papid> P97-1003 </papid>charniak, 1997), because the statistics associated with word-specific rules are more informative for disambiguation purposes.</citsent>
<aftsection>
<nextsent>ifwe use a[i, j, h] to represent lexicalized constituent, ?(?)
</nextsent>
<nextsent>to represent the viterbi score function applicable to any constituent, and (?)
</nextsent>
<nextsent>to represent the rule probability function applicable to any rule,figure 2 shows the equation for the dynamic programming computation of the viterbi parse.
</nextsent>
<nextsent>the two terms of the outermost max operator are symmetric cases for heads coming from left and right.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4644">
<title id=" W05-1507.xml">machine translation as lexicalized parsing with hooks </title>
<section> hook trick for bilexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the two terms of the outermost max operator are symmetric cases for heads coming from left and right.
</prevsent>
<prevsent>containing five free variables i,j,k,h?,h, ranging over 1 to n, the length of input sentence, both terms can be instantiated in n5 possible ways, implying that the complexity of the parsing algorithm is o(n5).
</prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
eisner and satta (1999) <papid> P99-1059 </papid>pointed out we dont have to enumerate and h?</citsent>
<aftsection>
<nextsent>simultaneously.
</nextsent>
<nextsent>the trick, shown in mathematical form in figure 2 (bottom) isvery simple.
</nextsent>
<nextsent>when maximizing over h?, is irrelevant.
</nextsent>
<nextsent>after getting the intermediate result of maximizing over h?, we have one less free variable than before.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4645">
<title id=" W05-1507.xml">machine translation as lexicalized parsing with hooks </title>
<section> hook trick for bilexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the intermediate result coming from binarizing the second term can be visualized as k b[h] . the shape of the intermediate re-.
</prevsent>
<prevsent>sults gave rise to the nickname of hook?.
</prevsent>
</prevsection>
<citsent citstr=" N03-1021 ">
melamed (2003) <papid> N03-1021 </papid>discussed the applicability of the hook trick for parsing bilexical multi text grammars.</citsent>
<aftsection>
<nextsent>the analysis of the hook trick in this section shows that it is essentially an algebraic manipulation.
</nextsent>
<nextsent>we will formulate the itg viterbi decoding algorithm in dynamic programming equation in the following section and apply the same algebraic manipulation to produce hooks that are suitable for itg decoding.
</nextsent>
<nextsent>we start from the bigram case, in which each decoding constituent keeps left boundary word and 67 tu11 u12 v12v11 u21 u22 v22v21 y z[ ] ss u21 y ss     v21 v22 u11 u12 v11 v12u22 (a) (b) figure 1: itg decoding using 3-gram language model.
</nextsent>
<nextsent>two boundary words need to be kept on the left (u) and right (v) of each constituent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4648">
<title id=" W05-1011.xml">approximate searching for distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we have intergrated this into an existing distributional similarity system, tripling efficiency with minor accuracy penalty.
</prevsent>
<prevsent>with the development of wordnet (fellbaum, 1998)and large electronic thesauri, information from lexical semantic resources is regularly used to solve nlp problems.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
these problems include collocation discovery (pearce, 2001), smoothing and estimation(brown et al, 1992; <papid> J92-4003 </papid>clark and weir, 2001) <papid> N01-1013 </papid>and question answering (pasca and harabagiu, 2001).</citsent>
<aftsection>
<nextsent>unfortunately, these resources are expensive andtime-consuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.
</nextsent>
<nextsent>in addition, lexicographers cannot keepup with constantly evolving language use and cannot afford to build new resources for the many sub domains that nlp techniques are being applied to.
</nextsent>
<nextsent>there is clear need for methods to extract lexical semantic resources automatically or tools that assist in their manual creation and maintenance.much of the existing work on automatically extracting resources is based on the distributional hypothesis that similar words appear in similar contexts.
</nextsent>
<nextsent>existing approaches differ primarily in their definition of context?, e.g. the surrounding words or the entire document, and their choice of distance metric for calculating similarity between the vector of contexts representing each term.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4649">
<title id=" W05-1011.xml">approximate searching for distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we have intergrated this into an existing distributional similarity system, tripling efficiency with minor accuracy penalty.
</prevsent>
<prevsent>with the development of wordnet (fellbaum, 1998)and large electronic thesauri, information from lexical semantic resources is regularly used to solve nlp problems.
</prevsent>
</prevsection>
<citsent citstr=" N01-1013 ">
these problems include collocation discovery (pearce, 2001), smoothing and estimation(brown et al, 1992; <papid> J92-4003 </papid>clark and weir, 2001) <papid> N01-1013 </papid>and question answering (pasca and harabagiu, 2001).</citsent>
<aftsection>
<nextsent>unfortunately, these resources are expensive andtime-consuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.
</nextsent>
<nextsent>in addition, lexicographers cannot keepup with constantly evolving language use and cannot afford to build new resources for the many sub domains that nlp techniques are being applied to.
</nextsent>
<nextsent>there is clear need for methods to extract lexical semantic resources automatically or tools that assist in their manual creation and maintenance.much of the existing work on automatically extracting resources is based on the distributional hypothesis that similar words appear in similar contexts.
</nextsent>
<nextsent>existing approaches differ primarily in their definition of context?, e.g. the surrounding words or the entire document, and their choice of distance metric for calculating similarity between the vector of contexts representing each term.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4650">
<title id=" W05-1011.xml">approximate searching for distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finding synonyms using distributional similarity involves performing nearest-neighbour search over the context vectors for each term.
</prevsent>
<prevsent>this is very computationally intensive and scales according to the vocabulary size and the number of contexts for each term.
</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
curran and moens (2002<papid> W02-0908 </papid>b) have demonstrated that dramatically increasing the quantity of text used to extract contexts significantly improves synonym qual ity.</citsent>
<aftsection>
<nextsent>unfortunately, this also increases the vocabulary size and the number of contexts for each term, making the use of huge datasets infeasible.there have been many data structures and approximation algorithms proposed to reduce the computational complexity of nearest-neighbour search(chavez et al, 2001).
</nextsent>
<nextsent>many of these approaches reduce the search space by using clustering techniques to generate an index of near-neighbours.
</nextsent>
<nextsent>we use the spacial approximation sample hierarchy (sash)data structure developed by houle (2003b) as it allows more control over the efficiency-approximation trade-off than other approximation methods.
</nextsent>
<nextsent>this paper describes integrating the sash intoan existing distributional similarity system (curran, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4658">
<title id=" W05-1011.xml">approximate searching for distributional similarity </title>
<section> distributional similarity.  </section>
<citcontext>
<prevsection>
<prevsent>a context relation is defined as tuple (w, r,w?)where is term, which occurs in some grammatical relation with another word w?
</prevsent>
<prevsent>in some sentence.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we refer to the tuple (r,w?) as an attribute of w. for example, (dog, diect-obj, walk) indicates that dog was the direct object of walk in sentence.context extraction begins with maximum entropy pos tagger and chunker (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the grefenstette (1994) relation extractor produces context relations that are then lemmatised using the minnen et al (2000) <papid> W00-1427 </papid>morphological analyser.</nextsent>
<nextsent>the relations for each term are collected together and counted, producing context vector of attributes and their frequencies in the corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4659">
<title id=" W05-1011.xml">approximate searching for distributional similarity </title>
<section> distributional similarity.  </section>
<citcontext>
<prevsection>
<prevsent>in some sentence.
</prevsent>
<prevsent>we refer to the tuple (r,w?) as an attribute of w. for example, (dog, diect-obj, walk) indicates that dog was the direct object of walk in sentence.context extraction begins with maximum entropy pos tagger and chunker (ratnaparkhi, 1996).<papid> W96-0213 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
the grefenstette (1994) relation extractor produces context relations that are then lemmatised using the minnen et al (2000) <papid> W00-1427 </papid>morphological analyser.</citsent>
<aftsection>
<nextsent>the relations for each term are collected together and counted, producing context vector of attributes and their frequencies in the corpus.
</nextsent>
<nextsent>2.2 measures and weights.
</nextsent>
<nextsent>both nearest-neighbour and cluster analysis methods require distance measure that calculates the similarity between context vectors.
</nextsent>
<nextsent>curran (2004) decomposes this measure into measure and weightfunctions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4686">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a novel aspect of our approach is the use of verb, slot, and noun class information as the basis for backing off in our probability model.
</prevsent>
<prevsent>we achieve 5065% reduction in the error rate over an informed baseline, indicating the potential of our approach for task that has heretofore relied on large amounts of manually generated training data.
</prevsent>
</prevsection>
<citsent citstr=" W98-1106 ">
semantic annotation of text corpora is needed to support tasks such as information extraction andquestion-answering (e.g., riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>niu and hirst, 2004).<papid> W04-0509 </papid></citsent>
<aftsection>
<nextsent>in particular, labelling the semantic roles of the arguments of verb (or any predicate), as in (1) and (2), provides crucial information about the relations among event participants.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>kiva .
</nextsent>
<nextsent>    admires mats ff  2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4688">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a novel aspect of our approach is the use of verb, slot, and noun class information as the basis for backing off in our probability model.
</prevsent>
<prevsent>we achieve 5065% reduction in the error rate over an informed baseline, indicating the potential of our approach for task that has heretofore relied on large amounts of manually generated training data.
</prevsent>
</prevsection>
<citsent citstr=" W04-0509 ">
semantic annotation of text corpora is needed to support tasks such as information extraction andquestion-answering (e.g., riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>niu and hirst, 2004).<papid> W04-0509 </papid></citsent>
<aftsection>
<nextsent>in particular, labelling the semantic roles of the arguments of verb (or any predicate), as in (1) and (2), provides crucial information about the relations among event participants.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>kiva .
</nextsent>
<nextsent>    admires mats ff  2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4689">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>    admires mats ff  2.
</prevsent>
<prevsent>jo flfiffi ff ! returned to london  #  $  $ $%&amp;.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
because of the importance of this task, number of recent methods have been proposed for automatic semantic role labelling (e.g., gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman et al , 2003; <papid> W03-1007 </papid>hacioglu et al , 2003; thompson et al , 2003).</citsent>
<aftsection>
<nextsent>these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</nextsent>
<nextsent>to achieve this, we take bootstrapping?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4691">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>    admires mats ff  2.
</prevsent>
<prevsent>jo flfiffi ff ! returned to london  #  $  $ $%&amp;.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
because of the importance of this task, number of recent methods have been proposed for automatic semantic role labelling (e.g., gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman et al , 2003; <papid> W03-1007 </papid>hacioglu et al , 2003; thompson et al , 2003).</citsent>
<aftsection>
<nextsent>these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</nextsent>
<nextsent>to achieve this, we take bootstrapping?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4692">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>    admires mats ff  2.
</prevsent>
<prevsent>jo flfiffi ff ! returned to london  #  $  $ $%&amp;.
</prevsent>
</prevsection>
<citsent citstr=" W03-1006 ">
because of the importance of this task, number of recent methods have been proposed for automatic semantic role labelling (e.g., gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman et al , 2003; <papid> W03-1007 </papid>hacioglu et al , 2003; thompson et al , 2003).</citsent>
<aftsection>
<nextsent>these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</nextsent>
<nextsent>to achieve this, we take bootstrapping?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4693">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>    admires mats ff  2.
</prevsent>
<prevsent>jo flfiffi ff ! returned to london  #  $  $ $%&amp;.
</prevsent>
</prevsection>
<citsent citstr=" W03-1007 ">
because of the importance of this task, number of recent methods have been proposed for automatic semantic role labelling (e.g., gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman et al , 2003; <papid> W03-1007 </papid>hacioglu et al , 2003; thompson et al , 2003).</citsent>
<aftsection>
<nextsent>these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</nextsent>
<nextsent>to achieve this, we take bootstrapping?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4694">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jo flfiffi ff ! returned to london  #  $  $ $%&amp;.
</prevsent>
<prevsent>because of the importance of this task, number of recent methods have been proposed for automatic semantic role labelling (e.g., gildea and jurafsky, 2002; <papid> J02-3001 </papid>gildea and palmer, 2002; <papid> P02-1031 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman et al , 2003; <papid> W03-1007 </papid>hacioglu et al , 2003; thompson et al , 2003).</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</citsent>
<aftsection>
<nextsent>to achieve this, we take bootstrapping?
</nextsent>
<nextsent>approach (e.g., hindle and rooth, 1993; <papid> J93-1005 </papid>yarowsky, 1995; <papid> P95-1026 </papid>jones et al ,1999), which initially makes only the role assignments that are unambiguous according to verb lexicon.</nextsent>
<nextsent>we then iteratively: create probability model based on the currently annotated semantic roles, use this probability model to assign roles that are deemed to have sufficient evidence, and add the newly labelled arguments to our annotated set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4695">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</prevsent>
<prevsent>to achieve this, we take bootstrapping?</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
approach (e.g., hindle and rooth, 1993; <papid> J93-1005 </papid>yarowsky, 1995; <papid> P95-1026 </papid>jones et al ,1999), which initially makes only the role assignments that are unambiguous according to verb lexicon.</citsent>
<aftsection>
<nextsent>we then iteratively: create probability model based on the currently annotated semantic roles, use this probability model to assign roles that are deemed to have sufficient evidence, and add the newly labelled arguments to our annotated set.
</nextsent>
<nextsent>as we iterate, we gradually both grow the size of the annotated set, and relax the evidence thresholds for the probability model, until all arguments have been assigned roles.
</nextsent>
<nextsent>to our knowledge, this is the first unsupervised semantic role labelling system applied to general semantic roles in domain-general corpus.
</nextsent>
<nextsent>in similar vein of work, riloff and colleagues (riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>jones et al , 1999) used bootstrapping to learn case frames?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4696">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these supervised methods are limited by their reliance on the manually role tagged corpora of framenet (baker et al , 1998) <papid> P98-1013 </papid>or propbank (palmer et al , 2003) as training data, which are expensive to produce, are limited in size, and may not be representative.we have developed novel method of unsupervised semantic role labelling that avoids the need for expensive manual labelling of text, and enables the use of large, representative corpus.</prevsent>
<prevsent>to achieve this, we take bootstrapping?</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
approach (e.g., hindle and rooth, 1993; <papid> J93-1005 </papid>yarowsky, 1995; <papid> P95-1026 </papid>jones et al ,1999), which initially makes only the role assignments that are unambiguous according to verb lexicon.</citsent>
<aftsection>
<nextsent>we then iteratively: create probability model based on the currently annotated semantic roles, use this probability model to assign roles that are deemed to have sufficient evidence, and add the newly labelled arguments to our annotated set.
</nextsent>
<nextsent>as we iterate, we gradually both grow the size of the annotated set, and relax the evidence thresholds for the probability model, until all arguments have been assigned roles.
</nextsent>
<nextsent>to our knowledge, this is the first unsupervised semantic role labelling system applied to general semantic roles in domain-general corpus.
</nextsent>
<nextsent>in similar vein of work, riloff and colleagues (riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>jones et al , 1999) used bootstrapping to learn case frames?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4699">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in similar vein of work, riloff and colleagues (riloff and schmelzenbach, 1998; <papid> W98-1106 </papid>jones et al , 1999) used bootstrapping to learn case frames?</prevsent>
<prevsent>for verbs, but their approach has been applied in very narrow topic domains with topic-specific roles.</prevsent>
</prevsection>
<citsent citstr=" C02-1132 ">
in other work, gildea (2002) <papid> C02-1132 </papid>has explored unsupervised methods to discover role-slot mappings for verbs, but not to apply this knowledge to label text with roles.</citsent>
<aftsection>
<nextsent>our approach also differs from earlier work inits novel use of classes of information in backing off to less specific role probabilities (in contrast to using simple subsets of information, as in gildea and jurafsky, 2002).<papid> J02-3001 </papid></nextsent>
<nextsent>if warranted, we base our decisions on the probability of role given the verb, the syntactic slot (syntactic argument position), and the noun occurring in that slot.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4716">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>particular noun, and preposition if there is one, used in the instance.
</prevsent>
<prevsent>classes of nouns in the model are given by the wordnet hierarchy.
</prevsent>
</prevsection>
<citsent citstr=" J02-2003 ">
determining the appropriate level of generalization for noun is an open problem (e.g., clark and weir, 2002).<papid> J02-2003 </papid></citsent>
<aftsection>
<nextsent>currently, we use cut through wordnet including all the top categories, except for the category entity?; the latter, because of its generality, is replaced in the cut by its immediate children (schulte im walde, 2003).
</nextsent>
<nextsent>given noun argument, all of its ancestors that appear in this cut are used as the class(es) for the noun.
</nextsent>
<nextsent>(credit for noun is apportioned equally across multipleclasses.)
</nextsent>
<nextsent>unknown words placed in separate category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4717">
<title id=" W04-3213.xml">unsupervised semantic role labeling </title>
<section> the probability model.  </section>
<citcontext>
<prevsection>
<prevsent>unknown words placed in separate category.
</prevsent>
<prevsent>this yields noun classification system that is very coarse and that does not distinguish between senses, but which is simple and computationally feasible.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
thus captures consistent relations between verb and class of nouns, regardless of the slot in which the noun occurs.verb classes have been shown to be very important in capturing generalizations across verb behaviour in computational systems (e.g., palmer, 2000; merlo and stevenson, 2001).<papid> J01-3003 </papid></citsent>
<aftsection>
<nextsent>in semantic role labelling using verbnet, they are particularly relevant since the classes are based on commonality of role-labelled syntactic frames (kipper et al ,2000).
</nextsent>
<nextsent>the class of verb in our model is its verb net class that is compatible with the current frame.
</nextsent>
<nextsent>when multiple classes are compatible, we apportion the counts uniformly among them.
</nextsent>
<nextsent>for probability   , then, we generalize over all verbs in class of the target verb, giving us much more extensive data over relevant role assignments to particular slot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4744">
<title id=" W05-0909.xml">meteor an automatic metric for mt evaluation with improved correlation with human judgments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is shown to be an improvement on using simply unigramprecision, unigram-recall and their harmonic f1 combination.
</prevsent>
<prevsent>we also perform experiments to show the relative contributions of the various mapping modules.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
automatic metrics for machine translation (mt) evaluation have been receiving significant attention in the past two years, since ibm bleu metric was proposed and made available (papineni et al 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>bleu and the closely related nist metric (doddington, 2002) have been extensively used for comparative evaluation of the various mt systems developed under the darpa tides research program, as well as by other mt researchers.
</nextsent>
<nextsent>the utility and attractiveness of automatic metrics for mt evaluation has consequently been widely recognized by the mt community.
</nextsent>
<nextsent>evaluating an mt system using such automatic metrics is much faster, easier and cheaper compared to human evaluations, which require trained bilingual evaluators.
</nextsent>
<nextsent>in addition to their utility for comparing the performance of different systems on common translation task, automatic metrics can be applied on frequent and ongoing basis during system development, in order to guide the development of the system based on concrete performance improvements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4746">
<title id=" W05-0909.xml">meteor an automatic metric for mt evaluation with improved correlation with human judgments </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>as our matching approach improves, the need for multiple references for the metric may in fact diminish.
</prevsent>
<prevsent>nevertheless, we are exploring ways in which to improve our matching against multiple references.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
recent work by (pang et al 2003) <papid> N03-1024 </papid>provides the mechanism for producing semantically meaningful additional synthetic?</citsent>
<aftsection>
<nextsent>references from small set of real references.
</nextsent>
<nextsent>we plan to explore whether using such synthetic references can improve the performance of our metric.
</nextsent>
<nextsent>weigh matches produced by different modules differently: our current multi-stage approach prefers metric imposes priority on the different matching modules.
</nextsent>
<nextsent>however, once all the stages have been run, unigrams mapped through different mapping modules are treated the same.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4747">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P06-4007 ">
this paper describes novel framework for using scenario knowledge in open domain question answering (q/a) applications that uses state-of-the-art textual entailment system (hickl et al, 2006<papid> P06-4007 </papid>b) inorder to discover textual information relevant to the set of topics associated with scenario description.</citsent>
<aftsection>
<nextsent>an intrinsic and an extrinsic evaluation of this method is presented in the context of an automatic q/asystem and results from several user scenarios are discussed.
</nextsent>
<nextsent>users of todays automatic question-answering(q/a) systems generally have complex information needs that cannot be satisfied by asking single questions in isolation.
</nextsent>
<nextsent>when users interact with q/a systems, they often formulate sets of queries that they believe will help them gather the information that needed to perform one or more specific tasks.
</nextsent>
<nextsent>while human users are generally able to identify their information needs independently, the information needs of organizations are often presented in the form of short prose descriptions ? known as scenarios ? which outline the range of knowledge sought by customer in order to achieve specific outcome or to accomplish particular task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4753">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while human users are generally able to identify their information needs independently, the information needs of organizations are often presented in the form of short prose descriptions ? known as scenarios ? which outline the range of knowledge sought by customer in order to achieve specific outcome or to accomplish particular task.
</prevsent>
<prevsent>(an example of one scenario is presented in figure 1.)recent work in q/a has sought to use information derived from these kinds of scenarios in order to retrieve sets of answers that are more relevant ? and responsive ? to customers information needs.
</prevsent>
</prevsection>
<citsent citstr=" P05-1026 ">
while (harabagiu et al, 2005) <papid> P05-1026 </papid>used topic signatures (lin and hovy, 2000; <papid> C00-1072 </papid>scenario description the customer has commissioned research project looking at the impact of the outsourcing of american jobson the united states?</citsent>
<aftsection>
<nextsent>relationship with india.
</nextsent>
<nextsent>after conducting research on u.s. companies currently doing business in india, the customer wants to know why american corporations have sought to outsource jobs to india, the types of economic advantages that american companies could gain from relocating to india, and the kinds of economic or political inducements that india has offered to american companies looking to outsource jobs there.
</nextsent>
<nextsent>the customer is not interested in demographic information on indian employees of american firms.
</nextsent>
<nextsent>table 1: example of user scenario.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4754">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while human users are generally able to identify their information needs independently, the information needs of organizations are often presented in the form of short prose descriptions ? known as scenarios ? which outline the range of knowledge sought by customer in order to achieve specific outcome or to accomplish particular task.
</prevsent>
<prevsent>(an example of one scenario is presented in figure 1.)recent work in q/a has sought to use information derived from these kinds of scenarios in order to retrieve sets of answers that are more relevant ? and responsive ? to customers information needs.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
while (harabagiu et al, 2005) <papid> P05-1026 </papid>used topic signatures (lin and hovy, 2000; <papid> C00-1072 </papid>scenario description the customer has commissioned research project looking at the impact of the outsourcing of american jobson the united states?</citsent>
<aftsection>
<nextsent>relationship with india.
</nextsent>
<nextsent>after conducting research on u.s. companies currently doing business in india, the customer wants to know why american corporations have sought to outsource jobs to india, the types of economic advantages that american companies could gain from relocating to india, and the kinds of economic or political inducements that india has offered to american companies looking to outsource jobs there.
</nextsent>
<nextsent>the customer is not interested in demographic information on indian employees of american firms.
</nextsent>
<nextsent>table 1: example of user scenario.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4756">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the customer is not interested in demographic information on indian employees of american firms.
</prevsent>
<prevsent>table 1: example of user scenario.
</prevsent>
</prevsection>
<citsent citstr=" C04-1084 ">
harabagiu, 2004) <papid> C04-1084 </papid>computed automatically from collections of documents relevant to scenario in order to approximate the semantic content of ascenario, (narayanan and harabagiu, 2004) <papid> C04-1100 </papid>employed formal models of the interrelated events,actions, states, and relations implicit to scenario in order to produce fine-grained, context sensitive inferences that could be used to answer questions.</citsent>
<aftsection>
<nextsent>scenario knowledge was also included in the form of axiomatic logic transformation developed in (moldovan et al, 2003).<papid> N03-1022 </papid></nextsent>
<nextsent>under this approach, information extracted from the scenario narrative is converted to logical axioms that can used in conjunction with logic prover in order justify answers returned for questions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4758">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the customer is not interested in demographic information on indian employees of american firms.
</prevsent>
<prevsent>table 1: example of user scenario.
</prevsent>
</prevsection>
<citsent citstr=" C04-1100 ">
harabagiu, 2004) <papid> C04-1084 </papid>computed automatically from collections of documents relevant to scenario in order to approximate the semantic content of ascenario, (narayanan and harabagiu, 2004) <papid> C04-1100 </papid>employed formal models of the interrelated events,actions, states, and relations implicit to scenario in order to produce fine-grained, context sensitive inferences that could be used to answer questions.</citsent>
<aftsection>
<nextsent>scenario knowledge was also included in the form of axiomatic logic transformation developed in (moldovan et al, 2003).<papid> N03-1022 </papid></nextsent>
<nextsent>under this approach, information extracted from the scenario narrative is converted to logical axioms that can used in conjunction with logic prover in order justify answers returned for questions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4761">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>table 1: example of user scenario.
</prevsent>
<prevsent>harabagiu, 2004) <papid> C04-1084 </papid>computed automatically from collections of documents relevant to scenario in order to approximate the semantic content of ascenario, (narayanan and harabagiu, 2004) <papid> C04-1100 </papid>employed formal models of the interrelated events,actions, states, and relations implicit to scenario in order to produce fine-grained, context sensitive inferences that could be used to answer questions.</prevsent>
</prevsection>
<citsent citstr=" N03-1022 ">
scenario knowledge was also included in the form of axiomatic logic transformation developed in (moldovan et al, 2003).<papid> N03-1022 </papid></citsent>
<aftsection>
<nextsent>under this approach, information extracted from the scenario narrative is converted to logical axioms that can used in conjunction with logic prover in order justify answers returned for questions.
</nextsent>
<nextsent>in this paper, we propose that scenario-relevant passages in natural language texts can be identified by recognizing semantic relation, known as contextual entailment (ce), that exists between text passage and one of set of sub questions that are conventionally implied by scenario.
</nextsent>
<nextsent>under this model, we expect that scenario can be considered to contextually entail passage t, when there exists at least one sub question derived from that textually entails the passage t. we show thatby using state-of-the-art textual entailment system (hickl et al, 2006<papid> P06-4007 </papid>b), we can provide q/a systems with another mechanism for approximating the inference between questions and relevant answers.</nextsent>
<nextsent>we show how each of these cases of con 32 textual entailment can be computed and how it can be used in the intrinsic and extrinsic evaluation of q/a system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4771">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> recognizing textual entailment.  </section>
<citcontext>
<prevsection>
<prevsent>q = b0 + ? j=1 bjxj + we believe that since logistic regression uses amaximum likelihood method, it is suitable technique for normalizing across range of confidence values output by the te system.
</prevsent>
<prevsent>34 coreference coreference ne alia sing concept textual input 1 textual input 2 lexical alignment paraphrase acquisition alignment module www training corpora classifier yes no features alignment dependency features paraphrase features semantic/ pragmatic features feature extraction classification module lexico semantic pos/ ner synonyms/ antonyms normalization syntactic semantic temporal parsing modality detection speech act recognition pragmatics fact ivity detection belief recognition preprocessing figure 4: textual entailment architecture.
</prevsent>
</prevsection>
<citsent citstr=" H05-1049 ">
recent work in computational semantics (haghighi et al, 2005; <papid> H05-1049 </papid>hickl et al, 2006<papid> P06-4007 </papid>b; maccartney et al, 2006) <papid> N06-1006 </papid>has demonstrated the viability of supervised machine learning-basedapproaches to the recognition of textual entailment (te).</citsent>
<aftsection>
<nextsent>while these approaches have not incorporated the forms of structured world knowledge featured in many logic-based te systems, classification-based approaches have been consistently among the top-performing systems in both the 2005 and 2006 pascal recognizing textual entailment (rte) challenges (dagan et al., 2005), with the best systems (such as (hickl et al, 2006<papid> P06-4007 </papid>b)) correctly identifying instances of textual entailment more than 75% of the time.</nextsent>
<nextsent>the architecture of our te system is presented in figure 4.1 pairs of texts are initially sent to preprocessing module, which performs syntactic and semantic parsing of each sentence, resolves coreference, and annotates entities and predicates with wide range of lexico-semantic and prag 1for more information on the te system described in this section, please see (hickl et al, 2006<papid> P06-4007 </papid>b) and (harabagiu and hickl, 2006).<papid> P06-1114 </papid>matic information, including named entity information, synonymy and antonymy information, and polarity and modality information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4778">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> recognizing textual entailment.  </section>
<citcontext>
<prevsection>
<prevsent>q = b0 + ? j=1 bjxj + we believe that since logistic regression uses amaximum likelihood method, it is suitable technique for normalizing across range of confidence values output by the te system.
</prevsent>
<prevsent>34 coreference coreference ne alia sing concept textual input 1 textual input 2 lexical alignment paraphrase acquisition alignment module www training corpora classifier yes no features alignment dependency features paraphrase features semantic/ pragmatic features feature extraction classification module lexico semantic pos/ ner synonyms/ antonyms normalization syntactic semantic temporal parsing modality detection speech act recognition pragmatics fact ivity detection belief recognition preprocessing figure 4: textual entailment architecture.
</prevsent>
</prevsection>
<citsent citstr=" N06-1006 ">
recent work in computational semantics (haghighi et al, 2005; <papid> H05-1049 </papid>hickl et al, 2006<papid> P06-4007 </papid>b; maccartney et al, 2006) <papid> N06-1006 </papid>has demonstrated the viability of supervised machine learning-basedapproaches to the recognition of textual entailment (te).</citsent>
<aftsection>
<nextsent>while these approaches have not incorporated the forms of structured world knowledge featured in many logic-based te systems, classification-based approaches have been consistently among the top-performing systems in both the 2005 and 2006 pascal recognizing textual entailment (rte) challenges (dagan et al., 2005), with the best systems (such as (hickl et al, 2006<papid> P06-4007 </papid>b)) correctly identifying instances of textual entailment more than 75% of the time.</nextsent>
<nextsent>the architecture of our te system is presented in figure 4.1 pairs of texts are initially sent to preprocessing module, which performs syntactic and semantic parsing of each sentence, resolves coreference, and annotates entities and predicates with wide range of lexico-semantic and prag 1for more information on the te system described in this section, please see (hickl et al, 2006<papid> P06-4007 </papid>b) and (harabagiu and hickl, 2006).<papid> P06-1114 </papid>matic information, including named entity information, synonymy and antonymy information, and polarity and modality information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4791">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> recognizing textual entailment.  </section>
<citcontext>
<prevsection>
<prevsent>recent work in computational semantics (haghighi et al, 2005; <papid> H05-1049 </papid>hickl et al, 2006<papid> P06-4007 </papid>b; maccartney et al, 2006) <papid> N06-1006 </papid>has demonstrated the viability of supervised machine learning-basedapproaches to the recognition of textual entailment (te).</prevsent>
<prevsent>while these approaches have not incorporated the forms of structured world knowledge featured in many logic-based te systems, classification-based approaches have been consistently among the top-performing systems in both the 2005 and 2006 pascal recognizing textual entailment (rte) challenges (dagan et al., 2005), with the best systems (such as (hickl et al, 2006<papid> P06-4007 </papid>b)) correctly identifying instances of textual entailment more than 75% of the time.</prevsent>
</prevsection>
<citsent citstr=" P06-1114 ">
the architecture of our te system is presented in figure 4.1 pairs of texts are initially sent to preprocessing module, which performs syntactic and semantic parsing of each sentence, resolves coreference, and annotates entities and predicates with wide range of lexico-semantic and prag 1for more information on the te system described in this section, please see (hickl et al, 2006<papid> P06-4007 </papid>b) and (harabagiu and hickl, 2006).<papid> P06-1114 </papid>matic information, including named entity information, synonymy and antonymy information, and polarity and modality information.</citsent>
<aftsection>
<nextsent>once preprocessing is complete, texts are then sent to an alignment module, which uses lexical alignment module in conjunction with paraphrase acquisition module in order to determine the likelihood that pairs of elements selected from each sentence contain corresponding information that could be used in recognizing textual entailment.
</nextsent>
<nextsent>lexical alignment is performed using amaximum entropy-based classifier which computes an alignment probability p(a) equal to the likelihood that term selected from one text corresponds to an element selected from another text.
</nextsent>
<nextsent>once these pairs of corresponding elements are identified, alignment information is then used in order to extract portions of texts that could be related via one or more phrase-level alternation sor paraphrases?.
</nextsent>
<nextsent>in order to acquire these alternations, the most likely pairs of aligned elements were then sent to paraphrase acquisition module, which extracts sentences that contain instances of both aligned elements from the world wide web.output from these two modules are then combined in final classication module, which uses features derived from (1) lexico-semantic properties, (2) semantic dependencies, (3) predicate based features (including polarity and modality),(4) lexical alignment, and (5) paraphrase acquisition in order learn decision tree classifier capable of determining whether an entailment relationship exists for pair of texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4796">
<title id=" W06-0705.xml">using scenario knowledge in automatic question answering </title>
<section> extrinsic evaluation of contextual.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate the quality of each set of answers, and for the answer set 2 and 3, we produce separate evaluation for each configuration for the contextual entailment.
</prevsent>
<prevsent>entailment questions asked in response to user scenario tend to be complex.
</prevsent>
</prevsection>
<citsent citstr=" W04-2508 ">
following work in (hickl et al, 2004), <papid> W04-2508 </papid>we believe complex questions can be answered in one of two ways: either by(1) using techniques (similar to the ones proposed in (harabagiu et al, 2006)) for automatically decomposing complex questions into sets ofinformationally-simpler questions, or by (2) using multi-document summarization (mds) system (such as the one described in (lacatusu et al,2006)) in order to assemble ranked list of passages which contain information that is potentially relevant to the users question.</citsent>
<aftsection>
<nextsent>first, we expect that contextual entailment can be used to select the decompositions of complex question that are most closely related to scenario.by assigning more confidence to the decomposi tions that are contextually entailed by scenario,systems can select set of answers that are relevant to both the user scenario ? and the users question.
</nextsent>
<nextsent>in contrast, contextual entailment can beused in conjunction with the output of mds sys tem: once summary has been constructed fromthe passages retrieved for query, contextual en 36 user scenario question keyword extraction system question answering entailment contextual question decomposition documents entailment contextual multi document summarization system candidate sub questions query relevant documents candidate answers summary answers ranked figure 6: framework for extrinsic evaluation of contextual entailment in q/a. tail ment can be used to select the most relevant sentences from the summary.the architecture of this proposed system is illustrated in figure 6.
</nextsent>
<nextsent>when using contextual entailment for selecting question decompositions, we relyon the method reported in (harabagiu et al, 2006) which generates questions by using random walk on bipar tite graph of salient relations and answers.
</nextsent>
<nextsent>in this case, the recognition of entailment between questions operates as filter, forcing questions that arenot entailed by any of the signature answers derived from the scenario context (see figure 3) to be dropped from consideration.when entailment information is used for reranking candidate answers, the summary is added to the scenario context, each summary sentence being treated akin to signature answer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4804">
<title id=" W05-0406.xml">identifying non referential it a machine learning approach incorporating linguistically motivated patterns </title>
<section> a subset of the bnc sampler corpus (burnard, </section>
<citcontext>
<prevsection>
<prevsent>it appears in over 10% of the sentences in our corpus.
</prevsent>
<prevsent>the corpus is described in further detail in section 3.previous research on this topic is fairly limited.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
paice and husk (1987) introduces rule-based method for identifying non-referential it and lappinand leass (1994) <papid> J94-4002 </papid>and denber (1998) describe rule based components of their pronoun resolution systems which identify non-referential it.</citsent>
<aftsection>
<nextsent>evans (2001)describes machine learning system which classifies it into seven types based on the type of referent.
</nextsent>
<nextsent>their approaches are described in detail in section 4.
</nextsent>
<nextsent>in section 5 we describe our system which com-.
</nextsent>
<nextsent>bines and extends elements of the systems developed by paice and husk (1987) and evans (2001), and the results are presented in section 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZB4806">
<title id=" W05-0406.xml">identifying non referential it a machine learning approach incorporating linguistically motivated patterns </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>presence of an immediately preceding preposition using our training and testing data with the same algorithm from timbl, we obtained results similar to evanss, shown in table 6.
</prevsent>
<prevsent>the slightly higher accuracy is likely due to corpus differences or the reduced feature set which ignores features largely relevant to other types of it.current state-of-the-art reference resolution systems typically include filters for non-referential noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" C02-1139 ">
an example of such system is ng and cardie (2002), <papid> C02-1139 </papid>which shows the improvement in reference resolution when non-referential noun phrases are identified.</citsent>
<aftsection>
<nextsent>results are not given for the specific task of identifying non-referential it, so direct comparison is not possible.
</nextsent>
<nextsent>as seen in the previous section, both rule-based and machine learning methods have been shown to be fairly effective at identifying non-referential it.rule-based methods look for the grammatical patterns known to be associated with non-referential it but are limited by fixed word lists; machine learning methods can handle open classes of words, but areless able to generalize about the grammatical patterns associated with non-referential it from small training set.
</nextsent>
<nextsent>evanss memory-based learning system showed slight integration of rules into the machine learning system by using features such as the presence of following that.
</nextsent>
<nextsent>given the descriptions of types of non referential it from section 2, it is possible to create more specific rules which detect the fixed grammatical patterns associated with non-referential it such as it verb that or it verb adj to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>