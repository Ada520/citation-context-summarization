37	pseudo-projective parsing was proposed by nivre and nilsson as a way of dealing with non-projective structures in a projective data-driven parser. 
3	moreover, the study of formal grammarsisonly partially relevant for research on data-driven dependency parsing, where most systems are not grammar-based but rely on inductive inference from treebank data . 
14	in this section we combine the best results from the previous section with the graph transformations proposed by nivre and nilsson to recover non-projective dependencies. 
38	we projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called head by nivre and nilsson , which means that a lifted arc is assigned the label r‚Üëh, where r is the original label and h is the label of the original head in the nonprojective dependency graph. 
6	for handling non-projective relations, nivre and nilsson suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective. 
32	many thanks to the sdt people for granting the special license for conll-x and to tomaÀáz erjavec for converting the danish dependency treebank13 ; swedish: talbanken0514 ; turkish: metusabancƒ± treebank15 . 
5	most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees , or on incorporating nonlocal dependency information in nonterminal categories in constituency representations or in the categories used to label arcs in dependency representations . 
2	recent work by nivre and nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing . 
33	nivre's parser has been tested for swedish , english , czech , bulgarian and chinese cheng et al , while mcdonald‚Äôs parser has been applied to english , czech and, very recently, danish . 
35	although the parser only derives projective graphs, the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of nivre and nilsson . 
31	the pseudo-projective approach : transform non-projective training trees to projective ones but encode the information necessary to make the inverse transformation in the deprel, so that this inverse transformation can also be carried out on the test trees . 
15	thus, nivre and nilsson improve parsing accuracy for maltparser by projectivizing training data and applying an inverse transformation to the output of the parser, while hall and nov¬¥ak apply post-processing to the output of charniak‚Äôs parser . 
24	most previous dependency parsing models have focused on projective trees, including the work of eisner , collins et al , yamada and matsumoto , nivre and scholz , and mcdonald et al . 
10	jin et al is an example of it for chinese, where the authors describe an adaptation of nivre's parser to bidirectionality. 
26	this is in contrast to other non-projective methods, such as that of nivre and nilsson , who implement non-projectivity in a pseudo-projective parser with edge transformations. 
7	the following treebanks were used for training the parser: . 
28	as a general result, our experiments confirm previous studies on non-projective dependency parsing : the phenomenon of non-projectivity cannot be ignored without also ignoring a significant portion of real-world data . 
27	the pseudo-projective parser of nivre and nilsson . 
34	following nivre and nilsson we use the following definition: ‚Äúan arc is projective iff all nodes occurring between i and j are dominated by i (where dominates is the transitive closure of the arc rela26many thanks to montserrat civit and toni mart¬¥ƒ± for allowing us to use cast3lb for conll-x and to amit dubey for converting the treebank. 
30	however, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation . 
19	maltparser is a data-driven parser-generator, which can induce a dependency parser from a treebank, and which supports several parsing algorithms and learning algorithms. 
21	table 2: transformations; t = transformation; as = attachment score of œÑ‚àí1 ) compared to ‚àÜt maltparser is used with the parsing algorithm of nivre together with the feature model used for parsing czech by nivre and nilsson . 
8	you could map a non-projective dependency tree to a projective one, learn and predict the tree, then bring it back to the non-projective dependency tree . 
13	we see that pseudo-projective parsing brings a very consistent increase in accuracy of at least 1.5 percentage points, which is more than that reported by nivre and nilsson , and that the addition of the ps-to-ms transformations increases accuracy with about the same margin. 
16	in addition, we replace mbl with svm, a learning algorithm that tends to give higher accuracy in classifier-based parsing although it is more 6more precisely, we use the variant called path in nivre and nilsson . 
12	this work was made possible because of the annotated corpora that were kindly provided to us: arabic , bulgarian , chinese , czech , danish , dutch , german , japanese , portuguese , slovene , spanish , swedish , and turkish . 
40	with the emergence of the important role of word-to-word relations in parsing , dependency grammars have gained acertain popularity; e.g., yamada and matsumoto for english, kudo and matsumoto , sekine et al for japanese, chung and rim for korean, nivre et al for swedish, nivre and nilsson for czech, among others. 
11	we trained the models on projectivizedù graphs following nivre and nilsson method. 
39	graph transformations for recovering non-projective structures . 
9	our experiments were conducted on conll-x shared task, with various datasets . 
22	to deal with non-projective languages, we use a similar approach of to map non-projective trees to projective trees. 
4	it should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves . 
25	nivre and nilsson presented a parsing model that allows for the introduction of non-projective edges into dependency trees through learned edge transformations within their memory-based parser. 
18	in section 4.2 we use mbl, again with the same settings as nivre and nilsson ,3 and in section 4.2 we use svm with a polynomial kernel of degree 2.4 the metrics for evaluation are the attachment score , i.e., the proportion of words that are assigned the correct head, and the exact match score , i.e., the proportion of sentences that are assigned a completely correct analysis. 
23	the resources provided for 12 languages are described in: . 
36	typical examples are bulgarian , chinese , danish , and swedish . 
29	dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as czech , bulgarian , and turkish . 
17	whether better parsing accuracy can be obtained by transforming 1about 2% of all dependencies are non-projective and about 25% of all sentences have a non-projective dependency graph . 
1	an alternative method, used by charniak in the adaptation of his parser for czech 6 and used by nivre and nilsson , alters the dependency links by raising the governor to a higher node in the tree whenever 5 bilexical dependencies are components of both the collins and charniak parsers and effectively model the types of syntactic subordination that we wish to extract in a dependency tree. 
20	the parser used is maltparser , a freely available system that combines a deterministic parsing strategy with discriminative classifiers for predicting the next parser action. 
