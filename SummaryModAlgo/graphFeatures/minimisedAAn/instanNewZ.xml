<paper>
<cited id="Z0">
<title id=" W03-1012.xml">using ltag based features in parse reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one way to solve this problem is to use kernel function that is tailored for particular nlp applications, such as the tree kernel (collins and duffy, 2001) for statistical parsing.
</prevsent>
<prevsent>in addition to n-gram features, more complex high-level features are often exploited to obtain higher accuracy, especially when discriminative models are used for statistical parsing.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
for example, all possible sub-trees can be used as features (collins and duffy, 2002; <papid> P02-1034 </papid>bod, 2003).<papid> E03-1005 </papid></citsent>
<aftsection>
<nextsent>however, most of the sub-trees are linguistically meaningless, and are source of noisy features thus limiting efficiency and accuracy.
</nextsent>
<nextsent>an alternative to the useof arbitrary sets of sub-trees is to use the set of elementary trees as defined in lexicalized tree adjoining grammar (ltag) (joshi and schabes, 1997).
</nextsent>
<nextsent>ltag based features not only allow more limited and linguistically more valid set of features over sub-trees, they also provide the use of features that use discontinuous sub-trees which are outside the scope of previous tree kernel definitions using arbitrary sub-trees.
</nextsent>
<nextsent>in this paper, we use the ltag based features in the parse reranking problem (collins,2000; collins and duffy, 2002).<papid> P02-1034 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1">
<title id=" W03-1012.xml">using ltag based features in parse reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one way to solve this problem is to use kernel function that is tailored for particular nlp applications, such as the tree kernel (collins and duffy, 2001) for statistical parsing.
</prevsent>
<prevsent>in addition to n-gram features, more complex high-level features are often exploited to obtain higher accuracy, especially when discriminative models are used for statistical parsing.
</prevsent>
</prevsection>
<citsent citstr=" E03-1005 ">
for example, all possible sub-trees can be used as features (collins and duffy, 2002; <papid> P02-1034 </papid>bod, 2003).<papid> E03-1005 </papid></citsent>
<aftsection>
<nextsent>however, most of the sub-trees are linguistically meaningless, and are source of noisy features thus limiting efficiency and accuracy.
</nextsent>
<nextsent>an alternative to the useof arbitrary sets of sub-trees is to use the set of elementary trees as defined in lexicalized tree adjoining grammar (ltag) (joshi and schabes, 1997).
</nextsent>
<nextsent>ltag based features not only allow more limited and linguistically more valid set of features over sub-trees, they also provide the use of features that use discontinuous sub-trees which are outside the scope of previous tree kernel definitions using arbitrary sub-trees.
</nextsent>
<nextsent>in this paper, we use the ltag based features in the parse reranking problem (collins,2000; collins and duffy, 2002).<papid> P02-1034 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z4">
<title id=" W03-1012.xml">using ltag based features in parse reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ltag based features not only allow more limited and linguistically more valid set of features over sub-trees, they also provide the use of features that use discontinuous sub-trees which are outside the scope of previous tree kernel definitions using arbitrary sub-trees.
</prevsent>
<prevsent>in this paper, we use the ltag based features in the parse reranking problem (collins,2000; collins and duffy, 2002).<papid> P02-1034 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0402 ">
we use the support vector machine (svm) (vapnik, 1999) based algorithm proposed in (shen and joshi, 2003) <papid> W03-0402 </papid>as the reranker in this paper.</citsent>
<aftsection>
<nextsent>we apply the tree kernel to derivation trees of ltag, and extract features from derivation trees.
</nextsent>
<nextsent>both the tree kernel and the linear kernel on the richer feature set are used.
</nextsent>
<nextsent>our experiments show that the use of tree kernel on derivation trees makes the notion of tree kernel more powerful and more applicable.
</nextsent>
<nextsent>in this section, we give brief introduction to the lexicalized tree adjoining grammar (more details can be found in (joshi and schabes, 1997)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z6">
<title id=" W03-1012.xml">using ltag based features in parse reranking </title>
<section> lexicalized tree adjoining grammar.  </section>
<citcontext>
<prevsection>
<prevsent>there are two kinds of elementary trees, initial trees and auxiliary trees.elementary trees can be combined through two operations, substitution and adjunction.
</prevsent>
<prevsent>substitution is used to attach an initial tree, and adjunction is used to attach an auxiliary tree.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
in addition to adjunction, we also use sister adjunction as defined in the ltag statistical parser described in (chiang, 2000).<papid> P00-1058 </papid>1 the tree resulting from the combination of elementary trees is is called derived tree.</citsent>
<aftsection>
<nextsent>the tree that records the history of how derived tree is built from the elementary trees is called derivation tree.2we illustrate the ltag formalism using an example.
</nextsent>
<nextsent>example 1: pierre vinken will join the board as non-executive director.
</nextsent>
<nextsent>the derived tree for example 1 is shown in fig.
</nextsent>
<nextsent>1 (we omit the pos tags associated with each word to save space), and fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z7">
<title id=" W03-1012.xml">using ltag based features in parse reranking </title>
<section> parse reranking.  </section>
<citcontext>
<prevsection>
<prevsent>we will show how this property affects our redefined tree kernel later in this paper.
</prevsent>
<prevsent>in our experiments in this paper, we only use ltag grammars where each elementary tree is lexicalized by exactly one word (terminal symbol) on the frontier.
</prevsent>
</prevsection>
<citsent citstr=" P93-1005 ">
in recent years, reranking techniques have been successfully used in statistical parsers to rerank the out put of history-based models (black et al, 1993).<papid> P93-1005 </papid></citsent>
<aftsection>
<nextsent>in this paper, we will use the ltag based features to improve the performance of reranking.
</nextsent>
<nextsent>our motivations for using ltag based features for reranking are the following:?
</nextsent>
<nextsent>unlike the generative model, it is trivial to incorporate features of various kinds in reranking setting.
</nextsent>
<nextsent>furthermore the nature of reranking makes it possible to use global features, 1(join)??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z44">
<title id=" W03-0411.xml">preposition semantic classification via penn treebank and framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, in the cyckb there are close to 200 different types of semantic roles.
</prevsent>
<prevsent>these range from high-level roles (e.g.,beneficiaries) through medium-level roles (e.g., ex changes) to highly specialized roles (e.g., catalyst).1preposition classification using two different semantic role inventories are investigated in this paper, taking advantage of large annotated corpora.after providing background to the work in section 2, experiments over the semantic role annotations are discussed in section 3.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
the results over treebank (marcus et al, 1994) <papid> H94-1020 </papid>are covered first.</citsent>
<aftsection>
<nextsent>treebank include about dozen high-levelroles similar to fill mores. next, experiments using the finer-grained semantic role annotations in framenet version 0.75 (fillmore et al, 2001) are 1part of the cyc kb is freely available at www.opencyc.org.presented.
</nextsent>
<nextsent>framenet includes over 140 roles, approaching but not quite as specialized as cycs inventory.
</nextsent>
<nextsent>section 4 follows with comparison to related work, emphasizing work in broad-coverage preposition disambiguation.
</nextsent>
<nextsent>2.1 semantic roles in the penn treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z46">
<title id=" W03-0411.xml">preposition semantic classification via penn treebank and framenet </title>
<section> classification experiments.  </section>
<citcontext>
<prevsection>
<prevsent>although this can be highly accurate, it will likely overfit the data and generalize poorly.
</prevsent>
<prevsent>to overcome these problems, class-based approach is used for the collocations, with wordnet high-level synsets as the source of the word classes.
</prevsent>
</prevsection>
<citsent citstr=" J99-2002 ">
therefore, in addition to using collocations in the form of other words, this uses collocations in the form of semantic categories.a supervised approach for word-sense disambiguation is used following bruce and wiebe (1999).<papid> J99-2002 </papid></citsent>
<aftsection>
<nextsent>the results described here were obtained using the settings in figure 1.
</nextsent>
<nextsent>these are similar to the settings used by ohara et al (2000) in the first senseval competition, with the exception of thehypernym collocations.
</nextsent>
<nextsent>this shows that for the hy pernym associations, only those words that occur within 5 words of the target prepositions are con sidered.2 the main difference from that of standard wsd approach is that, during the determination of theclass-based collocations, each word token is replaced by synset tokens for its hypernyms in wordnet, several of which might occur more than once.
</nextsent>
<nextsent>this introduces noise due to ambiguity, but given the conditional-independence selection scheme, the preference for hypernym synsets that occur for different words will compensate somewhat.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z47">
<title id=" W03-0411.xml">preposition semantic classification via penn treebank and framenet </title>
<section> classification experiments.  </section>
<citcontext>
<prevsection>
<prevsent>these figures were produced by analyzing the parse trees for the semantic role annotations in the penn treebank.
</prevsent>
<prevsent>features: pos2 part-of-speech 2 words to left pos1: part-of-speech 1 word to left pos+1: part-of-speech 1 word to right pos+2: part-of-speech 2 words to right prep preposition being classified word coll : word collocation for role hypernymcoll : hypernym collocation for role collocation context: word: anywhere in the sentence hypernym: within 5 words of target preposition collocation selection: frequency: f(word)   1 ci threshold: p(c|coll)p(c) p(c)  = 0.2 organization: per-class-binary model selection: overall classifier: decision tree individual classifiers: naive bayes 10-fold cross-validationfigure 1: feature settings used in the preposition classification experiments.
</prevsent>
</prevsection>
<citsent citstr=" W98-1126 ">
ci refers to conditional independence; the per-class-binary organization uses separate binary feature per role (wiebe et al., 1998).<papid> W98-1126 </papid>the best results.</citsent>
<aftsection>
<nextsent>this exploits the specific clues provided by the word collocations while generalizing to unseen cases via the hypernym collocations.
</nextsent>
<nextsent>3.1 penn treebank.
</nextsent>
<nextsent>to see how these conceptual associations are derived, consider the differences in the prior versusclass-based conditional probabilities for the semantic roles of the preposition at?
</nextsent>
<nextsent>in treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z48">
<title id=" W03-0411.xml">preposition semantic classification via penn treebank and framenet </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there has been quite bit of workin this area but mainly for spatial prepositions (jap kowicz and wiebe, 1991; zelinsky-wibbelt, 1993).
</prevsent>
<prevsent>there is currently more interest in this type ofclassification.
</prevsent>
</prevsection>
<citsent citstr=" W02-0802 ">
litkowski (2002) <papid> W02-0802 </papid>presents manually derived rules for disambiguating prepositions, in particular for of?.</citsent>
<aftsection>
<nextsent>srihari et al (2001) presentmanually-derived rules for disambiguating prepositions used in named entities.gildea and jurafsky (2002) <papid> J02-3001 </papid>classify semantic role assignments using all the annotations in framenet, for example, covering all types of verbal arguments.</nextsent>
<nextsent>they use several features derived from the output of parser, such as the constituent type of the phrase (e.g., np) and the grammatical function (e.g., subject).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z49">
<title id=" W03-0411.xml">preposition semantic classification via penn treebank and framenet </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is currently more interest in this type ofclassification.
</prevsent>
<prevsent>litkowski (2002) <papid> W02-0802 </papid>presents manually derived rules for disambiguating prepositions, in particular for of?.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
srihari et al (2001) presentmanually-derived rules for disambiguating prepositions used in named entities.gildea and jurafsky (2002) <papid> J02-3001 </papid>classify semantic role assignments using all the annotations in framenet, for example, covering all types of verbal arguments.</citsent>
<aftsection>
<nextsent>they use several features derived from the output of parser, such as the constituent type of the phrase (e.g., np) and the grammatical function (e.g., subject).
</nextsent>
<nextsent>they include lexical features for the headword of the phrase and the predicating word for the entire annotated frame.
</nextsent>
<nextsent>theyre port an accuracy of 76.9% with baseline of 40.6% over the framenet semantic roles.
</nextsent>
<nextsent>however, dueto the conditioning of the classification on the pred icating word for the frame, the range of roles for particular classification is more limited than in our case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z50">
<title id=" W03-0411.xml">preposition semantic classification via penn treebank and framenet </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>theyre port an accuracy of 76.9% with baseline of 40.6% over the framenet semantic roles.
</prevsent>
<prevsent>however, dueto the conditioning of the classification on the pred icating word for the frame, the range of roles for particular classification is more limited than in our case.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
blaheta and charniak (2000) <papid> A00-2031 </papid>classify semantic role assignments using all the annotations in tree bank.</citsent>
<aftsection>
<nextsent>they use few parser-derived features, suchas the constituent labels for nearby nodes and part of-speech for parent and grandparent nodes.
</nextsent>
<nextsent>they also include lexical features for the head and alternative head (since prepositions are considered asthe head by their parser).
</nextsent>
<nextsent>they report an accuracy of 77.6% over the form/function tags from the penn treebank with baseline of 37.8%,3 their task is somewhat different, since they address all adjuncts, not just prepositions, hence their lower baseline.
</nextsent>
<nextsent>in addition, they include the nominal and adverbial roles, which are syntactic and presumably more predictable than the others in this group.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z52">
<title id=" W02-0713.xml">sharing problems and solutions for machine translation of spoken and written interaction </title>
<section> sharing solutions to shared.  </section>
<citcontext>
<prevsection>
<prevsent>in the latter group, he classifies approaches that use confidence measures, online garbage modeling in keyword spotting, and the use of an additional phoneme recognizer running in parallel to word recognizer.
</prevsent>
<prevsent>these approaches might be adapted to the problem of discriminating misspelled and oov words in chat interaction, just as approaches to spelling correction might provide alternative solutions to the analogous problem in speech recognition.
</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
for example, models of oov words might compete with models of in-vocabulary recognition errors using brill and moores (2000) <papid> P00-1037 </papid>error model for noisy channel spelling correction that takes into account the probabilities of errors occurring in specific positions in the word.</citsent>
<aftsection>
<nextsent>by modeling recognition errors, the model captures the stochastic properties of both the language and the individual recognition system.
</nextsent>
<nextsent>because our goal is not only recognizing, but also translating messages, we are especially interested in solutions that will facilitate the translation system and process.
</nextsent>
<nextsent>consequently, solutions based on modeling the contexts of oov word use and the contexts of nonstandard spellings seem most promising.
</nextsent>
<nextsent>for example, it would be worth exploring whether the templates used in example-based translation could be used to model these contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z53">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper also includes in-depth performance analysis sensitive to properties of the feature space and component classifiers.
</prevsent>
<prevsent>when evaluated on the standard senseval1 and 2 datasets on 4 languages (english, spanish, basque, andswedish), classifier combination performance exceeds the best published results on these datasets.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
classifier combination has been extensively studied in the last decade, and has been shown to be successful in improving the performance of diverse nlp applications, including pos tagging (brill and wu, 1998; van halteren et al, 2001), base noun phrase chunking (sang et al, 2000), parsing (henderson and brill, 1999) <papid> W99-0623 </papid>and word sense disambiguation (kilgarriff and rosenzweig, 2000; stevenson and wilks, 2001).<papid> J01-3001 </papid></citsent>
<aftsection>
<nextsent>there are several reasons why classifier combination is useful.
</nextsent>
<nextsent>first, by consulting the output of multiple classifiers, the system will im prove its robustness.
</nextsent>
<nextsent>second, it is possible that the problem can be decomposed into orthogonal feature spaces (e.g. linguistic constraints and word occurrence statistics) and it is often better to train different classifiers in each of the feature spaces and then combine their output, instead of designing acomplex system that handles the multimodal information.
</nextsent>
<nextsent>third, it has been shown by perrone and cooper (1993) that it is possible to reduce the classification error by factor of
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z54">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper also includes in-depth performance analysis sensitive to properties of the feature space and component classifiers.
</prevsent>
<prevsent>when evaluated on the standard senseval1 and 2 datasets on 4 languages (english, spanish, basque, andswedish), classifier combination performance exceeds the best published results on these datasets.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
classifier combination has been extensively studied in the last decade, and has been shown to be successful in improving the performance of diverse nlp applications, including pos tagging (brill and wu, 1998; van halteren et al, 2001), base noun phrase chunking (sang et al, 2000), parsing (henderson and brill, 1999) <papid> W99-0623 </papid>and word sense disambiguation (kilgarriff and rosenzweig, 2000; stevenson and wilks, 2001).<papid> J01-3001 </papid></citsent>
<aftsection>
<nextsent>there are several reasons why classifier combination is useful.
</nextsent>
<nextsent>first, by consulting the output of multiple classifiers, the system will im prove its robustness.
</nextsent>
<nextsent>second, it is possible that the problem can be decomposed into orthogonal feature spaces (e.g. linguistic constraints and word occurrence statistics) and it is often better to train different classifiers in each of the feature spaces and then combine their output, instead of designing acomplex system that handles the multimodal information.
</nextsent>
<nextsent>third, it has been shown by perrone and cooper (1993) that it is possible to reduce the classification error by factor of
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z56">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>related work in classifier combination is discussed throughout this article.
</prevsent>
<prevsent>for the specific task of word sense disambiguation, the first empirical study was presented in kilgarriff and rosenzweig (2000),where the authors combined the output of the participating senseval1 systems via simple (non weighted) voting, using either absolute majority,relative majority, or unanimous voting.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
stevenson and wilks (2001) <papid> J01-3001 </papid>presented classifier combination framework where 3 disambiguation methods (simulated annealing, subject codes and selectional restrictions) were combined using the timbl memory-based approach (daelemans et al, 1999).pedersen (2000) <papid> A00-2009 </papid>presents experiments with an ensemble of nave bayes classifiers, which outperform all previous published results on two ambiguous words (line and interest).</citsent>
<aftsection>
<nextsent>the feature space is critical factor in classifier design, given the need to fuel the diverse strengths ofthe component classifiers.
</nextsent>
<nextsent>thus its quality is of ten highly correlated with performance.
</nextsent>
<nextsent>for this association for computational linguistics.
</nextsent>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z57">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> the wsd feature space.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 part-of-speech tagging and.
</prevsent>
<prevsent>lemmatization part-of-speech tagger availability varied across the languages that are studied here.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
an electronically available transformation-based pos tagger (ngai and florian, 2001) <papid> N01-1006 </papid>was trained on standard labeled data for english (penn treebank), swedish (suc 1 corpus), and basque.</citsent>
<aftsection>
<nextsent>for spanish, an minimally supervised tagger (cucerzan and yarowsky, 2000) <papid> P00-1035 </papid>was used.</nextsent>
<nextsent>lemmatization was performed using an existing trie-based supervised models for english, and combination of supervised and unsupervised methods (yarowsky and wicentowski, 2000) <papid> P00-1027 </papid>for all the other languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z59">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> the wsd feature space.  </section>
<citcontext>
<prevsection>
<prevsent>lemmatization part-of-speech tagger availability varied across the languages that are studied here.
</prevsent>
<prevsent>an electronically available transformation-based pos tagger (ngai and florian, 2001) <papid> N01-1006 </papid>was trained on standard labeled data for english (penn treebank), swedish (suc 1 corpus), and basque.</prevsent>
</prevsection>
<citsent citstr=" P00-1035 ">
for spanish, an minimally supervised tagger (cucerzan and yarowsky, 2000) <papid> P00-1035 </papid>was used.</citsent>
<aftsection>
<nextsent>lemmatization was performed using an existing trie-based supervised models for english, and combination of supervised and unsupervised methods (yarowsky and wicentowski, 2000) <papid> P00-1027 </papid>for all the other languages.</nextsent>
<nextsent>3.2 syntactic features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z60">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> the wsd feature space.  </section>
<citcontext>
<prevsection>
<prevsent>an electronically available transformation-based pos tagger (ngai and florian, 2001) <papid> N01-1006 </papid>was trained on standard labeled data for english (penn treebank), swedish (suc 1 corpus), and basque.</prevsent>
<prevsent>for spanish, an minimally supervised tagger (cucerzan and yarowsky, 2000) <papid> P00-1035 </papid>was used.</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
lemmatization was performed using an existing trie-based supervised models for english, and combination of supervised and unsupervised methods (yarowsky and wicentowski, 2000) <papid> P00-1027 </papid>for all the other languages.</citsent>
<aftsection>
<nextsent>3.2 syntactic features.
</nextsent>
<nextsent>the syntactic features extracted for target word depend on the words part of speech:
</nextsent>
<nextsent>verbs: the head noun of the verbs object, par ticle/preposition and prepositional object;
</nextsent>
<nextsent>nouns: the headword of any verb-object,subject-verb or noun-noun relationships identified for the target word;
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z61">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> classifier models for word sense.  </section>
<citcontext>
<prevsection>
<prevsent>by utilizing the binary ratio for k-way modeling of feature probabilities, this approach performs well on tasks where the data is sparse.
</prevsent>
<prevsent>4.3 the mmvc model.
</prevsent>
</prevsection>
<citsent citstr=" W02-1005 ">
the mixture maximum variance correction classifier (mmvc henceforth) (cucerzan and yarowsky,2002) <papid> W02-1005 </papid>is two step classifier.</citsent>
<aftsection>
<nextsent>first, the sense probability is computed as linear mixture
</nextsent>
<nextsent> where the probability    is estimated from data and    is computed as weighted normalized similarity between the word and the target word (also taking into account the distance in the document between and ).
</nextsent>
<nextsent>in second pass, the sense whose variance exceeds theoretically motivated threshold is selected as the final sense label (for details, see cucerzan and yarowsky (2002)).<papid> W02-1005 </papid></nextsent>
<nextsent>4.4 the discriminative models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z63">
<title id=" W02-1004.xml">modeling consensus classifier combination for word sense disambiguation </title>
<section> classifier models for word sense.  </section>
<citcontext>
<prevsection>
<prevsent>in second pass, the sense whose variance exceeds theoretically motivated threshold is selected as the final sense label (for details, see cucerzan and yarowsky (2002)).<papid> W02-1005 </papid></prevsent>
<prevsent>4.4 the discriminative models.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
two discriminative models are used in the experiments presented in section 5 - transformation based learning system (tbl henceforth) (brill,1995; <papid> J95-4004 </papid>ngai and florian, 2001) <papid> N01-1006 </papid>and non hierarchical decision lists system (dl henceforth) (yarowsky, 1996).</citsent>
<aftsection>
<nextsent>for prediction, these systems utilize local n-grams around the target word (up to 3 words/lemma/pos to the left/right), bag-of-wordsand lemma/collocation (20 words around the target word, grouped by different window sizes) and the syntactic features listed in section 3.2.the tbl system was modified to include redundant rules that do not improve absolute accuracy on training data in the traditional greedy training algorithm, but are nonetheless positively correlated with particular sense.
</nextsent>
<nextsent>the benefit of this approach is that predictive but redundant features in training context may appear by themselves in new test contexts, improving coverage and increasing tbl base model performance by 1-2%.
</nextsent>
<nextsent>one necessary property for success in combining classifiers is that the errors produced by the component classifiers should not be positively correlated.
</nextsent>
<nextsent>on one extreme, if the classifier outputs are 0.0 0.2 0.4 0.6 0.8 1.0 mmvc cosine bayes bayes ratio tbl decision lists figure 2: empirically-derived classifier similarity strongly correlated, they will have very high inter agreement rate and there is little to be gained from the joint output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z66">
<title id=" W03-0508.xml">examining the consensus between human summaries initial experiments with factoid analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is an understatement to say that measuring thequality of summaries is hard.
</prevsent>
<prevsent>in fact, there is unanimous consensus in the summarisation community that evaluation of summaries is monstrously difficult task.
</prevsent>
</prevsection>
<citsent citstr=" W00-0408 ">
in the past years, there has been quite lot of summarisation work that has effectively aimed at finding viable evaluation strategies (sparck jones,1999; jing et al, 1998; donaway et al, 2000).<papid> W00-0408 </papid></citsent>
<aftsection>
<nextsent>large scale conferences like summac (mani et al, 1999)<papid> E99-1011 </papid>and duc (2002) have unfortunately shown weak results in that current evaluation measures could not distinguish between automatic summaries ? though they are effective enough to distinguish them from human-written summaries.</nextsent>
<nextsent>in principle, the best way to evaluate summary is to try to perform the task for which the summary was meant in the first place, and measure the quality of the summary on the basis of degree of success in executing the task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z67">
<title id=" W03-0508.xml">examining the consensus between human summaries initial experiments with factoid analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, there is unanimous consensus in the summarisation community that evaluation of summaries is monstrously difficult task.
</prevsent>
<prevsent>in the past years, there has been quite lot of summarisation work that has effectively aimed at finding viable evaluation strategies (sparck jones,1999; jing et al, 1998; donaway et al, 2000).<papid> W00-0408 </papid></prevsent>
</prevsection>
<citsent citstr=" E99-1011 ">
large scale conferences like summac (mani et al, 1999)<papid> E99-1011 </papid>and duc (2002) have unfortunately shown weak results in that current evaluation measures could not distinguish between automatic summaries ? though they are effective enough to distinguish them from human-written summaries.</citsent>
<aftsection>
<nextsent>in principle, the best way to evaluate summary is to try to perform the task for which the summary was meant in the first place, and measure the quality of the summary on the basis of degree of success in executing the task.
</nextsent>
<nextsent>however, such extrinsic evaluations are so time-consuming to set up that they cannot be used for the day-to-day evaluation needed during system development.
</nextsent>
<nextsent>so in practice, method for intrinsic evaluation is needed, where the properties of the summary itself are examined, independent of its application.
</nextsent>
<nextsent>we think one of the reasons for the difficulty of an intrinsic evaluation is that summarisation has to call upon at least two hard subtasks: selection of information and production of new text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z68">
<title id=" W03-0508.xml">examining the consensus between human summaries initial experiments with factoid analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this presupposes, however, that there is single best?
</prevsent>
<prevsent>result.
</prevsent>
</prevsection>
<citsent citstr=" C96-2166 ">
in summarisation there appears to be no one truth?, as is evidenced by low agreement between humans in producing gold standard summaries by sentence selection (rath et al, 1961; jing et al,1998; zechner, 1996), <papid> C96-2166 </papid>and low overlap measures between humans when gold standards summaries are created by reformulation in the summarisers?</citsent>
<aftsection>
<nextsent>own words (e.g. the average overlap for the 542 single document summary pairs in duc-02 was only about 47%).
</nextsent>
<nextsent>but even though the non-existence of any one gold standard is generally acknowledged in the summarisation community, actual practice nevertheless ignores this.
</nextsent>
<nextsent>comparisons against single gold standard are widely used, due to the expense of compiling summary gold standards and the lack of composite measures for comparison to more than one gold standard.
</nextsent>
<nextsent>in related field, information retrieval (ir), the problem of subjectivity of relevance judgements is circumvented by extensive sampling: many different queries are collected to level out the difference humans have in suggesting queries and in selecting relevant documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z70">
<title id=" W03-0508.xml">examining the consensus between human summaries initial experiments with factoid analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while relevance judgements between humans remain different, voorhees (2000)shows that the relative rankings of systems are nevertheless stable across annotators, which means that meaningful ir measures have been found despite the inherent subjectivity of relevance judgements.
</prevsent>
<prevsent>similarly, in mt, the recent bleu measure also uses the idea that one gold standard is not enough.
</prevsent>
</prevsection>
<citsent citstr=" W02-0406 ">
in an experiment, papineni et al (2001) based an evaluation on collection of four reference translations of 40 general news stories and showed the evaluation to be comparable to human judgement.lin and hovy (2002) <papid> W02-0406 </papid>examine the use of multiple gold standard for summarisation evaluation, and conclude we need more than one model summary although we cannot estimate how many model summaries are required to achieve reliable automated summary evaluation?.</citsent>
<aftsection>
<nextsent>we explore the differences and similarities between various human summaries in order to create basis for such an estimate, and as side-effect, also re-examine the degree of difference between the use of single summary gold standard and the use of compound gold standard.
</nextsent>
<nextsent>1.2 similarity measures.
</nextsent>
<nextsent>the second aspect we examine is the similarity measure to be used for gold standard comparison.in principle, the comparison can be done via co selection of extracted sentences (rath et al, 1961;jing et al, 1998; zechner, 1996), <papid> C96-2166 </papid>by string-based surface measures (lin and hovy, 2002; <papid> W02-0406 </papid>saggion et al, 2002), or by subjective judgements of the amount of information overlap (duc, 2002).</nextsent>
<nextsent>the rationale for using information overlap judgement as the main evaluation metric for duc is the wish to measure the meaning of sentences rather than use surface based similarity such as co-selection (which does not even take identical information expressed in different sentences into account) and string-based measures.in the duc competitions, assessors judge the informational overlap between model units?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z78">
<title id=" W03-0434.xml">a robust risk minimization based named entity recognition system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has become more important nowadays due to the large amount of available electronic text, which makes it necessary to build systems that can automatically process and extract information from text.
</prevsent>
<prevsent>inspite of significant work in this area, the problem itself has not been solved.
</prevsent>
</prevsection>
<citsent citstr=" M98-1021 ">
although some earlier reports suggested accuracy (f1-number) of machine learning based systems to be in the lower 90s with relatively small amount of labeled data (for example, (bikel et al, 1999; mikheev et al, 1998; <papid> M98-1021 </papid>sundheim, 1995)), <papid> M95-1002 </papid>these studies were often performed on relatively restricted do mains.</citsent>
<aftsection>
<nextsent>our experience indicates that the performance of statistically based named entity extraction system can vary significantly depending on the underlying domain.
</nextsent>
<nextsent>there are still open challenges to make the performance of statistical system consistent across different types of data sources.
</nextsent>
<nextsent>in this paper we present system for named entity recognition based on our earlier work on text chunking(zhang et al, 2002).
</nextsent>
<nextsent>one advantage of the proposed system is that it can easily incorporate large number of linguistic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z79">
<title id=" W03-0434.xml">a robust risk minimization based named entity recognition system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has become more important nowadays due to the large amount of available electronic text, which makes it necessary to build systems that can automatically process and extract information from text.
</prevsent>
<prevsent>inspite of significant work in this area, the problem itself has not been solved.
</prevsent>
</prevsection>
<citsent citstr=" M95-1002 ">
although some earlier reports suggested accuracy (f1-number) of machine learning based systems to be in the lower 90s with relatively small amount of labeled data (for example, (bikel et al, 1999; mikheev et al, 1998; <papid> M98-1021 </papid>sundheim, 1995)), <papid> M95-1002 </papid>these studies were often performed on relatively restricted do mains.</citsent>
<aftsection>
<nextsent>our experience indicates that the performance of statistically based named entity extraction system can vary significantly depending on the underlying domain.
</nextsent>
<nextsent>there are still open challenges to make the performance of statistical system consistent across different types of data sources.
</nextsent>
<nextsent>in this paper we present system for named entity recognition based on our earlier work on text chunking(zhang et al, 2002).
</nextsent>
<nextsent>one advantage of the proposed system is that it can easily incorporate large number of linguistic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z80">
<title id=" W03-0434.xml">a robust risk minimization based named entity recognition system </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>we have found that such features can appreciably improve the performance of our system, but discussion is beyond the scope of this paper.
</prevsent>
<prevsent>a related idea is to combine the outputs of different systems.
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
see (florian et al, 2003) <papid> W03-0425 </papid>for such study.</citsent>
<aftsection>
<nextsent>fortunately, as our experiments indicate, special purpose patterns may not be necessary for quite reasonable accuracy.
</nextsent>
<nextsent>in table 4, we report the performance of our system on the german data.
</nextsent>
<nextsent>we shall note that the performance is significantly lower than the corresponding english performance.
</nextsent>
<nextsent>our experience indicates that even for english, the real-world performance of statistical named entity recognizer can be very low.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z81">
<title id=" W02-1210.xml">efficient deep processing of japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the grammar is based on work done in the verb mobil project (siegel 2000) on machine translation of spoken dialogues in the domain of travel planning.
</prevsent>
<prevsent>it has since been greatly extended to accommodate written japanese and new domains.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
the grammar is couched in the theoretical framework of head-driven phrase structure grammar (hpsg) (pollard &amp; sag 1994), with semantic representations in minimal recur sion semantics (mrs) (copestake et al 2001).<papid> P01-1019 </papid></citsent>
<aftsection>
<nextsent>hpsg is well suited to the task of multilingual development of broad coverage grammars: it is flexible enough (analyses can be shared across languages but also tailored as necessary), and has rich theoretical literature from which to draw analyzes and inspiration.
</nextsent>
<nextsent>the characteristic type hierarchy of hpsg also facilitates the development of grammars that are easy to extend.
</nextsent>
<nextsent>mrs is flat semantic formalism that works well with typed feature structures and is flexible in that it provides structures that are under-specified for scopal information.
</nextsent>
<nextsent>these structures give compact representations of ambiguities that are often irrelevant to the task at hand.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z82">
<title id=" W02-1210.xml">efficient deep processing of japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hpsg and mrs have the further advantage that there are practical and useful open-source tools for writing, testing, and efficiently processing grammars written in these formalisms.
</prevsent>
<prevsent>the tools we are using in this project include the lkb system (copestake 2002) for grammar development, [incr tsdb()] (oepen &amp; carroll 2000) for testing the grammar and tracking changes, and pet (callmeier 2000), very efficient hpsg parser, for processing.
</prevsent>
</prevsection>
<citsent citstr=" C00-1004 ">
we also use the chasen tokenizer and pos tagger (asahara &amp; matsumoto 2000).<papid> C00-1004 </papid></citsent>
<aftsection>
<nextsent>while couched within the same general framework (hpsg), our approach differs from that of kanayama et al(2000).<papid> C00-1060 </papid></nextsent>
<nextsent>the work described there achieves impressive coverage (83.7% on the edr corpus of newspaper text) with an underspecified grammar consisting of small number of lexical entries, lexical types associated with parts of speech, and six underspecified grammar rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z83">
<title id=" W02-1210.xml">efficient deep processing of japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tools we are using in this project include the lkb system (copestake 2002) for grammar development, [incr tsdb()] (oepen &amp; carroll 2000) for testing the grammar and tracking changes, and pet (callmeier 2000), very efficient hpsg parser, for processing.
</prevsent>
<prevsent>we also use the chasen tokenizer and pos tagger (asahara &amp; matsumoto 2000).<papid> C00-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-1060 ">
while couched within the same general framework (hpsg), our approach differs from that of kanayama et al(2000).<papid> C00-1060 </papid></citsent>
<aftsection>
<nextsent>the work described there achieves impressive coverage (83.7% on the edr corpus of newspaper text) with an underspecified grammar consisting of small number of lexical entries, lexical types associated with parts of speech, and six underspecified grammar rules.
</nextsent>
<nextsent>in contrast, our grammar is much larger in terms of the number of lexical entries, the number of grammar rules, and the constraints on both,1 and takes correspondingly more effort to bring up to that level of coverage.
</nextsent>
<nextsent>the higher level of detail allows us to output precise semantic representations as well as to use syntactic, semantic and lexical information to reduce ambiguity and rank parses.
</nextsent>
<nextsent>1 japanese hpsg syntax.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z86">
<title id=" W02-1210.xml">efficient deep processing of japanese </title>
<section> robustness and performance issues.  </section>
<citcontext>
<prevsection>
<prevsent>restrictions like head-complement preferred to head-adjunct are quite obvious.
</prevsent>
<prevsent>others require domain-specific mechanisms that shall be subject of further work.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
stochastic disambiguation methods being developed for the erg by the redwoods project at stanford university (oepen et al 2002) <papid> C02-2025 </papid>should be applicable to this grammar as well.</citsent>
<aftsection>
<nextsent>the grammar currently covers 93.4% of constructed examples for the banking domain (747 sentences) and 78.2% of realistic email correspondence data (316 sentences), concerning requests for documents.
</nextsent>
<nextsent>during three months of work, the coverage in the banking domain increased 48.49%.
</nextsent>
<nextsent>the coverage of the document request data increased 51.43% in the following two weeks.
</nextsent>
<nextsent>phenomenon total items # positive items # word string % lexical items ? parser analyses ? total results # overall coverage % total 747 747 101 75.24 6.54 698 93.4 fig.3 coverage of banking data, generated by [incr tsdb()] phenomenon total items # positive items # word string % lexical items ? parser analyses ? total results # overall coverage % total 316 316 1.00 83.90 39.91 247 78.2 fig.4 coverage of document request data, generated by [incr tsdb()] we applied the grammar to unseen data in one of the covered domains, namely the faq site of japanese bank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z87">
<title id=" W03-0802.xml">what an xsltbased infrastructure for the integration of natural language processing components </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the infrastructure is open, portable and well suited for, but not restricted to the development of hybrid nlp architectures as well as nlp applications.
</prevsent>
<prevsent>during the last decade, sgml and xml have become an important interchange format for linguistic data, be they created manually by linguists, or automatically by natural language processing (nlp) components.
</prevsent>
</prevsection>
<citsent citstr=" P01-1040 ">
lt-xml (brew et al  2000), xces (ide and romary 2001) <papid> P01-1040 </papid>and many other are examples for xml-based or xml-supporting software architectures for natural language processing.</citsent>
<aftsection>
<nextsent>the main focus of the white board project (2000-2002) was to integrate shallow and deep natural language processing components.
</nextsent>
<nextsent>the idea was to combine both in order to benefit from their advantages.
</nextsent>
<nextsent>successful and beneficial integration included tokenization, pos, morphology, lexical, named entity, phrase chunk and (for german) topological sentence field levels in fully automated xml-based system.
</nextsent>
<nextsent>crysmann et al  (2002)<papid> P02-1056 </papid>and frank et al  (2003) show that this close deep shallow combination significantly increases robustness and performance compared to the (already fast) standalone deep hpsg parser by callmeier (2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z88">
<title id=" W03-0802.xml">what an xsltbased infrastructure for the integration of natural language processing components </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea was to combine both in order to benefit from their advantages.
</prevsent>
<prevsent>successful and beneficial integration included tokenization, pos, morphology, lexical, named entity, phrase chunk and (for german) topological sentence field levels in fully automated xml-based system.
</prevsent>
</prevsection>
<citsent citstr=" P02-1056 ">
crysmann et al  (2002)<papid> P02-1056 </papid>and frank et al  (2003) show that this close deep shallow combination significantly increases robustness and performance compared to the (already fast) standalone deep hpsg parser by callmeier (2000).</citsent>
<aftsection>
<nextsent>the only comparable architecture so far was described by grover et al  (2002), <papid> W02-1706 </papid>but their integration was limited to tokenization and pos tagging (the shallow chunker did not guide or contribute to deep analysis).</nextsent>
<nextsent>in this paper, we will focus on one of the central integration facilities, the xslt-based white board annotation transformer (what), report on the benefits of xslt-based nlp component integration, and present examples of xsl transformation of shallow and deep annotations used in the integrated architecture.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z89">
<title id=" W03-0802.xml">what an xsltbased infrastructure for the integration of natural language processing components </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>successful and beneficial integration included tokenization, pos, morphology, lexical, named entity, phrase chunk and (for german) topological sentence field levels in fully automated xml-based system.
</prevsent>
<prevsent>crysmann et al  (2002)<papid> P02-1056 </papid>and frank et al  (2003) show that this close deep shallow combination significantly increases robustness and performance compared to the (already fast) standalone deep hpsg parser by callmeier (2000).</prevsent>
</prevsection>
<citsent citstr=" W02-1706 ">
the only comparable architecture so far was described by grover et al  (2002), <papid> W02-1706 </papid>but their integration was limited to tokenization and pos tagging (the shallow chunker did not guide or contribute to deep analysis).</citsent>
<aftsection>
<nextsent>in this paper, we will focus on one of the central integration facilities, the xslt-based white board annotation transformer (what), report on the benefits of xslt-based nlp component integration, and present examples of xsl transformation of shallow and deep annotations used in the integrated architecture.
</nextsent>
<nextsent>because the infrastructure is in general independent of deep or shallow paradigms, it can also be applied to purely shallow or deep systems.
</nextsent>
<nextsent>deep processing (dnlp) systems1 try to apply as much linguistic knowledge as possible during the analysis of sentences and result in uniformly represented collection of the knowledge that contributed to the analysis.
</nextsent>
<nextsent>the result often consists of many possible analyses per sentence reflecting the uncertainty which of the possible readings was intended ? or no answer at all if the linguistic knowledge was contradictory or insufficient with respect to the input sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z90">
<title id=" W03-0802.xml">what an xsltbased infrastructure for the integration of natural language processing components </title>
<section> what: the white board annotation.  </section>
<citcontext>
<prevsection>
<prevsent>the what has been successfully used in the white board architecture for online analysis of german newspaper sentences.
</prevsent>
<prevsent>for more details on motivation and evaluation cf.
</prevsent>
</prevsection>
<citsent citstr=" C02-1093 ">
frank et al  (2003) and becker and frank (2002).<papid> C02-1093 </papid></citsent>
<aftsection>
<nextsent>the simplified diagram in figure 3 depicts the components and places where what comes into play in the hybrid integration of deep and shallow processing components (v, n, denote the what query types).
</nextsent>
<nextsent>the system takes an input sentence, and runs three shallow systems on it: ? the rule-based shallow sppc (piskorski and neumann 2000) for named entity recognition, ? tnt/chunkie, statistics-based shallow pos tagger and chunker by (skut and brants 1998), ? lopar, probabilistic context-free parser (schmid 2000), which takes pos-tagged tokens as input, and produces binary tree representations of sentence fields, e.g., topo.bin in fig.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>for justification for binary vs. flat trees cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z94">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>a female-individual may have clothes.
</prevsent>
<prevsent>clothes can be washed.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
((:i (:q det named-entity) enter[v] (:q the room[n])) (:i (:q det female-individual) have[v] (:q det room[n])) (:i (:q det female-individual) sleep[v]) (:i (:q det female-individual) have[v] (:q det (:f plur clothe[n]))) (:i (:q det (:f plur clothe[n])) washed[a])) the results are produced as logical forms (the last five lines above ? see schubert, 2002, for some details), from which the english glosses are generated automatically.our work so far has focused on data in the penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>particularly the brown corpus and some examples from the wall street journal corpus.</citsent>
<aftsection>
<nextsent>the advantage is that treebank annotations allow us to postpone the challenges of reasonably accurate parsing, though we will soon be experimenting with industrial strength?
</nextsent>
<nextsent>parsers on unannotated texts.
</nextsent>
<nextsent>we reported some specifics of our approach and some preliminary results in (schubert, 2002).
</nextsent>
<nextsent>since then we have refined our extraction methods to the point where we can reliably apply them the treebank corpora, on average extracting more than 2 generalized propositions per sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z95">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z96">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" W99-0631 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z97">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z98">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" C92-2099 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z99">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" P92-1053 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z100">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" H93-1054 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z101">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" C92-4212 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z102">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> introduction: deriving general.  </section>
<citcontext>
<prevsection>
<prevsent>some additional miscellaneous examples are person may believe proposition?, bills may be approved by committees?, us-state mayhave high schools?, children may live with rela tives?, comedy may be delightful?, book maybe write-ed (i.e., written) by an agent?, female individual may have spouse?, an artery can be thickened?, house may have windows?, etc. the programs that produce these results consist of (1) treebank pre processor that makes various modification sto treebank trees so as to facilitate the extraction of semantic information (for instance, differentiating different kinds of sbar?, such as s-that and s-although, and identifying certain noun phrases and prepositional phrases, such as next friday?, as temporal); (2) pattern matcher that uses type of regular-expression language to identify particular kinds of phrase structure patterns (e.g., verb + complement patterns, with possible inserted adverbials or other material); (3) semantic pattern extraction routine that associates particular semantic patterns with particular phrase structure patterns andre cursively instantiates and collects such patterns for the preprocessed tree, in bottom-up fashion; (4) abstraction routines that abstract away modifiers and other type preserving operators?, before semantic patterns are constructed at the next-higher level in the tree (for instance,stripping the interpreted modifier washed?
</prevsent>
<prevsent>from the interpreted noun phrase her washed clothes?); (5) routines for deriving propositional patterns from the resulting miscellaneous semantic patterns, and rendering them in asimple, approximate english form; and (6) heuristic routines for filtering out many ill-formed or vacuous propositions.
</prevsent>
</prevsection>
<citsent citstr=" C90-1005 ">
in addition, semantic interpretation of individual words involves some simple morphological analysis, for instance to allow the interpretation of (vbd slept) in terms of predicate sleep[v].in (schubert, 2002) we made some comparisons between our project and earlier work in knowledge extraction (e.g., (muc, 1993; muc, 1995; muc, 1998; berland and charniak, 1999; <papid> P99-1008 </papid>clark and weir, 1999; <papid> W99-0631 </papid>hearst, 1998; riloff and jones, 1999)) and in discovery of selectional preferences (e.g., (agirre and martinez, 2001; <papid> W01-0703 </papid>grishman and sterling, 1992; <papid> C92-2099 </papid>resnik, 1992; <papid> P92-1053 </papid>resnik, 1993; <papid> H93-1054 </papid>zernik, 1992; <papid> C92-4212 </papid>zernik and jacobs, 1990)).<papid> C90-1005 </papid></citsent>
<aftsection>
<nextsent>reiterating briefly, wenote that knowledge extraction work has generally employed carefully tuned extraction patterns to locate and extract some predetermined, specific kinds of facts; our goal, instead, is to process every phrase and sentence that is encountered, abstracting from it miscellaneous general knowledge whenever possible.
</nextsent>
<nextsent>methods for discovering selectional preferences do seek out conventional patterns of verb-argument combination, but tend to lose the con nection?
</nextsent>
<nextsent>between argument types (e.g., that road may carry traffic, newspaper may carry story, but road is unlikely to carry story); in any event, they have not led so far to amass ment of data interpret able as general world knowledge.
</nextsent>
<nextsent>our concern in this paper is with the evaluation of the results we currently obtain for the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z103">
<title id=" W03-0902.xml">extracting and evaluating general world knowledge from the brown corpus </title>
<section> seems false (no. dont think so. hardly).  </section>
<citcontext>
<prevsection>
<prevsent>the overall pairwise agreement results for classification into six judgement catagories are shown in table 2.
</prevsent>
<prevsent>judge 1 90.1 56.9 10.4 61.7 62.4 57.358.5 judge 1 judge 2 judge 3 judge 4 judge 5 54.5 56.0 49.3 judge 2 judge 3 judge 4 table 2.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
overall % agreement among judges for 250 propositions 60.1a commonly used metric for evaluating interrater reliability in categorization of data is the kappa statistic (car letta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>as concession to the popularity of that statistic, we compute it in few different ways here,though ? as we will explain ? we do not consider it particularly appropriate.
</nextsent>
<nextsent>for 6 judgement categories, kappa computed in the conventional way for pairs of judges ranges from .195 to .367, averaging .306.
</nextsent>
<nextsent>for 3 (more in clusive) judgement categories, the pairwise kappa scores range from .303 to .462, with an average of .375.
</nextsent>
<nextsent>these scores, though certainly indicating positive correlation between the assessments of multiple judges, are well below the lower threshold of .67 often employed in deciding whether judgements are sufficiently consistent across judges to be useful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z104">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>mbmt has the ability to produce consistent, high-quality translations (conditioned on the quality of the original bilingual dictio nary) and is therefore suited to translating compounds in closed domains.
</prevsent>
<prevsent>its most obvious drawback is that the method can translate only those source language strings contained in the translation database.there are number of ways to populate the translation database used in mbmt, the easiest of which isto take translation pairs directly from bilingual dictionary (dictionary-driven mbmt or mbmtdict).mbmtdict offers an extremist solution to the id iomaticity problem, in treating all nn compounds as being fully lexicalised.
</prevsent>
</prevsection>
<citsent citstr=" P95-1032 ">
over generation is not an issue, as all translations are manually determined.as an alternative to pre compiled bilingual dictionary, translation pairs can be extracted from parallel corpus (fung, 1995; <papid> P95-1032 </papid>smadja et al, 1996;<papid> J96-1001 </papid>ohmori and higashida, 1999), that is bilingual document set that is translation-equivalent at the sentence or paragraph level; we term this mt configuration alignment-driven mbmt (or mbmtalign).</citsent>
<aftsection>
<nextsent>while this method alleviates the problem of limited scala bil ity, it relies on the existence of parallel corpus in the desired domain, which is often an unreasonable requirement.
</nextsent>
<nextsent>whereas parallel corpus assumes translation equivalence, comparable corpus is simply cross lingual pairing of corpora from the same domain (fung and mckeown, 1997; <papid> W97-0119 </papid>rapp, 1999; <papid> P99-1067 </papid>tanaka and matsuo, 1999; tanaka, 2002).<papid> C02-1065 </papid></nextsent>
<nextsent>it is possible to extract translation pairs from comparable corpus by way of the following process (cao and li, 2002): 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z105">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>mbmt has the ability to produce consistent, high-quality translations (conditioned on the quality of the original bilingual dictio nary) and is therefore suited to translating compounds in closed domains.
</prevsent>
<prevsent>its most obvious drawback is that the method can translate only those source language strings contained in the translation database.there are number of ways to populate the translation database used in mbmt, the easiest of which isto take translation pairs directly from bilingual dictionary (dictionary-driven mbmt or mbmtdict).mbmtdict offers an extremist solution to the id iomaticity problem, in treating all nn compounds as being fully lexicalised.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
over generation is not an issue, as all translations are manually determined.as an alternative to pre compiled bilingual dictionary, translation pairs can be extracted from parallel corpus (fung, 1995; <papid> P95-1032 </papid>smadja et al, 1996;<papid> J96-1001 </papid>ohmori and higashida, 1999), that is bilingual document set that is translation-equivalent at the sentence or paragraph level; we term this mt configuration alignment-driven mbmt (or mbmtalign).</citsent>
<aftsection>
<nextsent>while this method alleviates the problem of limited scala bil ity, it relies on the existence of parallel corpus in the desired domain, which is often an unreasonable requirement.
</nextsent>
<nextsent>whereas parallel corpus assumes translation equivalence, comparable corpus is simply cross lingual pairing of corpora from the same domain (fung and mckeown, 1997; <papid> W97-0119 </papid>rapp, 1999; <papid> P99-1067 </papid>tanaka and matsuo, 1999; tanaka, 2002).<papid> C02-1065 </papid></nextsent>
<nextsent>it is possible to extract translation pairs from comparable corpus by way of the following process (cao and li, 2002): 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z106">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>over generation is not an issue, as all translations are manually determined.as an alternative to pre compiled bilingual dictionary, translation pairs can be extracted from parallel corpus (fung, 1995; <papid> P95-1032 </papid>smadja et al, 1996;<papid> J96-1001 </papid>ohmori and higashida, 1999), that is bilingual document set that is translation-equivalent at the sentence or paragraph level; we term this mt configuration alignment-driven mbmt (or mbmtalign).</prevsent>
<prevsent>while this method alleviates the problem of limited scala bil ity, it relies on the existence of parallel corpus in the desired domain, which is often an unreasonable requirement.</prevsent>
</prevsection>
<citsent citstr=" W97-0119 ">
whereas parallel corpus assumes translation equivalence, comparable corpus is simply cross lingual pairing of corpora from the same domain (fung and mckeown, 1997; <papid> W97-0119 </papid>rapp, 1999; <papid> P99-1067 </papid>tanaka and matsuo, 1999; tanaka, 2002).<papid> C02-1065 </papid></citsent>
<aftsection>
<nextsent>it is possible to extract translation pairs from comparable corpus by way of the following process (cao and li, 2002): 1.
</nextsent>
<nextsent>extract nn compounds from the source language corpus by searching for nn bigrams (e.g.    kikai  honyaku machine translation?)
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>compositionally generate translation candidates for each nn compound by accessing translations for each component word and slotting these into translation templates; example je translation templates for source japanese string [n n  ]j are [n   ]e and [n  of  ]e, where the numeric sub scripts indicate word co indexation between japanese and english (resulting in, e.g., machine translation and translation of machine) 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z107">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>over generation is not an issue, as all translations are manually determined.as an alternative to pre compiled bilingual dictionary, translation pairs can be extracted from parallel corpus (fung, 1995; <papid> P95-1032 </papid>smadja et al, 1996;<papid> J96-1001 </papid>ohmori and higashida, 1999), that is bilingual document set that is translation-equivalent at the sentence or paragraph level; we term this mt configuration alignment-driven mbmt (or mbmtalign).</prevsent>
<prevsent>while this method alleviates the problem of limited scala bil ity, it relies on the existence of parallel corpus in the desired domain, which is often an unreasonable requirement.</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
whereas parallel corpus assumes translation equivalence, comparable corpus is simply cross lingual pairing of corpora from the same domain (fung and mckeown, 1997; <papid> W97-0119 </papid>rapp, 1999; <papid> P99-1067 </papid>tanaka and matsuo, 1999; tanaka, 2002).<papid> C02-1065 </papid></citsent>
<aftsection>
<nextsent>it is possible to extract translation pairs from comparable corpus by way of the following process (cao and li, 2002): 1.
</nextsent>
<nextsent>extract nn compounds from the source language corpus by searching for nn bigrams (e.g.    kikai  honyaku machine translation?)
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>compositionally generate translation candidates for each nn compound by accessing translations for each component word and slotting these into translation templates; example je translation templates for source japanese string [n n  ]j are [n   ]e and [n  of  ]e, where the numeric sub scripts indicate word co indexation between japanese and english (resulting in, e.g., machine translation and translation of machine) 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z108">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>over generation is not an issue, as all translations are manually determined.as an alternative to pre compiled bilingual dictionary, translation pairs can be extracted from parallel corpus (fung, 1995; <papid> P95-1032 </papid>smadja et al, 1996;<papid> J96-1001 </papid>ohmori and higashida, 1999), that is bilingual document set that is translation-equivalent at the sentence or paragraph level; we term this mt configuration alignment-driven mbmt (or mbmtalign).</prevsent>
<prevsent>while this method alleviates the problem of limited scala bil ity, it relies on the existence of parallel corpus in the desired domain, which is often an unreasonable requirement.</prevsent>
</prevsection>
<citsent citstr=" C02-1065 ">
whereas parallel corpus assumes translation equivalence, comparable corpus is simply cross lingual pairing of corpora from the same domain (fung and mckeown, 1997; <papid> W97-0119 </papid>rapp, 1999; <papid> P99-1067 </papid>tanaka and matsuo, 1999; tanaka, 2002).<papid> C02-1065 </papid></citsent>
<aftsection>
<nextsent>it is possible to extract translation pairs from comparable corpus by way of the following process (cao and li, 2002): 1.
</nextsent>
<nextsent>extract nn compounds from the source language corpus by searching for nn bigrams (e.g.    kikai  honyaku machine translation?)
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>compositionally generate translation candidates for each nn compound by accessing translations for each component word and slotting these into translation templates; example je translation templates for source japanese string [n n  ]j are [n   ]e and [n  of  ]e, where the numeric sub scripts indicate word co indexation between japanese and english (resulting in, e.g., machine translation and translation of machine) 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z109">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>that is, it applies steps 2 and 3 of the method for mbmtcomp to an arbitrary source language string.interpretation-driven dmt (or dmtinterp) offers the means to deal with nn compounds where strict word-to-word alignment does not hold.
</prevsent>
<prevsent>it generally does this in two stages: 1.
</prevsent>
</prevsection>
<citsent citstr=" P97-1018 ">
use semantics and/or pragmatics to carry out deep analysis of the source nn compound,and map it into some intermediate (i.e. inter lingual) semantic representation (copestake and lascarides, 1997; <papid> P97-1018 </papid>barker and szpakowicz, 1998; <papid> P98-1015 </papid>rosario and hearst, 2001)<papid> W01-0511 </papid>2.</citsent>
<aftsection>
<nextsent>generate the translation directly from the semantic representationdmtinterp removes any direct source/target language interdependence, and hence solves the problem of over generation due to cross lingual bias.
</nextsent>
<nextsent>at thesame time, it is forced into tackling idiomaticity headon, by way of interpreting each individual nn compound.
</nextsent>
<nextsent>as for dmtcomp, dmtinterp suffers from undergeneration.
</nextsent>
<nextsent>with dmtinterp, context must often be called upon in interpreting nn compounds (e.g. apple juice seat (levi, 1978; bauer, 1979)), and minimal pairs with sharply-differentiated semantics such as colour/group photograph illustrate the fine-grained distinctions that must be made.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z110">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>that is, it applies steps 2 and 3 of the method for mbmtcomp to an arbitrary source language string.interpretation-driven dmt (or dmtinterp) offers the means to deal with nn compounds where strict word-to-word alignment does not hold.
</prevsent>
<prevsent>it generally does this in two stages: 1.
</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
use semantics and/or pragmatics to carry out deep analysis of the source nn compound,and map it into some intermediate (i.e. inter lingual) semantic representation (copestake and lascarides, 1997; <papid> P97-1018 </papid>barker and szpakowicz, 1998; <papid> P98-1015 </papid>rosario and hearst, 2001)<papid> W01-0511 </papid>2.</citsent>
<aftsection>
<nextsent>generate the translation directly from the semantic representationdmtinterp removes any direct source/target language interdependence, and hence solves the problem of over generation due to cross lingual bias.
</nextsent>
<nextsent>at thesame time, it is forced into tackling idiomaticity headon, by way of interpreting each individual nn compound.
</nextsent>
<nextsent>as for dmtcomp, dmtinterp suffers from undergeneration.
</nextsent>
<nextsent>with dmtinterp, context must often be called upon in interpreting nn compounds (e.g. apple juice seat (levi, 1978; bauer, 1979)), and minimal pairs with sharply-differentiated semantics such as colour/group photograph illustrate the fine-grained distinctions that must be made.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z111">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methods for translating nn compounds.  </section>
<citcontext>
<prevsection>
<prevsent>that is, it applies steps 2 and 3 of the method for mbmtcomp to an arbitrary source language string.interpretation-driven dmt (or dmtinterp) offers the means to deal with nn compounds where strict word-to-word alignment does not hold.
</prevsent>
<prevsent>it generally does this in two stages: 1.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
use semantics and/or pragmatics to carry out deep analysis of the source nn compound,and map it into some intermediate (i.e. inter lingual) semantic representation (copestake and lascarides, 1997; <papid> P97-1018 </papid>barker and szpakowicz, 1998; <papid> P98-1015 </papid>rosario and hearst, 2001)<papid> W01-0511 </papid>2.</citsent>
<aftsection>
<nextsent>generate the translation directly from the semantic representationdmtinterp removes any direct source/target language interdependence, and hence solves the problem of over generation due to cross lingual bias.
</nextsent>
<nextsent>at thesame time, it is forced into tackling idiomaticity headon, by way of interpreting each individual nn compound.
</nextsent>
<nextsent>as for dmtcomp, dmtinterp suffers from undergeneration.
</nextsent>
<nextsent>with dmtinterp, context must often be called upon in interpreting nn compounds (e.g. apple juice seat (levi, 1978; bauer, 1979)), and minimal pairs with sharply-differentiated semantics such as colour/group photograph illustrate the fine-grained distinctions that must be made.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z112">
<title id=" W03-1803.xml">noun noun compound machine translation a feasibility study on shallow processing </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>in order to generate english and japanese nn compound test data, we first extracted out all nn bigrams from the bnc (90m word tokens, burnard (2000))and 1996 mainichi shimbun corpus (32m word tokens, mainichi newspaper co.
</prevsent>
<prevsent>(1996)), respectively.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
the bnc had been tagged and chunked using fntbl (ngai and florian, 2001), <papid> N01-1006 </papid>and lemmatised using morph (minnen et al, 2001), while the mainichi shimbun had been segmented and tagged using alt jaws.5 for both english and japanese, we took only those nn bigrams adjoined by non-nouns to ensure that they were not part of larger compound nomi nal.</citsent>
<aftsection>
<nextsent>in the case of english, we additionally measured the entropy of the left and right contexts for each nntype, and filtered out all compounds where either entropy value was ffi  .6 this was done in an attempt to, once again, exclude nns which were embedded in larger mwes, such as service department in social service department.
</nextsent>
<nextsent>we next extracted out the 250 most common nn compounds from the english and japanese data, and from the remaining data, randomly selected further 250 nn compounds of frequency 10 or greater (out.
</nextsent>
<nextsent>of 20,748 english and 169,899 japanese nn com pounds).
</nextsent>
<nextsent>in this way, we generated total of 500 nn compounds for each of english and japanese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z114">
<title id=" W03-0811.xml">multi platform testbed an integration platform for multimodal dialog systems </title>
<section> high-level interfaces for dialog system.  </section>
<citcontext>
<prevsection>
<prevsent>in order to exchangeinstantiated knowledge structures between different system components they need to be encoded in m3l.
</prevsent>
<prevsent>instead of relying on manual reproduction of the underlying terminological knowledge within the m3l definition we decided to automate that task.
</prevsent>
</prevsection>
<citsent citstr=" W03-0809 ">
our tool oil2xsd (gurevych et al, 2003) <papid> W03-0809 </papid>transforms an ontology written in oil (fensel et al, 2001) into an m3l compatible xml schema definition.</citsent>
<aftsection>
<nextsent>the resulting schema specification captures the hierarchical structure and significant part of the semantics of the ontology.
</nextsent>
<nextsent>for example in figure2, the representation of the event structure inside the intention lattice originates from the ontology.
</nextsent>
<nextsent>the main advantage of this approach is that the structural knowledge available on the semantic level is consistently mapped tothe communication interfaces and m3l can easily be updated as the ontology evolves.in addition to the language specification itself, specific m3l api has been developed, which offers lightweight programming interface to simplify the processing of such xml structures within the implementation of component.
</nextsent>
<nextsent>customized testbed utilities like tailored xslt style sheets for the generic data viewer as well as several other tools are provided for easier evaluation of m3l-based processing results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z115">
<title id=" W03-1203.xml">combining optimal clustering and hidden markov models for extractive summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this case, documents are related by topic over time.multi-document summarization is also an extension of single document summarization.
</prevsent>
<prevsent>one of themost robust and domain-independent summarization approaches is extraction-based or shallow summarization (mani (1999)).
</prevsent>
</prevsection>
<citsent citstr=" W02-0401 ">
in extraction-based summarization, salient sentences are automatically extracted to form summary directly (kupiec et. al, (1995), myaeng &amp; jang (1999), jing et. al, (2000), nomoto &amp; matsumoto (2001),  matsumoto (2002), zha(2002), osborne (2002)), <papid> W02-0401 </papid>or followed by synthesis stage to generate more natural summary (mckeown &amp; radev (1999), hovy &amp; lin (1999)).</citsent>
<aftsection>
<nextsent>summarization therefore involves some theme or topic identification and then extraction of salient segments in document.
</nextsent>
<nextsent>story segmentation, document and sentence and classification can often be accomplished by unsupervised, clustering methods, with little or no requirement of human labeled data (deerwester (1991), white &amp; cardie (2002), <papid> W02-0402 </papid>jing et. al (2000)).</nextsent>
<nextsent>unsupervised methods or hybrids of supervised and unsupervised methods for extractive summarization have been found to yield promising results that are either comparable or superior to supervised methods (nomoto &amp; matsumoto (2001),  matsumoto (2002)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z116">
<title id=" W03-1203.xml">combining optimal clustering and hidden markov models for extractive summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in extraction-based summarization, salient sentences are automatically extracted to form summary directly (kupiec et. al, (1995), myaeng &amp; jang (1999), jing et. al, (2000), nomoto &amp; matsumoto (2001),  matsumoto (2002), zha(2002), osborne (2002)), <papid> W02-0401 </papid>or followed by synthesis stage to generate more natural summary (mckeown &amp; radev (1999), hovy &amp; lin (1999)).</prevsent>
<prevsent>summarization therefore involves some theme or topic identification and then extraction of salient segments in document.</prevsent>
</prevsection>
<citsent citstr=" W02-0402 ">
story segmentation, document and sentence and classification can often be accomplished by unsupervised, clustering methods, with little or no requirement of human labeled data (deerwester (1991), white &amp; cardie (2002), <papid> W02-0402 </papid>jing et. al (2000)).</citsent>
<aftsection>
<nextsent>unsupervised methods or hybrids of supervised and unsupervised methods for extractive summarization have been found to yield promising results that are either comparable or superior to supervised methods (nomoto &amp; matsumoto (2001),  matsumoto (2002)).
</nextsent>
<nextsent>in these works, vector space models are used and document or sentence vectors are clustered together according to some similarity measure (deerwester (1991), dagan et al  (1997)).<papid> P97-1008 </papid></nextsent>
<nextsent>the disadvantage of clustering methods lies intheir ad hoc nature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z118">
<title id=" W03-1203.xml">combining optimal clustering and hidden markov models for extractive summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>story segmentation, document and sentence and classification can often be accomplished by unsupervised, clustering methods, with little or no requirement of human labeled data (deerwester (1991), white &amp; cardie (2002), <papid> W02-0402 </papid>jing et. al (2000)).</prevsent>
<prevsent>unsupervised methods or hybrids of supervised and unsupervised methods for extractive summarization have been found to yield promising results that are either comparable or superior to supervised methods (nomoto &amp; matsumoto (2001),  matsumoto (2002)).</prevsent>
</prevsection>
<citsent citstr=" P97-1008 ">
in these works, vector space models are used and document or sentence vectors are clustered together according to some similarity measure (deerwester (1991), dagan et al  (1997)).<papid> P97-1008 </papid></citsent>
<aftsection>
<nextsent>the disadvantage of clustering methods lies intheir ad hoc nature.
</nextsent>
<nextsent>since sentence vectors are considered to be independent sample points, the sentence order information is lost.
</nextsent>
<nextsent>various heuristics and revision strategies have been applied to the general sentence selection schema to take into consideration text cohesion (white &amp; cardie (2002), <papid> W02-0402 </papid>mani and bloedorn (1999), aone et. al (1999), zha (2002), barzilay et al , (2001)).<papid> H01-1065 </papid></nextsent>
<nextsent>we would like to preserve the natural linear cohesion of sentences in text as baseline prior to the application of any revision strategies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z121">
<title id=" W03-1203.xml">combining optimal clustering and hidden markov models for extractive summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the disadvantage of clustering methods lies intheir ad hoc nature.
</prevsent>
<prevsent>since sentence vectors are considered to be independent sample points, the sentence order information is lost.
</prevsent>
</prevsection>
<citsent citstr=" H01-1065 ">
various heuristics and revision strategies have been applied to the general sentence selection schema to take into consideration text cohesion (white &amp; cardie (2002), <papid> W02-0402 </papid>mani and bloedorn (1999), aone et. al (1999), zha (2002), barzilay et al , (2001)).<papid> H01-1065 </papid></citsent>
<aftsection>
<nextsent>we would like to preserve the natural linear cohesion of sentences in text as baseline prior to the application of any revision strategies.
</nextsent>
<nextsent>to compensate for the ad hoc nature of vector space models, probabilistic approaches have regained some interests in information retrieval in recent years (knight &amp; marcu (2000), berger &lafferty; (1999), miller et al , (1999)).
</nextsent>
<nextsent>these recent probabilistic methods in information retrieval are largely inspired by the success of probabilistic models in machine translation in the early 90s (brown et. al), and regard information retrieval as noisy channel problem.
</nextsent>
<nextsent>hidden markov models proposed by miller et al  (1999), and have shown to outperform tf, idf in trec information retrieval tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z122">
<title id=" W03-1203.xml">combining optimal clustering and hidden markov models for extractive summarization </title>
<section> a stochastic process of theme clas sifi </section>
<citcontext>
<prevsection>
<prevsent>is equally likely for all documents, so that finding the best class sequence becomes: )))(()),((,)),2(()),1((( )))((),()),((),(,)),2((),2()),1((),1((maxarg )()|(maxarg)|(maxarg tsctscscscp tsctstsctsscsscsp cpcdpdcp cc
</prevsent>
<prevsent>?= ? note that the total number of theme classes is far fewer than the total number of sentences in document and the mapping is not one-to-one.
</prevsent>
</prevsection>
<citsent citstr=" P97-1013 ">
our task is similar to the concept of discourse parsing (marcu (1997)), <papid> P97-1013 </papid>where discourse structures are extracted from the text.</citsent>
<aftsection>
<nextsent>in our case, we are carrying out discourse tagging, whereby we assign the class labels or tags to each sentence in the document.
</nextsent>
<nextsent>we use hidden markov model for this stochastic process, where the classes are assumed to be hidden states.
</nextsent>
<nextsent>we make the following assumptions: ? the probability of the sentence given its past only depends on its theme class (emission probabilities); ? the probability of the theme class only depends onthe theme classes of the previous sentences (tran sition probabilities).
</nextsent>
<nextsent>the above assumptions lead to hidden markov model with states representing different theme classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z125">
<title id=" W03-1203.xml">combining optimal clustering and hidden markov models for extractive summarization </title>
<section> salient sentence extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the final trained viterbi decoder is then used to tag un-annotated data sets into class-sentence pairs.
</prevsent>
<prevsent>we can then extract salient sentences from each class to be included in summary, or for question-answering.
</prevsent>
</prevsection>
<citsent citstr=" C96-2166 ">
to evaluate the effectiveness of our method as afoundation for extractive summarization, we extract sentences from each theme class in each document using four features, namely: (1) the position of the sentence p 1= -- the further it is from the title, the less important it is supposed to be; (2) the cosine similarity of the sentence with the centro id of its class 1; (3) its similarity with the first sentence in the article 2; and(4) the so-called model (zechner (1996), <papid> C96-2166 </papid>nomoto &amp; matsumoto (2000)), where the mass of sentence is computed as the sum of tf, idf values of index terms in that sentence and the center of mass is chosen as the salient sentence to be included in summary.</citsent>
<aftsection>
<nextsent>))(())))((log(1(maxarg 1 tsidftstfz l i s
</nextsent>
<nextsent>= ?+= the above features are linearly combined to yield final saliency score for every sentence: zwwwpwsw ?+?+?+?= 423121)( our features are similar to those in an existing system (radev 2002), with the difference in the cen troid computation (and cluster definition), resulting from our stochastic system.
</nextsent>
<nextsent>many researchers have proposed various evaluation methods for summarization.
</nextsent>
<nextsent>we find that extrinsic, task-oriented evaluation method to be most easily automated, and quantifiable (radev 2000).we choose to evaluate our stochastic theme classification system (stcs) on multi-document summarization task, among other possible tasks we choose content-based method to evaluate the summaries extracted by our system, compared to those by another extraction-based system mead (radev 2002), and against baseline system that chooses the top sentence in each document as salient sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z126">
<title id=" W03-0613.xml">learning word meanings and descriptive parameter spaces from music </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>from community meta data.representation that allows for far more perceptual generality in the time domain than our previous works single frame-based power spectral density.
</prevsent>
<prevsent>our current platform for retrieving audio and description is shown in figure 2.
</prevsent>
</prevsection>
<citsent citstr=" P93-1023 ">
we acknowledge previous work on the computational study of adjectival scales as in (hatzivassiloglou and mckeown, 1993), <papid> P93-1023 </papid>where system could group gradation scales using clustering algorithm.</citsent>
<aftsection>
<nextsent>the polar representation of adjectives discussed in (miller, 1990) also influenced our system.
</nextsent>
<nextsent>we propose an unsupervised model of language feature collection that is based on description by observation, that is, learning target classifications by reading about the musical artists in reviews and discussions.
</nextsent>
<nextsent>3.1 community metadata.
</nextsent>
<nextsent>our model is called community meta data (whitman and lawrence, 2002) and has been successfully used in style detection (whitman and smaragdis, 2002) and artist similarity prediction (ellis et al, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z127">
<title id=" W03-0613.xml">learning word meanings and descriptive parameter spaces from music </title>
<section> automatically uncovering description.  </section>
<citcontext>
<prevsection>
<prevsent>our model is called community meta data (whitman and lawrence, 2002) and has been successfully used in style detection (whitman and smaragdis, 2002) and artist similarity prediction (ellis et al, 2002).
</prevsent>
<prevsent>it creates machine understandable representation of artist description by searching the internet for the artist name and performing light natural language processing on the retrievedpages.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
we split the returned documents into classes encompassing n-grams (terms of word length n), adjectives (using part-of-speech tagger (brill, 1992)) <papid> A92-1021 </papid>and noun phrases (using lexical chunker (ramshaw and marcus, 1995).)<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>each pair {artist, term} retrieved is givenan associated salience weight, which indicates the relative importance of term as associated to artist.
</nextsent>
<nextsent>thesesaliences are computed using variant of the popular tf idf measure gaussian weighted to avoid highly specific and highly general terms.
</nextsent>
<nextsent>(see table 2 for an example.)one important feature of community meta data is its time sensitivity; terms can be crawled once week and we can take into account trajectories of community-level opinion about certain artists.
</nextsent>
<nextsent>although tempting, we are reticent to make the claim that the community meta data vectors computationally approach the linguistic division of labor?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z128">
<title id=" W03-0613.xml">learning word meanings and descriptive parameter spaces from music </title>
<section> automatically uncovering description.  </section>
<citcontext>
<prevsection>
<prevsent>our model is called community meta data (whitman and lawrence, 2002) and has been successfully used in style detection (whitman and smaragdis, 2002) and artist similarity prediction (ellis et al, 2002).
</prevsent>
<prevsent>it creates machine understandable representation of artist description by searching the internet for the artist name and performing light natural language processing on the retrievedpages.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
we split the returned documents into classes encompassing n-grams (terms of word length n), adjectives (using part-of-speech tagger (brill, 1992)) <papid> A92-1021 </papid>and noun phrases (using lexical chunker (ramshaw and marcus, 1995).)<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>each pair {artist, term} retrieved is givenan associated salience weight, which indicates the relative importance of term as associated to artist.
</nextsent>
<nextsent>thesesaliences are computed using variant of the popular tf idf measure gaussian weighted to avoid highly specific and highly general terms.
</nextsent>
<nextsent>(see table 2 for an example.)one important feature of community meta data is its time sensitivity; terms can be crawled once week and we can take into account trajectories of community-level opinion about certain artists.
</nextsent>
<nextsent>although tempting, we are reticent to make the claim that the community meta data vectors computationally approach the linguistic division of labor?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z129">
<title id=" W02-1702.xml">cascading xsl filters for content selection in multilingual document generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these cascading filters are implemented in xsl.
</prevsent>
<prevsent>it is widely accepted that content selection plays crucial role in text generation (reiter and dale 2000).
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
this process is normally seen as goal-directed activity in which text segments are fit into the discourse structure of the text so as to convey coherent communicative goal (grosz and sidner 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>content planning techniques, such as textual schemas (mckeown 1985) or plan operators (moore and paris 1993), have been successfully used as models of text generation.
</nextsent>
<nextsent>there are cases, though, in which these techniques may face some limitations, for example, when the structure of the discourse is difficult to anticipate (mellish et al 1998).<papid> W98-1404 </papid></nextsent>
<nextsent>nevertheless, when set of well-defined communicative goals exists, complex goals can be broken down into sequences of utterances and generation becomes an efficient  top-down   process (marcu 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z130">
<title id=" W02-1702.xml">cascading xsl filters for content selection in multilingual document generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this process is normally seen as goal-directed activity in which text segments are fit into the discourse structure of the text so as to convey coherent communicative goal (grosz and sidner 1986).<papid> J86-3001 </papid></prevsent>
<prevsent>content planning techniques, such as textual schemas (mckeown 1985) or plan operators (moore and paris 1993), have been successfully used as models of text generation.</prevsent>
</prevsection>
<citsent citstr=" W98-1404 ">
there are cases, though, in which these techniques may face some limitations, for example, when the structure of the discourse is difficult to anticipate (mellish et al 1998).<papid> W98-1404 </papid></citsent>
<aftsection>
<nextsent>nevertheless, when set of well-defined communicative goals exists, complex goals can be broken down into sequences of utterances and generation becomes an efficient  top-down   process (marcu 1997).
</nextsent>
<nextsent>this paper shows macrolevel content selection algorithm that applies user profiles to constrain and discriminate the contents of text, whose discourse structure is represented using simplified version of rhetorical structure theory (mann and thompson 1988).
</nextsent>
<nextsent>the algorithm has been implemented using xml/xsl-based technology in multilingual document generation system for educational purposes.
</nextsent>
<nextsent>the main objective of this courseviewgenerator system (barrutieta, 2001 and barrutieta et al, 2001) is to automatically produce multilingual learning documents that suit the student needs at each particular stage of the learning process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z131">
<title id=" W03-0903.xml">less is more using a single knowledge representation in dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, examples highlighting the usefulness of our approach are given.
</prevsent>
<prevsent>the ways in which knowledge has been represented inmulti-modal dialogue systems (mmds) show that individual representations with different semantics and heterogeneously structured content can be found in various formats within single natural language processing(nlp) systems and applications.
</prevsent>
</prevsection>
<citsent citstr=" P96-1009 ">
for example, typical nlp system, such as trains (allen et al, 1996), <papid> P96-1009 </papid>employs different knowledge representations for parsing, action planning and generation, despite the fact that whatis being represented is common to all those representations, e. g., the parser representation for going from to has no similarity to the action planners representation thereof (ferguson et al, 1996).</citsent>
<aftsection>
<nextsent>also central concepts, for example city, are represented in multiple ways through out the system.
</nextsent>
<nextsent>the origin for this state of affairs is that the respective knowledge stores are hand-crafted individually for each task.
</nextsent>
<nextsent>sometimes they are compiled into code and cease to be externally available.
</nextsent>
<nextsent>where an explicit knowledge representation is used, we find multitude of formats and inference engines, which often cause both performance and tract ability problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z132">
<title id=" W03-0903.xml">less is more using a single knowledge representation in dialogue systems </title>
<section> our approach to knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>these objects refer to different domains, such as sight and route in the tourism domain, avmedium and actor in the tv and cinema do main, etc., and can be associated with certain relations in the processes via slot constraint definitions.
</prevsent>
<prevsent>4.3 representing processes.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the modeling of process as kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the framenet data(baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>based on the analysis of our dialogue data, we developed the following classification of processes (see figure 2):   general process, set of the most general processes such as duplication, imitation or repetition pro cesses;   mental process, set of processes such as cognitive, emotional or perceptual processes;   physical process, set of processes such as motion, transaction or controlling processes;  social process, set of processes such as communication or instruction processes.while the three last classes can be understood intuitively, the first one needs further explanation.
</nextsent>
<nextsent>it consists of several subclasses, such as abstractduplicationprocess, abstractrepetitionprocess, abstractimitationprocess, etc. these are abstract processes that are independent from the real processes and can take place at the same time with the main process.
</nextsent>
<nextsent>the mental process subtree includes cognitiveprocess,emotionprocess and perceptualprocess.
</nextsent>
<nextsent>under cogni tive process we understand group of processes that aimat acquiring information or making plans about the future.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z133">
<title id=" W03-0903.xml">less is more using a single knowledge representation in dialogue systems </title>
<section> example applications of ontology.  </section>
<citcontext>
<prevsection>
<prevsent>5all examples are displayed with the germano riginal on top and glossed translation below.
</prevsent>
<prevsent>5.1 semantic coherence scoring.
</prevsent>
</prevsection>
<citsent citstr=" N03-1012 ">
we introduced the notion of semantic coherence as special measurement which can be applied to estimate how well given speech recognition hypothesis (srh) fits with respect to the existing knowledge representation(gurevych et al, 2003).<papid> N03-1012 </papid></citsent>
<aftsection>
<nextsent>this provides mechanism increasing the robustness and reliability of multi-modal dialogue systems.
</nextsent>
<nextsent>5.1.1 challenge one of the major challenges in making an mmds reliable enough to be deployed in more complex real world applications is an accurate recognition of the users?
</nextsent>
<nextsent>input.
</nextsent>
<nextsent>in many cases both correct and incorrect representations of the users?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z134">
<title id=" W03-0903.xml">less is more using a single knowledge representation in dialogue systems </title>
<section> example applications of ontology.  </section>
<citcontext>
<prevsection>
<prevsent>the scoring software performs number of processing steps:   converting each srh into concept representation.
</prevsent>
<prevsent>for this purpose, each entry of the systems lexicon was augmented with zero, one or multiple ontology concepts;   converting the domain model, i.e. an ontology, into directed graph with concepts as nodes and relations as edges;   scoring concept representations using the shortest path between concepts based scoring metric.
</prevsent>
</prevsection>
<citsent citstr=" W02-0207 ">
for example, in our data (gurevych et al, 2002) <papid> W02-0207 </papid>user expressed the wish to get more information about specific church, as: (3) kann may ich bitte please informationen information zur about the heiliggeistkirche church of holy spirit bekommen get looking at two srhs from the ensuing n-best list wefound that example (5) constituted suitable representation of the utterance, whereas example (4) constituted less adequate representation thereof, labeled accordingly by the human annotators: (4) kann may ich information information zur about the heiliggeistkirche church of holy spirit kommen come (5) kann may ich information information zur about the heiliggeistkirche church of holy spirit bekommen get according to the lexicon entries, the srhs are transformed into two alternative concept representations:  </citsent>
<aftsection>
<nextsent> :  person; information search process; church; motion directed transliterated process  ;
</nextsent>
<nextsent> :  person; information search process; church; transaction process  . the scores are normalized as numbers on scale from0 to 1 with higher scores indicating better semantic coherence.
</nextsent>
<nextsent>then, the resulting score assigned to example4 is 0.6, and the score of example 5 is 0.75.
</nextsent>
<nextsent>the evaluation of the method against the hand-annotated corpus has shown that it successfully classifies 73.2% in german corpus of 2.284 speech recognition hypotheses as either coherent or incoherent, given baseline 54.55% derived from the annotation experiments (the majority class).additional application of the semantic coherence scoring method is the calculation of semantic coherence score for srhs taking into account their conceptual context (porzel and gurevych, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z135">
<title id=" W03-0903.xml">less is more using a single knowledge representation in dialogue systems </title>
<section> example applications of ontology.  </section>
<citcontext>
<prevsection>
<prevsent>second, and most notably, using overlay (alexandersson and becker, 2003) we can straightforwardly inherit information from one discourse state to another, even if the focussed instance of the ontology is from different but related type than the one of the current hypothesis.
</prevsent>
<prevsent>the advantage of this technique becomes evident in the dialogue excerpt below.
</prevsent>
</prevsection>
<citsent citstr=" P92-1004 ">
the data structure of the discourse memory is based on the ideas presented in luperfoy (1992),<papid> P92-1004 </papid>salmon-alt (2000).</citsent>
<aftsection>
<nextsent>a three-tiered partition of modality, discourse and domain layer is connected with double threaded focus structure.
</nextsent>
<nextsent>a non-monotonic unification-like operation called overlay serves as the main algorithm for manipulating instances of the ontology.
</nextsent>
<nextsent>it combines new information (cover) with old context information (background)by unifying where possible, and overwriting where unification would fail.
</nextsent>
<nextsent>additionally, the operation does not fail if the types differ, but assimilates the background tothe type of the cover - thereby possibly deleting information of the background - before the cover is layed over the background.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z136">
<title id=" W03-0303.xml">word alignment based on bilingual bracketing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal is to extract structure information from parallel sentences, and thereby improve word/phrase alignment via bilingual constraint transfer.this approach can be generalized to the automatic acquisition of translation lexicon and phrase translations esp. for languages for which resources are relatively scarce compared with english.
</prevsent>
<prevsent>the parallel sentences in building statistical machine translation (smt) systems are mostly unrestricted text where full parsing often fails, and robustness with respect to the inherent noise of the parallel data is important.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
bilingual bracketing [wu 1997] <papid> J97-3002 </papid>is one of the bilingual shallow parsing approaches studied for chinese-english word alignment.</citsent>
<aftsection>
<nextsent>it uses translation lexicon within aprobabilistic context free grammar (pcfg) as generative model to analyze the parallel sentences with weak order constraints.
</nextsent>
<nextsent>this provides framework to incorporate knowledge from the english side such as pos, phrase structure and potentially more detailed parsing results.in this paper, we use simplified bilingual bracketing grammar together with statistical translation lexicon such as the model-1 lexicon [brown 1993] to do the bilingual bracketing.
</nextsent>
<nextsent>a boosting strategy is studied and applied to the statistical lexicon training.
</nextsent>
<nextsent>english pos andbase noun phrase (np) detection are used to further im prove the alignment performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z141">
<title id=" W03-0303.xml">word alignment based on bilingual bracketing </title>
<section> bilingual bracketing.  </section>
<citcontext>
<prevsection>
<prevsent>each a-production rule has probability.
</prevsent>
<prevsent>in our algorithm, we use the same pcfg.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
however, instead of estimating the probabilities for the production rules via em as described in [wu 1997], <papid> J97-3002 </papid>we assign the probabilities to the rules using the model-1 statistical translation lexicon [brown et al  1993].<papid> J93-2003 </papid>because the syntactic a-production rules do not compete with the lexical rules, we can set them some default values.</citsent>
<aftsection>
<nextsent>also we make no assumptions which bracketing direction is more likely to occur, thus the probabilities for [ ] and    are set to be equal.
</nextsent>
<nextsent>as for the lexical rules, we experimented with the conditional probabilities p(e|f), p(f |e) and the interpolation of p(f |e, epos) andp(f |e) (described in section 4.1).
</nextsent>
<nextsent>as for these probabilities of aligning word to the null word or to unknown words, they are set to be 1e-7, which is the default small value used in training model-1.
</nextsent>
<nextsent>the word alignment can then be done via maximizing the likelihood of matched words subject to the bracketing grammar using dynamic programming.the result of the parsing gives bracketing for both in put sentences as well as bracket al gnments indicating the corresponding brackets between the sentence pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z143">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate this method by demonstrating that web frequencies and correlate with frequencies obtained from carefully edited, balanced corpus.
</prevsent>
<prevsent>we also perform task-based evaluation, showing that web frequencies can reliably predict human plausibility judgments.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
in two recent papers, banko and brill (2001<papid> P01-1005 </papid>a), banko and brill (2001<papid> P01-1005 </papid>b) criticize the fact that current nlp algorithms are typically optimized, tested, and compared on fairly small datasets (corpora with millions ofwords), even though datasets several orders of magnitude larger are available, at least for some tasks.</citsent>
<aftsection>
<nextsent>banko and brill go on to demonstrate that learning algorithms typically used for nlp tasks benefit significantly from larger training sets, and their performance shows no sign of reaching an asymptote as the size of the training set increases.
</nextsent>
<nextsent>arguably, the largest dataset that is available for nlp is the web, which currently consists of at least 968 million pages.1 data retrieved from the web therefore provides enormous potential 1this is the number of pages indexed by google in march 2002, as estimated by search engine showdown (see http://www.searchengineshowdown.com/).
</nextsent>
<nextsent>for training nlp algorithms, if banko and brills findings generalize.
</nextsent>
<nextsent>there is small body of existing research that tries to harness the potential of the web for nlp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z151">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for training nlp algorithms, if banko and brills findings generalize.
</prevsent>
<prevsent>there is small body of existing research that tries to harness the potential of the web for nlp.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
grefenstette and nioche (2000) and jones and ghani (2000) use the web to generate corpora for languages where electronic resources are scarce, while resnik (1999)<papid> P99-1068 </papid>describes method for mining the web for bilingual texts.</citsent>
<aftsection>
<nextsent>mihalcea and moldovan (1999) <papid> P99-1020 </papid>and agirre and martinez (2000) use the web for word sense disambiguation, and volk (2001) proposes method for resolving pp attachment ambiguities based on web data.a particularly interesting application is proposed by grefenstette (1998), who uses the web for example-based machine translation.</nextsent>
<nextsent>his task is to translate compounds from french into english,with corpus evidence serving as filter for candidate translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z152">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is small body of existing research that tries to harness the potential of the web for nlp.
</prevsent>
<prevsent>grefenstette and nioche (2000) and jones and ghani (2000) use the web to generate corpora for languages where electronic resources are scarce, while resnik (1999)<papid> P99-1068 </papid>describes method for mining the web for bilingual texts.</prevsent>
</prevsection>
<citsent citstr=" P99-1020 ">
mihalcea and moldovan (1999) <papid> P99-1020 </papid>and agirre and martinez (2000) use the web for word sense disambiguation, and volk (2001) proposes method for resolving pp attachment ambiguities based on web data.a particularly interesting application is proposed by grefenstette (1998), who uses the web for example-based machine translation.</citsent>
<aftsection>
<nextsent>his task is to translate compounds from french into english,with corpus evidence serving as filter for candidate translations.
</nextsent>
<nextsent>as an example consider the french compound groupe de travail.
</nextsent>
<nextsent>there are five translation of groupe and three translations for travail (inthe dictionary that grefenstette (1998) is using), resulting in 15 possible candidate translations.
</nextsent>
<nextsent>only one of them, viz., work group has high corpus frequency, which makes it likely that this is the correct translation into english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z153">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> obtaining frequencies from the web.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 sampling bigrams.
</prevsent>
<prevsent>two types of adjective-noun bigrams were used in the present study: seen bigrams, i.e., bigrams that occur in given corpus, and unseen bigrams, i.e., bigrams that fail to occur in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" E99-1005 ">
for the seen adjective-noun bigrams, we used the data oflapata et al (1999), <papid> E99-1005 </papid>who compiled set of 90 bi grams as follows.</citsent>
<aftsection>
<nextsent>first, 30 adjectives were randomly chosen from lemmatized version of the bnc sothat each adjective had exactly two senses according to wordnet (miller et al, 1990) and was unambiguously tagged as adjective?
</nextsent>
<nextsent>98.6% of the time.
</nextsent>
<nextsent>the 30 adjectives ranged in bnc frequency from 1.9 to 49.1 per million.
</nextsent>
<nextsent>gsearch (corley et al, 2001), chart parser which detects syntactic patterns in atagged corpus by exploiting user-specified context free grammar and syntactic query, was usedto extract all nouns occurring in head-modifier relationship with one of the 30 adjectives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z154">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> obtaining frequencies from the web.  </section>
<citcontext>
<prevsection>
<prevsent>for each adjective, the set of bigrams was divided into three frequency bands based on an equal division of the range of log-transformed co-occurrence frequencies.
</prevsent>
<prevsent>then one bigram was chosen at random from each band.
</prevsent>
</prevsection>
<citsent citstr=" P01-1046 ">
lapata et al (2001) <papid> P01-1046 </papid>compiled set of 90 unseenadjective-noun bigrams using the same 30 adjec tives.</citsent>
<aftsection>
<nextsent>for each adjective, the gsearch chunker wasused to compile list of all nouns that failed to cooccur in head-modifier relationship with the adjective.
</nextsent>
<nextsent>proper nouns and low-frequency nouns were discarded from this list.
</nextsent>
<nextsent>then each adjective was paired with three randomly chosen nouns from its list of non-co-occurring nouns.
</nextsent>
<nextsent>for the present study, we applied the procedure used by lapata et al (1999) <papid> E99-1005 </papid>and lapata et al (2001) <papid> P01-1046 </papid>to noun-noun bigrams and to verb-object bigrams, creating set of 90 seen and 90 unseen bigrams for each type of predicate-argument relationship.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z177">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> obtaining frequencies from the web.  </section>
<citcontext>
<prevsection>
<prevsent>all nouns modifying one of the 30 nouns were extracted from the bnc using heuristic which looks for consecutive pairs of nouns that are neither preceded nor succeeded by another noun (lauer, 1995).
</prevsent>
<prevsent>verb-object bigrams for the 30 pre selected verbs were obtained from the bnc using cass (abney, 1996), robust chunk parser designed for the shallow analysis of noisy text.
</prevsent>
</prevsection>
<citsent citstr=" N01-1009 ">
the parsers output was post-processed to remove bracketing errors and errors in identifying chunk categories that could potentially result in bigrams whose members do not stand in verb-argument relationship (see lapata (2001) <papid> N01-1009 </papid>for details on the filtering process).</citsent>
<aftsection>
<nextsent>only nominal heads were retained fromthe objects returned by the parser.
</nextsent>
<nextsent>as in the adjective study, noun-noun bigrams and verb-object bi grams with proper nouns or low-frequency nouns (less than 10 per million) were discarded.
</nextsent>
<nextsent>the sets of noun-noun and verb-object bigrams were divided into three frequency bands and one bigram was chosen at random from each band.
</nextsent>
<nextsent>the procedure described by lapata et al (2001) <papid> P01-1046 </papid>was followed for creating sets of unseen noun-noun and verb-object bigrams: for each of noun or verb, we compiled list of all nouns with which it failed to co-occur with in noun-noun or verb-object bigram in the bnc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z271">
<title id=" W02-1030.xml">using the web to overcome data sparseness </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>these results show that our heuristic method yields useful frequencies; the simplifications we made in obtaining the counts, as wellas the fact that web data are noisy, seem to be outweighed by the fact that the web is up to three orders of magnitude larger than the bnc (see our estimate in section 2.2).
</prevsent>
<prevsent>this paper explored novel approach to overcoming data sparseness.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
if bigram is unseen in given corpus, conventional approaches recreate its frequency using techniques such as back-off, linear interpolation, class-based smoothing or distance-weighted averaging (see dagan et al (1999) and lee (1999) <papid> P99-1004 </papid>for overviews).</citsent>
<aftsection>
<nextsent>the approach proposed here doesnot recreate the missing counts, but instead retrieves them from corpus that is much larger (but also much more noisy) than any existing corpus: it launches queries to search engine in order to determine how often bigram occurs on the web.
</nextsent>
<nextsent>we systematically investigated the validity of this approach by using it to obtain frequencies forpredicate-argument bigrams (adjective-noun, noun noun, and verb-object bigrams).
</nextsent>
<nextsent>we first applied the approach to seen bigrams randomly sampled from the bnc.
</nextsent>
<nextsent>we found that the counts obtained from the web are highly correlated with the counts obtained from the bnc, which indicates that web queries can generate frequencies that are comparable to the ones obtained from balanced, carefully edited corpus such as the bnc.secondly, we performed tasked-based evaluation that used the web frequencies to predict human plausibility judgments for predicate-argumentbigrams.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z272">
<title id=" W03-1022.xml">super sense tagging of unknown nouns in wordnet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in terms of the wordnet lexical database, one would like to automatically assign unknown words position in the synset hierarchy, introducing new synsets and extending the synset hierarchy where appropriate.
</prevsent>
<prevsent>doing this accurately is adifficult problem, and in this paper we address simpler problem: automatically determining the broad semantic class, or super sense, to which unknown words belong.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
systems for thesaurus extension (hearst, 1992;<papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>information extraction (riloff and jones, 1999) or named-entity recognition (collins and singer, 1999) <papid> W99-0613 </papid>each partially address this problem in different ways.</citsent>
<aftsection>
<nextsent>the goal in these tasks is automatically tagging words with semantic labels such as vehicle?, organization?, person?, etc.in this paper we extend the named-entity recognition approach to the classification of common nouns into 26 different supersenses.
</nextsent>
<nextsent>rather than define these ourselves, we adopted the 26 lexicographer class?
</nextsent>
<nextsent>labels used in wordnet, which include labels such as person, location, event, quantity, etc. we believe our general approach should generalize to other definitions of supersenses.using the wordnet lexicographer classes as su per senses has number of practical advantages.first, we show how information contained in the dictionary can be used as additional training data that improves the systems accuracy.
</nextsent>
<nextsent>secondly, it is possible to use very natural evaluation procedure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z273">
<title id=" W03-1022.xml">super sense tagging of unknown nouns in wordnet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in terms of the wordnet lexical database, one would like to automatically assign unknown words position in the synset hierarchy, introducing new synsets and extending the synset hierarchy where appropriate.
</prevsent>
<prevsent>doing this accurately is adifficult problem, and in this paper we address simpler problem: automatically determining the broad semantic class, or super sense, to which unknown words belong.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
systems for thesaurus extension (hearst, 1992;<papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>information extraction (riloff and jones, 1999) or named-entity recognition (collins and singer, 1999) <papid> W99-0613 </papid>each partially address this problem in different ways.</citsent>
<aftsection>
<nextsent>the goal in these tasks is automatically tagging words with semantic labels such as vehicle?, organization?, person?, etc.in this paper we extend the named-entity recognition approach to the classification of common nouns into 26 different supersenses.
</nextsent>
<nextsent>rather than define these ourselves, we adopted the 26 lexicographer class?
</nextsent>
<nextsent>labels used in wordnet, which include labels such as person, location, event, quantity, etc. we believe our general approach should generalize to other definitions of supersenses.using the wordnet lexicographer classes as su per senses has number of practical advantages.first, we show how information contained in the dictionary can be used as additional training data that improves the systems accuracy.
</nextsent>
<nextsent>secondly, it is possible to use very natural evaluation procedure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z274">
<title id=" W03-1022.xml">super sense tagging of unknown nouns in wordnet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in terms of the wordnet lexical database, one would like to automatically assign unknown words position in the synset hierarchy, introducing new synsets and extending the synset hierarchy where appropriate.
</prevsent>
<prevsent>doing this accurately is adifficult problem, and in this paper we address simpler problem: automatically determining the broad semantic class, or super sense, to which unknown words belong.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
systems for thesaurus extension (hearst, 1992;<papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>information extraction (riloff and jones, 1999) or named-entity recognition (collins and singer, 1999) <papid> W99-0613 </papid>each partially address this problem in different ways.</citsent>
<aftsection>
<nextsent>the goal in these tasks is automatically tagging words with semantic labels such as vehicle?, organization?, person?, etc.in this paper we extend the named-entity recognition approach to the classification of common nouns into 26 different supersenses.
</nextsent>
<nextsent>rather than define these ourselves, we adopted the 26 lexicographer class?
</nextsent>
<nextsent>labels used in wordnet, which include labels such as person, location, event, quantity, etc. we believe our general approach should generalize to other definitions of supersenses.using the wordnet lexicographer classes as su per senses has number of practical advantages.first, we show how information contained in the dictionary can be used as additional training data that improves the systems accuracy.
</nextsent>
<nextsent>secondly, it is possible to use very natural evaluation procedure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z279">
<title id=" W03-1022.xml">super sense tagging of unknown nouns in wordnet </title>
<section> lexicographer classes for noun.  </section>
<citcontext>
<prevsection>
<prevsent>the reasonable size of the label set makes it possible to apply state of-the-art machine learning methods.
</prevsent>
<prevsent>otherwise, classifying new words at the synset level defines multiclass problem with huge class space - more than 66,000 noun synsets in wordnet 1.6, more than75,000 in the newest release, 1.71 (cf.
</prevsent>
</prevsection>
<citsent citstr=" W02-0903 ">
also (cia ramita, 2002) <papid> W02-0903 </papid>on this problem).</citsent>
<aftsection>
<nextsent>at the same time the labels are not too abstract or vague.
</nextsent>
<nextsent>most of the classes seem natural and easily recognizable.
</nextsent>
<nextsent>thatis probably why they were chosen by the lexicog raphers to facilitate their task.
</nextsent>
<nextsent>but there are more important practical and methodological advantages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z283">
<title id=" W03-1022.xml">super sense tagging of unknown nouns in wordnet </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we will investigate this issue in future research.open class words were morphologically simplified with the morph?
</prevsent>
<prevsent>function included in wordnet.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we parsed the wordnet definitions and example sentences with the same syntactic parser used for bllip (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>it is not always possible to identify the noun that represents the synset in the wordnet glosses.
</nextsent>
<nextsent>for example, in the gloss for the synset relegation the example sentence is he has been relegated to post in siberia?, where verb is used instead of the noun.
</nextsent>
<nextsent>when it was possible to identify the target noun the complete feature set was used; otherwise only thesurrounding-word features (2) and the spelling features (7) of all synonyms were used.
</nextsent>
<nextsent>with the definitions it is much harder to individuate the target;consider the definition member of the genus ca nis?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z284">
<title id=" W03-1022.xml">super sense tagging of unknown nouns in wordnet </title>
<section> the multiclass averaged perceptron.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm is summarized in algorithm 1.
</prevsent>
<prevsent>notice that the multiclass perceptron algorithm learns all weight vectors in coupled manner, in contrast to methods that perform multiclass classification by combining binary classifiers, for example,training classifier for each class in one-against the-rest manner.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the averaged version of the perceptron (collins, 2002), <papid> W02-1001 </papid>like the voted perceptron (freund and schapire, 1999), reduces the effect of over-training.</citsent>
<aftsection>
<nextsent>in addition to the matrix of weight vectors the model keeps track for each feature ? of each value it assumed during training, ? , and the number of consecutive training instance presentations during which this weight was not changed, or life span?,  ] ? ob . when training is done these weights are av-.
</nextsent>
<nextsent>eraged and the final averaged weight r1?;?
</nextsent>
<nextsent>of feature ? is computed as ? 1?;?
</nextsent>
<nextsent>[ ? ?o  ] ?o ?  ] ? oqb (3) for example, if there is feature weight that is not updated until example 500, at which point it is incremented to value 1, and is not touched again until after example 1000, then the average weight of that feature in the averaged perceptron at example 750 will be: ???;rff?;?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z285">
<title id=" W03-0707.xml">flexible and personalizable mixed initiative dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first and foremost, it is essential to develop tools that will enable rapid configuration of dialogue systems in new domains of knowledge, guided mainly from domain-dependent information sources.
</prevsent>
<prevsent>our efforts in generic dialogue development represent strong initiative toward that goal (po lifroni and chung, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N03-1005 ">
secondly, we need to be ableto support incremental update of vocabularies and language models for speech recognition and understanding, in essentially instantaneous time (schalkwyk et al, 2003; seneff et al, 1998; chung et al, 2003).<papid> N03-1005 </papid></citsent>
<aftsection>
<nextsent>this would allow great flexibility within single dialogue where the user might ask about named entity that is not yet known tothe system.
</nextsent>
<nextsent>third, while we can make use of large lexical resource for pronunciation modeling, we must have available as well high-performance letter-to-sound capability, integrating multiple knowledge sources such as web page, spoken name, spoken spelling of the name, and/or key-padded name (chung and seneff, 2002).fourth, we need to have intelligent knowledge acquisition systems, capable of populating database from web sources, and extracting and organizing key elements from the database (polifroni et al, 2003).
</nextsent>
<nextsent>these ideas can best be illustrated through couple of example scenarios.
</nextsent>
<nextsent>in figure 1, the user begins with request for restaurant in neighborhood of boston.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z286">
<title id=" W03-0707.xml">flexible and personalizable mixed initiative dialogue systems </title>
<section> underlying technologies.  </section>
<citcontext>
<prevsection>
<prevsent>speechbuilder: over the past few years, we have been developing set of utilities that would enable research results to be migrated directly into application development (glass and weinstein, 2001).
</prevsent>
<prevsent>our goal is to enable natural, mixed-initiative interfaces similar to those now created manually by relatively small group of expert developers.
</prevsent>
</prevsection>
<citsent citstr=" W00-0303 ">
we make no distinction between the technology components of speech builder and those of our most sophisticated dialogue systems, such as the mercury flight reservation domain (seneff and polifroni, 2000).<papid> W00-0303 </papid></citsent>
<aftsection>
<nextsent>speech builder employs web-based interface where developers type in the specifics of their domain, guided by forms andpull-down menus.
</nextsent>
<nextsent>components such as recognition vocabulary, parse rules, and semantic mappings are created automatically from example sentences entered by the developer.
</nextsent>
<nextsent>in several recent short courses, naive developers have been able to implement new domain and converse with it on the telephone in matter of hours.language modelling: patchwork grammars serious limitation in todays technology to immediate deployment of new system is the chicken-and-egg problem of the language model.
</nextsent>
<nextsent>system performance is critically tiedto the quality of the statistical language model, which typically depends on large domain-dependent corpora that dont exist until the domain is actually deployed and widely used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z290">
<title id=" W03-1726.xml">introduction to ckip chinese word segmentation system for the first international chinese word segmentation bakeoff </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is well known that there are two major difficulties in chinese word segmentation.
</prevsent>
<prevsent>one is resolving the ambiguous segmentation, and the other is identifying unknown words.
</prevsent>
</prevsection>
<citsent citstr=" C92-1019 ">
our earlier work mainly focused on the resolving of segmentation ambiguities and using regular expressions to handle the determinant measure and reduplication compounds (chen &amp; liu 1992, <papid> C92-1019 </papid>chen 1999).</citsent>
<aftsection>
<nextsent>we adopt variation of the longest matching algorithm with several heuristic rules to resolve the ambiguities and achieve 99.77% of the success rate without counting the mistakes occurred due to the existence of unknown words.
</nextsent>
<nextsent>after that, we were paying more attention on the problems of extracting and identifying unknown words (chen et.al 1997, chen &amp; bai 1998, chen &amp; ma 2002, <papid> C02-1049 </papid>tseng &amp; chen 2002, <papid> W02-1811 </papid>ma &amp; chen 2003).<papid> W03-1705 </papid></nextsent>
<nextsent>the process of unknown word extraction could be roughly divided into two steps, i.e. detection process and extraction process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z291">
<title id=" W03-1726.xml">introduction to ckip chinese word segmentation system for the first international chinese word segmentation bakeoff </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our earlier work mainly focused on the resolving of segmentation ambiguities and using regular expressions to handle the determinant measure and reduplication compounds (chen &amp; liu 1992, <papid> C92-1019 </papid>chen 1999).</prevsent>
<prevsent>we adopt variation of the longest matching algorithm with several heuristic rules to resolve the ambiguities and achieve 99.77% of the success rate without counting the mistakes occurred due to the existence of unknown words.</prevsent>
</prevsection>
<citsent citstr=" C02-1049 ">
after that, we were paying more attention on the problems of extracting and identifying unknown words (chen et.al 1997, chen &amp; bai 1998, chen &amp; ma 2002, <papid> C02-1049 </papid>tseng &amp; chen 2002, <papid> W02-1811 </papid>ma &amp; chen 2003).<papid> W03-1705 </papid></citsent>
<aftsection>
<nextsent>the process of unknown word extraction could be roughly divided into two steps, i.e. detection process and extraction process.
</nextsent>
<nextsent>the detection process detects possible occurrences of unknown words (chen &amp; bai 1998), so that deeper morphological analysis is carried out only at the places where unknown word morphemes were detected (chen &amp; ma 2002).<papid> C02-1049 </papid></nextsent>
<nextsent>a bottom-up merging algorithm was proposed in (ma &amp; chen 2003), <papid> W03-1705 </papid>which utilizes hybrid statistical and linguistic information to extract unknown words effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z292">
<title id=" W03-1726.xml">introduction to ckip chinese word segmentation system for the first international chinese word segmentation bakeoff </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our earlier work mainly focused on the resolving of segmentation ambiguities and using regular expressions to handle the determinant measure and reduplication compounds (chen &amp; liu 1992, <papid> C92-1019 </papid>chen 1999).</prevsent>
<prevsent>we adopt variation of the longest matching algorithm with several heuristic rules to resolve the ambiguities and achieve 99.77% of the success rate without counting the mistakes occurred due to the existence of unknown words.</prevsent>
</prevsection>
<citsent citstr=" W02-1811 ">
after that, we were paying more attention on the problems of extracting and identifying unknown words (chen et.al 1997, chen &amp; bai 1998, chen &amp; ma 2002, <papid> C02-1049 </papid>tseng &amp; chen 2002, <papid> W02-1811 </papid>ma &amp; chen 2003).<papid> W03-1705 </papid></citsent>
<aftsection>
<nextsent>the process of unknown word extraction could be roughly divided into two steps, i.e. detection process and extraction process.
</nextsent>
<nextsent>the detection process detects possible occurrences of unknown words (chen &amp; bai 1998), so that deeper morphological analysis is carried out only at the places where unknown word morphemes were detected (chen &amp; ma 2002).<papid> C02-1049 </papid></nextsent>
<nextsent>a bottom-up merging algorithm was proposed in (ma &amp; chen 2003), <papid> W03-1705 </papid>which utilizes hybrid statistical and linguistic information to extract unknown words effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z293">
<title id=" W03-1726.xml">introduction to ckip chinese word segmentation system for the first international chinese word segmentation bakeoff </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our earlier work mainly focused on the resolving of segmentation ambiguities and using regular expressions to handle the determinant measure and reduplication compounds (chen &amp; liu 1992, <papid> C92-1019 </papid>chen 1999).</prevsent>
<prevsent>we adopt variation of the longest matching algorithm with several heuristic rules to resolve the ambiguities and achieve 99.77% of the success rate without counting the mistakes occurred due to the existence of unknown words.</prevsent>
</prevsection>
<citsent citstr=" W03-1705 ">
after that, we were paying more attention on the problems of extracting and identifying unknown words (chen et.al 1997, chen &amp; bai 1998, chen &amp; ma 2002, <papid> C02-1049 </papid>tseng &amp; chen 2002, <papid> W02-1811 </papid>ma &amp; chen 2003).<papid> W03-1705 </papid></citsent>
<aftsection>
<nextsent>the process of unknown word extraction could be roughly divided into two steps, i.e. detection process and extraction process.
</nextsent>
<nextsent>the detection process detects possible occurrences of unknown words (chen &amp; bai 1998), so that deeper morphological analysis is carried out only at the places where unknown word morphemes were detected (chen &amp; ma 2002).<papid> C02-1049 </papid></nextsent>
<nextsent>a bottom-up merging algorithm was proposed in (ma &amp; chen 2003), <papid> W03-1705 </papid>which utilizes hybrid statistical and linguistic information to extract unknown words effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z301">
<title id=" W03-1706.xml">the effect of rhythm on structural disambiguation in chinese </title>
<section> content chunk parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the purpose of content chunk parsing is to recognize phrases in sequence of content words.
</prevsent>
<prevsent>specifically speaking, the content chunking contains two subtasks: (1) to recognize the maximum phrase in sequence of content words; (2) to analyze the hierarchical structure within the phrase down to words.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
like basenp chunking(church, 1988; <papid> A88-1019 </papid>ramshaw &amp; marcus 1995), <papid> W95-0107 </papid>content chunk parsing is also kind of shallow parsing.</citsent>
<aftsection>
<nextsent>content chunk parsing is deeper than basenp chunking in two aspects: (1) content chunk may contain verb phrases and other phrases even full sentence as long as the all the components are content words; (2) it may contain recursive nps.
</nextsent>
<nextsent>thus the content chunk can supply more structural information than basenp.
</nextsent>
<nextsent>the motives for content chunk parsing are two fold: (1) like other shallow parsing tasks, it can simplify the parsing task.
</nextsent>
<nextsent>this can be explained in two aspects.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z302">
<title id=" W03-1706.xml">the effect of rhythm on structural disambiguation in chinese </title>
<section> content chunk parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the purpose of content chunk parsing is to recognize phrases in sequence of content words.
</prevsent>
<prevsent>specifically speaking, the content chunking contains two subtasks: (1) to recognize the maximum phrase in sequence of content words; (2) to analyze the hierarchical structure within the phrase down to words.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
like basenp chunking(church, 1988; <papid> A88-1019 </papid>ramshaw &amp; marcus 1995), <papid> W95-0107 </papid>content chunk parsing is also kind of shallow parsing.</citsent>
<aftsection>
<nextsent>content chunk parsing is deeper than basenp chunking in two aspects: (1) content chunk may contain verb phrases and other phrases even full sentence as long as the all the components are content words; (2) it may contain recursive nps.
</nextsent>
<nextsent>thus the content chunk can supply more structural information than basenp.
</nextsent>
<nextsent>the motives for content chunk parsing are two fold: (1) like other shallow parsing tasks, it can simplify the parsing task.
</nextsent>
<nextsent>this can be explained in two aspects.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z303">
<title id=" W03-1706.xml">the effect of rhythm on structural disambiguation in chinese </title>
<section> pcfg + pf model.  </section>
<citcontext>
<prevsection>
<prevsent>= fsfi afipafsp ),|(),|( ??
</prevsent>
<prevsent>(5) under this pcfg+pf model, the goal of parser is to choose parse that maximizes the following score: )|,(maxarg)|( 1 afs iii it pst score ??
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
= = (6) our model is thus simplification of more sophisticated models which integrate pcfgs with features, such as those in magerman(1995), <papid> P95-1037 </papid>collins(1997) <papid> P97-1003 </papid>and goodman(1997).</citsent>
<aftsection>
<nextsent>compared with these models, our model is more practical when only small training data is available, since we assume the independence between features.
</nextsent>
<nextsent>for example, in goodmans probabilistic feature grammar (pfg), each symbol in pcfg is replaced by set of features, so it can describe specific constraints on the rule.
</nextsent>
<nextsent>in the pfg model the generation of each feature is dependent on all the previously generated features, thus likely leading to severe sparse data problem in parameter estimation.
</nextsent>
<nextsent>our simplified model assumes independence between the features, thus data sparseness problem can be significantly alleviated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z304">
<title id=" W03-1706.xml">the effect of rhythm on structural disambiguation in chinese </title>
<section> pcfg + pf model.  </section>
<citcontext>
<prevsection>
<prevsent>= fsfi afipafsp ),|(),|( ??
</prevsent>
<prevsent>(5) under this pcfg+pf model, the goal of parser is to choose parse that maximizes the following score: )|,(maxarg)|( 1 afs iii it pst score ??
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
= = (6) our model is thus simplification of more sophisticated models which integrate pcfgs with features, such as those in magerman(1995), <papid> P95-1037 </papid>collins(1997) <papid> P97-1003 </papid>and goodman(1997).</citsent>
<aftsection>
<nextsent>compared with these models, our model is more practical when only small training data is available, since we assume the independence between features.
</nextsent>
<nextsent>for example, in goodmans probabilistic feature grammar (pfg), each symbol in pcfg is replaced by set of features, so it can describe specific constraints on the rule.
</nextsent>
<nextsent>in the pfg model the generation of each feature is dependent on all the previously generated features, thus likely leading to severe sparse data problem in parameter estimation.
</nextsent>
<nextsent>our simplified model assumes independence between the features, thus data sparseness problem can be significantly alleviated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z305">
<title id=" W02-1606.xml">word sense disambiguation in a koreantojapanese mt system using neural networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, word sense disambiguation (wsd) is essential to the selection of an appropriate japanese target word.
</prevsent>
<prevsent>much research on word sense disambiguation has revealed that several different types of information can contribute to the resolution of lexical ambiguity.
</prevsent>
</prevsection>
<citsent citstr=" J92-1001 ">
these include surrounding words (an unordered set of words surrounding target word), local collocations (a short sequence of words near target word, taking word order into account), syntactic relations (selectional restrictions), parts of speech, morphological forms, etc (mcroy, 1992, <papid> J92-1001 </papid>ng and zelle, 1997).</citsent>
<aftsection>
<nextsent>some researchers use neural networks in their word sense disambiguation systems because of its strong capability in classification (waltz et al, 1985, gallant, 1991, leacock et al, 1993, <papid> H93-1051 </papid>and mooney, 1996).<papid> W96-0208 </papid></nextsent>
<nextsent>since, however, most such methods require few thousands of features or large amounts of hand-written data for training, it is not clear that the same neural network models will be applicable to real world applications.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z306">
<title id=" W02-1606.xml">word sense disambiguation in a koreantojapanese mt system using neural networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much research on word sense disambiguation has revealed that several different types of information can contribute to the resolution of lexical ambiguity.
</prevsent>
<prevsent>these include surrounding words (an unordered set of words surrounding target word), local collocations (a short sequence of words near target word, taking word order into account), syntactic relations (selectional restrictions), parts of speech, morphological forms, etc (mcroy, 1992, <papid> J92-1001 </papid>ng and zelle, 1997).</prevsent>
</prevsection>
<citsent citstr=" H93-1051 ">
some researchers use neural networks in their word sense disambiguation systems because of its strong capability in classification (waltz et al, 1985, gallant, 1991, leacock et al, 1993, <papid> H93-1051 </papid>and mooney, 1996).<papid> W96-0208 </papid></citsent>
<aftsection>
<nextsent>since, however, most such methods require few thousands of features or large amounts of hand-written data for training, it is not clear that the same neural network models will be applicable to real world applications.
</nextsent>
<nextsent>we propose word sense disambiguation method that combines both the neural net-based approach and the work of li et al(2000), especially focusing on the practicality of the method for application to real world mt systems.
</nextsent>
<nextsent>to reduce the number of input features of neural networks to practical size, we use concept codes of thesaurus as features.
</nextsent>
<nextsent>in this paper, yale roman ization is used to represent korean expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z307">
<title id=" W02-1606.xml">word sense disambiguation in a koreantojapanese mt system using neural networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much research on word sense disambiguation has revealed that several different types of information can contribute to the resolution of lexical ambiguity.
</prevsent>
<prevsent>these include surrounding words (an unordered set of words surrounding target word), local collocations (a short sequence of words near target word, taking word order into account), syntactic relations (selectional restrictions), parts of speech, morphological forms, etc (mcroy, 1992, <papid> J92-1001 </papid>ng and zelle, 1997).</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
some researchers use neural networks in their word sense disambiguation systems because of its strong capability in classification (waltz et al, 1985, gallant, 1991, leacock et al, 1993, <papid> H93-1051 </papid>and mooney, 1996).<papid> W96-0208 </papid></citsent>
<aftsection>
<nextsent>since, however, most such methods require few thousands of features or large amounts of hand-written data for training, it is not clear that the same neural network models will be applicable to real world applications.
</nextsent>
<nextsent>we propose word sense disambiguation method that combines both the neural net-based approach and the work of li et al(2000), especially focusing on the practicality of the method for application to real world mt systems.
</nextsent>
<nextsent>to reduce the number of input features of neural networks to practical size, we use concept codes of thesaurus as features.
</nextsent>
<nextsent>in this paper, yale roman ization is used to represent korean expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z308">
<title id=" W02-1606.xml">word sense disambiguation in a koreantojapanese mt system using neural networks </title>
<section> construction of refined feature set.  </section>
<citcontext>
<prevsection>
<prevsent>otherwise, the concept code is discarded.
</prevsent>
<prevsent>2.3.2 concept code generalization after concept discrimination, co-occurring concept codes in each cci type must be further selected and the code generalized.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
to perform code generalization, li adopted to smadjas work (smadja, 1993) <papid> J93-1007 </papid>and defined the code strength using code frequency and standard deviation in each level of the concept hierarchy.</citsent>
<aftsection>
<nextsent>the generalization filter selects the concept codes with strength larger than threshold.
</nextsent>
<nextsent>we perform this generalizaion processing on the kadokawa thesaurus level l4 and l3.
</nextsent>
<nextsent>after processing, the system stores there ty re fe e 3 3 th s refined conceptual patterns ({c1, c2, c3, ...}, pei, w(si)) as knowledge source for wsd of al texts.
</nextsent>
<nextsent>these refined cci are used as input atures for the neural network.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z309">
<title id=" W03-0406.xml">unsupervised learning of word sense disambiguation rules by estimating an optimum iteration number in the em algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many problems in natural language processing can be converted into classification problems, and be solved by an inductive learning method.
</prevsent>
<prevsent>this strategy has been very successful, but it has serious problem in that an inductive learning method requires labeled data, which is expensive because it must be made manually.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
to over come this problem, unsupervised learning methods using huge unlabeled data to boost the performance of rules learned by small labeled data have been proposed re cently(blum and mitchell, 1998)(yarowsky, 1995)(<papid> P95-1026 </papid>park et al, 2000)(<papid> P00-1069 </papid>li and li, 2002).</citsent>
<aftsection>
<nextsent>among these methods,the method using the em algorithm proposed by the pa per(nigam et al, 2000), which is referred to as the em method in this paper, is the state of the art.
</nextsent>
<nextsent>however, the target of the em method is text classification.
</nextsent>
<nextsent>it is hoped that this method can be applied to wsd, because wsd isthe most important problem in natural language processing.
</nextsent>
<nextsent>the em method works well in text classification, but often causes worse classification in wsd.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z310">
<title id=" W03-0406.xml">unsupervised learning of word sense disambiguation rules by estimating an optimum iteration number in the em algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many problems in natural language processing can be converted into classification problems, and be solved by an inductive learning method.
</prevsent>
<prevsent>this strategy has been very successful, but it has serious problem in that an inductive learning method requires labeled data, which is expensive because it must be made manually.
</prevsent>
</prevsection>
<citsent citstr=" P00-1069 ">
to over come this problem, unsupervised learning methods using huge unlabeled data to boost the performance of rules learned by small labeled data have been proposed re cently(blum and mitchell, 1998)(yarowsky, 1995)(<papid> P95-1026 </papid>park et al, 2000)(<papid> P00-1069 </papid>li and li, 2002).</citsent>
<aftsection>
<nextsent>among these methods,the method using the em algorithm proposed by the pa per(nigam et al, 2000), which is referred to as the em method in this paper, is the state of the art.
</nextsent>
<nextsent>however, the target of the em method is text classification.
</nextsent>
<nextsent>it is hoped that this method can be applied to wsd, because wsd isthe most important problem in natural language processing.
</nextsent>
<nextsent>the em method works well in text classification, but often causes worse classification in wsd.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z312">
<title id=" W02-1715.xml">salt an xml application for web based multimodal dialog management </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>which can subsequently be identified as constituent of the email command?
</prevsent>
<prevsent>semantic object.
</prevsent>
</prevsection>
<citsent citstr=" P97-1036 ">
because the notion of semantic objects is quite generic, dialog designers should find little difficulty employing other multimodal integration algorithms, such as the unification based approach described in (johnston et al 1997), <papid> P97-1036 </papid>in salt.</citsent>
<aftsection>
<nextsent>salt speech objects encapsulate speech functionality.
</nextsent>
<nextsent>they resemble to the gui objects in many ways.
</nextsent>
<nextsent>because they share the same high level abstraction, salt speech objects inter operate with gui objects in seamless and consistent manner.
</nextsent>
<nextsent>multimodal dialog designers can elect to ignore the modality of communication, much the same way as they are insulated from having to distinguish whether text string is entered to field through keyboard or cut and pasted with pointing device.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z313">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researches on corpus-based approaches to machine translation (mt) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri.
</prevsent>
<prevsent>these approaches generally relyon large text corpora, which play an important role in natural language processing (nlp) and information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" J94-4003 ">
moreover, non-alignedcomparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dagan and itai, 1994; <papid> J94-4003 </papid>dejean et al, 2002; <papid> C02-1166 </papid>diab and finch, 2000; fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>nakagawa, 2000; peters and picchi, 1995; rapp, 1999; <papid> P99-1067 </papid>shahzad and al., 1999; tanaka and iwasaki, 1996).<papid> C96-2098 </papid></citsent>
<aftsection>
<nextsent>unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period.
</nextsent>
<nextsent>this property made comparable corpora more abundant, less expensive and more accessible through the world wide web.in the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on cross-language information retrieval (clir).
</nextsent>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is conducted on ntcir, large-scale data collection for (japanese, english) language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z314">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researches on corpus-based approaches to machine translation (mt) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri.
</prevsent>
<prevsent>these approaches generally relyon large text corpora, which play an important role in natural language processing (nlp) and information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" C02-1166 ">
moreover, non-alignedcomparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dagan and itai, 1994; <papid> J94-4003 </papid>dejean et al, 2002; <papid> C02-1166 </papid>diab and finch, 2000; fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>nakagawa, 2000; peters and picchi, 1995; rapp, 1999; <papid> P99-1067 </papid>shahzad and al., 1999; tanaka and iwasaki, 1996).<papid> C96-2098 </papid></citsent>
<aftsection>
<nextsent>unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period.
</nextsent>
<nextsent>this property made comparable corpora more abundant, less expensive and more accessible through the world wide web.in the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on cross-language information retrieval (clir).
</nextsent>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is conducted on ntcir, large-scale data collection for (japanese, english) language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z315">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researches on corpus-based approaches to machine translation (mt) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri.
</prevsent>
<prevsent>these approaches generally relyon large text corpora, which play an important role in natural language processing (nlp) and information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
moreover, non-alignedcomparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dagan and itai, 1994; <papid> J94-4003 </papid>dejean et al, 2002; <papid> C02-1166 </papid>diab and finch, 2000; fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>nakagawa, 2000; peters and picchi, 1995; rapp, 1999; <papid> P99-1067 </papid>shahzad and al., 1999; tanaka and iwasaki, 1996).<papid> C96-2098 </papid></citsent>
<aftsection>
<nextsent>unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period.
</nextsent>
<nextsent>this property made comparable corpora more abundant, less expensive and more accessible through the world wide web.in the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on cross-language information retrieval (clir).
</nextsent>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is conducted on ntcir, large-scale data collection for (japanese, english) language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z316">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researches on corpus-based approaches to machine translation (mt) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri.
</prevsent>
<prevsent>these approaches generally relyon large text corpora, which play an important role in natural language processing (nlp) and information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
moreover, non-alignedcomparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dagan and itai, 1994; <papid> J94-4003 </papid>dejean et al, 2002; <papid> C02-1166 </papid>diab and finch, 2000; fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>nakagawa, 2000; peters and picchi, 1995; rapp, 1999; <papid> P99-1067 </papid>shahzad and al., 1999; tanaka and iwasaki, 1996).<papid> C96-2098 </papid></citsent>
<aftsection>
<nextsent>unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period.
</nextsent>
<nextsent>this property made comparable corpora more abundant, less expensive and more accessible through the world wide web.in the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on cross-language information retrieval (clir).
</nextsent>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is conducted on ntcir, large-scale data collection for (japanese, english) language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z317">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researches on corpus-based approaches to machine translation (mt) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri.
</prevsent>
<prevsent>these approaches generally relyon large text corpora, which play an important role in natural language processing (nlp) and information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" C96-2098 ">
moreover, non-alignedcomparable corpora have been given special interest in bilingual terminology acquisition and lexical resources enrichment (dagan and itai, 1994; <papid> J94-4003 </papid>dejean et al, 2002; <papid> C02-1166 </papid>diab and finch, 2000; fung, 2000; koehn and knight, 2002; <papid> W02-0902 </papid>nakagawa, 2000; peters and picchi, 1995; rapp, 1999; <papid> P99-1067 </papid>shahzad and al., 1999; tanaka and iwasaki, 1996).<papid> C96-2098 </papid></citsent>
<aftsection>
<nextsent>unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period.
</nextsent>
<nextsent>this property made comparable corpora more abundant, less expensive and more accessible through the world wide web.in the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on cross-language information retrieval (clir).
</nextsent>
<nextsent>clir consists of retrieving documents written in one language using queries written in another language.
</nextsent>
<nextsent>an application is conducted on ntcir, large-scale data collection for (japanese, english) language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z318">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> two-stages comparable corpora-based.  </section>
<citcontext>
<prevsection>
<prevsent>experiments and evaluations in clir are discussed in sections 4.
</prevsent>
<prevsent>section 5 concludes the present paper.
</prevsent>
</prevsection>
<citsent citstr=" P03-2025 ">
approach our proposed approach to bilingual terminology acquisition from comparable corpora (sadat et al,2003; <papid> P03-2025 </papid>sadat et al, 2003) <papid> P03-2025 </papid>is based on the assumption of similar collocation, i.e., if two words are mutual translations, then their most frequent collocates are likely to be mutual translations as well.</citsent>
<aftsection>
<nextsent>more over, we apply this assumption in both directions of the corpora, i.e., find translations of the source term in the target language corpus but also translations of the target terms in the source language corpus.the proposed two-stages approach for the acquisition, disambiguation and selection of bilingual terminology is described as follows: ? bilingual terminology acquisition from source language to target language to yield first translation model, represented by similarity simst . ? bilingual terminology acquisition from target language to source language to yield second translation model, represented by similarity simts . ? merge the first and second models to yielda two-stages translation model, based on bidirectional comparable corpora and represented by similarity simst .we follow strategies of previous researches (de jean et al, 2002; <papid> C02-1166 </papid>fung, 2000; rapp, 1999) <papid> P99-1067 </papid>for the first and second translation models and propose merging strategy for the two-stages translation model (sadat et al, 2003).<papid> P03-2025 </papid></nextsent>
<nextsent>first, word frequencies, context word frequencies in surrounding positions (here three-words window) are computed following statistics-based metrics, the log-likelihood ratio (dunning, 1993).<papid> J93-1003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z323">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> two-stages comparable corpora-based.  </section>
<citcontext>
<prevsection>
<prevsent>approach our proposed approach to bilingual terminology acquisition from comparable corpora (sadat et al,2003; <papid> P03-2025 </papid>sadat et al, 2003) <papid> P03-2025 </papid>is based on the assumption of similar collocation, i.e., if two words are mutual translations, then their most frequent collocates are likely to be mutual translations as well.</prevsent>
<prevsent>more over, we apply this assumption in both directions of the corpora, i.e., find translations of the source term in the target language corpus but also translations of the target terms in the source language corpus.the proposed two-stages approach for the acquisition, disambiguation and selection of bilingual terminology is described as follows: ? bilingual terminology acquisition from source language to target language to yield first translation model, represented by similarity simst . ? bilingual terminology acquisition from target language to source language to yield second translation model, represented by similarity simts . ? merge the first and second models to yielda two-stages translation model, based on bidirectional comparable corpora and represented by similarity simst .we follow strategies of previous researches (de jean et al, 2002; <papid> C02-1166 </papid>fung, 2000; rapp, 1999) <papid> P99-1067 </papid>for the first and second translation models and propose merging strategy for the two-stages translation model (sadat et al, 2003).<papid> P03-2025 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
first, word frequencies, context word frequencies in surrounding positions (here three-words window) are computed following statistics-based metrics, the log-likelihood ratio (dunning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>context vectors for each source term and each target termare constructed.
</nextsent>
<nextsent>next, context vectors of the target words are translated using preliminary bilingual dictionary.
</nextsent>
<nextsent>we consider all translation candidates, keeping the same context frequency value as the source term.
</nextsent>
<nextsent>this step requires seed lexicon, to expand using the proposed bootstrapping approach of this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z325">
<title id=" W03-1108.xml">learning bilingual translations from comparable corpora to cross language information retrieval hybrid statistics based and linguistics based approach </title>
<section> experiments and evaluations.  </section>
<citcontext>
<prevsection>
<prevsent>the special phonetic alphabet (herejapanese katakana) is used to write down foreign words and loan words, example names of persons and others.
</prevsent>
<prevsent>katakana terms could be treated via transliteration or possible roman ization, i.e., conversion of japanese katakana to their english equivalence or the alphabetical description of their pronunciation.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
transliteration is the phonetic or spelling representation of one language using the alphabet of another language (knight and graehl, 1998).<papid> J98-4003 </papid></citsent>
<aftsection>
<nextsent>4.3 evaluations on smart weighting.
</nextsent>
<nextsent>schemes conducted experiments and evaluations were completed on ntcir test collection using the monolin table 1: an example for the two-stages comparable corpora translation model and linguistics-based pruning two-stages comparable corpora linguistics-based pruning japanese english similarity english similarity term translation value rank translation value rank famous 0.449 1
</nextsent>
<nextsent>picture 0.361 2 picture 0.361 1 (eiga) movie 0.2163 3 movie 0.2163 2 oscar 0.1167 4 oscar 0.1167 3 film 0.1116 5 film 0.1116 4 gual english runs, i.e., english queries to retrieve english documents and the bilingual japanese english runs, i.e., japanese queries to retrieve english document.
</nextsent>
<nextsent>topics 0101 to 0149 were considered and key terms contained in the fields, title  title , description  description and concept  concept  were used to generate 49 queries in japanese and english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z326">
<title id=" W03-0908.xml">towards light semantic processing for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern question answering (qa) systems aim at providing answers to natural language questions in an open domain context.
</prevsent>
<prevsent>this task is usually achieved by combining information retrieval (ir) with information extraction (ie) techniques, modified to be applicable to unrestricted texts.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
although semantics-poor techniques, suchas surface pattern matching (soubbotin, 2002; ravichandran and hovy, 2002) <papid> P02-1006 </papid>or statistical methods (ittycheriahet al, 2002), have been successful in answering factoid questions, more complex tasks require consideration of text meaning.</citsent>
<aftsection>
<nextsent>this requirement has motivated work on qa systems to incorporate knowledge processing components such as semantic representation, ontologies, reasoning and inference engines, e.g., (moldovan et al., 2003), (hovy et al, 2002), (chu-carroll et al, 2003).
</nextsent>
<nextsent>since world knowledge databases for open-domain tasks are unavailable, alternative approaches for meaning representation must be adopted.
</nextsent>
<nextsent>in this paper, we present our preliminary approach to semantics-based answer detection in the javelin qa system (nyberg et al, 2003).
</nextsent>
<nextsent>in contrast to other qa systems, we are trying to realizea formal model for lightweight semantics-based open domain question answering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z327">
<title id=" W03-0908.xml">towards light semantic processing for question answering </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we are concerned with the two components which support linguistic analysis: the question analysis and passage understanding modules (ques tion analyzer and information extractor, respectively).the relevant aspects of syntactic processing in both modules are presented in section 3, whereas the semantic representation is introduced in section 4.
</prevsent>
<prevsent>the system employs two different parsing techniques:a chart parser with hand-written grammars for question analysis, and lexicalized, broad coverage skipping parser for passage analysis.
</prevsent>
</prevsection>
<citsent citstr=" P00-1071 ">
for question analysis, parsing serves two goals: to identify the finest answer focus(moldovan et al, 2000; <papid> P00-1071 </papid>hermjakob, 2001), <papid> W01-1203 </papid>and to produce grammatical analysis (f-structure) for questions.</citsent>
<aftsection>
<nextsent>due to the lack of publicly available parsers which have suitable coverage of question forms, we have manually developed set of grammars to achieve these goals.
</nextsent>
<nextsent>on the other hand, the limited coverage and ambiguity in these grammars made adopting the same approach for passage analysis inefficient.
</nextsent>
<nextsent>in effect, we use two distinct parsers which provide two syntactic representations,including grammatical functions.
</nextsent>
<nextsent>these syntactic structures are then transformed into common semantic representation discussed in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z328">
<title id=" W03-0908.xml">towards light semantic processing for question answering </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we are concerned with the two components which support linguistic analysis: the question analysis and passage understanding modules (ques tion analyzer and information extractor, respectively).the relevant aspects of syntactic processing in both modules are presented in section 3, whereas the semantic representation is introduced in section 4.
</prevsent>
<prevsent>the system employs two different parsing techniques:a chart parser with hand-written grammars for question analysis, and lexicalized, broad coverage skipping parser for passage analysis.
</prevsent>
</prevsection>
<citsent citstr=" W01-1203 ">
for question analysis, parsing serves two goals: to identify the finest answer focus(moldovan et al, 2000; <papid> P00-1071 </papid>hermjakob, 2001), <papid> W01-1203 </papid>and to produce grammatical analysis (f-structure) for questions.</citsent>
<aftsection>
<nextsent>due to the lack of publicly available parsers which have suitable coverage of question forms, we have manually developed set of grammars to achieve these goals.
</nextsent>
<nextsent>on the other hand, the limited coverage and ambiguity in these grammars made adopting the same approach for passage analysis inefficient.
</nextsent>
<nextsent>in effect, we use two distinct parsers which provide two syntactic representations,including grammatical functions.
</nextsent>
<nextsent>these syntactic structures are then transformed into common semantic representation discussed in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z329">
<title id=" W03-0908.xml">towards light semantic processing for question answering </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>(tokens 6))) (qa ( (gap ( (atype temporal) (path (*mult* adjunct object)))) (qtype entity))) (root found) (subject ( (bbn-name person) (brill-pos nnp) (cat n) (definite +) (gen-pn +) (human +) (number sg) (ortho  wendys ) (person third) (proper-noun +) (root wendy) (tokens 3))) (tense past) (tokens 5))figure 1: when was wendys founded: kantoo structure 3.1 questions.
</prevsent>
<prevsent>the question analysis consists of two steps: lexical processing and syntactic parsing.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
for the lexical processing step, we have integrated several external resources:the brill part-of-speech tagger (brill, 1995), <papid> J95-4004 </papid>bbn identi finder (bbn, 2000) (to tag named entities such as proper names, time expressions, numbers, etc.), wordnet (fellbaum, 1998) (for semantic categorization), and the kan too lexifier (nyberg and mitamura, 2000) (to access syntactic lexicon for verb valence information).</citsent>
<aftsection>
<nextsent>the hand-written grammars employed in the project are based on the lexical functional grammar (lfg) formalism (bresnan, 1982), and are used with the kantooparser (nyberg and mitamura, 2000).
</nextsent>
<nextsent>the parser outputs functional structure (f-structure) which specifies the grammatical functions of question components, e.g., subject, object, adjunct, etc. as illustrated in fig.
</nextsent>
<nextsent>1, the resulting f-structure provides deep, detailed syntactic analysis of the question.
</nextsent>
<nextsent>3.2 passages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z330">
<title id=" W02-2008.xml">a very very large corpus doesnt always yield reliable estimates </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P01-1005 ">
banko and brill (2001) <papid> P01-1005 </papid>suggested that the development of very large training corpora may be more effective for progress in empirical natural language processing than improving methods that use existing smaller training corpora.</citsent>
<aftsection>
<nextsent>this work tests their claim by exploring whether very large corpus can eliminate the sparseness problems associated with estimating unigram probabilities.
</nextsent>
<nextsent>we do this by empirically investigating the convergence behaviour of unigram probability estimates on one billion word corpus.
</nextsent>
<nextsent>when using one billion words, as expected, we do find that many of our estimates do converge to their eventual value.
</nextsent>
<nextsent>however, we also find that for some words,no such convergence occurs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z339">
<title id=" W02-2008.xml">a very very large corpus doesnt always yield reliable estimates </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their experiments show logarithmic trend in performance as corpus size increases without performance reaching an upper bound.
</prevsent>
<prevsent>this leads them to believe that the development of large scale training material will yield superior results than further experimentation with machine learning methods on existing smaller scale training corpora.
</prevsent>
</prevsection>
<citsent citstr=" P02-1030 ">
recent work has replicated the banko and brill (2001) <papid> P01-1005 </papid>results on the much more complex task of automatic thesaurus extraction, showing that contextual statistics, collected over very large corpus, significantly improve system performance (curran and moens, 2002).<papid> P02-1030 </papid></citsent>
<aftsection>
<nextsent>other research has shown that query statistics from web search engine can be used as substitute for counts collected from large corpora (volk, 2001; keller et al, 2002).<papid> W02-1030 </papid></nextsent>
<nextsent>to further investigate the benefits of using very large corpora we empirically analyse the convergence behaviour of unigram probability estimates for range of words with different relative frequen cies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z340">
<title id=" W02-2008.xml">a very very large corpus doesnt always yield reliable estimates </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this leads them to believe that the development of large scale training material will yield superior results than further experimentation with machine learning methods on existing smaller scale training corpora.
</prevsent>
<prevsent>recent work has replicated the banko and brill (2001) <papid> P01-1005 </papid>results on the much more complex task of automatic thesaurus extraction, showing that contextual statistics, collected over very large corpus, significantly improve system performance (curran and moens, 2002).<papid> P02-1030 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1030 ">
other research has shown that query statistics from web search engine can be used as substitute for counts collected from large corpora (volk, 2001; keller et al, 2002).<papid> W02-1030 </papid></citsent>
<aftsection>
<nextsent>to further investigate the benefits of using very large corpora we empirically analyse the convergence behaviour of unigram probability estimates for range of words with different relative frequencies.
</nextsent>
<nextsent>by dramatically increasing the size of the training corpus, we expect our confidence in the probability estimates for each word to increase.
</nextsent>
<nextsent>as theory predicts, unigram probability estimates for many words do converge as corpus size grows.
</nextsent>
<nextsent>however, contrary to intuition, we found that formany commonplace words, for example tightness, there was no sign of convergence as corpus size approaches one billion words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z341">
<title id=" W02-2008.xml">a very very large corpus doesnt always yield reliable estimates </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>previously unseen linguistic events are frequently presented to nlp systems.
</prevsent>
<prevsent>to handle these unseen events the statistical models used by the system must be smoothed.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
smoothing typically adds considerable computational complexity to the system since multiple models need to be estimated and applied together, and it is often considered black art (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>having access to very large corpora ought to reduce the need for smoothing, and so ought to allow us to design simpler systems.
</nextsent>
<nextsent>the difficulty of obtaining reliable probability estimates is central to many nlp tasks.
</nextsent>
<nextsent>can we improve the performance of these systems by simply using lot more data?
</nextsent>
<nextsent>as might be expected, for many words, estimating probabilities on very large corpus can be valuable, improving system performance significantly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z342">
<title id=" W02-2008.xml">a very very large corpus doesnt always yield reliable estimates </title>
<section> further work.  </section>
<citcontext>
<prevsection>
<prevsent>an example of this is calculating the area between unity andthe ratio curves.
</prevsent>
<prevsent>some example words with different convergence behaviour selected using this area measure are given in table 2 in the appendix.
</prevsent>
</prevsection>
<citsent citstr=" P97-1048 ">
weare also interested in applying the exponential models of lexical attraction and repulsion described by beeferman et al (1997) <papid> P97-1048 </papid>to the very large corpus.</citsent>
<aftsection>
<nextsent>we would like to investigate the overall error in the probability mass distribution by comparing the whole distributions at each sample with the final distribution.
</nextsent>
<nextsent>to estimate the error properly will require smoothing methods to be taken into consideration.
</nextsent>
<nextsent>acknowledgements we would like to thank marc moens, steve finch, tara murphy, yuval krymolowski and the many anonymous reviewers for their insightful comments that have contributed significantly to this paper.this research is partly supported by commonwealth scholarship and sydney university travelling scholarship.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z343">
<title id=" W03-1611.xml">paraphrasing japanese noun phrases using character based indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the effectiveness of phrasal indexing has recently drawn researchers?
</prevsent>
<prevsent>attention (lewis, 1992; mitra et al, 1997; tokunaga et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P97-1004 ">
however, query expansion of phrasal index terms has not been fully investigated yet (jacquemin et al, 1997).<papid> P97-1004 </papid>to deal with variations of linguistic expressions, paraphrasing has recently been studied for various applications of natural language processing, such as machine translation (mitamura, 2001; shimohata and sumita,2002), dialog systems (ebert et al, 2001), <papid> W01-1608 </papid>qa systems (katz, 1997) and information extraction (shinyama et al, 2002).</citsent>
<aftsection>
<nextsent>paraphrasing is defined as process of transforming an expression into another while keeping its meaning intact.
</nextsent>
<nextsent>however, it is difficult to define what keeping its meaning intact?
</nextsent>
<nextsent>means, although it is the core of the definition.
</nextsent>
<nextsent>on what basis could we consider different linguistic expressions denoting the same meaning?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z344">
<title id=" W03-1611.xml">paraphrasing japanese noun phrases using character based indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the effectiveness of phrasal indexing has recently drawn researchers?
</prevsent>
<prevsent>attention (lewis, 1992; mitra et al, 1997; tokunaga et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W01-1608 ">
however, query expansion of phrasal index terms has not been fully investigated yet (jacquemin et al, 1997).<papid> P97-1004 </papid>to deal with variations of linguistic expressions, paraphrasing has recently been studied for various applications of natural language processing, such as machine translation (mitamura, 2001; shimohata and sumita,2002), dialog systems (ebert et al, 2001), <papid> W01-1608 </papid>qa systems (katz, 1997) and information extraction (shinyama et al, 2002).</citsent>
<aftsection>
<nextsent>paraphrasing is defined as process of transforming an expression into another while keeping its meaning intact.
</nextsent>
<nextsent>however, it is difficult to define what keeping its meaning intact?
</nextsent>
<nextsent>means, although it is the core of the definition.
</nextsent>
<nextsent>on what basis could we consider different linguistic expressions denoting the same meaning?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z345">
<title id=" W03-1611.xml">paraphrasing japanese noun phrases using character based indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in past research, various types of clues have been used to find paraphrases.
</prevsent>
<prevsent>for example, shinyama et al tried to find paraphrases assuming that two sentences sharing many named entities and similar structure are likely to be paraphrases of each other (shinyama et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
barzilay and mckeown assume that two translations from the same original text contain paraphrases (barzilay and mckeown, 2001).<papid> P01-1008 </papid></citsent>
<aftsection>
<nextsent>torisawa used subcategorization information of verbs to paraphrase japanese noun phrase construction np1 no np2?
</nextsent>
<nextsent>into noun phrase with relative clause (torisawa, 2001).
</nextsent>
<nextsent>most of previous work on paraphrasing took corpus-based approach with notable exceptions of jacquemin (jacquemin et al,1997; <papid> P97-1004 </papid>jacquemin, 1999) <papid> P99-1044 </papid>and katz (katz, 1997).</nextsent>
<nextsent>in particular, text alignment technique is generally used to find sentence level paraphrases (shimohata and sumita, 2002; barzilay and lee, 2002).<papid> W02-1022 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z347">
<title id=" W03-1611.xml">paraphrasing japanese noun phrases using character based indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>torisawa used subcategorization information of verbs to paraphrase japanese noun phrase construction np1 no np2?
</prevsent>
<prevsent>into noun phrase with relative clause (torisawa, 2001).
</prevsent>
</prevsection>
<citsent citstr=" P99-1044 ">
most of previous work on paraphrasing took corpus-based approach with notable exceptions of jacquemin (jacquemin et al,1997; <papid> P97-1004 </papid>jacquemin, 1999) <papid> P99-1044 </papid>and katz (katz, 1997).</citsent>
<aftsection>
<nextsent>in particular, text alignment technique is generally used to find sentence level paraphrases (shimohata and sumita, 2002; barzilay and lee, 2002).<papid> W02-1022 </papid></nextsent>
<nextsent>in this paper, we follow the corpus-based approach and propose method to find paraphrases of japanese noun phrase in large corpus using information retrieval techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z348">
<title id=" W03-1611.xml">paraphrasing japanese noun phrases using character based indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>into noun phrase with relative clause (torisawa, 2001).
</prevsent>
<prevsent>most of previous work on paraphrasing took corpus-based approach with notable exceptions of jacquemin (jacquemin et al,1997; <papid> P97-1004 </papid>jacquemin, 1999) <papid> P99-1044 </papid>and katz (katz, 1997).</prevsent>
</prevsection>
<citsent citstr=" W02-1022 ">
in particular, text alignment technique is generally used to find sentence level paraphrases (shimohata and sumita, 2002; barzilay and lee, 2002).<papid> W02-1022 </papid></citsent>
<aftsection>
<nextsent>in this paper, we follow the corpus-based approach and propose method to find paraphrases of japanese noun phrase in large corpus using information retrieval techniques.
</nextsent>
<nextsent>the significant feature of our method is use of character-based indexing.
</nextsent>
<nextsent>japanese uses four types of writing; kanzi (chinese characters), hiragana, katakana, and roman alphabet.
</nextsent>
<nextsent>among these, hiraganaand katakana are phonographic, and kanzi is an ideo graphic writing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z350">
<title id=" W03-1611.xml">paraphrasing japanese noun phrases using character based indexing </title>
<section> ranking.  </section>
<citcontext>
<prevsection>
<prevsent>however, even though kanzi denotes certain meaning, its meaning is often ambiguous.
</prevsent>
<prevsent>this problem is similar to word sense ambiguities, which have been studied for many years.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
tosolve this problem, we adopt an idea one sense per collocation which was introduced in word sense disambiguation research (yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>considering newspaper article in which the retrieved passage and the input noun phrase is included as the context, the context similarity is taken into account for ranking paraphrase candidates.
</nextsent>
<nextsent>more concretely, context similarity is calculated by following procedure.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>for each paraphrase candidate, context vector is. constructed from the newspaper article containing the passage from which the candidate is derived.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z351">
<title id=" W02-1003.xml">an incremental decision list learner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show variation that adds thresholding to the standard sorting algorithm for decision lists, leading to similar improvements.
</prevsent>
<prevsent>experimental results show that the new algorithm produces substantially lower error rates and entropy, while simultaneously learning lists that are over an order of magnitude smaller than those produced by the standard algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
decision lists (rivest, 1987) have been used for variety of natural language tasks, including accent restoration (yarowsky, 1994), <papid> P94-1013 </papid>word sense disambiguation (yarowsky, 2000), finding the past tense of english verbs (mooney and califf, 1995), and several other problems.</citsent>
<aftsection>
<nextsent>we show problem with the standard algorithm for learning probabilistic decision lists, and we introduce an incremental algorithm that consistently works better.
</nextsent>
<nextsent>while the obvious implementation for this algorithm would be very slow, we also show how to efficiently implement it.
</nextsent>
<nextsent>thenew algorithm produces smaller lists, while simultaneously substantially reducing entropy (by about 40%), and error rates (by about 25% relative.)
</nextsent>
<nextsent>decision lists are very simple, easy to understand formalism.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z354">
<title id=" W02-1003.xml">an incremental decision list learner </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>when the value of  is ??, all rules are included (the standard algorithm).
</prevsent>
<prevsent>even when benefit is predicted, this may be due to overfitting; we can get further improvements by setting the threshold to higher value, such as 3, which means that only rules that save at least three bits ? and thus are unlikely to lead to over fitting ? are added.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
there has been modest amount of previous work on improving probabilistic decision lists, as well as fair amount of work in related fields, especially in transformation-based learning (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>first, we note that non-probabilistic decision list sand transformation-based learning (tbl) are actually very similar formalisms.
</nextsent>
<nextsent>in particular, as observed by roth (1998), in the two-class case, they are identical.
</nextsent>
<nextsent>non-probabilistic decision lists learn rules of the form if i then output y?
</nextsent>
<nextsent>while tbls output rules of the form if i and current-class is ? , change class to y?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z356">
<title id=" W02-1003.xml">an incremental decision list learner </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the near equivalence of tbls and decision lists is important for two reasons.
</prevsent>
<prevsent>first, it shows the connection between our work and previous work.
</prevsent>
</prevsection>
<citsent citstr=" W94-0111 ">
in particular, our new algorithm can be thought of as probabilistic version of the ramshaw and marcus (1994)<papid> W94-0111 </papid>algorithm, for speeding up tbls.</citsent>
<aftsection>
<nextsent>just as that algorithm stores the expected error rate improvement of each question, our algorithm stores the expected entropy improvement.
</nextsent>
<nextsent>(actually, the ramshaw and marcus algorithm is somewhat more complex, be cause it is able to deal with dynamic problems suchas part-of-speech tagging.)
</nextsent>
<nextsent>similarly, the space efficient algorithm using compound questions at the end of section 2.2.1 can be thought of as static probabilistic version of the efficient tbl of ngai and florian (2001).<papid> N01-1006 </papid></nextsent>
<nextsent>the second reason that the connection to tbls is important is that it shows us that probabilistic decision lists are natural way to probabilize tbls.florian et al (2000) <papid> W00-1304 </papid>showed one way to make probabilistic versions of tbls, but the technique is somewhat complicated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z357">
<title id=" W02-1003.xml">an incremental decision list learner </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>just as that algorithm stores the expected error rate improvement of each question, our algorithm stores the expected entropy improvement.
</prevsent>
<prevsent>(actually, the ramshaw and marcus algorithm is somewhat more complex, be cause it is able to deal with dynamic problems suchas part-of-speech tagging.)
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
similarly, the space efficient algorithm using compound questions at the end of section 2.2.1 can be thought of as static probabilistic version of the efficient tbl of ngai and florian (2001).<papid> N01-1006 </papid></citsent>
<aftsection>
<nextsent>the second reason that the connection to tbls is important is that it shows us that probabilistic decision lists are natural way to probabilize tbls.florian et al (2000) <papid> W00-1304 </papid>showed one way to make probabilistic versions of tbls, but the technique is somewhat complicated.</nextsent>
<nextsent>it involved conversion to decision tree, and then further growing of the tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z358">
<title id=" W02-1003.xml">an incremental decision list learner </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(actually, the ramshaw and marcus algorithm is somewhat more complex, be cause it is able to deal with dynamic problems suchas part-of-speech tagging.)
</prevsent>
<prevsent>similarly, the space efficient algorithm using compound questions at the end of section 2.2.1 can be thought of as static probabilistic version of the efficient tbl of ngai and florian (2001).<papid> N01-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-1304 ">
the second reason that the connection to tbls is important is that it shows us that probabilistic decision lists are natural way to probabilize tbls.florian et al (2000) <papid> W00-1304 </papid>showed one way to make probabilistic versions of tbls, but the technique is somewhat complicated.</citsent>
<aftsection>
<nextsent>it involved conversion to decision tree, and then further growing of the tree.
</nextsent>
<nextsent>their technique does have the advantage that it correctly handles the multi-class case.
</nextsent>
<nextsent>that is, by using decision tree, it is relatively easy to incorporate the current state, while the decision list learner ignores that state.
</nextsent>
<nextsent>however, this is not clearly an advantage?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z363">
<title id=" W02-1003.xml">an incremental decision list learner </title>
<section> experimental results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>accent restoration (yarowsky, 1994), <papid> P94-1013 </papid>word sense disambiguation (yarowsky, 2000), and other problems all fall into this framework, and typically use similar feature types.</prevsent>
<prevsent>we thus chose one problem of this type, grammar checking, and believe that our results should carry over at leastto these other, closely related problems.</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
in particular, we chose to use exactly the same training, test, problems, and feature sets used by banko and brill(2001<papid> P01-1005 </papid>a), banko and brill(2001<papid> P01-1005 </papid>b).</citsent>
<aftsection>
<nextsent>these problems consisted of trying to guess which of two conf usable words, e.g. their?
</nextsent>
<nextsent>or there?, user intended.
</nextsent>
<nextsent>banko and brill chose this data to be representative of typical machine learning problems, and, by trying it across data sizes and different pairs of words, it exhibits good deal of different behaviors.
</nextsent>
<nextsent>banko and brill used standard set of features, including words within window of 2, part-of-speech tags within window of 2, pairs of word or tag features, and whether or not given word occurred within window of 9.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z370">
<title id=" W03-1705.xml">a bottom up merging algorithm for chinese unknown word extraction </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, occurrences of unknown words, which do not listed in the dictionary, degraded significantly the performances of most word segmentation methods, so unknown word extraction became key technology for chinese segmentation.
</prevsent>
<prevsent>for unknown words with more regular morphological structures, such as personal names, morphological rules are commonly used for improving the performance by restricting the structures of extracted words (chen et. al 1994, sun et. al 1994, lin et. al 1994).
</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
however, it not possible to list morphological rules for all kinds of unknown words, especially those words with very irregular structures, which have the characteristics of variable lengths and flexible morphological structures, such as proper names, abbreviations etc. therefore, statistical approaches usually play major roles on irregular unknown word extraction in most previous work (sproat &amp; shih 1990, chiang et. al 1992, tung and lee 1995, palmer 1997, <papid> P97-1041 </papid>chang et. al 1997, sun et. al 1998, <papid> P98-2206 </papid>ge et. al 1999).</citsent>
<aftsection>
<nextsent>for statistical methods, an important issue is how to resolve competing ambiguous extractions which might include erroneous extractions of phrases or partial phrases.
</nextsent>
<nextsent>they might have statistical significance in corpus as well.
</nextsent>
<nextsent>very frequently superfluous character strings with strong statistic associations are extracted.
</nextsent>
<nextsent>these wrong results are usually hard to be filtered out unless deep content and context analyses were performed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z371">
<title id=" W03-1705.xml">a bottom up merging algorithm for chinese unknown word extraction </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, occurrences of unknown words, which do not listed in the dictionary, degraded significantly the performances of most word segmentation methods, so unknown word extraction became key technology for chinese segmentation.
</prevsent>
<prevsent>for unknown words with more regular morphological structures, such as personal names, morphological rules are commonly used for improving the performance by restricting the structures of extracted words (chen et. al 1994, sun et. al 1994, lin et. al 1994).
</prevsent>
</prevsection>
<citsent citstr=" P98-2206 ">
however, it not possible to list morphological rules for all kinds of unknown words, especially those words with very irregular structures, which have the characteristics of variable lengths and flexible morphological structures, such as proper names, abbreviations etc. therefore, statistical approaches usually play major roles on irregular unknown word extraction in most previous work (sproat &amp; shih 1990, chiang et. al 1992, tung and lee 1995, palmer 1997, <papid> P97-1041 </papid>chang et. al 1997, sun et. al 1998, <papid> P98-2206 </papid>ge et. al 1999).</citsent>
<aftsection>
<nextsent>for statistical methods, an important issue is how to resolve competing ambiguous extractions which might include erroneous extractions of phrases or partial phrases.
</nextsent>
<nextsent>they might have statistical significance in corpus as well.
</nextsent>
<nextsent>very frequently superfluous character strings with strong statistic associations are extracted.
</nextsent>
<nextsent>these wrong results are usually hard to be filtered out unless deep content and context analyses were performed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z372">
<title id=" W03-1705.xml">a bottom up merging algorithm for chinese unknown word extraction </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>lin et al (1993) adopt the following strategy: first, they decide whether there is any unknown word within detected region with fix size in sentence, and then they extract the unknown word from the region by statistical method if the previous answer is  yes .
</prevsent>
<prevsent>a limitation of this method is that it restricts at most one unknown word occurs in the detected region, so that it could not deal with occurrences of consecutive unknown words within sentence.
</prevsent>
</prevsection>
<citsent citstr=" C02-1049 ">
chen &amp; ma (2002) <papid> C02-1049 </papid>adopt another strategy: after an initial segmentation process, each mono syllable is decided whether it is common word or morpheme of unknown word by set of syntactic discriminators.</citsent>
<aftsection>
<nextsent>the syntactic discriminators are set of syntactic patterns containing monosyllabic, words which are learned from large word segmented corpus, to discriminate between monosyllabic words and morphemes of unknown words.
</nextsent>
<nextsent>then more deep analysis can be carried out at the detected unknown word morphemes to extract unknown words.
</nextsent>
<nextsent>in this paper, in order to avoid extractions of superfluous character strings with high frequencies, we proposed to use set of general rules, which is formulated as context free grammar rules of composing detected morphemes and their adjacent tokens, to match all kinds of unknown words, for instance which includes the rule of (uw
</nextsent>
<nextsent>uw uw).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z373">
<title id=" W03-1705.xml">a bottom up merging algorithm for chinese unknown word extraction </title>
<section> rules for unknown words.  </section>
<citcontext>
<prevsection>
<prevsent>the constraints we applied include word length, linguistic and statistical constraints.
</prevsent>
<prevsent>for statistical constraints, since the target of our system is to extract unknown words from text, we use text based statistical measure as the statistical constraint.
</prevsent>
</prevsection>
<citsent citstr=" C00-1027 ">
it is well known that keywords often reoccur in document (church 2000) <papid> C00-1027 </papid>and very possible the keywords are also unknown words.</citsent>
<aftsection>
<nextsent>therefore the reoccurrence frequency within document is adopted as the constraint.
</nextsent>
<nextsent>another useful statistical phenomenon in document is that polysyllabic morpheme is very unlikely to be the morphemes of two different unknown words within the same text.
</nextsent>
<nextsent>hence we restrict the rule with polysyllabic symbols by evaluating the conditional probability of polysyllabic symbols.
</nextsent>
<nextsent>in addition, syntactic constraints are also utilized here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z374">
<title id=" W03-1705.xml">a bottom up merging algorithm for chinese unknown word extraction </title>
<section> rules for unknown words.  </section>
<citcontext>
<prevsection>
<prevsent>we regard the possibility of rule application as co-occurrence and association strength of its right hand side symbols within text.
</prevsent>
<prevsent>in other words, rule has higher priority of application while its right-hand side symbols are strongly associated with each other, or co-occur frequently in the same text.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
there have been many statistical measures which estimate co-occurrence and the degree of association in previous researches, such as mutual information (church 1990, sporat 1990), t-score (church 1991), dice matrix (smadja 1993, <papid> J93-1007 </papid>1996).</citsent>
<aftsection>
<nextsent>here, we adopt four well-developed kinds of statistical measures as our priority individually: mutual information (mi), variant of mutual information (vmi), t-score, and co-occurrence.
</nextsent>
<nextsent>the formulas are listed in table 4.
</nextsent>
<nextsent>mi mainly focuses on association strength, and vmi and score consider both co-occurrence and association strength.
</nextsent>
<nextsent>the performances of these four measures are evaluated in our experiments discussed in section 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z376">
<title id=" W03-0306.xml">word alignment baselines </title>
<section> alignment as binary classification.  </section>
<citcontext>
<prevsection>
<prevsent>however, the assumption made in this approach is that the alignments are independent and identically distributed (iid).
</prevsent>
<prevsent>this is false, but the same assumption is made by the alignment evaluation metrics.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
this approach also introduces difficulty in incorporating knowledge of adjacency of aligned pairs, and hmm approaches to word alignment show that this knowledge is important (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>all of the techniques presented in this work approach the problem as binary classification task.
</nextsent>
<nextsent>2.1 random baseline.
</nextsent>
<nextsent>a randomized baseline was created which flips coin tomark alignments.
</nextsent>
<nextsent>the bias of the coin is chosen to maximize the f-measure on the trial dataset, and the resulting performance gives insight into the inherent difficulty ofthe task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z378">
<title id=" W03-0306.xml">word alignment baselines </title>
<section> unsupervised methods.  </section>
<citcontext>
<prevsection>
<prevsent>10) 8.80 16.98 11.59 88.41 13.65 10.26 11.71 81.54 bos (eq.
</prevsent>
<prevsent>11) 20.42 20.07 20.24 79.76 35.32 10.65 16.37 59.82 bnnrule 84.88 25.04 38.68 61.32 86.55 8.30 15.14 45.38 nnrule 65.89 63.29 64.57 35.43 35.89 35.43 35.66 58.50 table 1: trial set results.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
tences (gale and church, 1991; brown et al, 1991).<papid> P91-1022 </papid></citsent>
<aftsection>
<nextsent>the observation can be codified as distance between the word at position on the lhs and the word at position on the rhs dlen(i, j) = 1 ? 4 ? l(li) ? l(rj) (l(li) + l(rj))2 (1) where l(li) is the length of the token at position on the lhs.
</nextsent>
<nextsent>note that dlen is similar to normalized harmonic mean, ranging from 0 to 1.0, with the minimum achieved when the lengths are the same.
</nextsent>
<nextsent>a threshold on dlen is used to turn this distance metric into classification rule.
</nextsent>
<nextsent>3.3 edit distances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z379">
<title id=" W03-0306.xml">word alignment baselines </title>
<section> unsupervised methods.  </section>
<citcontext>
<prevsection>
<prevsent>it can be interpreted as an edit distance rate, edits per character: dwedit(i, j) = edits(li, rj) l(li) + l(rj) (2) dlcedit is the same as dwedit, except both arguments are lower-cased prior to the edit distance calculation.
</prevsent>
<prevsent>3.4 dotplot geometry.
</prevsent>
</prevsection>
<citsent citstr=" W96-0201 ">
geometric approaches to bilingual alignment have been used with great success in both finding anchor points and aligning sentences (fung and mckeown, 1994; melamed, 1996).<papid> W96-0201 </papid></citsent>
<aftsection>
<nextsent>three distance metrics were created to incorporate the knowledge that all of the aligned pairs use roughly the same word order.
</nextsent>
<nextsent>in every case, the distance of the pair of words from diagonal in the dotplot was used.
</nextsent>
<nextsent>in the metrics below, the l1 norm distance from point (i, j) to line from (0), line from (0) to (i, j) is dl1(i, i, j, j) = ? ?
</nextsent>
<nextsent>i ? j ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z382">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in broad range of natural language applications, from research supported by nsf grants iis-99-84168, itr-iis-00-85836 and an onr muri award.
</prevsent>
<prevsent>names of authors are listed alphabetically.
</prevsent>
</prevsection>
<citsent citstr=" P00-1014 ">
prepositional phrase attachment (pantel and lin, 2000; <papid> P00-1014 </papid>stetina and nagao, 1997), <papid> W97-0109 </papid>co-reference resolution (ng and cardie, 2002) <papid> P02-1014 </papid>to text summarization (saggion and lapalme, 2002), <papid> J02-4005 </papid>semantic information is necessary component in the inference, by providing level of abstraction that is necessary for robust decisions.</citsent>
<aftsection>
<nextsent>inducing that the prepositional phrase in they ate cake with fork?
</nextsent>
<nextsent>has the same grammatical function as that in they ate cake with spoon?, for example, depends on the knowledge that cutlery?
</nextsent>
<nextsent>and tableware?
</nextsent>
<nextsent>are the hypernyms of both fork?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z383">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in broad range of natural language applications, from research supported by nsf grants iis-99-84168, itr-iis-00-85836 and an onr muri award.
</prevsent>
<prevsent>names of authors are listed alphabetically.
</prevsent>
</prevsection>
<citsent citstr=" W97-0109 ">
prepositional phrase attachment (pantel and lin, 2000; <papid> P00-1014 </papid>stetina and nagao, 1997), <papid> W97-0109 </papid>co-reference resolution (ng and cardie, 2002) <papid> P02-1014 </papid>to text summarization (saggion and lapalme, 2002), <papid> J02-4005 </papid>semantic information is necessary component in the inference, by providing level of abstraction that is necessary for robust decisions.</citsent>
<aftsection>
<nextsent>inducing that the prepositional phrase in they ate cake with fork?
</nextsent>
<nextsent>has the same grammatical function as that in they ate cake with spoon?, for example, depends on the knowledge that cutlery?
</nextsent>
<nextsent>and tableware?
</nextsent>
<nextsent>are the hypernyms of both fork?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z384">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in broad range of natural language applications, from research supported by nsf grants iis-99-84168, itr-iis-00-85836 and an onr muri award.
</prevsent>
<prevsent>names of authors are listed alphabetically.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
prepositional phrase attachment (pantel and lin, 2000; <papid> P00-1014 </papid>stetina and nagao, 1997), <papid> W97-0109 </papid>co-reference resolution (ng and cardie, 2002) <papid> P02-1014 </papid>to text summarization (saggion and lapalme, 2002), <papid> J02-4005 </papid>semantic information is necessary component in the inference, by providing level of abstraction that is necessary for robust decisions.</citsent>
<aftsection>
<nextsent>inducing that the prepositional phrase in they ate cake with fork?
</nextsent>
<nextsent>has the same grammatical function as that in they ate cake with spoon?, for example, depends on the knowledge that cutlery?
</nextsent>
<nextsent>and tableware?
</nextsent>
<nextsent>are the hypernyms of both fork?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z385">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in broad range of natural language applications, from research supported by nsf grants iis-99-84168, itr-iis-00-85836 and an onr muri award.
</prevsent>
<prevsent>names of authors are listed alphabetically.
</prevsent>
</prevsection>
<citsent citstr=" J02-4005 ">
prepositional phrase attachment (pantel and lin, 2000; <papid> P00-1014 </papid>stetina and nagao, 1997), <papid> W97-0109 </papid>co-reference resolution (ng and cardie, 2002) <papid> P02-1014 </papid>to text summarization (saggion and lapalme, 2002), <papid> J02-4005 </papid>semantic information is necessary component in the inference, by providing level of abstraction that is necessary for robust decisions.</citsent>
<aftsection>
<nextsent>inducing that the prepositional phrase in they ate cake with fork?
</nextsent>
<nextsent>has the same grammatical function as that in they ate cake with spoon?, for example, depends on the knowledge that cutlery?
</nextsent>
<nextsent>and tableware?
</nextsent>
<nextsent>are the hypernyms of both fork?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z386">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stand-alone words may have several meanings and take on relations (e.g., hypernyms, hyponyms) that depend on their meanings.
</prevsent>
<prevsent>consequently,there are very few success stories of automatically using wordnet in natural language applications.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
in many cases, reported (and unreported) problems are due to thefact that wordnet enumerates all the senses of polyse mous words; attempts to use this resource automatically often result in noisy and non-uniform information (brill and resnik, 1994; <papid> C94-2195 </papid>krymolowski and roth, 1998).<papid> W98-0717 </papid></citsent>
<aftsection>
<nextsent>phrase net is designed based on the assumption that, by and large, semantic ambiguity in english disappears when local context of words is taken into account.
</nextsent>
<nextsent>it makes use of wordnet as an important knowledge source and is generated automatically using wordnet and machine learning based processing of large english corpora.it enhances wordnet synset with its contextual information and refines its relational structure, including relations such as hypernym, hyponym, antonym and synonym, by maintaining only those links that respect contextual constraints.
</nextsent>
<nextsent>however, phrase net is not just functional extension of wordnet.
</nextsent>
<nextsent>it is an independent lexical semantic system allied with proper user interfaces and access functions that will allow researchers and practitioners to use it in applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z387">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stand-alone words may have several meanings and take on relations (e.g., hypernyms, hyponyms) that depend on their meanings.
</prevsent>
<prevsent>consequently,there are very few success stories of automatically using wordnet in natural language applications.
</prevsent>
</prevsection>
<citsent citstr=" W98-0717 ">
in many cases, reported (and unreported) problems are due to thefact that wordnet enumerates all the senses of polyse mous words; attempts to use this resource automatically often result in noisy and non-uniform information (brill and resnik, 1994; <papid> C94-2195 </papid>krymolowski and roth, 1998).<papid> W98-0717 </papid></citsent>
<aftsection>
<nextsent>phrase net is designed based on the assumption that, by and large, semantic ambiguity in english disappears when local context of words is taken into account.
</nextsent>
<nextsent>it makes use of wordnet as an important knowledge source and is generated automatically using wordnet and machine learning based processing of large english corpora.it enhances wordnet synset with its contextual information and refines its relational structure, including relations such as hypernym, hyponym, antonym and synonym, by maintaining only those links that respect contextual constraints.
</nextsent>
<nextsent>however, phrase net is not just functional extension of wordnet.
</nextsent>
<nextsent>it is an independent lexical semantic system allied with proper user interfaces and access functions that will allow researchers and practitioners to use it in applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z388">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> the design of phrase net.  </section>
<citcontext>
<prevsection>
<prevsent>context is one important notion in phrasenet.
</prevsent>
<prevsent>while the context may mean different things in natural language,many previous work in statistically natural language processing defined context?
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
as an n-word window around the target word (gale et al , 1992; brown et al , 1991; <papid> P91-1034 </papid>roth, 1998).</citsent>
<aftsection>
<nextsent>in phrase net, context?
</nextsent>
<nextsent>has more precise definition that depends on the grammatical structure of sentence rather than simply counting surrounding words.
</nextsent>
<nextsent>we define context?
</nextsent>
<nextsent>to be the syntactic structure of the sentence in which the word of interest occurs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z389">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> the design of phrase net.  </section>
<citcontext>
<prevsection>
<prevsent>similarly to pn rl this function is implemented by appealing to wordnet senses and pruning the possible sense based on the word list determined for the given context.
</prevsent>
<prevsent>pn st is not implemented at this point, but is designed to output sentence that has same structure as the input context, but use different words.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
it is inspired by the work on reformulation, e.g., (barzilay and mckeown, 2001).<papid> P01-1008 </papid></citsent>
<aftsection>
<nextsent>we can envision many ways users of phrase net can make use of the retrieved information.
</nextsent>
<nextsent>at this point in the life of phrase net we focus mostly on using phrase net as way to acquire semantic features to aid learning based natural language applications.
</nextsent>
<nextsent>this determines our priorities in the implementation that we describe next.
</nextsent>
<nextsent>constructing phrase net involves three main stages: (1)extracting syntactic skeletons from corpora, (2) constructing the core element in phrasenet: consets, and (3) developing access functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z390">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> evaluation and application.  </section>
<citcontext>
<prevsection>
<prevsent>for example, given the question: what cuban dictator did fidel castro force out of power in 1958??
</prevsent>
<prevsent>we would like to determine that its answer should be name of person.
</prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
our approach to qc follows that of (li and roth, 2002).<papid> C02-1150 </papid></citsent>
<aftsection>
<nextsent>the question classifier used is multi-class classifier which can classify question into one of 50 fine-grained classes.
</nextsent>
<nextsent>the baseline classifier makes use of syntactic features like the standard pos information and information extracted by shallow parser in addition to the words inthe sentence.
</nextsent>
<nextsent>the classifier is then augmented with standard wordnet or with phrase net information as follows.
</nextsent>
<nextsent>in all cases, words in the sentence are augmented with additional words that are supposed to be semantically related to them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z391">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we point to some of the related workon syntax, semantics interaction and lexical semantic resources in computational linguistics and natural language processing.
</prevsent>
<prevsent>many current syntactic theories make the common assumption that various aspects of syntactic alternation are predicable via the meaning of the predicate in the sentence (fillmore, 1968; jackendoff, 1990;levin, 1993).
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
with the resurgence of lexical semantics and corpus linguistics during the past two decades, this so-called linking regularity triggers broad interest of using syntactic representations illustrated in corpora to classify lexical meaning (baker et al , 1998; <papid> P98-1013 </papid>levin, 1993; dorr and jones, 1996; lapata and brew, 1999; <papid> W99-0632 </papid>lin, 1998b; pantel and lin, 2002).framenet (baker et al , 1998) <papid> P98-1013 </papid>produces semantic dictionary that documents combinatorial properties of english lexical items in semantic and syntactic terms based on attestations in very large corpus.</citsent>
<aftsection>
<nextsent>in framenet, frame is an intuitive structure that formalizes the links between semantics and syntax in the results of lexicalanalysis.
</nextsent>
<nextsent>(fillmore et al , 2001) however, instead of derived via attested sentences from corpora automatically,each conceptual frame together with all its frame elements has to be constructed via slow and labor-intensive manual work.
</nextsent>
<nextsent>framenet is not constructed automatically based on observed syntactic alternations.
</nextsent>
<nextsent>though deep semantic analysis is built for each frame, lack of automatic derivation of the semantic roles from large corpora3 confines the usage of this network drastically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z392">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this section we point to some of the related workon syntax, semantics interaction and lexical semantic resources in computational linguistics and natural language processing.
</prevsent>
<prevsent>many current syntactic theories make the common assumption that various aspects of syntactic alternation are predicable via the meaning of the predicate in the sentence (fillmore, 1968; jackendoff, 1990;levin, 1993).
</prevsent>
</prevsection>
<citsent citstr=" W99-0632 ">
with the resurgence of lexical semantics and corpus linguistics during the past two decades, this so-called linking regularity triggers broad interest of using syntactic representations illustrated in corpora to classify lexical meaning (baker et al , 1998; <papid> P98-1013 </papid>levin, 1993; dorr and jones, 1996; lapata and brew, 1999; <papid> W99-0632 </papid>lin, 1998b; pantel and lin, 2002).framenet (baker et al , 1998) <papid> P98-1013 </papid>produces semantic dictionary that documents combinatorial properties of english lexical items in semantic and syntactic terms based on attestations in very large corpus.</citsent>
<aftsection>
<nextsent>in framenet, frame is an intuitive structure that formalizes the links between semantics and syntax in the results of lexicalanalysis.
</nextsent>
<nextsent>(fillmore et al , 2001) however, instead of derived via attested sentences from corpora automatically,each conceptual frame together with all its frame elements has to be constructed via slow and labor-intensive manual work.
</nextsent>
<nextsent>framenet is not constructed automatically based on observed syntactic alternations.
</nextsent>
<nextsent>though deep semantic analysis is built for each frame, lack of automatic derivation of the semantic roles from large corpora3 confines the usage of this network drastically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z395">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while no evaluation has ever been done to determine if concrete word tokens are necessary when the syntactic phrase types are already presented, lins work indirectly shows that the concrete lexical representation is effective.
</prevsent>
<prevsent>wordnet (fellbaum, 1998) by far is the most widely used semantic database.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
however, this database does not 3the attempt to label these semantic roles automatically in (gildea and jurafsky, 2002) <papid> J02-3001 </papid>assumes knowledge of the frame and covers only 20% of them.</citsent>
<aftsection>
<nextsent>always work as successfully as researchers have expected (krymolowski and roth, 1998; <papid> W98-0717 </papid>montemagni and pirelli, 1998).<papid> W98-0712 </papid></nextsent>
<nextsent>this seems to be due to lack of topical context (harabagiu et al , 1999; <papid> W99-0501 </papid>agirre et al , 2001) as well aslocal context (fellbaum, 1998).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z397">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wordnet (fellbaum, 1998) by far is the most widely used semantic database.
</prevsent>
<prevsent>however, this database does not 3the attempt to label these semantic roles automatically in (gildea and jurafsky, 2002) <papid> J02-3001 </papid>assumes knowledge of the frame and covers only 20% of them.</prevsent>
</prevsection>
<citsent citstr=" W98-0712 ">
always work as successfully as researchers have expected (krymolowski and roth, 1998; <papid> W98-0717 </papid>montemagni and pirelli, 1998).<papid> W98-0712 </papid></citsent>
<aftsection>
<nextsent>this seems to be due to lack of topical context (harabagiu et al , 1999; <papid> W99-0501 </papid>agirre et al , 2001) as well aslocal context (fellbaum, 1998).</nextsent>
<nextsent>by adding contextual information, many researchers, (e.g., (green et al , 2001;lapata and brew, 1999; <papid> W99-0632 </papid>landes et al , 1998)), have already made some improvements over it.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z398">
<title id=" W03-0412.xml">phrase net towards context sensitive lexical semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, this database does not 3the attempt to label these semantic roles automatically in (gildea and jurafsky, 2002) <papid> J02-3001 </papid>assumes knowledge of the frame and covers only 20% of them.</prevsent>
<prevsent>always work as successfully as researchers have expected (krymolowski and roth, 1998; <papid> W98-0717 </papid>montemagni and pirelli, 1998).<papid> W98-0712 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0501 ">
this seems to be due to lack of topical context (harabagiu et al , 1999; <papid> W99-0501 </papid>agirre et al , 2001) as well aslocal context (fellbaum, 1998).</citsent>
<aftsection>
<nextsent>by adding contextual information, many researchers, (e.g., (green et al , 2001;lapata and brew, 1999; <papid> W99-0632 </papid>landes et al , 1998)), have already made some improvements over it.</nextsent>
<nextsent>the work on the importance of connecting syntax and semantics in developing lexical semantic resources shows the importance of contextual information as step towards deeper level of processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z401">
<title id=" W03-1404.xml">systematicity and the lexicon in creative metaphor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this view, systematicity is measure of how much metaphor resonates and coheres with existing metaphors for thinking about the target concept, so that when viewed collectively, they together suggest the operation of common underlying schema.
</prevsent>
<prevsent>this view of systematicity is external to the concepts involved since it predicates their aptness to each other on the existence of other structures (metaphor schemas) into which they can be coherently connected.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
in this paper we argue that the lexicon is central to the determination of both kinds of systematicity, internal and external, especially if one is an adherent of the generative lexicon view of word meaning as championed by (pustejovsky, 1991).<papid> J91-4003 </papid></citsent>
<aftsection>
<nextsent>in such lexicon we can expect to find precisely the kind of relational structure needed to perform structure mapping and thereby measure the internal systematicity of metaphor like ? passport is travel diary?
</nextsent>
<nextsent>in addition, we can expect to find the lexicalized metaphor structures that represent the surface manifestations of existing modes of thought, and it is against these structures that the external systematicity of an interpretation can be measured.
</nextsent>
<nextsent>this research is conducted in the context of wordnet (miller, 1995; fellbaum, 1998), comprehensive lexical knowledge-base of english.
</nextsent>
<nextsent>the structure of wordnet makes explicit some of the relationships needed to construct generative lexicon, most obviously the formal (taxonomic) and constitutive (meronymic) aspects of word meaning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z402">
<title id=" W03-1404.xml">systematicity and the lexicon in creative metaphor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the structure of wordnet makes explicit some of the relationships needed to construct generative lexicon, most obviously the formal (taxonomic) and constitutive (meronymic) aspects of word meaning.
</prevsent>
<prevsent>but to truly test model of metaphoric interpretation on large-scale, it is necessary to augment these relationships with the telic and agentive components that are not encoded directly but merely alluded to in the textual glosses associated with each sense entry.
</prevsent>
</prevsection>
<citsent citstr=" W99-0501 ">
in the sections to follow we describe mechanism for automating the extraction of these relationships (in the same vein as (harabagiu et al  1999), <papid> W99-0501 </papid>and for using them to generative apt interpretations for metaphors involving wordnet entries.</citsent>
<aftsection>
<nextsent>in generative lexicon, the core elements of word meaning are represented by nexus of relations called qualia structure, which ties together the formal (i.e., hierarchical relations), constitutive (i.e., meronymic), telic (i.e., functional) and agentive (i.e., construction/creation) aspects of word.
</nextsent>
<nextsent>for instance, diary is formally kind of book?
</nextsent>
<nextsent>that constitutes collection of personal writings?
</nextsent>
<nextsent>whose telic purpose is to record?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z403">
<title id=" W02-1509.xml">coping with problems in grammars automatically extracted from treebanks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much linguistic research is oriented to finding general principles for natural language, classifying linguistic phenomena, building regular models (e.g., grammars) for the well-behaved (or wellunderstood) part of languages and studying remaining interesting?
</prevsent>
<prevsent>problems in compartmentalized way.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
with the availability of large natural language corpora annotated for syntactic structure, the treebanks, e.g., (marcus et al, 1993), <papid> J93-2004 </papid>automatic grammar extraction became possible (chen and vijay shanker, 2000; xia, 1999).</citsent>
<aftsection>
<nextsent>suddenly, grammars started being extracted with an attempt to havefull?
</nextsent>
<nextsent>coverage of the constructions in certain language (of course, to the extent that the used corpora represents the language) and that immediately poses question: if we do not know how to model many phenomena grammatically how can that be that we are extracting such wide-coverage grammar?.
</nextsent>
<nextsent>to answer that question we have to start new thread at the edge of linguistics and computational linguistics.
</nextsent>
<nextsent>more than numbers to express coverage,we have to start analyzing the quality of automatically generated grammars, identifying extraction problems and uncovering whatever solutions are being given for them, however interesting or ugly they might be, challenging the current paradigms of linguistic research to provide answers for the problems on by-need?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z404">
<title id=" W02-1509.xml">coping with problems in grammars automatically extracted from treebanks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to answer that question we have to start new thread at the edge of linguistics and computational linguistics.
</prevsent>
<prevsent>more than numbers to express coverage,we have to start analyzing the quality of automatically generated grammars, identifying extraction problems and uncovering whatever solutions are being given for them, however interesting or ugly they might be, challenging the current paradigms of linguistic research to provide answers for the problems on by-need?
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
basis.in this paper we report on particular experience of automatic extraction of an english grammar from the wsj corpus of the penn treebank (ptb)(marcus et al, 1994)<papid> H94-1020 </papid>1 using tree adjoining grammar (tags, (joshi and schabes, 1997)).</citsent>
<aftsection>
<nextsent>we use an automatic tool developed by (xia, 2001) properly adapted to our particular needs and focus on some problems we have found to extract linguistically(and computationally) sound grammar and the solutions we gave to them.
</nextsent>
<nextsent>the list of problems is sample, far from being exhaustive2 likewise, the solutions will not always be satisfactory.
</nextsent>
<nextsent>in section 2 we introduce the method of grammar extraction employed.
</nextsent>
<nextsent>the problems are discussed in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z406">
<title id=" W02-1509.xml">coping with problems in grammars automatically extracted from treebanks </title>
<section> extraction problems.  </section>
<citcontext>
<prevsection>
<prevsent>should anchor tree with one np object.
</prevsent>
<prevsent>however in such tree it would be impossible to adjoin the tree for the intervening advp quickly?
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
as vp modifier and still have it between the verb and the np.9 lex tract then would instead extract an9a striking use of sister adjunction in (chiang, 2000) <papid> P00-1058 </papid>is exactly the elegant way it solves this problem: the non-argument tree can be adjoined onto node (say, vp), positioning itself in between the vps children, which is not possible with tags.</citsent>
<aftsection>
<nextsent>(np (np the 3 billion new zealand dollars) (prn (-lrb- -lrb-) (np us$ 1.76 billion *u*) (-rrb- -rrb-))) a) parenthetical np attached to another np (s (np-sbj the total relationship) (prn (, ,) (sbar-adv as mr. lee sees it) (, ,)) (vp (vbz is) ...)) b) parenthetical between subject and verb figure 12: parentheticals in transitive tree for the vb pass?, onto which theadvp modifier tree would adjoin.
</nextsent>
<nextsent>the second oddity is that the np object would also be extracted as vp modifier tree.
</nextsent>
<nextsent>in nutshell, objects in extracted trees are restricted to those which are not extra posed and hence the trees may not truly reflect the proper domain of locality.
</nextsent>
<nextsent>one view is that the set of trees for certain subcategorization frame would include these degenerate cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z407">
<title id=" W03-1027.xml">virtual examples for text classification with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even if we have good supervised-learning method,we cannot get high-performance without an annotated corpus.
</prevsent>
<prevsent>the problem is that corpus annotation is labor intensive and very expensive.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in order to overcome this, several methods are proposed, including minimally-supervised learning methods (e.g., (yarowsky, 1995; <papid> P95-1026 </papid>blum and mitchell, 1998)), and active learning methods (e.g., (thompson et al., 1999; sassano, 2002)).<papid> P02-1064 </papid></citsent>
<aftsection>
<nextsent>the spirit behind these methods is to utilize precious labeled examples maximally.
</nextsent>
<nextsent>another method following the same spirit is one using virtual examples (artificially created exam ples) generated from labeled examples.
</nextsent>
<nextsent>this method has been rarely discussed in natural language processing.
</nextsent>
<nextsent>in terms of active learning, lewis and gale (1994) mentioned the use of virtual examples in text classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z408">
<title id=" W03-1027.xml">virtual examples for text classification with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even if we have good supervised-learning method,we cannot get high-performance without an annotated corpus.
</prevsent>
<prevsent>the problem is that corpus annotation is labor intensive and very expensive.
</prevsent>
</prevsection>
<citsent citstr=" P02-1064 ">
in order to overcome this, several methods are proposed, including minimally-supervised learning methods (e.g., (yarowsky, 1995; <papid> P95-1026 </papid>blum and mitchell, 1998)), and active learning methods (e.g., (thompson et al., 1999; sassano, 2002)).<papid> P02-1064 </papid></citsent>
<aftsection>
<nextsent>the spirit behind these methods is to utilize precious labeled examples maximally.
</nextsent>
<nextsent>another method following the same spirit is one using virtual examples (artificially created exam ples) generated from labeled examples.
</nextsent>
<nextsent>this method has been rarely discussed in natural language processing.
</nextsent>
<nextsent>in terms of active learning, lewis and gale (1994) mentioned the use of virtual examples in text classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z409">
<title id=" W03-1027.xml">virtual examples for text classification with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we focus on virtual examples with support vector machines, introduced by vap nik (1995).
</prevsent>
<prevsent>the reason for this is that svm is one of most successful machine learning methods in nlp.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
for example, nl tasks to which svms have been applied are text classification (joachims, 1998; du mais et al, 1998), chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>dependency analysis (kudo and matsumoto, 2002) <papid> W02-2016 </papid>and so forth.</citsent>
<aftsection>
<nextsent>in this study, we choose text classification as afirst case of the study of virtual examples in nlp because text classification in real world requires minimizing annotation cost, and it is not too complicated to perform some non-trivial experiments.
</nextsent>
<nextsent>moreover,there are simple methods, which we propose, to generate virtual examples from labeled examples (sec tion 4).
</nextsent>
<nextsent>we show how virtual examples can improve the performance of classifier with svm in text classification, especially for small training sets.
</nextsent>
<nextsent>in this section we give some theoretical definitions of svms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z410">
<title id=" W03-1027.xml">virtual examples for text classification with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we focus on virtual examples with support vector machines, introduced by vap nik (1995).
</prevsent>
<prevsent>the reason for this is that svm is one of most successful machine learning methods in nlp.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
for example, nl tasks to which svms have been applied are text classification (joachims, 1998; du mais et al, 1998), chunking (kudo and matsumoto, 2001), <papid> N01-1025 </papid>dependency analysis (kudo and matsumoto, 2002) <papid> W02-2016 </papid>and so forth.</citsent>
<aftsection>
<nextsent>in this study, we choose text classification as afirst case of the study of virtual examples in nlp because text classification in real world requires minimizing annotation cost, and it is not too complicated to perform some non-trivial experiments.
</nextsent>
<nextsent>moreover,there are simple methods, which we propose, to generate virtual examples from labeled examples (sec tion 4).
</nextsent>
<nextsent>we show how virtual examples can improve the performance of classifier with svm in text classification, especially for small training sets.
</nextsent>
<nextsent>in this section we give some theoretical definitions of svms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z411">
<title id=" W02-1008.xml">combining sample selection and error driven pruning for machine learning of coreference rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, the system outperforms the best-performing learning-based coreference system to date.
</prevsent>
<prevsent>noun phrase coreference resolution refers to the problem of determining which noun phrases (nps)refer to each real-world entity mentioned in document.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
machine learning approaches to this problem have been reasonably successful, operating primarily by recasting the problem as classification task (e.g. aone and bennett (1995), mccarthy and lehnert (1995), soon et al (2001)).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>specifically, an inductive learning algorithm is used to train classifier that decides whether or not two nps in document are coreferent.
</nextsent>
<nextsent>training data are typically created by relying on coreference chains from the training documents: training instances are generated by pairing each np with each of its preceding nps; instances are labeled as positive if the two nps are in the same coreference chain, and labeled as negative otherwise.1 separate clustering mechanism then coordinates the possibly contradictory pairwise coreference classification decisions and constructs partition on theset of nps with one cluster for each set of co referent nps.
</nextsent>
<nextsent>although, in principle, any clustering algorithm can be used, most previous work uses single link clustering algorithm to impose coreference par titions.2 an implicit assumption in the choice of the single-link clustering algorithm is that coreference resolution is viewed as anaphora resolution, i.e. the goal during clustering is to find an antecedent for each anaphoric np in document.3three intrinsic properties of coreference4, how ever, make the formulation of the problem as aclassification-based single-link clustering task potentially undesirable: coreference is rare relation.
</nextsent>
<nextsent>that is, mostnp pairs in document are not coreferent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z412">
<title id=" W02-1008.xml">combining sample selection and error driven pruning for machine learning of coreference rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although, in principle, any clustering algorithm can be used, most previous work uses single link clustering algorithm to impose coreference par titions.2 an implicit assumption in the choice of the single-link clustering algorithm is that coreference resolution is viewed as anaphora resolution, i.e. the goal during clustering is to find an antecedent for each anaphoric np in document.3three intrinsic properties of coreference4, how ever, make the formulation of the problem as aclassification-based single-link clustering task potentially undesirable: coreference is rare relation.
</prevsent>
<prevsent>that is, mostnp pairs in document are not coreferent.
</prevsent>
</prevsection>
<citsent citstr=" W97-0319 ">
con 1two nps are in the same coreference chain if and only if they are coreferent.2one exception is kehlers work on probabilistic coreference (kehler, 1997), <papid> W97-0319 </papid>in which he applies dempsters rule of combination (dempster, 1968) to combine all pairwise probabilities of coreference to form partition.</citsent>
<aftsection>
<nextsent>3in this paper, we consider an np anaphoric if it is part of coreference chain but is not the head of the chain.
</nextsent>
<nextsent>4here, we use the term coreference loosely to refer to either the problem or the binary relation defined on set of nps.
</nextsent>
<nextsent>the particular choice should be clear from the context.
</nextsent>
<nextsent>association for computational linguistics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z413">
<title id=" W02-1008.xml">combining sample selection and error driven pruning for machine learning of coreference rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to results reported there, how ever, we show empirically that system performance increases noticeably in response to negative example selection, with increases in f-measure of 3-5%.
</prevsent>
<prevsent>second, in an attempt to avoid the inclusion of hard?
</prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
training instances, we present corpus-based method for implicit selection of positive instances.the approach is fully automated variant of the example selection algorithm introduced in harabagiu et al (2001).<papid> N01-1008 </papid></citsent>
<aftsection>
<nextsent>with positive example selection, system performance (f-measure) again increases, by 12-14%.
</nextsent>
<nextsent>finally, to more tightly tie the classification- and clustering-level coreference decisions, we propose an error-driven rule pruning algorithm that optimizes the coreference classifier ruleset with respect to the clustering-level coreference scoring function.overall, the use of pruning boosts system performance from an f-measure of 69.3 to 69.5, and from 57.2 to 63.4 for the muc-6 and muc-7 data sets,respectively, enabling the system to achieve performance that surpasses that of the best muc coreference systems by 4.6% and 1.6%.
</nextsent>
<nextsent>in particular, the system outperforms the best-performing learning based coreference system (soon et al, 2001) <papid> J01-4004 </papid>by 6.9% and 3.0%.the remainder of the paper is organized as fol lows.</nextsent>
<nextsent>in sections 2 and 3, we present the machine learning framework underlying the baseline coreference system and examine the effect of negative sample selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z416">
<title id=" W02-1008.xml">combining sample selection and error driven pruning for machine learning of coreference rules </title>
<section> negative sample selection.  </section>
<citcontext>
<prevsection>
<prevsent>the np with the highest confidence value among the preceding nps that are classified as being co referent with np   is selected as the antecedent of np  ; otherwise, no antecedent is selected for np  .
</prevsent>
<prevsent>as noted above, skewed class distributions arise when generating all valid instances from the training texts.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
a number of methods for handling skewed distributions have been proposed in the machine learning literature, most of which modify the learn 6see ng and cardie (2002) <papid> P02-1014 </papid>for detailed description of the features.</citsent>
<aftsection>
<nextsent>7in all of the work presented here, nps are identified, and feature values computed entirely automatically.
</nextsent>
<nextsent>algorithm neg-select(neg: set of all possible negative instances) for !   #$ % &amp; neg do if np   is anaphoric then if np  precedes ( (np  ) then neg := neg )#* !   % %,+ else neg := neg )#*!
</nextsent>
<nextsent> $ %+ return neg figure 1: the neg-select algorithm ing algorithm to incorporate loss function with much larger penalty for minority class errors than for instances from the majority classes (e.g. gordon and perlis (1989), pazzani et al (1994)).
</nextsent>
<nextsent>we investigate here different approach to handling skewed class distributions ? negative sample selection, i.e. the selection of smaller subset of negative instances from the set of available negative instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z417">
<title id=" W02-1008.xml">combining sample selection and error driven pruning for machine learning of coreference rules </title>
<section> negative sample selection.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate the coreference system with negative sample selection on the muc-6 andmuc-7 coreference datasets in each case, training the coreference classifier on the 30 dry run texts, and applying the coreference resolution algorithm on the 2030 formal evaluation?
</prevsent>
<prevsent>texts.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
results are shown in rows 1 and 2 of table 2 where performance is reported in terms of recall, precision,and f-measure using the model-theoretic muc scoring program (vilain et al, 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>the baseline system employs no sample selection, i.e. all available training examples are used.
</nextsent>
<nextsent>row 2 shows the performance of the baseline after incorporating negselect.
</nextsent>
<nextsent>with negative sample selection, the percentage of positive instances rises from 2% to 8% for the muc-6 dataset and from 2% to 7% for themuc-7 dataset.
</nextsent>
<nextsent>for both datasets, we see statistically significant increases in recall and statistically significant, but much larger drops in precision.9 the resulting f-measure scores, however, increase non trivially from 52.4 to 55.2 (for muc-6), and from 41.3 to 46.0 (for muc-7).10
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z419">
<title id=" W02-1008.xml">combining sample selection and error driven pruning for machine learning of coreference rules </title>
<section> pruning the coreference ruleset.  </section>
<citcontext>
<prevsection>
<prevsent>we will address this issue in the next section.
</prevsent>
<prevsent>as noted in the introduction, machine learning approaches to coreference resolution that rely only on pairwise np coreference classifiers will not necessarily enforce the transit ivity constraint inherent in the coreference relation.
</prevsent>
</prevsection>
<citsent citstr=" W99-0611 ">
although approaches to coreference resolution that rely only on clustering could easily enforce transit ivity (as in cardie and wagstaff (1999)), <papid> W99-0611 </papid>they have not performed as well as state-of-the-art approaches to coreference.</citsent>
<aftsection>
<nextsent>in this section, we propose method for resolving this conflict: we introduce an error-driven rule pruning algorithm that considers rules induced by the coreference classifier and discards those that cause the ruleset to perform poorly with respect to the global, clustering-level coreference scoring function.the algorithm.
</nextsent>
<nextsent>the error-driven pruning algorithm is inspired by the backward elimination algorithm commonly used for feature selection (see blum and langley (1997)) and is shown in figure 3.
</nextsent>
<nextsent>the algorithm, rule-select, takes as input a. ruleset learned from training corpus for performing coreference resolution, pruning corpus (dis joint from the training corpus), and clustering-level 12more precisely, ripper will induce new rule if the rule is more than 50% accurate and the resulting description length is fewer than 64 bits larger than the smallest description length obtained so far.
</nextsent>
<nextsent>algorithm rule-select(r: ruleset, p: pruning corpus, s: scoring function) best score @d= score of the coreference system using on w.r.t. s; @d= nil; repeat := the rule in whose removal yields ruleset with which the coreference system achieves the best score on w.r.t. s. if e best score then best score @a= b; @a= )b* + else break while true return figure 3: the rule-select algorithm coreference scoring function that is the same as the one being used for evaluating the final output of thesystem.13 at each iteration, rule-select greedily discards the rule whose removal yields rule set with which the coreference system performs thebest (with respect to the coreference scoring function) on the pruning corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z420">
<title id=" W03-0612.xml">population testing extracting semantic information on nearsynonymy from native speakers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>use of ptm presumes that all knowledge about lexical meaning in language resides collectively in the mind(s) of its native speakers, and that this in ter subjective understanding may be extracted via targeted surveys that encourage creative, thinking responses.
</prevsent>
<prevsent>in this paper we show (1) examples of such tests performed on group of high school students in finland, (2) resulting data from the tests that is surprisingly quantifiable, and (3) web-based visualization program we are developing to analyze and present the collected data.
</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
the problem of near-synonym discrimination presents formidable challenge to computer-based natural language processing systems (edmonds 1999; edmonds and hirst, 2002), <papid> J02-2001 </papid>as well as to humans who are attempting to acquire near-native competency in foreign lan guage.</citsent>
<aftsection>
<nextsent>in both cases, comprehensive lexical database specifically designed for near-synonymy in the target language is pre-requisite for the further development of practical applications in their respective domains.
</nextsent>
<nextsent>some promising approaches have appeared in recent literature.
</nextsent>
<nextsent>these include corpus based procedures (ink pen and hirst 2001, 2002), and applied component ial analysis, in particular continuing work on cross-lingual semantic primitives by wierzbicka and her colleagues (wierzbicka 1996, 1999).
</nextsent>
<nextsent>corpus-based approaches are, however, constrained by the kind and scope of pre-existing corpora and tools that are currently available; while component ial analysis necessarily depends heavily on the subjective judgment of its investigators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z421">
<title id=" W02-1019.xml">minimum bayes risk word alignments of bilingual texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe various loss functions, including some that incorporate linguistic analysis as can be obtained from parse trees, and show that these approaches can improve alignments of the english-french hansards.
</prevsent>
<prevsent>the automatic determination of word alignments in bilingual corpora would be useful for natural language processing tasks such as statistical machine translation, automatic dictionary construction, and multilingual document retrieval.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
the development of techniques in all these areas would be facilitated by automatic performance metrics, and alignment and translation quality metrics have been proposed (och and ney, 2000<papid> P00-1056 </papid>b; papineni et al, 2002).</citsent>
<aftsection>
<nextsent>however, given the difficulty of judging translation quality, it is unlikely that single, global metric will be found for any of these tasks.
</nextsent>
<nextsent>it is more likely that specialized metrics will be developed to measure specific aspects of system performance.
</nextsent>
<nextsent>this is even desirable, as these specialized metrics could be used in tuning systems for particular applications.
</nextsent>
<nextsent>we have applied minimum bayes-risk (mbr)procedures developed for automatic speech recognition (goel and byrne, 2000) to word alignment of bitexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z435">
<title id=" W02-1019.xml">minimum bayes risk word alignments of bilingual texts </title>
<section> word-to-word bitext alignment.  </section>
<citcontext>
<prevsection>
<prevsent>this is modeling approach that can be used with statistical models of speech and language to develop algorithms that are optimized for specific loss functions.
</prevsent>
<prevsent>we will discuss loss functions that canbe used for word alignment and show how the over all alignment process can be improved by the use of loss functions that incorporate linguistic features, such as parses and part-of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we will study the problem of aligning an english sentence to french sentence and we will use the word alignment of the ibm statistical translation models (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>let and denote pair of translated english and french sentences.
</nextsent>
<nextsent>an english word is defined as an ordered pair, where the index refers to the position of the word in the english sentence; is the vocabulary of english; and the word at position is the null word to which spurious?
</nextsent>
<nextsent>french words may be aligned.
</nextsent>
<nextsent>similarly, french word is written as . an alignment between and is defined to be sequence where . under the alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z452">
<title id=" W02-1019.xml">minimum bayes risk word alignments of bilingual texts </title>
<section> word alignment experiments.  </section>
<citcontext>
<prevsection>
<prevsent>it reflects how strongly the words and are bound together by the syntactic structure of the english sentence as determined by the parser.
</prevsent>
<prevsent>figure 1 shows the parse tree for an english sentence in the test data with the pairwise syntactic distances between the english words corresponding to the leaf nodes.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
top np prp vp vbp think sbar np dt that vp vbz is adjp jj good . . pairwise distances g( , think ) = 4 g( ,  that ) = 7 g( , is ) = 7 g(  ,  good ) = 8 g(  ,  . ) = 8 figure 1: parse tree for english sentence with the pairwise syntactic distances between words.to obtain these distances, ratnaparkhis part of-speech (pos) tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>and collins?</citsent>
<aftsection>
<nextsent>parser (collins, 1999) were used to obtain parse trees for the english side of the test corpus.
</nextsent>
<nextsent>with defined as in equation 14, the generalized alignment error loss function (equation 3) is called the parse-tree syntactic distance ( ).
</nextsent>
<nextsent>5.2 distances derived from part-of-speech.
</nextsent>
<nextsent>labels suppose part-of-speech(pos) tagger is available to tag each word in the english sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z527">
<title id=" W02-1019.xml">minimum bayes risk word alignments of bilingual texts </title>
<section> discussion and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>in future work we will investigate loss functions that incorporate french and english parse-tree information into the alignment decoding process.
</prevsent>
<prevsent>our ultimate goal, towards which this work is the first step, is to construct loss functions that take advantage of linguistic structures such as syntactic dependencies found through monolingual analysis of the sentence sto be aligned.
</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
recent work (hwa et al, 2002) <papid> P02-1050 </papid>suggests that translational corresponence of linguistic structures can indeed be useful in projecting parses across languages.</citsent>
<aftsection>
<nextsent>our ideal would be to construct mbr decoders based on loss functions that are sensitive both to word alignment as well as to agreement in higher level structures such as parse trees.
</nextsent>
<nextsent>in this way ambiguity present in word-to-word alignment swill be resolved by the alignment of linguistic structures.
</nextsent>
<nextsent>generalized alignment error rates decoder aer ptsd-s posd-s awcd-s ptsd-a posd-a awcd-a ml 18.13 3.13 4.35 4.69 29.39 51.36 54.58 mbr-ae 14.87 1.34 1.89 1.94 19.81 36.42 38.58 mbr-ptsd 23.26 0.62 0.69 0.82 14.45 26.76 28.42 mbr-posd 28.60 2.43 0.69 3.23 15.70 26.28 29.48 mbr-awcd 24.71 1.00 0.95 0.86 14.92 26.83 28.39 table 1: performance (%) of the mbr decoders under the alignment error and generalized alignment error rates.
</nextsent>
<nextsent>for each metric the error rate of the matched decoder is in bold.mbr alignment is promising modeling framework for the detailed linguistic annotation of bilingual texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z528">
<title id=" W03-0425.xml">named entity recognition through classifier combination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden markov model) are combined under different conditions.
</prevsent>
<prevsent>when no gazetteer or other additional training resources are used, the combined system attains performance of 91.6fon the english development data; integrating name, location and person gazette ers, and named entity systems trained on additional, more general, data reduces the f-measure error by factor of 15 to 21% on the english data.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
this paper investigates the combination of set of diverse statistical named entity classifiers, including rule-based classifier ? the transformation-based learning classifier (brill, 1995; <papid> J95-4004 </papid>florian and ngai, 2001, henceforth fntbl) with the forward-backward extension described in florian (2002<papid> W02-2010 </papid>a), hidden markov model classifier (henceforth hmm), similar to the one described in bikel et al (1999), robust risk minimization classifier, based on regularized winnow method (zhang et al,2002) (henceforth rrm) and maximum entropy classifier (darroch and rat cliff, 1972; berger et al, 1996; <papid> J96-1002 </papid>borthwick, 1999) (henceforth maxent).</citsent>
<aftsection>
<nextsent>this particular set of classifiers is diverse across multiple dimensions, making it suitable for combination:?
</nextsent>
<nextsent>fntbl is discriminant classifier ? it bases its classification decision only on the few most discriminant features active on an example ? while hmm, rrmand maxent are agglomerative classifiers ? their decision is based on the combination of all features active for the particular example.
</nextsent>
<nextsent>in dealing with the data sparseness problem, fntbl, maxent and rrm investigate and integrate in their decision arbitrary feature types, while hmm is dependent on pre specified back-off path.
</nextsent>
<nextsent>the search methods employed by each classifier are different: the hmm, maxent and rrm classifiers construct model for each example and then relyon sequence search such as the viterbi algorithm (viterbi, 1967) to identify the best overall sequence, while fntbl starts with most frequent classification (usually per token), and then dynamically models the interaction between classifications, effectively performing the search at training time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z529">
<title id=" W03-0425.xml">named entity recognition through classifier combination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden markov model) are combined under different conditions.
</prevsent>
<prevsent>when no gazetteer or other additional training resources are used, the combined system attains performance of 91.6fon the english development data; integrating name, location and person gazette ers, and named entity systems trained on additional, more general, data reduces the f-measure error by factor of 15 to 21% on the english data.
</prevsent>
</prevsection>
<citsent citstr=" W02-2010 ">
this paper investigates the combination of set of diverse statistical named entity classifiers, including rule-based classifier ? the transformation-based learning classifier (brill, 1995; <papid> J95-4004 </papid>florian and ngai, 2001, henceforth fntbl) with the forward-backward extension described in florian (2002<papid> W02-2010 </papid>a), hidden markov model classifier (henceforth hmm), similar to the one described in bikel et al (1999), robust risk minimization classifier, based on regularized winnow method (zhang et al,2002) (henceforth rrm) and maximum entropy classifier (darroch and rat cliff, 1972; berger et al, 1996; <papid> J96-1002 </papid>borthwick, 1999) (henceforth maxent).</citsent>
<aftsection>
<nextsent>this particular set of classifiers is diverse across multiple dimensions, making it suitable for combination:?
</nextsent>
<nextsent>fntbl is discriminant classifier ? it bases its classification decision only on the few most discriminant features active on an example ? while hmm, rrmand maxent are agglomerative classifiers ? their decision is based on the combination of all features active for the particular example.
</nextsent>
<nextsent>in dealing with the data sparseness problem, fntbl, maxent and rrm investigate and integrate in their decision arbitrary feature types, while hmm is dependent on pre specified back-off path.
</nextsent>
<nextsent>the search methods employed by each classifier are different: the hmm, maxent and rrm classifiers construct model for each example and then relyon sequence search such as the viterbi algorithm (viterbi, 1967) to identify the best overall sequence, while fntbl starts with most frequent classification (usually per token), and then dynamically models the interaction between classifications, effectively performing the search at training time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z531">
<title id=" W03-0425.xml">named entity recognition through classifier combination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden markov model) are combined under different conditions.
</prevsent>
<prevsent>when no gazetteer or other additional training resources are used, the combined system attains performance of 91.6fon the english development data; integrating name, location and person gazette ers, and named entity systems trained on additional, more general, data reduces the f-measure error by factor of 15 to 21% on the english data.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
this paper investigates the combination of set of diverse statistical named entity classifiers, including rule-based classifier ? the transformation-based learning classifier (brill, 1995; <papid> J95-4004 </papid>florian and ngai, 2001, henceforth fntbl) with the forward-backward extension described in florian (2002<papid> W02-2010 </papid>a), hidden markov model classifier (henceforth hmm), similar to the one described in bikel et al (1999), robust risk minimization classifier, based on regularized winnow method (zhang et al,2002) (henceforth rrm) and maximum entropy classifier (darroch and rat cliff, 1972; berger et al, 1996; <papid> J96-1002 </papid>borthwick, 1999) (henceforth maxent).</citsent>
<aftsection>
<nextsent>this particular set of classifiers is diverse across multiple dimensions, making it suitable for combination:?
</nextsent>
<nextsent>fntbl is discriminant classifier ? it bases its classification decision only on the few most discriminant features active on an example ? while hmm, rrmand maxent are agglomerative classifiers ? their decision is based on the combination of all features active for the particular example.
</nextsent>
<nextsent>in dealing with the data sparseness problem, fntbl, maxent and rrm investigate and integrate in their decision arbitrary feature types, while hmm is dependent on pre specified back-off path.
</nextsent>
<nextsent>the search methods employed by each classifier are different: the hmm, maxent and rrm classifiers construct model for each example and then relyon sequence search such as the viterbi algorithm (viterbi, 1967) to identify the best overall sequence, while fntbl starts with most frequent classification (usually per token), and then dynamically models the interaction between classifications, effectively performing the search at training time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z532">
<title id=" W03-0425.xml">named entity recognition through classifier combination </title>
<section> the algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>this section describes only briefly the classifiers used in combination in section 4; full description of the algorithms and their properties is beyond the scope of this paper ? the reader is instead referred to the original articles.
</prevsent>
<prevsent>3.1 the robust risk minimization classifier.
</prevsent>
</prevsection>
<citsent citstr=" W03-0434 ">
this classifier is described in detail in (zhang and johnson, 2003, <papid> W03-0434 </papid>this volume), along with comprehensive evaluation of its performance, and therefore is not presented here.</citsent>
<aftsection>
<nextsent>3.2 the maximum entropy classifier.
</nextsent>
<nextsent>the maxent classifier computes the posterior class probability of an example by evaluating the normalized product of the weights active for the particular example.
</nextsent>
<nextsent>the model weights are trained using the improved iterative scaling algorithm (berger et al, 1996).<papid> J96-1002 </papid></nextsent>
<nextsent>to avoid running in severe over-training problems, feature cutoff of 4 is applied before the model weights are learned.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z537">
<title id=" W02-1706.xml">xml based nlp tools for analysing and annotating medical language </title>
<section> pre-parsing of medline abstracts.  </section>
<citcontext>
<prevsection>
<prevsent>from this point on, all processing is directed at the abstract elements through the query?.*/abstract1.
</prevsent>
<prevsent>steps 3 and 4 make calls to fsgmatch to identify and (word) elements as described above and after this point, in step 5, the mark-up is discarded (using the lt ttt program sgdelmarkup) since it has now served its purpose.
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
step 6 contains call to the other main lt ttt program, ltpos (mikheev, 1997), <papid> J97-3003 </papid>which performs both sentence identification and pos tagging.</citsent>
<aftsection>
<nextsent>the sub query (-qs) option picks out abstracts as the elements within records (-q option) that are tobe processed; the -qw option indicates that the in put has already been segmented into words marked 1the query language that the lt ttt and lt xml tools use is specialised xml query language which pinpoints the part of the xml tree-structure that is to be processed at that point.
</nextsent>
<nextsent>this query language pre-dates xpath and in expressiveness it constitutes subset of xpath except that it also allows regular expressions over text content.
</nextsent>
<nextsent>future plans include modifying out tools to allow for the use of xpath as query language.
</nextsent>
<nextsent>up as elements; the -sent option indicates that sentences should be wrapped as sent elements; the -tag option is an instruction to output pos tags and the -pos attr option indicates that pos tags should be encoded as the value of the attribute on elements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z538">
<title id=" W02-1706.xml">xml based nlp tools for analysing and annotating medical language </title>
<section> pre-parsing of medline abstracts.  </section>
<citcontext>
<prevsection>
<prevsent>up as elements; the -sent option indicates that sentences should be wrapped as sent elements; the -tag option is an instruction to output pos tags and the -pos attr option indicates that pos tags should be encoded as the value of the attribute on elements.
</prevsent>
<prevsent>the final resource.xml names the resource file that ltpos is to use.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
note that the tagset used by ltpos is the penn treebank tagset (marcus et al , 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>1.
</nextsent>
<nextsent>ohs2xml.perl \ 2.
</nextsent>
<nextsent>| fsgmatch -q  .*/text  ohsumed.gr \ 3.
</nextsent>
<nextsent>| fsgmatch -q  .*/abstract  pretok.gr \ 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z539">
<title id=" W02-1706.xml">xml based nlp tools for analysing and annotating medical language </title>
<section> pre-parsing of medline abstracts.  </section>
<citcontext>
<prevsection>
<prevsent>this gives the potential for much wider range of transformations of the input than fsgmatch allows and, in particular, we use perls stream-handling capabilities to pass the content of xml elements out to non xml program, receive the result back and encode it back in the xml mark-up.
</prevsent>
<prevsent>step 7 of the pipeline in figure 3 shows call to xmlperl with the rule file lemma.rule.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
this rule file invokes minnen et al (2000) <papid> W00-1427 </papid>morpha lemmatiser: the pcdata content of each verbal or nominal element is passed to thelemmatiser and the lemma that is returned is encoded as the value of the attribute lm.</citsent>
<aftsection>
<nextsent>a sample of the output from the pipeline is shown in figure 1.
</nextsent>
<nextsent>as part of our work with ohsumed, we have been attempting to improve the coverage of handcrafted, linguistically motivated grammar which provides full-syntactic analysis paired with logical forms.
</nextsent>
<nextsent>the grammar and parsing system we useis the wide-coverage grammar, morphological analyser and lexicon provided by the alvey natural language tools (anlt) system (carroll et al  1991, grover et al  1993).
</nextsent>
<nextsent>our first aim was to increase coverage up to reasonable level so that parse ranking techniques could then be applied.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z540">
<title id=" W02-1706.xml">xml based nlp tools for analysing and annotating medical language </title>
<section> deep grammatical analysis.  </section>
<citcontext>
<prevsection>
<prevsent>note that the case of monitoring would be problematic for strategy where tagging is used only in case lexical look-up fails, since here it is incomplete rather than failed.
</prevsent>
<prevsent>the implementation of our word tag pair look-up method is specific to the anlt system and uses its morphological analysis component to treat tags as novel kind of affix.
</prevsent>
</prevsection>
<citsent citstr=" P01-1034 ">
space considerations preclude discussion of this topic here but see grover and lascarides (2001) <papid> P01-1034 </papid>for further details.</citsent>
<aftsection>
<nextsent>another impediment to parse coverage is the prevalence of technical expressions and formulae in biomedical and other technical language.
</nextsent>
<nextsent>forex ample, the following sentence has straightforward overall syntactic structure but the anlt grammar does not contain specialist rules for handling expressions such as 5.0+/-0.4 grams tension and thus the parse would fail.
</nextsent>
<nextsent>control tissues displayed reproducible response to bethanechol stimulation at different calcium concentrations with an ed50 of 0.4 mm calcium and peak response of 5.0+/-0.4 grams tension.our response to issues like these is to place further layer of processing in between the output of the initial token isation pipeline in figure 3 and the input to the parser.
</nextsent>
<nextsent>since the anlt system is notxml-based, we already use xmlperl to convert sentences to the anlt input format of one sentence perline with tags appended to words using an underscore.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z541">
<title id=" W02-1706.xml">xml based nlp tools for analysing and annotating medical language </title>
<section> shallow analysis.  </section>
<citcontext>
<prevsection>
<prevsent>we achieve this conversion using xmlperl with simple rule file.
</prevsent>
<prevsent>the output of cass and the grammatical relations processor is list of each verb-argument pair in the corpus: manage :obj re fibrillation respond :subj psoriasis access :to system 4.3 shallow parsing with the tag sequence.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
grammar our second method of acquiring verb grammatical relations uses the statistical parser developed by briscoe and carroll (1993), <papid> J93-1002 </papid>by briscoe and carroll (1997) <papid> A97-1052 </papid>which is an extension of the anlt grammar development system which we used for our deep grammatical analysis as reported in section 3 above.</citsent>
<aftsection>
<nextsent>the statistical parser, known as the tag sequence grammar (tsg), uses hand-crafted grammar where the lexical entries are for pos tags rather than words themselves.
</nextsent>
<nextsent>thus it is strings of tags that are parsed rather than strings of words.
</nextsent>
<nextsent>the statistical part of the system is the parse ranking component where probabilities are associated with transitions in an lr parse table.
</nextsent>
<nextsent>the grammar does not achieve full-coverage but on the ohsumed corpus we were able to obtain parses for 99.05% of sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z542">
<title id=" W02-1706.xml">xml based nlp tools for analysing and annotating medical language </title>
<section> shallow analysis.  </section>
<citcontext>
<prevsection>
<prevsent>we achieve this conversion using xmlperl with simple rule file.
</prevsent>
<prevsent>the output of cass and the grammatical relations processor is list of each verb-argument pair in the corpus: manage :obj re fibrillation respond :subj psoriasis access :to system 4.3 shallow parsing with the tag sequence.
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
grammar our second method of acquiring verb grammatical relations uses the statistical parser developed by briscoe and carroll (1993), <papid> J93-1002 </papid>by briscoe and carroll (1997) <papid> A97-1052 </papid>which is an extension of the anlt grammar development system which we used for our deep grammatical analysis as reported in section 3 above.</citsent>
<aftsection>
<nextsent>the statistical parser, known as the tag sequence grammar (tsg), uses hand-crafted grammar where the lexical entries are for pos tags rather than words themselves.
</nextsent>
<nextsent>thus it is strings of tags that are parsed rather than strings of words.
</nextsent>
<nextsent>the statistical part of the system is the parse ranking component where probabilities are associated with transitions in an lr parse table.
</nextsent>
<nextsent>the grammar does not achieve full-coverage but on the ohsumed corpus we were able to obtain parses for 99.05% of sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z543">
<title id=" W02-1103.xml">semiautomatic creation of taxonomies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although applied to spanish/english our method claims to be general enough to be applied in the cases skeletal taxonomy already exists and we dispose of methods for mapping items to this taxonomy with known confidence scores.
</prevsent>
<prevsent>the automatic construction of accurate tax onomies from sets of incomplete, partially overlapping knowledge sources with different coverage/confidence characteristics has been object of interest for many researchers (bisson et al, 2000; faatz et al, 2001; mihalcea and moldovan, 2001).the case of lexical taxonomies is specially challenging because of their huge size that advises against manual construction.
</prevsent>
</prevsection>
<citsent citstr=" H94-1025 ">
using bilingual dictionaries for mapping words or senses of language to english counterparts is not new (okumura and hovy, 1994; <papid> H94-1025 </papid>asanoma, 2001).</citsent>
<aftsection>
<nextsent>in fact the work presented here can be considered an extension of (atserias et al, 1997; farreres et al, 1998) <papid> W98-0709 </papid>that was the base of the approach to building the spanish wordnet within eurowordnet2 project.</nextsent>
<nextsent>from then within our group several efforts have been devoted to: 1http://www.cogsci.princeton.edu/~wn/ 2http://www.hum.uva.nl/~ewn/ 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z544">
<title id=" W02-1103.xml">semiautomatic creation of taxonomies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the automatic construction of accurate tax onomies from sets of incomplete, partially overlapping knowledge sources with different coverage/confidence characteristics has been object of interest for many researchers (bisson et al, 2000; faatz et al, 2001; mihalcea and moldovan, 2001).the case of lexical taxonomies is specially challenging because of their huge size that advises against manual construction.
</prevsent>
<prevsent>using bilingual dictionaries for mapping words or senses of language to english counterparts is not new (okumura and hovy, 1994; <papid> H94-1025 </papid>asanoma, 2001).</prevsent>
</prevsection>
<citsent citstr=" W98-0709 ">
in fact the work presented here can be considered an extension of (atserias et al, 1997; farreres et al, 1998) <papid> W98-0709 </papid>that was the base of the approach to building the spanish wordnet within eurowordnet2 project.</citsent>
<aftsection>
<nextsent>from then within our group several efforts have been devoted to: 1http://www.cogsci.princeton.edu/~wn/ 2http://www.hum.uva.nl/~ewn/ 1.
</nextsent>
<nextsent>validating and debugging the content of the.
</nextsent>
<nextsent>most important (higher levels in the hierarchy) and less confident (lesser scoring) synsets.
</nextsent>
<nextsent>mains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z545">
<title id=" W03-1310.xml">answering clinical questions with role identification </title>
<section> locating answers by role identification.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 why roles?.
</prevsent>
<prevsent>in gqa systems, as mentioned, in the question answer matching process, usually the answer candidates are first checked to see if they contain the expected answer type, in order to rule out irrelevantcandidates.
</prevsent>
</prevsection>
<citsent citstr=" P01-1037 ">
this is shown to be efficient, as indicated by harabagiu et al (2001): <papid> P01-1037 </papid>systems that did not include ne recognizers performed poorly in the trec evaluations.</citsent>
<aftsection>
<nextsent>the effectiveness of this method depends on successfully recognizing nes in the answer candidates.
</nextsent>
<nextsent>however, for questions that cannot be answered by named entities, the qa task is more complex, as it will be more difficult to recognize the corresponding answer type in the answer candidates.
</nextsent>
<nextsent>the same problem occurs in mqa.
</nextsent>
<nextsent>the important information in medical text usually corresponds to the basic pico fields.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z546">
<title id=" W03-1601.xml">generation of single sentence paraphrases from predicate argument structure using lexico grammatical resources </title>
<section> typical generation methodology.  </section>
<citcontext>
<prevsection>
<prevsent>enjoy experiencer theme amy interaction figure 1: the semantics underlying (2a-2b) the input is hierarchical predicate/argument structure such as that shown in fig.
</prevsent>
<prevsent>1.
</prevsent>
</prevsection>
<citsent citstr=" J90-1004 ">
the output of this process should be set of grammatical sentences whose meaning matches the original semantic input.one standard approach to sentence generation from predicate/argument structure (like the semantic-head-driven generation in (shieber et al., 1990)) <papid> J90-1004 </papid>involves simple algorithm.</citsent>
<aftsection>
<nextsent>1.
</nextsent>
<nextsent>decompose the input into the top predicate (to be realized by (single) lexical item that serves as the syntactic head) and identify the arguments and modi ers2.
</nextsent>
<nextsent>recursively realize arguments, then modi ers 3.
</nextsent>
<nextsent>combine the realizations in step 2 with the head in step 1 in realizing the input in fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z547">
<title id=" W03-1601.xml">generation of single sentence paraphrases from predicate argument structure using lexico grammatical resources </title>
<section> our generation methodology.  </section>
<citcontext>
<prevsection>
<prevsent>the key to our ability to handle paraphrases in uniform manner is that our processing is driven by our lexicon and thus we do not make any priori assumptions about 1) the amount of the input realized by lexical unit, 2) there lationship between semantic and syntactic types (and thus the syntactic rank or category of the realization of the top piece), 3) the nature ofthe mapping between thematic roles and syntactic positions, and 4) the grammatical alternation (e.g., there are dierent resources for the same verb in dierent alternations: the active,passive, topical ized, etc.).
</prevsent>
<prevsent>because this information is contained in each lexico-grammatical resource, generation can proceed no matter what choices are speci ed about these in each individual resource.
</prevsent>
</prevsection>
<citsent citstr=" P97-1026 ">
our approach is fundamentally dierent from systems that reason directly about syntax and build realizations by syntactic rank ((bateman, 1997), (elhadad et al, 1997); (nicolov et al, 1995); (stone and doran, 1997)).<papid> P97-1026 </papid></citsent>
<aftsection>
<nextsent>4.1 our algorithm.
</nextsent>
<nextsent>our generation algorithm is simple, recursive,semantic-head-driven generation process, consistent with the approach described in section 2, but one driven by the semantic input and the lexico-grammatical resources.1.
</nextsent>
<nextsent>given an unrealized input, nd lexico grammatical resource that matches portion including the top predicate and satis es any selectional restrictions2.
</nextsent>
<nextsent>recursively realize arguments, then modi ers 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z548">
<title id=" W03-1601.xml">generation of single sentence paraphrases from predicate argument structure using lexico grammatical resources </title>
<section> our generation methodology.  </section>
<citcontext>
<prevsection>
<prevsent>the syntactic sides contain the verbs enjoy and please in the active voice con guration.
</prevsent>
<prevsent>the mappings include links between enjoy and its realization as well as links between the unrealized agent (x) or theme (y) and the subject or the complement.
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
our mapping between semantic and syntactic constituents bears resemblance to the pairings in synchronous tag (shieber and schabes, 1990).<papid> C90-3045 </papid></citsent>
<aftsection>
<nextsent>just like in synchronous tag, the mapping is vpnp vp npv enjoy s 0 0 1 enjoy experiencer theme y 1 vpnp vp npv please s 0 0 1 enjoy experiencer theme y 1 figure 2: two dierent resources for enjoy critical for combining realizations (in step 3 ofour algorithm in section 4.1).
</nextsent>
<nextsent>there are, how ever, advantages that our approach has.
</nextsent>
<nextsent>for one, we are not constrained by the isomorphism requirement in synchronous tag derivation.
</nextsent>
<nextsent>also, the dsg formalism that we use aords greater exibility, signi cant in our approach, as discussed later in this paper (and in more detail in (kozlowski, 2002b)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z549">
<title id=" W03-1601.xml">generation of single sentence paraphrases from predicate argument structure using lexico grammatical resources </title>
<section> our generation methodology.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 the grammatical formalism.
</prevsent>
<prevsent>both step 3 of our algorithm (putting realizations together) and the needs of lexico grammatical resources (the encapsulation of syntactic consequences such as the position of argument realizations) place signi cant demands on the grammatical formalism to be used in the implementation of the architecture.
</prevsent>
</prevsection>
<citsent citstr=" J01-1004 ">
one grammatical formalism that is well-suited forour purposes is the d-tree substitution grammars (dsg, (rambow et al, 2001)), <papid> J01-1004 </papid>variant of tree-adjoining grammars (tag).</citsent>
<aftsection>
<nextsent>this formalism features an extended domain of locality and exibility in encapsulation of syntactic consequences, crucial in our architecture.
</nextsent>
<nextsent>consider the elementary dsg structures on the right-hand-side of the resources for enjoy and please in fig.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>note that nodes marked with # are substitution nodes corresponding to syntactic positions into which the realizations of u 0 0 1 1 vpnp vp please npvu 0 0 1 1 np the interaction amy vpnp vp enjoy figure 3: combining argument realizations with the resources for enjoy and please arguments will be substituted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z550">
<title id=" W03-0102.xml">pointing to places in a deductive geo spatial theory </title>
<section> outline of geo logica.  </section>
<citcontext>
<prevsection>
<prevsent>well present the representation of place names and discuss mechanisms for finding places corresponding to given description.
</prevsent>
<prevsent>well discuss the solution of sample problem, mention some related work, and describe proposed extensions.
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
questions are posed to geo logica in subset of english and translated into logic by natural language parser,the system gemini (dowding et al, 1993).<papid> P93-1008 </papid></citsent>
<aftsection>
<nextsent>the logical form of the question is rephrased as theorem and presented to the theorem prover snark (stickel et al,2000).
</nextsent>
<nextsent>(a knowledgeable user of geo logica may prefer to bypass the parser and phrase the query directly in logical form.)
</nextsent>
<nextsent>the geo spatial theory that snark uses for this application consists of set of axioms, logical sentences that provide definitions and describe properties of important spatial constants, functions, and relations, including those in the logical form of the query.
</nextsent>
<nextsent>when snark proves theorem, it shows that the theorem follows logically from the axioms in the theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z551">
<title id=" W02-1112.xml">using the wordnet hierarchy for associative anaphora resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, from computational perspective, the primary focus of this work is the resolution of pronominal anaphora.
</prevsent>
<prevsent>there is significantly less work on full definite np anaphora, and less still on what we will term here associativeanaphora: that is, the phenomonen in which definite referring expression is used to refer to an entity not previously mentioned in text, but the existence of which can be inferred by virtue of some previously mentioned entity.
</prevsent>
</prevsection>
<citsent citstr=" W97-1301 ">
although these referring expressions have been widely discussed in the linguistics, psychology and philosophy literature, computational approaches are relatively rare (with few notable exceptions, such as the work of (poesio et al., 1997) <papid> W97-1301 </papid>and (vieira, 1998).</citsent>
<aftsection>
<nextsent>a typical example from the literature is the use of the definite noun phrase reference in the second sentence in example (1):1 1in these examples, italics are used to indicate anaphors.
</nextsent>
<nextsent>(1) bus came around the corner.
</nextsent>
<nextsent>the driver had mean look in her eye.here, the hearer is likely to infer that the driver referred to in the second sentence belongs to the bus mentioned in the first sentence.
</nextsent>
<nextsent>for our purposes, we consider the driver to be the textual antecedent of the anaphor, and the relationship between the referents of the anaphor and antecedent to be part-of relationship.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z552">
<title id=" W02-1112.xml">using the wordnet hierarchy for associative anaphora resolution </title>
<section> the problem.  </section>
<citcontext>
<prevsection>
<prevsent>several antecedents may refer to the same entity;given an appropriate coreference resolution mechanism, this is non-problematic.
</prevsent>
<prevsent>also, we are not concerned here with with determining the precise nature of the relationship that holds between the associative anaphor and its antecedent, although in most cases we consider this will be one of meronymy.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
all we require is the ability to be able to establish connection between the entities mentioned in text, effectively knitting the semantic fabric underlying the discourse.as way of moving towards this result, our motivating observation is simple one, and one that has been explored in other areas (see, for example,(hearst, 1992; <papid> C92-2082 </papid>knott and dale, 1992)): that semantic relationships which are left implicit for reader to infer in some contexts may also occur explicitly in others, as in example (2): (2) bus nearly collided with car.</citsent>
<aftsection>
<nextsent>the driver of the bus had mean look in her eye.
</nextsent>
<nextsent>here, we have prima facie evidence of the existence of relationship between drivers and buses.
</nextsent>
<nextsent>our goal is to see whether this kind of evidence can be gathered from corpus and then used in cases where the association between the two entities is not made explicit.
</nextsent>
<nextsent>3.1 the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z553">
<title id=" W02-1112.xml">using the wordnet hierarchy for associative anaphora resolution </title>
<section> an experiment.  </section>
<citcontext>
<prevsection>
<prevsent>, and the in the case of the pattern   genitive n
</prevsent>
<prevsent>, as the head of the associative construction, and to the other head noun in each case as the modifier of the associative construction; thus, in the example under discussion, the head is head and the modifier is stingray.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
to identify associative constructions, we first process our texts using con exors fdg parser(tapanainen and jarvinen, 1997).<papid> A97-1011 </papid></citsent>
<aftsection>
<nextsent>we then use collection of regular expression matching procedures to identify the nps in the text.
</nextsent>
<nextsent>a further filter over the extracted nps identifies the expressions that meet the patterns described above; we find 17164 instances of the   np of np
</nextsent>
<nextsent>construction over 11322 types, and 5662 instances of the  genitive n
</nextsent>
<nextsent>construction over 2133 types.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z554">
<title id=" W02-1112.xml">using the wordnet hierarchy for associative anaphora resolution </title>
<section> conclusions and further work.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we have begun to consider the following.first, we can make use of word sense disambiguation to reduce the negative consequences of generalising to synsets.
</prevsent>
<prevsent>second, we intend to explore whether it is possible to determine an appropriate level of generalisation based on the class of the anaphor and antecedent.
</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
third, there is scope for building on existing work on learning selectional preferences for wsd and the resolution of syntactic ambiguity; we suspect that, in particular, the work on learning class-to-class selectional preferences by (agirre and martinez, 2001) <papid> W01-0703 </papid>may be useful here.</citsent>
<aftsection>
<nextsent>we are also looking for better ways to assess the results of using the axioms.
</nextsent>
<nextsent>two directions here are clear.
</nextsent>
<nextsent>first, so far we have only relatively small number of hand-annotated examples, from single source.
</nextsent>
<nextsent>increasing the number of example swill let us investigate questions like whether different choices of parameters are appropriate to different classes of anaphor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z555">
<title id=" W02-1024.xml">a hybrid approach to natural language web search </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>adopting similar approach as faq finder (hammond et al, 1995), ask jeeves maintains database of questions and web pages that provide answers to them.
</prevsent>
<prevsent>user questions are compared against those in the database, and links to web pages for the closest matches are returned.
</prevsent>
</prevsection>
<citsent citstr=" P01-1009 ">
similar to our approach, electric knowledge transforms natural language question into series of increasingly more general key word queries (bierner, 2001).<papid> P01-1009 </papid></citsent>
<aftsection>
<nextsent>however, their query formulation process utilizes hard-crafted regular expressions, while we adopt more general machine learning approach for transformation rule applica tion.our work is also closely related to question answering in the question analysis component (e.g., (harabagui et al, 2001; prager et al, 2000; clarke et al, 2001; ittycheriah et al, 2001)).<papid> N01-1005 </papid></nextsent>
<nextsent>in particular, harabagui et al(2001) also iteratively reformulate queries based partly on the search results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z556">
<title id=" W02-1024.xml">a hybrid approach to natural language web search </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>user questions are compared against those in the database, and links to web pages for the closest matches are returned.
</prevsent>
<prevsent>similar to our approach, electric knowledge transforms natural language question into series of increasingly more general key word queries (bierner, 2001).<papid> P01-1009 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1005 ">
however, their query formulation process utilizes hard-crafted regular expressions, while we adopt more general machine learning approach for transformation rule applica tion.our work is also closely related to question answering in the question analysis component (e.g., (harabagui et al, 2001; prager et al, 2000; clarke et al, 2001; ittycheriah et al, 2001)).<papid> N01-1005 </papid></citsent>
<aftsection>
<nextsent>in particular, harabagui et al(2001) also iteratively reformulate queries based partly on the search results.
</nextsent>
<nextsent>however, their mechanism for query reformulation is heuristic-based.
</nextsent>
<nextsent>we utilized machine learning to 1www.askjeeves.com, www.electricknowledge.com, and www.northernlight.com, respectively.
</nextsent>
<nextsent>optimize the query formulation process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z557">
<title id=" W02-1024.xml">a hybrid approach to natural language web search </title>
<section> risque: hybrid system for natural.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting parse tree is first analyzed for np/vp extraction.
</prevsent>
<prevsent>each np includes the head noun and up totwo premodifiers, which covers most nps in our domain.
</prevsent>
</prevsection>
<citsent citstr=" A97-1030 ">
the nps are further processed by named entity recognizer (prager et al, 2000; wacholder et al., 1997), <papid> A97-1030 </papid>with reference to domain-specific proper names in our ontology.</citsent>
<aftsection>
<nextsent>recognized compound terms, such as hard drive?, are treated as single entities, rather than as head nouns (drive?)
</nextsent>
<nextsent>with premodifiers (hard?).
</nextsent>
<nextsent>this prevents part of the compound term from being dropped when the dropmod ifier transformation rule is applied.
</nextsent>
<nextsent>the parse tree is also used to classify the question as buy or support.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z558">
<title id=" W03-0701.xml">combining semantic and temporal constraints for multimodal integration in conversation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in such an environment, not only are more interaction modalities available, but also richer contexts are established during the interaction.
</prevsent>
<prevsent>understanding user inputs, for example, what users refer to is important.
</prevsent>
</prevsection>
<citsent citstr=" J95-1003 ">
previous work on multimodal reference resolution includes the use of focus space model (neal et al, 1998), the centering framework (zancanaro et al, 1997), context factors (huls et al, 1995), <papid> J95-1003 </papid>and rules (kehler 2000).</citsent>
<aftsection>
<nextsent>these previous approaches focus on semantics constraints without fully addressing temporal constraints.
</nextsent>
<nextsent>in user study1, we found that the majority of user referring behavior involved one referring expression and one gesture (as in [s2, g2] in table 1).
</nextsent>
<nextsent>the earlier approaches worked well for these types of references.
</nextsent>
<nextsent>however, we found that 14.1% of the inputs were complex, which involved multiple referring expressions from speech utterances and multiple gestures (s3 in table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z559">
<title id=" W02-1603.xml">plaesarn machine aided translation tool for englishtothai </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>insufficient basic language knowledge, result of inadequate distribution in thepast, conversely, is the major obstruction for information comprehension.
</prevsent>
<prevsent>there are presently several english-thai mt systems for instance, parsit (sornlertlamvanich, 2000), plae thai,and agentdict.
</prevsent>
</prevsection>
<citsent citstr=" E89-1037 ">
the first one applies semantic transfer model via the methodology similar to the lexical functional grammar (kaplan et al., 1989) <papid> E89-1037 </papid>and it is develop with the intention of public use.</citsent>
<aftsection>
<nextsent>the latter two implicitly apply the direct transfer model with the purpose of commercial use.
</nextsent>
<nextsent>nonetheless, by limited vocabularies and translation rules, the users must accept the only one translation result that is occasionally semantically divergent or ungrammatical.
</nextsent>
<nextsent>due to the according reason, we initiated this project in order to relieve language problem of thai people.
</nextsent>
<nextsent>in this project, we develop semi-automatic translation system to assist them to translate english documents into thai.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z560">
<title id=" W02-1603.xml">plaesarn machine aided translation tool for englishtothai </title>
<section> relevant problems and their.  </section>
<citcontext>
<prevsection>
<prevsent>i was in the park and using telescope to see girl.furthermore, an example of word-sense ambiguity is live near the bank.?
</prevsent>
<prevsent>the noun bank can be semantically interpreted into at least two senses as follows.?
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
n. financial institution that accepts deposits and channels the money into lending activities ? n. sloping land (especially the slope beside body of water) in order to resolve structural ambiguity, we apply the concept of the statistical machine translation approach (brown et al, 1990).<papid> J90-2002 </papid></citsent>
<aftsection>
<nextsent>we apply the maximum-entropy-inspired parser (charniak, 1999) (so-called charniak parser) to analyze and determine the appropriate grammatical structure of an english sentence.
</nextsent>
<nextsent>from (charniak, 1999), charniak presented that the parser uses the penn tree bank tag set (marcuset al, 1994) (or ptb in abbreviation) as grammatical structure representation, and it yielded 90.1% average precision for sentences of length 40 or less, and 89.5% for sentences of length 100 and less.
</nextsent>
<nextsent>moreover, with the intention to resolve word-sense ambiguity, we embedded numerical statistic value with each translation rule (including lexical transfer rule) with the major aim of assisting to select the best translation parse tree from every possibility (charniak, 1997).
</nextsent>
<nextsent>section 3.4 will describe the method and the tool to do so.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z561">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> sense tagged corpora.  </section>
<citcontext>
<prevsection>
<prevsent>the availability of large amounts of semantically tagged data is crucial for creating successful wsd systems.
</prevsent>
<prevsent>yet, as of today, only few sense tagged corpora are publicly available.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
one of the first large scale hand tagging efforts is reported in (miller et al, 1993), <papid> H93-1061 </papid>where subset of the brown corpus was tagged with wordnet july 2002, pp.</citsent>
<aftsection>
<nextsent>116-122.
</nextsent>
<nextsent>association for computational linguistics.
</nextsent>
<nextsent>disambiguation: recent successes and future directions, philadelphia, proceedings of the siglex/senseval workshop on word sense senses.
</nextsent>
<nextsent>the corpus includes total of 234,136 tagged word occurrences, out of which 186,575are polysemous.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z562">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> sense tagged corpora.  </section>
<citcontext>
<prevsection>
<prevsent>disambiguation: recent successes and future directions, philadelphia, proceedings of the siglex/senseval workshop on word sense senses.
</prevsent>
<prevsent>the corpus includes total of 234,136 tagged word occurrences, out of which 186,575are polysemous.
</prevsent>
</prevsection>
<citsent citstr=" P94-1020 ">
there are 88,058 noun occurrences of which 70,214 are polysemous.the next significant hand tagging task was reported in (bruce and wiebe, 1994), <papid> P94-1020 </papid>where 2,476 usages of interest were manually assigned with sense tags from the longman dictionary of contemporary english (ldoce).</citsent>
<aftsection>
<nextsent>this corpus was used in various experiments, with classification accuracies ranging from 75% to 90%, depending on the algorithm and features employed.
</nextsent>
<nextsent>the high accuracy of the lexas system (ng and lee, 1996) <papid> P96-1006 </papid>is due in part to the use of largecorpora.</nextsent>
<nextsent>for this system, 192,800 word occurrences have been manually tagged with senses from wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z563">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> sense tagged corpora.  </section>
<citcontext>
<prevsection>
<prevsent>there are 88,058 noun occurrences of which 70,214 are polysemous.the next significant hand tagging task was reported in (bruce and wiebe, 1994), <papid> P94-1020 </papid>where 2,476 usages of interest were manually assigned with sense tags from the longman dictionary of contemporary english (ldoce).</prevsent>
<prevsent>this corpus was used in various experiments, with classification accuracies ranging from 75% to 90%, depending on the algorithm and features employed.</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
the high accuracy of the lexas system (ng and lee, 1996) <papid> P96-1006 </papid>is due in part to the use of largecorpora.</citsent>
<aftsection>
<nextsent>for this system, 192,800 word occurrences have been manually tagged with senses from wordnet.
</nextsent>
<nextsent>the set of tagged words consists of the 191 most frequently occurring nouns and verbs.
</nextsent>
<nextsent>the authors mention that approximately one man-year of effort was spent in tagging the dataset.
</nextsent>
<nextsent>lately, the senseval competitions provide agood environment for the development of supervised wsd systems, making freely available large amounts of sense tagged data for about 100 words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z564">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> sense tagged corpora.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, (kilgarriff, 1998) mentions the hector corpus, which comprises about 300 word types with 300-1000 tagged instances for each word, selected from 17 million word corpus.
</prevsent>
<prevsent>sense tagged corpora have thus been central to accurate wsd systems.
</prevsent>
</prevsection>
<citsent citstr=" W97-0201 ">
estimations made in (ng,1997) <papid> W97-0201 </papid>indicated that high accuracy domain independent system for wsd would probably need corpus of about 3.2 million sense tagged words.at throughput of one word per minute (edmonds, 2000), this would require about 27 man years of human annotation effort.with open mind word expert we aim at creating very large sense tagged corpus, by making use of the incredible resource of knowledge constituted by the millions of web users, combined with techniques for active learning.</citsent>
<aftsection>
<nextsent>open mind word expert is web-based interface where users can tag words with their wordnet senses.
</nextsent>
<nextsent>tagging is organized by word.
</nextsent>
<nextsent>that is, for each ambiguous word for which we want to build sense tagged corpus, users are presented with set of natural language (english) sentences that include an instance of the ambiguous word.
</nextsent>
<nextsent>initially, example sentences are extracted from large textual corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z565">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> open mind word expert.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows screen shot fromthe system interface, illustrating the screen presented to users when tagging the noun child?.
</prevsent>
<prevsent>3.1 data.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the starting corpus we use is formed by mix of three different sources of data, namely the penn treebank corpus (marcus et al, 1993), <papid> J93-2004 </papid>the los angeles times collection, as provided during trec conferences1 , and open mind commonsense2, collection of about 400,000 commonsense assertions in english as contributed by volunteers over the web.</citsent>
<aftsection>
<nextsent>a mix of several sources, each covering different spectrum of usage, is 1http://trec.nist.gov 2http://commonsense.media.mit.edu figure 1: screen shot from open mind word expert used to increase the coverage of word senses and writing styles.
</nextsent>
<nextsent>while the first two sources are well known to the nlp community, the open mind common sense constitutes fairly new textualcorpus.
</nextsent>
<nextsent>it consists mostly of simple single sentences.
</nextsent>
<nextsent>these sentences tend to be explanations and assertions similar to glosses of dictionary, but phrased in more common language and with many sentences per sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z566">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> open mind word expert.  </section>
<citcontext>
<prevsection>
<prevsent>the features are selected from pool of eighteen different features that have been previously acknowledged as good indicators ofword sense, including: part of speech of the ambiguous word itself, surrounding words and their parts of speech, keywords in context, noun before and after, verb before and after, and others.
</prevsent>
<prevsent>an iterative forward search algorithm identifies at each step the feature that leads to the highestcross-validation precision computed on the training data.
</prevsent>
</prevsection>
<citsent citstr=" C02-1039 ">
more details on this system can be found in (mihalcea, 2002<papid> C02-1039 </papid>b).</citsent>
<aftsection>
<nextsent>the second classifier is constraint-based language tagger (cobalt).
</nextsent>
<nextsent>the system treats every training example as set of soft constraints on the sense of the word of interest.
</nextsent>
<nextsent>wordnet glosses, hyponyms, hyponym glosses and other wordnet data is also used to create soft constraints.
</nextsent>
<nextsent>currently, only keywords in context?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z568">
<title id=" W02-0817.xml">building a sense tagged corpus with open mind word expert </title>
<section> open mind word expert.  </section>
<citcontext>
<prevsection>
<prevsent>this will be implemented if there are indications of need for this in the pilot; it will help screen out contributors who, for example, always select the first sense (andare in high agreement with other contributors who do the same).
</prevsent>
<prevsent>in all, automatic assessment of the quality of tagging seems possible, and, based on the experience of prior volunteer contribution projects (singh, 2002), the rate of maliciously misleading or incorrect contributions is surprisingly low.additionally, the tagging quality will be estimated by comparing the agreement level among web contributors with the agreement level that was already measured in previous sense tagging projects.
</prevsent>
</prevsection>
<citsent citstr=" W97-0206 ">
an analysis of the semantic annotation task performed by novice taggers as part of the semcor project (fellbaum et al, 1997) <papid> W97-0206 </papid>revealed an agreement of about 82.5% among novice taggers, and 75.2% among novice taggers and lexi cographers.</citsent>
<aftsection>
<nextsent>moreover, since we plan to use paid, trained taggers to create separate test corpus for eachof the words tagged with open mind word expert, these same paid taggers could also validate small percentage of the training data for which no gold standard exists.
</nextsent>
<nextsent>3.4 engaging the contributors.
</nextsent>
<nextsent>we believe that making the contribution proces sas engaging and as game-like?
</nextsent>
<nextsent>for the contributors as possible is crucial to collecting large volume of data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z571">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in terms of parsing development, it is broadly assumed that parsers need such information in order to reduce the number of possible analyses and, therefore, solve syntactic ambiguity.
</prevsent>
<prevsent>over the last years various methods for acquiring subcategorisation information from corpora has been proposed.
</prevsent>
</prevsection>
<citsent citstr=" J93-2002 ">
some of them induce syntactic subcategorisation from tagged texts (brent, 1993; <papid> J93-2002 </papid>briscoe and carrol, 1997; marques, 2000).</citsent>
<aftsection>
<nextsent>unfortunately, syntactic information is not enough to solve structural ambiguity.
</nextsent>
<nextsent>consider the following verbal phrases: (1) [peel [  the potato] [  with knife]] (2) [peel [  [  the potato] [  with rough stain]]] the attachment of with pp?
</nextsent>
<nextsent>to both the verb peel?
</nextsent>
<nextsent>in phrase (1) and to the np the potato?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z572">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in general, we know that knifes are used for peeling, and potatoes can have different kinds of stains.
</prevsent>
<prevsent>so, the parser is able to propose correct analysis only if the lexicon is provided with, not only syntactic subcategorisation information, but also with information on semantic-pragmatic requirements (i.e., with selection restrictions).other works attempt to acquire selection restrictions requiring pre-existing lexical ressources.
</prevsent>
</prevsection>
<citsent citstr=" W97-0209 ">
the learning algorithm requires sample corpora to be constituted by verb-noun, noun-verb, or verb-prepnoun dependencies, where the nouns are semantically tagged by using lexical hierarchies such as wordnet (resnik, 1997; <papid> W97-0209 </papid>framis, 1995).</citsent>
<aftsection>
<nextsent>selection restrictions are induced by considering those dependencies associated with the same semantic tags.
</nextsent>
<nextsent>for instance, if verb ratify frequently appears with nouns semantically tagged as legal documents?
</nextsent>
<nextsent>in the direct object position (e.g., article, law, precept, . . .
</nextsent>
<nextsent>),then it follows that it must select for nouns denoting legal documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z573">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>acl special interest group on the lexicon (siglex), philadelphia, unsupervised lexical acquisition: proceedings of the workshop of the set of semantic tags is used to annotate the training corpus, it is not obvious that the tags available are the more appropriate for extracting domain-specificsemantic restrictions.
</prevsent>
<prevsent>if the tags were created specifically to capture corpus dependent restrictions, there could be serious problems concerning portability to new specific domain.
</prevsent>
</prevsection>
<citsent citstr=" A92-1014 ">
by contrast, unsupervised strategies to acquire selection restrictions do not require training corpus to be semantically annotated using pre-existing lexical hierarchies (sekine et al, 1992; <papid> A92-1014 </papid>dagan etal., 1998; grishman and sterling, 1994).<papid> C94-2119 </papid></citsent>
<aftsection>
<nextsent>they require only minimum of linguistic knowledge in order to identify meaningful?
</nextsent>
<nextsent>syntactic dependencies.
</nextsent>
<nextsent>according to the grefenstettes terminology, they can be classified as knowledge-poor approaches?(grefenstette, 1994).
</nextsent>
<nextsent>semantic preferences are induced by merely using co-occurrence data, i.e., by using similarity measure to identify words which occur in the same dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z574">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>acl special interest group on the lexicon (siglex), philadelphia, unsupervised lexical acquisition: proceedings of the workshop of the set of semantic tags is used to annotate the training corpus, it is not obvious that the tags available are the more appropriate for extracting domain-specificsemantic restrictions.
</prevsent>
<prevsent>if the tags were created specifically to capture corpus dependent restrictions, there could be serious problems concerning portability to new specific domain.
</prevsent>
</prevsection>
<citsent citstr=" C94-2119 ">
by contrast, unsupervised strategies to acquire selection restrictions do not require training corpus to be semantically annotated using pre-existing lexical hierarchies (sekine et al, 1992; <papid> A92-1014 </papid>dagan etal., 1998; grishman and sterling, 1994).<papid> C94-2119 </papid></citsent>
<aftsection>
<nextsent>they require only minimum of linguistic knowledge in order to identify meaningful?
</nextsent>
<nextsent>syntactic dependencies.
</nextsent>
<nextsent>according to the grefenstettes terminology, they can be classified as knowledge-poor approaches?(grefenstette, 1994).
</nextsent>
<nextsent>semantic preferences are induced by merely using co-occurrence data, i.e., by using similarity measure to identify words which occur in the same dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z575">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this case, the noun means particular kind of process.
</prevsent>
<prevsent>it seems obvious that its similar words, secretary and council, cannot appear insuch subcategorisation contexts, since they are related to the other sense of the word.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
soft clusters, in which words can be members of different clusters to different degrees, might solve this problem to acer tain extent (pereira et al, 1993).<papid> P93-1024 </papid></citsent>
<aftsection>
<nextsent>we claim, how ever, that class membership should be modeled by boolean decisions.
</nextsent>
<nextsent>since subcategorisation contexts require words in boolean terms (i.e., words are either required or not required), words are either members or not members of specific subcagorisation classes.
</nextsent>
<nextsent>hence, we propose clustering method in which aword may be gathered into different boolean clusters, each cluster representing the semantic restrictions imposed by class of subcategorisation contexts.
</nextsent>
<nextsent>this paper describes an unsupervised method for acquiring information on syntactic and semantic subcategorisation from partially parsed text corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z576">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>millions of word occurrences.
</prevsent>
<prevsent>we need larger annotated corpor ato improve the learning task, in particular, concerning verb subcategorisation.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
as we do not propose long distance attachments, our method can not be compared with other standard corpus-based approaches to attachment resolution (hindle and rooth, 1993; <papid> J93-1005 </papid>brill and resnik, 1994; <papid> C94-2195 </papid>li and abe, 1998).<papid> P98-2124 </papid></citsent>
<aftsection>
<nextsent>long distance attachments only will be considered after having achieved the corrections for immediate dependencies in the first cycle of syntactic analysis.
</nextsent>
<nextsent>we are currently working on the specification of new analysis cycles in order to long distance attachments be solved.
</nextsent>
<nextsent>consider again the phrase emanou de facto da lei.
</nextsent>
<nextsent>at the second cycle, the diagnoser proposed that the first pp de facto is not corrected attached to emanou.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z577">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>millions of word occurrences.
</prevsent>
<prevsent>we need larger annotated corpor ato improve the learning task, in particular, concerning verb subcategorisation.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
as we do not propose long distance attachments, our method can not be compared with other standard corpus-based approaches to attachment resolution (hindle and rooth, 1993; <papid> J93-1005 </papid>brill and resnik, 1994; <papid> C94-2195 </papid>li and abe, 1998).<papid> P98-2124 </papid></citsent>
<aftsection>
<nextsent>long distance attachments only will be considered after having achieved the corrections for immediate dependencies in the first cycle of syntactic analysis.
</nextsent>
<nextsent>we are currently working on the specification of new analysis cycles in order to long distance attachments be solved.
</nextsent>
<nextsent>consider again the phrase emanou de facto da lei.
</nextsent>
<nextsent>at the second cycle, the diagnoser proposed that the first pp de facto is not corrected attached to emanou.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z578">
<title id=" W02-0905.xml">using co composition for acquiring syntactic and semantic subcategorisation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>millions of word occurrences.
</prevsent>
<prevsent>we need larger annotated corpor ato improve the learning task, in particular, concerning verb subcategorisation.
</prevsent>
</prevsection>
<citsent citstr=" P98-2124 ">
as we do not propose long distance attachments, our method can not be compared with other standard corpus-based approaches to attachment resolution (hindle and rooth, 1993; <papid> J93-1005 </papid>brill and resnik, 1994; <papid> C94-2195 </papid>li and abe, 1998).<papid> P98-2124 </papid></citsent>
<aftsection>
<nextsent>long distance attachments only will be considered after having achieved the corrections for immediate dependencies in the first cycle of syntactic analysis.
</nextsent>
<nextsent>we are currently working on the specification of new analysis cycles in order to long distance attachments be solved.
</nextsent>
<nextsent>consider again the phrase emanou de facto da lei.
</nextsent>
<nextsent>at the second cycle, the diagnoser proposed that the first pp de facto is not corrected attached to emanou.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z579">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, several algorithms have been developed to acquire semantic lexicons automatically or semi-automatically using corpus-based techniques.
</prevsent>
<prevsent>for our purposes, the term semantic lexicon will refer to dictionary of words labeled with semantic classes (e.g., \bird  is an animal and \truck  is vehicle).
</prevsent>
</prevsection>
<citsent citstr=" P99-1042 ">
semantic class information has proven to be useful for many natural language processing tasks, including information extraction (rilo and schmelzenbach, 1998; soderland et al, 1995), anaphora resolution (aone and bennett, 1996), question answering (moldovan et al, 1999; hirschman et al, 1999), <papid> P99-1042 </papid>and prepositional phrase attachment (brill and resnik, 1994).<papid> C94-2195 </papid></citsent>
<aftsection>
<nextsent>although some semantic dictionaries do exist (e.g., wordnet (miller, 1990)), these resources often do not contain the specialized vocabulary and jargon that is needed for speci domains.
</nextsent>
<nextsent>even for relatively general texts, such as the wall street journal(marcus et al, 1993) <papid> J93-2004 </papid>or terrorism articles (muc 4 proceedings, 1992), roark and charniak (roark.</nextsent>
<nextsent>and charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z580">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, several algorithms have been developed to acquire semantic lexicons automatically or semi-automatically using corpus-based techniques.
</prevsent>
<prevsent>for our purposes, the term semantic lexicon will refer to dictionary of words labeled with semantic classes (e.g., \bird  is an animal and \truck  is vehicle).
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
semantic class information has proven to be useful for many natural language processing tasks, including information extraction (rilo and schmelzenbach, 1998; soderland et al, 1995), anaphora resolution (aone and bennett, 1996), question answering (moldovan et al, 1999; hirschman et al, 1999), <papid> P99-1042 </papid>and prepositional phrase attachment (brill and resnik, 1994).<papid> C94-2195 </papid></citsent>
<aftsection>
<nextsent>although some semantic dictionaries do exist (e.g., wordnet (miller, 1990)), these resources often do not contain the specialized vocabulary and jargon that is needed for speci domains.
</nextsent>
<nextsent>even for relatively general texts, such as the wall street journal(marcus et al, 1993) <papid> J93-2004 </papid>or terrorism articles (muc 4 proceedings, 1992), roark and charniak (roark.</nextsent>
<nextsent>and charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z581">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic class information has proven to be useful for many natural language processing tasks, including information extraction (rilo and schmelzenbach, 1998; soderland et al, 1995), anaphora resolution (aone and bennett, 1996), question answering (moldovan et al, 1999; hirschman et al, 1999), <papid> P99-1042 </papid>and prepositional phrase attachment (brill and resnik, 1994).<papid> C94-2195 </papid></prevsent>
<prevsent>although some semantic dictionaries do exist (e.g., wordnet (miller, 1990)), these resources often do not contain the specialized vocabulary and jargon that is needed for speci domains.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
even for relatively general texts, such as the wall street journal(marcus et al, 1993) <papid> J93-2004 </papid>or terrorism articles (muc 4 proceedings, 1992), roark and charniak (roark.</citsent>
<aftsection>
<nextsent>and charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in wordnet.
</nextsent>
<nextsent>these results suggest that automatic semantic lexicon acquisition could be used to enhance existing resources such as wordnet, or to produce semantic lexicons for specialized domains.we have developed weakly supervised bootstrapping algorithm called basilisk that automatically generates semantic lexicons.
</nextsent>
<nextsent>basilisk hypothesizes the semantic class of word by gathering collective evidence about semantic associations from extraction pattern contexts.
</nextsent>
<nextsent>basilisk also learns multiple semantic classes simultaneously, which helps constrain the bootstrapping process.first, we present basilisks bootstrapping algorithm and explain how it diers from previous work on semantic lexicon induction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z582">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> bootstrapping using collective.  </section>
<citcontext>
<prevsection>
<prevsent>the pattern pool and the candidate word pool are then emptied, and the bootstrapping process starts over again.
</prevsent>
<prevsent>2.1.3 related work several weakly supervised learning algorithm shave previously been developed to generate semantic lexicons from text corpora.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
rilo and shepherd(rilo and shepherd, 1997) developed bootstrapping algorithm that exploits lexical co-occurrence statistics, and roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>re ned this algorithm to focus more explicitly on certain syntactic structures.</citsent>
<aftsection>
<nextsent>hale, ge, and charniak (ge et al, 1998) <papid> W98-1119 </papid>devised technique to learn the gender of words.</nextsent>
<nextsent>caraballo (caraballo, 1999) <papid> P99-1016 </papid>and hearst (hearst, 1992) <papid> C92-2082 </papid>created techniques to learn hypernym/hyponym relationships.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z583">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> bootstrapping using collective.  </section>
<citcontext>
<prevsection>
<prevsent>2.1.3 related work several weakly supervised learning algorithm shave previously been developed to generate semantic lexicons from text corpora.
</prevsent>
<prevsent>rilo and shepherd(rilo and shepherd, 1997) developed bootstrapping algorithm that exploits lexical co-occurrence statistics, and roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>re ned this algorithm to focus more explicitly on certain syntactic structures.</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
hale, ge, and charniak (ge et al, 1998) <papid> W98-1119 </papid>devised technique to learn the gender of words.</citsent>
<aftsection>
<nextsent>caraballo (caraballo, 1999) <papid> P99-1016 </papid>and hearst (hearst, 1992) <papid> C92-2082 </papid>created techniques to learn hypernym/hyponym relationships.</nextsent>
<nextsent>none of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations.several learning algorithms have also been developed for named entity recognition (e.g., (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)).(<papid> W99-0612 </papid>collins and singer, 1999) <papid> W99-0613 </papid>used contextual information of dierent sort than we do.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z584">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> bootstrapping using collective.  </section>
<citcontext>
<prevsection>
<prevsent>rilo and shepherd(rilo and shepherd, 1997) developed bootstrapping algorithm that exploits lexical co-occurrence statistics, and roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>re ned this algorithm to focus more explicitly on certain syntactic structures.</prevsent>
<prevsent>hale, ge, and charniak (ge et al, 1998) <papid> W98-1119 </papid>devised technique to learn the gender of words.</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
caraballo (caraballo, 1999) <papid> P99-1016 </papid>and hearst (hearst, 1992) <papid> C92-2082 </papid>created techniques to learn hypernym/hyponym relationships.</citsent>
<aftsection>
<nextsent>none of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations.several learning algorithms have also been developed for named entity recognition (e.g., (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)).(<papid> W99-0612 </papid>collins and singer, 1999) <papid> W99-0613 </papid>used contextual information of dierent sort than we do.</nextsent>
<nextsent>furthermore, our research aims to learn general nouns (e.g., \artist ) rather than proper nouns, so many of the features commonly used to great advantage for named entity recognition (e.g., capitalization and title words) are not applicable to our task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z585">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> bootstrapping using collective.  </section>
<citcontext>
<prevsection>
<prevsent>rilo and shepherd(rilo and shepherd, 1997) developed bootstrapping algorithm that exploits lexical co-occurrence statistics, and roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>re ned this algorithm to focus more explicitly on certain syntactic structures.</prevsent>
<prevsent>hale, ge, and charniak (ge et al, 1998) <papid> W98-1119 </papid>devised technique to learn the gender of words.</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
caraballo (caraballo, 1999) <papid> P99-1016 </papid>and hearst (hearst, 1992) <papid> C92-2082 </papid>created techniques to learn hypernym/hyponym relationships.</citsent>
<aftsection>
<nextsent>none of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations.several learning algorithms have also been developed for named entity recognition (e.g., (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)).(<papid> W99-0612 </papid>collins and singer, 1999) <papid> W99-0613 </papid>used contextual information of dierent sort than we do.</nextsent>
<nextsent>furthermore, our research aims to learn general nouns (e.g., \artist ) rather than proper nouns, so many of the features commonly used to great advantage for named entity recognition (e.g., capitalization and title words) are not applicable to our task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z586">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> bootstrapping using collective.  </section>
<citcontext>
<prevsection>
<prevsent>hale, ge, and charniak (ge et al, 1998) <papid> W98-1119 </papid>devised technique to learn the gender of words.</prevsent>
<prevsent>caraballo (caraballo, 1999) <papid> P99-1016 </papid>and hearst (hearst, 1992) <papid> C92-2082 </papid>created techniques to learn hypernym/hyponym relationships.</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
none of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations.several learning algorithms have also been developed for named entity recognition (e.g., (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)).(<papid> W99-0612 </papid>collins and singer, 1999) <papid> W99-0613 </papid>used contextual information of dierent sort than we do.</citsent>
<aftsection>
<nextsent>furthermore, our research aims to learn general nouns (e.g., \artist ) rather than proper nouns, so many of the features commonly used to great advantage for named entity recognition (e.g., capitalization and title words) are not applicable to our task.
</nextsent>
<nextsent>the algorithm most closely related to basilisk is meta-bootstrapping (rilo and jones, 1999), which also uses extraction pattern contexts for semantic lexicon induction.
</nextsent>
<nextsent>meta-bootstrapping identi es single extraction pattern that is highly correlated with semantic category and then assumes that all ofits extracted noun phrases belong to the same category.
</nextsent>
<nextsent>however, this assumption is often violated, which allows incorrect terms to enter the lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z587">
<title id=" W02-1028.xml">a bootstrapping method for learning semantic lexicons using extraction pattern contexts </title>
<section> bootstrapping using collective.  </section>
<citcontext>
<prevsection>
<prevsent>hale, ge, and charniak (ge et al, 1998) <papid> W98-1119 </papid>devised technique to learn the gender of words.</prevsent>
<prevsent>caraballo (caraballo, 1999) <papid> P99-1016 </papid>and hearst (hearst, 1992) <papid> C92-2082 </papid>created techniques to learn hypernym/hyponym relationships.</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
none of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations.several learning algorithms have also been developed for named entity recognition (e.g., (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)).(<papid> W99-0612 </papid>collins and singer, 1999) <papid> W99-0613 </papid>used contextual information of dierent sort than we do.</citsent>
<aftsection>
<nextsent>furthermore, our research aims to learn general nouns (e.g., \artist ) rather than proper nouns, so many of the features commonly used to great advantage for named entity recognition (e.g., capitalization and title words) are not applicable to our task.
</nextsent>
<nextsent>the algorithm most closely related to basilisk is meta-bootstrapping (rilo and jones, 1999), which also uses extraction pattern contexts for semantic lexicon induction.
</nextsent>
<nextsent>meta-bootstrapping identi es single extraction pattern that is highly correlated with semantic category and then assumes that all ofits extracted noun phrases belong to the same category.
</nextsent>
<nextsent>however, this assumption is often violated, which allows incorrect terms to enter the lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z590">
<title id=" W03-0420.xml">maximum entropy models for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>starting with an annotated corpus and set of features which are easily obtainable for almost any language, we first build baseline ne recognizer which is then used to extract the named entities and their context information from additional non annotated data.
</prevsent>
<prevsent>in turn, these lists are incorporated into the final recognizer to further im prove the recognition accuracy.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in this paper, we present an approach for extracting the named entities (ne) of natural language inputs which uses the maximum entropy (me) framework (berger et al., 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the objective can be described as follows.
</nextsent>
<nextsent>given natural input sequence            we choose the ne tag sequence           with the highest probability among all possible tag sequences:       fffiffifl !
</nextsent>
<nextsent>the argmax operation denotes the search problem, i.e.the generation of the sequence of named entities.
</nextsent>
<nextsent>according to the conll-2003 competition, we concentrate on four types of named entities: persons (per), locations (loc), organizations (org), and names of miscellaneous entities (misc) that do not belong to the previous three groups, e.g.[per clinton] [org ballybunion] fans invited to [loc chicago] . additionally, the task requires the processing of two different languages from which only english was specified before the submission deadline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z592">
<title id=" W03-0420.xml">maximum entropy models for named entity recognition </title>
<section> maximum entropy models.  </section>
<citcontext>
<prevsection>
<prevsent>    9  : cy9;   (   *  21  2160     /70 )130 ,  therefore, the time-consuming re normalization in eq.
</prevsent>
<prevsent>1 is not needed during search.
</prevsent>
</prevsection>
<citsent citstr=" M98-1018 ">
we run viterbi search to find the highest probability sequence (borthwick et al, 1998).<papid> M98-1018 </papid></citsent>
<aftsection>
<nextsent>experiments were performed on english and german testsets.
</nextsent>
<nextsent>the english data was derived from the reuters cor pus1 while the german test sets were extracted from theeci multilingual text corpus.
</nextsent>
<nextsent>the datasets contain tokens (words and punctuation marks), information about the sentence boundaries, as well as the assigned ne tags.
</nextsent>
<nextsent>additionally, pos tag and syntactic chunk tag were assigned to each token.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z593">
<title id=" W03-1315.xml">an investigation of various information sources for classifying biological names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate the extent to which different sources of information contribute towards the task of classifying the type of biological entity phrase might refer to.
</prevsent>
<prevsent>the classification task is an integral part of named entity extraction.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
for this reason, name classification has been studied in solving the named entity extraction task in the nlp and information extraction communities (see, for example, (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>and various approaches reported in the muc conferences (muc-6, 1995)).</citsent>
<aftsection>
<nextsent>however,many of these approaches do not distinguish the detection of the names (i.e., identifying sequence of characters and words in text as name) from that of its classification as separate phases.
</nextsent>
<nextsent>yet, we believe that we will gain from examining the two as separate tasks as the classification task, the focus of this work, is sufficiently distinct from the name identification task.
</nextsent>
<nextsent>more importantly, from the perspective of the current work, we hope to show that the sources of information that help in solving the two tasks are quite distinct.similar to the approaches of name classification of (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999), <papid> W99-0612 </papid>we investigate both name intern aland external clues.</nextsent>
<nextsent>however, we believe that the situation in the specialized domain of biomedicine is sufficiently distinct, that the clues for this domain need further investigation and that the classification task has not received the similar attention deserved.a large number of name extraction methods proposed in this specialized domain have focused on extracting protein names only (fukuda et al, 1998; franzen et al, 2002; tanabe et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z596">
<title id=" W03-1315.xml">an investigation of various information sources for classifying biological names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we investigate the extent to which different sources of information contribute towards the task of classifying the type of biological entity phrase might refer to.
</prevsent>
<prevsent>the classification task is an integral part of named entity extraction.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
for this reason, name classification has been studied in solving the named entity extraction task in the nlp and information extraction communities (see, for example, (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>and various approaches reported in the muc conferences (muc-6, 1995)).</citsent>
<aftsection>
<nextsent>however,many of these approaches do not distinguish the detection of the names (i.e., identifying sequence of characters and words in text as name) from that of its classification as separate phases.
</nextsent>
<nextsent>yet, we believe that we will gain from examining the two as separate tasks as the classification task, the focus of this work, is sufficiently distinct from the name identification task.
</nextsent>
<nextsent>more importantly, from the perspective of the current work, we hope to show that the sources of information that help in solving the two tasks are quite distinct.similar to the approaches of name classification of (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999), <papid> W99-0612 </papid>we investigate both name intern aland external clues.</nextsent>
<nextsent>however, we believe that the situation in the specialized domain of biomedicine is sufficiently distinct, that the clues for this domain need further investigation and that the classification task has not received the similar attention deserved.a large number of name extraction methods proposed in this specialized domain have focused on extracting protein names only (fukuda et al, 1998; franzen et al, 2002; tanabe et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z601">
<title id=" W03-1315.xml">an investigation of various information sources for classifying biological names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, many information extraction methods are based on identifying or inducing patterns by which information (of the kind being extracted) is expressed in natural language text.
</prevsent>
<prevsent>if we can tag the text with occurrences of various types of names (or phrases that refer to biological entities) then better generalizations of patterns can be induced.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
there are at least two efforts (narayanaswamy et al., 2003; kazama et al, 2002) <papid> W02-0301 </papid>that consider the recognition of names of different classes of biomedical relevance.</citsent>
<aftsection>
<nextsent>work reported in (pustejovsky et al, 2002; castano et al, 2002) also seeks to classify or find the sortal information of phrases that refer to biological entities.
</nextsent>
<nextsent>however, classification was notthe primary focus of these papers and hence the details and accuracy of the classification methods are not described in much detail.
</nextsent>
<nextsent>other related works include those of (hatzivassiloglou et al, 2001; liu et al, 2001) that use external or contextual clues to disambiguate ambiguous expressions.
</nextsent>
<nextsent>while these works maybe viewed as similar to word sense disambiguation (wsd), the one reported in (hatzivassiloglou et al, 2001) in particular is close to classification as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z606">
<title id=" W03-1315.xml">an investigation of various information sources for classifying biological names </title>
<section> sources of information for name.  </section>
<citcontext>
<prevsection>
<prevsent>we now turn our attention to looking at clues that are outside the name being classified.
</prevsent>
<prevsent>using context has been widely used for wsd and has also been applied to name classification (for example, in (collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)).<papid> W99-0612 </papid>this approach has also been adopted for the biomedical domain as illustrated in the work of (hatzivas siloglou et al, 2001; narayanaswamy et al, 2003; castano et al, 2002)2.</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in the wsd work involving the use of context, we can find two approaches: one that uses few strong contextual evidences for disambiguation purposes, as exemplified by (yarowsky, 1995); <papid> P95-1026 </papid>and the other that uses weaker evidences but considers combination of number of them, as exemplified by (galeet al, 1992).</citsent>
<aftsection>
<nextsent>we explore both the methods.
</nextsent>
<nextsent>in section 4.4, we discuss our formulation and present simple way of extracting contextual clues.
</nextsent>
<nextsent>2(castano et al, 2002) can be seen as using context in its type coercion rules.
</nextsent>
<nextsent>3.1 division of the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z608">
<title id=" W03-1010.xml">a plethora of methods for learning english count ability </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(countable) vs. please use white paper substance to be written on?
</prevsent>
<prevsent>(uncountable).
</prevsent>
</prevsection>
<citsent citstr=" P03-1059 ">
this research complements that described in baldwin and bond (2003), <papid> P03-1059 </papid>where we present the linguistic foundations and features drawn upon in the count ability classification task, and motivate the claim that count ability preferences can be learned from corpus evidence.</citsent>
<aftsection>
<nextsent>in this paper, we focus on the methods used to tackle the task of count ability classification based on this fixed feature set.the remainder of this paper is structured as follows.
</nextsent>
<nextsent>section 2 outlines the count ability classes, resources and pre-processors.
</nextsent>
<nextsent>section 3 presents two methods of representing the feature space.
</nextsent>
<nextsent>section 4 details the different classifier designs and the dataset, which are then evaluated in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z610">
<title id=" W03-1010.xml">a plethora of methods for learning english count ability </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>the values for the features described above were extracted from the written component of the british national corpus (bnc, burnard (2000)) using three different pre-processors: (a) pos tagger, (b) full text chunker and (c) dependency parser.
</prevsent>
<prevsent>these areused independently to test the efficacy of the different systems at capturing features used in the classification process, and in tandem to consolidate the strengths of the individual methods.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
with the pos extraction method, we first tagged the bnc using an fntbl-based tagger (ngai and florian, 2001) <papid> N01-1006 </papid>trained over the brown and wsj corpora and based on the penn pos tagset.</citsent>
<aftsection>
<nextsent>we then lemmatised this data using penn tagset-customised version of morph (minnen et al, 2001).
</nextsent>
<nextsent>finally, we implemented range of high-precision, low-recall pos-based templates to extract out the features from the processed data.for the chunker, we ran fntbl over the lemmatised tagged data, training over conll 2000style (tjong kim sang and buchholz, 2000) chunk converted versions of the full brown and wsj corpora.
</nextsent>
<nextsent>for the np-internal features (e.g. determiners, head number), we used the noun chunks directly, or applied pos-based templates locally within noun chunks.
</nextsent>
<nextsent>for inter-chunk features (e.g. subject verb agreement), we looked at only adjacent chunk pairs so as to maintain high level of precision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z611">
<title id=" W03-1010.xml">a plethora of methods for learning english count ability </title>
<section> feature representation.  </section>
<citcontext>
<prevsection>
<prevsent>tok(f s,w)(sys?)| |tok(f s,w)(sys?)
</prevsent>
<prevsent>tok(f s,w)(sys?)|where tok (f s,w)(sys i) returns the set of token instances of (f s,w).
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the ? statistic (carletta, 1996) <papid> J96-2004 </papid>is recast as: ?(f s,w)(sys?, sys?)</citsent>
<aftsection>
<nextsent>= agr(f s,w)(sys?, sys?)?
</nextsent>
<nextsent>agr(f s,?)(sys?,sys?)
</nextsent>
<nextsent>n ??
</nextsent>
<nextsent>agr(f s,?)(sys?,sys?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z613">
<title id=" W02-1508.xml">parallel distributed grammar engineering for practical applications </title>
<section> integrated competence and.  </section>
<citcontext>
<prevsection>
<prevsent>tion, was designed to meet al of the requirements identified in the dfki ? yy case study.
</prevsent>
<prevsent>generally speaking, the [incr tsdb()] environment is an integrated package for diagnostics, evaluation, and benchmarking in practical grammar and system engineering.
</prevsent>
</prevsection>
<citsent citstr=" P94-1040 ">
the toolkit implements an approach to grammar development and system optimization that builds on precise empirical data and systematic experimentation, as it has been advocated by, among others, erbach &amp; uszkoreit (1990), erbach (1991), and carroll (1994).<papid> P94-1040 </papid></citsent>
<aftsection>
<nextsent>[incr tsdb()] has been integrated with, as of june 2002, nine differentconstraint-based grammar development and parsing systems (including both environments in use atyy, i.e. the lkb and pet), thus providing pre standard reference point for relatively large (and growing) community of nlp developers.
</nextsent>
<nextsent>the [incrtsdb()] environment builds on the following components and modules:?
</nextsent>
<nextsent>test and reference data stored with annotations in structured database; annotations can range from minimal information (unique test item identifier, item origin, length et al) to fine-grained linguistic classifications (e.g.regarding grammaticality and linguistic phenomena presented in an item), as they are represented in the tsnlp test suites, for example (oepen, netter, &amp; klein, 1997); ? tools to browse the available data, identify suitable subsets and feed them through the analysis component of processing systems like the lkb and pet, lilfes (makino, yoshida, torisawa, &amp; tsujii, 1998), trale (penn, 2000), page (uszkoreit et al, 1994), <papid> C94-1072 </papid>and others; ? the ability to gather multitude of precise andfine-grained (grammar) competence and (system) performance measures like the number of readings obtained per test item, various time and memory usage statistics, ambiguity and non-determinism metrics, and salient properties of the result structure sand store them in uniform, platform-independent data format as competence and performance pro file; and ? graphical facilities to inspect the resulting profiles, analyze system competence (i.e. grammatical coverage and overgeneration) and performance (e.g. cpu time and memory usage, parser search space, constraint solver   &amp; $ % parser 3parser 2parser 1grammar 3grammar 2grammar 1 testset 3testset 2testset 1 parallelvirtualmachine and lisp apirelationaldbms batch control statistics user interface ansi common-lisp tcl/tkfigure 1: rough sketch of [incr tsdb()] architecture: the core engine comprises the database management, batch control and statistics component, and the user interface.workload, and others) at variable granularities, aggregate, correlate, and visualize the data, and compare among profiles obtained from previous grammar or system versions or other processing environments.</nextsent>
<nextsent>as it is depicted in figure 1, the [incr tsdb()] architecture can be broken down into three majorparts: (i) the underlying database management system (dbms), (ii) the batch control and statistics kernel (providing c and lisp application program interface to client systems that can be distributed across the network), and (iii) the graphical user interface (gui).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z614">
<title id=" W02-1508.xml">parallel distributed grammar engineering for practical applications </title>
<section> integrated competence and.  </section>
<citcontext>
<prevsection>
<prevsent>[incr tsdb()] has been integrated with, as of june 2002, nine differentconstraint-based grammar development and parsing systems (including both environments in use atyy, i.e. the lkb and pet), thus providing pre standard reference point for relatively large (and growing) community of nlp developers.
</prevsent>
<prevsent>the [incrtsdb()] environment builds on the following components and modules:?
</prevsent>
</prevsection>
<citsent citstr=" C94-1072 ">
test and reference data stored with annotations in structured database; annotations can range from minimal information (unique test item identifier, item origin, length et al) to fine-grained linguistic classifications (e.g.regarding grammaticality and linguistic phenomena presented in an item), as they are represented in the tsnlp test suites, for example (oepen, netter, &amp; klein, 1997); ? tools to browse the available data, identify suitable subsets and feed them through the analysis component of processing systems like the lkb and pet, lilfes (makino, yoshida, torisawa, &amp; tsujii, 1998), trale (penn, 2000), page (uszkoreit et al, 1994), <papid> C94-1072 </papid>and others; ? the ability to gather multitude of precise andfine-grained (grammar) competence and (system) performance measures like the number of readings obtained per test item, various time and memory usage statistics, ambiguity and non-determinism metrics, and salient properties of the result structure sand store them in uniform, platform-independent data format as competence and performance pro file; and ? graphical facilities to inspect the resulting profiles, analyze system competence (i.e. grammatical coverage and overgeneration) and performance (e.g. cpu time and memory usage, parser search space, constraint solver   &amp; $ % parser 3parser 2parser 1grammar 3grammar 2grammar 1 testset 3testset 2testset 1 parallelvirtualmachine and lisp apirelationaldbms batch control statistics user interface ansi common-lisp tcl/tkfigure 1: rough sketch of [incr tsdb()] architecture: the core engine comprises the database management, batch control and statistics component, and the user interface.workload, and others) at variable granularities, aggregate, correlate, and visualize the data, and compare among profiles obtained from previous grammar or system versions or other processing environments.</citsent>
<aftsection>
<nextsent>as it is depicted in figure 1, the [incr tsdb()] architecture can be broken down into three majorparts: (i) the underlying database management system (dbms), (ii) the batch control and statistics kernel (providing c and lisp application program interface to client systems that can be distributed across the network), and (iii) the graphical user interface (gui).
</nextsent>
<nextsent>although, historically, thedbms was developed independently and the kernel can be operated without the gui, the full functionality of the integrated competence and performance laboratory as demonstrated belowonlyemerges from the combination of all three components.
</nextsent>
<nextsent>likewise, the flexibility of clearly defined api to client systems and its ability to par allelize batch processing and distribute test runs across the network have greatly contributed to the success of the package.
</nextsent>
<nextsent>the following paragraphs review some of the fundamental aspects in more detail, sketch essential functionality, and comment on how they have been exploited in the dfki ? yy cooperation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z615">
<title id=" W02-1508.xml">parallel distributed grammar engineering for practical applications </title>
<section> looking back quantifying evolution.  </section>
<citcontext>
<prevsection>
<prevsent>however, not surprisingly the addition of grammatical coverage comes witha sharp increase in ambiguity (which may indicate overgeneration): the graphs in figure 2 clearly show that, once coverage on the trading?
</prevsent>
<prevsent>data was above eighty percent, grammar ians shifted their engineering focus on tightening?
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
the grammar, i.e.the elimination of spurious ambiguity and overgen eration (see siegel &amp; bender, 2002, <papid> W02-1210 </papid>for details on the grammar).another view on grammar evolution is presented in figure 3, depicting the size?</citsent>
<aftsection>
<nextsent>of the japanese grammar over the same five-month development cycle.
</nextsent>
<nextsent>although measuring the size of2quantifying input complexity for japanese is non trivial task, as the count of the number of input words would depend on the approach to string segmentation used in specific system (the fairly aggressive tokenizer of chasen, asahara &amp; matsumoto, 2000, <papid> C00-1004 </papid>in our case); to avoid potential for confusion, we report input complexity in the (overtly system specific) number of lexical items stipulated by the grammar instead: around 50 and 80, on average, for the banking?</nextsent>
<nextsent>and trading?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z616">
<title id=" W02-1508.xml">parallel distributed grammar engineering for practical applications </title>
<section> looking back quantifying evolution.  </section>
<citcontext>
<prevsection>
<prevsent>the grammar, i.e.the elimination of spurious ambiguity and overgen eration (see siegel &amp; bender, 2002, <papid> W02-1210 </papid>for details on the grammar).another view on grammar evolution is presented in figure 3, depicting the size?</prevsent>
<prevsent>of the japanese grammar over the same five-month development cycle.</prevsent>
</prevsection>
<citsent citstr=" C00-1004 ">
although measuring the size of2quantifying input complexity for japanese is non trivial task, as the count of the number of input words would depend on the approach to string segmentation used in specific system (the fairly aggressive tokenizer of chasen, asahara &amp; matsumoto, 2000, <papid> C00-1004 </papid>in our case); to avoid potential for confusion, we report input complexity in the (overtly system specific) number of lexical items stipulated by the grammar instead: around 50 and 80, on average, for the banking?</citsent>
<aftsection>
<nextsent>and trading?
</nextsent>
<nextsent>datasets, respectively (as of february 2002).
</nextsent>
<nextsent>12-sep-2001 (13:24 h) ? 14-feb-2002 (17:14 h) 8800 9000 9200 9400 9600 9800 10000 10200 88 90 92 94 96 98 100 102 104 106 grammar size (generated by [incr tsdb()] at 30-jun-2002 (16:09 h))????
</nextsent>
<nextsent>types ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z617">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the purpose of language model (lm) is to determine the priori probability of word sequencew1; : : : ; wn, (w1; : : : ; wn).
</prevsent>
<prevsent>language modeling is essential in wide variety of applications; we focus on speech recognition in our research.
</prevsent>
</prevsection>
<citsent citstr=" W98-1121 ">
although word based lms (with bigram and trigram being the most common) remain the mainstay in many continuous speech recognition systems, recent eorts have explored variety of ways to improve lm performance (niesler and woodland, 1996; chelba et al, 1997;srinivas, 1997; heeman, 1998; <papid> W98-1121 </papid>chelba, 2000; rosenfeld, 2000; goodman, 2001; roark, 2001; <papid> J01-2004 </papid>charniak, 2001).<papid> P01-1017 </papid>class-based lms attempt to deal with data sparseness and generalize better to unseen word sequences by rst grouping words into classes and then using these classes to compute n-gram probabilities.</citsent>
<aftsection>
<nextsent>part of-speech (pos) tags were initially used as classes by jelinek (1990) in conditional probabilistic model (which predicts the tag sequence for word sequence rst and then uses it to predict the word sequence): pr(wn1 )  t1;t2;:::;tn y i=1 pr(tijti11 )pr(wijti) (1)however, jelineks pos lm is less eective at predicting word candidates than an n-gram word-based lm because it deletes important lexical information for predicting the next word.
</nextsent>
<nextsent>heemans (1998) pos lm achieves perplexity reduction compared to atrigram lm by instead rede ning the speech recognition problem as determining: w; t = argmax w;t (w;t ja) = argmax w;t (w;t)p (ajw;t)  argmax w;t (w;t)p (ajw ) where is the pos sequence tn1 associated with the word sequence = wn1 given the speech utterance a. the lm (w;t ) is joint probabilistic model that accounts for both the sequence of words wn1 and their tag assignments tn1 by estimating the joint probabilities of words and tags: (wn1 ; n 1 ) = y i=1 (wi; tijwi11 ; ti11 ) (2) johnson (2001) <papid> P01-1042 </papid>and laerty et al (2001) provide insight into why joint model is superior to conditional model.recently, there has been good progress in developing structured models (chelba, 2000; charniak, association for computational linguistics.</nextsent>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z618">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the purpose of language model (lm) is to determine the priori probability of word sequencew1; : : : ; wn, (w1; : : : ; wn).
</prevsent>
<prevsent>language modeling is essential in wide variety of applications; we focus on speech recognition in our research.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
although word based lms (with bigram and trigram being the most common) remain the mainstay in many continuous speech recognition systems, recent eorts have explored variety of ways to improve lm performance (niesler and woodland, 1996; chelba et al, 1997;srinivas, 1997; heeman, 1998; <papid> W98-1121 </papid>chelba, 2000; rosenfeld, 2000; goodman, 2001; roark, 2001; <papid> J01-2004 </papid>charniak, 2001).<papid> P01-1017 </papid>class-based lms attempt to deal with data sparseness and generalize better to unseen word sequences by rst grouping words into classes and then using these classes to compute n-gram probabilities.</citsent>
<aftsection>
<nextsent>part of-speech (pos) tags were initially used as classes by jelinek (1990) in conditional probabilistic model (which predicts the tag sequence for word sequence rst and then uses it to predict the word sequence): pr(wn1 )  t1;t2;:::;tn y i=1 pr(tijti11 )pr(wijti) (1)however, jelineks pos lm is less eective at predicting word candidates than an n-gram word-based lm because it deletes important lexical information for predicting the next word.
</nextsent>
<nextsent>heemans (1998) pos lm achieves perplexity reduction compared to atrigram lm by instead rede ning the speech recognition problem as determining: w; t = argmax w;t (w;t ja) = argmax w;t (w;t)p (ajw;t)  argmax w;t (w;t)p (ajw ) where is the pos sequence tn1 associated with the word sequence = wn1 given the speech utterance a. the lm (w;t ) is joint probabilistic model that accounts for both the sequence of words wn1 and their tag assignments tn1 by estimating the joint probabilities of words and tags: (wn1 ; n 1 ) = y i=1 (wi; tijwi11 ; ti11 ) (2) johnson (2001) <papid> P01-1042 </papid>and laerty et al (2001) provide insight into why joint model is superior to conditional model.recently, there has been good progress in developing structured models (chelba, 2000; charniak, association for computational linguistics.</nextsent>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z619">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the purpose of language model (lm) is to determine the priori probability of word sequencew1; : : : ; wn, (w1; : : : ; wn).
</prevsent>
<prevsent>language modeling is essential in wide variety of applications; we focus on speech recognition in our research.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
although word based lms (with bigram and trigram being the most common) remain the mainstay in many continuous speech recognition systems, recent eorts have explored variety of ways to improve lm performance (niesler and woodland, 1996; chelba et al, 1997;srinivas, 1997; heeman, 1998; <papid> W98-1121 </papid>chelba, 2000; rosenfeld, 2000; goodman, 2001; roark, 2001; <papid> J01-2004 </papid>charniak, 2001).<papid> P01-1017 </papid>class-based lms attempt to deal with data sparseness and generalize better to unseen word sequences by rst grouping words into classes and then using these classes to compute n-gram probabilities.</citsent>
<aftsection>
<nextsent>part of-speech (pos) tags were initially used as classes by jelinek (1990) in conditional probabilistic model (which predicts the tag sequence for word sequence rst and then uses it to predict the word sequence): pr(wn1 )  t1;t2;:::;tn y i=1 pr(tijti11 )pr(wijti) (1)however, jelineks pos lm is less eective at predicting word candidates than an n-gram word-based lm because it deletes important lexical information for predicting the next word.
</nextsent>
<nextsent>heemans (1998) pos lm achieves perplexity reduction compared to atrigram lm by instead rede ning the speech recognition problem as determining: w; t = argmax w;t (w;t ja) = argmax w;t (w;t)p (ajw;t)  argmax w;t (w;t)p (ajw ) where is the pos sequence tn1 associated with the word sequence = wn1 given the speech utterance a. the lm (w;t ) is joint probabilistic model that accounts for both the sequence of words wn1 and their tag assignments tn1 by estimating the joint probabilities of words and tags: (wn1 ; n 1 ) = y i=1 (wi; tijwi11 ; ti11 ) (2) johnson (2001) <papid> P01-1042 </papid>and laerty et al (2001) provide insight into why joint model is superior to conditional model.recently, there has been good progress in developing structured models (chelba, 2000; charniak, association for computational linguistics.</nextsent>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z620">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although word based lms (with bigram and trigram being the most common) remain the mainstay in many continuous speech recognition systems, recent eorts have explored variety of ways to improve lm performance (niesler and woodland, 1996; chelba et al, 1997;srinivas, 1997; heeman, 1998; <papid> W98-1121 </papid>chelba, 2000; rosenfeld, 2000; goodman, 2001; roark, 2001; <papid> J01-2004 </papid>charniak, 2001).<papid> P01-1017 </papid>class-based lms attempt to deal with data sparseness and generalize better to unseen word sequences by rst grouping words into classes and then using these classes to compute n-gram probabilities.</prevsent>
<prevsent>part of-speech (pos) tags were initially used as classes by jelinek (1990) in conditional probabilistic model (which predicts the tag sequence for word sequence rst and then uses it to predict the word sequence): pr(wn1 )  t1;t2;:::;tn y i=1 pr(tijti11 )pr(wijti) (1)however, jelineks pos lm is less eective at predicting word candidates than an n-gram word-based lm because it deletes important lexical information for predicting the next word.</prevsent>
</prevsection>
<citsent citstr=" P01-1042 ">
heemans (1998) pos lm achieves perplexity reduction compared to atrigram lm by instead rede ning the speech recognition problem as determining: w; t = argmax w;t (w;t ja) = argmax w;t (w;t)p (ajw;t)  argmax w;t (w;t)p (ajw ) where is the pos sequence tn1 associated with the word sequence = wn1 given the speech utterance a. the lm (w;t ) is joint probabilistic model that accounts for both the sequence of words wn1 and their tag assignments tn1 by estimating the joint probabilities of words and tags: (wn1 ; n 1 ) = y i=1 (wi; tijwi11 ; ti11 ) (2) johnson (2001) <papid> P01-1042 </papid>and laerty et al (2001) provide insight into why joint model is superior to conditional model.recently, there has been good progress in developing structured models (chelba, 2000; charniak, association for computational linguistics.</citsent>
<aftsection>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.
</nextsent>
<nextsent>238-247.
</nextsent>
<nextsent>proceedings of the conference on empirical methods in natural2001; roark, 2001) <papid> J01-2004 </papid>that incorporate syntactic information.</nextsent>
<nextsent>these lms capture the hierarchical characteristics of language rather than speci information about words and their lexical features (e.g., case, number).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z623">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> superarv language model.  </section>
<citcontext>
<prevsection>
<prevsent>px and mx([r]) represent the position of word and its modi ee (for role r), respectively.
</prevsent>
<prevsent>i ee of the role value assigned to n3 is set equal to its own position).
</prevsent>
</prevsection>
<citsent citstr=" P01-1010 ">
including need roles also provides mechanism for using non-headword dependencies to constrain parse structures, which bod (2001) <papid> P01-1010 </papid>has shown contributes to improved parsing accuracy.</citsent>
<aftsection>
<nextsent>during parsing, the grammaticality of sentence in language de ned by cdg is determined by applying set of constraints to the possible role value assignments (harper and helzerman, 1995; maruyama, 1990).<papid> P90-1005 </papid></nextsent>
<nextsent>originally, the constraints were comprised of set of hand-written rules specifying which role values (unary constraints) and pairs of role values (binary constraints) were grammatical (maruyama, 1990).<papid> P90-1005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z624">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> superarv language model.  </section>
<citcontext>
<prevsection>
<prevsent>i ee of the role value assigned to n3 is set equal to its own position).
</prevsent>
<prevsent>including need roles also provides mechanism for using non-headword dependencies to constrain parse structures, which bod (2001) <papid> P01-1010 </papid>has shown contributes to improved parsing accuracy.</prevsent>
</prevsection>
<citsent citstr=" P90-1005 ">
during parsing, the grammaticality of sentence in language de ned by cdg is determined by applying set of constraints to the possible role value assignments (harper and helzerman, 1995; maruyama, 1990).<papid> P90-1005 </papid></citsent>
<aftsection>
<nextsent>originally, the constraints were comprised of set of hand-written rules specifying which role values (unary constraints) and pairs of role values (binary constraints) were grammatical (maruyama, 1990).<papid> P90-1005 </papid></nextsent>
<nextsent>in order to derive the constraints directly from cdg annotated sentences, we have developed an algorithm to extract grammar relations using information derived directly from annotated sentences (harper et al, 2000; <papid> A00-2014 </papid>harper and wang, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z628">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> superarv language model.  </section>
<citcontext>
<prevsection>
<prevsent>during parsing, the grammaticality of sentence in language de ned by cdg is determined by applying set of constraints to the possible role value assignments (harper and helzerman, 1995; maruyama, 1990).<papid> P90-1005 </papid></prevsent>
<prevsent>originally, the constraints were comprised of set of hand-written rules specifying which role values (unary constraints) and pairs of role values (binary constraints) were grammatical (maruyama, 1990).<papid> P90-1005 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2014 ">
in order to derive the constraints directly from cdg annotated sentences, we have developed an algorithm to extract grammar relations using information derived directly from annotated sentences (harper et al, 2000; <papid> A00-2014 </papid>harper and wang, 2001).</citsent>
<aftsection>
<nextsent>using the relationship between role values position and its modi ees position, unary and binary constraints can be represented as nite set of abstract role values (arvs) and abstract role value pairs (arvps), respectively.
</nextsent>
<nextsent>the light gray box of figure 1 shows an example of an arv and an arvp.
</nextsent>
<nextsent>the arv for the governor role value of did indicates its lexical category, lexical features, role, label, and positional relation information.
</nextsent>
<nextsent>(px1   mx1) indicates that did is governed by word that precedesit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z630">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> superarv language model.  </section>
<citcontext>
<prevsection>
<prevsent>the average number of superarvs for words of dierent lexical categories vary, with verbs having the greatest superarv ambiguity.
</prevsent>
<prevsent>this is mostly due to the variety of feature combinations and variations on complement types and positions.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we have observed in several experiments that the number of superarvsdoes not grow signi cantly as training set size in creases; the moderate-sized resource management corpus (price et al, 1988) with 25,168 words produces 328 superarvs, compared to 538 superarvs for the 1 million word wall street journal (wsj) penn treebank set (marcus et al, 1993), <papid> J93-2004 </papid>and 791 forthe 37 million word training set of the wsj continuous speech recognition task.superarvs can be accumulated from corpus annotated with cdg relations and stored directly with words in lexicon, so we can learn their frequency of occurrence for the corresponding word.</citsent>
<aftsection>
<nextsent>a super arv can then be selected from the lexicon and used to generate role values that meet their constraints.since there are no large benchmark corpora annotated with cdg information1, we have developed methodology to automatically transform constituent bracketing found in available treebanks into cdg annotations.
</nextsent>
<nextsent>in addition to generating dependency structures by headword percolation (chelba, 2000), our transformer also utilizes rule-based method to determine lexical features and need role values for words, as described by wang et al (2001).
</nextsent>
<nextsent>our superarv lm estimates the joint probability of words wn1 and their superarv tags n 1 : pr(wn1 n 1 ) = y i=1 pr(witijwi11 ti11 ) = y i=1 pr(tijwi11 ti11 )
</nextsent>
<nextsent>pr(wijwi11 ti1)  y i=1 pr(tijwi1i2ti1i2)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z647">
<title id=" W02-1031.xml">the superarv language model investigating the effectiveness of tightly integrating multiple knowledge sources </title>
<section> investigating the knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>source contributions next, we attempt to explain the contrast between the encouraging results from our superarv lm andthe reported poor performance of several probabilistic dependency grammar models, i.e., the traditional probabilistic dependency grammar (pdg) lm, the probabilistic link grammar (plg) (laerty et al, 1992) lm, and zemans probabilistic dependency grammar model (zpdg) (hajic et al, 1998).
</prevsent>
<prevsent>zpdg was evaluated on the prague dependency treebank(hajic, 1998) during the 1998 johns hopkins summer workshop (hajic et al, 1998) and produced much lower parsing accuracy (under 60%) than collins?
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
probabilistic context-free grammar parser(80%) (collins, 1996).<papid> P96-1025 </papid></citsent>
<aftsection>
<nextsent>fong et al (1995) evaluated the probabilistic link grammar lm described in (laerty et al, 1992) on small arti cial corpora and found that the lm has greater perplexity thana standard bigram.
</nextsent>
<nextsent>additionally, only modest improvement on the bigram was achieved after fong and wu (1995) revised the model to make grammar rule learning feasible.one possible reason for their poor performance, especially in the light of our superarv lm results, isthat these probabilistic dependency grammar models do not utilize sucient knowledge to achieve high level of accuracy.
</nextsent>
<nextsent>the knowledge sources the superarv lm uses, represented as components of the structure shown in figure 1, include: lexical category (denoted c), lexical features (denoted f), role label or link type information (denoted l), governor role dependency relation constraint (r, l,uc) (denoted g), set of need role dependency relation constraints (r;l; uc)+ (denoted n), and mod ee constraints represented as the lexical category of the modi ee for each role (denoted m).
</nextsent>
<nextsent>table 5 summarizes the knowledge sources that each of the probabilistic dependency grammar models uses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z648">
<title id=" W02-1015.xml">handling noisy training and testing data </title>
<section> an error taxonomy.  </section>
<citcontext>
<prevsection>
<prevsent>5 experimental results.
</prevsent>
<prevsent>as sort of case study in the meta-algorithms presented in the previous sections, we will look at the problem of function tagging in the treebank.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
blaheta and charniak (2000) <papid> A00-2031 </papid>describe an algorithm for marking sentence constituents with function tags such as sbj (for sentence subjects) and tmp (fortemporal phrases).</citsent>
<aftsection>
<nextsent>we trained this algorithm on sections 02{21 of the treebank and ran it on section 24 (the development corpus), then analysed the output.first, we printed out every constituent with function tag error.
</nextsent>
<nextsent>we then examined the sentence in which each occurred, and determined whether the error was in the algorithm or in the treebank, or elsewhere, as reported in table 1.
</nextsent>
<nextsent>of the errors we examined, less than half were due solely to an algo rithmic failure in the function tagger itself.
</nextsent>
<nextsent>the next largest category was parse error: this function tagging algorithm requires parsed input, and in these cases, that input was incorrect and led the function tagger astray; had the tagger received the treebank parse, it would have given correct output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z650">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe an lr parser of parts-of speech (and punctuation labels) for tree adjoining grammars (tags), that solve stable conflicts in greedy way, with limited amount of backtracking.
</prevsent>
<prevsent>we evaluate the parser using the penn treebank showing that the method yield very fast parsers with at least reasonable accuracy, confirming the intuition that lr parsing benefits from the use of rich grammars.
</prevsent>
</prevsection>
<citsent citstr=" P83-1017 ">
the lr approach for parsing has long been considered for natural language parsing (lang, 1974; tomita, 1985; wright and wrigley, 1991; shieber, 1983; <papid> P83-1017 </papid>pereira, 1985; merlo, 1996), but it was not until more recent past, with the advent of corpus based techniques made possible by the availability of large treebanks, that parsing results and evaluation started being reported (briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 1997; carroll and briscoe, 1996; <papid> W96-0209 </papid>ruland, 2000).<papid> C00-2098 </papid></citsent>
<aftsection>
<nextsent>the appeal of lr parsing (knuth, 1965) derives from its high capacity of postponement of structural decisions, therefore allowing for much of the spurious local ambiguity to be automatically discarded.
</nextsent>
<nextsent>but it is still the case that conflicts arise in the lr table for natural language grammars, and in large quantity.
</nextsent>
<nextsent>the key question is how one can use the contextual information contained in the parsing stack to cope with the remaining (local) ambiguity manifested as conflicts in the lr tables.
</nextsent>
<nextsent>the aforementioned work has concentrated on lr parsing forcfgs which has clear deficiency in making available sufficient context in the lr states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z651">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe an lr parser of parts-of speech (and punctuation labels) for tree adjoining grammars (tags), that solve stable conflicts in greedy way, with limited amount of backtracking.
</prevsent>
<prevsent>we evaluate the parser using the penn treebank showing that the method yield very fast parsers with at least reasonable accuracy, confirming the intuition that lr parsing benefits from the use of rich grammars.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
the lr approach for parsing has long been considered for natural language parsing (lang, 1974; tomita, 1985; wright and wrigley, 1991; shieber, 1983; <papid> P83-1017 </papid>pereira, 1985; merlo, 1996), but it was not until more recent past, with the advent of corpus based techniques made possible by the availability of large treebanks, that parsing results and evaluation started being reported (briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 1997; carroll and briscoe, 1996; <papid> W96-0209 </papid>ruland, 2000).<papid> C00-2098 </papid></citsent>
<aftsection>
<nextsent>the appeal of lr parsing (knuth, 1965) derives from its high capacity of postponement of structural decisions, therefore allowing for much of the spurious local ambiguity to be automatically discarded.
</nextsent>
<nextsent>but it is still the case that conflicts arise in the lr table for natural language grammars, and in large quantity.
</nextsent>
<nextsent>the key question is how one can use the contextual information contained in the parsing stack to cope with the remaining (local) ambiguity manifested as conflicts in the lr tables.
</nextsent>
<nextsent>the aforementioned work has concentrated on lr parsing forcfgs which has clear deficiency in making available sufficient context in the lr states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z652">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe an lr parser of parts-of speech (and punctuation labels) for tree adjoining grammars (tags), that solve stable conflicts in greedy way, with limited amount of backtracking.
</prevsent>
<prevsent>we evaluate the parser using the penn treebank showing that the method yield very fast parsers with at least reasonable accuracy, confirming the intuition that lr parsing benefits from the use of rich grammars.
</prevsent>
</prevsection>
<citsent citstr=" W96-0209 ">
the lr approach for parsing has long been considered for natural language parsing (lang, 1974; tomita, 1985; wright and wrigley, 1991; shieber, 1983; <papid> P83-1017 </papid>pereira, 1985; merlo, 1996), but it was not until more recent past, with the advent of corpus based techniques made possible by the availability of large treebanks, that parsing results and evaluation started being reported (briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 1997; carroll and briscoe, 1996; <papid> W96-0209 </papid>ruland, 2000).<papid> C00-2098 </papid></citsent>
<aftsection>
<nextsent>the appeal of lr parsing (knuth, 1965) derives from its high capacity of postponement of structural decisions, therefore allowing for much of the spurious local ambiguity to be automatically discarded.
</nextsent>
<nextsent>but it is still the case that conflicts arise in the lr table for natural language grammars, and in large quantity.
</nextsent>
<nextsent>the key question is how one can use the contextual information contained in the parsing stack to cope with the remaining (local) ambiguity manifested as conflicts in the lr tables.
</nextsent>
<nextsent>the aforementioned work has concentrated on lr parsing forcfgs which has clear deficiency in making available sufficient context in the lr states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z653">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe an lr parser of parts-of speech (and punctuation labels) for tree adjoining grammars (tags), that solve stable conflicts in greedy way, with limited amount of backtracking.
</prevsent>
<prevsent>we evaluate the parser using the penn treebank showing that the method yield very fast parsers with at least reasonable accuracy, confirming the intuition that lr parsing benefits from the use of rich grammars.
</prevsent>
</prevsection>
<citsent citstr=" C00-2098 ">
the lr approach for parsing has long been considered for natural language parsing (lang, 1974; tomita, 1985; wright and wrigley, 1991; shieber, 1983; <papid> P83-1017 </papid>pereira, 1985; merlo, 1996), but it was not until more recent past, with the advent of corpus based techniques made possible by the availability of large treebanks, that parsing results and evaluation started being reported (briscoe and carroll, 1993; <papid> J93-1002 </papid>inui et al, 1997; carroll and briscoe, 1996; <papid> W96-0209 </papid>ruland, 2000).<papid> C00-2098 </papid></citsent>
<aftsection>
<nextsent>the appeal of lr parsing (knuth, 1965) derives from its high capacity of postponement of structural decisions, therefore allowing for much of the spurious local ambiguity to be automatically discarded.
</nextsent>
<nextsent>but it is still the case that conflicts arise in the lr table for natural language grammars, and in large quantity.
</nextsent>
<nextsent>the key question is how one can use the contextual information contained in the parsing stack to cope with the remaining (local) ambiguity manifested as conflicts in the lr tables.
</nextsent>
<nextsent>the aforementioned work has concentrated on lr parsing forcfgs which has clear deficiency in making available sufficient context in the lr states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z654">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they use tree adjoining grammars (tags) (joshi and schabes, 1997; joshiet al, 1975) to defend the possibility of granular incremental computations in lr parsing.
</prevsent>
<prevsent>incidentally or not, they make use of disambiguation contexts that are only possible in state of conceptual lr parser for rich grammar formalism such as tag, but not for cfg.
</prevsent>
</prevsection>
<citsent citstr=" P98-2156 ">
concrete lr-like algorithms for tags have only recently been proposed (prolo, 2000; nederhof, 1998), <papid> P98-2156 </papid>though their evaluation was restricted to the quality of the parsing table (see also (schabes andvijay-shanker, 1990; kinyon, 1997) for earlier at tempts).</citsent>
<aftsection>
<nextsent>in this paper, we revisit the lr parsing technique,applied to rich grammar formalism: tag.
</nextsent>
<nextsent>following (briscoe and carroll, 1993), <papid> J93-1002 </papid>conflict resolution is based on contextual information extracted fromthe so called instantaneous description or configu ration: stack, representing the control memory ofthe lr parser, and look ahead sequence, here limited to one symbol.1 however, while briscoe and carroll invested on massive parallel computation of the possible parsing paths, with pruning and posterior ranking, we ex 1unlike (wright and wrigley, 1991)s approach who tries to transpose pcfg probabilities to lr tables, facing difficulties which, to the best of our knowledge, have not been yet solved to content (cf.</nextsent>
<nextsent>also (ng and tomita, 1991; wright et al, 1991; abney et al, 1999)).<papid> P99-1070 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z656">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we revisit the lr parsing technique,applied to rich grammar formalism: tag.
</prevsent>
<prevsent>following (briscoe and carroll, 1993), <papid> J93-1002 </papid>conflict resolution is based on contextual information extracted fromthe so called instantaneous description or configu ration: stack, representing the control memory ofthe lr parser, and look ahead sequence, here limited to one symbol.1 however, while briscoe and carroll invested on massive parallel computation of the possible parsing paths, with pruning and posterior ranking, we ex 1unlike (wright and wrigley, 1991)s approach who tries to transpose pcfg probabilities to lr tables, facing difficulties which, to the best of our knowledge, have not been yet solved to content (cf.</prevsent>
</prevsection>
<citsent citstr=" P99-1070 ">
also (ng and tomita, 1991; wright et al, 1991; abney et al, 1999)).<papid> P99-1070 </papid></citsent>
<aftsection>
<nextsent>association for computational linguistics.
</nextsent>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.
</nextsent>
<nextsent>103-110.
</nextsent>
<nextsent>proceedings of the conference on empirical methods in natural peri ment with simple greedy depth-first technique with limited amount of backtracking, that resembles to certain extent the commitment/recovery models from the psycho linguistic research on human language processing, supported by the occurrence of garden paths?.2 we use the penn treebank wsj corpus, release 2 (marcus et al, 1994), <papid> H94-1020 </papid>to evaluate the approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z657">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>language processing (emnlp), philadelphia, july 2002, pp.
</prevsent>
<prevsent>103-110.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
proceedings of the conference on empirical methods in natural peri ment with simple greedy depth-first technique with limited amount of backtracking, that resembles to certain extent the commitment/recovery models from the psycho linguistic research on human language processing, supported by the occurrence of garden paths?.2 we use the penn treebank wsj corpus, release 2 (marcus et al, 1994), <papid> H94-1020 </papid>to evaluate the approach.</citsent>
<aftsection>
<nextsent>table 1 shows the architecture of our parsing application.
</nextsent>
<nextsent>we extract tag from piece of the penn treebank, the training corpus, and submit it to an lr parser generator.
</nextsent>
<nextsent>the same training corpus is used again to extract statistical information that isused by the driver as follows.
</nextsent>
<nextsent>the grammar generation process generates as sub product the tag derivation trees for the annotated sentences compatible with the extracted grammar trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z661">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>7however, two new categories were defined: one for time nouns, namely those that appear in the penn treebank as heads of constituents marked tmp?
</prevsent>
<prevsent>(for temporal); another for theword that?.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
this is similar to (collins, 1997)<papid> P97-1003 </papid>s and char niak97s definition of separate category for auxiliary verbs.8we also included some punctuation symbols among the terminals such as comma, colon and semicolon.</citsent>
<aftsection>
<nextsent>they are extracted into the grammar as if they were regular modifiers.
</nextsent>
<nextsent>their main use is in guiding parsing decisions.
</nextsent>
<nextsent>section %failed tput recall prec.
</nextsent>
<nextsent> 0 1.3 18 81.76 23 1.9 19 81.41 0 (flat) 1.3 18 78.21 77.35 77.78 23 (flat) 1.9 19 77.52 76.96 77.24 table 1: results on the development and test set recall and prec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z663">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>section %failed tput recall prec.
</prevsent>
<prevsent> 0 1.3 18 81.76 23 1.9 19 81.41 0 (flat) 1.3 18 78.21 77.35 77.78 23 (flat) 1.9 19 77.52 76.96 77.24 table 1: results on the development and test set recall and prec.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
are the labeled parsing recall and precision, respectively, as defined in (collins, 1997)<papid> P97-1003 </papid> (slightly different from (black et al, 1991)).<papid> H91-1060 </papid></citsent>
<aftsection>
<nextsent>   is their harmonic average.
</nextsent>
<nextsent>tput is the average number of sentences parsed per second.
</nextsent>
<nextsent>to obtain the average, the number of sentences submitted as input (not only those that parsed successfully) is divided by the total time (excluded the time overhead before it starts parsing the first sentence).
</nextsent>
<nextsent>the programs were run under linux, in pc with pentium iii 930mhz processor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z664">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the reason for such increase in structure is not quite particular decision of ours, but consequence of using sound grammar under the tag grammatical formalism.9however, having concluded our manifesto, we understand that algorithms that try to keep precision as high as the recall necessarily have losses in recall compared to if they ignored the precision, and therefore in order to have fair comparison with them and to improve the credibility of our results, we flattened the parse trees in post-processing step, using simple rule-based technique on top of some frequency measures for individual grammar trees gathered by (xia, 2001) and the result is presented in the bottom lines of the table.9by sound we mean grammar that properly factors recur sion in one way or another.
</prevsent>
<prevsent>grammars have been extracted where the right side of rule reflects exactly each single-level expansion found in the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
we are also aware of few alternatives in grammatical formalisms that could capture such flatness, e.g., sister adjunction (chiang, 2000).<papid> P00-1058 </papid></citsent>
<aftsection>
<nextsent>the most salient positive result is that the parse ris able to parse sentences at rate of about 20 sentences per second.
</nextsent>
<nextsent>most of the medium-to-high accuracy parsers take at least few seconds per sentence under the same conditions.10 this is an enormous speed-up.
</nextsent>
<nextsent>as for the accuracy, it is not far from the top performing parser for parts-of-speech that we are aware of, reported by (simaan, 2000): recall/precision =   91   perhaps the most similar work to ours is briscoe and carrolls (1993; <papid> J93-1002 </papid>1995; 1992; 1996).</nextsent>
<nextsent>they implemented standard lr parser for cfgs, and probabilistic method for conflict resolution similar to ours in that the decisions are conditioned to the lr states but with different methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z666">
<title id=" W02-1014.xml">fast lr parsing using rich tree adjoining grammars </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>the high reliability of ff fl    , suggests that we should look for way to enrich the parsing table.lr parser for the full class of tags is problematic.
</prevsent>
<prevsent>the bpack action of early structural commitment is involved in most of the decision points where the wrong action is taken.
</prevsent>
</prevsection>
<citsent citstr=" J95-4002 ">
we are currently working on version of the lr parser for subclass of tags, the tree insertion grammars (schabes and waters, 1995), <papid> J95-4002 </papid>for which efficient true lr parsers can be obtained.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z667">
<title id=" W03-0108.xml">a confidence based framework for disambiguating geographic terms </title>
<section> real-time processing of documents.  </section>
<citcontext>
<prevsection>
<prevsent>can potentially mean any of 22 points with that name, or none of them.
</prevsent>
<prevsent>the main source of geographic references are names from the high-quality meta carta gazetteer.
</prevsent>
</prevsection>
<citsent citstr=" W03-0110 ">
see (axel rod, 2003) <papid> W03-0110 </papid>for the process of building and updating this gazetteer.</citsent>
<aftsection>
<nextsent>the procedure used to obtain realistic initial confidences associated with the gazetteer names is described in section 5.1.we mention some of the alternative sources of potentially geographic references here.
</nextsent>
<nextsent>we have capabilities allowing to match us postal addresses and pass them to third-party geo location software producing coordinate for the address.
</nextsent>
<nextsent>coordinates such as 380110.5 1214448.8 or 56.51n 25.86e arematched.
</nextsent>
<nextsent>we match some of jintaccs (depart ment of the army, 1990) message traffic formats such as 163940n 1062920e (means 163940n 1062920e).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z668">
<title id=" W03-0108.xml">a confidence based framework for disambiguating geographic terms </title>
<section> training.  </section>
<citcontext>
<prevsection>
<prevsent>thus the training process is iterative.
</prevsent>
<prevsent>5.2 data mining of geographically significant local.
</prevsent>
</prevsection>
<citsent citstr=" A97-1051 ">
linguistic contexts we currently use data mining on tagged corpora to learn the contexts in which geographic and non-geographic references occur, the words and phrases leading up to and trailing the name n. the tagged corpora were obtained using the alembic tagger (day et al, 1997).<papid> A97-1051 </papid></citsent>
<aftsection>
<nextsent>the accumulated statistics allow us to determine whether specific context is positive or negative indicator of term being geographic, and the strength of this particular indicator.
</nextsent>
<nextsent>for any context c, an adjustment is applied to the confidence which is nonlinear function of the probability of geographic reference occurring in in the tagged corpus.
</nextsent>
<nextsent>the addition of geographic dimensions to information retrieval means that in addition to the relevance of documents to textual query, the relevance to the places mentioned in those documents must also be considered in order to rank the documents.
</nextsent>
<nextsent>the two kinds of relevance, traditional textual query relevance rw and georelevancerg , must be properly balanced to return documents relevant to users query.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z669">
<title id=" W03-1720.xml">combining segmenter and chunker for chinese word segmentation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>1.2 correction by support vector machine-based.
</prevsent>
<prevsent>chunker while the hmm-based word segmenter achieves good accuracy for known words, it cannot identify compound words and out-of-vocabulary words.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
therefore, we introduce support vector machine(below svm)-basedchunker (kudo and matsumoto, 2001) <papid> N01-1025 </papid>to cover the errors made by the segmenter.</citsent>
<aftsection>
<nextsent>the svm-based chunkerre-assigns new word boundaries to the output of the seg menter.an svm (vapnik, 1998) is binary classifier.
</nextsent>
<nextsent>suppose we have set of training data for binary class problem: (x1, y1), . . .
</nextsent>
<nextsent>, (xn , yn ), where xi ? rn is feature vector of the th sample in the training data and yi ? {+1,1} is the label of the sample.
</nextsent>
<nextsent>the goal is to find decision function which accurately predicts for an unseen x. an svm classifier gives decision function f(x) for an input vector where f(x) = sign( ? zisv iyik(x, zi) + b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z671">
<title id=" W02-1206.xml">lexicon based orthographic disambiguation in cjk intelligent information retrieval </title>
<section> morphophonemic: n.k. yz (ramyong) vs..  </section>
<citcontext>
<prevsection>
<prevsent>5 the role of lexical databases.
</prevsent>
<prevsent>because of the irregular orthography of cjk languages, lexeme-based procedures such as orthographic disambiguation cannot be based on probabilistic methods (e.g. bigramming) alone.
</prevsent>
</prevsection>
<citsent citstr=" W97-0316 ">
many attempts have been made along these lines, as for example brill (2001) and goto et al (2001), with some claiming performance equivalent to lexicon-based methods, while kwok (1997) <papid> W97-0316 </papid>reports good results with only small lexicon and simple segmentor.</citsent>
<aftsection>
<nextsent>these methods may be satisfactory for pure ir (relevant document retrieval), but for orthographic disambiguation and c2c conversion, emerson (2000) and others have shown that robust morphological analyzer capable of processing lexemes, rather than bigrams or n-grams, must be supported by large-scale computational lexicon (even 100,000 entries is much too small).
</nextsent>
<nextsent>the cjk dictionary institute (cjki), which specializes in cjk computational lexicography, is engaged in an ongoing research and development effort to compile comprehensive cjk lexical databases (currently about 5.5 million entries), with special emphasis on orthographic disambiguation and proper nouns.
</nextsent>
<nextsent>listed below are the principal components useful for intelligent ir tools and orthographic disambiguation.
</nextsent>
<nextsent>1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z672">
<title id=" W02-1818.xml">chinese base phrases chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recognizing simple and non-recursive base phrases is an important subtask for many natural language processing applications, such as information retrieval.
</prevsent>
<prevsent>gee and grosjean (gee and grosjean, 1983) showed psychological evidence that chunks like base phrases play an important role in human language understanding.
</prevsent>
</prevsection>
<citsent citstr=" W00-0726 ">
conll-2000s shared task identified many kinds of english base phrases, which are syntactically related non-overlapping groups of words (tjong and buchholz, 2000).<papid> W00-0726 </papid></citsent>
<aftsection>
<nextsent>the shared task has significantly heightened the progress in the techniques of english partial parsing.
</nextsent>
<nextsent>for chinese processing, zhao (1998) put forward definition of chinese basenp that is combination of determinative modifier and head noun (zhao, 1998).
</nextsent>
<nextsent>based on that research, zhao et al.
</nextsent>
<nextsent>(2000) extended the concept of basenp to seven types of chinese base phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z673">
<title id=" W02-0809.xml">dutch word sense disambiguation optimizing the local ness of context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>solving lexical ambiguity, or word sense disambiguation (wsd), is an important task in natural language processing systems (kilgarriff and palmer, 2000).
</prevsent>
<prevsent>much like syntactic word-class disambiguation, it is not end in itself, but rather sub task of other natural language processing tasks.
</prevsent>
</prevsection>
<citsent citstr=" W02-0814 ">
the problem is far from solved, and research and competition in the development of wsd systems in isolation remains meri table, preferrably on many different languages and genres.this paper describes refinement of an existing all-words wsd system for dutch (hoste et al , 2002<papid> W02-0814 </papid>b) that is an ensemble of word experts, each specialised in disambiguating the senses for one particular ambiguous wordform.</citsent>
<aftsection>
<nextsent>each word expert has memory-based classification kernel.
</nextsent>
<nextsent>the system was developed on the basis of dutch wsd data made available for the senseval-2 competition.
</nextsent>
<nextsent>the data, collection of 102 childrens books for the age range of 4 to 12, is annotated according to non-hierarchical sense inventory that is based on childrens dictionary (for detailed description of the data, cf.
</nextsent>
<nextsent>(hendrickx and vanden bosch, 2002)).since senseval-2, both the data and the system have been refined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z688">
<title id=" W02-0809.xml">dutch word sense disambiguation optimizing the local ness of context </title>
<section> the dutch wsd system: algorithms,.  </section>
<citcontext>
<prevsection>
<prevsent>data, instance generation the memory-based wsd system for dutch, henceforth referred to as mbwsd-d, is built from the viewpoint of wsd as classification task.
</prevsent>
<prevsent>givenan ambiguous word and its context as input features, data-trained classifier assigns the contextually correct class (sense) to it.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
our approach tomemory-based all-words wsd follows the memory based approach of (ng and lee, 1996), <papid> P96-1006 </papid>and thework by (veenstra et al , 2000) on memory based approach to the english lexical sample task of senseval-1.</citsent>
<aftsection>
<nextsent>we borrow the classification-based approach, and the word-expert concept of the latter: for each word form, word expert classifier is trained on disambiguating its one particular wordform.in this section we give an overview of the learning algorithms used, the data, and how this data was converted into instances of ambiguous words in context, to make the wsd task learn able for the memory-based word experts.
</nextsent>
<nextsent>2.1 learning algorithms.
</nextsent>
<nextsent>the distinguishing feature of memory-based learning (mbl) in contrast with minimal-description length-driven or eager?
</nextsent>
<nextsent>ml algorithms is that mbl keeps all training data in memory, and only abstracts at classification time by extrapolating class from the most similar item(s) in memory to the new test item.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z689">
<title id=" W02-0809.xml">dutch word sense disambiguation optimizing the local ness of context </title>
<section> the dutch wsd system: algorithms,.  </section>
<citcontext>
<prevsection>
<prevsent>this strategy is often referred to as lazy?
</prevsent>
<prevsent>learning.
</prevsent>
</prevsection>
<citsent citstr=" P97-1056 ">
in recent work (daelemans et al ,1999) we have shown that for typical natural language processing tasks, this lazy learning approach performs well because it allows extrapolation from low-frequency or exceptional cases, whereas eager methods tend to treat these as discard able noise.also, the automatic feature weighting in the similarity metric of memory-based learner makes the approach well-suited for domains with large numbers of features from heterogeneous sources, as it embodies smoothing-by-similarity method when data is sparse (zavrel and daelemans, 1997).<papid> P97-1056 </papid></citsent>
<aftsection>
<nextsent>forour experiments, we used the mbl algorithms implemented in timbl1.
</nextsent>
<nextsent>we give brief overview ofthe algorithms and metrics here, and refer to (daele mans et al , 1997; daelemans et al , 2001) for more information.
</nextsent>
<nextsent>ib1 ? the distance between test item and each memory item is defined as the number of features for which they have different value (ahaet al , 1991).
</nextsent>
<nextsent>classification occurs via the nearest-distances rule: all memory items which are equally near at the nearest  distances surrounding the test item are taken into account in classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z692">
<title id=" W02-0809.xml">dutch word sense disambiguation optimizing the local ness of context </title>
<section> the dutch wsd system: algorithms,.  </section>
<citcontext>
<prevsection>
<prevsent>as the use of keyword information does not seemto contribute to the dutch wsd system, we decided to pursue optimizing the local context information.
</prevsent>
<prevsent>the previously used local context of three was never tested against smaller or bigger contexts, so for this study we varied the context from oneword to five words left and right, plus their part of-speech (pos) tags (i.e., we tested symmetrical contexts only).
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
pos tags of the focus word itself are also included, to aid sense disambiguations related to syntactic differences (stevenson and wilks,2001).<papid> J01-3001 </papid></citsent>
<aftsection>
<nextsent>pos tags were generated by mbt (daele mans et al , 1996).
</nextsent>
<nextsent>the following is an instance of the ambiguous word donker [dark] and its context ?(...)zei : hmmm , het donker is ook niet zo eng(...)
</nextsent>
<nextsent>[said:,hmm the dark is also not so scary]?: zei punc : int hmmm punc , art het v is adv ook adv niet adv zo adj eng donker duister instances were made for each ambiguous word,consisting of 22 features.
</nextsent>
<nextsent>the first ten features represent the five words left to the ambiguous focus word and their part-of-speech tags, followed by thepart-of-speech tag of the focus word, in this example which stands for noun.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z703">
<title id=" W03-1805.xml">a language model approach to key phrase extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a word sequence can be informative for particular domain but not phrase; toyota, honda, ford?
</prevsent>
<prevsent>is an example of non-phrase sequence of informative words in hybrid car domain.the algorithm we propose for key phrase finding requires that the key phrase score well for both phrase ness and informativeness.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
word collocation various collocation metrics have been proposed, including mean and variance (smadja, 1994), the t-test (church et al, 1991), the chi-square test, pointwise mutual information(mi) (church and hanks, 1990), <papid> J90-1003 </papid>and binomial log likelihood ratio test (blrt) (dunning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>according to (manning and schutze, 1999),blrt is one of the most stable methods for collocation discovery.
</nextsent>
<nextsent>(pantel and lin, 2001) reports, however, that blrt score can be also high for two frequent terms that are rarely adjacent, such as the word pair the the,?
</nextsent>
<nextsent>and uses hybrid of mi and blrt.
</nextsent>
<nextsent>key phrase extraction damerau (1993) uses the relative frequency ratio between two corpora to extract domain-specific keyphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z704">
<title id=" W03-1805.xml">a language model approach to key phrase extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a word sequence can be informative for particular domain but not phrase; toyota, honda, ford?
</prevsent>
<prevsent>is an example of non-phrase sequence of informative words in hybrid car domain.the algorithm we propose for key phrase finding requires that the key phrase score well for both phrase ness and informativeness.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
word collocation various collocation metrics have been proposed, including mean and variance (smadja, 1994), the t-test (church et al, 1991), the chi-square test, pointwise mutual information(mi) (church and hanks, 1990), <papid> J90-1003 </papid>and binomial log likelihood ratio test (blrt) (dunning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>according to (manning and schutze, 1999),blrt is one of the most stable methods for collocation discovery.
</nextsent>
<nextsent>(pantel and lin, 2001) reports, however, that blrt score can be also high for two frequent terms that are rarely adjacent, such as the word pair the the,?
</nextsent>
<nextsent>and uses hybrid of mi and blrt.
</nextsent>
<nextsent>key phrase extraction damerau (1993) uses the relative frequency ratio between two corpora to extract domain-specific keyphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z706">
<title id=" W03-1805.xml">a language model approach to key phrase extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one problem of using relative frequency is that it tends to assign toohigh score for words whose frequency in the back ground corpus is small (or even zero).
</prevsent>
<prevsent>some work has been done in extracting key phrases from technical documents treating key phrase extraction as supervised learning problem (frank et al, 1999; turney, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J01-1001 ">
the portability of learned classifier across various unstructured/structured text is not clear, however, and the agreement between classifier and human judges is not high.1 we would like to have the ability to extractkeyphrases from totally new domain of text with outbuilding training corpus.combining key phrase and collocation yamamoto and church (2001) <papid> J01-1001 </papid>compare two metrics, mi and residual idf (ridf), and observed that mi is suitable for finding collocation and ridf is suitable for finding informative phrases.</citsent>
<aftsection>
<nextsent>they took the intersection of each top 10% of phrases identified by mi and ridf, but did not extend the approach to combining the two metrics into unified score.
</nextsent>
<nextsent>log-likelihood ratio test we can use various statistics as measure for phrase ness and informativeness.
</nextsent>
<nextsent>for our baseline,we have selected the method based on binomial log likelihood ratio test (blrt) described in (dunning, 1993).<papid> J93-1003 </papid></nextsent>
<nextsent>the basic idea of using blrt for text analysis is to consider word sequence as repeated sequence of binary trials comparing each word in corpus to target word, and use the likelihood ratio of two hypotheses that (i) two events, observed  </nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z709">
<title id=" W03-1805.xml">a language model approach to key phrase extraction </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>z 6b^ . b^ )  b^ )
</prevsent>
<prevsent> here each word only depends on the previous two words.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
please refer to (jelinek, 1990) and (chen and goodman, 1996)<papid> P96-1041 </papid>for more about n-gram models and associated smoothing methods.</citsent>
<aftsection>
<nextsent>now suppose we have foreground corpus and background corpus and have created language model for each corpus.
</nextsent>
<nextsent>the simplest language model is unigram model, which assumes each word of given word sequence is drawn independently.
</nextsent>
<nextsent>we denote the unigram model for the foreground corpus as
</nextsent>
<nextsent>fg and for the background corpus as
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z713">
<title id=" W03-0429.xml">named entity recognition using hundreds of thousands of features </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>the inverse of the words position in the sentence, and of the position of that sentence in the document; 8.
</prevsent>
<prevsent>the pos, chunk and lemma features from the training data; 9.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
whether the word is part of any entity, according to previous application of the tnt-subcat tagger (brants, 2000) (<papid> A00-1031 </papid>see below) trained on the tag set {o, i-entity} (test f?=1 performance was 94.70 english and 74.33 german on this tag set); and run description test loc misc org per overall 1.</citsent>
<aftsection>
<nextsent>tnt test 86.67 79.60 73.04 88.54 82.90.
</nextsent>
<nextsent>test 81.28 68.98 65.71 82.84 75.54 2.
</nextsent>
<nextsent>tnt + subcat test 91.46 81.41 80.63 91.64 87.49.
</nextsent>
<nextsent>test 85.71 68.41 73.82 87.95 80.68 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z714">
<title id=" W03-0110.xml">on building a high performance gazetteer database </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as such, the conversion scripts must perform some amount of normalization and classification of the input data in order to maintain single unified repository figure 1: the gazetteer production process of geographic data.
</prevsent>
<prevsent>however, in order to justify the over head of consolidating all the data into single entity, it must be possible to output all of it into multiple gazette ers designed for different goals.it should also be possible to perform filtering operations on the gazetteer entries, such as comparing entry names against common-language dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" W03-0108 ">
this can be used determine whether occurrences of gazetteer names in documents are geographically relevant (rauch et al, 2003).<papid> W03-0108 </papid></citsent>
<aftsection>
<nextsent>this is the task for the export scripts.
</nextsent>
<nextsent>however, in this paper, we shall focus on the heart of the system, namely the gazdb.
</nextsent>
<nextsent>section 2 describes how the gazdb relates geographic names and features.
</nextsent>
<nextsent>in section 3 we describe how the gazdb handles ambiguities and inconsistencies in geographic names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z715">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as an algorithm for learning the second stage classifier, we employa decision list learning method.
</prevsent>
<prevsent>experimental evaluation shows that the proposed method achieves improvement over the best known results with japanese named entity extractors based on maximum entropy models.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
in the recent corpus-based nlp research, system combination techniques have been successfully applied to several tasks such as parts-of-speech tagging (van halteren et al, 1998), base noun phrase chunking (tjong kim sang, 2000), and parsing (henderson and brill, 1999; <papid> W99-0623 </papid>henderson and brill, 2000).<papid> A00-2005 </papid></citsent>
<aftsection>
<nextsent>the aim of system combination is to combine portions of the individual systems?
</nextsent>
<nextsent>outputs which are partial but can be regarded as highly accurate.
</nextsent>
<nextsent>the process of system combination can be decomposed into the following two sub-processes: 1.
</nextsent>
<nextsent>collect systems which behave as differently as.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z718">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as an algorithm for learning the second stage classifier, we employa decision list learning method.
</prevsent>
<prevsent>experimental evaluation shows that the proposed method achieves improvement over the best known results with japanese named entity extractors based on maximum entropy models.
</prevsent>
</prevsection>
<citsent citstr=" A00-2005 ">
in the recent corpus-based nlp research, system combination techniques have been successfully applied to several tasks such as parts-of-speech tagging (van halteren et al, 1998), base noun phrase chunking (tjong kim sang, 2000), and parsing (henderson and brill, 1999; <papid> W99-0623 </papid>henderson and brill, 2000).<papid> A00-2005 </papid></citsent>
<aftsection>
<nextsent>the aim of system combination is to combine portions of the individual systems?
</nextsent>
<nextsent>outputs which are partial but can be regarded as highly accurate.
</nextsent>
<nextsent>the process of system combination can be decomposed into the following two sub-processes: 1.
</nextsent>
<nextsent>collect systems which behave as differently as.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z729">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose method for combining outputs of (japanese) named entity chunk ers, which belongs to the family of stacking techniques.
</prevsent>
<prevsent>inthe sub-process 1, we focus on models which differ in the lengths of preceding/subsequent contexts to be incorporated in the models.
</prevsent>
</prevsection>
<citsent citstr=" P00-1042 ">
as the base model for supervised learning of japanese named entity chunking, we employ model based on the maximum entropy model (uchimoto et al, 2000), <papid> P00-1042 </papid>which performed the best in irex (information retrieval and extraction exercise) workshop (irex committee, 1999) among those based on machine learning techniques.</citsent>
<aftsection>
<nextsent>uchimoto et al (2000) <papid> P00-1042 </papid>reported that the optimal number of preceding/subsequent contexts to be incorporated in the model is two morphemes to both left and right from the current position.</nextsent>
<nextsent>in this paper, we train several maximum entropy models which differ in the lengths of preceding/subsequent contexts, and then combine their outputs.as the sub-process 2, we propose to apply stacking technique which learns classifier for combining outputs of several named entity chunkers.this second stage classifier learns rules for accepting/rejecting outputs of several individual named entity chunkers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z741">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> named entity chunking based on.  </section>
<citcontext>
<prevsection>
<prevsent>in the formal run (general domain) table 1: statistics of ne types of irex frequency (%) ne type training test organization 3676 (19.7) 361 (23.9) person 3840 (20.6) 338 (22.4) location 5463 (29.2) 413 (27.4) artifact 747 (4.0) 48 (3.2) date 3567 (19.1) 260 (17.2) time 502 (2.7) 54 (3.5) money 390 (2.1) 15 (1.0) percent 492 (2.6) 21 (1.4) total 18677 1510of the workshop, the participating systems were requested to recognize 1,510 named entities included in the held-out 71 newspaper articles.
</prevsent>
<prevsent>2.2 named entity chunking.
</prevsent>
</prevsection>
<citsent citstr=" W98-1120 ">
we first provide our definition of the task of japanese named entity chunking (sekine et al, 1998; <papid> W98-1120 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>uchimoto et al, 2000).<papid> P00-1042 </papid></citsent>
<aftsection>
<nextsent>suppose that sequence of morphemes is given as below: ( left context ) (named entity) ( right context ) ? ?
</nextsent>
<nextsent>m k ? ?
</nextsent>
<nextsent>m 1 ne 1 ? ?
</nextsent>
<nextsent>m ne ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z742">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> named entity chunking based on.  </section>
<citcontext>
<prevsection>
<prevsent>in the formal run (general domain) table 1: statistics of ne types of irex frequency (%) ne type training test organization 3676 (19.7) 361 (23.9) person 3840 (20.6) 338 (22.4) location 5463 (29.2) 413 (27.4) artifact 747 (4.0) 48 (3.2) date 3567 (19.1) 260 (17.2) time 502 (2.7) 54 (3.5) money 390 (2.1) 15 (1.0) percent 492 (2.6) 21 (1.4) total 18677 1510of the workshop, the participating systems were requested to recognize 1,510 named entities included in the held-out 71 newspaper articles.
</prevsent>
<prevsent>2.2 named entity chunking.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
we first provide our definition of the task of japanese named entity chunking (sekine et al, 1998; <papid> W98-1120 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>uchimoto et al, 2000).<papid> P00-1042 </papid></citsent>
<aftsection>
<nextsent>suppose that sequence of morphemes is given as below: ( left context ) (named entity) ( right context ) ? ?
</nextsent>
<nextsent>m k ? ?
</nextsent>
<nextsent>m 1 ne 1 ? ?
</nextsent>
<nextsent>m ne ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z761">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> named entity chunking based on.  </section>
<citcontext>
<prevsection>
<prevsent>training variable length (59-gram) model, testing with 9-gram model the major disadvantage of the 5/7/9-gram mode lsis that in the training phase it does not take into account whether or not the preceding/subsequent morphemes constitute one named entity together withthe morpheme at the current position.
</prevsent>
<prevsent>considering this disadvantage, we examine another model, namely, variable length model, which incorporates variable length contextual information.
</prevsent>
</prevsection>
<citsent citstr=" C00-2102 ">
in the training phase, this model considers which of the preced ing/subsequent morphemes constitute one named entity together with the morpheme at the current position (sassano and utsuro, 2000).<papid> C00-2102 </papid></citsent>
<aftsection>
<nextsent>it also considers several morphemes in the left/right contexts of the named entity.
</nextsent>
<nextsent>here we restrict this model to explicitly considering the cases of named entities of the length up to three morphemes and only implicitly considering those longer than three morphemes.
</nextsent>
<nextsent>we also restrict it to considering two morphemes in both left and right contexts of the named entity.
</nextsent>
<nextsent>( left context ) (named entity) ( right context ) ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z762">
<title id=" W02-1036.xml">combining outputs of multiple japanese named entity chunk ers by stacking </title>
<section> train the classifier nechk.  </section>
<citcontext>
<prevsection>
<prevsent>, n) 3.4 learning algorithm.
</prevsent>
<prevsent>we apply simple decision list learning method to the task of learning classifier for combining outputs of named entity chunkers4.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
a decision list (yarowsky, 1994) <papid> P94-1013 </papid>is sorted list of decision rules, each of which decides the value of class given some features of an event.</citsent>
<aftsection>
<nextsent>each decision rule in decision list is sorted in descending order with respect to some preference value, and rules with higher preference values are applied first when applying the decision list to some new test data.
</nextsent>
<nextsent>in this paper, we simply sort the decision list according to the conditional probability (class | f) of the class of the i-th systems output given feature . 4 experimental evaluation.
</nextsent>
<nextsent>we experimentally evaluate the performance of the proposed system combination method using the irex workshops training and test data.
</nextsent>
<nextsent>4.1 comparison of outputs of individual.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z765">
<title id=" W03-1311.xml">extracting information on pneumonia in infants using natural language processing of radiology reports </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>in other types of radiology reports, for instance abdominal echogra phy, bpd generally means biparietal diameter, ameasure of the gestation age.
</prevsent>
<prevsent>word sense disambiguation is difficult problem, which is widely discussed in the computational linguistics literature.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
a review of methods for word sense disambiguation is presented by ide and colleagues (ideand veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>in the clinical setting, an important part of the solution will involve identifying the particular domain and use of special purposedomain-specific disambiguators that tag ambiguous abbreviations and specify their appropriate sense prior to parsing, based on the domain and other contextual information.
</nextsent>
<nextsent>defining the appropriate domain granularity will be important, but may be difficult task because the granularity may vary with the abbreviation.
</nextsent>
<nextsent>for example, in the case of radiographic reports, possibly the domain should involve all chest x-rays or only chest x-rays of neonates, or the specific type of reports.
</nextsent>
<nextsent>in this study, we wanted to first evaluate the feasibility of automated surveillance based on nlpin real clinical situation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z766">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, the views must be conditionally independent of each other given the class.
</prevsent>
<prevsent>empirical results on artificial datasets by muslea et al  (2002) and nigam and ghani (2000)confirm that co-training is sensitive to these assumptions.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
indeed, although the algorithm has been applied successfully to natural language processing (nlp) tasks that have natural view factor ization (e.g. web page classification (blum and mitchell, 1998) and named entity classification (collins and singer, 1999)), <papid> W99-0613 </papid>there has been little success, and anumber of reported problems, when applying co training to nlp datasets for which no natural feature split has been found (e.g. anaphora resolution (mueller et al , 2002)).</citsent>
<aftsection>
<nextsent>as result, researchers have begun to investigate co-training procedures that do not require explicit view factorization.
</nextsent>
<nextsent>goldman and zhou (2000) and steedman et al  (2003<papid> N03-1031 </papid>b) use two different learning algorithms in lieu of the multiple views required by standard co-training.1 the intuition is that the two learning algorithms can potentially substitute for thetwo views: different learners have different representation and search biases and can complement each other by inducing different hypotheses from thedata.</nextsent>
<nextsent>despite their similarities, the principles under lying the goldman and zhou and steedman et al  co-training algorithms are fundamentally different.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z767">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, although the algorithm has been applied successfully to natural language processing (nlp) tasks that have natural view factor ization (e.g. web page classification (blum and mitchell, 1998) and named entity classification (collins and singer, 1999)), <papid> W99-0613 </papid>there has been little success, and anumber of reported problems, when applying co training to nlp datasets for which no natural feature split has been found (e.g. anaphora resolution (mueller et al , 2002)).</prevsent>
<prevsent>as result, researchers have begun to investigate co-training procedures that do not require explicit view factorization.</prevsent>
</prevsection>
<citsent citstr=" N03-1031 ">
goldman and zhou (2000) and steedman et al  (2003<papid> N03-1031 </papid>b) use two different learning algorithms in lieu of the multiple views required by standard co-training.1 the intuition is that the two learning algorithms can potentially substitute for thetwo views: different learners have different representation and search biases and can complement each other by inducing different hypotheses from thedata.</citsent>
<aftsection>
<nextsent>despite their similarities, the principles under lying the goldman and zhou and steedman et al  co-training algorithms are fundamentally different.
</nextsent>
<nextsent>in particular, goldman and zhou relyon hypothesis testing to select new instances to add to the labeled data.
</nextsent>
<nextsent>on the other hand, steedman et al  use two learning algorithms that correspond to coarsely different features, thus retaining in spirit the advantages1steedman et al  (2003<papid> N03-1031 </papid>b) bootstrap two parsers that use different statistical models via co-training.</nextsent>
<nextsent>hence, the two parsers can effectively be viewed as two different learning algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z787">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of this paper is two-fold.
</prevsent>
<prevsent>first, we propose single-view algorithm for bootstrapping coreference classifiers.
</prevsent>
</prevsection>
<citsent citstr=" N03-1023 ">
like anaphora resolution, noun phrase coreference resolution is problem for which natural feature split is not readily available.in related work (ng and cardie, 2003), <papid> N03-1023 </papid>we compare the performance of the blum and mitchell co training algorithm with that of two existing single view bootstrapping algorithms ? self-training with bagging (banko and brill, 2001) <papid> P01-1005 </papid>and em (nigam et al ., 2000) ? on coreference resolution, and show that single-view weakly supervised learners are viable alternative to co-training for the task.</citsent>
<aftsection>
<nextsent>this paper instead focuses on developing single-view algorithm that combines aspects of each of the gold man and zhou and steedman et al  algorithms.second, we investigate new method that, inspired by steedman et al  (2003<papid> N03-1031 </papid>a), ranks unlabeled instances to be added to the labeled data in an attempt to alleviate problem commonly observed in bootstrapping experiments ? performance deterioration due to the degradation in the quality of the labeled data as bootstrapping progresses (pierce and cardie, 2001; <papid> W01-0501 </papid>riloff and jones, 1999).in set of baseline experiments, we first demonstrate that multi-view co-training fails to boost the performance of the coreference system under various parameter settings.</nextsent>
<nextsent>we then show that oursingle-view weakly supervised algorithm successfully bootstraps the coreference classifiers, boosting the f-measure score by 9-12% on two standard coreference data sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z789">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of this paper is two-fold.
</prevsent>
<prevsent>first, we propose single-view algorithm for bootstrapping coreference classifiers.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
like anaphora resolution, noun phrase coreference resolution is problem for which natural feature split is not readily available.in related work (ng and cardie, 2003), <papid> N03-1023 </papid>we compare the performance of the blum and mitchell co training algorithm with that of two existing single view bootstrapping algorithms ? self-training with bagging (banko and brill, 2001) <papid> P01-1005 </papid>and em (nigam et al ., 2000) ? on coreference resolution, and show that single-view weakly supervised learners are viable alternative to co-training for the task.</citsent>
<aftsection>
<nextsent>this paper instead focuses on developing single-view algorithm that combines aspects of each of the gold man and zhou and steedman et al  algorithms.second, we investigate new method that, inspired by steedman et al  (2003<papid> N03-1031 </papid>a), ranks unlabeled instances to be added to the labeled data in an attempt to alleviate problem commonly observed in bootstrapping experiments ? performance deterioration due to the degradation in the quality of the labeled data as bootstrapping progresses (pierce and cardie, 2001; <papid> W01-0501 </papid>riloff and jones, 1999).in set of baseline experiments, we first demonstrate that multi-view co-training fails to boost the performance of the coreference system under various parameter settings.</nextsent>
<nextsent>we then show that oursingle-view weakly supervised algorithm successfully bootstraps the coreference classifiers, boosting the f-measure score by 9-12% on two standard coreference data sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z800">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, we propose single-view algorithm for bootstrapping coreference classifiers.
</prevsent>
<prevsent>like anaphora resolution, noun phrase coreference resolution is problem for which natural feature split is not readily available.in related work (ng and cardie, 2003), <papid> N03-1023 </papid>we compare the performance of the blum and mitchell co training algorithm with that of two existing single view bootstrapping algorithms ? self-training with bagging (banko and brill, 2001) <papid> P01-1005 </papid>and em (nigam et al ., 2000) ? on coreference resolution, and show that single-view weakly supervised learners are viable alternative to co-training for the task.</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
this paper instead focuses on developing single-view algorithm that combines aspects of each of the gold man and zhou and steedman et al  algorithms.second, we investigate new method that, inspired by steedman et al  (2003<papid> N03-1031 </papid>a), ranks unlabeled instances to be added to the labeled data in an attempt to alleviate problem commonly observed in bootstrapping experiments ? performance deterioration due to the degradation in the quality of the labeled data as bootstrapping progresses (pierce and cardie, 2001; <papid> W01-0501 </papid>riloff and jones, 1999).in set of baseline experiments, we first demonstrate that multi-view co-training fails to boost the performance of the coreference system under various parameter settings.</citsent>
<aftsection>
<nextsent>we then show that oursingle-view weakly supervised algorithm successfully bootstraps the coreference classifiers, boosting the f-measure score by 9-12% on two standard coreference datasets.
</nextsent>
<nextsent>finally, we present experimental results that suggest that our method for ranking instances is more resistant to performance deterioration in the bootstrapping process than blum and mitchells rank-by-confidence?
</nextsent>
<nextsent>method.
</nextsent>
<nextsent>noun phrase coreference resolution refers to the problem of determining which noun phrases (nps)refer to each real-world entity mentioned in doc ument.2 in this section, we give an overview ofthe coreference resolution system to which the boot 2concrete examples of the coreference task can be found in muc-6 (1995) and muc-7 (1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z801">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> noun phrase coreference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>method.
</prevsent>
<prevsent>noun phrase coreference resolution refers to the problem of determining which noun phrases (nps)refer to each real-world entity mentioned in doc ument.2 in this section, we give an overview ofthe coreference resolution system to which the boot 2concrete examples of the coreference task can be found in muc-6 (1995) and muc-7 (1998).
</prevsent>
</prevsection>
<citsent citstr=" W02-1008 ">
strapping algorithms will be applied.the framework underlying the coreference system is standard combination of classification and clustering (see ng and cardie (2002) <papid> W02-1008 </papid>for details).coreference resolution is first recast as classification task, in which pair of nps is classified as co referring or not based on constraints that are learned from an annotated corpus.</citsent>
<aftsection>
<nextsent>a separate clustering mechanism then coordinates the possibly contradictory pairwise classifications and constructs partition on the set of nps.
</nextsent>
<nextsent>when the system operates within the weakly supervised setting, weakly supervised algorithm bootstraps the coreference classifier from the given labeled and unlabeled data rather than from much larger set of labeled instances.
</nextsent>
<nextsent>the clustering algorithm, however, is not manipulated by the bootstrapping procedure.
</nextsent>
<nextsent>we employ naive bayes and decision list learners in our single-view, multiple-learner framework for bootstrapping coreference classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z803">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> multi-view co-training.  </section>
<citcontext>
<prevsection>
<prevsent>based on observations of the coreference task and the features employed by our coreference system, the justifications suggest that the two learners can potentially compensate for each others weaknesses.
</prevsent>
<prevsent>in this section, we describe the blum and mitchell (b&m;) multi-view co-training algorithm and apply it to coreference resolution.3this justifies the use of decision list as potential classifier for bootstrapping.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
see yarowsky (1995) <papid> P95-1026 </papid>for details.</citsent>
<aftsection>
<nextsent>4.1 the multi-view co-training algorithm.
</nextsent>
<nextsent>the intuition behind the b&m; co-training algorithm is to train two classifiers that can help augment each others labeled data by exploiting two separate but redundant views of the data.
</nextsent>
<nextsent>specifically, each classifier is trained using one view of the labeled data and predicts labels for all instances in the data pool, which consists of randomly chosen subset of the unlabeled data.
</nextsent>
<nextsent>each then selects its most confident predictions, and adds the corresponding instances with their predicted labels to the labeled data while maintaining the class distribution in the labeled data.the number of instances to be added to the labeled data by each classifier at each iteration is limited by pre-specified growth size to ensure that only the instances that have high probability of being assigned the correct label are incorporated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z809">
<title id=" W03-1015.xml">bootstrapping coreference classifiers with multiple machine learning algorithms </title>
<section> multi-view co-training.  </section>
<citcontext>
<prevsection>
<prevsent>see ng and cardie (2003) <papid> N03-1023 </papid>for details.</prevsent>
<prevsent>0 50 100 150 200 250 300 350 400 450 500 20 30 40 50 60 70 80 90 100 number of co training iterations sc or baseline recall precision fmeasure figure 1: learning curve for co-training (pool size = 500, growth size = 50, views formed by randomly splitting the features) for muc-6.</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
using the model-theoretic muc scoring program(vilain et al , 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>the baseline coreference system, which is trained only on the initially labeled data using all of the features, achieves an f-measure of 51.6 (nb) and 28.7 (dl) on the muc-6 dataset and 40.1 (nb) and 45.8 (dl) on muc-7.
</nextsent>
<nextsent>the results shown in row 2 of table 2 correspond to the best f-measure scores achieved by co-training across all of the parameter combinations described in the previous subsection.
</nextsent>
<nextsent>in comparison to the baseline, co-training is able to improve system performance in only two of the four classifier/data set combinations: f-measure increases by 2% and 6%for muc-6/dl and muc-7/nb, respectively.
</nextsent>
<nextsent>nevertheless, co-training produces high-precision classifiers in all four cases (at the expense of recall).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z833">
<title id=" W03-0107.xml">bootstrapping toponym classifiers </title>
<section> scope and prior work.  </section>
<citcontext>
<prevsection>
<prevsent>or spring field, ma?
</prevsent>
<prevsent>and test the system on text where these cues have been stripped out and on hand-tagged historical texts.
</prevsent>
</prevsection>
<citsent citstr=" A97-1030 ">
as in early work with such named-entity recognition systems as nominator (wacholder et al, 1997), <papid> A97-1030 </papid>much previous work in gnd has relied on heuristic rules (ol ligschlaeger and hauptmann, 1999; kanada, 1999) andsuch culturally specific and knowledge intensive techniques as postal codes, addresses, and telephone numbers (mccurley, 2001).</citsent>
<aftsection>
<nextsent>in previous work, we used the heuristic technique of calculating weighted centro ids of geographic focus in documents (smith and crane, 2001).
</nextsent>
<nextsent>sites closer to the centro id were weighted more heavily than sites far away unless they had some countervailing importance such as being world capital.news texts offer two principal advantages for bootstrapping geo coding applications.
</nextsent>
<nextsent>just as journalistic style prefers identifying persons by full name and title on first mention, place names, when not of major cities, are often first mentioned followed by the name of their state,province, or country.
</nextsent>
<nextsent>even if toponym is strictly unambiguous, it may still be labelled to provide the reader with some backoff?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z834">
<title id=" W03-0107.xml">bootstrapping toponym classifiers </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>in trying to disambiguate portland?, we would thus consider oregon, maine, and england, among other options, but not maryland.
</prevsent>
<prevsent>as in the word sense disambiguation task as usually defined, we are classifying names and not clustering them.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
this approach is practical for geographic names, for which broad-coverage gazette ers exist, though less so for personal names (mann and yarowsky, 2003).<papid> W03-0405 </papid></citsent>
<aftsection>
<nextsent>system performance is measured with reference to the naive baseline where each ambiguous toponym is guessed to be the most commonly occurring place.
</nextsent>
<nextsent>london, england, would thus always be guessed rather than london, ontario.
</nextsent>
<nextsent>bootstrapping methods similar to ours have been shown to be competitive in word sense disambiguation (yarowsky and florian, 2003; yarowsky, 1995).<papid> P95-1026 </papid></nextsent>
<nextsent>our ability to disambiguate place names should be weighed against the ease or difficulty of the task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z835">
<title id=" W03-0107.xml">bootstrapping toponym classifiers </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>system performance is measured with reference to the naive baseline where each ambiguous toponym is guessed to be the most commonly occurring place.
</prevsent>
<prevsent>london, england, would thus always be guessed rather than london, ontario.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
bootstrapping methods similar to ours have been shown to be competitive in word sense disambiguation (yarowsky and florian, 2003; yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>our ability to disambiguate place names should be weighed against the ease or difficulty of the task.
</nextsent>
<nextsent>in world where most toponyms referred unambiguously to one place, we would not be impressed by near-perfect performance.
</nextsent>
<nextsent>before considering how toponyms are used in text, we can examine the inherent ambiguity of place names in 1our annotated data also includes disambiguated texts of herodotus?
</nextsent>
<nextsent>histories and caesars gallic war, but toponyms inthe ancient (especially greek) world do not show enough ambiguity with personal names or with each other to be interesting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z836">
<title id=" W02-1704.xml">xmlxsl in the dictionary the case of discourse markers </title>
<section> requirements on discourse.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 the text understanding perspective.
</prevsent>
<prevsent>in text understanding, discourse markers serve as cues for inferring the rhetorical or semantic structure of the text.
</prevsent>
</prevsection>
<citsent citstr=" P97-1013 ">
in the approach proposed in (marcu, 1997), <papid> P97-1013 </papid>for example, the presence of discourse markers is used to hypothesize individual textual units and relations holding between them.</citsent>
<aftsection>
<nextsent>then, the overall discourse structure tree is built using constraint satisfactiontechniques.
</nextsent>
<nextsent>our analysis method uses the lexicon for an initial identification and disambiguation of discourse markers.
</nextsent>
<nextsent>they serve as one of several other shallow features that determine through statistical, learned language model the optimal rhetorical analysis.in contrast to the use of markers in generation, the list of cues is significantly longer and includes phrasal items like aus diesem grund (for this reason) or genauer genommen (more precisely).
</nextsent>
<nextsent>in the following we show some sample representations and style sheets that have been abridged for presentation purposes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z837">
<title id=" W02-1704.xml">xmlxsl in the dictionary the case of discourse markers </title>
<section> our xml/xsl solution.  </section>
<citcontext>
<prevsection>
<prevsent>5.3 the text generation view.
</prevsent>
<prevsent>for the lexicon to be applied in our text generation system polibox?
</prevsent>
</prevsection>
<citsent citstr=" C02-2027 ">
(stede, 2002),<papid> C02-2027 </papid>we need lisp-based version of dim lex.</citsent>
<aftsection>
<nextsent>using the (defstruct  name   slot1   xml version= 1.0 ?   xsl:stylesheet xmlns:xsl=  http://www.w3.org/1999/xsl/transform   5  xsl:template match= /    font size= -2    xsl:apply-templates/   /font   /xsl:template  10  xsl:template match= dictionary    xsl:apply-templates/   /xsl:template   xsl:template match= entry     font size= 2     15  xsl:attribute name= name    xsl:value-of select= form/orth /   /xsl:attribute   xsl:value-of select= ./@id / :  xsl:value-of select= form/orth /  20  /a  /b  /font   xsl:apply-templates/  /p   /xsl:template   xsl:template match= form    xsl:choose  25  xsl:when match= .[alt_orth=none?]    /xsl:when   xsl:otherwise   br/  alternative orthography: /b   xsl:value-of select= alt_orth /  30  /xsl:otherwise   /xsl:choose   /xsl:template   xsl:template match= sem    br/  semantics: /b  35  xsl:value-of select= ko_sub /  /  xsl:value-of select= function /   br/  related markers: /b   xsl:for-each select= rel     xsl:attribute name= href   40 # xsl:value-of select= . /   /xsl:attribute   xsl:value-of select= . /  /a   /xsl:for-each   /xsl:template  45  xsl:template match= syn    br/  occurrences: /b   xsl:choose   xsl:when match= .[init\_field=?-?]    /xsl:when  50  xsl:otherwise  initial field /  /xsl:otherwise   /xsl:choose   /xsl:template  55  xsl:template match= examples    br/  examples: /b   xsl:for-each select= example    xsl:value-of select= . /  br/   /xsl:for-each  60  /xsl:template   /xsl:stylesheet  figure 4: the xsl file for the html view shown in figure 2..
</nextsent>
<nextsent> slotn ) construct, we define class of objects for discourse markers, where the features needed for generation are stored in the slots.
</nextsent>
<nextsent>again, we abbreviate slightly: (defstruct disc marker relation n-complexity s-complexity ortho pos ...
</nextsent>
<nextsent>style)now, lisp-object for each individual discourse marker entry is created with the function make-discmarker, which provides the values for the slots.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z838">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>studies on named entity (ne) extraction are making progress for various languages, such as english and japanese.
</prevsent>
<prevsent>a number of evaluation workshops have been held, including the message understanding conference (muc)1 for english and other languages, and the information retrieval and extraction exercise (irex)2 for japanese.
</prevsent>
</prevsection>
<citsent citstr=" M98-1002 ">
extraction accuracy for english has reached nearly practical level (marsh and perzanowski, 1998).<papid> M98-1002 </papid></citsent>
<aftsection>
<nextsent>as for japanese, it is more difficult to find ne bound 1http://www.itl.nist.gov/iaui/894.02/ related_projects/muc/ 2http://nlp.cs.nyu.edu/irex/ aries, however, ne extraction is relatively accurate (sekine and isahara, 2000).
</nextsent>
<nextsent>most of the past research on ne extraction used monolingual corpora, but the application of ne extraction techniques to bilingual (or multilingual) corpora is expected to obtain ne translation pairs.
</nextsent>
<nextsent>weare developing japanese-english machine translation system for documents including many nes, such as news articles or documents about current topics.
</nextsent>
<nextsent>translating ne correctly is indispensable for conveying information correctly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z839">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are few japanese-english corpora which are translated literally.
</prevsent>
<prevsent>therefore, we decided to extract ne translation pairs fromcontent-aligned corpora, such as multilingual broadcast news articles including new nes daily, which are not literally translated.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
sentential alignment (brown et al, 1991; <papid> P91-1022 </papid>galeand church, 1993; <papid> J93-1004 </papid>kay and roscheisen, 1993; <papid> J93-1006 </papid>ut suro et al, 1994; <papid> C94-2175 </papid>haruno and yamazaki, 1996) <papid> P96-1018 </papid>is commonly used as starting point for finding the translations of words or expressions from bilingualcorpora.</citsent>
<aftsection>
<nextsent>however, it is not always possible to correspond non-parallel corpora in sentences.
</nextsent>
<nextsent>past statistical methods for non-parallel corpora (fung and yee, 1998) <papid> P98-1069 </papid>are not valid for finding translations of words or expressions with low frequency.</nextsent>
<nextsent>these methods have problem in covering nes because there are many nes that appear only once in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z840">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are few japanese-english corpora which are translated literally.
</prevsent>
<prevsent>therefore, we decided to extract ne translation pairs fromcontent-aligned corpora, such as multilingual broadcast news articles including new nes daily, which are not literally translated.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
sentential alignment (brown et al, 1991; <papid> P91-1022 </papid>galeand church, 1993; <papid> J93-1004 </papid>kay and roscheisen, 1993; <papid> J93-1006 </papid>ut suro et al, 1994; <papid> C94-2175 </papid>haruno and yamazaki, 1996) <papid> P96-1018 </papid>is commonly used as starting point for finding the translations of words or expressions from bilingualcorpora.</citsent>
<aftsection>
<nextsent>however, it is not always possible to correspond non-parallel corpora in sentences.
</nextsent>
<nextsent>past statistical methods for non-parallel corpora (fung and yee, 1998) <papid> P98-1069 </papid>are not valid for finding translations of words or expressions with low frequency.</nextsent>
<nextsent>these methods have problem in covering nes because there are many nes that appear only once in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z841">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are few japanese-english corpora which are translated literally.
</prevsent>
<prevsent>therefore, we decided to extract ne translation pairs fromcontent-aligned corpora, such as multilingual broadcast news articles including new nes daily, which are not literally translated.
</prevsent>
</prevsection>
<citsent citstr=" J93-1006 ">
sentential alignment (brown et al, 1991; <papid> P91-1022 </papid>galeand church, 1993; <papid> J93-1004 </papid>kay and roscheisen, 1993; <papid> J93-1006 </papid>ut suro et al, 1994; <papid> C94-2175 </papid>haruno and yamazaki, 1996) <papid> P96-1018 </papid>is commonly used as starting point for finding the translations of words or expressions from bilingualcorpora.</citsent>
<aftsection>
<nextsent>however, it is not always possible to correspond non-parallel corpora in sentences.
</nextsent>
<nextsent>past statistical methods for non-parallel corpora (fung and yee, 1998) <papid> P98-1069 </papid>are not valid for finding translations of words or expressions with low frequency.</nextsent>
<nextsent>these methods have problem in covering nes because there are many nes that appear only once in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z842">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are few japanese-english corpora which are translated literally.
</prevsent>
<prevsent>therefore, we decided to extract ne translation pairs fromcontent-aligned corpora, such as multilingual broadcast news articles including new nes daily, which are not literally translated.
</prevsent>
</prevsection>
<citsent citstr=" C94-2175 ">
sentential alignment (brown et al, 1991; <papid> P91-1022 </papid>galeand church, 1993; <papid> J93-1004 </papid>kay and roscheisen, 1993; <papid> J93-1006 </papid>ut suro et al, 1994; <papid> C94-2175 </papid>haruno and yamazaki, 1996) <papid> P96-1018 </papid>is commonly used as starting point for finding the translations of words or expressions from bilingualcorpora.</citsent>
<aftsection>
<nextsent>however, it is not always possible to correspond non-parallel corpora in sentences.
</nextsent>
<nextsent>past statistical methods for non-parallel corpora (fung and yee, 1998) <papid> P98-1069 </papid>are not valid for finding translations of words or expressions with low frequency.</nextsent>
<nextsent>these methods have problem in covering nes because there are many nes that appear only once in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z843">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are few japanese-english corpora which are translated literally.
</prevsent>
<prevsent>therefore, we decided to extract ne translation pairs fromcontent-aligned corpora, such as multilingual broadcast news articles including new nes daily, which are not literally translated.
</prevsent>
</prevsection>
<citsent citstr=" P96-1018 ">
sentential alignment (brown et al, 1991; <papid> P91-1022 </papid>galeand church, 1993; <papid> J93-1004 </papid>kay and roscheisen, 1993; <papid> J93-1006 </papid>ut suro et al, 1994; <papid> C94-2175 </papid>haruno and yamazaki, 1996) <papid> P96-1018 </papid>is commonly used as starting point for finding the translations of words or expressions from bilingualcorpora.</citsent>
<aftsection>
<nextsent>however, it is not always possible to correspond non-parallel corpora in sentences.
</nextsent>
<nextsent>past statistical methods for non-parallel corpora (fung and yee, 1998) <papid> P98-1069 </papid>are not valid for finding translations of words or expressions with low frequency.</nextsent>
<nextsent>these methods have problem in covering nes because there are many nes that appear only once in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z844">
<title id=" W03-1503.xml">construction and analysis of japanese english broadcast news corpus with named entity tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentential alignment (brown et al, 1991; <papid> P91-1022 </papid>galeand church, 1993; <papid> J93-1004 </papid>kay and roscheisen, 1993; <papid> J93-1006 </papid>ut suro et al, 1994; <papid> C94-2175 </papid>haruno and yamazaki, 1996) <papid> P96-1018 </papid>is commonly used as starting point for finding the translations of words or expressions from bilingualcorpora.</prevsent>
<prevsent>however, it is not always possible to correspond non-parallel corpora in sentences.</prevsent>
</prevsection>
<citsent citstr=" P98-1069 ">
past statistical methods for non-parallel corpora (fung and yee, 1998) <papid> P98-1069 </papid>are not valid for finding translations of words or expressions with low frequency.</citsent>
<aftsection>
<nextsent>these methods have problem in covering nes because there are many nes that appear only once in corpus.
</nextsent>
<nextsent>so we need specialized method for extracting ne translation pairs.
</nextsent>
<nextsent>transliteration is used for finding the translations of ne in the source language from texts in the target language (stalls and knight, 1998; goto et al, 2001; al-onazian and knight,2002).
</nextsent>
<nextsent>transliteration is useful for the names of persons and places; however, it is not applicable to all sorts of nes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z845">
<title id=" W03-1206.xml">hitiqa an interactive question answering system a preliminary report </title>
<section> human-computer dialogue: how the user.  </section>
<citcontext>
<prevsection>
<prevsent>as the answer, while how long was the titanic??
</prevsent>
<prevsent>expects some length measure as an answer, probably in yards and feet, or meters.
</prevsent>
</prevsection>
<citsent citstr=" C00-1043 ">
this is generally very good strategy, that has been exploited successfully in number of automated qa systems that appeared in recent years, especially in the context of trec qa1 evaluations (harabagiu et al, 2000; <papid> C00-1043 </papid>hovy et al, 2000; prager at al., 2001).</citsent>
<aftsection>
<nextsent>this process is not easily applied to analytical questions.
</nextsent>
<nextsent>this is because the type of an answer for analytical questions cannot always be anticipated due to their inherently exploratory character.
</nextsent>
<nextsent>in contrast to factual question, an analytical question has an unlimited variety of syntactic forms with only loose connection between their syntax and the expected answer.
</nextsent>
<nextsent>given the unlimited potential of the formation of analytical questions, it would be counter-productive to restrict them to limited number of question/answer types.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z846">
<title id=" W03-1206.xml">hitiqa an interactive question answering system a preliminary report </title>
<section> framing.  </section>
<citcontext>
<prevsection>
<prevsent>we have modified gate to separate organizations into companies and other organizations, and we have also expanded by adding new concepts such as industries.
</prevsent>
<prevsent>therefore, the framing process resembles strongly the template filling task in information extraction (cf.
</prevsent>
</prevsection>
<citsent citstr=" M98-1007 ">
muc3 evaluations), with one significant exception: while the muc task was to fill in template using potentially any amount of source text (humphreys et al, 1998), <papid> M98-1007 </papid>the framing is essentially an inverse process.</citsent>
<aftsection>
<nextsent>in framing, potentially multiple frames can be associated with small chunk of text (a passage or short paragraph).
</nextsent>
<nextsent>furthermore, this chunk of text is part of cluster of very similar text chunks that further reinforce some of the most salient features of these texts.
</nextsent>
<nextsent>this makes the frame filling significantly less error-prone task ? our experience has been far more positive than the muc evaluation results may indicate.
</nextsent>
<nextsent>this is because, rather than trying to find the most appropriate values for attributes from among many potential candidates, we in essence fit the frames over small passages4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z847">
<title id=" W03-1206.xml">hitiqa an interactive question answering system a preliminary report </title>
<section> enabling dialogue with the user.  </section>
<citcontext>
<prevsection>
<prevsent>the main advantage of the amities model is its reliance on data-driven semantics which allows for spontaneous and mixed initiative dialogue to occur.
</prevsent>
<prevsent>by contrast, the major approaches to implementation of dialogue systems to date relyon systems of functional transitions that make the resulting system much less flexible.
</prevsent>
</prevsection>
<citsent citstr=" W00-0303 ">
in the grammar-based approach, which is prevalent in commercial systems, such as in various telephony products, as well as in practically oriented research prototypes5, (e.g., darpa, 2002; seneff and polifoni, 2000; <papid> W00-0303 </papid>ferguson and allen, 1998) complete dialogue transition graph is designed to guide the conversation and predict user responses, which is suitable for closed domains only.</citsent>
<aftsection>
<nextsent>in the statistical variation of this approach, transition graph is derived from large body of annotated conversations (e.g., walker, 2000; litman and pan, 2002).
</nextsent>
<nextsent>this latter approach is facilitated through dialogue annotation process, e.g., using dialogue act markup in several layers (damsl) (allen and core, 1997), which is system of functional dialogue acts.
</nextsent>
<nextsent>nonetheless, an efficient, spontaneous dialogue cannot be designed on purely functional layer.
</nextsent>
<nextsent>therefore, here we are primarily interested in the semantic layer, that is, the information exchange and information building effects of conversation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z848">
<title id=" W03-0803.xml">ollie online learning for information extraction </title>
<section> implementation of the ollie server.  </section>
<citcontext>
<prevsection>
<prevsent>mostof the data transferred during the client-server communication is also compressed, which reduces the level of network traffic ? always problem in client server architectures that run over the internet.
</prevsent>
<prevsent>figure 2: annotating text in the ollie client another utility provided by the client is page that lets the user specify the access rights to the doc ument/corpus, which determine whether it can be shared for viewing or collaborative annotation (see section 4 for details on security).
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
while the client side of the ollie application is presented as set of web pages, the server part is based on the open source gate architecture.gate is an infrastructure for developing and deploying software components that process human language (cunningham et al, 2002).<papid> P02-1022 </papid></citsent>
<aftsection>
<nextsent>it is written in java and exploits component-based software development, object orientation and mobile code.
</nextsent>
<nextsent>on equality of gate is that it uses unicode through out (tablan et al, 2002).
</nextsent>
<nextsent>its unicode capabilities have been tested on variety of slavic, germanic,romance, and indic languages (gamback and olsson, 2000; baker et al, 2002).
</nextsent>
<nextsent>this allows ollie to handle documents in languages other than english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z852">
<title id=" W03-0803.xml">ollie online learning for information extraction </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>be cause the documents reside on the shared server oneuser can see errors or questionable markup introduced by another user and initiate discussion.
</prevsent>
<prevsent>such collaborative annotation is useful in the wider context of creating and sharing language resources (ma et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
a number of machine learning approaches for information extraction have been developed recently, e.g., (collins, 2002; <papid> P02-1062 </papid>bikel et al, 1999), including some that use active learning, e.g., (thomp sonet al, 1999) or offer automated support, e.g,(ciravegna et al, 2002), in order to lower the overhead of annotating training data.</citsent>
<aftsection>
<nextsent>while there exist corpora used for comparative evaluation, (e.g., muc or the cmu seminar corpus), there is no easyway to test those ml algorithms on other data, evaluate their portability to new domains, or experiment with different parameters of the models.
</nextsent>
<nextsent>while some of the algorithms are available for experimentation, they are implemented in different languages, require different data formats, and run on different platforms.
</nextsent>
<nextsent>all of this makes it hard to ensure experimental repeatability and eliminate site-specific skew effects.
</nextsent>
<nextsent>also, since not all systems are freely available, we propose an open, distributed environment where researchers can experiment with different learning methods on their own data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z853">
<title id=" W03-1712.xml">building a large chinese corpus annotated with semantic dependency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as basic research tools for investigators in natural language processing, large annotated corpora play an important role in investigating diverse language phenomena, building statistical language models, evaluating and comparing kinds of parsing models.
</prevsent>
<prevsent>at present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for example, the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus.</citsent>
<aftsection>
<nextsent>for chinese, some corpora annotated with phrase structure also have been built, for instance the penn chinese treebank (xia et al, 2000) and sina corpus (huang and chen, 1992).<papid> C92-4194 </papid></nextsent>
<nextsent>a syntactic annotation scheme based on dependency was proposed by (lai and huang, 2000), <papid> P00-1033 </papid>and small corpus was built for testing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z854">
<title id=" W03-1712.xml">building a large chinese corpus annotated with semantic dependency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at present most of corpora are annotated mainly with syntactic knowledge, though some function tags are added to annotate semantic knowledge.
</prevsent>
<prevsent>for example, the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus.</prevsent>
</prevsection>
<citsent citstr=" C92-4194 ">
for chinese, some corpora annotated with phrase structure also have been built, for instance the penn chinese treebank (xia et al, 2000) and sina corpus (huang and chen, 1992).<papid> C92-4194 </papid></citsent>
<aftsection>
<nextsent>a syntactic annotation scheme based on dependency was proposed by (lai and huang, 2000), <papid> P00-1033 </papid>and small corpus was built for testing.</nextsent>
<nextsent>however, very limited work has been done with annotation semantic knowledge in all languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z855">
<title id=" W03-1712.xml">building a large chinese corpus annotated with semantic dependency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus.</prevsent>
<prevsent>for chinese, some corpora annotated with phrase structure also have been built, for instance the penn chinese treebank (xia et al, 2000) and sina corpus (huang and chen, 1992).<papid> C92-4194 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1033 ">
a syntactic annotation scheme based on dependency was proposed by (lai and huang, 2000), <papid> P00-1033 </papid>and small corpus was built for testing.</citsent>
<aftsection>
<nextsent>however, very limited work has been done with annotation semantic knowledge in all languages.
</nextsent>
<nextsent>from 1999, berkeley started framenet project (baker et al, 1998), <papid> P98-1013 </papid>which produced the frame-semantic descriptions of several thousand english lexical items and backed up these description with semantically annotated attestations from contemporary english corpus.</nextsent>
<nextsent>although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example english wordnet (miller et al, 1993) and chinese hownet (dong and dong, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z856">
<title id=" W03-1712.xml">building a large chinese corpus annotated with semantic dependency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a syntactic annotation scheme based on dependency was proposed by (lai and huang, 2000), <papid> P00-1033 </papid>and small corpus was built for testing.</prevsent>
<prevsent>however, very limited work has been done with annotation semantic knowledge in all languages.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
from 1999, berkeley started framenet project (baker et al, 1998), <papid> P98-1013 </papid>which produced the frame-semantic descriptions of several thousand english lexical items and backed up these description with semantically annotated attestations from contemporary english corpus.</citsent>
<aftsection>
<nextsent>although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example english wordnet (miller et al, 1993) and chinese hownet (dong and dong, 2001).
</nextsent>
<nextsent>for chinese, many attentions have been naturally paid to researches on semantics, because chinese is meaning-combined language, its syntax is very flexible, and semantic rules are more stable than syntactic rules.
</nextsent>
<nextsent>for instance, in chinese it is very pervasive that more than one part-of -speeches word has, and word does not have tense or voice flec tional transition under different tenses or voices.
</nextsent>
<nextsent>nevertheless, no large chinese corpus annotated with semantic knowledge has ever been built at present.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z857">
<title id=" W03-1106.xml">text classification in asian languages without word segmentation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we have presented simple language model based approach without word segmentation for chinese and japanese text classification.
</prevsent>
<prevsent>by comparison tothree standard text classifiers, the language modeling approach consistently demonstrates better classification accuracies while avoiding word segmentation and feature selection.
</prevsent>
</prevsection>
<citsent citstr=" C02-1148 ">
although straightforward, the language modeling approach appears to give state of the art results for chinese and japanese text classification.it has been found that word segmentation in chinese text retrieval is tricky and the relationship between word segmentation and retrieval performance is not monotonic (peng et al, 2002).<papid> C02-1148 </papid></citsent>
<aftsection>
<nextsent>however, since text classification and text retrieval are two different tasks, it is not clear whether the same relationship exists in text classification context.
</nextsent>
<nextsent>we are currently investigating this issue and interesting findings have already been observed.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z858">
<title id=" W03-0408.xml">updating an nlp system to fit new domains an empirical study on the sentence segmentation problem </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular they did not consider the main issues investigated in this paper as well as generally applicable supervised adaptation methodologies such as what we propose.
</prevsent>
<prevsent>in fact, it will be very difficult to extend their methods to natural language processing problems that use different statistical models.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
the adaption idea in (gales and woodland, 1996) is also closely related to the idea of combining supervised and unsupervised learning in the same domain (merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>in machine learning, thisis often referred to as semi-supervised learning or learning with unlabeled data.
</nextsent>
<nextsent>such methods are not always reliable and can often fail(zhang and oles, 2000).
</nextsent>
<nextsent>although potentially useful for small distributional parameter shifts, they cannot recover labels for examples not (or inadequately) represented in the old training data.
</nextsent>
<nextsent>in such cases, it is necessary to use supervised adaption methods which we study in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z859">
<title id=" W03-0408.xml">updating an nlp system to fit new domains an empirical study on the sentence segmentation problem </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in such cases, it is necessary to use supervised adaption methods which we study in this paper.
</prevsent>
<prevsent>another related idea is so called active learning paradigm (lewis and catlett, 1994; zhang and oles, 2000), which selectively annotates themost informative data (from the same domain) so as to reduce the total number of annotations required to achievea certain level of accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
see (tang et al, 2002; <papid> P02-1016 </papid>steedman et al, 2003) <papid> N03-1031 </papid>for related studies in statistical natural language parsing.</citsent>
<aftsection>
<nextsent>boundary detection for the purpose of this paper, we consider the following form of the sentence boundary detection problem: to determine for each period ?.?
</nextsent>
<nextsent>whether it denotes sentence boundary or not (most non-sentence boundary cases occur in abbreviations).
</nextsent>
<nextsent>although other symbols such as ???
</nextsent>
<nextsent>and ?!?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z860">
<title id=" W03-0408.xml">updating an nlp system to fit new domains an empirical study on the sentence segmentation problem </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in such cases, it is necessary to use supervised adaption methods which we study in this paper.
</prevsent>
<prevsent>another related idea is so called active learning paradigm (lewis and catlett, 1994; zhang and oles, 2000), which selectively annotates themost informative data (from the same domain) so as to reduce the total number of annotations required to achievea certain level of accuracy.
</prevsent>
</prevsection>
<citsent citstr=" N03-1031 ">
see (tang et al, 2002; <papid> P02-1016 </papid>steedman et al, 2003) <papid> N03-1031 </papid>for related studies in statistical natural language parsing.</citsent>
<aftsection>
<nextsent>boundary detection for the purpose of this paper, we consider the following form of the sentence boundary detection problem: to determine for each period ?.?
</nextsent>
<nextsent>whether it denotes sentence boundary or not (most non-sentence boundary cases occur in abbreviations).
</nextsent>
<nextsent>although other symbols such as ???
</nextsent>
<nextsent>and ?!?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z861">
<title id=" W03-0408.xml">updating an nlp system to fit new domains an empirical study on the sentence segmentation problem </title>
<section> generalized winnow for sentence.  </section>
<citcontext>
<prevsection>
<prevsent>token before the period token after the period character to the right type of character to the right character to the left type of character to the left character to the right of blank after word type of character to the right of blank after word character left of first character of word type of character left of first character of word first character of the preceding word type of first character of the preceding word length of preceding word distance to previous period table 1: linguistic features the features presented here may not be optimal.
</prevsent>
<prevsent>in particular, unlike (zhang et al, 2002), we do not use higher order features (for example, combinations of the above features).
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
however, this list of features has already given good performance, comparing favorably with previous approaches (see (reynar and ratnaparkhi, 1997; <papid> A97-1004 </papid>mikheev, 2000) <papid> A00-2035 </papid>and references therein).</citsent>
<aftsection>
<nextsent>the standard evaluation data is the wall-street journal (wsj) tree-bank.
</nextsent>
<nextsent>based on our processing scheme, the training set contains about seventy-four thousand periods, and the test set contains about thirteen thousand periods.
</nextsent>
<nextsent>if we train on the training set, and test on the test set, the accuracy is ?l???
</nextsent>
<nextsent>another dataset which has been annotated is the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z862">
<title id=" W03-0408.xml">updating an nlp system to fit new domains an empirical study on the sentence segmentation problem </title>
<section> generalized winnow for sentence.  </section>
<citcontext>
<prevsection>
<prevsent>token before the period token after the period character to the right type of character to the right character to the left type of character to the left character to the right of blank after word type of character to the right of blank after word character left of first character of word type of character left of first character of word first character of the preceding word type of first character of the preceding word length of preceding word distance to previous period table 1: linguistic features the features presented here may not be optimal.
</prevsent>
<prevsent>in particular, unlike (zhang et al, 2002), we do not use higher order features (for example, combinations of the above features).
</prevsent>
</prevsection>
<citsent citstr=" A00-2035 ">
however, this list of features has already given good performance, comparing favorably with previous approaches (see (reynar and ratnaparkhi, 1997; <papid> A97-1004 </papid>mikheev, 2000) <papid> A00-2035 </papid>and references therein).</citsent>
<aftsection>
<nextsent>the standard evaluation data is the wall-street journal (wsj) tree-bank.
</nextsent>
<nextsent>based on our processing scheme, the training set contains about seventy-four thousand periods, and the test set contains about thirteen thousand periods.
</nextsent>
<nextsent>if we train on the training set, and test on the test set, the accuracy is ?l???
</nextsent>
<nextsent>another dataset which has been annotated is the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z863">
<title id=" W03-1806.xml">multiword unit hybrid extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as consequence, their identification is crucial issue for applications that require some degree of semantic processing (e.g. machine translation, summarization, information retrieval).
</prevsent>
<prevsent>in recent years, there has been growing awareness in the natural language processing (nlp) community of the problems that mwus pose and the need for their robust handling.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
for that purpose, syntactical (didier bourigault, 1993), statistical (frank smadja, 1993; <papid> J93-1007 </papid>ted dunning, 1993; <papid> J93-1003 </papid>gal dias, 2002) and hybrid syntaxicostatistical methodologies (batrice daille, 1996; jean philippe goldman et al 2001) have been proposed.</citsent>
<aftsection>
<nextsent>in this paper, we propose an original hybrid system called helas1 that extracts mwu candidates from part-of-speech tagged corpora.
</nextsent>
<nextsent>unlike classical hybrid systems that manually pre-define local part-of-speech patterns of interest (batrice daille, 1996; jean-philippe goldman et al 2001), our solution automatically identifies relevant syntactical patterns from the corpus.
</nextsent>
<nextsent>word statistics are then combined with the endogenously acquired linguistic information in order to extract the most relevant sequences of words i.e. mwu candidates.
</nextsent>
<nextsent>technically, we conjugate the mutual expectation (me) association measure with the acquisition process called genlocalmaxs (gal dias, 2002) in five step process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z866">
<title id=" W03-1806.xml">multiword unit hybrid extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as consequence, their identification is crucial issue for applications that require some degree of semantic processing (e.g. machine translation, summarization, information retrieval).
</prevsent>
<prevsent>in recent years, there has been growing awareness in the natural language processing (nlp) community of the problems that mwus pose and the need for their robust handling.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
for that purpose, syntactical (didier bourigault, 1993), statistical (frank smadja, 1993; <papid> J93-1007 </papid>ted dunning, 1993; <papid> J93-1003 </papid>gal dias, 2002) and hybrid syntaxicostatistical methodologies (batrice daille, 1996; jean philippe goldman et al 2001) have been proposed.</citsent>
<aftsection>
<nextsent>in this paper, we propose an original hybrid system called helas1 that extracts mwu candidates from part-of-speech tagged corpora.
</nextsent>
<nextsent>unlike classical hybrid systems that manually pre-define local part-of-speech patterns of interest (batrice daille, 1996; jean-philippe goldman et al 2001), our solution automatically identifies relevant syntactical patterns from the corpus.
</nextsent>
<nextsent>word statistics are then combined with the endogenously acquired linguistic information in order to extract the most relevant sequences of words i.e. mwu candidates.
</nextsent>
<nextsent>technically, we conjugate the mutual expectation (me) association measure with the acquisition process called genlocalmaxs (gal dias, 2002) in five step process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z876">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the blocks are further filtered using unigram-count selection criteria.
</prevsent>
<prevsent>the system has been successfully test on chinese-english and an arabic english translation task.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
various papers use phrase-based translation systems(och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.
</nextsent>
<nextsent>specifically, we compute the probability of block sequence
</nextsent>
<nextsent> . block   is pair consisting of contiguous source and contiguous target phrase.
</nextsent>
<nextsent>the block sequence figure 1: block sequence that jointly generates  target and source phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z877">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the blocks are further filtered using unigram-count selection criteria.
</prevsent>
<prevsent>the system has been successfully test on chinese-english and an arabic english translation task.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
various papers use phrase-based translation systems(och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.
</nextsent>
<nextsent>specifically, we compute the probability of block sequence
</nextsent>
<nextsent> . block   is pair consisting of contiguous source and contiguous target phrase.
</nextsent>
<nextsent>the block sequence figure 1: block sequence that jointly generates  target and source phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z878">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the blocks are further filtered using unigram-count selection criteria.
</prevsent>
<prevsent>the system has been successfully test on chinese-english and an arabic english translation task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
various papers use phrase-based translation systems(och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.
</nextsent>
<nextsent>specifically, we compute the probability of block sequence
</nextsent>
<nextsent> . block   is pair consisting of contiguous source and contiguous target phrase.
</nextsent>
<nextsent>the block sequence figure 1: block sequence that jointly generates  target and source phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z879">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the blocks are further filtered using unigram-count selection criteria.
</prevsent>
<prevsent>the system has been successfully test on chinese-english and an arabic english translation task.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
various papers use phrase-based translation systems(och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.
</nextsent>
<nextsent>specifically, we compute the probability of block sequence
</nextsent>
<nextsent> . block   is pair consisting of contiguous source and contiguous target phrase.
</nextsent>
<nextsent>the block sequence figure 1: block sequence that jointly generates  target and source phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z884">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> block generation algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes dp-based decoder using blocks.
</prevsent>
<prevsent>experimental results are presented in section 4.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
starting point for the block generation algorithm is word alignment obtained from an hmm viterbi training (vogel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>the hmm viterbi training is carried out twice with english as target language and chinese as source language and vice versa.
</nextsent>
<nextsent>we obtain two alignment relations: @ml no6p rtso:fi= rvu$pxwzy\[ k^] no6*8%_`qy:fi= 8au y,wzp [ rbu/pcwdy is an alignment function from source to target positions and 8autyewfp is an alignment function from target to source positions 1.
</nextsent>
<nextsent>we compute the union and the intersection of the two alignment relations @ and kg] : l @ji kg] l @jl ] we call the intersection relation h, because it represents high-precision alignment, and the union alignment k, because it is taken to be lower precision higher recall alignment (och and ney, 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>the intersection his also (partial) bijection between the target and source positions: it covers the same number of target and source positions and there is bijection between source and target positions that are covered.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z885">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> block generation algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the hmm viterbi training is carried out twice with english as target language and chinese as source language and vice versa.
</prevsent>
<prevsent>we obtain two alignment relations: @ml no6p rtso:fi= rvu$pxwzy\[ k^] no6*8%_`qy:fi= 8au y,wzp [ rbu/pcwdy is an alignment function from source to target positions and 8autyewfp is an alignment function from target to source positions 1.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we compute the union and the intersection of the two alignment relations @ and kg] : l @ji kg] l @jl ] we call the intersection relation h, because it represents high-precision alignment, and the union alignment k, because it is taken to be lower precision higher recall alignment (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>the intersection his also (partial) bijection between the target and source positions: it covers the same number of target and source positions and there is bijection between source and target positions that are covered.
</nextsent>
<nextsent>for the ce experiments reported in section 4 about f % of the target and source positions are covered by word links in , forthe ae experiments about f % are covered.
</nextsent>
<nextsent>the extension algorithm presented assumes that hpoqk ,which is valid in this case since and are derived from intersection and union.
</nextsent>
<nextsent>we introduce the following additional piece of notation: rjst 6 :l npb= u`y and 6pvqy :xw [ (2) rjst 6 h: is the set of all source positions that are covered by some word links in , where the source positions are shown along the -axis and the target positions are shown along the -axis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z886">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> dp-based decoder.  </section>
<citcontext>
<prevsection>
<prevsent>the solid word links are word links in , the striped word links are word links in . using the links in , we can learn one-to-many block translations, e.g. the pair ( \ ,xinhua news agency?)
</prevsent>
<prevsent>is learned from the training data.
</prevsent>
</prevsection>
<citsent citstr=" J03-1005 ">
we use dp-based beam search procedure similar to the one presented in (tillmann and ney, 2003).<papid> J03-1005 </papid></citsent>
<aftsection>
<nextsent>we maximize over all block segment ations lmf \ for which the source phrases yield segmentation of the input source sentence, generating the target sentence simultaneously.
</nextsent>
<nextsent>the decoder processes search states of the following form: h ikj,; -mle-ano-qp.,.-rpms
</nextsent>
<nextsent>t and , are the two predecessor words used for the trigram language model, lis the so-called cover age vector to keep track of the already processed source position, nis the last processed source position.
</nextsent>
<nextsent>p is the source phrase length of the block table 3: effect of the extension scheme u=v:w on the ce translation experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z888">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the second column reports the total number of blocks in millions collected - including all the blocks that occurred only once.
</prevsent>
<prevsent>the third column reports the number of blocks that occurred at least twice.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
these blocks are used to compute the results in the fourth column: the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>with ? reference translation using ? -grams along with 95% confidence interval is reported 4.</citsent>
<aftsection>
<nextsent>line  and line ? of this table show results where only the source interval projection without any extension is carried out.
</nextsent>
<nextsent>for the ?#?
</nextsent>
<nextsent>w ? extension scheme, the high-recall union set itself is used for projection.
</nextsent>
<nextsent>the results are worse than for all other schemes, since lot of smaller blocks are discarded due to the projection approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z893">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>block unigram counts are used to filter the blocks.
</prevsent>
<prevsent>the phrasal model is included into syntax-based model.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
projection of phrases has also been used in(yarowsky et al, 2001).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>in this paper, we describe block-based unigram model for smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z894">
<title id=" W03-1001.xml">a projection extension algorithm for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the phrasal model is included into syntax-based model.
</prevsent>
<prevsent>projection of phrases has also been used in(yarowsky et al, 2001).<papid> H01-1035 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in this paper, we describe block-based unigram model for smt.
</nextsent>
<nextsent>a novel block learning algorithm is presented that extends high-precision interval projections by elements from high-recall alignment.the extension method is shown to improve translation performance significantly.
</nextsent>
<nextsent>for the chinese-to english task, we obtained nist score of 3?
</nextsent>
<nextsent>onthe june 2002 darpa tides large data evaluation test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z895">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thesauri have traditionally been used in information retrieval tasks to expand words in queries with synonymous terms (e.g. ruge, (1997)).
</prevsent>
<prevsent>since the development of wordnet (fellbaum, 1998) and large electronic thesauri, information from semantic resources is regularly leveraged to solve nlp problems.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
these tasks include collocation discovery (pearce, 2001), smoothing and model estimation (brown et al, 1992; <papid> J92-4003 </papid>clark and weir, 2001) <papid> N01-1013 </papid>and text classification (baker and mccallum, 1998).unfortunately, thesauri are expensive and time consuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.</citsent>
<aftsection>
<nextsent>in addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many sub domains that nlp techniques are being applied to.
</nextsent>
<nextsent>there is clear need for methods to extract thesauriautomatically or tools that assist in the manual creation and updating of these semantic resources.
</nextsent>
<nextsent>much of the existing work on thesaurus extraction and word clustering is based on the observation that related terms will appear in similar contexts.
</nextsent>
<nextsent>these systems differ primarily in their definition of con text?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z896">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thesauri have traditionally been used in information retrieval tasks to expand words in queries with synonymous terms (e.g. ruge, (1997)).
</prevsent>
<prevsent>since the development of wordnet (fellbaum, 1998) and large electronic thesauri, information from semantic resources is regularly leveraged to solve nlp problems.
</prevsent>
</prevsection>
<citsent citstr=" N01-1013 ">
these tasks include collocation discovery (pearce, 2001), smoothing and model estimation (brown et al, 1992; <papid> J92-4003 </papid>clark and weir, 2001) <papid> N01-1013 </papid>and text classification (baker and mccallum, 1998).unfortunately, thesauri are expensive and time consuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.</citsent>
<aftsection>
<nextsent>in addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many sub domains that nlp techniques are being applied to.
</nextsent>
<nextsent>there is clear need for methods to extract thesauriautomatically or tools that assist in the manual creation and updating of these semantic resources.
</nextsent>
<nextsent>much of the existing work on thesaurus extraction and word clustering is based on the observation that related terms will appear in similar contexts.
</nextsent>
<nextsent>these systems differ primarily in their definition of con text?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z897">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems differ primarily in their definition of con text?
</prevsent>
<prevsent>and the way they calculate similarity from the contexts each term appears in.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into vector-space representation of the contexts that each target term appears in (pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin, 1998<papid> P98-2127 </papid>b).</citsent>
<aftsection>
<nextsent>other systems take the whole document as the context and consider term co-occurrence at the document level (crouch, 1988; sanderson and croft, 1999).
</nextsent>
<nextsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.alternatively, some systems are based on the observation that related terms appear together in particular contexts.
</nextsent>
<nextsent>these systems extract related terms directly by recognising linguistic patterns (e.g. x, and other zs) which link synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></nextsent>
<nextsent>our previous work (curran and moens, 2002) <papid> P02-1030 </papid>has evaluated thesaurus extraction performance and efficiency using several different context models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z898">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems differ primarily in their definition of con text?
</prevsent>
<prevsent>and the way they calculate similarity from the contexts each term appears in.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into vector-space representation of the contexts that each target term appears in (pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin, 1998<papid> P98-2127 </papid>b).</citsent>
<aftsection>
<nextsent>other systems take the whole document as the context and consider term co-occurrence at the document level (crouch, 1988; sanderson and croft, 1999).
</nextsent>
<nextsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.alternatively, some systems are based on the observation that related terms appear together in particular contexts.
</nextsent>
<nextsent>these systems extract related terms directly by recognising linguistic patterns (e.g. x, and other zs) which link synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></nextsent>
<nextsent>our previous work (curran and moens, 2002) <papid> P02-1030 </papid>has evaluated thesaurus extraction performance and efficiency using several different context models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z905">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other systems take the whole document as the context and consider term co-occurrence at the document level (crouch, 1988; sanderson and croft, 1999).
</prevsent>
<prevsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.alternatively, some systems are based on the observation that related terms appear together in particular contexts.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
these systems extract related terms directly by recognising linguistic patterns (e.g. x, and other zs) which link synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>our previous work (curran and moens, 2002) <papid> P02-1030 </papid>has evaluated thesaurus extraction performance and efficiency using several different context models.</nextsent>
<nextsent>in this paper, we evaluate some existing similarity metric sand propose and motivate new metric which outperforms the existing metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z906">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other systems take the whole document as the context and consider term co-occurrence at the document level (crouch, 1988; sanderson and croft, 1999).
</prevsent>
<prevsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.alternatively, some systems are based on the observation that related terms appear together in particular contexts.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
these systems extract related terms directly by recognising linguistic patterns (e.g. x, and other zs) which link synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>our previous work (curran and moens, 2002) <papid> P02-1030 </papid>has evaluated thesaurus extraction performance and efficiency using several different context models.</nextsent>
<nextsent>in this paper, we evaluate some existing similarity metric sand propose and motivate new metric which outperforms the existing metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z907">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>once these contexts have been defined, these systems then use clustering or nearest neighbour methods to find similar terms.alternatively, some systems are based on the observation that related terms appear together in particular contexts.
</prevsent>
<prevsent>these systems extract related terms directly by recognising linguistic patterns (e.g. x, and other zs) which link synonyms and hyponyms (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1030 ">
our previous work (curran and moens, 2002) <papid> P02-1030 </papid>has evaluated thesaurus extraction performance and efficiency using several different context models.</citsent>
<aftsection>
<nextsent>in this paper, we evaluate some existing similarity metric sand propose and motivate new metric which outperforms the existing metrics.
</nextsent>
<nextsent>we also present an approximation algorithm that bounds the time complexity of pairwise thesaurus extraction.
</nextsent>
<nextsent>this results insignificant reduction in runtime with only marginal performance penalty in our experiments.
</nextsent>
<nextsent>july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z916">
<title id=" W02-0908.xml">improvements in automatic thesaurus extraction </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>term is the (direct/indirect) object of verb 3.
</prevsent>
<prevsent>term is modified by noun or adjective 4.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
term is modified by prepositional phrase the relation tuple is then converted to root form using the sussex morphological analyser (minnen et al, 2000) <papid> W00-1427 </papid>and the pos tags are removed.</citsent>
<aftsection>
<nextsent>the relations for each term are collected together and counted, producing context vector of attributes and (adjective, good) 2005 (adjective, faintest) 89 (direct-obj, have) 1836 (indirect-obj, toy) 74 (adjective, preconceived) 42 (adjective, foggiest) 15 figure 1: example attributes of the noun idea their frequencies in the corpus.
</nextsent>
<nextsent>figure 1 shows some example attributes for idea.the second system component performs nearest neighbour or cluster analysis to determine which terms are similar based on their context vectors.
</nextsent>
<nextsent>both methods require function that calculates the similarity between context vectors.
</nextsent>
<nextsent>for experimental analysis we have decomposed this function into measure and weight functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z954">
<title id=" W03-0703.xml">directions for multiparty human computer interaction research </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, evaluation framework shave improved beyond the single utterance accuracy measures used decade ago to dialog-level subjective and quantitative measures (walker et al, 1998).as dialog systems have advanced, new area of research has also been developing in automatic recognition and analysis of multi-party human-human spoken interactions, such as meetings, talk shows, court room proceedings, and industrial settings (cohen et al, 2002).
</prevsent>
<prevsent>multi-party interactions pose challenges for speech recognition and speaker tracking because of frequent talker overlap (shriberg et al, 2001), noise androom reverberation, but they also introduce new challenges for discourse modeling.
</prevsent>
</prevsection>
<citsent citstr=" H01-1051 ">
until recently, empirical research was only possible using single-speaker and dialog corpora, but now there are many hours of data being collected in multi-talker environments (morgan et al 2001; <papid> H01-1051 </papid>schultz et al 2001).</citsent>
<aftsection>
<nextsent>while many challenges remain in dialog systems from error handling and user modeling to response generation ? technology has advanced to the point where one can also envision tackling the combined problem ofmulti-party human-computer interaction.
</nextsent>
<nextsent>a key motivation for research in such domain is supporting human human collaboration.
</nextsent>
<nextsent>we envision scenario where computer plays role as conversational agent, much as in dialog system, except that it interacts with multiple collaborating humans.
</nextsent>
<nextsent>the human participants may be at distributed locations, perhaps with small subgroups at each location, possibly with different platforms for input and output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z955">
<title id=" W03-0703.xml">directions for multiparty human computer interaction research </title>
<section> research issues.  </section>
<citcontext>
<prevsection>
<prevsent>different user queries and dialog states might need to be tracked simultaneously, and formal models of this type of interaction need to be established.
</prevsent>
<prevsent>recently, probabilistic models of human-computer dialogs have become increasingly popular.
</prevsent>
</prevsection>
<citsent citstr=" P00-1013 ">
the most commonly used paradigm is that of markov decision processes and partially observable markov decision processes, where the entire dialog is modelled as sequence of states and associated actions, each of which has certain value (or reward) (singh et al., 1999; roy et al, 2000).<papid> P00-1013 </papid></citsent>
<aftsection>
<nextsent>the goal is to to choose that sequence of actions which maximizes the overall reward in response to the users query.
</nextsent>
<nextsent>states can be thought of as representing the underlying intentions of the user.these are typically not entirely transparent but only indirectly (or partially) observable through the speech input.
</nextsent>
<nextsent>multi-party dialogs might require extensions to this and other modeling frameworks.
</nextsent>
<nextsent>for instance, it is unclear whether multiple parallel subdialogs can be modelled by single state sequence (i.e. single decision process), or whether multiple, partially independent decision process are required.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z956">
<title id=" W02-1115.xml">selecting the most highly correlated pairs within a large vocabulary </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since this does not depend on the size of the vocabulary under analysis, it is possible to compute correlations between all the words in corpus.
</prevsent>
<prevsent>in order to find relationships between words in large corpus or between labels in large database, we may use distance measure between the binary vectors of  dimensions, where  is the number of documents or records, and the  th element is 1 if the  th document/record contains the word or the label, or 0 otherwise.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
there are several distance measures suitable for this purpose, such as the mutual information(church and hanks, 1990), <papid> J90-1003 </papid>the dice coeffi cient(manning and schueutze 8.5, 1999), the phi coefficient(manning and schuetze 5.3.3, 1999), the cosine measure(manning and schueutze 8.5, 1999) and the confidence(arrawal and srikant, 1995).there are also special functions for certain applications, such as then complimentary similarity measure (csm)(hagita and sawaki, 1995) which isknown as to be suitable for cases with noisy pat tern.</citsent>
<aftsection>
<nextsent>all of these five measures can be obtained from asimple contingency table.
</nextsent>
<nextsent>this table has four numbers for each word/label  and word/label  . the first number is the number of documents/records that have both  and  . we define this number as
</nextsent>
<nextsent>ff  . the second number is the number of doc-.
</nextsent>
<nextsent>uments/records that have  but not  . we define this number as  fi
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z957">
<title id=" W02-1115.xml">selecting the most highly correlated pairs within a large vocabulary </title>
<section> correlation of all sub strings.  </section>
<citcontext>
<prevsection>
<prevsent>memory space requirement and computation time does not depend on   , this method can be used to generate list of the most hightly correlated sub strings of any length.
</prevsent>
<prevsent>in fact, in some cases,  may be too large to compute.
</prevsent>
</prevsection>
<citsent citstr=" J01-1001 ">
the yamamoto-church method(yamamoto and church, 2001) <papid> J01-1001 </papid>allows for the creation of fl</citsent>
<aftsection>
<nextsent>  table using
</nextsent>
<nextsent> memory space and
</nextsent>
<nextsent> computation time, where  represents all sub strings in given corpus.
</nextsent>
<nextsent>yamamotos method shows that although there may be
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z958">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so far, attention has focused on parsing, because the semantically annotated corpora required for learning semantic interpretation have not been available.
</prevsent>
<prevsent>the completion of the first phase of the propbank (kingsbury et al , 2002) represents an important step.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the propbank super imposes an annotation of semantic predicate-argument structures on top of the penn treebank (ptb) (marcus et al , 1993; <papid> J93-2004 </papid>marcus et al , 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>the arc labels chosen for the arguments are specific to the predicate, not universal.in this paper, we find that the use of deep linguistic representations to predict these semantic labels are more effective than the generally more surface-syntax representations previously employed (gildea and palmer (2002)).<papid> P02-1031 </papid></nextsent>
<nextsent>specifically, we show that the syntactic dependency structure that results load arg0 john arg2 hay arg1 truck figure 1: propbank-style semantic representation for both john loaded the truck with hay and john loaded hay into the truck from the extraction of tree adjoining grammar(tag) from the ptb, and the features that accompany this structure, form better basis for determining semantic role labels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z959">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>so far, attention has focused on parsing, because the semantically annotated corpora required for learning semantic interpretation have not been available.
</prevsent>
<prevsent>the completion of the first phase of the propbank (kingsbury et al , 2002) represents an important step.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
the propbank super imposes an annotation of semantic predicate-argument structures on top of the penn treebank (ptb) (marcus et al , 1993; <papid> J93-2004 </papid>marcus et al , 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>the arc labels chosen for the arguments are specific to the predicate, not universal.in this paper, we find that the use of deep linguistic representations to predict these semantic labels are more effective than the generally more surface-syntax representations previously employed (gildea and palmer (2002)).<papid> P02-1031 </papid></nextsent>
<nextsent>specifically, we show that the syntactic dependency structure that results load arg0 john arg2 hay arg1 truck figure 1: propbank-style semantic representation for both john loaded the truck with hay and john loaded hay into the truck from the extraction of tree adjoining grammar(tag) from the ptb, and the features that accompany this structure, form better basis for determining semantic role labels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z960">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the completion of the first phase of the propbank (kingsbury et al , 2002) represents an important step.
</prevsent>
<prevsent>the propbank super imposes an annotation of semantic predicate-argument structures on top of the penn treebank (ptb) (marcus et al , 1993; <papid> J93-2004 </papid>marcus et al , 1994).<papid> H94-1020 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
the arc labels chosen for the arguments are specific to the predicate, not universal.in this paper, we find that the use of deep linguistic representations to predict these semantic labels are more effective than the generally more surface-syntax representations previously employed (gildea and palmer (2002)).<papid> P02-1031 </papid></citsent>
<aftsection>
<nextsent>specifically, we show that the syntactic dependency structure that results load arg0 john arg2 hay arg1 truck figure 1: propbank-style semantic representation for both john loaded the truck with hay and john loaded hay into the truck from the extraction of tree adjoining grammar(tag) from the ptb, and the features that accompany this structure, form better basis for determining semantic role labels.
</nextsent>
<nextsent>crucially, the same structure is also produced when parsing with tag.
</nextsent>
<nextsent>we suggest that the syntactic representation chosen inthe ptb is less well suited for semantic processing than the other, deeper syntactic representations.in fact, this deeper representation expresses syntactic notions that have achieved wide acceptance across linguistic frameworks, unlike the very particular surface-syntactic choices made by the linguists who created the ptb syntactic annotation rules.the outline of this paper is as follows.
</nextsent>
<nextsent>in section 2 we introduce the propbank and describe the problem of predicting semantic tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z967">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> extraction of tags from the propbank.  </section>
<citcontext>
<prevsection>
<prevsent>we subsequently experiment with their prediction given raw text fed through deterministic dependency parser.
</prevsent>
<prevsent>our experiments depend upon automatically extracting tags from the propbank.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
in doing so, we follow the work of others in extracting grammars of various kinds from the ptb, whether it be tag(xia, 1999; chen and vijay-shanker, 2000; chiang, 2000), <papid> P00-1058 </papid>combinatory categorial grammar (hockenmaier and steedman, 2002), or constraint dependency grammar (wang and harper, 2002).<papid> W02-1031 </papid></citsent>
<aftsection>
<nextsent>we will discuss tags and an important principle guiding their formation, the extraction procedure from theptb that is described in (chen, 2001) including extensions to extract tag from the propbank, and finally the extraction of deeper linguistic features vp vp are vbp vpnp falling vbg np nns prices figure 4: parse tree associated with the sentence prices are falling has been fragmented into three tree frames.
</nextsent>
<nextsent>from the resulting tag.a tag is defined to be set of lexicalized elementary trees (joshi and schabes, 1991).
</nextsent>
<nextsent>theymay be composed by several well-defined operations to form parse trees.
</nextsent>
<nextsent>a lexicalized elementary tree where the lexical item is removed is called tree frame or supertag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z968">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> extraction of tags from the propbank.  </section>
<citcontext>
<prevsection>
<prevsent>we subsequently experiment with their prediction given raw text fed through deterministic dependency parser.
</prevsent>
<prevsent>our experiments depend upon automatically extracting tags from the propbank.
</prevsent>
</prevsection>
<citsent citstr=" W02-1031 ">
in doing so, we follow the work of others in extracting grammars of various kinds from the ptb, whether it be tag(xia, 1999; chen and vijay-shanker, 2000; chiang, 2000), <papid> P00-1058 </papid>combinatory categorial grammar (hockenmaier and steedman, 2002), or constraint dependency grammar (wang and harper, 2002).<papid> W02-1031 </papid></citsent>
<aftsection>
<nextsent>we will discuss tags and an important principle guiding their formation, the extraction procedure from theptb that is described in (chen, 2001) including extensions to extract tag from the propbank, and finally the extraction of deeper linguistic features vp vp are vbp vpnp falling vbg np nns prices figure 4: parse tree associated with the sentence prices are falling has been fragmented into three tree frames.
</nextsent>
<nextsent>from the resulting tag.a tag is defined to be set of lexicalized elementary trees (joshi and schabes, 1991).
</nextsent>
<nextsent>theymay be composed by several well-defined operations to form parse trees.
</nextsent>
<nextsent>a lexicalized elementary tree where the lexical item is removed is called tree frame or supertag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z969">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> extraction of tags from the propbank.  </section>
<citcontext>
<prevsection>
<prevsent>these elementary trees canbe composed by tag operations to form the original parse tree.
</prevsent>
<prevsent>the extraction procedure determines the structure of each elementary tree by localizing dependencies through the use of heuristics.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
salient heuristics include the use of head percolation table (magerman, 1995), <papid> P95-1037 </papid>and another table that distinguishes between complements and adjunct nodes inthe tree.</citsent>
<aftsection>
<nextsent>for our current work, we use the head percolation table to determine heads of phrases.
</nextsent>
<nextsent>also, we treat propbank argument (arg0 . . .
</nextsent>
<nextsent>arg9) as complement and propbank adjunct (argms) asan adjunct when such annotation is available.1 otherwise, we basically follow the approach of (chen, 2001).2 besides introducing one kind of tag extraction1the version of the propbank we are using is not fully annotated with semantic role information, although the most common predicates are.
</nextsent>
<nextsent>2specifically, ca1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z974">
<title id=" W03-1006.xml">use of deep linguistic features for the recognition and labeling of semantic arguments </title>
<section> semantic roles from raw text.  </section>
<citcontext>
<prevsection>
<prevsent>for the latter, we use the best performing model from section 6in order to find semantic roles given syntactic features from the parse.
</prevsent>
<prevsent>7.1 supertagging.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
super tagging (bangalore and joshi (1999)) <papid> J99-2004 </papid>is the task of assigning single super tag to each word given raw text as input.</citsent>
<aftsection>
<nextsent>for example, given the sentence prices are falling, super tagger might return the super tagged sentence in figure 4.
</nextsent>
<nextsent>supertaggingreturns an almost-parse in the sense that it is performing much parsing disambiguation.
</nextsent>
<nextsent>the typical technique to perform super tagging is the trigram model, akin to models of the same name for part of-speech tagging.
</nextsent>
<nextsent>this is the technique that we use here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z981">
<title id=" W02-0804.xml">defining and representing preposition senses a preliminary analysis </title>
<section> defining preposition semantics for.  </section>
<citcontext>
<prevsection>
<prevsent>this task is extremely difficult, but necessary for any real nlp application with quite wide coverage.
</prevsent>
<prevsent>very informally, in our perspective, we assume that sense (more or less large and constrained) of lexeme has basic formand basic expressions or usages (surface forms reflecting the basic sense).
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
the basic sense originates derived usages, which are more or less constrained and limited, via metonymy, metaphor, slight sense-shiftings or co-composition (pustejovsky, 1991, <papid> J91-4003 </papid>1995).</citsent>
<aftsection>
<nextsent>one of the difficulties is, given set of usages, to partition the minto semantically coherent sets, each set corresponding to sense.
</nextsent>
<nextsent>sense delimitation is largely an open problem.
</nextsent>
<nextsent>it is july 2002, pp.
</nextsent>
<nextsent>25-31.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z982">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rates can be further improved with the addition of simple linguistic processing.
</prevsent>
<prevsent>automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (nlp), such as machine translation (mt), cross language information retrieval (clir), and bilingual text alignment.
</prevsent>
</prevsection>
<citsent citstr=" W93-0301 ">
as noted in tsuji (2002), many previous methods (dagan et al, 1993; <papid> W93-0301 </papid>kupiec, 1993; <papid> P93-1003 </papid>wu and xia, 1994; melamed, 1996; smadja et al, 1996) <papid> J96-1001 </papid>deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to low frequency words, such as transliterated words.</citsent>
<aftsection>
<nextsent>these transliterated words are often domain-specific and created frequently.
</nextsent>
<nextsent>many of them are not found in existing bilingual dictionaries.
</nextsent>
<nextsent>thus, it is difficult to handle transliteration only via simple dictionary lookup.
</nextsent>
<nextsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z983">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rates can be further improved with the addition of simple linguistic processing.
</prevsent>
<prevsent>automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (nlp), such as machine translation (mt), cross language information retrieval (clir), and bilingual text alignment.
</prevsent>
</prevsection>
<citsent citstr=" P93-1003 ">
as noted in tsuji (2002), many previous methods (dagan et al, 1993; <papid> W93-0301 </papid>kupiec, 1993; <papid> P93-1003 </papid>wu and xia, 1994; melamed, 1996; smadja et al, 1996) <papid> J96-1001 </papid>deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to low frequency words, such as transliterated words.</citsent>
<aftsection>
<nextsent>these transliterated words are often domain-specific and created frequently.
</nextsent>
<nextsent>many of them are not found in existing bilingual dictionaries.
</nextsent>
<nextsent>thus, it is difficult to handle transliteration only via simple dictionary lookup.
</nextsent>
<nextsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z984">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rates can be further improved with the addition of simple linguistic processing.
</prevsent>
<prevsent>automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (nlp), such as machine translation (mt), cross language information retrieval (clir), and bilingual text alignment.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
as noted in tsuji (2002), many previous methods (dagan et al, 1993; <papid> W93-0301 </papid>kupiec, 1993; <papid> P93-1003 </papid>wu and xia, 1994; melamed, 1996; smadja et al, 1996) <papid> J96-1001 </papid>deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to low frequency words, such as transliterated words.</citsent>
<aftsection>
<nextsent>these transliterated words are often domain-specific and created frequently.
</nextsent>
<nextsent>many of them are not found in existing bilingual dictionaries.
</nextsent>
<nextsent>thus, it is difficult to handle transliteration only via simple dictionary lookup.
</nextsent>
<nextsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z985">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</prevsent>
<prevsent>in this paper, we present framework of acquisition for english and chinese transliterated word pairs based on the proposed statistical machine transliteration model.
</prevsent>
</prevsection>
<citsent citstr=" P98-1036 ">
recently, much research has been done on machine transliteration for many language pairs, such as english/arabic (al-onaizan and knight, 2002), eng lish/chinese (chen et al, 1998; <papid> P98-1036 </papid>lin and chen, 2002; <papid> W02-2017 </papid>wan and verspoor, 1998), <papid> P98-2220 </papid>english/japanese (knight and graehl, 1998), <papid> J98-4003 </papid>and english/korean (lee and choi, 1997; oh and choi, 2002).<papid> C02-1099 </papid></citsent>
<aftsection>
<nextsent>most previous approaches to machine transliteration have focused on the use of pronunciation dictionary for converting source words into phonetic symbols, manually assigned scoring matrix for measuring phonetic similarities between source and target words, or method based on heuristic rules for source-to-target word transliteration.
</nextsent>
<nextsent>however, words with unknown pronunciations may cause problems for transliteration.
</nextsent>
<nextsent>in addition, using either lan guage-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.
</nextsent>
<nextsent>the proposed method in this paper requires no conversion of source words into phonetic symbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z987">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</prevsent>
<prevsent>in this paper, we present framework of acquisition for english and chinese transliterated word pairs based on the proposed statistical machine transliteration model.
</prevsent>
</prevsection>
<citsent citstr=" W02-2017 ">
recently, much research has been done on machine transliteration for many language pairs, such as english/arabic (al-onaizan and knight, 2002), eng lish/chinese (chen et al, 1998; <papid> P98-1036 </papid>lin and chen, 2002; <papid> W02-2017 </papid>wan and verspoor, 1998), <papid> P98-2220 </papid>english/japanese (knight and graehl, 1998), <papid> J98-4003 </papid>and english/korean (lee and choi, 1997; oh and choi, 2002).<papid> C02-1099 </papid></citsent>
<aftsection>
<nextsent>most previous approaches to machine transliteration have focused on the use of pronunciation dictionary for converting source words into phonetic symbols, manually assigned scoring matrix for measuring phonetic similarities between source and target words, or method based on heuristic rules for source-to-target word transliteration.
</nextsent>
<nextsent>however, words with unknown pronunciations may cause problems for transliteration.
</nextsent>
<nextsent>in addition, using either lan guage-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.
</nextsent>
<nextsent>the proposed method in this paper requires no conversion of source words into phonetic symbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z988">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</prevsent>
<prevsent>in this paper, we present framework of acquisition for english and chinese transliterated word pairs based on the proposed statistical machine transliteration model.
</prevsent>
</prevsection>
<citsent citstr=" P98-2220 ">
recently, much research has been done on machine transliteration for many language pairs, such as english/arabic (al-onaizan and knight, 2002), eng lish/chinese (chen et al, 1998; <papid> P98-1036 </papid>lin and chen, 2002; <papid> W02-2017 </papid>wan and verspoor, 1998), <papid> P98-2220 </papid>english/japanese (knight and graehl, 1998), <papid> J98-4003 </papid>and english/korean (lee and choi, 1997; oh and choi, 2002).<papid> C02-1099 </papid></citsent>
<aftsection>
<nextsent>most previous approaches to machine transliteration have focused on the use of pronunciation dictionary for converting source words into phonetic symbols, manually assigned scoring matrix for measuring phonetic similarities between source and target words, or method based on heuristic rules for source-to-target word transliteration.
</nextsent>
<nextsent>however, words with unknown pronunciations may cause problems for transliteration.
</nextsent>
<nextsent>in addition, using either lan guage-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.
</nextsent>
<nextsent>the proposed method in this paper requires no conversion of source words into phonetic symbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z989">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</prevsent>
<prevsent>in this paper, we present framework of acquisition for english and chinese transliterated word pairs based on the proposed statistical machine transliteration model.
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
recently, much research has been done on machine transliteration for many language pairs, such as english/arabic (al-onaizan and knight, 2002), eng lish/chinese (chen et al, 1998; <papid> P98-1036 </papid>lin and chen, 2002; <papid> W02-2017 </papid>wan and verspoor, 1998), <papid> P98-2220 </papid>english/japanese (knight and graehl, 1998), <papid> J98-4003 </papid>and english/korean (lee and choi, 1997; oh and choi, 2002).<papid> C02-1099 </papid></citsent>
<aftsection>
<nextsent>most previous approaches to machine transliteration have focused on the use of pronunciation dictionary for converting source words into phonetic symbols, manually assigned scoring matrix for measuring phonetic similarities between source and target words, or method based on heuristic rules for source-to-target word transliteration.
</nextsent>
<nextsent>however, words with unknown pronunciations may cause problems for transliteration.
</nextsent>
<nextsent>in addition, using either lan guage-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.
</nextsent>
<nextsent>the proposed method in this paper requires no conversion of source words into phonetic symbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z990">
<title id=" W03-0317.xml">acquisition of english chinese transliterated word pairs from parallel aligned texts using a statistical machine transliteration model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for clir, the accuracy of transliteration highly affects the performance of retrieval.
</prevsent>
<prevsent>in this paper, we present framework of acquisition for english and chinese transliterated word pairs based on the proposed statistical machine transliteration model.
</prevsent>
</prevsection>
<citsent citstr=" C02-1099 ">
recently, much research has been done on machine transliteration for many language pairs, such as english/arabic (al-onaizan and knight, 2002), eng lish/chinese (chen et al, 1998; <papid> P98-1036 </papid>lin and chen, 2002; <papid> W02-2017 </papid>wan and verspoor, 1998), <papid> P98-2220 </papid>english/japanese (knight and graehl, 1998), <papid> J98-4003 </papid>and english/korean (lee and choi, 1997; oh and choi, 2002).<papid> C02-1099 </papid></citsent>
<aftsection>
<nextsent>most previous approaches to machine transliteration have focused on the use of pronunciation dictionary for converting source words into phonetic symbols, manually assigned scoring matrix for measuring phonetic similarities between source and target words, or method based on heuristic rules for source-to-target word transliteration.
</nextsent>
<nextsent>however, words with unknown pronunciations may cause problems for transliteration.
</nextsent>
<nextsent>in addition, using either lan guage-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.
</nextsent>
<nextsent>the proposed method in this paper requires no conversion of source words into phonetic symbols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z994">
<title id=" W03-1016.xml">statistical acquisition of content selection rules for natural language generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>content selection is the task of choosing the right information to communicate in the output of natural language generation (nlg) system, given semantic input and communicative goal.
</prevsent>
<prevsent>in general, content selection is highly domain dependenttask; new rules must be developed for each new do main, and typically this is done manually.
</prevsent>
</prevsection>
<citsent citstr=" W01-0802 ">
morevoer, it has been argued (sripada et al, 2001) <papid> W01-0802 </papid>that content selection is the most important task from users standpoint (i.e., users may tolerate errors in wording, as long as the information being sought is present in the text).</citsent>
<aftsection>
<nextsent>designing content selection rules manually is tedious task.
</nextsent>
<nextsent>a realistic knowledge base contains large amount of information that could potentially be included in text and designer must examinea sizable number of texts, produced in different situations, to determine the specific constraints for the selection of each piece of information.our goal is to develop system that can automatically acquire constraints for the content selection task.
</nextsent>
<nextsent>our algorithm uses the information we learned from corpus of desired outputs for the system (i.e., human-produced text) aligned against related semantic data (i.e., the type of data the system will use as input).
</nextsent>
<nextsent>it produces constraints on every piece of the input where constraints dictate if it should appear in the output at all and if so, under what conditions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z995">
<title id=" W03-1016.xml">statistical acquisition of content selection rules for natural language generation </title>
<section> domain: biographical descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>our final remarks,together with proposed future work conclude the paper.
</prevsent>
<prevsent>the research described here is done for the automatic construction of the content selection module of pro genie (duboue and mckeown, 2003a),a biography generator under construction.
</prevsent>
</prevsection>
<citsent citstr=" P01-1059 ">
biography generation is an exciting field that has attracted practitioners of nlg in the past (kim et al, 2002; schiffman et al, 2001; <papid> P01-1059 </papid>radev and mckeown, 1997; <papid> A97-1033 </papid>teich and bateman, 1994).<papid> W94-0318 </papid></citsent>
<aftsection>
<nextsent>it has the advantages of being constrained domain amenable to current generation approaches, while at the same time offering more possibilities than many constrained domains, given the variety of styles that biographies exhibit, as well as the possibility for ultimately generating relatively long biographies.we have gathered resource of text and associated knowledge in the biography domain.
</nextsent>
<nextsent>more specifically, our resource is collection of human produced texts together with the knowledge basea generation system might use as input for generation.
</nextsent>
<nextsent>the knowledge base contains many pieces of information related to the person the biography talks about (and that the system will use to generate that type of biography), not all of which necessarily will appear in the biography.
</nextsent>
<nextsent>that is, the associated knowledge base is not the semantics of the target text but the larger set1 of all things that could possibly be said about the person in question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z996">
<title id=" W03-1016.xml">statistical acquisition of content selection rules for natural language generation </title>
<section> domain: biographical descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>our final remarks,together with proposed future work conclude the paper.
</prevsent>
<prevsent>the research described here is done for the automatic construction of the content selection module of pro genie (duboue and mckeown, 2003a),a biography generator under construction.
</prevsent>
</prevsection>
<citsent citstr=" A97-1033 ">
biography generation is an exciting field that has attracted practitioners of nlg in the past (kim et al, 2002; schiffman et al, 2001; <papid> P01-1059 </papid>radev and mckeown, 1997; <papid> A97-1033 </papid>teich and bateman, 1994).<papid> W94-0318 </papid></citsent>
<aftsection>
<nextsent>it has the advantages of being constrained domain amenable to current generation approaches, while at the same time offering more possibilities than many constrained domains, given the variety of styles that biographies exhibit, as well as the possibility for ultimately generating relatively long biographies.we have gathered resource of text and associated knowledge in the biography domain.
</nextsent>
<nextsent>more specifically, our resource is collection of human produced texts together with the knowledge basea generation system might use as input for generation.
</nextsent>
<nextsent>the knowledge base contains many pieces of information related to the person the biography talks about (and that the system will use to generate that type of biography), not all of which necessarily will appear in the biography.
</nextsent>
<nextsent>that is, the associated knowledge base is not the semantics of the target text but the larger set1 of all things that could possibly be said about the person in question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z997">
<title id=" W03-1016.xml">statistical acquisition of content selection rules for natural language generation </title>
<section> domain: biographical descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>our final remarks,together with proposed future work conclude the paper.
</prevsent>
<prevsent>the research described here is done for the automatic construction of the content selection module of pro genie (duboue and mckeown, 2003a),a biography generator under construction.
</prevsent>
</prevsection>
<citsent citstr=" W94-0318 ">
biography generation is an exciting field that has attracted practitioners of nlg in the past (kim et al, 2002; schiffman et al, 2001; <papid> P01-1059 </papid>radev and mckeown, 1997; <papid> A97-1033 </papid>teich and bateman, 1994).<papid> W94-0318 </papid></citsent>
<aftsection>
<nextsent>it has the advantages of being constrained domain amenable to current generation approaches, while at the same time offering more possibilities than many constrained domains, given the variety of styles that biographies exhibit, as well as the possibility for ultimately generating relatively long biographies.we have gathered resource of text and associated knowledge in the biography domain.
</nextsent>
<nextsent>more specifically, our resource is collection of human produced texts together with the knowledge basea generation system might use as input for generation.
</nextsent>
<nextsent>the knowledge base contains many pieces of information related to the person the biography talks about (and that the system will use to generate that type of biography), not all of which necessarily will appear in the biography.
</nextsent>
<nextsent>that is, the associated knowledge base is not the semantics of the target text but the larger set1 of all things that could possibly be said about the person in question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z998">
<title id=" W03-1016.xml">statistical acquisition of content selection rules for natural language generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>given the experimental nature of these results, we would not yet draw any conclusions about the ultimate benefit of the ripper approach.
</prevsent>
<prevsent>very few researchers have addressed the problem of knowledge acquisition for content selection in generation.
</prevsent>
</prevsection>
<citsent citstr=" W00-1429 ">
a notable exception is reiter et al (2000)<papid> W00-1429 </papid>swork, which discusses rainbow of knowledge engineering techniques (including direct acquisition from experts, discussion groups, etc.).</citsent>
<aftsection>
<nextsent>they also experiment development imdb.com selected prec.
</nextsent>
<nextsent>rec.
</nextsent>
<nextsent>f* selected prec.
</nextsent>
<nextsent>rec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z999">
<title id=" W03-1016.xml">statistical acquisition of content selection rules for natural language generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, in this paper, we show how the pairing of semantic input with target text in large quantities allows us to elicit statistical rules with such criteria.
</prevsent>
<prevsent>aside from that particular work, there seems toexist some momentum in the literature for two level content selection process (e.g., sripada et al.
</prevsent>
</prevsection>
<citsent citstr=" J97-1004 ">
(2001), bontcheva and wilks (2001), and lester and porter (1997)).<papid> J97-1004 </papid></citsent>
<aftsection>
<nextsent>for instance, distinguish two levels of content determination, local?
</nextsent>
<nextsent>content determination is the selection of relatively small knowledge structures, each of which will be used to generate one or two sentences?
</nextsent>
<nextsent>while global?
</nextsent>
<nextsent>content determination is the process of deciding which of these structures to include in an explanation?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1000">
<title id=" W03-0907.xml">story understanding through multi representation model construction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are concerned with in-depth understanding in contrast to information extraction.
</prevsent>
<prevsent>since research on common sense reasoning to date has focused on small benchmark problems, it would be difficult to launch into the problem of in-depth understanding of adult-level stories right away.
</prevsent>
</prevsection>
<citsent citstr=" P99-1042 ">
instead, we and others have proposed to start by handling childrens stories (hirschman et al, 1999; <papid> P99-1042 </papid>mccarthy et al, 2002).</citsent>
<aftsection>
<nextsent>we have formed corpus of 15 early reader stories for pre-school and kindergarten students,drawn from the random house step into reading?
</nextsent>
<nextsent>series.
</nextsent>
<nextsent>in this paper, we treat one of the stories in this corpus.
</nextsent>
<nextsent>the representations we develop for this story will,we hope, be applicable to the understanding of there maining 14 stories as well as other early reader stories though the representations will certainly require elabora tion.since our primary research focus is on in-depth understanding, we make the simplifying assumption that the narrative text has already been parsed into event calculus formulas (shanahan, 1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1001">
<title id=" W03-0907.xml">story understanding through multi representation model construction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we treat one of the stories in this corpus.
</prevsent>
<prevsent>the representations we develop for this story will,we hope, be applicable to the understanding of there maining 14 stories as well as other early reader stories though the representations will certainly require elabora tion.since our primary research focus is on in-depth understanding, we make the simplifying assumption that the narrative text has already been parsed into event calculus formulas (shanahan, 1997).
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
we manually annotate the narrative text with event calculus formulas, which are similar to the predicate-argument structures produced by semantic parsers (alshawi, 1992; beale et al, 1995;gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>in complete story understanding program, semantic parser would feed its surface-level understanding of story to our program,which would in turn produce more detailed understanding.
</nextsent>
<nextsent>1.3 brief history of story understanding.
</nextsent>
<nextsent>starting in the 1960s, number of programs have been written that are able to read and understand handful of stories.2 several programs built in the 1970s were based on the knowledge structures of scripts, plans, and goals (schank and abelson, 1977).
</nextsent>
<nextsent>the boris in-depth story understanding program (dyer, 1983) integrated scripts,plans, and goals with other knowledge structures including emotions, interpersonal relations, spatiotemporal maps, and story themes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1002">
<title id=" W03-1606.xml">normalization and paraphrasing using symbolic methods </title>
<section> paraphrase detection.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, takahashi et. al.
</prevsent>
<prevsent>(takahashi et al, 2000) developed lexico-structural paraphrasing system.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
kaji et al developed system which is able to produce verbal paraphrase using dictionary definitions (kaji et al,2000) and barzilay and mckeown showed how, using parallel corpora of english literary translations, they extract paraphrases (barzilay and mckeown, 2001).<papid> P01-1008 </papid></citsent>
<aftsection>
<nextsent>paraphrase detection is useful step in many nlp applications.
</nextsent>
<nextsent>for instance, in multi-documentsummarization, paraphrase detection helps to identify similar text segments in order that the summary become more concise (mckeown et al, 1999).
</nextsent>
<nextsent>paraphrase detection can also be used to augment recall in different ie systems.
</nextsent>
<nextsent>in our experiment, paraphrase detection is step in normalization, as we want to instantiate the same way the predicates presented above when the informative content is similar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1003">
<title id=" W03-1606.xml">normalization and paraphrasing using symbolic methods </title>
<section> paraphrase detection.  </section>
<citcontext>
<prevsection>
<prevsent>the morpho-syntactic normalizer is general module that is neither corpus- nor application-dedicated.it consists of hand-made rules that apply to the syntactic representation produced by our parser.
</prevsent>
<prevsent>it use swell known syntactic equivalences such as passive active transformation and verb alternations proposed in levin.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
it also exploits the classification given bythe comlex lexicon (grishman et al, 1994) <papid> C94-1042 </papid>in order to calculate the deep-subject of infinitive verbs.</citsent>
<aftsection>
<nextsent>for instance the utterance antimony ores are mixed with other metals is finally represented with set of normalized syntactic relations expressing that the normalized subject (subj-n) of the verb mix is unknown, and that mix has two second actants (obj-n) ore and metal : subj-n(mix,someone) obj-n(mix,ore) obj-n(mix,metal) for this example, both passive transformation and reciprocal alternation transformation have been applied on the set of dependencies produced by the general parser.
</nextsent>
<nextsent>deep syntactic rules are expressed using the same formalism than general syntactic rules presented in the previous section.
</nextsent>
<nextsent>for instance the following rule construct an obj-n (normalized object) dependency between the surface syntactic subject and verb in passive form3.
</nextsent>
<nextsent>if ( subj(#1,#2) &amp; vdomain[passive](#1,#3) ) obj-n(#3,#2) unlike roses approach (rose?, 2000) which also developed deep syntactic analyzer, this is done exclusively by hand-made rules based on the previous calculated dependencies on the one hand and syntactic and morphological properties of the nodes involved in the dependencies on the other hand.together with the exploration of syntactic properties, we also take advantage of morphological properties in order enrich our deep syntactic analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1004">
<title id=" W03-0308.xml">treqal a word alignment system with limited language resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and barbu, 2002; tufi?, 2002) we largely described our extractor of translation equivalents, called treq.
</prevsent>
<prevsent>it was aimed at building translation dictionaries from parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" W02-0808 ">
we described in (ide et al  2002) <papid> W02-0808 </papid>how this program is used in word clustering and in checking out the validity of the cross-lingual links between the monolingual wordnets of the multilingual balkan et lexical ontology (stamatou et al  2002).</citsent>
<aftsection>
<nextsent>in this paper we describe the treq-al system, which builds on treq and aims at generating word-alignment map for parallel text (a bitext).
</nextsent>
<nextsent>treq-al was built in less than two weeks for the shared task proposed by the organizers of the workshop on building and using parallel texts:data driven machine translation and beyond?
</nextsent>
<nextsent>at the hlt-naacl 20031 conference.
</nextsent>
<nextsent>it can be improved in several ways that became conspicuous when we analyzed the evaluation results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1005">
<title id=" W03-1020.xml">a fast algorithm for feature selection in conditional maximum entropy modeling </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper describes fast algorithm that selects features for conditional maximum entropy modeling.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
berger et al  (1996) <papid> J96-1002 </papid>present san incremental feature selection (ifs) algorithm, which computes the approximate gains for all candidate features at each selection stage, and is very time-consuming for any problems with large feature spaces.</citsent>
<aftsection>
<nextsent>in this new algorithm, instead, we only compute the approximate gains for the top-ranked features based on the models obtained from previous stages.
</nextsent>
<nextsent>experiments on wsj data in penn treebank are conducted to show that the new algorithm greatly speeds up the feature selection process while maintaining the same quality of selected features.
</nextsent>
<nextsent>one variant of this new algorithm with look-ahead functionality is also tested to further confirm the good quality of the selected features.
</nextsent>
<nextsent>the new algorithm is easy to implement, and given feature space of size f, it only uses o(f) more space than the original ifs algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1009">
<title id=" W03-1020.xml">a fast algorithm for feature selection in conditional maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one variant of this new algorithm with look-ahead functionality is also tested to further confirm the good quality of the selected features.
</prevsent>
<prevsent>the new algorithm is easy to implement, and given feature space of size f, it only uses o(f) more space than the original ifs algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W00-0729 ">
maximum entropy (me) modeling has received lot of attention in language modeling and natural language processing for the past few years (e.g., rosenfeld, 1994; berger et al 1996<papid> J96-1002 </papid>; <papid> J96-1002 </papid>ratnaparkhi, 1998; koeling, 2000).<papid> W00-0729 </papid></citsent>
<aftsection>
<nextsent>one of the main advantages using me modeling is the ability to incorporate various features in the same framework with sound mathematical foundation.
</nextsent>
<nextsent>there are two main tasks in me modeling: the feature selection process that chooses from feature space subset of good features to be included in the model; and the parameter estimation process that estimates the weighting factors for each selected feature in the exponential model.
</nextsent>
<nextsent>this paper is primarily concerned with the feature selection process in me modeling.
</nextsent>
<nextsent>while the majority of the work in me modeling has been focusing on parameter estimation, less effort has been made in feature selection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1011">
<title id=" W03-1020.xml">a fast algorithm for feature selection in conditional maximum entropy modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, when feature space is large and complex, it is clearly advantageous to perform feature selection, which not only speeds up the probability computation and requires smaller memory size during its application, but also shortens the cycle of model selection during the training.
</prevsent>
<prevsent>feature selection is very difficult optimization task when the feature space under investigation is large.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
this is because we essentially try to find best subset from collection of all the possible feature subsets, which has size of 2 | | , where |w| is the size of the feature space.in the past, most researchers resorted to simple count cutoff technique for selecting features (rosenfeld, 1994; ratnaparkhi, 1998; reynar and ratnaparkhi, 1997; <papid> A97-1004 </papid>koeling, 2000), <papid> W00-0729 </papid>where only the features that occur in corpus more than predefined cutoff threshold get selected.</citsent>
<aftsection>
<nextsent>chen and rosenfeld (1999) experimented on feature selection technique that uses c 2 test to see whether feature should be included in the me model, where the 2 test is computed using the count from prior distribution and the count from the real trainingdata.
</nextsent>
<nextsent>it is simple and probably effective technique for language modeling tasks.
</nextsent>
<nextsent>since me models are optimized using their likelihood or likelihood gains as the criterion, it is important to establish the relationship between 2 test score and the likelihood gain, which, however, is absent.berger et al  (1996) <papid> J96-1002 </papid>presented an incremental feature selection (ifs) algorithm where only one feature is added at each selection and the estimated parameter values are kept for the features selected in the previous stages.</nextsent>
<nextsent>while this greedy search assumption is reasonable, the speed of the ifs algorithm is still an issue for complex tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1016">
<title id=" W03-1020.xml">a fast algorithm for feature selection in conditional maximum entropy modeling </title>
<section> the incremental feature selection al-.  </section>
<citcontext>
<prevsection>
<prevsent>for instance such that there is and * (x , y) = 1 do z[i] -=sum[i, y] sum[i, y] ?= exp(a*) z[i] += sum[i, y] 5.
</prevsent>
<prevsent>go to step 1.
</prevsent>
</prevsection>
<citsent citstr=" P02-1002 ">
figure 1: variant of the ifs algorithm.one difference here from the original ifs algorithm is that we adopt technique in (goodman,2002) <papid> P02-1002 </papid>for optimizing the parameters in the conditional me training.</citsent>
<aftsection>
<nextsent>specifically, we use array to store the normalizing factors, and array sum for all the un-normalized conditional probabilities sum[i, y].
</nextsent>
<nextsent>thus, one only needs to modify those sum[i, y] that satisfy * (x , y)=1, and to make changes to their corresponding normalizing factors z[i].
</nextsent>
<nextsent>in contrast to what is shown in berger et al 1996<papid> J96-1002 </papid>s paper, here is how the different values in this variant of the ifs algorithm are computed.</nextsent>
<nextsent>let us denote ? = jj yxfxysum )),(exp()|( ? = xysumxz )|()( then, the model can be represented by sum(y|x) and z(x) as follows: )(/)|()|( xzxysumxyp = where sum(y|x ) and z(x ) correspond to sum[i,y] and z[i] in figure 1, respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1025">
<title id=" W02-1401.xml">disambiguating noun compounds with latent semantic indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, such decomposition is non-trivial for the case of compounds consisting of three or more nouns due to the structural ambiguity of these constructions.
</prevsent>
<prevsent>the identification of modifier-head pairs in compounds also has applications within the fieldof information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" P96-1003 ">
several studies have shown that extracting modifier-headpairs from text and including these ascom pound indexing terms can improve recall and precision (evans and zhai, 1996; <papid> P96-1003 </papid>pohl mann and kraaij, 1997; strzalkowski and vauthey, 1992).<papid> P92-1014 </papid>identification of these noun modifier relationships is also important for terminology transla tion.</citsent>
<aftsection>
<nextsent>however, obtaining correct modifier-headpairs is once again hampered by the notorious ambiguity of nominal compounds?
</nextsent>
<nextsent>(strza lkowski and vauthey, 1992, <papid> P92-1014 </papid>p.107).to summarise, the syntactic disambiguation of noun compounds is important for several nlp applications; however, disambiguation is difficult because attachments within compounds are not syntactically governed.</nextsent>
<nextsent>clearly, then, this lack of syntactic constraints forces us to consider the use of extra-syntactic factors inthe process of disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1027">
<title id=" W02-1401.xml">disambiguating noun compounds with latent semantic indexing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, such decomposition is non-trivial for the case of compounds consisting of three or more nouns due to the structural ambiguity of these constructions.
</prevsent>
<prevsent>the identification of modifier-head pairs in compounds also has applications within the fieldof information retrieval (ir).
</prevsent>
</prevsection>
<citsent citstr=" P92-1014 ">
several studies have shown that extracting modifier-headpairs from text and including these ascom pound indexing terms can improve recall and precision (evans and zhai, 1996; <papid> P96-1003 </papid>pohl mann and kraaij, 1997; strzalkowski and vauthey, 1992).<papid> P92-1014 </papid>identification of these noun modifier relationships is also important for terminology transla tion.</citsent>
<aftsection>
<nextsent>however, obtaining correct modifier-headpairs is once again hampered by the notorious ambiguity of nominal compounds?
</nextsent>
<nextsent>(strza lkowski and vauthey, 1992, <papid> P92-1014 </papid>p.107).to summarise, the syntactic disambiguation of noun compounds is important for several nlp applications; however, disambiguation is difficult because attachments within compounds are not syntactically governed.</nextsent>
<nextsent>clearly, then, this lack of syntactic constraints forces us to consider the use of extra-syntactic factors inthe process of disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1031">
<title id=" W02-1401.xml">disambiguating noun compounds with latent semantic indexing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>specifically, given sequence of three nouns n1 n2 n3 , if (n2 n3 ) is more acceptable constituent than (n1 n2 ), then build (n1 (n2 n3 )); else build ((n1 n2 ) n3 ).there remains the question of how accept ability?
</prevsent>
<prevsent>is to be determined computationally.
</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
several researchers (e.g., (barker, 1998; evans and zhai, 1996; <papid> P96-1003 </papid>pohl mann and kraaij, 1997;pustejovsky et al, 1993; <papid> J93-2005 </papid>strzalkowski and vauthey, 1992)) <papid> P92-1014 </papid>collect statistics on the occurrence frequency of structurally unambiguous two-noun compounds to inform the analysis of the ambiguous compound.</citsent>
<aftsection>
<nextsent>for example, given the compound computer data bases?, the structure (computer (data bases)) would be preferred if (data bases) occurred more frequently than (computer data) in the corpus.
</nextsent>
<nextsent>however,by assuming that sufficient examples of subcomponents exist in the training corpus, all the above approaches risk falling foul of the sparse data problem.
</nextsent>
<nextsent>most noun-noun compounds are rare, and statistics based on such infrequent events may lead to an unreliable estimation of the acceptability of particular modifier-head pairs.
</nextsent>
<nextsent>the work of resnik (1993) goes some way towards alleviating this problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1033">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe how we have determined the meaning of time phrases in weather forecasts by analysing parallel corpus of (a) manually-written weather forecast texts and (b) the numerical data (from weather simulation) that the human forecasters examined when writing the textual forecasts.
</prevsent>
<prevsent>the analysis procedure first aligns (associates) text fragments with data segments, and then infers the meaning of each time phrase by statistically analysing the time of data segments that are aligned to textual phrases that contain this time phrase.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
this is broadly similar in concept to the use of parallel multilingual corpora in machine translation (brown et al, 1990), <papid> J90-2002 </papid>except that our parallel corpus consists of texts and underlying numeric data, not texts and their translations.</citsent>
<aftsection>
<nextsent>in other words, we are trying to learn what words mean in terms of non-linguistic data, not the best translations of words in another language.
</nextsent>
<nextsent>probably the biggest surprise in our analysis was the substantial variation we saw between individuals.
</nextsent>
<nextsent>for example, by evening apparently meant 1800 to some people, but 0000 to others.
</nextsent>
<nextsent>although the possibility of such variation in individual idiolects has been acknowledged in the past (for example, (nunberg, 1978; parikh, 1994)),it seems to be ignored by most recent work on lexical semantics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1034">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, by evening apparently meant 1800 to some people, but 0000 to others.
</prevsent>
<prevsent>although the possibility of such variation in individual idiolects has been acknowledged in the past (for example, (nunberg, 1978; parikh, 1994)),it seems to be ignored by most recent work on lexical semantics.
</prevsent>
</prevsection>
<citsent citstr=" J02-4007 ">
we have published other papers that have summarise dour key findings, notably variation between individuals (reiter and sripada, 2002<papid> J02-4007 </papid>a; reiter and sripada, 2002<papid> J02-4007 </papid>b); and also described the corpus itself (sripada et al., 2003<papid> E03-1021 </papid>b).</citsent>
<aftsection>
<nextsent>the purpose of this paper is to describe our analysis procedure (including alignment) and results in detail, and to also discuss our current work on using parallel text-data corpora to learn the meanings of other types of words.
</nextsent>
<nextsent>linguists and lexicographers have used number of different techniques to determine the meanings of words.
</nextsent>
<nextsent>these include asking native-speaker informants to judge the acceptability and oddness of test sentences (cruse, 1986); defining word senses via lexicographic analysis of citations and corpora (landau, 1984); and asking subjects to respond to fill in the blank?
</nextsent>
<nextsent>questions (cassidy and hall, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1042">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, by evening apparently meant 1800 to some people, but 0000 to others.
</prevsent>
<prevsent>although the possibility of such variation in individual idiolects has been acknowledged in the past (for example, (nunberg, 1978; parikh, 1994)),it seems to be ignored by most recent work on lexical semantics.
</prevsent>
</prevsection>
<citsent citstr=" E03-1021 ">
we have published other papers that have summarise dour key findings, notably variation between individuals (reiter and sripada, 2002<papid> J02-4007 </papid>a; reiter and sripada, 2002<papid> J02-4007 </papid>b); and also described the corpus itself (sripada et al., 2003<papid> E03-1021 </papid>b).</citsent>
<aftsection>
<nextsent>the purpose of this paper is to describe our analysis procedure (including alignment) and results in detail, and to also discuss our current work on using parallel text-data corpora to learn the meanings of other types of words.
</nextsent>
<nextsent>linguists and lexicographers have used number of different techniques to determine the meanings of words.
</nextsent>
<nextsent>these include asking native-speaker informants to judge the acceptability and oddness of test sentences (cruse, 1986); defining word senses via lexicographic analysis of citations and corpora (landau, 1984); and asking subjects to respond to fill in the blank?
</nextsent>
<nextsent>questions (cassidy and hall, 1996).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1043">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>however, like all psychological research, it has examined language usage in an artificial experimental context, not naturally occurring language.
</prevsent>
<prevsent>in the nlp community, models of word meanings are typically either entered by user or developer (for example in microsofts english query natural-language inter day hour wind dir wind speed 25-10-00 0 ssw 12 25-10-00 3 sse 11 25-10-00 6 ese 18 25-10-00 9 ese 16 25-10-00 12 15 25-10-00 15 ene 15 25-10-00 18 ene 18 25-10-00 21 nne 20 26-10-00 0 nnw 26 table 1: wind (at 10m) extract from 24-oct-00 data file face) or derived from hand-built knowledge base (eg, (reiter, 1991)).
</prevsent>
</prevsection>
<citsent citstr=" W02-1022 ">
there is growing interest in trying to learn word meanings from parallel text-data corpora, for example (siskind, 2001; barzilay and lee, 2002; <papid> W02-1022 </papid>roy, 2002).</citsent>
<aftsection>
<nextsent>we believe our work is unusual because we are using naturally occurring texts and data.
</nextsent>
<nextsent>siskind (2001), in contrast, used data which was explicitly created for his experiments; barzilay and lee (2002) <papid> W02-1022 </papid>used texts which subjects had written for previous experiment; and roy (2002) used both data and texts that were created for his experiments.</nextsent>
<nextsent>the sumtime project is investigating better technology for building software systems that automatically generate textual summaries of time-series data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1047">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> analysis procedure for time phrases.  </section>
<citcontext>
<prevsection>
<prevsent>we next associated each wind phrase with an entry in the corresponding data file.
</prevsent>
<prevsent>in other words, we aligned the textual wind phrases with the numeric data file entries.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
as in other uses of parallel corpora, good alignment is essential in order for the results to be meaningful (och and ney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>to associate data file entries with wind phrases, we first searched the data file for entries which matched the wind phrase.
</nextsent>
<nextsent>an entry matched if its speed was within the range defined in the phrase, and if its direction was within 12 degrees of the direction mentioned in the phrase.
</nextsent>
<nextsent>in 343 cases, no data file entry matched the wind phrase.
</nextsent>
<nextsent>we believe that such cases were mostly due to (a) forecasters not literally reporting the data file, but instead adjusting what they said based on their meteorological expertise and on information not available to the numerical weather simulation (such as satellite weather images); (b) forecasters reporting simultaneous change in wind speed and direction, when in fact speed and direction changed at different times (this may be due to forecasters trying towrite texts quickly, so that they can use the most up-to date data (reiter et al, 2003)); and (c) forecaster errors.for example, the third phrase in our example, backing ne early afternoon, does not match any ofthe data file entries shown in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1053">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> current and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the data also suggests that the forecasters may disagree about the meaning of morning, with f4 in particular considering morning to be the period 0300-0900, while f5 considers morning to be the period 0600-1200.
</prevsent>
<prevsent>6.1 verb choice.
</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
we would like to use our corpus to learn choice rules for verbs which are near-synonyms (edmonds and hirst, 2002).<papid> J02-2001 </papid></citsent>
<aftsection>
<nextsent>we are currently attempting to learn rules which predict which of three possible verbs ? decreasing, easing, and falling ? are used when the wind speed decreases.
</nextsent>
<nextsent>we have conducted two experiments.
</nextsent>
<nextsent>the first was semantic analysis, where we attempted to learn choice rule based on features extracted from the numerical data.to do this, we used our aligned corpus to extract semantic features which we thought could be relevant to this decision (such as the amount by which the wind speed has decreased), and then analysed this with ripper (co hen, 1995).
</nextsent>
<nextsent>this gave the rules shown in figure 2; these again show substantial variation between individual fore verb f1 f2 f3 f4 f5 total decreasing 0 0 3 2 0 5 easing 1 19 0 0 0 20 falling 4 0 61 0 0 65 table 7: choice of wind decrease verb when subsequent word is variable, by forecaster (mode in bold) casters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1054">
<title id=" W03-0611.xml">learning the meaning and usage of time phrases from a parallel text data corpus </title>
<section> current and future work.  </section>
<citcontext>
<prevsection>
<prevsent>these rules suggest that at least for some forecasters, decreasing suggests larger change in the wind speed than easing; this is the sort of near-synonym connotational difference that we expected to find.
</prevsent>
<prevsent>more surprisingly (at least to us), the presence of forecast date in some of the rules suggests that forecasters change how they write over time.
</prevsent>
</prevsection>
<citsent citstr=" W00-1429 ">
perhaps in retrospect this should not have been surprise, because we have also observed changes over time in how people write in previous project (reiter et al, 2000).<papid> W00-1429 </papid></citsent>
<aftsection>
<nextsent>we also analysed collocation effects, that is whether we could predict verb choice based purely on the words immediately preceding and following the verb (and hence ignoring the numerical prediction data).
</nextsent>
<nextsent>this was done on the complete corpus (not just verbs that were part of successfully aligned phrases).
</nextsent>
<nextsent>it is difficult to directly compare the collocation analysis with the semantic onedue to differences in the corpora texts used, but in general terms the reduction in baseline error rate seems comparable to the semantic analysis.
</nextsent>
<nextsent>some of the collocation effects were both strong and forecaster-dependent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1062">
<title id=" W03-0501.xml">hedge trimmer a parseandtrim approach to headline generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we claim that the construction of informative abstracts requires access to deeper linguistic knowledge, in order to make substantial improvements over purely statistical approaches.
</prevsent>
<prevsent>in this paper, we present our technique for producing headlines using parse-and-trim approach based on the bbn parser.
</prevsent>
</prevsection>
<citsent citstr=" M98-1009 ">
as described in miller et al (1998), <papid> M98-1009 </papid>the bbn parser builds augmented parse trees according to process similar to that described in collins (1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>the bbn parser has been used successfully for the task of information extraction in the sift system (miller et al., 2000).<papid> A00-2030 </papid></nextsent>
<nextsent>the next section presents previous work in the area of automatic generation of abstracts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1063">
<title id=" W03-0501.xml">hedge trimmer a parseandtrim approach to headline generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we claim that the construction of informative abstracts requires access to deeper linguistic knowledge, in order to make substantial improvements over purely statistical approaches.
</prevsent>
<prevsent>in this paper, we present our technique for producing headlines using parse-and-trim approach based on the bbn parser.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
as described in miller et al (1998), <papid> M98-1009 </papid>the bbn parser builds augmented parse trees according to process similar to that described in collins (1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>the bbn parser has been used successfully for the task of information extraction in the sift system (miller et al., 2000).<papid> A00-2030 </papid></nextsent>
<nextsent>the next section presents previous work in the area of automatic generation of abstracts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1064">
<title id=" W03-0501.xml">hedge trimmer a parseandtrim approach to headline generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present our technique for producing headlines using parse-and-trim approach based on the bbn parser.
</prevsent>
<prevsent>as described in miller et al (1998), <papid> M98-1009 </papid>the bbn parser builds augmented parse trees according to process similar to that described in collins (1997).<papid> P97-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
the bbn parser has been used successfully for the task of information extraction in the sift system (miller et al., 2000).<papid> A00-2030 </papid></citsent>
<aftsection>
<nextsent>the next section presents previous work in the area of automatic generation of abstracts.
</nextsent>
<nextsent>following this, we present feasibility tests used to establish the validity of an approach that constructs headlines from words in story, taken in order and focusing on the earlier part of the story.
</nextsent>
<nextsent>next, we describe the application of the parse-and-trim approach to the problem of headline generation.
</nextsent>
<nextsent>we discuss the linguistically-motivated heuristics we use to produce results that are headlinelike.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1065">
<title id=" W03-0501.xml">hedge trimmer a parseandtrim approach to headline generation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we evaluate hedge trimmer by comparing it to our earlier work on headline generation, probabilistic model for automatic headline generation (zajic et al 2002).
</prevsent>
<prevsent>in this paper we will refer to this statistical system as hmm hedge we demonstrate the effectiveness of our linguistically-motivated approach, hedge trimmer, over the probabilistic model, hmm hedge, using both human evaluation and automatic metrics.
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
other researchers have investigated the topic of automatic generation of abstracts, but the focus has been different, e.g., sentence extraction (edmundson, 1969; johnson et al 1993; kupiec et al, 1995; mann et al, 1992; teufel and moens, 1997; zechner, 1995), processing of structured templates (paice and jones, 1993), sentence compression (hori et al, 2002; knight and marcu, 2001; grefenstette, 1998, luhn, 1958), and generation of abstracts from multiple sources (radev and mckeown, 1998).<papid> J98-3005 </papid></citsent>
<aftsection>
<nextsent>we focus instead on the construction of headline-style abstracts from single story.
</nextsent>
<nextsent>headline generation can be viewed as analogous to statistical machine translation, where concise document is generated from verbose one using noisy channel model and the viterbi search to select the most likely summarization.
</nextsent>
<nextsent>this approach has been explored in (zajic et al, 2002) and (banko et al, 2000).<papid> P00-1041 </papid></nextsent>
<nextsent>the approach we use in hedge is most similar to that of (knight and marcu, 2001), where single sentence is shortened using statistical compression.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1066">
<title id=" W03-0501.xml">hedge trimmer a parseandtrim approach to headline generation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>we focus instead on the construction of headline-style abstracts from single story.
</prevsent>
<prevsent>headline generation can be viewed as analogous to statistical machine translation, where concise document is generated from verbose one using noisy channel model and the viterbi search to select the most likely summarization.
</prevsent>
</prevsection>
<citsent citstr=" P00-1041 ">
this approach has been explored in (zajic et al, 2002) and (banko et al, 2000).<papid> P00-1041 </papid></citsent>
<aftsection>
<nextsent>the approach we use in hedge is most similar to that of (knight and marcu, 2001), where single sentence is shortened using statistical compression.
</nextsent>
<nextsent>as in this work, we select headline words from story words in the order that they appear in the storyin particular, the first sentence of the story.
</nextsent>
<nextsent>however, we use linguistically motivated heuristics for shortening the sentence; there is no statistical model, which means we do not require any prior training on large corpus of story/headline pairs.
</nextsent>
<nextsent>linguistically motivated heuristics have been used by (mckeown et al 2002) to distinguish constituents of parse trees which can be removed without affecting grammaticality or correctness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1067">
<title id=" W03-0501.xml">hedge trimmer a parseandtrim approach to headline generation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>hmm hedge was trained on 700,000 news articles and headlines from the tipster corpus.
</prevsent>
<prevsent>5.2 bleu: automatic evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu (papineni et al 2002) <papid> P02-1040 </papid>is system for automatic evaluation of machine translation.</citsent>
<aftsection>
<nextsent>bleu uses modified n-gram precision measure to compare machine translations to reference human translations.
</nextsent>
<nextsent>we treat summarization as type of translation from verbose language to concise one, and compare automatically generated headlines to human generated headlines.
</nextsent>
<nextsent>for this evaluation we used 100 headlines created for 100 ap stories from the tipster collection for august 6, 1990 as reference summarizations for those stories.
</nextsent>
<nextsent>these 100 stories had never been run through either system or evaluated by the authors prior to this evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1068">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>various attempts worldwide have begun focussing onthe argument structure of verbs as part of developing dependency grammars.
</prevsent>
<prevsent>the propbank project at penn (kingsbury and palmer, 2002) is an example of this process for english; similar projects are underway for czech (hajicova etc), german (broker1998), and others.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the framenet project at berkeley (baker et al , 1998) <papid> P98-1013 </papid>has classi ed many words in terms of their relation to relatively small number of core semantic concepts such as `commerce  and `judgment .</citsent>
<aftsection>
<nextsent>various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the levin class as gold standard for evaluation (gildea, 2002; <papid> C02-1132 </papid>mccarthy, 2000; <papid> A00-2034 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000).</nextsent>
<nextsent>in the next two sections, we provide background on verbnet and propbank which play central roles in the cluster methodology presented here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1069">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the propbank project at penn (kingsbury and palmer, 2002) is an example of this process for english; similar projects are underway for czech (hajicova etc), german (broker1998), and others.
</prevsent>
<prevsent>the framenet project at berkeley (baker et al , 1998) <papid> P98-1013 </papid>has classi ed many words in terms of their relation to relatively small number of core semantic concepts such as `commerce  and `judgment .</prevsent>
</prevsection>
<citsent citstr=" C02-1132 ">
various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the levin class as gold standard for evaluation (gildea, 2002; <papid> C02-1132 </papid>mccarthy, 2000; <papid> A00-2034 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000).</citsent>
<aftsection>
<nextsent>in the next two sections, we provide background on verbnet and propbank which play central roles in the cluster methodology presented here.
</nextsent>
<nextsent>2.1 verbnet.
</nextsent>
<nextsent>verbnet is verb lexicon with syntactic and semantic information for english verbs, referring to levin verb classes (levin, 1993) for systematic construction of lexical entries.
</nextsent>
<nextsent>this lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides clear and regular association between syntactic and semantic properties of verbs and verb classes (kipper et al ,2000; dang et al , 2000).<papid> C00-2148 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1070">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the propbank project at penn (kingsbury and palmer, 2002) is an example of this process for english; similar projects are underway for czech (hajicova etc), german (broker1998), and others.
</prevsent>
<prevsent>the framenet project at berkeley (baker et al , 1998) <papid> P98-1013 </papid>has classi ed many words in terms of their relation to relatively small number of core semantic concepts such as `commerce  and `judgment .</prevsent>
</prevsection>
<citsent citstr=" A00-2034 ">
various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the levin class as gold standard for evaluation (gildea, 2002; <papid> C02-1132 </papid>mccarthy, 2000; <papid> A00-2034 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000).</citsent>
<aftsection>
<nextsent>in the next two sections, we provide background on verbnet and propbank which play central roles in the cluster methodology presented here.
</nextsent>
<nextsent>2.1 verbnet.
</nextsent>
<nextsent>verbnet is verb lexicon with syntactic and semantic information for english verbs, referring to levin verb classes (levin, 1993) for systematic construction of lexical entries.
</nextsent>
<nextsent>this lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides clear and regular association between syntactic and semantic properties of verbs and verb classes (kipper et al ,2000; dang et al , 2000).<papid> C00-2148 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1071">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the propbank project at penn (kingsbury and palmer, 2002) is an example of this process for english; similar projects are underway for czech (hajicova etc), german (broker1998), and others.
</prevsent>
<prevsent>the framenet project at berkeley (baker et al , 1998) <papid> P98-1013 </papid>has classi ed many words in terms of their relation to relatively small number of core semantic concepts such as `commerce  and `judgment .</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
various attempts have been made to automatically cluster verbs into semantically meaningful classes, using the levin class as gold standard for evaluation (gildea, 2002; <papid> C02-1132 </papid>mccarthy, 2000; <papid> A00-2034 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000).</citsent>
<aftsection>
<nextsent>in the next two sections, we provide background on verbnet and propbank which play central roles in the cluster methodology presented here.
</nextsent>
<nextsent>2.1 verbnet.
</nextsent>
<nextsent>verbnet is verb lexicon with syntactic and semantic information for english verbs, referring to levin verb classes (levin, 1993) for systematic construction of lexical entries.
</nextsent>
<nextsent>this lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides clear and regular association between syntactic and semantic properties of verbs and verb classes (kipper et al ,2000; dang et al , 2000).<papid> C00-2148 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1072">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 verbnet.
</prevsent>
<prevsent>verbnet is verb lexicon with syntactic and semantic information for english verbs, referring to levin verb classes (levin, 1993) for systematic construction of lexical entries.
</prevsent>
</prevsection>
<citsent citstr=" C00-2148 ">
this lexicon exploits the systematic link between syntax and semantics that motivates these classes, and thus provides clear and regular association between syntactic and semantic properties of verbs and verb classes (kipper et al ,2000; dang et al , 2000).<papid> C00-2148 </papid></citsent>
<aftsection>
<nextsent>each class in the hierarchy is composed of set of members (linked to their wordnet synsets) and set of syntactic frames and semantic information for each frame.
</nextsent>
<nextsent>currently, verbnet has over 4,000 verb senses described (3,004 lemmas) within 191 rst level classes.
</nextsent>
<nextsent>verbnet has hierarchical structure, with the rst level classes constituted by the original levin classes.
</nextsent>
<nextsent>in order to ensure that each class is coherent, so that all its members share common set of thematic roles,syntactic frames and semantic predicates, some restructuring of the classes was required.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1073">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>verbnet has hierarchical structure, with the rst level classes constituted by the original levin classes.
</prevsent>
<prevsent>in order to ensure that each class is coherent, so that all its members share common set of thematic roles,syntactic frames and semantic predicates, some restructuring of the classes was required.
</prevsent>
</prevsection>
<citsent citstr=" P98-1046 ">
this reorganization, which was facilitated by the use of inter sective levin classes (dang et al , 1998), <papid> P98-1046 </papid>re ned the classes to account for semantic and syntactic dier ences within class.</citsent>
<aftsection>
<nextsent>a child subclass inherits all the information from its parent class, and adds information to it, which can be in terms of imposing further restrictions on the roles, or adding syntactic frames or semantic predicates to the subclass.the hierarchical organization of verbnet is illustrated in figure 1.
</nextsent>
<nextsent>the transfer of message verb class is subdivided into three levels.
</nextsent>
<nextsent>at the top level are thematic roles, syntactic frames and semantic predicates shared by all members of the class.
</nextsent>
<nextsent>in this particular case, there is transitive frame with the topic (message) as the direct object (agent verb topic), as in \john explained trigonometry , and frame for topic and recipient (agent verb topic to recipient), as in \john taught math to mary .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1074">
<title id=" W03-0910.xml">deriving verb meaning clusters from syntactic structure </title>
<section> issue and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>verbnet uses at semantic representation inwhich the semantics of each syntactic frame is captured by conjunction of predicates 1, such as motion, contact, transfer info, which can be negated or not.
</prevsent>
<prevsent>these predicates can take arguments over theverb complements, as well as over implicit existen tially quanti ed event variables.
</prevsent>
</prevsection>
<citsent citstr=" J88-2003 ">
each semantic predicate in verbnet al include time function specifying whether the predicate is true in the preparatory (during(e)), culmination (end(e)), or consequent (result(e)) stage of an event, in tripartite event structure is similar to that of moens and steedman (1988), <papid> J88-2003 </papid>which allows us to express the semantics of classes of verbs like change of state verbs whose description requires reference to complex event structure.</citsent>
<aftsection>
<nextsent>2.2 propbank.
</nextsent>
<nextsent>in dierent vein, the propbank project (kingsbury and palmer, 2002) has endeavoured to describe all the most frequent verbs of english in terms of their argument structure.
</nextsent>
<nextsent>this project has three majordierences from previous works.
</nextsent>
<nextsent>first, the description of each verb is accompanied by rich set of examples drawn from real language, in this case the wall street journal sections of the penn treebank (marcus, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1075">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>language processing (emnlp), philadelphia, july 2002, pp.
</prevsent>
<prevsent>79-86.
</prevsent>
</prevsection>
<citsent citstr=" P97-1005 ">
proceedings of the conference on empirical methods in natural al., 1998; tomokiyo and jones, 2001; kessler et al, 1997).<papid> P97-1005 </papid></citsent>
<aftsection>
<nextsent>another, more related area of research is that of determining the genre of texts; subjective genres, such as editorial?, are often one of the possible categories (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al., 1997; <papid> P97-1005 </papid>finn et al, 2002).</nextsent>
<nextsent>other work explicitly attempts to find features indicating that subjective language is being used (hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>wiebe et al, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1076">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>79-86.
</prevsent>
<prevsent>proceedings of the conference on empirical methods in natural al., 1998; tomokiyo and jones, 2001; kessler et al, 1997).<papid> P97-1005 </papid></prevsent>
</prevsection>
<citsent citstr=" C94-2174 ">
another, more related area of research is that of determining the genre of texts; subjective genres, such as editorial?, are often one of the possible categories (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al., 1997; <papid> P97-1005 </papid>finn et al, 2002).</citsent>
<aftsection>
<nextsent>other work explicitly attempts to find features indicating that subjective language is being used (hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>wiebe et al, 2001).</nextsent>
<nextsent>but, while techniques for genre categorization and subjectivity detection canhelp us recognize documents that express an opinion, they do not address our specific classification task of determining what that opinion actually is.most previous research on sentiment-based classification has been at least partially knowledge-based.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1078">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>proceedings of the conference on empirical methods in natural al., 1998; tomokiyo and jones, 2001; kessler et al, 1997).<papid> P97-1005 </papid></prevsent>
<prevsent>another, more related area of research is that of determining the genre of texts; subjective genres, such as editorial?, are often one of the possible categories (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al., 1997; <papid> P97-1005 </papid>finn et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" C00-1044 ">
other work explicitly attempts to find features indicating that subjective language is being used (hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>wiebe et al, 2001).</citsent>
<aftsection>
<nextsent>but, while techniques for genre categorization and subjectivity detection canhelp us recognize documents that express an opinion, they do not address our specific classification task of determining what that opinion actually is.most previous research on sentiment-based classification has been at least partially knowledge-based.
</nextsent>
<nextsent>some of this work focuses on classifying the semantic orientation of individual words or phrases, using linguistic heuristics or pre-selected set of seed words (hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2002).</nextsent>
<nextsent>past work on sentiment-based categorization of entire documents has often involved either the use of models inspired by cognitive linguistics (hearst, 1992; sack, 1994) or the manual orsemi-manual construction of discriminant-word lexicons (huettner and subasic, 2000; das and chen,2001; tong, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1080">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>other work explicitly attempts to find features indicating that subjective language is being used (hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>wiebe et al, 2001).</prevsent>
<prevsent>but, while techniques for genre categorization and subjectivity detection canhelp us recognize documents that express an opinion, they do not address our specific classification task of determining what that opinion actually is.most previous research on sentiment-based classification has been at least partially knowledge-based.</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
some of this work focuses on classifying the semantic orientation of individual words or phrases, using linguistic heuristics or pre-selected set of seed words (hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2002).</citsent>
<aftsection>
<nextsent>past work on sentiment-based categorization of entire documents has often involved either the use of models inspired by cognitive linguistics (hearst, 1992; sack, 1994) or the manual orsemi-manual construction of discriminant-word lexicons (huettner and subasic, 2000; das and chen,2001; tong, 2001).
</nextsent>
<nextsent>interestingly, our baseline experiments, described in section 4, show that humans may not always have the best intuition for choosing discriminating words.
</nextsent>
<nextsent>turneys (2002) work on classification of review sis perhaps the closest to ours.2 he applied specific unsupervised learning technique based on the mutual information between document phrases andthe words excellent?
</nextsent>
<nextsent>and poor?, where the mutual information is computed using statistics gathered by search engine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1081">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> the movie-review domain.  </section>
<citcontext>
<prevsection>
<prevsent>for our experiments, we chose to work with movie reviews.
</prevsent>
<prevsent>this domain is experimentally convenient because there are large on-line collections of such reviews, and because reviewers often summarize their overall sentiment with machine-extractable rating indicator, such as number of stars; hence, we did not need to hand-label the data for supervised learning or evaluation purposes.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
we also note that turney (2002) <papid> P02-1053 </papid>found movie reviews to be the most 2indeed, although our choice of title was completely independent of his, our selections were eerily similar.difficult of several domains for sentiment classification, reporting an accuracy of 65.83% on 120 document set (random-choice performance: 50%).</citsent>
<aftsection>
<nextsent>but we stress that the machine learning methods and features we use are not specific to movie reviews, and should be easily applicable to other domains as long as sufficient training data exists.
</nextsent>
<nextsent>our data source was the internet movie database (imdb) archive of the rec.arts.movies.reviewsnewsgroup.3 we selected only reviews where the author rating was expressed either with stars or some numerical value (other conventions varied too widely to allow for automatic processing).
</nextsent>
<nextsent>ratings were automatically extracted and converted into one of three categories: positive, negative, or neutral.
</nextsent>
<nextsent>for the work described in this paper, we concentrated only on discriminating between positive and negative sentiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1083">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> machine learning methods.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, more sophisticated algorithms might (and of ten do) yield better results; we examine two such algorithms next.
</prevsent>
<prevsent>5.2 maximum entropy.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
maximum entropy classification (maxent, or me, for short) is an alternative technique which has proven effective in number of natural language processing applications (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>nigam et al (1999) show that it sometimes, but not always, outperforms naive bayes at standard textclassification.
</nextsent>
<nextsent>its estimate of (c | d) takes the following exponential form: pme(c | d) := 1 z(d) exp ( ? i,cfi,c(d, c) ) ,where z(d) is normalization function.
</nextsent>
<nextsent>fi,c is fea ture/class function for feature fi and class c, defined as follows:6 fi,c(d, c?)
</nextsent>
<nextsent>:= { 1, ni(d)   0 and c?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1084">
<title id=" W02-1011.xml">thumbs up sentiment classification using machine learning techniques </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>conditional-independence assumptions; on the other hand, recall that this does not imply that naive bayes will necessarily do poorly (domingos and pazzani, 1997).
</prevsent>
<prevsent>line (3) of the results table shows that bigram information does not improve performance beyond that of unigram presence, although adding in the bi grams does not seriously impact the results, even for naive bayes.
</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
this would not rule out the possibility that bigram presence is as equally useful feature as unigram presence; in fact, pedersen (2001) <papid> N01-1011 </papid>found that bigrams alone can be effective features for word sense disambiguation.</citsent>
<aftsection>
<nextsent>however, comparing line (4) to line (2) shows that relying just on bigrams causes accuracy to decline by as much as 5.8 percentage points.
</nextsent>
<nextsent>hence, if context is in fact important, as our intuitions suggest, bigrams are not effective at capturing it in our setting.11alternatively, we could have tried integrating frequency information into maxent.
</nextsent>
<nextsent>however, feature/class functions are traditionally defined as binary (berger et al., 1996); <papid> J96-1002 </papid>hence, explicitly incorporating frequencies would require different functions for each count (or count bin), making training impractical.</nextsent>
<nextsent>but cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1091">
<title id=" W03-1118.xml">text categorization using automatically acquired domain ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous works suggest that ontology acquisition is an iterative process, which includes keyword collection and structure reorganization.
</prevsent>
<prevsent>the ontology is revised, refined, and accumulated by human editor at each iteration (noy and mcguinness, 2001).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
for example, in order to find hyponym of keyword, the human editor must observe sentences containing this keyword and its related hyponyms (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>the editor then deduces rules for finding more hyponyms of this keyword.
</nextsent>
<nextsent>at each iteration the editor refines the rules to obtain better quality pairs of keyword-hyponyms.
</nextsent>
<nextsent>to speed up the above labor-intensive approach, semiautomatic approaches have been designed in which human editor only has to verify the results of the acquisition (maedche and staab, 2000).
</nextsent>
<nextsent>a knowledge representation framework, information map (infomap) in our previous work (hsu et al, 2001), has been designed to integrate various linguistic, common-sense and domain knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1092">
<title id=" W03-1118.xml">text categorization using automatically acquired domain ontology </title>
<section> automatic ontology acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>3.4 ontology merging.
</prevsent>
<prevsent>ontologies can be created by merging different resources.
</prevsent>
</prevsection>
<citsent citstr=" C02-1089 ">
one nlp resource that we will merge into our domain ontology is the noun-verb event frame (nvef) database (tsai and hsu, 2002).<papid> C02-1089 </papid></citsent>
<aftsection>
<nextsent>nvef is collection of permissible noun-verb sense-pairs that appear in general domain corpora.
</nextsent>
<nextsent>the noun will be the subject or object of the verb.
</nextsent>
<nextsent>this noun-verb sense-pair collection is domain independent.
</nextsent>
<nextsent>we can use nouns as domain keywords and find their correlated verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1093">
<title id=" W03-1309.xml">protein name tagging for biomedical annotation in text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using genia corpus 3.01, our method attains f-score of 70 points for protein molecule names, and 75 points for protein names including molecules, families and domains.
</prevsent>
<prevsent>this paper describes protein name tagging method which is fundamental precursor to information extraction of protein-protein interactions (ppis) from medline abstracts.
</prevsent>
</prevsection>
<citsent citstr=" C02-1110 ">
previous work in bio-entity (including protein) recognition can be categorized into three approaches: (a) exact and approximate string matching (hanisch et al, 2003), (b) handcrafted rule-based approaches (fukuda et al, 1998)(olsson et al, 2002), <papid> C02-1110 </papid>and (c) machine learning (col lier et al, 2000), (<papid> C00-1030 </papid>kazama et al, 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>previous approaches in (b) and (c) ignore the fact that bio-entities have boundary ambiguities.
</nextsent>
<nextsent>unlike general english, space character is nota sufficient token delimiter.
</nextsent>
<nextsent>moreover, name descriptions in biomedical resources are mostly compounds.
</nextsent>
<nextsent>a conventional english preprocessing undergoes pipeline of simple tokenization and part of-speech tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1094">
<title id=" W03-1309.xml">protein name tagging for biomedical annotation in text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using genia corpus 3.01, our method attains f-score of 70 points for protein molecule names, and 75 points for protein names including molecules, families and domains.
</prevsent>
<prevsent>this paper describes protein name tagging method which is fundamental precursor to information extraction of protein-protein interactions (ppis) from medline abstracts.
</prevsent>
</prevsection>
<citsent citstr=" C00-1030 ">
previous work in bio-entity (including protein) recognition can be categorized into three approaches: (a) exact and approximate string matching (hanisch et al, 2003), (b) handcrafted rule-based approaches (fukuda et al, 1998)(olsson et al, 2002), <papid> C02-1110 </papid>and (c) machine learning (col lier et al, 2000), (<papid> C00-1030 </papid>kazama et al, 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>previous approaches in (b) and (c) ignore the fact that bio-entities have boundary ambiguities.
</nextsent>
<nextsent>unlike general english, space character is nota sufficient token delimiter.
</nextsent>
<nextsent>moreover, name descriptions in biomedical resources are mostly compounds.
</nextsent>
<nextsent>a conventional english preprocessing undergoes pipeline of simple tokenization and part of-speech tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1095">
<title id=" W03-1309.xml">protein name tagging for biomedical annotation in text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using genia corpus 3.01, our method attains f-score of 70 points for protein molecule names, and 75 points for protein names including molecules, families and domains.
</prevsent>
<prevsent>this paper describes protein name tagging method which is fundamental precursor to information extraction of protein-protein interactions (ppis) from medline abstracts.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
previous work in bio-entity (including protein) recognition can be categorized into three approaches: (a) exact and approximate string matching (hanisch et al, 2003), (b) handcrafted rule-based approaches (fukuda et al, 1998)(olsson et al, 2002), <papid> C02-1110 </papid>and (c) machine learning (col lier et al, 2000), (<papid> C00-1030 </papid>kazama et al, 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>previous approaches in (b) and (c) ignore the fact that bio-entities have boundary ambiguities.
</nextsent>
<nextsent>unlike general english, space character is nota sufficient token delimiter.
</nextsent>
<nextsent>moreover, name descriptions in biomedical resources are mostly compounds.
</nextsent>
<nextsent>a conventional english preprocessing undergoes pipeline of simple tokenization and part of-speech tagging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1096">
<title id=" W03-1309.xml">protein name tagging for biomedical annotation in text </title>
<section> protein name tagging.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 morphological analysis.
</prevsent>
<prevsent>our morphological analysis gives (a) sophisticated tokenization, (b) part-of-speech tagging and (c) annotation of value-added information such as the stemmed form of word, accession numbers to biomedical resources.
</prevsent>
</prevsection>
<citsent citstr=" A00-1032 ">
our morphological analyzer for biomedical english, cocab2, is inspired by the work of yamashita and matsumoto (2000).<papid> A00-1032 </papid></citsent>
<aftsection>
<nextsent>2.1.1 preliminaries we first define terms used in this paper with an illustration in figure 2.
</nextsent>
<nextsent>a lexeme is an entry in dictionary.
</nextsent>
<nextsent>a common prefix search (cps) is standard technique for looking up lexemes in morphological analysis of non segmented languages.
</nextsent>
<nextsent>a dictionary is often trie data structure so that all possible lexemes that match with the prefix starting at given position in the sentence are retrieved efficiently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1097">
<title id=" W03-1309.xml">protein name tagging for biomedical annotation in text </title>
<section> protein name tagging.  </section>
<citcontext>
<prevsection>
<prevsent>theconll-1999 shared task dataset is used for training with yamcha, the general purpose svm-based chunker4.
</prevsent>
<prevsent>there are four kinds of chunk tags in the conll-1999 dataset, namely iob1, iob2, ioe1, and ioe2 (tjong kim sang and veenstra, 1999).
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
we follow kudo and matsumoto (2001) <papid> N01-1025 </papid>to train four basenp recognizers, one for each chunk tag.</citsent>
<aftsection>
<nextsent>theword-based output from the morphological analysis is cascaded to each basenp recognizer to mark basenp boundaries.
</nextsent>
<nextsent>we collect outputs from the 4http://cl.aist-nara.ac.jp/takuku/software/yamcha/).
</nextsent>
<nextsent>four recognizers, and interpret the tag as outside of basenp if all recognizers estimate the o(utside)?
</nextsent>
<nextsent>tag, otherwise inside of basenp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1115">
<title id=" W03-1309.xml">protein name tagging for biomedical annotation in text </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>our internal experiments with genia 3.0 (the version was corrected to genia 3.01) reveal that the corpus error is critical in our method.
</prevsent>
<prevsent>even corpus errors have been successfully removed, it would not be practical to increase the size of labor-intensiveannotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
use of unlabeled data in conjunction with small but quality set of labeled data.e.g. collins and singer (1999), <papid> W99-0613 </papid>would have to be ex plored.</citsent>
<aftsection>
<nextsent>tanabe and wilbur (2002) use hybrid approach of transformation-based learning (brill tagger) with rule-based postprocessing.
</nextsent>
<nextsent>an obvious drawback in their approach as with other rule-based approaches including fukuda et al (1998) is that the approaches cannot handle many correlated features.
</nextsent>
<nextsent>as pointed out in their paper, errors in the early stage of rule application are often propagated to the later stage, damaging the overall performance.
</nextsent>
<nextsent>in contrast, our method can deal with correlated features owing to the generalization characteristic of svm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1116">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>the main idea behind boosting algorithms is that set of many weak classifiers can be effectively combined to yield single strong classifier.
</prevsent>
<prevsent>each weak classifier is trained sequentially, increasingly focusing more heavily on the instances that the previous classifiers found difficult to classify.for the boosting framework, our system uses adaboost.mh (freund and schapire, 1997), an n-ary classification variant of the original binary ada boost algorithm.it performs well on number of natural language processing problems, including text categorization (schapire and singer, 2000) and word sense disambiguation (escudero et al, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W02-2035 ">
in particular, it has also been demonstrated that boosting can be used to build language-independent ner models that perform exceptionally well (wu et al, 2002; <papid> W02-2035 </papid>carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>2.2 support vector machines.
</nextsent>
<nextsent>support vector machines (svms) have gained considerable following in recent years (boser et al, 1992), particularly in dealing with high-dimensional spaces such as commonly found in natural language problems like text categorization (joachims, 1998).
</nextsent>
<nextsent>svms have shown promise when applied to chunking (kudo and matsumoto, 2001) <papid> N01-1025 </papid>and named entity recognition (sassano and utsuro, 2000; <papid> C00-2102 </papid>mcnamee and mayfield,2002), <papid> W02-2020 </papid>though performance is quite sensitive to parameter choices.</nextsent>
<nextsent>2.3 transformation-based learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1117">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>the main idea behind boosting algorithms is that set of many weak classifiers can be effectively combined to yield single strong classifier.
</prevsent>
<prevsent>each weak classifier is trained sequentially, increasingly focusing more heavily on the instances that the previous classifiers found difficult to classify.for the boosting framework, our system uses adaboost.mh (freund and schapire, 1997), an n-ary classification variant of the original binary ada boost algorithm.it performs well on number of natural language processing problems, including text categorization (schapire and singer, 2000) and word sense disambiguation (escudero et al, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
in particular, it has also been demonstrated that boosting can be used to build language-independent ner models that perform exceptionally well (wu et al, 2002; <papid> W02-2035 </papid>carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>2.2 support vector machines.
</nextsent>
<nextsent>support vector machines (svms) have gained considerable following in recent years (boser et al, 1992), particularly in dealing with high-dimensional spaces such as commonly found in natural language problems like text categorization (joachims, 1998).
</nextsent>
<nextsent>svms have shown promise when applied to chunking (kudo and matsumoto, 2001) <papid> N01-1025 </papid>and named entity recognition (sassano and utsuro, 2000; <papid> C00-2102 </papid>mcnamee and mayfield,2002), <papid> W02-2020 </papid>though performance is quite sensitive to parameter choices.</nextsent>
<nextsent>2.3 transformation-based learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1118">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 support vector machines.
</prevsent>
<prevsent>support vector machines (svms) have gained considerable following in recent years (boser et al, 1992), particularly in dealing with high-dimensional spaces such as commonly found in natural language problems like text categorization (joachims, 1998).
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
svms have shown promise when applied to chunking (kudo and matsumoto, 2001) <papid> N01-1025 </papid>and named entity recognition (sassano and utsuro, 2000; <papid> C00-2102 </papid>mcnamee and mayfield,2002), <papid> W02-2020 </papid>though performance is quite sensitive to parameter choices.</citsent>
<aftsection>
<nextsent>2.3 transformation-based learning.
</nextsent>
<nextsent>transformation-based learning (brill, 1995) (<papid> J95-4004 </papid>tbl) is arule-based machine learning algorithm that was first introduced by brill and used for part-of-speech tagging.</nextsent>
<nextsent>the central idea of transformation-based learning is to learn an ordered list of rules which progressively improve upon the current state of the training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1119">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 support vector machines.
</prevsent>
<prevsent>support vector machines (svms) have gained considerable following in recent years (boser et al, 1992), particularly in dealing with high-dimensional spaces such as commonly found in natural language problems like text categorization (joachims, 1998).
</prevsent>
</prevsection>
<citsent citstr=" C00-2102 ">
svms have shown promise when applied to chunking (kudo and matsumoto, 2001) <papid> N01-1025 </papid>and named entity recognition (sassano and utsuro, 2000; <papid> C00-2102 </papid>mcnamee and mayfield,2002), <papid> W02-2020 </papid>though performance is quite sensitive to parameter choices.</citsent>
<aftsection>
<nextsent>2.3 transformation-based learning.
</nextsent>
<nextsent>transformation-based learning (brill, 1995) (<papid> J95-4004 </papid>tbl) is arule-based machine learning algorithm that was first introduced by brill and used for part-of-speech tagging.</nextsent>
<nextsent>the central idea of transformation-based learning is to learn an ordered list of rules which progressively improve upon the current state of the training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1120">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 support vector machines.
</prevsent>
<prevsent>support vector machines (svms) have gained considerable following in recent years (boser et al, 1992), particularly in dealing with high-dimensional spaces such as commonly found in natural language problems like text categorization (joachims, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W02-2020 ">
svms have shown promise when applied to chunking (kudo and matsumoto, 2001) <papid> N01-1025 </papid>and named entity recognition (sassano and utsuro, 2000; <papid> C00-2102 </papid>mcnamee and mayfield,2002), <papid> W02-2020 </papid>though performance is quite sensitive to parameter choices.</citsent>
<aftsection>
<nextsent>2.3 transformation-based learning.
</nextsent>
<nextsent>transformation-based learning (brill, 1995) (<papid> J95-4004 </papid>tbl) is arule-based machine learning algorithm that was first introduced by brill and used for part-of-speech tagging.</nextsent>
<nextsent>the central idea of transformation-based learning is to learn an ordered list of rules which progressively improve upon the current state of the training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1121">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>svms have shown promise when applied to chunking (kudo and matsumoto, 2001) <papid> N01-1025 </papid>and named entity recognition (sassano and utsuro, 2000; <papid> C00-2102 </papid>mcnamee and mayfield,2002), <papid> W02-2020 </papid>though performance is quite sensitive to parameter choices.</prevsent>
<prevsent>2.3 transformation-based learning.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
transformation-based learning (brill, 1995) (<papid> J95-4004 </papid>tbl) is arule-based machine learning algorithm that was first introduced by brill and used for part-of-speech tagging.</citsent>
<aftsection>
<nextsent>the central idea of transformation-based learning is to learn an ordered list of rules which progressively improve upon the current state of the training set.
</nextsent>
<nextsent>an initial assignment is made based on simple statistics, and then rules are greedily learned to correct the mistakes, until no net improvement can be made.the experiments presented in this paper were performed using the fntbl toolkit (ngai and florian, 2001), <papid> N01-1006 </papid>which implements several optimizations in rule learning to drastically speed up the time needed for training.</nextsent>
<nextsent>3.1 preprocessing the data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1122">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> classification methods.  </section>
<citcontext>
<prevsection>
<prevsent>transformation-based learning (brill, 1995) (<papid> J95-4004 </papid>tbl) is arule-based machine learning algorithm that was first introduced by brill and used for part-of-speech tagging.</prevsent>
<prevsent>the central idea of transformation-based learning is to learn an ordered list of rules which progressively improve upon the current state of the training set.</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
an initial assignment is made based on simple statistics, and then rules are greedily learned to correct the mistakes, until no net improvement can be made.the experiments presented in this paper were performed using the fntbl toolkit (ngai and florian, 2001), <papid> N01-1006 </papid>which implements several optimizations in rule learning to drastically speed up the time needed for training.</citsent>
<aftsection>
<nextsent>3.1 preprocessing the data.
</nextsent>
<nextsent>the data that was provided by the conll organizers was sentence-delimited and tokenized, and hand-annotatedwith named entity chunks.
</nextsent>
<nextsent>the english data was automatically labeled with part-of-speech and chunk tags from the memory-based tagger and chunker (daelemans et al, 1996), <papid> W96-0102 </papid>and the german data was labelled with thedecision-tree-based tree tagger (schmidt, 1994).</nextsent>
<nextsent>we replaced the english part-of-speech tags with those generated by transformation-based learner (ngai and florian, 2001).<papid> N01-1006 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1123">
<title id=" W03-0433.xml">a stacked voted stacked model for named entity recognition </title>
<section> data resources.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 preprocessing the data.
</prevsent>
<prevsent>the data that was provided by the conll organizers was sentence-delimited and tokenized, and hand-annotatedwith named entity chunks.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
the english data was automatically labeled with part-of-speech and chunk tags from the memory-based tagger and chunker (daelemans et al, 1996), <papid> W96-0102 </papid>and the german data was labelled with thedecision-tree-based tree tagger (schmidt, 1994).</citsent>
<aftsection>
<nextsent>we replaced the english part-of-speech tags with those generated by transformation-based learner (ngai and florian, 2001).<papid> N01-1006 </papid></nextsent>
<nextsent>the chunk tags did not appear to help in either case and were discarded.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1125">
<title id=" W03-0316.xml">pos tagger for english vietnamese bilingual corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although, each word can be classified into various pos-tags, in defined context, it can only be attributed with definite pos.
</prevsent>
<prevsent>as an example, in this sentence: can can can?, the pos-tagger must be able to perform the following: ipro canaux canv adet cann?.
</prevsent>
</prevsection>
<citsent citstr=" W95-0101 ">
in order to proceed with pos-tagging, such various methods as hidden markov models (hmm); memory based models (daelemans, 1996); transformation based learning (tbl) (brill, 1995); <papid> W95-0101 </papid>maximum entropy; decision trees (schmid, 1994<papid> C94-1027 </papid>a); neural network (schmid, 1994<papid> C94-1027 </papid>b); and so on can be used.</citsent>
<aftsection>
<nextsent>in which, the methods based on machine learning in general and tbl in particular prove effective with much popularity at present.
</nextsent>
<nextsent>to achieve good results, the abovementioned methods must be equipped with exactly annotated training corpora.
</nextsent>
<nextsent>such training corpora for popular languages (e.g. english, french, etc.) are available (e.g. penn tree bank, susanne, etc.).
</nextsent>
<nextsent>unfortunately, so far, there has been no such annotated training data available for vietnamese pos-taggers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1127">
<title id=" W03-0316.xml">pos tagger for english vietnamese bilingual corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although, each word can be classified into various pos-tags, in defined context, it can only be attributed with definite pos.
</prevsent>
<prevsent>as an example, in this sentence: can can can?, the pos-tagger must be able to perform the following: ipro canaux canv adet cann?.
</prevsent>
</prevsection>
<citsent citstr=" C94-1027 ">
in order to proceed with pos-tagging, such various methods as hidden markov models (hmm); memory based models (daelemans, 1996); transformation based learning (tbl) (brill, 1995); <papid> W95-0101 </papid>maximum entropy; decision trees (schmid, 1994<papid> C94-1027 </papid>a); neural network (schmid, 1994<papid> C94-1027 </papid>b); and so on can be used.</citsent>
<aftsection>
<nextsent>in which, the methods based on machine learning in general and tbl in particular prove effective with much popularity at present.
</nextsent>
<nextsent>to achieve good results, the abovementioned methods must be equipped with exactly annotated training corpora.
</nextsent>
<nextsent>such training corpora for popular languages (e.g. english, french, etc.) are available (e.g. penn tree bank, susanne, etc.).
</nextsent>
<nextsent>unfortunately, so far, there has been no such annotated training data available for vietnamese pos-taggers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1131">
<title id=" W03-0316.xml">pos tagger for english vietnamese bilingual corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to overcome this drawback, this paper will present solution to indirectly build such an annotated training corpus for vietnamese by taking advantages of available english-vietnamese bilingual corpus named evc (dinh dien, 2001b).
</prevsent>
<prevsent>this evc has been automatically word-aligned (dinh dien et al, 2002a).
</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
our approach in this work is to use boot strapped pos tagger for english to annotate the english side of word-aligned parallel corpus, then directly project the tag annotations to the second language (vietnamese) via existing word-alignments (yarowsky and ngai, 2001).<papid> N01-1026 </papid></citsent>
<aftsection>
<nextsent>in this work, we made use of the tbl method and susanne training corpus to train our english pos-tagger.
</nextsent>
<nextsent>the remains of this paper is as follows: ? pos-tagging by tbl method: introducing to original tbl, improved ftbl, traditional english pos-tagger by tbl.
</nextsent>
<nextsent>english-vietnamese bilingual corpus (evc): resources of evc, word-alignment of evc.
</nextsent>
<nextsent>bootstrapping english-pos-tagger: bootstrapping english pos-tagger by the pos-tag of corresponding vietnamese words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1134">
<title id=" W03-0316.xml">pos tagger for english vietnamese bilingual corpus </title>
<section> english ? vietnamese bilingual corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy of word-alignment of this parallel corpus has been reported approximately 87% in (dinh dien et al, 2002b).
</prevsent>
<prevsent>for full details of word alignment of this evc corpus (precision, recall, coverage, etc.), please refer to (dinh dien et al, 2002a).
</prevsent>
</prevsection>
<citsent citstr=" W02-1607 ">
the result of this word-aligned parallel corpus has been used in various vietnamese nlp tasks, such as in training the vietnamese word segmenter (dinh dien et al., 2001a), word sense disambiguation (dinh dien, 2002<papid> W02-1607 </papid>b), etc. remarkably, this evc includes the susanne corpus (sampson, 1995) ? golden corpus has been manually annotated such necessary english linguistic annotations as lemma, pos tags, chunking tags, syntactic trees, etc. this english corpus has been translated into vietnamese by english teachers of foreign language department of vietnam university of hcm city.</citsent>
<aftsection>
<nextsent>in this paper, we will make use of this valuable annotated corpus as the training corpus for our boot strapped english pos-tagger.
</nextsent>
<nextsent>no. resources the number of pairs of sentences number of english words number of vietnamese morpho-words length (english words) percent (words/ evc) 1.
</nextsent>
<nextsent>computer books 9,475 165,042 239,984 17.42 7.67.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1135">
<title id=" W03-0320.xml">aligning and using an englishinuktitut parallel corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present an aligned parallel corpus of inuktitut and english from the nunavut hansards.
</prevsent>
<prevsent>the alignment at the sentence level and the word correspondence follow techniques described in the literature with augmentations suggested by the specific properties of this language pair.the lack of lexical resources for inuktitut, the unrelated ness of the two languages, the fact that the languages use different script and the richness of the morphology in inuktitut have guided our choice of technique.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
sentence shave been aligned using the length-based dynamic programming approach of gale and church (1993) <papid> J93-1004 </papid>enhanced with small number of lexical and non-alphabetic an chors.</citsent>
<aftsection>
<nextsent>word correspondences have been identified with the goal of finding an extensive high quality candidate glossary for english and inuktitut words.
</nextsent>
<nextsent>crucially, the algorithm considers not only full word correspondences,as most approaches do, but also multiple substring correspondences resulting in far greater coverage.
</nextsent>
<nextsent>2.1 the parallel texts.
</nextsent>
<nextsent>the corpus of parallel texts we present consists of3,432,212 words of english and 1,586,423 words of inuk titut from the nunavut hansards.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1146">
<title id=" W03-0320.xml">aligning and using an englishinuktitut parallel corpus </title>
<section> word correspondence.  </section>
<citcontext>
<prevsection>
<prevsent>pmi measures the amount of information that each substring conveys about the occurrence of the other.
</prevsent>
<prevsent>we recognize that pmi is badly behaved when the counts are near 1.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
to protect against that problem, we compute the 99.99999% confidence intervals around the pmi (lin, 1999), <papid> P99-1041 </papid>and use the lower bound as measure of association.</citsent>
<aftsection>
<nextsent>this lower bound rises as the pmi rises or as the amount of data increases.
</nextsent>
<nextsent>many measures of association would likely work as well as the lower confidence bound on pmi.
</nextsent>
<nextsent>we used that bound as metric inthis study for three reasons.
</nextsent>
<nextsent>first, that metric led to better performance than chi-squared on this data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1147">
<title id=" W03-0320.xml">aligning and using an englishinuktitut parallel corpus </title>
<section> word correspondence.  </section>
<citcontext>
<prevsection>
<prevsent>first, that metric led to better performance than chi-squared on this data.
</prevsent>
<prevsent>second, it addressed the problem of low frequency events.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
third, itmakes the correct judgment on gale and churchs well known chambre-communes problem (gale and church, 1991).<papid> H91-1026 </papid>the decision to include pairs of sub strings in the glossary proceeds as follows.</citsent>
<aftsection>
<nextsent>include the highest pmi scoring pairs if neither member of the pair has yet been included.
</nextsent>
<nextsent>if two pairs are tied, check whether the inuktitut members of the pairs are in substring relation.
</nextsent>
<nextsent>if they are, then add the pair with the longer substring to the glossary; if not, then add neither pair.many previous efforts have used similar methodology but were only able to focus on word to word correspondences (gale and church, 1991).<papid> H91-1026 </papid></nextsent>
<nextsent>here, the english words can correspond to any substring in any inuktitut word in the aligned region.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1151">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 dealing with knowledge acquisition.
</prevsent>
<prevsent>the acquisition of linguistic knowledge from corpora has been very successful line of research.
</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
research in the acquisition of subcategorization information, selectional preferences, in thematic role assignments and dia thesis alternations (agirre and martnez 2001, <papid> W01-0703 </papid>2002, mccarthy and korhonen, 1998; <papid> P98-2247 </papid>korhonen et al, 2000; <papid> W00-1325 </papid>mccarthy 2001), domain information (magnini and cavagli?</citsent>
<aftsection>
<nextsent>2000), topic signatures (agirre et al 2001b), lexico-semantic relations between words (agirre et al 2002) <papid> W02-0801 </papid>etc. has obtained encouraging results.</nextsent>
<nextsent>the acquisition process usually involves large bodies of text, which have been previously processed with shallow language processors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1152">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 dealing with knowledge acquisition.
</prevsent>
<prevsent>the acquisition of linguistic knowledge from corpora has been very successful line of research.
</prevsent>
</prevsection>
<citsent citstr=" P98-2247 ">
research in the acquisition of subcategorization information, selectional preferences, in thematic role assignments and dia thesis alternations (agirre and martnez 2001, <papid> W01-0703 </papid>2002, mccarthy and korhonen, 1998; <papid> P98-2247 </papid>korhonen et al, 2000; <papid> W00-1325 </papid>mccarthy 2001), domain information (magnini and cavagli?</citsent>
<aftsection>
<nextsent>2000), topic signatures (agirre et al 2001b), lexico-semantic relations between words (agirre et al 2002) <papid> W02-0801 </papid>etc. has obtained encouraging results.</nextsent>
<nextsent>the acquisition process usually involves large bodies of text, which have been previously processed with shallow language processors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1153">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 dealing with knowledge acquisition.
</prevsent>
<prevsent>the acquisition of linguistic knowledge from corpora has been very successful line of research.
</prevsent>
</prevsection>
<citsent citstr=" W00-1325 ">
research in the acquisition of subcategorization information, selectional preferences, in thematic role assignments and dia thesis alternations (agirre and martnez 2001, <papid> W01-0703 </papid>2002, mccarthy and korhonen, 1998; <papid> P98-2247 </papid>korhonen et al, 2000; <papid> W00-1325 </papid>mccarthy 2001), domain information (magnini and cavagli?</citsent>
<aftsection>
<nextsent>2000), topic signatures (agirre et al 2001b), lexico-semantic relations between words (agirre et al 2002) <papid> W02-0801 </papid>etc. has obtained encouraging results.</nextsent>
<nextsent>the acquisition process usually involves large bodies of text, which have been previously processed with shallow language processors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1154">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the acquisition of linguistic knowledge from corpora has been very successful line of research.
</prevsent>
<prevsent>research in the acquisition of subcategorization information, selectional preferences, in thematic role assignments and dia thesis alternations (agirre and martnez 2001, <papid> W01-0703 </papid>2002, mccarthy and korhonen, 1998; <papid> P98-2247 </papid>korhonen et al, 2000; <papid> W00-1325 </papid>mccarthy 2001), domain information (magnini and cavagli?</prevsent>
</prevsection>
<citsent citstr=" W02-0801 ">
2000), topic signatures (agirre et al 2001b), lexico-semantic relations between words (agirre et al 2002) <papid> W02-0801 </papid>etc. has obtained encouraging results.</citsent>
<aftsection>
<nextsent>the acquisition process usually involves large bodies of text, which have been previously processed with shallow language processors.
</nextsent>
<nextsent>much of the use of the acquired knowledge has been hampered by the fact that the texts are not sense-disambiguated, and therefore, only knowledge for words can be acquired, that is, subcategorization for words, selectional preferences for words, etc. it is well established fact that much of the linguistic behavior of words can be better explained if it is keyed to word senses.
</nextsent>
<nextsent>for instance, the subcategorization frames of verbs are highly dependent of the sense of the verb.
</nextsent>
<nextsent>some senses of given verb allow for particular combination of complements, while others do not (mccarthy, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1155">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 2.3) 2.2 dealing with wsd.
</prevsent>
<prevsent>word sense disambiguation (wsd) is the task of assigning the appropriate meaning (sense) to given word in text or discourse.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
ide and veronis (1998) <papid> J98-1001 </papid>argue that word sense ambiguity is central problem for many established hlt applications (for example machine translation, information extraction and information retrieval).</citsent>
<aftsection>
<nextsent>this is also the case for associated sub-tasks (i.e. reference resolution and parsing).
</nextsent>
<nextsent>for this reason many international research groups are working on wsd, using wide range of approaches.
</nextsent>
<nextsent>however, no large-scale broad coverage accurate wsd system has been built up to date2.
</nextsent>
<nextsent>with current state-of-the-art accuracy in the range 60-70%, wsd is one of the most important open problems in natural language processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1156">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a promising current line of research uses semantically annotated corpora to train machine learning (ml) algorithms to decide which word sense to choose in which contexts.
</prevsent>
<prevsent>the words in these annotated corpora are tagged manually with semantic classes taken from particular lexical semantic resource (most commonly wordnet).
</prevsent>
</prevsection>
<citsent citstr=" W00-1322 ">
many standard ml techniques have been tried, such as bayesian learning, exemplar based learning, decision lists, and recently margin-based classifiers like boosting and support vector machines (escudero et al, 2000<papid> W00-1322 </papid>a, 2000b, 2000c, 2000d, 2001; martnez and agirre, 2000).</citsent>
<aftsection>
<nextsent>these approaches are termed  supervised  because they learn from previously sense annotated data and therefore they require large amount of human intervention to annotate the training data.
</nextsent>
<nextsent>supervised wsd systems are data hungry.
</nextsent>
<nextsent>they suffer from the  knowledge acquisition bottleneck , it takes them mere seconds to digest all of the processed corpus contained in training materials that take months to annotate manually.
</nextsent>
<nextsent>so, although machine learning classifiers are undeniably effective, they are not feasible until we can obtain reliable unsupervised training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1158">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they suffer from the  knowledge acquisition bottleneck , it takes them mere seconds to digest all of the processed corpus contained in training materials that take months to annotate manually.
</prevsent>
<prevsent>so, although machine learning classifiers are undeniably effective, they are not feasible until we can obtain reliable unsupervised training data.
</prevsent>
</prevsection>
<citsent citstr=" W97-0201 ">
ng (1997) <papid> W97-0201 </papid>estimates that the manual annotation effort necessary to build broad coverage word-sense annotated english corpus is about 16 person-years; and this effort would have to be replicated for each different language.</citsent>
<aftsection>
<nextsent>unfortunately, many people think that ngs estimate might fell short, as the annotated corpus thus produced is not guaranteed to enable high accuracy wsd.
</nextsent>
<nextsent>some recent work is focusing on reducing the acquisition cost and the need for supervision
</nextsent>
<nextsent>competition: http://www.sle.sharp.co.uk/senseval2/ in corpus-based methods for wsd.
</nextsent>
<nextsent>leacock et al.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1159">
<title id=" W02-1304.xml">meaning a roadmap to knowledge technologies </title>
<section> see the conclusions of the senseval-2.  </section>
<citcontext>
<prevsection>
<prevsent>leacock et al.
</prevsent>
<prevsent>(1998) and mihalcea and moldovan (1999) automatically generate arbitrarily large corpora for unsupervised wsd training, using the synonyms or definitions of word senses provided in wordnet to formulate search engine queries over the web.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in another line of research, (yarowsky, 1995) <papid> P95-1026 </papid>and (blum and mitchell, 1998) have shown that it is possible to reduce the need for supervision with the help of large amounts of unannotated data.</citsent>
<aftsection>
<nextsent>applying these ideas, (agirre and martnez, 2000) has developed knowledge-based prototypes for obtaining accurate examples from the web for specific wordnet synsets, as well as, large quantities of unannotated examples.
</nextsent>
<nextsent>but in order to make significant advances in wsd system accuracy, systems need to be able to use types of lexical knowledge that are not currently available in wide-coverage lexical knowledge bases: for example subcategorisation frequencies for predicates (particularly verbs) relyon word senses, selectional preferences of predicates for classes of arguments, amongst others (carroll and mccarthy, 2000; mccarthy et al, 2001; agirre and martnez, 2002;).
</nextsent>
<nextsent>2.3 dealing with multilingualism.
</nextsent>
<nextsent>language diversity is at the same time valuable cultural heritage worth preserving, and an obstacle to achieving more cohesive social and economic development.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1160">
<title id=" W02-1803.xml">developing guidelines for the annotation of anaphors in the chinese treebank </title>
<section> what we are annotating.  </section>
<citcontext>
<prevsection>
<prevsent>the co indexation (#2) will be discussed in section 4 and the annotation #ext on the second *pro* will be discussed below in section 5.1.3.
</prevsent>
<prevsent>2.1 which anaphoric expressions.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
consistent with work in english (e.g., (da gan and itai, 1991; ge et al, 1998; <papid> W98-1119 </papid>lappinand leass, 1994; <papid> J94-4002 </papid>morton, 2000)), <papid> P00-1023 </papid>only third person pronouns and demonstratives were chosen to be annotated.</citsent>
<aftsection>
<nextsent>the pronouns include re exives (e.g., /\oneself ), reciprocals (e.g., /\one another ), and possessives.
</nextsent>
<nextsent>for the possess ives, the only distinct possessive forms are and (both \its/his/hers/theirs ), which are annotated.
</nextsent>
<nextsent>ordinary third-person pronouns in possessive constructions are annotated just as they would be in other contexts.unlike english, however, chinese is pro drop language, and there are zero pronouns in addition to the overtones.
</nextsent>
<nextsent>for pro drop, the bracketing guidelines for the ctb (xue and xia, 2000) specify use of the string \*pro*  (small pro) to explicitly denote zero pronoun in dropped subject or dropped object position in parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1161">
<title id=" W02-1803.xml">developing guidelines for the annotation of anaphors in the chinese treebank </title>
<section> what we are annotating.  </section>
<citcontext>
<prevsection>
<prevsent>the co indexation (#2) will be discussed in section 4 and the annotation #ext on the second *pro* will be discussed below in section 5.1.3.
</prevsent>
<prevsent>2.1 which anaphoric expressions.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
consistent with work in english (e.g., (da gan and itai, 1991; ge et al, 1998; <papid> W98-1119 </papid>lappinand leass, 1994; <papid> J94-4002 </papid>morton, 2000)), <papid> P00-1023 </papid>only third person pronouns and demonstratives were chosen to be annotated.</citsent>
<aftsection>
<nextsent>the pronouns include re exives (e.g., /\oneself ), reciprocals (e.g., /\one another ), and possessives.
</nextsent>
<nextsent>for the possess ives, the only distinct possessive forms are and (both \its/his/hers/theirs ), which are annotated.
</nextsent>
<nextsent>ordinary third-person pronouns in possessive constructions are annotated just as they would be in other contexts.unlike english, however, chinese is pro drop language, and there are zero pronouns in addition to the overtones.
</nextsent>
<nextsent>for pro drop, the bracketing guidelines for the ctb (xue and xia, 2000) specify use of the string \*pro*  (small pro) to explicitly denote zero pronoun in dropped subject or dropped object position in parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1162">
<title id=" W02-1803.xml">developing guidelines for the annotation of anaphors in the chinese treebank </title>
<section> what we are annotating.  </section>
<citcontext>
<prevsection>
<prevsent>the co indexation (#2) will be discussed in section 4 and the annotation #ext on the second *pro* will be discussed below in section 5.1.3.
</prevsent>
<prevsent>2.1 which anaphoric expressions.
</prevsent>
</prevsection>
<citsent citstr=" P00-1023 ">
consistent with work in english (e.g., (da gan and itai, 1991; ge et al, 1998; <papid> W98-1119 </papid>lappinand leass, 1994; <papid> J94-4002 </papid>morton, 2000)), <papid> P00-1023 </papid>only third person pronouns and demonstratives were chosen to be annotated.</citsent>
<aftsection>
<nextsent>the pronouns include re exives (e.g., /\oneself ), reciprocals (e.g., /\one another ), and possessives.
</nextsent>
<nextsent>for the possess ives, the only distinct possessive forms are and (both \its/his/hers/theirs ), which are annotated.
</nextsent>
<nextsent>ordinary third-person pronouns in possessive constructions are annotated just as they would be in other contexts.unlike english, however, chinese is pro drop language, and there are zero pronouns in addition to the overtones.
</nextsent>
<nextsent>for pro drop, the bracketing guidelines for the ctb (xue and xia, 2000) specify use of the string \*pro*  (small pro) to explicitly denote zero pronoun in dropped subject or dropped object position in parse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1163">
<title id=" W03-1209.xml">statistical qa  classifier vs reranker whats the difference </title>
<section> statistical answer pinpointing.  </section>
<citcontext>
<prevsection>
<prevsent>1.
</prevsent>
<prevsent>frequency: it has been observed that the.
</prevsent>
</prevsection>
<citsent citstr=" P02-1054 ">
correct answer has higher frequency (magnini et al; 2002) <papid> P02-1054 </papid>in the collection of answer chunks (c).</citsent>
<aftsection>
<nextsent>hence we count the number of time potential answer occurs in their output and use its logarithm as feature.
</nextsent>
<nextsent>this is positive continuous valued feature.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>expected answer class: most of the current.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1164">
<title id=" W02-1016.xml">spectral clustering for german verbs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>donnern 0.76 0.86 0.68 unterstutzen 0.71 0.79 0.68 beenden 0.68 0.80 0.65 table 4: empirical support, confidence and alignment for skew-divergenceset of position, but this is dominated by skew divergences correct identification of the whole class (see table 2 for reminder of the definitions of these classes).
</prevsent>
<prevsent>the systematic superiority of the probabilistic measure suggests that there is after all useful information about verb classes in the non-categorical part of our verb frame data.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
levins (levin, 1993) classification has provoked several studies that aim to acquire lexical semantic information from corpora using cues pertaining to mainly syntactic structure score method cluster 1.0 both freuen argern 1.0 skew liegen sitzen stehen 0.96 skew dienen folgen helfen 0.96 skew beschreiben charakterisieren interpretieren 0.96 skew behar ren insistieren, pochen 0.96 bcos liegen stehen 0.93 skew liefern vermitteln zustellen 0.93 both dammern nieseln regnen schneien 0.93 skew ahnen vermuten wissen table 5: cluster quality by origin (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000; lapata, 1999; <papid> P99-1051 </papid>mccarthy, 2000; <papid> A00-2034 </papid>lapata and brew, 1999).<papid> W99-0632 </papid></citsent>
<aftsection>
<nextsent>other work has used levins list of verbs (in conjunction with related lexical resources) for the creation of dictionaries that exploit the systematic correspondence between syntax and meaning (dorr, 1997; dang et al, 1997; dorr and jones, 1996).<papid> C96-1055 </papid></nextsent>
<nextsent>most statistical approaches, including ours, treat verbal meaning assignment as semantic clustering or classification task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1165">
<title id=" W02-1016.xml">spectral clustering for german verbs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>donnern 0.76 0.86 0.68 unterstutzen 0.71 0.79 0.68 beenden 0.68 0.80 0.65 table 4: empirical support, confidence and alignment for skew-divergenceset of position, but this is dominated by skew divergences correct identification of the whole class (see table 2 for reminder of the definitions of these classes).
</prevsent>
<prevsent>the systematic superiority of the probabilistic measure suggests that there is after all useful information about verb classes in the non-categorical part of our verb frame data.
</prevsent>
</prevsection>
<citsent citstr=" P99-1051 ">
levins (levin, 1993) classification has provoked several studies that aim to acquire lexical semantic information from corpora using cues pertaining to mainly syntactic structure score method cluster 1.0 both freuen argern 1.0 skew liegen sitzen stehen 0.96 skew dienen folgen helfen 0.96 skew beschreiben charakterisieren interpretieren 0.96 skew behar ren insistieren, pochen 0.96 bcos liegen stehen 0.93 skew liefern vermitteln zustellen 0.93 both dammern nieseln regnen schneien 0.93 skew ahnen vermuten wissen table 5: cluster quality by origin (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000; lapata, 1999; <papid> P99-1051 </papid>mccarthy, 2000; <papid> A00-2034 </papid>lapata and brew, 1999).<papid> W99-0632 </papid></citsent>
<aftsection>
<nextsent>other work has used levins list of verbs (in conjunction with related lexical resources) for the creation of dictionaries that exploit the systematic correspondence between syntax and meaning (dorr, 1997; dang et al, 1997; dorr and jones, 1996).<papid> C96-1055 </papid></nextsent>
<nextsent>most statistical approaches, including ours, treat verbal meaning assignment as semantic clustering or classification task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1166">
<title id=" W02-1016.xml">spectral clustering for german verbs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>donnern 0.76 0.86 0.68 unterstutzen 0.71 0.79 0.68 beenden 0.68 0.80 0.65 table 4: empirical support, confidence and alignment for skew-divergenceset of position, but this is dominated by skew divergences correct identification of the whole class (see table 2 for reminder of the definitions of these classes).
</prevsent>
<prevsent>the systematic superiority of the probabilistic measure suggests that there is after all useful information about verb classes in the non-categorical part of our verb frame data.
</prevsent>
</prevsection>
<citsent citstr=" A00-2034 ">
levins (levin, 1993) classification has provoked several studies that aim to acquire lexical semantic information from corpora using cues pertaining to mainly syntactic structure score method cluster 1.0 both freuen argern 1.0 skew liegen sitzen stehen 0.96 skew dienen folgen helfen 0.96 skew beschreiben charakterisieren interpretieren 0.96 skew behar ren insistieren, pochen 0.96 bcos liegen stehen 0.93 skew liefern vermitteln zustellen 0.93 both dammern nieseln regnen schneien 0.93 skew ahnen vermuten wissen table 5: cluster quality by origin (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000; lapata, 1999; <papid> P99-1051 </papid>mccarthy, 2000; <papid> A00-2034 </papid>lapata and brew, 1999).<papid> W99-0632 </papid></citsent>
<aftsection>
<nextsent>other work has used levins list of verbs (in conjunction with related lexical resources) for the creation of dictionaries that exploit the systematic correspondence between syntax and meaning (dorr, 1997; dang et al, 1997; dorr and jones, 1996).<papid> C96-1055 </papid></nextsent>
<nextsent>most statistical approaches, including ours, treat verbal meaning assignment as semantic clustering or classification task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1167">
<title id=" W02-1016.xml">spectral clustering for german verbs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>donnern 0.76 0.86 0.68 unterstutzen 0.71 0.79 0.68 beenden 0.68 0.80 0.65 table 4: empirical support, confidence and alignment for skew-divergenceset of position, but this is dominated by skew divergences correct identification of the whole class (see table 2 for reminder of the definitions of these classes).
</prevsent>
<prevsent>the systematic superiority of the probabilistic measure suggests that there is after all useful information about verb classes in the non-categorical part of our verb frame data.
</prevsent>
</prevsection>
<citsent citstr=" W99-0632 ">
levins (levin, 1993) classification has provoked several studies that aim to acquire lexical semantic information from corpora using cues pertaining to mainly syntactic structure score method cluster 1.0 both freuen argern 1.0 skew liegen sitzen stehen 0.96 skew dienen folgen helfen 0.96 skew beschreiben charakterisieren interpretieren 0.96 skew behar ren insistieren, pochen 0.96 bcos liegen stehen 0.93 skew liefern vermitteln zustellen 0.93 both dammern nieseln regnen schneien 0.93 skew ahnen vermuten wissen table 5: cluster quality by origin (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000; lapata, 1999; <papid> P99-1051 </papid>mccarthy, 2000; <papid> A00-2034 </papid>lapata and brew, 1999).<papid> W99-0632 </papid></citsent>
<aftsection>
<nextsent>other work has used levins list of verbs (in conjunction with related lexical resources) for the creation of dictionaries that exploit the systematic correspondence between syntax and meaning (dorr, 1997; dang et al, 1997; dorr and jones, 1996).<papid> C96-1055 </papid></nextsent>
<nextsent>most statistical approaches, including ours, treat verbal meaning assignment as semantic clustering or classification task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1168">
<title id=" W02-1016.xml">spectral clustering for german verbs </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the systematic superiority of the probabilistic measure suggests that there is after all useful information about verb classes in the non-categorical part of our verb frame data.
</prevsent>
<prevsent>levins (levin, 1993) classification has provoked several studies that aim to acquire lexical semantic information from corpora using cues pertaining to mainly syntactic structure score method cluster 1.0 both freuen argern 1.0 skew liegen sitzen stehen 0.96 skew dienen folgen helfen 0.96 skew beschreiben charakterisieren interpretieren 0.96 skew behar ren insistieren, pochen 0.96 bcos liegen stehen 0.93 skew liefern vermitteln zustellen 0.93 both dammern nieseln regnen schneien 0.93 skew ahnen vermuten wissen table 5: cluster quality by origin (merlo and stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000; lapata, 1999; <papid> P99-1051 </papid>mccarthy, 2000; <papid> A00-2034 </papid>lapata and brew, 1999).<papid> W99-0632 </papid></prevsent>
</prevsection>
<citsent citstr=" C96-1055 ">
other work has used levins list of verbs (in conjunction with related lexical resources) for the creation of dictionaries that exploit the systematic correspondence between syntax and meaning (dorr, 1997; dang et al, 1997; dorr and jones, 1996).<papid> C96-1055 </papid></citsent>
<aftsection>
<nextsent>most statistical approaches, including ours, treat verbal meaning assignment as semantic clustering or classification task.
</nextsent>
<nextsent>the underlying question is the following: how can corpus information be exploited in deriving the semantic class forgiven verb?
</nextsent>
<nextsent>despite the unifying theme of using corpora and corpus distributions for the acquisition task, the approaches differ in the inventory of classes they employ, in the methodology used for inferring semantic classes and the specific assumptions concerning the verbs to be classified (i.e., can they be pol ysemous or not).(merlo and stevenson, 2001) <papid> J01-3003 </papid>use grammatical features (acquired from corpora) to classify verbs into three semantic classes: unergative, unaccusative, and object-drop.</nextsent>
<nextsent>these classes are abstractions of levins (levin, 1993) classes and as result yield coarser classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1170">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> building translation memory.  </section>
<citcontext>
<prevsection>
<prevsent>adjoining nouns are grouped into one phrase..
</prevsent>
<prevsent>verb.
</prevsent>
</prevsection>
<citsent citstr=" J94-4001 ">
the japanese parser outputs the phrasal dependency structure of an input, and that is used as is. we used the japanese parser knp (kurohashi and nagao, 1994) <papid> J94-4001 </papid>and the english nl-parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>step 1: estimation of basic phrasal correspondences.
</nextsent>
<nextsent>we started with the word-level alignment to get the basic phrasal alignment.
</nextsent>
<nextsent>we used translation dictionaries for this process.
</nextsent>
<nextsent>the word sense ambiguity in the dictionaries is resolved with heuristics thatthe most plausible correspondence is near other correspondences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1171">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> building translation memory.  </section>
<citcontext>
<prevsection>
<prevsent>adjoining nouns are grouped into one phrase..
</prevsent>
<prevsent>verb.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the japanese parser outputs the phrasal dependency structure of an input, and that is used as is. we used the japanese parser knp (kurohashi and nagao, 1994) <papid> J94-4001 </papid>and the english nl-parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>step 1: estimation of basic phrasal correspondences.
</nextsent>
<nextsent>we started with the word-level alignment to get the basic phrasal alignment.
</nextsent>
<nextsent>we used translation dictionaries for this process.
</nextsent>
<nextsent>the word sense ambiguity in the dictionaries is resolved with heuristics thatthe most plausible correspondence is near other correspondences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1172">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when there are no plausible translation examples in the translation memory, the system selects low-similarity or low-confidence fte.
</prevsent>
<prevsent>however we believe this problem will be resolved as the number of translation examples increases, since the news corpus is increasing day by day.
</prevsent>
</prevsection>
<citsent citstr=" C90-3044 ">
the idea of example based machine translation systems was first proposed by (nagao, 1984), and preliminary systems that appeared about ten years (sato and na gao, 1990; <papid> C90-3044 </papid>sadler and vendelmans, 1990; <papid> C90-3101 </papid>maruyama and watanabe, 1992; furuse and iida, 1994) <papid> C94-1015 </papid>showed the basic feasibility of the idea.</citsent>
<aftsection>
<nextsent>recent studies have focused on the practical aspects of ebmt, and this technology has even been applied to some restricted domains.
</nextsent>
<nextsent>the work in (richardson et al, 2001; <papid> W01-1402 </papid>menezes and richardson, 2001) <papid> W01-1406 </papid>addressed the problem of technical manual translation in several languages, and the work of (imamura, 2002) dealt with dialogues translation in the travel arrangement domain.</nextsent>
<nextsent>these works select the translation example pairs based solely on the source language similarity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1173">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when there are no plausible translation examples in the translation memory, the system selects low-similarity or low-confidence fte.
</prevsent>
<prevsent>however we believe this problem will be resolved as the number of translation examples increases, since the news corpus is increasing day by day.
</prevsent>
</prevsection>
<citsent citstr=" C90-3101 ">
the idea of example based machine translation systems was first proposed by (nagao, 1984), and preliminary systems that appeared about ten years (sato and na gao, 1990; <papid> C90-3044 </papid>sadler and vendelmans, 1990; <papid> C90-3101 </papid>maruyama and watanabe, 1992; furuse and iida, 1994) <papid> C94-1015 </papid>showed the basic feasibility of the idea.</citsent>
<aftsection>
<nextsent>recent studies have focused on the practical aspects of ebmt, and this technology has even been applied to some restricted domains.
</nextsent>
<nextsent>the work in (richardson et al, 2001; <papid> W01-1402 </papid>menezes and richardson, 2001) <papid> W01-1406 </papid>addressed the problem of technical manual translation in several languages, and the work of (imamura, 2002) dealt with dialogues translation in the travel arrangement domain.</nextsent>
<nextsent>these works select the translation example pairs based solely on the source language similarity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1174">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when there are no plausible translation examples in the translation memory, the system selects low-similarity or low-confidence fte.
</prevsent>
<prevsent>however we believe this problem will be resolved as the number of translation examples increases, since the news corpus is increasing day by day.
</prevsent>
</prevsection>
<citsent citstr=" C94-1015 ">
the idea of example based machine translation systems was first proposed by (nagao, 1984), and preliminary systems that appeared about ten years (sato and na gao, 1990; <papid> C90-3044 </papid>sadler and vendelmans, 1990; <papid> C90-3101 </papid>maruyama and watanabe, 1992; furuse and iida, 1994) <papid> C94-1015 </papid>showed the basic feasibility of the idea.</citsent>
<aftsection>
<nextsent>recent studies have focused on the practical aspects of ebmt, and this technology has even been applied to some restricted domains.
</nextsent>
<nextsent>the work in (richardson et al, 2001; <papid> W01-1402 </papid>menezes and richardson, 2001) <papid> W01-1406 </papid>addressed the problem of technical manual translation in several languages, and the work of (imamura, 2002) dealt with dialogues translation in the travel arrangement domain.</nextsent>
<nextsent>these works select the translation example pairs based solely on the source language similarity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1175">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of example based machine translation systems was first proposed by (nagao, 1984), and preliminary systems that appeared about ten years (sato and na gao, 1990; <papid> C90-3044 </papid>sadler and vendelmans, 1990; <papid> C90-3101 </papid>maruyama and watanabe, 1992; furuse and iida, 1994) <papid> C94-1015 </papid>showed the basic feasibility of the idea.</prevsent>
<prevsent>recent studies have focused on the practical aspects of ebmt, and this technology has even been applied to some restricted domains.</prevsent>
</prevsection>
<citsent citstr=" W01-1402 ">
the work in (richardson et al, 2001; <papid> W01-1402 </papid>menezes and richardson, 2001) <papid> W01-1406 </papid>addressed the problem of technical manual translation in several languages, and the work of (imamura, 2002) dealt with dialogues translation in the travel arrangement domain.</citsent>
<aftsection>
<nextsent>these works select the translation example pairs based solely on the source language similarity.
</nextsent>
<nextsent>we believe thisis partly due to the high parallelism found in their cor pora.our work targets more general corpus of wider coverage, i.e., the broadcast news collection.
</nextsent>
<nextsent>generally available corpora like the one we use tend to be more freely translated and suffer from lower parallelism.
</nextsent>
<nextsent>this compelled us to use the criterion of translation confidence, together with the criterion of monolingual similarity used in the previous works.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1176">
<title id=" W03-0312.xml">word selection for ebmt based on monolingual similarity and translation confidence </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of example based machine translation systems was first proposed by (nagao, 1984), and preliminary systems that appeared about ten years (sato and na gao, 1990; <papid> C90-3044 </papid>sadler and vendelmans, 1990; <papid> C90-3101 </papid>maruyama and watanabe, 1992; furuse and iida, 1994) <papid> C94-1015 </papid>showed the basic feasibility of the idea.</prevsent>
<prevsent>recent studies have focused on the practical aspects of ebmt, and this technology has even been applied to some restricted domains.</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
the work in (richardson et al, 2001; <papid> W01-1402 </papid>menezes and richardson, 2001) <papid> W01-1406 </papid>addressed the problem of technical manual translation in several languages, and the work of (imamura, 2002) dealt with dialogues translation in the travel arrangement domain.</citsent>
<aftsection>
<nextsent>these works select the translation example pairs based solely on the source language similarity.
</nextsent>
<nextsent>we believe thisis partly due to the high parallelism found in their cor pora.our work targets more general corpus of wider coverage, i.e., the broadcast news collection.
</nextsent>
<nextsent>generally available corpora like the one we use tend to be more freely translated and suffer from lower parallelism.
</nextsent>
<nextsent>this compelled us to use the criterion of translation confidence, together with the criterion of monolingual similarity used in the previous works.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1177">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the hmm classifier is similar to the one described in (bikel et al, 1999).
</prevsent>
<prevsent>in the second part of this paper, we investigate the combination of set of diverse ne recognition classifiers.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
four statistical classifiers are combined in the experiments, including the above-mentionedhidden markov model classifier, transformation based learning classifier (brill, 1995; <papid> J95-4004 </papid>florian andngai, 2001), maximum entropy classifier (ratnaparkhi, 1999), and robust risk minimization classifier (zhang et al, 2002).the remainder of this paper is organized as follows: section 2 describes the experiment data, section 3 discusses specific issues related to chinesene recognition, section 4 presents the four classifiers and approaches to combining these classifiers.</citsent>
<aftsection>
<nextsent>we used three annotated chinese corpora in our experiments.
</nextsent>
<nextsent>the ibm-fbis corpus the foreign broadcast information service (fbis) offers an extensive collection of translations and transcriptions of open source information monitored worldwide on diverse topics such as military affairs, politics, economics, and science and technology.
</nextsent>
<nextsent>the ibm-fbis corpus consists of approximately 3,000 chinese articles obtained from fbis (about 3.2 million chinese characters in total).
</nextsent>
<nextsent>this corpus was tagged by native chinese speaker with 32 ne categories, such as person, location, organi-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1178">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> classifier combination.  </section>
<citcontext>
<prevsection>
<prevsent>besides the hmm classifier mentioned in the previous section, the following three classifiers were used in the experiments.
</prevsent>
<prevsent>4.1.1 the transformation-based learning (fntbl) classifier transformation-based learning is an error-driven algorithm which has two major steps: it starts by assigning some classification to each example, andthen automatically proposing, evaluating and selecting the classification changes that maximally decrease the number of errors.
</prevsent>
</prevsection>
<citsent citstr=" W97-0306 ">
tbl has some attractive qualities that make it suitable for the language-related tasks: it can automatically integrate heterogeneous types of knowledge, without the need for explicit modeling (similar to snow (dagan et al, 1997), <papid> W97-0306 </papid>maximum entropy, decision trees, etc); it is error driven, thus directly minimizes the ultimate evaluation measure: the error rate.</citsent>
<aftsection>
<nextsent>the tbl toolkit used in this experiment is described in (florian and ngai, 2001).
</nextsent>
<nextsent>4.1.2 the maximum entropy classifier (maxent)the model used here is based on the maximum entropy model used for shallow parsing (rat naparkhi, 1999).
</nextsent>
<nextsent>a sentence with ne tags is converted into shallow tree: tokens not in any ne are assigned an o? tag, while tokens within an ne are represented as constituents whose label is the same as the ne type.
</nextsent>
<nextsent>for example, the annotated sentence will fly to (lo cation new york) (dateref tomorrow)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1179">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 shows that, at least for the examined types of combination, using robust feature-based classifier to compute the classification distribution yields better performance than combining the classifications through either voting or weighted interpolation.
</prevsent>
<prevsent>the rrm-based classifier is able to incorporate heterogenous information from multiple sources, obtaining 2.8 absolute f-measure improvement versus the best performing classifier and 1.0 f-measure gain over the next best method.
</prevsent>
</prevsection>
<citsent citstr=" C02-1012 ">
sun et al (2002) <papid> C02-1012 </papid>proposes to use class-based model for chinese ne recognition.</citsent>
<aftsection>
<nextsent>specifically, it uses character-based trigram model for the class person, word-based model for the class location,and more complicated model for the class organization.
</nextsent>
<nextsent>this decision is consistent with our observation that the character-based model performs better than the word-based model for classes such as person, but is worse for classes such as organization.
</nextsent>
<nextsent>sekine and eriguchi (2000) <papid> C00-2167 </papid>provides an overview of japanese ne recognition.</nextsent>
<nextsent>it presents the results of 15 systems that participated in an evaluation project for information retrieval and information extraction (irex, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1180">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>specifically, it uses character-based trigram model for the class person, word-based model for the class location,and more complicated model for the class organization.
</prevsent>
<prevsent>this decision is consistent with our observation that the character-based model performs better than the word-based model for classes such as person, but is worse for classes such as organization.
</prevsent>
</prevsection>
<citsent citstr=" C00-2167 ">
sekine and eriguchi (2000) <papid> C00-2167 </papid>provides an overview of japanese ne recognition.</citsent>
<aftsection>
<nextsent>it presents the results of 15 systems that participated in an evaluation project for information retrieval and information extraction (irex, 1999).
</nextsent>
<nextsent>utsuro et al (2002) <papid> W02-1036 </papid>studies combining outputs of multiple japanese ne systems by stacking.</nextsent>
<nextsent>a second stage classifier ? in this case, decision list ? is trained to combine the outputs from first stage classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1181">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>sekine and eriguchi (2000) <papid> C00-2167 </papid>provides an overview of japanese ne recognition.</prevsent>
<prevsent>it presents the results of 15 systems that participated in an evaluation project for information retrieval and information extraction (irex, 1999).</prevsent>
</prevsection>
<citsent citstr=" W02-1036 ">
utsuro et al (2002) <papid> W02-1036 </papid>studies combining outputs of multiple japanese ne systems by stacking.</citsent>
<aftsection>
<nextsent>a second stage classifier ? in this case, decision list ? is trained to combine the outputs from first stage classifiers.
</nextsent>
<nextsent>this is similar 3measured as ???
</nextsent>
<nextsent>h|???
</nextsent>
<nextsent>in spirit to our application of the rrm classifier for combining classifier outputs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1182">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>h|???
</prevsent>
<prevsent>in spirit to our application of the rrm classifier for combining classifier outputs.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
classifier combination has been shownto be effective in improving the performance of nlp applications, and have been investigated by brill and wu (1998) <papid> P98-1029 </papid>andvan halteren et al (2001) for part-of-speech tagging, tjong kim sang et al (2000) for base noun phrase chunking, and florian et al (2003<papid> W03-0425 </papid>a) for word sense disambiguation.</citsent>
<aftsection>
<nextsent>among the investigated techniques were voting, probability interpolation, and classifier stacking.
</nextsent>
<nextsent>we also applied the classifier combination technique discussed in this paper to english and german (florian et al, 2003<papid> W03-0425 </papid>b).</nextsent>
<nextsent>in this paper, we discuss two topics related to chinese ne recognition: dealing with language-specific issues such as word segmentation, and combining multiple classifiers to enhance the system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1183">
<title id=" W03-1026.xml">how to get a chinese name entity segmentation and combination issues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>h|???
</prevsent>
<prevsent>in spirit to our application of the rrm classifier for combining classifier outputs.
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
classifier combination has been shownto be effective in improving the performance of nlp applications, and have been investigated by brill and wu (1998) <papid> P98-1029 </papid>andvan halteren et al (2001) for part-of-speech tagging, tjong kim sang et al (2000) for base noun phrase chunking, and florian et al (2003<papid> W03-0425 </papid>a) for word sense disambiguation.</citsent>
<aftsection>
<nextsent>among the investigated techniques were voting, probability interpolation, and classifier stacking.
</nextsent>
<nextsent>we also applied the classifier combination technique discussed in this paper to english and german (florian et al, 2003<papid> W03-0425 </papid>b).</nextsent>
<nextsent>in this paper, we discuss two topics related to chinese ne recognition: dealing with language-specific issues such as word segmentation, and combining multiple classifiers to enhance the system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1185">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition1 (ner) can be treated as atagging problem where each word in sentence is assigned label indicating whether it is part of named entity and the entity type.
</prevsent>
<prevsent>thus methods used for part of speech (pos) tagging and chunking can also be used for ner.
</prevsent>
</prevsection>
<citsent citstr=" W02-2019 ">
the papers from the conll-2002 shared task which used such methods (e.g. malouf (2002), <papid> W02-2019 </papid>burger et al (2002)) <papid> W02-2003 </papid>reported results significantly lower than the best system (carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>however, zhou and su (2002) <papid> P02-1060 </papid>have reported state of the art results on the muc-6 and muc-7 data using hmm-based tagger.</nextsent>
<nextsent>zhou and su (2002) <papid> P02-1060 </papid>used wide variety of features, which suggests that the relatively poor performance of the taggers used in conll-2002 was largely due to the feature sets used rather than the machine learning method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1186">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition1 (ner) can be treated as atagging problem where each word in sentence is assigned label indicating whether it is part of named entity and the entity type.
</prevsent>
<prevsent>thus methods used for part of speech (pos) tagging and chunking can also be used for ner.
</prevsent>
</prevsection>
<citsent citstr=" W02-2003 ">
the papers from the conll-2002 shared task which used such methods (e.g. malouf (2002), <papid> W02-2019 </papid>burger et al (2002)) <papid> W02-2003 </papid>reported results significantly lower than the best system (carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>however, zhou and su (2002) <papid> P02-1060 </papid>have reported state of the art results on the muc-6 and muc-7 data using hmm-based tagger.</nextsent>
<nextsent>zhou and su (2002) <papid> P02-1060 </papid>used wide variety of features, which suggests that the relatively poor performance of the taggers used in conll-2002 was largely due to the feature sets used rather than the machine learning method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1187">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition1 (ner) can be treated as atagging problem where each word in sentence is assigned label indicating whether it is part of named entity and the entity type.
</prevsent>
<prevsent>thus methods used for part of speech (pos) tagging and chunking can also be used for ner.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
the papers from the conll-2002 shared task which used such methods (e.g. malouf (2002), <papid> W02-2019 </papid>burger et al (2002)) <papid> W02-2003 </papid>reported results significantly lower than the best system (carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>however, zhou and su (2002) <papid> P02-1060 </papid>have reported state of the art results on the muc-6 and muc-7 data using hmm-based tagger.</nextsent>
<nextsent>zhou and su (2002) <papid> P02-1060 </papid>used wide variety of features, which suggests that the relatively poor performance of the taggers used in conll-2002 was largely due to the feature sets used rather than the machine learning method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1189">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus methods used for part of speech (pos) tagging and chunking can also be used for ner.
</prevsent>
<prevsent>the papers from the conll-2002 shared task which used such methods (e.g. malouf (2002), <papid> W02-2019 </papid>burger et al (2002)) <papid> W02-2003 </papid>reported results significantly lower than the best system (carreras et al, 2002).<papid> W02-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1060 ">
however, zhou and su (2002) <papid> P02-1060 </papid>have reported state of the art results on the muc-6 and muc-7 data using hmm-based tagger.</citsent>
<aftsection>
<nextsent>zhou and su (2002) <papid> P02-1060 </papid>used wide variety of features, which suggests that the relatively poor performance of the taggers used in conll-2002 was largely due to the feature sets used rather than the machine learning method.</nextsent>
<nextsent>we demonstrate this to be the case by improving on the best dutch results from conll-2002 using maximum entropy (me) tagger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1193">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> the me tagger.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, ame tagger can easily deal with diverse, overlapping features.
</prevsent>
<prevsent>we also use gaussian prior on the parameters for effective smoothing over the large feature space.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the me tagger is based on ratnaparkhi (1996)<papid> W96-0213 </papid>s pos tagger and is described in curran and clark (2003) <papid> E03-1071 </papid>the tagger uses models of the form: p(y|x) = 1 z(x) exp ( n?</citsent>
<aftsection>
<nextsent>i=1 ifi(x, y) ) (1) where is the tag, is the context and the fi(x, y) are the features with associated weights i. the probability of tag sequence y1 . . .
</nextsent>
<nextsent>yn given sentence w1 . . .
</nextsent>
<nextsent>wn is approximated as follows: p(y1 . . .
</nextsent>
<nextsent>yn|w1 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1194">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> the me tagger.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, ame tagger can easily deal with diverse, overlapping features.
</prevsent>
<prevsent>we also use gaussian prior on the parameters for effective smoothing over the large feature space.
</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
the me tagger is based on ratnaparkhi (1996)<papid> W96-0213 </papid>s pos tagger and is described in curran and clark (2003) <papid> E03-1071 </papid>the tagger uses models of the form: p(y|x) = 1 z(x) exp ( n?</citsent>
<aftsection>
<nextsent>i=1 ifi(x, y) ) (1) where is the tag, is the context and the fi(x, y) are the features with associated weights i. the probability of tag sequence y1 . . .
</nextsent>
<nextsent>yn given sentence w1 . . .
</nextsent>
<nextsent>wn is approximated as follows: p(y1 . . .
</nextsent>
<nextsent>yn|w1 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1201">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> the feature set.  </section>
<citcontext>
<prevsection>
<prevsent>the use of beam-search tagging means that tags can only be recorded from previous sentences.
</prevsent>
<prevsent>this memory is cleared at the beginning of each document.
</prevsent>
</prevsection>
<citsent citstr=" W02-2031 ">
the unigram predicates (see e.g. tsukamoto et al (2002)) <papid> W02-2031 </papid>encode the most probable tagfor the next words in the window.</citsent>
<aftsection>
<nextsent>the unigram probabilities are relative frequencies obtained from the training data.
</nextsent>
<nextsent>this feature enables us to know something about the likely ne tag of the next word before reaching it.
</nextsent>
<nextsent>most systems use gazette ers to encode information about personal and organisation names, locations and trigger words.
</nextsent>
<nextsent>there is considerable variation in the size of the gazette ers used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1205">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> the feature set.  </section>
<citcontext>
<prevsection>
<prevsent>some studies found that gazette ers did not improve performance (e.g. malouf (2002)) <papid> W02-2019 </papid>whilst others gained significant improvement using gazetteer sand triggers (e.g. carreras et al (2002)).<papid> W02-2004 </papid></prevsent>
<prevsent>our system incorporates only english and dutch first name and last name gazette ers as shown in table 6.</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
these gazette ers are used for predicates applied to the current, previous and next word in the window.collins (2002) <papid> P02-1062 </papid>includes number of interesting contextual predicates for ner.</citsent>
<aftsection>
<nextsent>one feature we have adapted encodes whether the current word is more frequently seen lowercase than upper case in large external corpus.
</nextsent>
<nextsent>this feature is useful for disambiguating beginning of sentence capitalisation and tagging sentences which are all capitalised.
</nextsent>
<nextsent>the frequency counts have been obtained from 1 billion words of english newspaper text collected by curran and osborne (2002).<papid> W02-2008 </papid></nextsent>
<nextsent>collins (2002) <papid> P02-1062 </papid>also describes mapping from words to word types which groups words with similar orthographic forms into classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1207">
<title id=" W03-0424.xml">language independent ner using a maximum entropy tagger </title>
<section> the feature set.  </section>
<citcontext>
<prevsection>
<prevsent>one feature we have adapted encodes whether the current word is more frequently seen lowercase than upper case in large external corpus.
</prevsent>
<prevsent>this feature is useful for disambiguating beginning of sentence capitalisation and tagging sentences which are all capitalised.
</prevsent>
</prevsection>
<citsent citstr=" W02-2008 ">
the frequency counts have been obtained from 1 billion words of english newspaper text collected by curran and osborne (2002).<papid> W02-2008 </papid></citsent>
<aftsection>
<nextsent>collins (2002) <papid> P02-1062 </papid>also describes mapping from words to word types which groups words with similar orthographic forms into classes.</nextsent>
<nextsent>this involves mapping characters to classes and merging adjacent characters of the same type.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1213">
<title id=" W03-1110.xml">issues in pre and post translation document expansion untranslatable cognates and mis segmented words </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>recent side experiments on preand post-translation query expansion on the english chinese pair show similar pattern of effectiveness for post-translation expansion over pre-translation expansion (levow et al , under review).
</prevsent>
<prevsent>a further complication is caused by the fact that mandarin chinese is written without white space separating words.
</prevsent>
</prevsection>
<citsent citstr=" H01-1050 ">
as result, some segmentation process must be performed to identify words for translation, even though indexing and retrieval can be performed effectively on   -gram units (meng etal., 2001).<papid> H01-1050 </papid></citsent>
<aftsection>
<nextsent>this segmentation process typically relies on list of terms that may appear in legal seg mentations.
</nextsent>
<nextsent>just as in the case of translation, these term lists often lack good coverage of proper names.thus, these terms may not be identified for translation, expansion, or even transcription by an automatic speech recognition system that also depends on word lists as models.
</nextsent>
<nextsent>these constraints limit the effectiveness of pre-translation expansion.
</nextsent>
<nextsent>in post-translation expansion, however, these problems are much less significant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1214">
<title id=" W03-0807.xml">current issues in software engineering for natural language processing </title>
<section> reuse.  </section>
<citcontext>
<prevsection>
<prevsent>a disadvantage is that repeated xml parsing between components may be too time-consuming in production scenario.
</prevsent>
<prevsent>2.5 code and design reuse: frameworks.
</prevsent>
</prevsection>
<citsent citstr=" C96-2187 ">
a framework is collection of pre-defined services that embody certain, given organization, within which the user can extend the functionality provided; frameworks impose certain organizational principles on the developer (griffel, 1998).the general architecture for text engineering (gate)3 is theory-neutral framework forthe management and integration of nlp components and documents on which they operate (cunningham et al, 1996; <papid> C96-2187 </papid>cunningham, 2000; bontcheva et al, 2002; cunningham et al, 2002; <papid> P02-1022 </papid>maynard et al, forthcoming).</citsent>
<aftsection>
<nextsent>gate 2 is compliant with the tipster architecture (grishman, 1995), contains the example ie system annie and is freely available including source (in java, which makes it also open for all languages due to the underlying use of unicode).
</nextsent>
<nextsent>a data type for annotating text spans is provided, which allows for generic visualization and editing components and graphical plug-and-play development environment.
</nextsent>
<nextsent>3 http://gate.ac.uk/ developers can make use of sample component toolbox.(zajac et al, 1997) <papid> A97-1036 </papid>present corelli, another tipster compliant architecture implemented in java (see(basili et al, 1999) for comparison).</nextsent>
<nextsent>the white board project (crysmann et al, 2002) <papid> P02-1056 </papid>uses monotonic xml annotation to integrate deep and shallow processing (figure 2, middle).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1215">
<title id=" W03-0807.xml">current issues in software engineering for natural language processing </title>
<section> reuse.  </section>
<citcontext>
<prevsection>
<prevsent>a disadvantage is that repeated xml parsing between components may be too time-consuming in production scenario.
</prevsent>
<prevsent>2.5 code and design reuse: frameworks.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
a framework is collection of pre-defined services that embody certain, given organization, within which the user can extend the functionality provided; frameworks impose certain organizational principles on the developer (griffel, 1998).the general architecture for text engineering (gate)3 is theory-neutral framework forthe management and integration of nlp components and documents on which they operate (cunningham et al, 1996; <papid> C96-2187 </papid>cunningham, 2000; bontcheva et al, 2002; cunningham et al, 2002; <papid> P02-1022 </papid>maynard et al, forthcoming).</citsent>
<aftsection>
<nextsent>gate 2 is compliant with the tipster architecture (grishman, 1995), contains the example ie system annie and is freely available including source (in java, which makes it also open for all languages due to the underlying use of unicode).
</nextsent>
<nextsent>a data type for annotating text spans is provided, which allows for generic visualization and editing components and graphical plug-and-play development environment.
</nextsent>
<nextsent>3 http://gate.ac.uk/ developers can make use of sample component toolbox.(zajac et al, 1997) <papid> A97-1036 </papid>present corelli, another tipster compliant architecture implemented in java (see(basili et al, 1999) for comparison).</nextsent>
<nextsent>the white board project (crysmann et al, 2002) <papid> P02-1056 </papid>uses monotonic xml annotation to integrate deep and shallow processing (figure 2, middle).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1216">
<title id=" W03-0807.xml">current issues in software engineering for natural language processing </title>
<section> reuse.  </section>
<citcontext>
<prevsection>
<prevsent>gate 2 is compliant with the tipster architecture (grishman, 1995), contains the example ie system annie and is freely available including source (in java, which makes it also open for all languages due to the underlying use of unicode).
</prevsent>
<prevsent>a data type for annotating text spans is provided, which allows for generic visualization and editing components and graphical plug-and-play development environment.
</prevsent>
</prevsection>
<citsent citstr=" A97-1036 ">
3 http://gate.ac.uk/ developers can make use of sample component toolbox.(zajac et al, 1997) <papid> A97-1036 </papid>present corelli, another tipster compliant architecture implemented in java (see(basili et al, 1999) for comparison).</citsent>
<aftsection>
<nextsent>the white board project (crysmann et al, 2002) <papid> P02-1056 </papid>uses monotonic xml annotation to integrate deep and shallow processing (figure 2, middle).</nextsent>
<nextsent>finally, the closest coupling takes place in architectures where most or all components are allowed to talk to each other, such as the german verb mobil speech translation system (gorz et al, 1996).alep, the advanced language engineering platform (simpkins and groenendijk, 1994; bredenkamp et al, 1997) is an early framework that focused on multilinguality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1217">
<title id=" W03-0807.xml">current issues in software engineering for natural language processing </title>
<section> reuse.  </section>
<citcontext>
<prevsection>
<prevsent>a data type for annotating text spans is provided, which allows for generic visualization and editing components and graphical plug-and-play development environment.
</prevsent>
<prevsent>3 http://gate.ac.uk/ developers can make use of sample component toolbox.(zajac et al, 1997) <papid> A97-1036 </papid>present corelli, another tipster compliant architecture implemented in java (see(basili et al, 1999) for comparison).</prevsent>
</prevsection>
<citsent citstr=" P02-1056 ">
the white board project (crysmann et al, 2002) <papid> P02-1056 </papid>uses monotonic xml annotation to integrate deep and shallow processing (figure 2, middle).</citsent>
<aftsection>
<nextsent>finally, the closest coupling takes place in architectures where most or all components are allowed to talk to each other, such as the german verb mobil speech translation system (gorz et al, 1996).alep, the advanced language engineering platform (simpkins and groenendijk, 1994; bredenkamp et al, 1997) is an early framework that focused on multilinguality.
</nextsent>
<nextsent>it offers an hpsg like, typed avm-based unification formalism (and parsers for it) as well as some infrastructural support.
</nextsent>
<nextsent>in the ls-gram project, it has been used to build analyzers for nine languages.
</nextsent>
<nextsent>however, it has been criticized for being too committed to particular approach to linguistic analysis and representation?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1218">
<title id=" W03-0807.xml">current issues in software engineering for natural language processing </title>
<section> reuse.  </section>
<citcontext>
<prevsection>
<prevsent>in the ls-gram project, it has been used to build analyzers for nine languages.
</prevsent>
<prevsent>however, it has been criticized for being too committed to particular approach to linguistic analysis and representation?
</prevsent>
</prevsection>
<citsent citstr=" A97-1035 ">
( cunningham et al, 1997).<papid> A97-1035 </papid></citsent>
<aftsection>
<nextsent>aleps text handling component (declerck, 1997) uses particular sgml-based annotation that can be enriched with user-defined tags.
</nextsent>
<nextsent>some standard components are provided, and rules allow the mapping of sgml tags to avms (lifting?).
</nextsent>
<nextsent>sris open agent architecture (oaa) 4(martin et al, 1999; cheyer and martin, 2001) is software platform that offers library for distributed agent implementation with bindings for several programming languages (c/c++, java, lisp, prolog etc.).
</nextsent>
<nextsent>agents request services from service agents via facilitation, coordinating service procedure of transparent delegation, whereby facilitators can consider strategic knowledge provided by requesting agents, trying to distribute and optimize goal completion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1220">
<title id=" W03-1608.xml">extracting structural paraphrases from aligned monolingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because manually collecting paraphrases is time-consuming and im practical for large-scale applications, attention has recently focused on techniques for automatically acquiring paraphrases.we present an unsupervised method for acquiring structural paraphrases, or fragments of syntactic trees that are roughly semantically equivalent, fro maligned monolingual corpora.
</prevsent>
<prevsent>the structural paraphrases produced by our algorithm are similar to the s-rules advocated by katz and levin for question answering (1988), except that our paraphrases are automatically generated.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
because there is disagreement regarding the exact definition of paraphrases (dras, 1999), we employ that operating definition that structural paraphrases are roughly interchangeable within the specific configuration of syntactic structures that they specify.our approach is synthesis of techniques developed by barzilay and mckeown (2001) <papid> P01-1008 </papid>and linand pantel (2001), designed to overcome the limitations of both.</citsent>
<aftsection>
<nextsent>in addition to the evaluation of paraphrases generated by our method, we also describea novel information retrieval system under development that is designed to take advantage of structural paraphrases.
</nextsent>
<nextsent>there has been rich body of research on automatically deriving paraphrases, including equating morphological and syntactic variants of technical terms(jacquemin et al, 1997), <papid> P97-1004 </papid>and identifying equivalent adjective-noun phrases (lapata, 2001).<papid> N01-1009 </papid></nextsent>
<nextsent>unfortunately, both are limited in types of paraphrases that they can extract.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1222">
<title id=" W03-1608.xml">extracting structural paraphrases from aligned monolingual corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>because there is disagreement regarding the exact definition of paraphrases (dras, 1999), we employ that operating definition that structural paraphrases are roughly interchangeable within the specific configuration of syntactic structures that they specify.our approach is synthesis of techniques developed by barzilay and mckeown (2001) <papid> P01-1008 </papid>and linand pantel (2001), designed to overcome the limitations of both.</prevsent>
<prevsent>in addition to the evaluation of paraphrases generated by our method, we also describea novel information retrieval system under development that is designed to take advantage of structural paraphrases.</prevsent>
</prevsection>
<citsent citstr=" P97-1004 ">
there has been rich body of research on automatically deriving paraphrases, including equating morphological and syntactic variants of technical terms(jacquemin et al, 1997), <papid> P97-1004 </papid>and identifying equivalent adjective-noun phrases (lapata, 2001).<papid> N01-1009 </papid></citsent>
<aftsection>
<nextsent>unfortunately, both are limited in types of paraphrases that they can extract.
</nextsent>
<nextsent>other researchers have explored distributional clustering of similar words (pereira et al., 1993; <papid> P93-1024 </papid>lin, 1998), but it is unclear to what extent such techniques produce paraphrases.1most relevant to this paper is the work of barzilay and mckeown and the work of lin and pan tel.</nextsent>
<nextsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted both single- and multiple-word paraphrases from sentence-aligned corpus for use in multi-document summarization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1223">
<title id=" W03-1608.xml">extracting structural paraphrases from aligned monolingual corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>because there is disagreement regarding the exact definition of paraphrases (dras, 1999), we employ that operating definition that structural paraphrases are roughly interchangeable within the specific configuration of syntactic structures that they specify.our approach is synthesis of techniques developed by barzilay and mckeown (2001) <papid> P01-1008 </papid>and linand pantel (2001), designed to overcome the limitations of both.</prevsent>
<prevsent>in addition to the evaluation of paraphrases generated by our method, we also describea novel information retrieval system under development that is designed to take advantage of structural paraphrases.</prevsent>
</prevsection>
<citsent citstr=" N01-1009 ">
there has been rich body of research on automatically deriving paraphrases, including equating morphological and syntactic variants of technical terms(jacquemin et al, 1997), <papid> P97-1004 </papid>and identifying equivalent adjective-noun phrases (lapata, 2001).<papid> N01-1009 </papid></citsent>
<aftsection>
<nextsent>unfortunately, both are limited in types of paraphrases that they can extract.
</nextsent>
<nextsent>other researchers have explored distributional clustering of similar words (pereira et al., 1993; <papid> P93-1024 </papid>lin, 1998), but it is unclear to what extent such techniques produce paraphrases.1most relevant to this paper is the work of barzilay and mckeown and the work of lin and pan tel.</nextsent>
<nextsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted both single- and multiple-word paraphrases from sentence-aligned corpus for use in multi-document summarization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1224">
<title id=" W03-1608.xml">extracting structural paraphrases from aligned monolingual corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there has been rich body of research on automatically deriving paraphrases, including equating morphological and syntactic variants of technical terms(jacquemin et al, 1997), <papid> P97-1004 </papid>and identifying equivalent adjective-noun phrases (lapata, 2001).<papid> N01-1009 </papid></prevsent>
<prevsent>unfortunately, both are limited in types of paraphrases that they can extract.</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
other researchers have explored distributional clustering of similar words (pereira et al., 1993; <papid> P93-1024 </papid>lin, 1998), but it is unclear to what extent such techniques produce paraphrases.1most relevant to this paper is the work of barzilay and mckeown and the work of lin and pan tel.</citsent>
<aftsection>
<nextsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted both single- and multiple-word paraphrases from sentence-aligned corpus for use in multi-document summarization.</nextsent>
<nextsent>they constructed an aligned corpus from multiple translations of foreign novels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1227">
<title id=" W03-1608.xml">extracting structural paraphrases from aligned monolingual corpora </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>although our data spareness problem can be alleviated simply by gathering larger corpus, the type of parallel text our algorithm requires is rather hard to obtain, i.e., there are only so many translations of so many foreignnovels.
</prevsent>
<prevsent>furthermore, since our paraphrases are arguably genre-specific, different applications may require different training corpora.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
similar to the workof barzilay and lee (2003), <papid> N03-1003 </papid>who have applied paraphrase generation techniques to comparable corpora consisting of different newspaper articles about the same event, we are currently attempting to solve the data sparseness problem by extending our approach to non-parallel corpora.</citsent>
<aftsection>
<nextsent>we believe that generating paraphrases at the structural level holds several key advantages over lexical paraphrases, from the capturing of long distance relationships to the more accurate modeling of context.
</nextsent>
<nextsent>the paraphrases generated by our approach could prove to be useful in any natural language application where understanding of linguistic variations is important.
</nextsent>
<nextsent>in particular, we are attempting to apply our results to improve the performance of question answering system, which we will describe in the following section.
</nextsent>
<nextsent>the ultimate goal of our work on paraphrases isto enable the development of high-precision question answering system (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1228">
<title id=" W03-1608.xml">extracting structural paraphrases from aligned monolingual corpora </title>
<section> paraphrases and question answering.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we are attempting to apply our results to improve the performance of question answering system, which we will describe in the following section.
</prevsent>
<prevsent>the ultimate goal of our work on paraphrases isto enable the development of high-precision question answering system (cf.
</prevsent>
</prevsection>
<citsent citstr=" C88-1065 ">
(katz and levin, 1988; <papid> C88-1065 </papid>soubbotin and soubbotin, 2001; hermjakob et al,2002)).</citsent>
<aftsection>
<nextsent>we believe that knowledge base of paraphrases is the key to overcoming challenges presented by the expressiveness of natural languages.
</nextsent>
<nextsent>because the same semantic content can be expressed in many different ways, question answering system must be able to cope with variety of alternative phrasings.
</nextsent>
<nextsent>in particular, an answer stated in form that differs from the form of the question presents significant problems: when did colorado become state?
</nextsent>
<nextsent>(1a) colorado became state in 1876.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1229">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we have evaluated these methods using large collection of news articles without additional annotation (section 6)and an evaluation corpus of 400 sentences annotated for opinion classifications (section 7).
</prevsent>
<prevsent>the results, presented in section 8, indicate that we achieve very high performance (more than 97%) atdocument-level classification and respectable performance (8691%) at detecting opinion sentences and classifying them according to orientation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
much of the earlier research in automated opinion detection has been performed by wiebe and colleagues (bruce and wiebe, 1999; wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>wiebe, 2000;wiebe et al, 2002), who proposed methods for discriminating between subjective and objective text at the document, sentence, and phrase levels.</citsent>
<aftsection>
<nextsent>bruce and wiebe (1999) annotated 1,001 sentences as subjective or objective, and wiebe et al (1999) <papid> P99-1032 </papid>described sentence-level naive bayes classifier usingas features the presence or absence of particular syntactic classes (pronouns, adjectives, cardinal numbers, modal verbs, adverbs), punctuation, and sentence position.</nextsent>
<nextsent>subsequently, hatzivassiloglou and wiebe (2000) <papid> C00-1044 </papid>showed that automatically detectedgradable adjectives are useful feature for subjectivity classification, while wiebe (2000) introduced lexical features in addition to the presence/absence of syntactic categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1230">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we have evaluated these methods using large collection of news articles without additional annotation (section 6)and an evaluation corpus of 400 sentences annotated for opinion classifications (section 7).
</prevsent>
<prevsent>the results, presented in section 8, indicate that we achieve very high performance (more than 97%) atdocument-level classification and respectable performance (8691%) at detecting opinion sentences and classifying them according to orientation.
</prevsent>
</prevsection>
<citsent citstr=" C00-1044 ">
much of the earlier research in automated opinion detection has been performed by wiebe and colleagues (bruce and wiebe, 1999; wiebe et al, 1999; <papid> P99-1032 </papid>hatzivassiloglou and wiebe, 2000; <papid> C00-1044 </papid>wiebe, 2000;wiebe et al, 2002), who proposed methods for discriminating between subjective and objective text at the document, sentence, and phrase levels.</citsent>
<aftsection>
<nextsent>bruce and wiebe (1999) annotated 1,001 sentences as subjective or objective, and wiebe et al (1999) <papid> P99-1032 </papid>described sentence-level naive bayes classifier usingas features the presence or absence of particular syntactic classes (pronouns, adjectives, cardinal numbers, modal verbs, adverbs), punctuation, and sentence position.</nextsent>
<nextsent>subsequently, hatzivassiloglou and wiebe (2000) <papid> C00-1044 </papid>showed that automatically detectedgradable adjectives are useful feature for subjectivity classification, while wiebe (2000) introduced lexical features in addition to the presence/absence of syntactic categories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1233">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recently, wiebe et al(2002) report on document-level subjectivity classification, using k-nearest neighbor algorithm based on the total count of subjective words and phrases within each document.
</prevsent>
<prevsent>psychological studies (bradley and lang, 1999) found measurable associations between words and human emotions.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
hatzivassiloglou and mckeown (1997) <papid> P97-1023 </papid>described an unsupervised learning method for obtaining positively and negatively oriented adjectives with accuracy over 90%, and demonstrated that this semantic orientation, or polarity, is consistent lexical property with high inter-rater agree ment.</citsent>
<aftsection>
<nextsent>turney (2002) <papid> P02-1053 </papid>showed that it is possible to use only few of those semantically oriented words (namely, excellent?</nextsent>
<nextsent>and poor?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1234">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>psychological studies (bradley and lang, 1999) found measurable associations between words and human emotions.
</prevsent>
<prevsent>hatzivassiloglou and mckeown (1997) <papid> P97-1023 </papid>described an unsupervised learning method for obtaining positively and negatively oriented adjectives with accuracy over 90%, and demonstrated that this semantic orientation, or polarity, is consistent lexical property with high inter-rater agree ment.</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
turney (2002) <papid> P02-1053 </papid>showed that it is possible to use only few of those semantically oriented words (namely, excellent?</citsent>
<aftsection>
<nextsent>and poor?)
</nextsent>
<nextsent>to label other phrases co-occuring with them as positive ornegative.
</nextsent>
<nextsent>he then used these phrases to automatically separate positive and negative movie and product reviews, with accuracy of 6684%.
</nextsent>
<nextsent>pang et al(2002) <papid> W02-1011 </papid>adopted more direct approach, using supervised machine learning with words and n-grams as features to predict orientation at the document level with up to 83% precision.our approach to document and sentence classification of opinions builds upon the earlier work by using extended lexical models with additional features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1235">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to label other phrases co-occuring with them as positive ornegative.
</prevsent>
<prevsent>he then used these phrases to automatically separate positive and negative movie and product reviews, with accuracy of 6684%.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
pang et al(2002) <papid> W02-1011 </papid>adopted more direct approach, using supervised machine learning with words and n-grams as features to predict orientation at the document level with up to 83% precision.our approach to document and sentence classification of opinions builds upon the earlier work by using extended lexical models with additional features.</citsent>
<aftsection>
<nextsent>unlike the work cited above, we do not relyon human annotations for training but only on weak meta data provided at the document level.
</nextsent>
<nextsent>oursentence-level classifiers introduce additional criteria for detecting subjective material (opinions), including methods based on sentence similarity withina topic and an approach that relies on multiple classifiers.
</nextsent>
<nextsent>at the document level, our classifier uses the same document labels that the method of (wiebe et al., 2002) does, but automatically detects the word sand phrases of importance without further analysis of the text.
</nextsent>
<nextsent>for determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (hatzivas siloglou and mckeown, 1997) <papid> P97-1023 </papid>and extended them to construct much larger set of semantically oriented words with method similar to that proposed by (turney, 2002).<papid> P02-1053 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1243">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> finding opinion sentences.  </section>
<citcontext>
<prevsection>
<prevsent>we also include the counts of parts of speech combined with polarity information (e.g.,jj+?
</prevsent>
<prevsent>for positive adjectives), as well as features encoding the polarity (if any) of the head verb, themain subject, and their immediate modifiers.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
syntactic structure was obtained with charniaks statistical parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>finally, we used as one of the features the average semantic orientation score of the words in the sentence.
</nextsent>
<nextsent>4.3 multiple naive bayes classifiers.
</nextsent>
<nextsent>our designation of all sentences in opinion or factual articles as opinion or fact sentences is an approximation.
</nextsent>
<nextsent>to address this, we apply an algorithm using multiple classifiers, each relying on different subset of our features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1248">
<title id=" W03-1017.xml">towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences </title>
<section> identifying the polarity of opinion.  </section>
<citcontext>
<prevsection>
<prevsent>we experimented with seed sets containing 1, 20, 100 and over 600 positive and negative pairs of adjectives.
</prevsent>
<prevsent>forgiven seed set size, we denote the set of positive seeds as adj and the set of negative seeds as adj  . we then calculate modified log-likelihood ratio  ff posfi  for word   with part of speech posfi (fl can be adjective, adverb, noun or verb) as the ratio of its collocation frequency with adj  and adj  within sentence,  ffi   posfi   !$# %&amp; freq ( )+* pos, * adj - /.10 freq 2  all * pos , * adj -  freq 2 3)ffi* pos, * adj 4 5.60 freq 2  all * pos , * adj 4  78 where freq ffi all  posfi  adj  represents the collocation frequency of all words  all of part of speech pos fi with adj  and 9 is smoothing constant ( 9 ;: =  in our case).
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we used brills tagger (brill, 1995) <papid> J95-4004 </papid>to obtain part-of-speech information.</citsent>
<aftsection>
<nextsent>5.2 sentence polarity tagging.
</nextsent>
<nextsent>as our measure of semantic orientation across an entire sentence we used the average per word log likelihood scores defined in the preceding section.
</nextsent>
<nextsent>to determine the orientation of an opinion sentence, all that remains is to specify cutoffs  / and  ? so that sentences for which the average log-likelihood score exceeds  5 are classified as positive opinions, sentences with scores lower than  ? are classified as negative opinions, and sentences with in-betweenscores are treated as neutral opinions.
</nextsent>
<nextsent>optimal values for    and    are obtained from the training data via density estimation using small, hand-labeled subset of sentences we estimate the proportion of sentences that are positive or negative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1253">
<title id=" W02-1406.xml">probabilistic named entity verification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, in oriental languages (such as chinese, japanese and korean), ne recognition is even more important because it significantly affects the performance of word segmentation, the most fundamental task for understanding the texts in oriental languages.
</prevsent>
<prevsent>therefore, high-accuracy ne recognition method is highly demanded for most natural language applications in various languages.
</prevsent>
</prevsection>
<citsent citstr=" M95-1014 ">
there are two major approaches to nerecognition: the handcrafted approach (grish man, 1995) <papid> M95-1014 </papid>and the statistical approach (bikel,1997; chen, 1998; yu, 1998).</citsent>
<aftsection>
<nextsent>in the first approach, system usually relies on large number of handcrafted rules.
</nextsent>
<nextsent>this kind of systems can be rapid proto typed but are hard to scale up.
</nextsent>
<nextsent>in fact, there will be numerous exceptions for most handcrafted rules.
</nextsent>
<nextsent>it is generally expensive and impossible to code for every exception we can imagine, not to mention those exceptions we are not able to think of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1254">
<title id=" W02-0909.xml">acquiring collocations for lexical choice between near synonyms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this task we use much larger corpus (the web).
</prevsent>
<prevsent>we also look at associations(longer-distance co-occurrences) as possible source of learning more about nuances that the near-synonyms may carry.
</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
edmonds and hirst (2002 <papid> J02-2001 </papid>to appear) developed alexical choice process for natural language generation (nlg) or machine translation (mt) that can decide which near-synonyms are most appropriate in particular situation.</citsent>
<aftsection>
<nextsent>the lexical choice process has to choose between clusters of near-synonyms (toconvey the basic meaning), and then to choose between the near-synonyms in each cluster.
</nextsent>
<nextsent>to group near-synonyms in clusters we trust lexicographers?
</nextsent>
<nextsent>judgment in dictionaries of synonym differences.
</nextsent>
<nextsent>for example task, job, duty, assignment, chore, stint, hitch all refer to one-time piece of work, but which one to choose depends on the duration of the work, the commitment and the effort involved, etc.in order to convey desired nuances of meaning and to avoid unwanted implications, knowledge about the differences among near-synonyms is necessary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1256">
<title id=" W02-0909.xml">acquiring collocations for lexical choice between near synonyms </title>
<section> extracting collocations from free text.  </section>
<citcontext>
<prevsection>
<prevsent>the first one, based on frequency of co-occurrence, 3http://www.hcu.ox.ac.uk/bnc/does not consider the length of the corpus.
</prevsent>
<prevsent>part-ofspeech filtering is needed to obtain useful collocations.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
the second method considers the means and variance of the distance between two words, and can compute flexible collocations (smadja, 1993).<papid> J93-1007 </papid></citsent>
<aftsection>
<nextsent>the third method is hypothesis testing, which uses statistical tests to decide if the words occur together with probability higher than chance (it tests whether we can reject the null hypothesis that the two words occurred together by chance).
</nextsent>
<nextsent>the fourth method is (pointwise) mutual information, an information theoretical measure.we use ted pedersens bigram statistics package4.
</nextsent>
<nextsent>bsp is suite of programs to aid in analyzing bigrams in corpus (newer versions allow ngrams).
</nextsent>
<nextsent>the package can compute bigram frequencies and various statistics to measure the degree of association between two words: mutual information (mi), dice, chi-square (2), log-likelihood (ll), and fishers exact test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1257">
<title id=" W02-0909.xml">acquiring collocations for lexical choice between near synonyms </title>
<section> extracting collocations from free text.  </section>
<citcontext>
<prevsection>
<prevsent>pearsons chi-square and log likelihood ratios measure the divergence of observed (ni j) and expected (mi j) sample counts (i = 1,2, = 1,2).
</prevsent>
<prevsent>the expected values are for the model that assumes independence (assumes that the null hypothesis is true).
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
for each cell in the contingency table, the expected counts are: mi = ni+n+ jn++ . the measures are calculated as (pedersen, 1996): 2 = i, (ni jmi j)2 mi ll = 2 i, log2 n2i mi log-likelihood ratios (dunning, 1993) <papid> J93-1003 </papid>are more appropriate for sparse data than chi-square.</citsent>
<aftsection>
<nextsent>fishers exact test is significance test that is considered to be more appropriate for sparse and skewed samples of data than statistics such as the log-likelihood ratio or pearsons chi-square test (pedersen, 1996).
</nextsent>
<nextsent>fishers exact test is computed by fixing the marginal totals of contingency table and then determining the probability of each of the possible tables that could result in those marginal totals.
</nextsent>
<nextsent>therefore it is computationally expensive.
</nextsent>
<nextsent>the formula is: = n1+!n2+!n+1!n+2!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1258">
<title id=" W02-0909.xml">acquiring collocations for lexical choice between near synonyms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is lot of work on using collocations in nlg (but not in the lexical choice sub-component).
</prevsent>
<prevsent>there are two typical ap proaches: the use of phrasal templates in the formof canned phrases, and the use of automatically extracted collocations for unification-based generation (mckeown and radev, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
statistical nlg systems (such as nitrogen (langkilde and knight, 1998)) <papid> W98-1426 </papid>make good use of the most frequent words and their collocations.</citsent>
<aftsection>
<nextsent>but such system cannot choose less-frequent synonym thatmay be more appropriate for conveying desired nuances of meaning, if the synonym is not frequent word.
</nextsent>
<nextsent>finally, there is work related to ours from the point of view of the synonymy relation.
</nextsent>
<nextsent>turney (2001) used mutual information to detect the best answer to questions about synonyms from test of english as foreign language (toefl) and english as second language (esl).
</nextsent>
<nextsent>given problem word (with or without context), and four alternative words, the question is to choose the alternative most similar in meaning with the problem word.his work is based on the assumption that two synonyms are likely to occur in the same document (on the web).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1259">
<title id=" W02-0909.xml">acquiring collocations for lexical choice between near synonyms </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in similar manner with(pearce, 2001), in section 3, we dont record collocations in our lexical knowledge-base if they dont help discriminate between near-synonyms.
</prevsent>
<prevsent>a difference is that we use more than frequency counts to classify collocations (we use combination of t-test and mi).
</prevsent>
</prevsection>
<citsent citstr=" P01-1025 ">
our evaluation was partly inspired by evert and krenn (2001).<papid> P01-1025 </papid></citsent>
<aftsection>
<nextsent>they collect collocations of the form noun-adjective and verb-prepositional phrase.
</nextsent>
<nextsent>they build solution using two human judges, and use the solution to decide what is the best threshold for taking the highest-ranked pairs as true collocations.
</nextsent>
<nextsent>in their experiment mi behaves worse that other measures (ll, t-test), but in our experiment mi on the web achieves good results.
</nextsent>
<nextsent>we presented an unsupervised method to acquire knowledge about the collocational behaviour of near-synonyms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1260">
<title id=" W03-1902.xml">from concrete to virtual annotation markup language the case of common refs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare our encoding schemes to the abstract xml encoding being proposed as standard.
</prevsent>
<prevsent>we also present our tool for coreference resolution that handles our data model.
</prevsent>
</prevsection>
<citsent citstr=" W97-1301 ">
we have been dealing with corpus based studies since 1997 (renata vieira and simone teufel, 1997; poesio et al, 1997).<papid> W97-1301 </papid></citsent>
<aftsection>
<nextsent>our focus has been the study of coreference.
</nextsent>
<nextsent>in the study of coreference we have dealt with annotation experiments (manual and auto matic) and their respective annotation schemes.
</nextsent>
<nextsent>towork on coreference we used information from syntactic annotated corpus, the penn treebank.
</nextsent>
<nextsent>our results (annotated corpus with coreference links and classification of coreference status) were prolog encoded.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1261">
<title id=" W03-1902.xml">from concrete to virtual annotation markup language the case of common refs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in order to be able to share there sources being built, we are relating our model with proposed standards.in section 2 we present previous annotation formats that we dealt with.
</prevsent>
<prevsent>in section 3 we give an overview of the work in common-refs.
</prevsent>
</prevsection>
<citsent citstr=" P01-1040 ">
section 4 relates our current model with the standards recently proposed (ide and romary, 2002; ide and romary, 2003; ide and romary, 2001).<papid> P01-1040 </papid></citsent>
<aftsection>
<nextsent>section 5 describes our tool for coreference resolution.
</nextsent>
<nextsent>a discussion on the problems we face with our annotation model is presented in section 6.
</nextsent>
<nextsent>our first annotation schemes were prolog lists of treebank sentences and their noun phrases (nps), as shown in figure 1.
</nextsent>
<nextsent>the lists were extracted from lisp lists of the penn treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1264">
<title id=" W03-1902.xml">from concrete to virtual annotation markup language the case of common refs </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>these lists were manipulated in our experiments on coreference annotation and resolution.
</prevsent>
<prevsent>the results of coreference annotation were lists of prolog facts dcc(index1,index2,code) as shownin figure 2.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
index1 refers to the sequential numbering of definite descriptions; index2 refers to the sequential numbering of noun phrases; and code refers to their classification, according to discourse status (poesio and vieira, 1998).<papid> J98-2001 </papid></citsent>
<aftsection>
<nextsent>for some of them there were also facts [s,[np,the,squabbling,[pp,within,[np,the, organization,[pp,of,[np,petroleum,exporting, countries]]]]],[vp,seems,[pp,under, [np,control]],[pp,for,now]].].
</nextsent>
<nextsent>[np,petroleum,exporting,countries].
</nextsent>
<nextsent>[np,the,organization, [pp,of,[np,petroleum,exporting,countries]]].
</nextsent>
<nextsent>[np,the,squabbling,[pp,within, [np,the,organization...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1271">
<title id=" W03-1902.xml">from concrete to virtual annotation markup language the case of common refs </title>
<section> automatic coreference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>attributes, as seen in figure 10(a).
</prevsent>
<prevsent>figure 10(b) represents the corresponding vaml encoding for the  anaphor  elements.
</prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
the heuristics to be applied to resolve coreference are based on previous studies about resolution of referring expressions (vieira and poesio, 2000; <papid> J00-4003 </papid>lap pin and leass, 1994; <papid> J94-4002 </papid>strube et al, 2002) <papid> W02-1040 </papid>and they are not discussed here.</citsent>
<aftsection>
<nextsent>the output is the last step in the process and it is also played by style sheet that translates the anaphor  nodes into  mark able  ones, so there sults can be visualized using the mmax tool.
</nextsent>
<nextsent>we have presented the evolution of our annotation schemes over 7 years of corpus research.
</nextsent>
<nextsent>we believe that standard orientation may shed some light to those who are defining their projects.
</nextsent>
<nextsent>concerning annotation level relations our annotation is based onobject-based anchoring, especially because our primary data is represented by xml elements (words in our dialect, basic struct elements with id attributes in vaml).considering relations like parallelism, alternatives and aggregation (ide and romary, 2002) we see that our model includes aggregation at the chunk level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1272">
<title id=" W03-1902.xml">from concrete to virtual annotation markup language the case of common refs </title>
<section> automatic coreference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>attributes, as seen in figure 10(a).
</prevsent>
<prevsent>figure 10(b) represents the corresponding vaml encoding for the  anaphor  elements.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
the heuristics to be applied to resolve coreference are based on previous studies about resolution of referring expressions (vieira and poesio, 2000; <papid> J00-4003 </papid>lap pin and leass, 1994; <papid> J94-4002 </papid>strube et al, 2002) <papid> W02-1040 </papid>and they are not discussed here.</citsent>
<aftsection>
<nextsent>the output is the last step in the process and it is also played by style sheet that translates the anaphor  nodes into  mark able  ones, so there sults can be visualized using the mmax tool.
</nextsent>
<nextsent>we have presented the evolution of our annotation schemes over 7 years of corpus research.
</nextsent>
<nextsent>we believe that standard orientation may shed some light to those who are defining their projects.
</nextsent>
<nextsent>concerning annotation level relations our annotation is based onobject-based anchoring, especially because our primary data is represented by xml elements (words in our dialect, basic struct elements with id attributes in vaml).considering relations like parallelism, alternatives and aggregation (ide and romary, 2002) we see that our model includes aggregation at the chunk level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1273">
<title id=" W03-1902.xml">from concrete to virtual annotation markup language the case of common refs </title>
<section> automatic coreference resolution.  </section>
<citcontext>
<prevsection>
<prevsent>attributes, as seen in figure 10(a).
</prevsent>
<prevsent>figure 10(b) represents the corresponding vaml encoding for the  anaphor  elements.
</prevsent>
</prevsection>
<citsent citstr=" W02-1040 ">
the heuristics to be applied to resolve coreference are based on previous studies about resolution of referring expressions (vieira and poesio, 2000; <papid> J00-4003 </papid>lap pin and leass, 1994; <papid> J94-4002 </papid>strube et al, 2002) <papid> W02-1040 </papid>and they are not discussed here.</citsent>
<aftsection>
<nextsent>the output is the last step in the process and it is also played by style sheet that translates the anaphor  nodes into  mark able  ones, so there sults can be visualized using the mmax tool.
</nextsent>
<nextsent>we have presented the evolution of our annotation schemes over 7 years of corpus research.
</nextsent>
<nextsent>we believe that standard orientation may shed some light to those who are defining their projects.
</nextsent>
<nextsent>concerning annotation level relations our annotation is based onobject-based anchoring, especially because our primary data is represented by xml elements (words in our dialect, basic struct elements with id attributes in vaml).considering relations like parallelism, alternatives and aggregation (ide and romary, 2002) we see that our model includes aggregation at the chunk level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1274">
<title id=" W03-1018.xml">evaluation and extension of maximum entropy models with inequality constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also propose an extension of the inequality me model, which results in natural integration withthe gaussian map estimation.
</prevsent>
<prevsent>experimental results demonstrate the advantage of the inequality models and the proposed extension.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the maximum entropy model (berger et al, 1996; <papid> J96-1002 </papid>pietra et al, 1997) has attained great popularity inthe nlp field due to its power, robustness, and successful performance in various nlp tasks (ratna parkhi, 1996; <papid> W96-0213 </papid>nigam et al, 1999; borthwick, 1999).</citsent>
<aftsection>
<nextsent>in the me estimation, an event is decomposed into features, which indicate the strength of certain aspects in the event, and the most uniform model among the models that satisfy: ep?[fi] = ep[fi], (1) for each feature.
</nextsent>
<nextsent>ep?[fi] represents the expectation of feature fi in the training data (empirical expec tation), and ep[fi] is the expectation with respect to the model being estimated.
</nextsent>
<nextsent>a powerful and robust estimation is possible since the features can be as specific or general as required and does not need to be independent of each other, and since the most uniform model avoids over fitting the training data.
</nextsent>
<nextsent>inspite of these advantages, the me model still suffers from lack of data as long as it imposes the equality constraint (1), since the empirical expectation calculated from the training data of limited sizeis inevitably unreliable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1275">
<title id=" W03-1018.xml">evaluation and extension of maximum entropy models with inequality constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also propose an extension of the inequality me model, which results in natural integration withthe gaussian map estimation.
</prevsent>
<prevsent>experimental results demonstrate the advantage of the inequality models and the proposed extension.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the maximum entropy model (berger et al, 1996; <papid> J96-1002 </papid>pietra et al, 1997) has attained great popularity inthe nlp field due to its power, robustness, and successful performance in various nlp tasks (ratna parkhi, 1996; <papid> W96-0213 </papid>nigam et al, 1999; borthwick, 1999).</citsent>
<aftsection>
<nextsent>in the me estimation, an event is decomposed into features, which indicate the strength of certain aspects in the event, and the most uniform model among the models that satisfy: ep?[fi] = ep[fi], (1) for each feature.
</nextsent>
<nextsent>ep?[fi] represents the expectation of feature fi in the training data (empirical expec tation), and ep[fi] is the expectation with respect to the model being estimated.
</nextsent>
<nextsent>a powerful and robust estimation is possible since the features can be as specific or general as required and does not need to be independent of each other, and since the most uniform model avoids over fitting the training data.
</nextsent>
<nextsent>inspite of these advantages, the me model still suffers from lack of data as long as it imposes the equality constraint (1), since the empirical expectation calculated from the training data of limited sizeis inevitably unreliable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1276">
<title id=" W03-1018.xml">evaluation and extension of maximum entropy models with inequality constraints </title>
<section> the maximum entropy model.  </section>
<citcontext>
<prevsection>
<prevsent>= log ? x,y p?(y|x) p?(x,y) .this optimization can be solved using algorithms such as the gis algorithm (darroch and rat cliff, 1972) and the iis algorithm (pietra et al, 1997).
</prevsent>
<prevsent>in addition, gradient-based algorithms can be applied since the objective function is concave.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
malouf (2002) <papid> W02-2018 </papid>compares several algorithms for theme estimation including gis, iis, and the limited memory variable metric (lmvm) method, which is gradient-based method, and shows that the lmvm method requires much less time to converge for real nlp datasets.</citsent>
<aftsection>
<nextsent>we also observed that the lmvmmethod converges very quickly for the text categorization datasets with an improvement in accuracy.therefore, we use the lmvm method (and its variant for the inequality models) throughout the experiments.
</nextsent>
<nextsent>thus, we only show the gradient when mentioning the training.
</nextsent>
<nextsent>the gradient of the objective function (8) is computed as: l(?)
</nextsent>
<nextsent>i = ep?[fi]?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1277">
<title id=" W03-1007.xml">maximum entropy models for framenet classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>each target predicate, for example, has on average only 30 sentences tagged.
</prevsent>
<prevsent>this data sparsity makes the task of learning semantic classifier formidable, and increases the importance of the modeling framework that is employed.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
to our knowledge, gildea and jurafsky (2002)<papid> J02-3001 </papid>is the only work to use framenet to build statistically based semantic classifier.</citsent>
<aftsection>
<nextsent>they split the problem into two distinct sub-tasks: frame element identification and frame element classification.
</nextsent>
<nextsent>in the identification phase, syntactic information is extracted from parse tree to learn the boundaries of the frame elements in sentence.
</nextsent>
<nextsent>in the classification phase, similar syntactic information is used to classify those elements into their semantic roles.
</nextsent>
<nextsent>in both phases gildea and jurafsky (2002)<papid> J02-3001 </papid>build model of the conditional probabilities of the classification given vector of syntactic features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1293">
<title id=" W03-1007.xml">maximum entropy models for framenet classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 1 datasets (including parse trees) were obtained from dan.
</prevsent>
<prevsent>gildea via personal communication.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
features for each frame element, features are extracted from the surface text of the sentence and from an automatically generated syntactic parse tree (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>the features used are described below: )|()|( 0 m i xrpxrp ? = = ? ?
</nextsent>
<nextsent>target predicate (tar): although there may be many predicates in sentence with associated frame elements, classification operates on only one target predicate at time.
</nextsent>
<nextsent>the target predicate is the only feature that is not extracted from the sentence itself and must be given by the user.
</nextsent>
<nextsent>note that the frame which the target predicate instantiates is not given, leaving any word sense ambiguities to be handled implicitly by the classifier.2 ? phrase type (pt): the syntactic phrase type of the frame element (e.g. np, pp) is extracted from the parse tree of the sentence by finding the constituent in the tree whose boundaries match the human annotated boundaries of the element.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1294">
<title id=" W03-1007.xml">maximum entropy models for framenet classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>during training, this information is provided by simply looking at the true classes of the frame element occurring positions before the target element.
</prevsent>
<prevsent>during testing, hypothesized classes of the elements are used and viterbi search is performed to find the most probable tag sequence for sentence.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
me models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>we model the probability of semantic role given vector of features according to the me formulation below: 3.3 3.4 experiments we present three experiments in which different feature sets are used to train the me classifier.
</nextsent>
<nextsent>the first experiment uses only those feature combinations described in gildea and jurafsky (2002)<papid> J02-3001 </papid>(fea ture sets 0-7 from table 1).</nextsent>
<nextsent>the second experiment uses superset of the first and incorporates the syntactic pattern features described above (feature sets 0-9).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1299">
<title id=" W03-1007.xml">maximum entropy models for framenet classification </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>rather, the me approach provides an overarching framework in which the full distribution of semantic roles given syntactic features can be modeled.
</prevsent>
<prevsent>we train the me models using the gis algorithm (darroch and rat cliff, 1972) as implemented in the yasmet me package (och, 2002).
</prevsent>
</prevsection>
<citsent citstr=" E03-1055 ">
we use the yasmet me tagger (bender et al, 2003) <papid> E03-1055 </papid>to perform the viterbi search.</citsent>
<aftsection>
<nextsent>the classifier was trained until performance on the development set ceased to improve.
</nextsent>
<nextsent>feature weights were smoothed using gaussian priors with mean 0 (chen and rosenfeld, 1999).
</nextsent>
<nextsent>the standard deviation of this distribution was optimized on the development set for each experiment.
</nextsent>
<nextsent>classifier performance on test set 81.7 83.6 84.7 78.5 76 78 80 82 84 86 g&j; exp 1 exp 2 exp 3 % or re ct figure 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1309">
<title id=" W02-0805.xml">a study of polysemy and sense proximity in the senseval2 test suite </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we are interested in characterizing wordnet 1.7 as sense inventory for the senseval-2 wsd comparative evaluation.
</prevsent>
<prevsent>unlike conventional dictionaries, wordnet does not group senses of the same word in hierarchical structure; every sense belongs to synset, and can only be related to other senses via conceptual relations (rather than sense relations).
</prevsent>
</prevsection>
<citsent citstr=" C96-1005 ">
conceptual relations can be used to define measures of semantic distance (sussna, 1993; agirre and rigau, 1996; <papid> C96-1005 </papid>resnik, 1995), but topic relatedness is not well captured by wordnet relations, and this is fundamental parameter to estimate sense similarity in many nlp applications (gonzalo et al, 2000).<papid> W00-0802 </papid>the issue of estimating semantic distance between senses of polysemous word has been previously addressed in (resnik and yarowsky, 1997;resnik and yarowsky, 1999).</citsent>
<aftsection>
<nextsent>they propose measure of semantic distance based on the likelihood of the sense distinction being lexicalized in some target language.
</nextsent>
<nextsent>the measure was tested using statistics collected from native-speaker translations of 222polysemous contexts across 12 languages.
</nextsent>
<nextsent>the results obtained showed that monolingual sense dis july 2002, pp.
</nextsent>
<nextsent>32-39.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1310">
<title id=" W02-0805.xml">a study of polysemy and sense proximity in the senseval2 test suite </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we are interested in characterizing wordnet 1.7 as sense inventory for the senseval-2 wsd comparative evaluation.
</prevsent>
<prevsent>unlike conventional dictionaries, wordnet does not group senses of the same word in hierarchical structure; every sense belongs to synset, and can only be related to other senses via conceptual relations (rather than sense relations).
</prevsent>
</prevsection>
<citsent citstr=" W00-0802 ">
conceptual relations can be used to define measures of semantic distance (sussna, 1993; agirre and rigau, 1996; <papid> C96-1005 </papid>resnik, 1995), but topic relatedness is not well captured by wordnet relations, and this is fundamental parameter to estimate sense similarity in many nlp applications (gonzalo et al, 2000).<papid> W00-0802 </papid>the issue of estimating semantic distance between senses of polysemous word has been previously addressed in (resnik and yarowsky, 1997;resnik and yarowsky, 1999).</citsent>
<aftsection>
<nextsent>they propose measure of semantic distance based on the likelihood of the sense distinction being lexicalized in some target language.
</nextsent>
<nextsent>the measure was tested using statistics collected from native-speaker translations of 222polysemous contexts across 12 languages.
</nextsent>
<nextsent>the results obtained showed that monolingual sense dis july 2002, pp.
</nextsent>
<nextsent>32-39.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1315">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most ofthese noun forms are common nouns (nouns describing non-specific members of general class, e.g. detective?).
</prevsent>
<prevsent>only small percentage1 of the nounsin wordnet are proper nouns (nouns describing specific instances, e.g. ?[the detective] columbo?).
</prevsent>
</prevsection>
<citsent citstr=" W98-0706 ">
the wordnet ontology has been widely useful, with applications in information retrieval (sussna, 1993), text classification (scott and matwin, 1998), <papid> W98-0706 </papid>and question answering (pasca and harabagiu, 2001).</citsent>
<aftsection>
<nextsent>these successes have shown that common noun ontologies have wide applicability and utility.
</nextsent>
<nextsent>there exists no ontology with similar coverage and detail for proper nouns.
</nextsent>
<nextsent>prior work in proper noun identification has focused on named entity?
</nextsent>
<nextsent>1a random 100 synset sample was composed of 9% proper nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1316">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> ontologies for question answering.  </section>
<citcontext>
<prevsection>
<prevsent>some of the proper noun types are relatively static (greek gods, kings of babylonia).
</prevsent>
<prevsent>other categories are more ephemeral(lead singers, british actresses).
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
wordnet enumerates 70 greek gods and 80 kings, but no lead singers and no british actresses.ravichandran and hovy (2002) <papid> P02-1006 </papid>present an alternative ontology for type preference and describe method for using this alternative ontology to extract particular answers using surface text patterns.</citsent>
<aftsection>
<nextsent>their proposed ontology is orders of magnitude smaller than wordnet and ontologies considered here, having less than 200 nodes.
</nextsent>
<nextsent>in order to better answer the questions in table 1, we built proper noun ontology from approximately 1gigabyte of ap news wire text.
</nextsent>
<nextsent>to do so, we tok answer white wordnet black grey chromatic colorachromatic color red blue pink color preference type figure 1: using wordnet to directly provide type preferences distance, length light time altitude quantity answer 7 wingspan named entity recognizer wordnet size magnitude amount preference type figure 2: linking wordnet subtrees to named entity recognizer enized and part-of-speech tagged the text, and then searched for instances of common noun followed immediately by proper noun.
</nextsent>
<nextsent>this pattern detects phrases of the form ?[the] automaker mercedes benz?, and is ideally suited for proper nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1317">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> using proper noun ontology in a.  </section>
<citcontext>
<prevsection>
<prevsent>fur ontology correct total precision answered wordnet 127 169 75.1 ipno 46 67 68.6 wn + ipno 145 194 74.7table 4: performance on test corpus when an induced proper noun ontology (ipno) is combined with wordnet ther more, retrieving answers from smaller document spaces may be more difficult than retrieving answers from larger ones, if smaller spaces have less redundant coverage of potential answers.
</prevsent>
<prevsent>in this sentence comprehension task, there is virtually no redundancy.
</prevsent>
</prevsection>
<citsent citstr=" C02-1102 ">
to generate data for this task, we took trivia games, which, along with the question, had full sentence explanation (mann, 2002).<papid> C02-1102 </papid></citsent>
<aftsection>
<nextsent>baseline experiments used the wordnet ontology alone.
</nextsent>
<nextsent>from semantic type preference stated in the question, word was selected from the sentence as an answer if was child of the type preference.
</nextsent>
<nextsent>black?
</nextsent>
<nextsent>would be picked as an answer for color?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1318">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>bill gates is ten billionaire; steve jobs isnt.
</prevsent>
<prevsent>there has been considerable work in the past decade on building ontologies from unrestricted text.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
hearst (1992) <papid> C92-2082 </papid>used textual patterns (e.g. suchas?)</citsent>
<aftsection>
<nextsent>to identify common class members.
</nextsent>
<nextsent>caraballo and charniak (1999) <papid> W99-0609 </papid>and caraballo (1999)<papid> P99-1016 </papid>augmented these lexical patterns with more general lexical co-occurrence statistics (such as relative entropy).</nextsent>
<nextsent>berland and charniak (1999) <papid> P99-1008 </papid>use hearst style techniques to learn meronym relationships (part-whole) from corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1319">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>hearst (1992) <papid> C92-2082 </papid>used textual patterns (e.g. suchas?)</prevsent>
<prevsent>to identify common class members.</prevsent>
</prevsection>
<citsent citstr=" W99-0609 ">
caraballo and charniak (1999) <papid> W99-0609 </papid>and caraballo (1999)<papid> P99-1016 </papid>augmented these lexical patterns with more general lexical co-occurrence statistics (such as relative entropy).</citsent>
<aftsection>
<nextsent>berland and charniak (1999) <papid> P99-1008 </papid>use hearst style techniques to learn meronym relationships (part-whole) from corpora.</nextsent>
<nextsent>there has also been work in building ontologies from structured correct answer question (debbie) reynolds what actress once held the title of miss burbank??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1320">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>hearst (1992) <papid> C92-2082 </papid>used textual patterns (e.g. suchas?)</prevsent>
<prevsent>to identify common class members.</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
caraballo and charniak (1999) <papid> W99-0609 </papid>and caraballo (1999)<papid> P99-1016 </papid>augmented these lexical patterns with more general lexical co-occurrence statistics (such as relative entropy).</citsent>
<aftsection>
<nextsent>berland and charniak (1999) <papid> P99-1008 </papid>use hearst style techniques to learn meronym relationships (part-whole) from corpora.</nextsent>
<nextsent>there has also been work in building ontologies from structured correct answer question (debbie) reynolds what actress once held the title of miss burbank??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1321">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>to identify common class members.
</prevsent>
<prevsent>caraballo and charniak (1999) <papid> W99-0609 </papid>and caraballo (1999)<papid> P99-1016 </papid>augmented these lexical patterns with more general lexical co-occurrence statistics (such as relative entropy).</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
berland and charniak (1999) <papid> P99-1008 </papid>use hearst style techniques to learn meronym relationships (part-whole) from corpora.</citsent>
<aftsection>
<nextsent>there has also been work in building ontologies from structured correct answer question (debbie) reynolds what actress once held the title of miss burbank??
</nextsent>
<nextsent>(jim) lovell which astronaut did tom hanks play in apollo 13??
</nextsent>
<nextsent>xerxes which persian king moved an invasion force across the hellespont on bridge of ships?
</nextsent>
<nextsent>(donna) summer what was the name of the female disco singer who scored with the tune dim all the lights?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1322">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, we present initial results which attempt to gauge coverage improvement as result of the induced ontology.
</prevsent>
<prevsent>another related line of work is word clustering.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
in these experiments, the attempt is made to cluster similar nouns, without regard to forming hierarchy.pereira et al (1993) <papid> P93-1024 </papid>presented initial work, clustering nouns using their noun-verb co-occurrence information.</citsent>
<aftsection>
<nextsent>riloff and lehnert (1993) build semantic lexicons using extraction pattern co-occurrence.lin and pantel (2001) extend these methods by using many different types of relations and exploiting corpora of tremendous size.
</nextsent>
<nextsent>the important difference for this work between the hierarchical methods and the clustering methods is that clusters are unlabelled.
</nextsent>
<nextsent>the hierarchical methods can identify that jeep cherokee?
</nextsent>
<nextsent>is type of car.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1323">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>generating labels for proper noun clusters may be another way to build proper noun ontology.
</prevsent>
<prevsent>the method we use to build the fine-grained proper name ontology also resembles some of thework done in coarse-grained named entity recognition.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
in particular, collins and singer (1999) <papid> W99-0613 </papid>pre senta sophisticated method for using bootstrapping techniques to learn the coarse-classification forgiven proper noun.</citsent>
<aftsection>
<nextsent>riloff and jones (1999) also present amethod to use bootstrapping to create semantic lexicons of proper nouns.
</nextsent>
<nextsent>these methods may be applicable for use in fine-grained proper noun ontology construction as well.schiffman et al (2001) <papid> P01-1059 </papid>describe work on producing biographical summaries.</nextsent>
<nextsent>this work attempts to synthesize one description of person from multiple mentions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1324">
<title id=" W02-1111.xml">fine grained proper noun ontologies for question answering </title>
<section> prior work in building ontologies.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, collins and singer (1999) <papid> W99-0613 </papid>pre senta sophisticated method for using bootstrapping techniques to learn the coarse-classification forgiven proper noun.</prevsent>
<prevsent>riloff and jones (1999) also present amethod to use bootstrapping to create semantic lexicons of proper nouns.</prevsent>
</prevsection>
<citsent citstr=" P01-1059 ">
these methods may be applicable for use in fine-grained proper noun ontology construction as well.schiffman et al (2001) <papid> P01-1059 </papid>describe work on producing biographical summaries.</citsent>
<aftsection>
<nextsent>this work attempts to synthesize one description of person from multiple mentions.
</nextsent>
<nextsent>this summary is an end in itself, as opposed to general knowledge collected.
</nextsent>
<nextsent>these descriptions also attempt to be parsimonious in contrast to the rather free associations extracted by the method presented above.
</nextsent>
<nextsent>in this paper we have motivated the use of proper noun ontology for question answering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1325">
<title id=" W02-1101.xml">knowledge based multilingual document analysis </title>
<section> the namic architecture.  </section>
<citcontext>
<prevsection>
<prevsent>this proces sis explained in more detail in 4.
</prevsent>
<prevsent>in the next two sections, we will elaborate on the ie engine.
</prevsent>
</prevsection>
<citsent citstr=" W01-1013 ">
for full description of the namic architecture see (basili et al., 2001).<papid> W01-1013 </papid></citsent>
<aftsection>
<nextsent>3.1 lasie.
</nextsent>
<nextsent>in namic, we have integrated key part of the information extraction system called lasie (large-scale information extraction system, (humphreys et al, 1998)).<papid> M98-1007 </papid></nextsent>
<nextsent>specifically, we have taken the named entitymatcher and the discourse processor from the over all architecture of lasie.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1326">
<title id=" W02-1101.xml">knowledge based multilingual document analysis </title>
<section> the namic architecture.  </section>
<citcontext>
<prevsection>
<prevsent>for full description of the namic architecture see (basili et al., 2001).<papid> W01-1013 </papid></prevsent>
<prevsent>3.1 lasie.</prevsent>
</prevsection>
<citsent citstr=" M98-1007 ">
in namic, we have integrated key part of the information extraction system called lasie (large-scale information extraction system, (humphreys et al, 1998)).<papid> M98-1007 </papid></citsent>
<aftsection>
<nextsent>specifically, we have taken the named entitymatcher and the discourse processor from the over all architecture of lasie.
</nextsent>
<nextsent>the roles of each of these modules is outlined below.
</nextsent>
<nextsent>3.1.1 named entity matcherthe named entity (ne) matcher finds named entities (persons, organisations, locations, and dates, in our case) through secondary phase of parsing which uses ne grammar and set of gazetteer lists.
</nextsent>
<nextsent>it takes as input parsed text from the first phase of parsing and the ne grammar which contains rules for finding predefined set of named entities and set of gazetteer lists containing proper nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1327">
<title id=" W02-1101.xml">knowledge based multilingual document analysis </title>
<section> large-scale world model acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>4.2.1 eurowordneteurowordnet (vossen, 1998) is multilingual lexical knowledge (kb) base comprised of hierarchical representations of lexical items for several european languages (dutch, italian, spanish, german, french, czech and estonian).
</prevsent>
<prevsent>the wordnets are structured in the same way as the english wordnet developed at princeton (miller, 1990) in terms of synsets (sets of synonymous words) with basic semantic relations between them.in addition, the wordnets are linked to an interlingual-index (ili), based on the princeton wordnet 1.5.
</prevsent>
</prevsection>
<citsent citstr=" P00-1064 ">
(wordnet 1.6 is also connected to the ilias another english wordnet (daude et al, 2000)).<papid> P00-1064 </papid></citsent>
<aftsection>
<nextsent>via this index, the languages are interconnected sothat it is possible to go from concepts in one language to concepts in any other language having similar meaning.
</nextsent>
<nextsent>such an index also gives access to ashared top-ontology and subset of 1024 base concepts (bc).
</nextsent>
<nextsent>the base concepts provide common semantic framework for all the languages, while language specific properties are maintained in the individual wordnets.
</nextsent>
<nextsent>the kb can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (gonzalo et al, 1998).<papid> W98-0705 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1328">
<title id=" W02-1101.xml">knowledge based multilingual document analysis </title>
<section> large-scale world model acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>such an index also gives access to ashared top-ontology and subset of 1024 base concepts (bc).
</prevsent>
<prevsent>the base concepts provide common semantic framework for all the languages, while language specific properties are maintained in the individual wordnets.
</prevsent>
</prevsection>
<citsent citstr=" W98-0705 ">
the kb can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (gonzalo et al, 1998).<papid> W98-0705 </papid></citsent>
<aftsection>
<nextsent>4.2.2 euro wordnet as the object ontology the example rules shown in the previous section relate to agents which conveniently belong to class of named entities as would be easily recognised under the muc competition rules (person, company and location for example).
</nextsent>
<nextsent>however, majority of the rules extracted automatically from the corpus data involved other kinds of semantic classes of information which play key roles in the subcategorisation patterns of the verbs.
</nextsent>
<nextsent>in order to be able to work with these patterns,it was necessary to extend the number of semantic classes beyond the usual number of predefined classes, across variety of languages.representing the entirety of ewn in our object hierarchy would be time consuming, and lead to inefficient processing times.
</nextsent>
<nextsent>instead we took advantage of the base concepts (rodriquez et al, 1998) withinewn, set of approximately 1000 nodes, with hierarchical structure, that can be used to generalise the rest of the ewn hierarchy.these base concepts represent core set of common concepts to be covered for every language that has been defined in ewn.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1329">
<title id=" W03-0209.xml">automated rating of esl essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, computerized rating of essays writ tenby second-language speakers poses unique dilemmas, particularly for responses written by examinees at low levels of language proficiency.
</prevsent>
<prevsent>wherewe expect generally well-formed sentences from native english speaker responses, we find that the majority of the responses by lower proficiency second language english speakers will be made up of illformed sentences.
</prevsent>
</prevsection>
<citsent citstr=" W99-0411 ">
previous work in automated essay grading and related technologies has been surveyed and discussed in several different forums (burstein and chodorow, 1999; <papid> W99-0411 </papid>thompson, 1999; hearst, 2000; williams, 2001; rudner and gagne, 2001), and thorough survey of the field has recently been published (shermis and burstein, 2003).</citsent>
<aftsection>
<nextsent>typically these approaches have borrowed techniques and tools from several natural language processing(nlp) fields.
</nextsent>
<nextsent>for example, the knowledge-based engines have been used for analyzing essays: parsers (carbonell and hayes, 1984; schneider and mccoy, 1998), <papid> P98-2196 </papid>grammar and spelling checkers (park et al, 1997), <papid> A97-2014 </papid>discourse processing analyzers (miltsakaki and kukich, 2000), <papid> P00-1052 </papid>and other hand-crafted linguistic knowledge sources.</nextsent>
<nextsent>linkage 1, cost vector = (unused=0 dis=1 and=0 len=20) +-------------------------------xp------------------------------+ +--------------wd--------------+ | | +----------co---------+ | | +--------xc--------+ | | | +-----jp----+ | | +------op-----+ | | | +--dmu-+ | +-sp*i+--ppf-+ +--dmc-+ | | | | | | | | | | | | left-wall during my schooling.n , i.p have.v taken.v many classes.n . figure 1: sample link-parsed sentence with associated cost vector.on the other hand, much work has leveraged statistical methods in detecting properties of student essays via stylo metrics (aaronson, 2001)1, latent semantic indexing (wiemer-hastings et al, 1998), and feature analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1330">
<title id=" W03-0209.xml">automated rating of esl essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in automated essay grading and related technologies has been surveyed and discussed in several different forums (burstein and chodorow, 1999; <papid> W99-0411 </papid>thompson, 1999; hearst, 2000; williams, 2001; rudner and gagne, 2001), and thorough survey of the field has recently been published (shermis and burstein, 2003).</prevsent>
<prevsent>typically these approaches have borrowed techniques and tools from several natural language processing(nlp) fields.</prevsent>
</prevsection>
<citsent citstr=" P98-2196 ">
for example, the knowledge-based engines have been used for analyzing essays: parsers (carbonell and hayes, 1984; schneider and mccoy, 1998), <papid> P98-2196 </papid>grammar and spelling checkers (park et al, 1997), <papid> A97-2014 </papid>discourse processing analyzers (miltsakaki and kukich, 2000), <papid> P00-1052 </papid>and other hand-crafted linguistic knowledge sources.</citsent>
<aftsection>
<nextsent>linkage 1, cost vector = (unused=0 dis=1 and=0 len=20) +-------------------------------xp------------------------------+ +--------------wd--------------+ | | +----------co---------+ | | +--------xc--------+ | | | +-----jp----+ | | +------op-----+ | | | +--dmu-+ | +-sp*i+--ppf-+ +--dmc-+ | | | | | | | | | | | | left-wall during my schooling.n , i.p have.v taken.v many classes.n . figure 1: sample link-parsed sentence with associated cost vector.on the other hand, much work has leveraged statistical methods in detecting properties of student essays via stylo metrics (aaronson, 2001)1, latent semantic indexing (wiemer-hastings et al, 1998), and feature analysis.
</nextsent>
<nextsent>finally, mirroring noteworthy progress in other nlp fields involving data-driven methods, recent work has involved essay grading via exemplar-basedmachine learning techniques (chodorow and leacock, 2000).<papid> A00-2019 </papid></nextsent>
<nextsent>the most visible systems implement one (or more) of these approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1331">
<title id=" W03-0209.xml">automated rating of esl essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in automated essay grading and related technologies has been surveyed and discussed in several different forums (burstein and chodorow, 1999; <papid> W99-0411 </papid>thompson, 1999; hearst, 2000; williams, 2001; rudner and gagne, 2001), and thorough survey of the field has recently been published (shermis and burstein, 2003).</prevsent>
<prevsent>typically these approaches have borrowed techniques and tools from several natural language processing(nlp) fields.</prevsent>
</prevsection>
<citsent citstr=" A97-2014 ">
for example, the knowledge-based engines have been used for analyzing essays: parsers (carbonell and hayes, 1984; schneider and mccoy, 1998), <papid> P98-2196 </papid>grammar and spelling checkers (park et al, 1997), <papid> A97-2014 </papid>discourse processing analyzers (miltsakaki and kukich, 2000), <papid> P00-1052 </papid>and other hand-crafted linguistic knowledge sources.</citsent>
<aftsection>
<nextsent>linkage 1, cost vector = (unused=0 dis=1 and=0 len=20) +-------------------------------xp------------------------------+ +--------------wd--------------+ | | +----------co---------+ | | +--------xc--------+ | | | +-----jp----+ | | +------op-----+ | | | +--dmu-+ | +-sp*i+--ppf-+ +--dmc-+ | | | | | | | | | | | | left-wall during my schooling.n , i.p have.v taken.v many classes.n . figure 1: sample link-parsed sentence with associated cost vector.on the other hand, much work has leveraged statistical methods in detecting properties of student essays via stylo metrics (aaronson, 2001)1, latent semantic indexing (wiemer-hastings et al, 1998), and feature analysis.
</nextsent>
<nextsent>finally, mirroring noteworthy progress in other nlp fields involving data-driven methods, recent work has involved essay grading via exemplar-basedmachine learning techniques (chodorow and leacock, 2000).<papid> A00-2019 </papid></nextsent>
<nextsent>the most visible systems implement one (or more) of these approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1332">
<title id=" W03-0209.xml">automated rating of esl essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in automated essay grading and related technologies has been surveyed and discussed in several different forums (burstein and chodorow, 1999; <papid> W99-0411 </papid>thompson, 1999; hearst, 2000; williams, 2001; rudner and gagne, 2001), and thorough survey of the field has recently been published (shermis and burstein, 2003).</prevsent>
<prevsent>typically these approaches have borrowed techniques and tools from several natural language processing(nlp) fields.</prevsent>
</prevsection>
<citsent citstr=" P00-1052 ">
for example, the knowledge-based engines have been used for analyzing essays: parsers (carbonell and hayes, 1984; schneider and mccoy, 1998), <papid> P98-2196 </papid>grammar and spelling checkers (park et al, 1997), <papid> A97-2014 </papid>discourse processing analyzers (miltsakaki and kukich, 2000), <papid> P00-1052 </papid>and other hand-crafted linguistic knowledge sources.</citsent>
<aftsection>
<nextsent>linkage 1, cost vector = (unused=0 dis=1 and=0 len=20) +-------------------------------xp------------------------------+ +--------------wd--------------+ | | +----------co---------+ | | +--------xc--------+ | | | +-----jp----+ | | +------op-----+ | | | +--dmu-+ | +-sp*i+--ppf-+ +--dmc-+ | | | | | | | | | | | | left-wall during my schooling.n , i.p have.v taken.v many classes.n . figure 1: sample link-parsed sentence with associated cost vector.on the other hand, much work has leveraged statistical methods in detecting properties of student essays via stylo metrics (aaronson, 2001)1, latent semantic indexing (wiemer-hastings et al, 1998), and feature analysis.
</nextsent>
<nextsent>finally, mirroring noteworthy progress in other nlp fields involving data-driven methods, recent work has involved essay grading via exemplar-basedmachine learning techniques (chodorow and leacock, 2000).<papid> A00-2019 </papid></nextsent>
<nextsent>the most visible systems implement one (or more) of these approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1333">
<title id=" W03-0209.xml">automated rating of esl essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the knowledge-based engines have been used for analyzing essays: parsers (carbonell and hayes, 1984; schneider and mccoy, 1998), <papid> P98-2196 </papid>grammar and spelling checkers (park et al, 1997), <papid> A97-2014 </papid>discourse processing analyzers (miltsakaki and kukich, 2000), <papid> P00-1052 </papid>and other hand-crafted linguistic knowledge sources.</prevsent>
<prevsent>linkage 1, cost vector = (unused=0 dis=1 and=0 len=20) +-------------------------------xp------------------------------+ +--------------wd--------------+ | | +----------co---------+ | | +--------xc--------+ | | | +-----jp----+ | | +------op-----+ | | | +--dmu-+ | +-sp*i+--ppf-+ +--dmc-+ | | | | | | | | | | | | left-wall during my schooling.n , i.p have.v taken.v many classes.n . figure 1: sample link-parsed sentence with associated cost vector.on the other hand, much work has leveraged statistical methods in detecting properties of student essays via stylo metrics (aaronson, 2001)1, latent semantic indexing (wiemer-hastings et al, 1998), and feature analysis.</prevsent>
</prevsection>
<citsent citstr=" A00-2019 ">
finally, mirroring noteworthy progress in other nlp fields involving data-driven methods, recent work has involved essay grading via exemplar-basedmachine learning techniques (chodorow and leacock, 2000).<papid> A00-2019 </papid></citsent>
<aftsection>
<nextsent>the most visible systems implement one (or more) of these approaches.
</nextsent>
<nextsent>the project essay grade (peg) system, for example, uses lexicallybased metrics in scoring (page, 2003).
</nextsent>
<nextsent>the intelligent essay assessor (iea) uses latent semantic analysis in calculating its metrics (landauer et al, 2003).
</nextsent>
<nextsent>the e-rater system by educational testing services uses syntactic, discourse, and topical (i.e. vocabulary-based) data analysis (burstein, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1334">
<title id=" W02-1502.xml">the grammar matrix an open source starter kit for the rapid development of cross linguistically consistent broad coverage precision grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by using type hierarchy to represent cross-linguistic generalizations and providing compatibility with other open-source tools for grammar engineering,evaluation, parsing and generation, it facilitates not only quick start-up but also rapid growth towards the wide coverage necessary for robust natural language processing andthe precision parses and semantic representations necessary for natural language understanding.
</prevsent>
<prevsent>the past decade has seen the development ofwide-coverage implemented grammars representing deep linguistic analysis of several languages in several frameworks, including head-drivenphrase structure grammar (hpsg), lexical functional grammar (lfg), and lexicalized tree adjoining grammar (ltag).
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
in hpsg, the most extensive grammars are those of english (flickinger, 2000), german (muller &amp; kasper, 2000), and japanese (siegel, 2000; siegel &amp; bender, 2002).<papid> W02-1210 </papid>despite being couched in the same general framework and in some cases being written in thesame formalism and consequently being compatible with the same parsing and generation software,these grammars were developed more or less independently of each other.</citsent>
<aftsection>
<nextsent>they each represent between 5 and 15 person years of research efforts,and comprise 3570,000 lines of code.
</nextsent>
<nextsent>unfortunately, most of that research is undocumented and the accumulated analyses, best practices for grammar engineering, and tricks of the trade are only available through painstaking inspection ofthe grammars and/or consultation with their authors.
</nextsent>
<nextsent>this lack of documentation holds across frameworks, with certain notable exceptions, including alshawi (1992), muller (1999), and butt, king, nino, &amp; segond (1999).
</nextsent>
<nextsent>grammars which have been underdevelopment for many years tend to be very difficult to mine for information, as they contain layers upon layers of interacting analyses and decisions made in light of various intermediate stages of the grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1335">
<title id=" W02-1502.xml">the grammar matrix an open source starter kit for the rapid development of cross linguistically consistent broad coverage precision grammars </title>
<section> a detailed example </section>
<citcontext>
<prevsection>
<prevsent>the user groups have suggested refinements and extensions of the basic inventory, and it is expected that general solutions, as they are identified jointly, will propagate into the existing grammars too.
</prevsent>
<prevsent>as an example of the level of detail involved in the grammar matrix, in this section we consider the analysis of intersec tive and scopal modification.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
the matrix is built to give minimal recursionsemantics (mrs; copestake et al, 2001; <papid> P01-1019 </papid>copestake, flickinger, sag, &amp; pollard, 1999; copestake,flickinger, malouf, riehemann, &amp; sag, 1995) rep resentations.</citsent>
<aftsection>
<nextsent>the two english examples in (1) exemplify the difference between intersec tive and scopal modification:1 (1) a. keanu studied kung fu on spaceship.
</nextsent>
<nextsent>b. keanu probably studied kung fu.
</nextsent>
<nextsent>the mrss for (1a-b) (abstracting away from agreement information) are given in (2) and (3).
</nextsent>
<nextsent>the mrss are ordered tuples consisting of top handle (h1 in both cases), an instance or event variable (e in both cases), bag of elementary predica tions (eps), and bag of scope constraints (in these cases, qeq constraints or equal modulo quanti fiers?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1336">
<title id=" W02-1502.xml">the grammar matrix an open source starter kit for the rapid development of cross linguistically consistent broad coverage precision grammars </title>
<section> future extensions.  </section>
<citcontext>
<prevsection>
<prevsent>extensions for dialect variation will build on some exploratory work in adapting the english grammar to support american, british,and australian regional isms, both lexical and syntactic, while restricting dialect mixture in generation and associated spurious ambiguity in parsing.
</prevsent>
<prevsent>while the development of the matrix will be built largely on the lkb platform, support will also be needed for using the emerging grammars on other processing platforms, and for linking to other packages for pre-processing the linguistic input.
</prevsent>
</prevsection>
<citsent citstr=" C94-1072 ">
several other platforms exist which can efficiently parse text using the existing grammars, including the pet system developed in c++ at saarland university (germany) and the dfki (callmeier, 2000); the page system developed in lisp at the dfki (uszkoreit et al, 1994); <papid> C94-1072 </papid>the lilfes system developed at tokyo university (makino, yoshida,torisawa, &amp; tsujii, 1998), and parallel processing system developed in objective at delft university (the netherlands; van lohuizen, 2002).as part of the matrix package, sample configuration files and documentation will be provided for at least some of these additional platforms.existing pre-processing packages can also significantly reduce the effort required to develop new grammar, particularly for coping with the morphology/syntax interface.</citsent>
<aftsection>
<nextsent>for example, the chasen package for segmenting japanese input into words and morphemes (asahara &amp; matsumoto, 2000) <papid> C00-1004 </papid>has been linked to at least the lkband pet systems.</nextsent>
<nextsent>support for connecting implementations of language-specific pre-processingpackages of this kind will be preserved and extended as the matrix develops.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1337">
<title id=" W02-1502.xml">the grammar matrix an open source starter kit for the rapid development of cross linguistically consistent broad coverage precision grammars </title>
<section> future extensions.  </section>
<citcontext>
<prevsection>
<prevsent>while the development of the matrix will be built largely on the lkb platform, support will also be needed for using the emerging grammars on other processing platforms, and for linking to other packages for pre-processing the linguistic input.
</prevsent>
<prevsent>several other platforms exist which can efficiently parse text using the existing grammars, including the pet system developed in c++ at saarland university (germany) and the dfki (callmeier, 2000); the page system developed in lisp at the dfki (uszkoreit et al, 1994); <papid> C94-1072 </papid>the lilfes system developed at tokyo university (makino, yoshida,torisawa, &amp; tsujii, 1998), and parallel processing system developed in objective at delft university (the netherlands; van lohuizen, 2002).as part of the matrix package, sample configuration files and documentation will be provided for at least some of these additional platforms.existing pre-processing packages can also significantly reduce the effort required to develop new grammar, particularly for coping with the morphology/syntax interface.</prevsent>
</prevsection>
<citsent citstr=" C00-1004 ">
for example, the chasen package for segmenting japanese input into words and morphemes (asahara &amp; matsumoto, 2000) <papid> C00-1004 </papid>has been linked to at least the lkband pet systems.</citsent>
<aftsection>
<nextsent>support for connecting implementations of language-specific pre-processingpackages of this kind will be preserved and extended as the matrix develops.
</nextsent>
<nextsent>likewise, configuration files are included to support generation, at least within the lkb, provided that the grammar conforms to certain assumptions about semantic representation using the minimal recur sion semantics framework.
</nextsent>
<nextsent>finally, methodology is underdevelopment for constructing and using test suites organized arounda typology of linguistic phenomena, using the implementation platform of the [incr tsdb()] profiling package (oepen &amp; flickinger, 1998; oepen &amp; callmeier, 2000).
</nextsent>
<nextsent>these test suites will enable better communication about current coverage of given grammar built using the matrix, and serve as the basis for identifying additional phenomena that need to be addressed cross-linguistically within thematrix.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1338">
<title id=" W02-1502.xml">the grammar matrix an open source starter kit for the rapid development of cross linguistically consistent broad coverage precision grammars </title>
<section> evaluation and evolution.  </section>
<citcontext>
<prevsection>
<prevsent>this raises the question of how to propagate changes in the matrix to grammars based on earlier versions.
</prevsent>
<prevsent>the following three strategies (meant to be used in combination)seem promising: (i) segregate changes that are important to sync to (e.g., changes that affect mrs outputs, fundamental changes to important analyses), (ii) develop methodology for communicating changes in the matrix, their motivation and their implementation to the user community, and (iii) develop tools for semi-automating re synching of existing grammars to upgrades of the matrix.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
these tools could use the type hierarchy to predict where conflicts are likely to arise and bring these to the engineers attention, possibly inspired by the approach underdevelopment at csli for the dynamic maintenance of the lingo redwoods tree bank (oepen et al, 2002).<papid> C02-2025 </papid>finally, while initial development of the matrix has been and will continue to be highly centralized, we hope to provide support for proposed matrix improvements from the user community.</citsent>
<aftsection>
<nextsent>user feedback will already come in the form ofcase studies for the library as discussed in section 5 above, but also potentially in proposals for modification of the matrix drawing on experiences in grammar development.
</nextsent>
<nextsent>in order to provide users with some cross-linguistic context in which to develop and evaluate such proposals themselves, we intend to provide some sample matrix-derived grammars and corresponding test suites with the matrix.
</nextsent>
<nextsent>a user could thus make proposed chang eto the matrix, run the test suites for several languages using the supplied grammars which draw from that changed matrix, and use [incr tsdb()] to determine which phenomena have been affected by the change.
</nextsent>
<nextsent>it is clear that full automation of this evaluation process will be difficult, but at least some classes of changes to the matrix will permit this kind of quick cross-linguistic feedback tousers with only modest amount of additional infrastructure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1339">
<title id=" W03-1802.xml">conceptual structuring through term variations </title>
<section> automatic discovery and structuring.  </section>
<citcontext>
<prevsection>
<prevsent>this over generation method used in information retrieval by (jacquemin, 2001) gives low noise because the base noun must not only be an attested form in the corpus, but must also appear as an extension of head noun.
</prevsent>
<prevsent>at the end of the linguistic processing, the term extractor proposes as output:1.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
a list of pilot terms ranked from the most representative of the corpus to the least thanks to theloglikelihood coefficient introduced by (dun ning, 1993).<papid> J93-1003 </papid>2.</citsent>
<aftsection>
<nextsent>for each pilot term, xml structure is provided which gathers all the base structures and the variations encountered.
</nextsent>
<nextsent>an example of such data is given in figure in table 1.
</nextsent>
<nextsent>4.2 conceptual structuring.
</nextsent>
<nextsent>the conceptual structuring takes as input the data provided by the first step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1340">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also compare three variant syntactic representations to determine which one has the best properties with respect to cohesion.
</prevsent>
<prevsent>statistical machine translation (smt) seeks to develop mathematical models of the translation process whose parameters can be automatically estimated from parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the first work in smt, done at ibm (brown et al, 1993), <papid> J93-2003 </papid>develop eda noisy-channel model, factoring the translation process into two portions: the translation model and the language model.</citsent>
<aftsection>
<nextsent>the translation model captures the translation of source language words into the target language and the reordering of those words.
</nextsent>
<nextsent>the language model ranks the outputs of the translation model by how well they adhere to the syntactic constraints of the target language.1the prime deficiency of the ibm model is there ordering component.
</nextsent>
<nextsent>even in the most complex of 1though usually simple word n-gram model is used for the language model.
</nextsent>
<nextsent>the five ibm models, the reordering operation pays little attention to context and none at all to higher level syntactic structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1341">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many attempts have been made to remedy this by incorporating syntactic information into translation models.
</prevsent>
<prevsent>these have taken several different forms, but all share the basic assumption that phrases in one language tend to stay together (i.e. cohere) during translation and thus the word-reordering operation can move entire phrases, rather than moving each word independently.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
(yarowsky et al, 2001) <papid> H01-1035 </papid>states that during their work on noun phrase bracketing they found strong cohesion among noun phrases, even when comparing english to czech, relatively free word order language.</citsent>
<aftsection>
<nextsent>other than this, there is little in thesmt literature to validate the coherence assumption.
</nextsent>
<nextsent>several studies have reported alignment or translation performance for syntactically augmented translation models (wu, 1997; <papid> J97-3002 </papid>wang, 1998; alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>jones andhavrilla, 1998) and these results have been promising.</nextsent>
<nextsent>however, without focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1342">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(yarowsky et al, 2001) <papid> H01-1035 </papid>states that during their work on noun phrase bracketing they found strong cohesion among noun phrases, even when comparing english to czech, relatively free word order language.</prevsent>
<prevsent>other than this, there is little in thesmt literature to validate the coherence assump tion.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
several studies have reported alignment or translation performance for syntactically augmented translation models (wu, 1997; <papid> J97-3002 </papid>wang, 1998; alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>jones andhavrilla, 1998) and these results have been promising.</citsent>
<aftsection>
<nextsent>however, without focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face.
</nextsent>
<nextsent>the particulars of cohesion will clearly depend upon the pair of languages being compared.
</nextsent>
<nextsent>intuitively, we expect that while french and spanish will have high degree of cohesion, french and japanese may not.
</nextsent>
<nextsent>it is also clear that if the cohesion between two closely related languages is not high enough to be useful, then there is no hope for these methods when applied to distantly related languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1343">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(yarowsky et al, 2001) <papid> H01-1035 </papid>states that during their work on noun phrase bracketing they found strong cohesion among noun phrases, even when comparing english to czech, relatively free word order language.</prevsent>
<prevsent>other than this, there is little in thesmt literature to validate the coherence assump tion.</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
several studies have reported alignment or translation performance for syntactically augmented translation models (wu, 1997; <papid> J97-3002 </papid>wang, 1998; alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>jones andhavrilla, 1998) and these results have been promising.</citsent>
<aftsection>
<nextsent>however, without focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face.
</nextsent>
<nextsent>the particulars of cohesion will clearly depend upon the pair of languages being compared.
</nextsent>
<nextsent>intuitively, we expect that while french and spanish will have high degree of cohesion, french and japanese may not.
</nextsent>
<nextsent>it is also clear that if the cohesion between two closely related languages is not high enough to be useful, then there is no hope for these methods when applied to distantly related languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1344">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(yarowsky et al, 2001) <papid> H01-1035 </papid>states that during their work on noun phrase bracketing they found strong cohesion among noun phrases, even when comparing english to czech, relatively free word order language.</prevsent>
<prevsent>other than this, there is little in thesmt literature to validate the coherence assump tion.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
several studies have reported alignment or translation performance for syntactically augmented translation models (wu, 1997; <papid> J97-3002 </papid>wang, 1998; alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>jones andhavrilla, 1998) and these results have been promising.</citsent>
<aftsection>
<nextsent>however, without focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face.
</nextsent>
<nextsent>the particulars of cohesion will clearly depend upon the pair of languages being compared.
</nextsent>
<nextsent>intuitively, we expect that while french and spanish will have high degree of cohesion, french and japanese may not.
</nextsent>
<nextsent>it is also clear that if the cohesion between two closely related languages is not high enough to be useful, then there is no hope for these methods when applied to distantly related languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1345">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 data.
</prevsent>
<prevsent>to calculate spans, we need aligned pairs of english and french sentences along with parses for the english sentences.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
our aligned data comes from corpus described in (och and ney, 2000) <papid> P00-1056 </papid>which contains 500 sentence pairs randomly selected from the canadian hansard corpus and manually aligned.the alignments are of two types: sure (s) and possible (p).</citsent>
<aftsection>
<nextsent>s alignments are those which are unam situation .[ne not vraiment la0 1 2 3 4 5 6 7 pas][modifie]on change prp aux rb rb vb dt nn . do not thethey really change status . np vp advp np vp figure 1: alignment example with crossing biguous while alignments are those which are less certain.
</nextsent>
<nextsent>p alignments often appear when phrase in one language translates as unit into phrase in the other language (e.g. idioms, free translations, missing function words) but can also be the result of genuine ambiguity.
</nextsent>
<nextsent>when two annotators disagree, the union of the alignments produced by each annotator is recorded as the alignment in the corpus.
</nextsent>
<nextsent>when an alignment exists, there will always also exist p alignment such that a s. the english sentences were parsed using state-of-the-art statistical parser (charniak, 2000) <papid> A00-2018 </papid>trained on the university of pennsylvania treebank (marcus et al, 1993).<papid> J93-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1346">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>p alignments often appear when phrase in one language translates as unit into phrase in the other language (e.g. idioms, free translations, missing function words) but can also be the result of genuine ambiguity.
</prevsent>
<prevsent>when two annotators disagree, the union of the alignments produced by each annotator is recorded as the alignment in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
when an alignment exists, there will always also exist p alignment such that a s. the english sentences were parsed using state-of-the-art statistical parser (charniak, 2000) <papid> A00-2018 </papid>trained on the university of pennsylvania treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>3.2 phrasal translation filtering.
</nextsent>
<nextsent>je invoque le re`glement orderofpointon arise prp nnnndtvbp in in npnpnp pp np pp vp figure 2: phrasal translation example since alignments often align phrasal transla phrasal filter off phrasal filter on alignment type s   p s   p head crossings 0.236 4.790 5.284 0.172 2.772 2.492 modifier crossings 0.056 0.880 0.988 0.048 0.516 0.362 phrasal translations ? ?
</nextsent>
<nextsent>0.072 2.382 3.418 table 1: average number of crossings per sentence tions, the number of crossings when alignments are used will be artificially inflated.
</nextsent>
<nextsent>for example, in figure 2 note that every pair of english and french words under the verb phrase is aligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1347">
<title id=" W02-1039.xml">phrasal cohesion and statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>p alignments often appear when phrase in one language translates as unit into phrase in the other language (e.g. idioms, free translations, missing function words) but can also be the result of genuine ambiguity.
</prevsent>
<prevsent>when two annotators disagree, the union of the alignments produced by each annotator is recorded as the alignment in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
when an alignment exists, there will always also exist p alignment such that a s. the english sentences were parsed using state-of-the-art statistical parser (charniak, 2000) <papid> A00-2018 </papid>trained on the university of pennsylvania treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>3.2 phrasal translation filtering.
</nextsent>
<nextsent>je invoque le re`glement orderofpointon arise prp nnnndtvbp in in npnpnp pp np pp vp figure 2: phrasal translation example since alignments often align phrasal transla phrasal filter off phrasal filter on alignment type s   p s   p head crossings 0.236 4.790 5.284 0.172 2.772 2.492 modifier crossings 0.056 0.880 0.988 0.048 0.516 0.362 phrasal translations ? ?
</nextsent>
<nextsent>0.072 2.382 3.418 table 1: average number of crossings per sentence tions, the number of crossings when alignments are used will be artificially inflated.
</nextsent>
<nextsent>for example, in figure 2 note that every pair of english and french words under the verb phrase is aligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1348">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>further results show that this form of co-training considerably outperforms self-training.
</prevsent>
<prevsent>however, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results toagreement-based co-training, with only fraction of the computational cost.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
co-training (blum and mitchell, 1998), and several variants of co-training, have been applied to number of nlp problems, including word sense disambiguation (yarowsky, 1995), <papid> P95-1026 </papid>named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001) <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>in each case, co-training was used successfully to bootstrap model from only small amount of labelled data and much larger pool of un labelled data.
</nextsent>
<nextsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</nextsent>
<nextsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</nextsent>
<nextsent>agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1349">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>further results show that this form of co-training considerably outperforms self-training.
</prevsent>
<prevsent>however, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results toagreement-based co-training, with only fraction of the computational cost.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
co-training (blum and mitchell, 1998), and several variants of co-training, have been applied to number of nlp problems, including word sense disambiguation (yarowsky, 1995), <papid> P95-1026 </papid>named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001) <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>in each case, co-training was used successfully to bootstrap model from only small amount of labelled data and much larger pool of un labelled data.
</nextsent>
<nextsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</nextsent>
<nextsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</nextsent>
<nextsent>agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1350">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>further results show that this form of co-training considerably outperforms self-training.
</prevsent>
<prevsent>however, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results toagreement-based co-training, with only fraction of the computational cost.
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
co-training (blum and mitchell, 1998), and several variants of co-training, have been applied to number of nlp problems, including word sense disambiguation (yarowsky, 1995), <papid> P95-1026 </papid>named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001) <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>in each case, co-training was used successfully to bootstrap model from only small amount of labelled data and much larger pool of un labelled data.
</nextsent>
<nextsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</nextsent>
<nextsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</nextsent>
<nextsent>agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1351">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>further results show that this form of co-training considerably outperforms self-training.
</prevsent>
<prevsent>however, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results toagreement-based co-training, with only fraction of the computational cost.
</prevsent>
</prevsection>
<citsent citstr=" N01-1023 ">
co-training (blum and mitchell, 1998), and several variants of co-training, have been applied to number of nlp problems, including word sense disambiguation (yarowsky, 1995), <papid> P95-1026 </papid>named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001) <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>in each case, co-training was used successfully to bootstrap model from only small amount of labelled data and much larger pool of un labelled data.
</nextsent>
<nextsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</nextsent>
<nextsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</nextsent>
<nextsent>agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1352">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>further results show that this form of co-training considerably outperforms self-training.
</prevsent>
<prevsent>however, we find that simply re-training on all the newly labelled data can, in some cases, yield comparable results toagreement-based co-training, with only fraction of the computational cost.
</prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
co-training (blum and mitchell, 1998), and several variants of co-training, have been applied to number of nlp problems, including word sense disambiguation (yarowsky, 1995), <papid> P95-1026 </papid>named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>noun phrase bracketing (pierce and cardie, 2001) <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>in each case, co-training was used successfully to bootstrap model from only small amount of labelled data and much larger pool of un labelled data.
</nextsent>
<nextsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</nextsent>
<nextsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</nextsent>
<nextsent>agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1353">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in each case, co-training was used successfully to bootstrap model from only small amount of labelled data and much larger pool of un labelled data.
</prevsent>
<prevsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</citsent>
<aftsection>
<nextsent>agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</nextsent>
<nextsent>the idea behind co-training the pos taggers is very simple: use output from the tnt tagger as additional labelled data for the maximum entropy tagger, and vice versa, in the hope that one tagger can learn useful information from the output of the other.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1354">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</prevsent>
<prevsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</citsent>
<aftsection>
<nextsent>the idea behind co-training the pos taggers is very simple: use output from the tnt tagger as additional labelled data for the maximum entropy tagger, and vice versa, in the hope that one tagger can learn useful information from the output of the other.
</nextsent>
<nextsent>since the output of both taggers is noisy, there is question of which newly labelled examples to add to the training set.
</nextsent>
<nextsent>the additional data should be accurate, but also useful, providing the tagger with new information.
</nextsent>
<nextsent>our work differs from the blum and mitchell (1998) formulation of co-training by using two different learning algorithms rather than two independent feature sets (goldman and zhou, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1355">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</prevsent>
<prevsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</citsent>
<aftsection>
<nextsent>the idea behind co-training the pos taggers is very simple: use output from the tnt tagger as additional labelled data for the maximum entropy tagger, and vice versa, in the hope that one tagger can learn useful information from the output of the other.
</nextsent>
<nextsent>since the output of both taggers is noisy, there is question of which newly labelled examples to add to the training set.
</nextsent>
<nextsent>the additional data should be accurate, but also useful, providing the tagger with new information.
</nextsent>
<nextsent>our work differs from the blum and mitchell (1998) formulation of co-training by using two different learning algorithms rather than two independent feature sets (goldman and zhou, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1356">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous co-training approaches have typically used the score assigned by the model as an indicator of the reliability of newly labelled example.
</prevsent>
<prevsent>inthis paper we take different approach, based on theoretical work by dasgupta et al (2002) and abney (2002), <papid> P02-1046 </papid>inwhich newly labelled training examples are selected using greedy algorithm which explicitly maximises the pos taggers?</prevsent>
</prevsection>
<citsent citstr=" W02-2006 ">
agreement on un labelled data.we investigate whether co-training based upon directly maximising agreement can be successfully applied to pair of part-of-speech (pos) taggers: the markov model tnt tagger (brants, 2000) <papid> A00-1031 </papid>and the maximum entropy c&c; tagger (curran and clark, 2003).<papid> E03-1071 </papid>there has been some previous work on boo strap ping pos taggers (e.g., zavrel and daelemans (2000) and cucerzan and yarowsky (2002)), <papid> W02-2006 </papid>but to our knowledge no previous work on co-training pos taggers.</citsent>
<aftsection>
<nextsent>the idea behind co-training the pos taggers is very simple: use output from the tnt tagger as additional labelled data for the maximum entropy tagger, and vice versa, in the hope that one tagger can learn useful information from the output of the other.
</nextsent>
<nextsent>since the output of both taggers is noisy, there is question of which newly labelled examples to add to the training set.
</nextsent>
<nextsent>the additional data should be accurate, but also useful, providing the tagger with new information.
</nextsent>
<nextsent>our work differs from the blum and mitchell (1998) formulation of co-training by using two different learning algorithms rather than two independent feature sets (goldman and zhou, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1364">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> the pos taggers.  </section>
<citcontext>
<prevsection>
<prevsent>abney also presents greedy algorithm that maximises agreement on un labelled data, which produces comparable results to collins and singer (1999) <papid> W99-0613 </papid>on their named entity classification task.goldman and zhou (2000) show that, if the newly labelled examples used for re-training are selected carefully, co-training can still be successful even when the views used by the classifiers do not satisfy the independence assumption.</prevsent>
<prevsent>in remainder of the paper we present practical method for co-training pos taggers, and investigate the extent to which example selection based on the work of dasgupta et aland abney can be effective.</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the two pos taggers used in the experiments are tnt, publicly available markov model tagger (brants, 2000), <papid> A00-1031 </papid>and re implementation of the maximum entropy (me) tagger mxpost (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the me tagger,which we refer to as c&c;, uses the same features as mxpost, but is much faster for training and tagging (cur ran and clark, 2003).<papid> E03-1071 </papid></nextsent>
<nextsent>fast training and tagging times are important for the experiments performed here, since the bootstrapping process can require many tagging and training iterations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1366">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> the pos taggers.  </section>
<citcontext>
<prevsection>
<prevsent>first, it uses conditional model of tag sequence given string, rather than joint model.
</prevsent>
<prevsent>second, me models are used to define the conditional probabilities ofa tag given some context.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
the advantage of me models over the markov model used by tnt is that arbitrary features can easily be included in the context; so as well as considering the target word and the previous two tags (which is the information tnt uses), the me models also consider the words either side of the target word and, for unknown and infrequent words, various properties of the string of the target word.a disadvantage is that the training times for me models are usually relatively slow, especially with iterative scaling methods (see malouf (2002) <papid> W02-2018 </papid>for alternative methods).</citsent>
<aftsection>
<nextsent>here we use generalised iterative scaling (dar roch and rat cliff, 1972), but our implementation is much faster than ratnaparkhis publicly available tagger.
</nextsent>
<nextsent>the c&c; tagger trains in less than 7 minutes on the 1 million words of the penn treebank, and tags slightly faster than tnt.
</nextsent>
<nextsent>since the taggers share many common features, one might think they are not different enough for effectiveco-training to be possible.
</nextsent>
<nextsent>in fact, both taggers are sufficiently different for co-training to be effective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1370">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we leave these experiments to future work, but note that there is large computational cost associated with such experiments.
</prevsent>
<prevsent>the performance of the boot strapped taggers is still long way behind tagger trained on large amount of manually annotated data.
</prevsent>
</prevsection>
<citsent citstr=" A94-1009 ">
this finding is in accord with earlier work on bootstrapping taggers using em (el worthy, 1994; <papid> A94-1009 </papid>merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>an interesting question would be to determine the minimum number of manually labelled examples that need to be used to seed the system before we can achieve comparable results as using all available manually labelled sentences.for our experiments, co-training never led to decrease in performance, regardless of the number of iterations.
</nextsent>
<nextsent>the opposite behaviour has been observed in other applications of co-training (pierce and cardie, 2001).<papid> W01-0501 </papid>whether this robustness is property of the tagging problem or our approach is left for future work.</nextsent>
<nextsent>1this is probably by chance selection of better subsets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1371">
<title id=" W03-0407.xml">bootstrapping pos taggers using un labelled data </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we leave these experiments to future work, but note that there is large computational cost associated with such experiments.
</prevsent>
<prevsent>the performance of the boot strapped taggers is still long way behind tagger trained on large amount of manually annotated data.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
this finding is in accord with earlier work on bootstrapping taggers using em (el worthy, 1994; <papid> A94-1009 </papid>merialdo, 1994).<papid> J94-2001 </papid></citsent>
<aftsection>
<nextsent>an interesting question would be to determine the minimum number of manually labelled examples that need to be used to seed the system before we can achieve comparable results as using all available manually labelled sentences.for our experiments, co-training never led to decrease in performance, regardless of the number of iterations.
</nextsent>
<nextsent>the opposite behaviour has been observed in other applications of co-training (pierce and cardie, 2001).<papid> W01-0501 </papid>whether this robustness is property of the tagging problem or our approach is left for future work.</nextsent>
<nextsent>1this is probably by chance selection of better subsets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1373">
<title id=" W03-0103.xml">semi supervised learning of geographical gazetteer from the internet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>knowledge on place names comes normally from named entity recognition module.
</prevsent>
<prevsent>unfortunately, moststate-of-the-art named entity recognition systems support very coarse-grained classifications and thus can distinguish only between locations and non-locations.one of the main components of named entity recognition system is gazetteer ? huge list of preclas sified entities.
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
it has been shown in (mikheev et al,1999) <papid> E99-1001 </papid>that ne recognition system performs reasonably well for most classes even without gazetteers.</citsent>
<aftsection>
<nextsent>locations, however, could not be reliably identified (51,7% f-measure without gazette ers compared to 94,5% with afull gazetteer).
</nextsent>
<nextsent>and obviously, when one needs more sophisticated classes, including various types of locations, gazette ers should become even more important.
</nextsent>
<nextsent>one possible solution would be to create gazette ers manually, using world atlases, lists of place names on the web, and already existing digital collections, such as (adl, 2000).
</nextsent>
<nextsent>this task is only feasible, of course, when those resources have compatible formats and, thus, can be merged automatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1374">
<title id=" W03-0103.xml">semi supervised learning of geographical gazetteer from the internet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one possible solution was proposed in (smith, 2002).at least some information on almost any particular location already exists somewhere on the internet.
</prevsent>
<prevsent>the only problem is that this knowledge is highly distributed over millions of web pages and, thus, difficult to find.this leads us to conclusion that one can explore standard data mining techniques in order to induce gazette ers from the internet (semi-)automatically.
</prevsent>
</prevsection>
<citsent citstr=" W02-1030 ">
as it has been shown recently in (keller et al, 2002), <papid> W02-1030 </papid>internet counts produce reliable data for linguistic analysis, correlating well with corpus statistics and plausibility judgments.in this paper we present an approach for learning geographical gazette ers using very scarce resources.</citsent>
<aftsection>
<nextsent>this work is continuation of our previous study (ourioupina, 2002), described briefly in section 3.
</nextsent>
<nextsent>in the previous work we obtained collocational information from the internet, using set of manually pre compiled patterns.
</nextsent>
<nextsent>the system used this information to learn six binary classifiers, determining forgiven word, whether it is city,island, river, mountain, region, and country.
</nextsent>
<nextsent>although the previous approach helped us to reduce hand-coding drastically, we still needed some manually encoded knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1375">
<title id=" W02-1608.xml">extending the coverage of a valency dictionary </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, this information is not encoded in normalhuman-readable dictionaries, and is hard to enter manually.
</prevsent>
<prevsent>shirai (1999) estimates that at least 27,000 valency entries are needed to cover around 80% of japanese verbs in typical newspaper, and we expect this to be true of any language.
</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
various methods of creating detailed entries have been suggested, such as the extraction of candidates from corpora (manning, 1993; <papid> P93-1032 </papid>ut suro et al, 1997; kawahara and kurohashi, 2001), <papid> H01-1043 </papid>and the automatic and semi-automatic induction of semantic constraints (akiba et al, 2000).</citsent>
<aftsection>
<nextsent>however, the automatic construction of monolingual entries is still far from reaching the quality of hand-constructed resources.
</nextsent>
<nextsent>further, large-scale bilingual resources are still rare enough that it is much harder to automatically build bilingual entries.
</nextsent>
<nextsent>our work differs from corpus-based work such as manning (1993) <papid> P93-1032 </papid>or kawahara and kurohashi(2001) <papid> H01-1043 </papid>in that we are using existing lexical resources rather than corpus.</nextsent>
<nextsent>thus our method will work for rare words, so long as we can find them in bilingual dictionary, and know the english translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1376">
<title id=" W02-1608.xml">extending the coverage of a valency dictionary </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, this information is not encoded in normalhuman-readable dictionaries, and is hard to enter manually.
</prevsent>
<prevsent>shirai (1999) estimates that at least 27,000 valency entries are needed to cover around 80% of japanese verbs in typical newspaper, and we expect this to be true of any language.
</prevsent>
</prevsection>
<citsent citstr=" H01-1043 ">
various methods of creating detailed entries have been suggested, such as the extraction of candidates from corpora (manning, 1993; <papid> P93-1032 </papid>ut suro et al, 1997; kawahara and kurohashi, 2001), <papid> H01-1043 </papid>and the automatic and semi-automatic induction of semantic constraints (akiba et al, 2000).</citsent>
<aftsection>
<nextsent>however, the automatic construction of monolingual entries is still far from reaching the quality of hand-constructed resources.
</nextsent>
<nextsent>further, large-scale bilingual resources are still rare enough that it is much harder to automatically build bilingual entries.
</nextsent>
<nextsent>our work differs from corpus-based work such as manning (1993) <papid> P93-1032 </papid>or kawahara and kurohashi(2001) <papid> H01-1043 </papid>in that we are using existing lexical resources rather than corpus.</nextsent>
<nextsent>thus our method will work for rare words, so long as we can find them in bilingual dictionary, and know the english translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1379">
<title id=" W03-1710.xml">modeling of long distance context dependency in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the meanwhile, evaluation on chinese word segmentation shows that about 35 percent of errors can be corrected by using the mi-trigram model compared with the trigram model.
</prevsent>
<prevsent>language modeling is the attempt to characterize, capture and exploit the regularities and constraints in natural language.
</prevsent>
</prevsection>
<citsent citstr=" H90-1056 ">
among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation (katz 1987; jelinek 1989; gale and church 1990; <papid> H90-1056 </papid>brown et al  1992; <papid> J92-4003 </papid>yang et al  1996; bai et al 1998; zhou et al  1999; rosenfeld 2000; gao et al 2002).<papid> P02-1024 </papid></citsent>
<aftsection>
<nextsent>although ngram modeling is simple in nature and easy to use, it has obvious deficiencies.
</nextsent>
<nextsent>for instance, ngram modeling can only capture the short distance context dependency within an n-word window where currently the largest practical for natural language is three.
</nextsent>
<nextsent>in the meantime, it is found that there always exist many preferred relationships between words.
</nextsent>
<nextsent>two highly associated word pairs are ??/??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1380">
<title id=" W03-1710.xml">modeling of long distance context dependency in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the meanwhile, evaluation on chinese word segmentation shows that about 35 percent of errors can be corrected by using the mi-trigram model compared with the trigram model.
</prevsent>
<prevsent>language modeling is the attempt to characterize, capture and exploit the regularities and constraints in natural language.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation (katz 1987; jelinek 1989; gale and church 1990; <papid> H90-1056 </papid>brown et al  1992; <papid> J92-4003 </papid>yang et al  1996; bai et al 1998; zhou et al  1999; rosenfeld 2000; gao et al 2002).<papid> P02-1024 </papid></citsent>
<aftsection>
<nextsent>although ngram modeling is simple in nature and easy to use, it has obvious deficiencies.
</nextsent>
<nextsent>for instance, ngram modeling can only capture the short distance context dependency within an n-word window where currently the largest practical for natural language is three.
</nextsent>
<nextsent>in the meantime, it is found that there always exist many preferred relationships between words.
</nextsent>
<nextsent>two highly associated word pairs are ??/??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1381">
<title id=" W03-1710.xml">modeling of long distance context dependency in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the meanwhile, evaluation on chinese word segmentation shows that about 35 percent of errors can be corrected by using the mi-trigram model compared with the trigram model.
</prevsent>
<prevsent>language modeling is the attempt to characterize, capture and exploit the regularities and constraints in natural language.
</prevsent>
</prevsection>
<citsent citstr=" P02-1024 ">
among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation (katz 1987; jelinek 1989; gale and church 1990; <papid> H90-1056 </papid>brown et al  1992; <papid> J92-4003 </papid>yang et al  1996; bai et al 1998; zhou et al  1999; rosenfeld 2000; gao et al 2002).<papid> P02-1024 </papid></citsent>
<aftsection>
<nextsent>although ngram modeling is simple in nature and easy to use, it has obvious deficiencies.
</nextsent>
<nextsent>for instance, ngram modeling can only capture the short distance context dependency within an n-word window where currently the largest practical for natural language is three.
</nextsent>
<nextsent>in the meantime, it is found that there always exist many preferred relationships between words.
</nextsent>
<nextsent>two highly associated word pairs are ??/??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1382">
<title id=" W02-1303.xml">why nlp should move into ias </title>
<section> nlp applications to ias.  </section>
<citcontext>
<prevsection>
<prevsent>in the rest of the section, we will characterize these tasks briefly, with an emphasis on the nlp contribution to their solution, contribution which is largely constitutive in nature in the sense that they would probably not exist if nlp could not offer the know-how to implement them.
</prevsent>
<prevsent>3.2.1 mt for encryption inspired by the most obvious connection between encryption and nl, the largely apocryphal world war ii episode, when instead of an elaborate code, the american and british general headquarters in europe used the native speakers of navajo (shawnee, in another version, involving the pacific theater) to communicate in open, uncoded language and were never decoded,?
</prevsent>
</prevsection>
<citsent citstr=" P98-2160 ">
the idea was to use family of existing or rapidly deployable mt systems (see nirenburg and raskin 1998) <papid> P98-2160 </papid>to add level of encryption in an exotic?</citsent>
<aftsection>
<nextsent>language.
</nextsent>
<nextsent>raskin et al page 2 once proposed (raskin et al  2001), the idea failed to catch and has never been implemented, partially because there was no research challenge in that, but also because it would involve the security by obscurity?
</nextsent>
<nextsent>principle disdained by ias: one should assume that the adversary is at least as smart and knowledgeable as we, the good guys, are.
</nextsent>
<nextsent>also, an mt system, even if publicly available, is too long and messy key,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1383">
<title id=" W02-1408.xml">automatic discovery of term similarities using pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the approach has been tested and evaluated in the domain of molecular biology, and preliminary results are presented.
</prevsent>
<prevsent>in knowledge intensive discipline such as molecular biology, the vast and constantly increasing amount of information demands innovative techniques to gather and systematically structure knowledge, usually available only from text/document resources.
</prevsent>
</prevsection>
<citsent citstr=" C00-1077 ">
in order to discover new knowledge, one has to identify main concepts, which are linguistically represented by domain specific terms (maynard and ananiadou (2000)).<papid> C00-1077 </papid></citsent>
<aftsection>
<nextsent>there is an increased amount of new terms that represent newly created concepts.
</nextsent>
<nextsent>since existing term dictionaries usually do not meet the needs of specialists, automatic term extraction tools are indispensable for efficient term discovery and dynamic update of term dictionaries.
</nextsent>
<nextsent>however, automatic term recognition (atr) is not the ultimate aim: terms recognised should be related to existing knowledge and/or to each other.
</nextsent>
<nextsent>this entails the fact that terms should be classified or clustered so that semantically similar terms are grouped together.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1387">
<title id=" W02-1408.xml">automatic discovery of term similarities using pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, genies (friedman et al (2001)) uses semantic grammar and substantial syntactic knowledge in order to extract comprehensive information about signal transduction pathways.
</prevsent>
<prevsent>some of the systems are terminology-based, since technical terms semantically characterise documents and therefore represent starting place for knowledge acquisition tasks.
</prevsent>
</prevsection>
<citsent citstr=" C02-1083 ">
for example, mima et al (2002) <papid> C02-1083 </papid>introduce tims, terminology-based knowledge acquisition system, which integrates automatic term recognition, term variation management, context based automatic term clustering, ontology-based inference, and intelligent tag information retrieval.</citsent>
<aftsection>
<nextsent>the systems aim is to provide efficient access and integration of heterogeneous biological textual data and databases.
</nextsent>
<nextsent>there are numerous approaches to atr.
</nextsent>
<nextsent>some methods (bourigault (1992), <papid> C92-3150 </papid>ananiadou (1994)) <papid> C94-2167 </papid>rely purely on linguistic information, namely morpho-syntactic features of term candidates.</nextsent>
<nextsent>recently, hybrid approaches combining linguistic and statistical knowledge are becoming increasingly used (frantzi et al (2000), nakagawa et al (1998)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1388">
<title id=" W02-1408.xml">automatic discovery of term similarities using pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the systems aim is to provide efficient access and integration of heterogeneous biological textual data and databases.
</prevsent>
<prevsent>there are numerous approaches to atr.
</prevsent>
</prevsection>
<citsent citstr=" C92-3150 ">
some methods (bourigault (1992), <papid> C92-3150 </papid>ananiadou (1994)) <papid> C94-2167 </papid>rely purely on linguistic information, namely morpho-syntactic features of term candidates.</citsent>
<aftsection>
<nextsent>recently, hybrid approaches combining linguistic and statistical knowledge are becoming increasingly used (frantzi et al (2000), nakagawa et al (1998)).
</nextsent>
<nextsent>there is range of clustering and classification approaches that are based on statistical measures of word co-occurrences (e.g. ushioda (1996)), <papid> C96-2212 </papid>or syntactic information derived from corpora (e.g. grefenstette (1994)).</nextsent>
<nextsent>however, few of them deal with term clustering: maynard and ananiadou (2000) <papid> C00-1077 </papid>present method that uses manually defined semantic frames for specific classes, hatzivassiloglou et al (2001) use machine learning techniques to disambiguate names of proteins, genes and rnas, while friedman et al (2001) describe extraction of specific molecular pathways from journal articles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1389">
<title id=" W02-1408.xml">automatic discovery of term similarities using pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the systems aim is to provide efficient access and integration of heterogeneous biological textual data and databases.
</prevsent>
<prevsent>there are numerous approaches to atr.
</prevsent>
</prevsection>
<citsent citstr=" C94-2167 ">
some methods (bourigault (1992), <papid> C92-3150 </papid>ananiadou (1994)) <papid> C94-2167 </papid>rely purely on linguistic information, namely morpho-syntactic features of term candidates.</citsent>
<aftsection>
<nextsent>recently, hybrid approaches combining linguistic and statistical knowledge are becoming increasingly used (frantzi et al (2000), nakagawa et al (1998)).
</nextsent>
<nextsent>there is range of clustering and classification approaches that are based on statistical measures of word co-occurrences (e.g. ushioda (1996)), <papid> C96-2212 </papid>or syntactic information derived from corpora (e.g. grefenstette (1994)).</nextsent>
<nextsent>however, few of them deal with term clustering: maynard and ananiadou (2000) <papid> C00-1077 </papid>present method that uses manually defined semantic frames for specific classes, hatzivassiloglou et al (2001) use machine learning techniques to disambiguate names of proteins, genes and rnas, while friedman et al (2001) describe extraction of specific molecular pathways from journal articles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1390">
<title id=" W02-1408.xml">automatic discovery of term similarities using pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some methods (bourigault (1992), <papid> C92-3150 </papid>ananiadou (1994)) <papid> C94-2167 </papid>rely purely on linguistic information, namely morpho-syntactic features of term candidates.</prevsent>
<prevsent>recently, hybrid approaches combining linguistic and statistical knowledge are becoming increasingly used (frantzi et al (2000), nakagawa et al (1998)).</prevsent>
</prevsection>
<citsent citstr=" C96-2212 ">
there is range of clustering and classification approaches that are based on statistical measures of word co-occurrences (e.g. ushioda (1996)), <papid> C96-2212 </papid>or syntactic information derived from corpora (e.g. grefenstette (1994)).</citsent>
<aftsection>
<nextsent>however, few of them deal with term clustering: maynard and ananiadou (2000) <papid> C00-1077 </papid>present method that uses manually defined semantic frames for specific classes, hatzivassiloglou et al (2001) use machine learning techniques to disambiguate names of proteins, genes and rnas, while friedman et al (2001) describe extraction of specific molecular pathways from journal articles.</nextsent>
<nextsent>in our previous work, an integrated knowledge mining system in the domain of molecular biology, atract, has been developed (mima et al (2001)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1397">
<title id=" W02-1408.xml">automatic discovery of term similarities using pattern mining </title>
<section> term similarity measures.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, the following example: ... steroid receptors such as estrogen receptor, glucocorticoid receptor,and progesterone receptor.
</prevsent>
<prevsent>suggests that all the terms involved are highly correlated, since they appear in an enumeration (represented by the such-as pattern) which indicates their similarity (based on the is_a relationship).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
some of these patterns have been previously used to discover hyponym relations between words (hearst (1992)).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>we generalised 4 for our approach to acronym acquisition and term.
</nextsent>
<nextsent>normalisation, see nenadic et al (2002).
</nextsent>
<nextsent>the approach by taking into account patterns in which the terms are used concurrently within the same context.
</nextsent>
<nextsent>we hypothesise that the parallel usage of terms within the same context, as specific type of co-occurrence, shows their functional similarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1401">
<title id=" W02-1503.xml">the parallel grammar project </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as such, desideratum for the platforms is broad utilization scope.
</prevsent>
<prevsent>a grammar development platform should be able to be used to write grammars for wide variety of languages and broad range of purposes.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
in this paper, we report on the parallel grammar (pargram) project (butt et al, 1999) which uses the xle parser and grammar development platform (maxwell and kaplan, 1993) <papid> J93-4001 </papid>for six languages: english, french, german, japanese, norwegian, and urdu.</citsent>
<aftsection>
<nextsent>all ofthe grammars use the lexical-functional grammar (lfg) formalism which produces c(onstituent) structures (trees) and f(unctional)-structures (avms) as the syntactic analysis.
</nextsent>
<nextsent>lfg assumes version of chomskys universal grammar hypothesis, namely that all languages are structured by similar underlying principles.
</nextsent>
<nextsent>within lfg, f-structures are meant to encode language universal level of analysis, allowing for cross linguistic parallelism at this level of abstraction.
</nextsent>
<nextsent>although the construction of c-structures is governed 1we would like to thank emily bender, mary dalrymple, and ron kaplan for help with this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1402">
<title id=" W02-1503.xml">the parallel grammar project </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this parallelism applies to the syntactic analyses produced, as well as to grammar developmentitself: the sharing of templates and feature declarations, the utilization of common techniques, and the transfer of knowledge and technology from one grammar to another.
</prevsent>
<prevsent>the ability to bundle grammar writing techniques, such as templates, into transferable technology means that new grammars can be boot strapped in relatively short amount of time.there are number of other large-scale grammar projects in existence which we mention briefly here.
</prevsent>
</prevsection>
<citsent citstr=" C96-1049 ">
the ls-gram project (schmidt et al, 1996),<papid> C96-1049 </papid>funded by the eu-commission under lre (lin guistic research and engineering), was concerned with the development of grammatical resources for nine european languages: danish, dutch, english, french, german, greek, italian, portuguese, and spanish.</citsent>
<aftsection>
<nextsent>the project started in january 1994 and ended in july 1996.
</nextsent>
<nextsent>development of grammatical resources was carried out in the framework of the advanced language engineering platform (alep).the coverage of the grammars implemented in lsgram was, however, much smaller than the coverage of the english (riezler et al, 2002) <papid> P02-1035 </papid>or german grammar in pargram.</nextsent>
<nextsent>an effort which is clos erin spirit to pargram is the implemention of grammar development platforms for hpsg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1403">
<title id=" W02-1503.xml">the parallel grammar project </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the ls-gram project (schmidt et al, 1996),<papid> C96-1049 </papid>funded by the eu-commission under lre (lin guistic research and engineering), was concerned with the development of grammatical resources for nine european languages: danish, dutch, english, french, german, greek, italian, portuguese, and spanish.</prevsent>
<prevsent>the project started in january 1994 and ended in july 1996.</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
development of grammatical resources was carried out in the framework of the advanced language engineering platform (alep).the coverage of the grammars implemented in lsgram was, however, much smaller than the coverage of the english (riezler et al, 2002) <papid> P02-1035 </papid>or german grammar in pargram.</citsent>
<aftsection>
<nextsent>an effort which is clos erin spirit to pargram is the implemention of grammar development platforms for hpsg.
</nextsent>
<nextsent>in the verb mobil project (wahlster, 2000), hpsg grammars for english, german, and japanese were developed on two platforms: lkb (copestake, 2002) and page.
</nextsent>
<nextsent>the page system, developed and maintained in the language technology lab of the german national research center on artificial intelligence dfkigmbh, is an advanced nlp core engine that facilitates the development of grammatical and lexical resources, building on typed feature logics.
</nextsent>
<nextsent>to evaluate the hpsg platforms and to compare their merits with those of xle and the pargram projects, one would have to organize special workshop, particularly as the hpsg grammars in verb mobil were written for spoken language, characterized by short utterances, whereas the lfg grammars were developed for parsing technical manuals and/or newspaper texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1404">
<title id=" W02-1503.xml">the parallel grammar project </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the page system, developed and maintained in the language technology lab of the german national research center on artificial intelligence dfkigmbh, is an advanced nlp core engine that facilitates the development of grammatical and lexical resources, building on typed feature logics.
</prevsent>
<prevsent>to evaluate the hpsg platforms and to compare their merits with those of xle and the pargram projects, one would have to organize special workshop, particularly as the hpsg grammars in verb mobil were written for spoken language, characterized by short utterances, whereas the lfg grammars were developed for parsing technical manuals and/or newspaper texts.
</prevsent>
</prevsection>
<citsent citstr=" P02-1056 ">
there are some indications that the german and english grammars in pargram exceed the hpsg grammars in coverage (see (crysmann et al, 2002) <papid> P02-1056 </papid>on the german hpsg grammar).this paper is organized as follows.</citsent>
<aftsection>
<nextsent>we first provide history of the project.
</nextsent>
<nextsent>then, we discuss how parallelism is maintained in the project.
</nextsent>
<nextsent>finally, we provide summary and discussion.
</nextsent>
<nextsent>the pargram project began in 1994 with three languages: english, french, and german.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1405">
<title id=" W03-0435.xml">memory based named entity recognition using unannotated data </title>
<section> system 2: description.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 ratio of capitalized to non-capitalized.
</prevsent>
<prevsent>occurrence of tokens last feature added to all instances indicated if the focus word (the word to be classified) appears more often capitalized or un capitalized in the unannotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
this approach has been used earlier by (collins, 2002).<papid> P02-1062 </papid></citsent>
<aftsection>
<nextsent>inorder to make this feature, list was made of all word forms, converted to lowercase, in the corpus, and the ratio of capitalized to un capitalized occurrences.
</nextsent>
<nextsent>the extra feature was binary: on if word appears more often capitalized than not, and off otherwise.
</nextsent>
<nextsent>5.1 role of gazetteers.
</nextsent>
<nextsent>two experiments were run to assess the importance of the gazette ers in this experiment: the first used only theword to be classified and its context, the second used binary features indicating inclusion in gazette ers, as wellas the features used in the first experiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1406">
<title id=" W03-0311.xml">retrieving meaning equivalent sentences for example based rough translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>speech-to-speech translation (s2st) technologies consist of speech recognition, machine translation (mt), and speech synthesis (waibel, 1996; wahlster, 2000; yamamoto, 2000).
</prevsent>
<prevsent>the mt part receives speech texts recognized by speech recognizer.
</prevsent>
</prevsection>
<citsent citstr=" W02-0718 ">
the nature of speech causes difficulty in translation since the styles of speech are different from those of written text and are sometimes ungrammatical (lazzari, 2002).<papid> W02-0718 </papid></citsent>
<aftsection>
<nextsent>therefore, rule-based mt cannot translate speech accurately compared with its performance for written-style text .example-based mt (ebmt) is one of the corpus based machine translation methods.
</nextsent>
<nextsent>it retrieves examples similar to inputs and adjusts their translations to obtain the output (nagao, 1981).
</nextsent>
<nextsent>ebmt is promising method for s2st in that it performs robust translation of ungrammatical sentences and requires far less manual work than rule-based mt. however, there are two problems in applying ebmt to s2st.
</nextsent>
<nextsent>one is that the translation accuracy drastically drops as input sentences become long.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1407">
<title id=" W03-0311.xml">retrieving meaning equivalent sentences for example based rough translation </title>
<section> difficulty in example-based s2st.  </section>
<citcontext>
<prevsection>
<prevsent>a major problem with machine translation, regardless of the translation method, is that performance drops rapidly as input sentences become longer.
</prevsent>
<prevsent>for ebmt, the longer input sentences become, the fewer similar example sentences exist in the example corpus.
</prevsent>
</prevsection>
<citsent citstr=" W01-1401 ">
figure 1 shows translation difficulty in long sentences in ebmt (sumita, 2001).<papid> W01-1401 </papid></citsent>
<aftsection>
<nextsent>the ebmt system is given 591 test sentences and returns translation result as translated/untranslated.
</nextsent>
<nextsent>untranslated means that there exists no similar example sentences for the input.
</nextsent>
<nextsent>although the ebmt is equipped with large example corpus (about 170k sentences), it often failed to translate long inputs.
</nextsent>
<nextsent>2.2 style differences between concise and.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1408">
<title id=" W03-0311.xml">retrieving meaning equivalent sentences for example based rough translation </title>
<section> meaning-equivalent sentence.  </section>
<citcontext>
<prevsection>
<prevsent>a speech act is concept similar to modality in whichspeakers?
</prevsent>
<prevsent>intentions are represented.
</prevsent>
</prevsection>
<citsent citstr=" P99-1049 ">
the two studies introduced information of the speech act in their s2st systems (wahlster, 2000; tanaka and yokoo, 1999).<papid> P99-1049 </papid></citsent>
<aftsection>
<nextsent>the two studies and our method differ in the effect of speech act information.
</nextsent>
<nextsent>their effect of speech act information is so small that it is limited to generating the translation text.translation texts are refined by selecting proper expressions according to the detected speakers?
</nextsent>
<nextsent>intention.
</nextsent>
<nextsent>3.3 retrieval and ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1410">
<title id=" W03-0311.xml">retrieving meaning equivalent sentences for example based rough translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this indicates the robustness of the proposed method to the differences between the two styles.
</prevsent>
<prevsent>5.1 ebmt.
</prevsent>
</prevsection>
<citsent citstr=" C00-1019 ">
the rough translation proposed in this paper is type of ebmt (sumita, 2001; <papid> W01-1401 </papid>veale and way, 1997; carl, 1999; brown, 2000).<papid> C00-1019 </papid></citsent>
<aftsection>
<nextsent>the basic idea of ebmt is that sentences similar to the inputs are retrieved from an example corpus and their translations become the basis of outputs.
</nextsent>
<nextsent>here, let us consider the difference between our method and other ebmt methods by dividing similarity into content-word part and functional-word part.
</nextsent>
<nextsent>in the content-word part, our method and other ebmtmethods are almost the same.
</nextsent>
<nextsent>content words are important information in similarity measure process, and thesauri are utilized to extend lexical coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1411">
<title id=" W03-0311.xml">retrieving meaning equivalent sentences for example based rough translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>tm and our method share the retrieval strategy of rough and wide coverage.
</prevsent>
<prevsent>however, recall is more highly weighted than precision in tm, while recall and precision should be equally considered in our method.
</prevsent>
</prevsection>
<citsent citstr=" P01-1004 ">
to carry out wide coverage retrieval, tm relaxed various conditions on inputs: preserving only mono-gram and bi-gram onwords/characters (baldwin, 2001; <papid> P01-1004 </papid>sato, 1992), <papid> C92-4203 </papid>removing functional words (kumano et al, 2002; wakita et al,2000), and removing content words (sumita and tsutsumi, 1988).</citsent>
<aftsection>
<nextsent>in our method, information on functional words is removed and that on modality and tense is introduced instead.
</nextsent>
<nextsent>information on word order is also removed while instead we preserve information on whether each word is located in the focus area.
</nextsent>
<nextsent>in this paper, we introduced the idea of meaning equivalent sentences for robust example-based s2st.meaning-equivalent sentences have the same main meaning as the input despite lacking some unimportant information.
</nextsent>
<nextsent>translation of meaning-equivalent sentences corresponds to rough translations, which aim not at exact translation with narrow coverage but at rough translation with wide coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1412">
<title id=" W03-0311.xml">retrieving meaning equivalent sentences for example based rough translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>tm and our method share the retrieval strategy of rough and wide coverage.
</prevsent>
<prevsent>however, recall is more highly weighted than precision in tm, while recall and precision should be equally considered in our method.
</prevsent>
</prevsection>
<citsent citstr=" C92-4203 ">
to carry out wide coverage retrieval, tm relaxed various conditions on inputs: preserving only mono-gram and bi-gram onwords/characters (baldwin, 2001; <papid> P01-1004 </papid>sato, 1992), <papid> C92-4203 </papid>removing functional words (kumano et al, 2002; wakita et al,2000), and removing content words (sumita and tsutsumi, 1988).</citsent>
<aftsection>
<nextsent>in our method, information on functional words is removed and that on modality and tense is introduced instead.
</nextsent>
<nextsent>information on word order is also removed while instead we preserve information on whether each word is located in the focus area.
</nextsent>
<nextsent>in this paper, we introduced the idea of meaning equivalent sentences for robust example-based s2st.meaning-equivalent sentences have the same main meaning as the input despite lacking some unimportant information.
</nextsent>
<nextsent>translation of meaning-equivalent sentences corresponds to rough translations, which aim not at exact translation with narrow coverage but at rough translation with wide coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1413">
<title id=" W03-0415.xml">using lsa and noun coordination information to improve the recall and precision of automatic hyponymy extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper demonstrates that mathematical models for measuring semantic similarity between concepts can be used to improve the learning of hyponymy relationships between concepts from free text.
</prevsent>
<prevsent>in particular, we show that latent semantic analysis can be used to filter results, giving an increase in precision, and that neighbors in graph built from coordination information can be used to improve recall.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
the goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition (roark and charniak, 1998), <papid> P98-2182 </papid>information extraction (cardie, 1997), and ontology engineering (hahn and schnattinger, 1998).</citsent>
<aftsection>
<nextsent>the purpose of this kind ofwork is to collect information about the meanings of lexical items or phrases, and the relationships between them, so that the process of building semantic resources (such as ontologies and dictionaries) by hand can be automated or at least helped.
</nextsent>
<nextsent>one of the standard ways of arranging concepts is in concept hierarchy or taxonomy such as the wordnet noun taxonomy (fellbaum, 1998).
</nextsent>
<nextsent>the fundamental relationship between objects in taxonomy is called hyponymy, where is hyponym of if every is also an x. for example, every trout is also fish, so we say that trout is hyponym (below name?)
</nextsent>
<nextsent>of fish and conversely, fishis hypernym (above name?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1414">
<title id=" W03-0415.xml">using lsa and noun coordination information to improve the recall and precision of automatic hyponymy extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is also noted that the genus of an object, in traditional lexicographic terms, is often hypernym of that object (guthrie et al, 1996).
</prevsent>
<prevsent>throughout this paper we will write   for the relationship is hyponym of x?.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
in this paper,we use the hyponymy relationship to describe subset relationships, so we regard   to be true if the set of ys can reasonably be said to be subset of the set of xs.1 because hyponymy relationships are so central to knowledge engineering, there have been numerous attempts to learn them from text, beginning with those of hearst (1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>we review this work in section 2, where we reproduce similar experiments as baseline from which to expand.
</nextsent>
<nextsent>the rest of the paper demonstrates ways in which other mathematical models built from text corpora can be used to improve hyponymy extraction.
</nextsent>
<nextsent>in section 3, we show how latent semantic analysis can be used to filter potential relationships according to their semantic plausibility?.
</nextsent>
<nextsent>in section 4, we show how correctly extracted relationships can be used as seed-cases?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1415">
<title id=" W03-0415.xml">using lsa and noun coordination information to improve the recall and precision of automatic hyponymy extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in section 3, we show how latent semantic analysis can be used to filter potential relationships according to their semantic plausibility?.
</prevsent>
<prevsent>in section 4, we show how correctly extracted relationships can be used as seed-cases?
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
to extract several more relationships, thus improving recall; this work shares some similarities with that of caraballo (1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>in section 5 we show that combining the techniques of section 3 and section 4 improves both precision and recall.
</nextsent>
<nextsent>section 6 demonstrates that1another possible view is that hyponymy?
</nextsent>
<nextsent>should only refer to core relationships, not contingent ones (so pheasant  bird might be accepted but pheasant   food might not be, be cause it depends on context and culture).
</nextsent>
<nextsent>we use the broadersubset?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1419">
<title id=" W03-0415.xml">using lsa and noun coordination information to improve the recall and precision of automatic hyponymy extraction </title>
<section> 4 5 </section>
<citcontext>
<prevsection>
<prevsent>(bnc) might suggest that nutmeg, cinnamon, and coriander are also spices, because they appear to be similar to cloves.
</prevsent>
<prevsent>thus we can learn the hyponymy relations nutmeg   spice, cinnamon   spice, and coriander   spice that are not directly attested by lexico syntactic patterns in our training corpus.
</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
this kind of information from coordination patterns has been used for work in automatic lexical acquisition (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998; <papid> P98-2182 </papid>widdows and dorow, 2002)<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>the basic rationale behind these methods is that words that occur together in lists are usually semantically similar in some way: for example, the phrase y1, y2, and y3 suggests that there is some link between y1 and y2, etc. performing this analysis on whole corpus results in adata structure which holds collection of nouns and observed noun-noun relationships.
</nextsent>
<nextsent>if we think of the nouns as nodes and the noun-noun relationships as edges, this data structure is graph (bollobas, 1998), and combina toric methods can be used to analyze its structure.
</nextsent>
<nextsent>work using such techniques for lexical acquisition has proceeded by building classes of related words from single seed-word?
</nextsent>
<nextsent>with some desired property (such as being representative of paticular semantic class).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1421">
<title id=" W03-0415.xml">using lsa and noun coordination information to improve the recall and precision of automatic hyponymy extraction </title>
<section> 4 5 </section>
<citcontext>
<prevsection>
<prevsent>(bnc) might suggest that nutmeg, cinnamon, and coriander are also spices, because they appear to be similar to cloves.
</prevsent>
<prevsent>thus we can learn the hyponymy relations nutmeg   spice, cinnamon   spice, and coriander   spice that are not directly attested by lexico syntactic patterns in our training corpus.
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
this kind of information from coordination patterns has been used for work in automatic lexical acquisition (riloff and shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998; <papid> P98-2182 </papid>widdows and dorow, 2002)<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>the basic rationale behind these methods is that words that occur together in lists are usually semantically similar in some way: for example, the phrase y1, y2, and y3 suggests that there is some link between y1 and y2, etc. performing this analysis on whole corpus results in adata structure which holds collection of nouns and observed noun-noun relationships.
</nextsent>
<nextsent>if we think of the nouns as nodes and the noun-noun relationships as edges, this data structure is graph (bollobas, 1998), and combina toric methods can be used to analyze its structure.
</nextsent>
<nextsent>work using such techniques for lexical acquisition has proceeded by building classes of related words from single seed-word?
</nextsent>
<nextsent>with some desired property (such as being representative of paticular semantic class).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1428">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>trial sets consisted of 37 english-french, and 17 romanian-english aligned sentences.
</prevsent>
<prevsent>2.3 test data.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
a total of 447 english-french aligned sentences (ochand ney, 2000), <papid> C00-2163 </papid>and 248 romanian-english aligned sentences were released one week prior to the deadline.</citsent>
<aftsection>
<nextsent>participants were required to run their word alignment systems on these two sets, and submit word alignments.
</nextsent>
<nextsent>teams were allowed to submit an unlimited number of results sets for each language pair.
</nextsent>
<nextsent>2.3.1 gold standard word aligned data the gold standard for the two language pair alignments were produced using slightly different alignment procedures, which allowed us to study different schemes for producing gold standards for word aligned data.for english-french, annotators where instructed to as sign sure or probable tag to each word alignment theyproduced.
</nextsent>
<nextsent>the intersection of the sure alignments produced by the two annotators led to the final sure aligned set, while the reunion of the probable alignments led to the final probable aligned set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1431">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>this set of evaluations pertains to full coverage word alignments.
</prevsent>
<prevsent> no-null-align, where all null alignments were removed from both submission file and gold standard data.
</prevsent>
</prevsection>
<citsent citstr=" W03-0303 ">
team system name description language technologies institute, cmu bibr (zhao and vogel, 2003) <papid> W03-0303 </papid>mitre corporation fourday (henderson, 2003) <papid> W03-0306 </papid>rali - universite?</citsent>
<aftsection>
<nextsent>the montreal ralign (simard and langlais, 2003) <papid> W03-0304 </papid>romanian academy institute of artificial intelligence racai (tufis?</nextsent>
<nextsent>et al, 2003) university of alberta pro align (lin and cherry, 2003) <papid> W03-0302 </papid>university of minnesota, duluth umd (thomson mcinnes and pedersen, 2003) <papid> W03-0309 </papid>xerox research centre europe xrce (dejean et al, 2003) <papid> W03-0305 </papid>table 1: teams participating in the word alignment shared task we conducted therefore 14 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, with different figure determined for null-align and no-null-align alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1432">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>this set of evaluations pertains to full coverage word alignments.
</prevsent>
<prevsent> no-null-align, where all null alignments were removed from both submission file and gold standard data.
</prevsent>
</prevsection>
<citsent citstr=" W03-0306 ">
team system name description language technologies institute, cmu bibr (zhao and vogel, 2003) <papid> W03-0303 </papid>mitre corporation fourday (henderson, 2003) <papid> W03-0306 </papid>rali - universite?</citsent>
<aftsection>
<nextsent>the montreal ralign (simard and langlais, 2003) <papid> W03-0304 </papid>romanian academy institute of artificial intelligence racai (tufis?</nextsent>
<nextsent>et al, 2003) university of alberta pro align (lin and cherry, 2003) <papid> W03-0302 </papid>university of minnesota, duluth umd (thomson mcinnes and pedersen, 2003) <papid> W03-0309 </papid>xerox research centre europe xrce (dejean et al, 2003) <papid> W03-0305 </papid>table 1: teams participating in the word alignment shared task we conducted therefore 14 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, with different figure determined for null-align and no-null-align alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1433">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent> no-null-align, where all null alignments were removed from both submission file and gold standard data.
</prevsent>
<prevsent>team system name description language technologies institute, cmu bibr (zhao and vogel, 2003) <papid> W03-0303 </papid>mitre corporation fourday (henderson, 2003) <papid> W03-0306 </papid>rali - universite?</prevsent>
</prevsection>
<citsent citstr=" W03-0304 ">
the montreal ralign (simard and langlais, 2003) <papid> W03-0304 </papid>romanian academy institute of artificial intelligence racai (tufis?</citsent>
<aftsection>
<nextsent>et al, 2003) university of alberta pro align (lin and cherry, 2003) <papid> W03-0302 </papid>university of minnesota, duluth umd (thomson mcinnes and pedersen, 2003) <papid> W03-0309 </papid>xerox research centre europe xrce (dejean et al, 2003) <papid> W03-0305 </papid>table 1: teams participating in the word alignment shared task we conducted therefore 14 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, with different figure determined for null-align and no-null-align alignments.</nextsent>
<nextsent>seven teams from around the world participated in the word alignment shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1434">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>team system name description language technologies institute, cmu bibr (zhao and vogel, 2003) <papid> W03-0303 </papid>mitre corporation fourday (henderson, 2003) <papid> W03-0306 </papid>rali - universite?</prevsent>
<prevsent>the montreal ralign (simard and langlais, 2003) <papid> W03-0304 </papid>romanian academy institute of artificial intelligence racai (tufis?</prevsent>
</prevsection>
<citsent citstr=" W03-0302 ">
et al, 2003) university of alberta pro align (lin and cherry, 2003) <papid> W03-0302 </papid>university of minnesota, duluth umd (thomson mcinnes and pedersen, 2003) <papid> W03-0309 </papid>xerox research centre europe xrce (dejean et al, 2003) <papid> W03-0305 </papid>table 1: teams participating in the word alignment shared task we conducted therefore 14 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, with different figure determined for null-align and no-null-align alignments.</citsent>
<aftsection>
<nextsent>seven teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the names of the participating systems, the corresponding institutions,and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>all seven teams participated in the romanian-english subtask, and five teams participated in the english-frenchsubtask.3 there were no restrictions placed on the number of submissions each team could make.
</nextsent>
<nextsent>this resulted in total of 27 submissions from the seven teams, where 14 sets of results were submitted for the english-french subtask, and 13 for the romanian-english subtask.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1435">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>team system name description language technologies institute, cmu bibr (zhao and vogel, 2003) <papid> W03-0303 </papid>mitre corporation fourday (henderson, 2003) <papid> W03-0306 </papid>rali - universite?</prevsent>
<prevsent>the montreal ralign (simard and langlais, 2003) <papid> W03-0304 </papid>romanian academy institute of artificial intelligence racai (tufis?</prevsent>
</prevsection>
<citsent citstr=" W03-0309 ">
et al, 2003) university of alberta pro align (lin and cherry, 2003) <papid> W03-0302 </papid>university of minnesota, duluth umd (thomson mcinnes and pedersen, 2003) <papid> W03-0309 </papid>xerox research centre europe xrce (dejean et al, 2003) <papid> W03-0305 </papid>table 1: teams participating in the word alignment shared task we conducted therefore 14 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, with different figure determined for null-align and no-null-align alignments.</citsent>
<aftsection>
<nextsent>seven teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the names of the participating systems, the corresponding institutions,and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>all seven teams participated in the romanian-english subtask, and five teams participated in the english-frenchsubtask.3 there were no restrictions placed on the number of submissions each team could make.
</nextsent>
<nextsent>this resulted in total of 27 submissions from the seven teams, where 14 sets of results were submitted for the english-french subtask, and 13 for the romanian-english subtask.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1436">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>team system name description language technologies institute, cmu bibr (zhao and vogel, 2003) <papid> W03-0303 </papid>mitre corporation fourday (henderson, 2003) <papid> W03-0306 </papid>rali - universite?</prevsent>
<prevsent>the montreal ralign (simard and langlais, 2003) <papid> W03-0304 </papid>romanian academy institute of artificial intelligence racai (tufis?</prevsent>
</prevsection>
<citsent citstr=" W03-0305 ">
et al, 2003) university of alberta pro align (lin and cherry, 2003) <papid> W03-0302 </papid>university of minnesota, duluth umd (thomson mcinnes and pedersen, 2003) <papid> W03-0309 </papid>xerox research centre europe xrce (dejean et al, 2003) <papid> W03-0305 </papid>table 1: teams participating in the word alignment shared task we conducted therefore 14 evaluations for each submission file: aer, sure/probable precision, sure/probable recall, and sure/probable f-measure, with different figure determined for null-align and no-null-align alignments.</citsent>
<aftsection>
<nextsent>seven teams from around the world participated in the word alignment shared task.
</nextsent>
<nextsent>table 1 lists the names of the participating systems, the corresponding institutions,and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
</nextsent>
<nextsent>all seven teams participated in the romanian-english subtask, and five teams participated in the english-frenchsubtask.3 there were no restrictions placed on the number of submissions each team could make.
</nextsent>
<nextsent>this resulted in total of 27 submissions from the seven teams, where 14 sets of results were submitted for the english-french subtask, and 13 for the romanian-english subtask.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1437">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>ofthe 27 total submissions, there were 17 in the limited resources subtask, and 10 in the unlimited resources sub task.
</prevsent>
<prevsent>tables 2 and 3 show all of the submissions for each team in the two subtasks, and provide brief description of their approaches.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
while each participating system was unique, there were few unifying themes.four teams had approaches that relied (to varying de grees) on an ibm model of statistical machine translation(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>umd was straightforward implementation of ibm model 2, bibr employed boosting procedure in deriving an ibm model 1 lexicon, ralign used ibm model 2 as foundation for their recursive splitting procedure, and xrce used ibm model 4 as base for alignment with lemmatized text and bilingual lexicons.
</nextsent>
<nextsent>two teams made use of syntactic structure in the text to be aligned.
</nextsent>
<nextsent>pro align satisfies constraints derived from dependency tree parse of the english sentence being 3the two teams that did not participate in english-french were fourday and racai.
</nextsent>
<nextsent>aligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1438">
<title id=" W03-0301.xml">an evaluation exercise for word alignment </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, aer for english-french (5.71% highest error reduction) is clearly better than the aer for romanian-english (28.86% highest error reduction).
</prevsent>
<prevsent>this difference in performance between the two datasets is not surprise.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
as expected, word alignment, like many other nlp tasks (banko and brill, 2001), <papid> P01-1005 </papid>highly benefits from large amounts of training data.</citsent>
<aftsection>
<nextsent>increased performance is therefore expected when larger training datasets are available.
</nextsent>
<nextsent>the only evaluation set where romanian-english data leads to better performance is the probable alignmentsset.
</nextsent>
<nextsent>we believe however that these figures are not directly comparable, since the english-french probable alignments were obtained as reunion of the alignments assigned by two different annotators, while for the romanian-english probable set two annotators hadto reach an agreement (that is, an intersection of their individual alignment assignments).interestingly, in an overall evaluation, the limited resources systems seem to lead to better results than those with unlimited resources.
</nextsent>
<nextsent>out of 28 different evaluation figures, 20 top ranked figures are provided by systems with limited resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1439">
<title id=" W03-1122.xml">question answering based on virtually integrated lexical knowledge base </title>
<section> measures.  </section>
<citcontext>
<prevsection>
<prevsent>all of the relations in figure 2 are translated into logical form (see below).
</prevsent>
<prevsent>as shown in interpretation as abduction?
</prevsent>
</prevsection>
<citsent citstr=" P88-1012 ">
(hobbs et al 1988), <papid> P88-1012 </papid>abductive inference is inference to the best explanation?.</citsent>
<aftsection>
<nextsent>these relations showed the interpretation of text is the minimal explanation of why the text would be true?
</nextsent>
<nextsent>based on the abductive inference.
</nextsent>
<nextsent>by the same token, the interpretation of question is the minimal explanation of why the question would be true?
</nextsent>
<nextsent>based on set of lexical knowledge bases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1442">
<title id=" W03-1901.xml">outline of the international standard linguistic annotation framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the focus of the work is on data modeling, markup, data exchange and the evaluation of language resources other than termi nologies (which have already been treated in iso/tc 37).
</prevsent>
<prevsent>the worldwide use of iso/tc 37/sc4 standards should improve information management within industrial, technical and scientific environments, and increase efficiency in computer supported language communication.within iso/tc 37/sc 4, working group (wg11) has been established to develop linguistic annotation framework (laf) that can serve as basis for harmonizing existing language resources as well as developing new ones.
</prevsent>
</prevsection>
<citsent citstr=" W03-1905 ">
the overall design ofthe architecture and the data model that it will in stantiate have been described in ide et al, 2003.<papid> W03-1905 </papid></citsent>
<aftsection>
<nextsent>in this paper we provide description of the data model and its instantiations in laf, in order to enable annotators to begin to explore how their schemes will map into the framework.
</nextsent>
<nextsent>the following terms and definitions are used in the discussion that follows:annotation: the process of adding linguistic information to language data (annotation of cor pus?)
</nextsent>
<nextsent>or the linguistic information itself (an annotation?), independent of its representation.
</nextsent>
<nextsent>for example, one may annotate document for syntax using lisp-like representation, an xml representation, etc.representation: the format in which the annotation is rendered, e.g. xml, lisp, etc. independent of its content.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1444">
<title id=" W03-1901.xml">outline of the international standard linguistic annotation framework </title>
<section> laf overview.  </section>
<citcontext>
<prevsection>
<prevsent>there is no requirement that single xml-compliant document may be created by merging stand-off annotation documents with the primary data; that is, two annotation documents may specify trees over the primary data that contain overlapping hierarchies.
</prevsent>
<prevsent>laf development has proceeded by first identifying an abstract data model that can formally describe linguistic annotations, distinct from any particular representation (as defined in the previoussection).
</prevsent>
</prevsection>
<citsent citstr=" P01-1040 ">
development of this model has been discussed extensively within the language engineering community and tested on variety of annotation types (see ide and romary, 2001<papid> P01-1040 </papid>a, 2001b, 2002).</citsent>
<aftsection>
<nextsent>the data model forms the core of the framework by serving as the reference point for all annotation representation schemes.
</nextsent>
<nextsent>the overall design of laf is illustrated in figure 1.
</nextsent>
<nextsent>the fundamental principle is that the user con-.
</nextsent>
<nextsent>trols the representation format for linguistic annotations, which is mappable to the data model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1464">
<title id=" W03-0416.xml">an efficient clustering algorithm for class based language models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>obtained by clustering can improve the performance of various nlp tasks.
</prevsent>
<prevsent>examples have been class-based
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
-gram models(brown et al, 1992; <papid> J92-4003 </papid>kneser and ney, 1993), smoothing techniques for structural disambiguation (li and abe, 1998) <papid> P98-2124 </papid>and word sense disambiguation (shutze, 1998).</citsent>
<aftsection>
<nextsent>in this paper, we define general form for class-based probabilistic language models, and propose an efficient and model-theoretic algorithm for clustering based onthis.
</nextsent>
<nextsent>the algorithm involves three operations, classify, merge, and split, all of which decreases the optimization function based on the mdl principle (rissanen, 1984), and can efficiently find point near the local optimum.
</nextsent>
<nextsent>the algorithm is applicable to more general tasks than existing studies (li and abe, 1998; <papid> P98-2124 </papid>berkhinand becher, 2002), and computational costs are significantly small, which allows its application to very large corpora.</nextsent>
<nextsent>clustering algorithms may be classified into threetypes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1466">
<title id=" W03-0416.xml">an efficient clustering algorithm for class based language models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>obtained by clustering can improve the performance of various nlp tasks.
</prevsent>
<prevsent>examples have been class-based
</prevsent>
</prevsection>
<citsent citstr=" P98-2124 ">
-gram models(brown et al, 1992; <papid> J92-4003 </papid>kneser and ney, 1993), smoothing techniques for structural disambiguation (li and abe, 1998) <papid> P98-2124 </papid>and word sense disambiguation (shutze, 1998).</citsent>
<aftsection>
<nextsent>in this paper, we define general form for class-based probabilistic language models, and propose an efficient and model-theoretic algorithm for clustering based onthis.
</nextsent>
<nextsent>the algorithm involves three operations, classify, merge, and split, all of which decreases the optimization function based on the mdl principle (rissanen, 1984), and can efficiently find point near the local optimum.
</nextsent>
<nextsent>the algorithm is applicable to more general tasks than existing studies (li and abe, 1998; <papid> P98-2124 </papid>berkhinand becher, 2002), and computational costs are significantly small, which allows its application to very large corpora.</nextsent>
<nextsent>clustering algorithms may be classified into threetypes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1477">
<title id=" W03-0426.xml">named entity recognition with long short term memory </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sard net, self-organising map for sequences is used to generate representations for the lexical items presented to the lstm network, whilst orthogonal representations are used to represent the part of speech and chunk tags.
</prevsent>
<prevsent>in this paper, long short-term memory (lstm) (hochreiter and schmidhuber, 1997) is applied to named entity recognition, using data from the reuters corpus, english language, volume 1, and the european corpus initiative multilingual corpus 1.lstm is an architecture and training algorithm for recurrent neural networks (rnns), capable of remembering information over long time periods during the processing of sequence.
</prevsent>
</prevsection>
<citsent citstr=" W01-0722 ">
lstm was applied to an earlier conll shared task,namely clause identification (hammerton, 2001) <papid> W01-0722 </papid>although the performance was significantly below the performance of other methods, e.g. lstm achieved an fscore of 50.42 on the test data where other systems?</citsent>
<aftsection>
<nextsent>fscores ranged from 62.77 to 80.44.
</nextsent>
<nextsent>however, not all training data was used in training the lstm networks.
</nextsent>
<nextsent>better performance has since been obtained where the complete training set was used (hammerton, unpublished), yielding an fscore of 64.66 on the test data.
</nextsent>
<nextsent>an efficient method of representing lexical items isneeded.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1479">
<title id=" W03-1612.xml">paraphrasing rules for automatic evaluation of translation into japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the evaluation of machine translation is not so straightforward since there are infinite ways to out put similar meanings and one can not enumerate the right answers exhaustively.
</prevsent>
<prevsent>inspite of that, automatic translation evaluation is practically important because the evaluation is laborious work for human sand evaluation by humans tends to be arbitrary.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
automatic evaluation is more reliable than human evaluation because of its consistency for the same trans lations.bleu (papineni et al, 2002<papid> P02-1040 </papid>b) is one of the methods for automatic evaluation of translation quality.</citsent>
<aftsection>
<nextsent>it uses the ratio of co-occurring n-grams betweena translation and single or multiple reference sentences.
</nextsent>
<nextsent>high correlation is reported between the bleu score and human evaluations for translations from arabic, chinese, french, and spanish to english (papineni et al, 2002<papid> P02-1040 </papid>a).</nextsent>
<nextsent>this paper investigates how to apply bleu to the evaluation of english-to-japanese translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1487">
<title id=" W03-1612.xml">paraphrasing rules for automatic evaluation of translation into japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several methods of paraphrasing have been studied.
</prevsent>
<prevsent>some of them aimat the preprocessing of machine translation (mita mura and nyberg, 2001; takahashi et al, 2001).they use paraphrasing to transform the input sentences so that the language-transferring routines can handle them easily.
</prevsent>
</prevsection>
<citsent citstr=" C02-1161 ">
another application of paraphrasing is to canonicalize many expressions that have the same semantics, supporting information retrieval or question answering (zukerman and raskutti, 2002; <papid> C02-1161 </papid>torisawa, 2002).<papid> C02-1120 </papid></citsent>
<aftsection>
<nextsent>paraphrasing techniques in these studies are considered to be useful, but they are difficult to evaluate.
</nextsent>
<nextsent>machine translation evaluation requires methods to judge whether two sentences have the same meaning even when they are syntactically different.
</nextsent>
<nextsent>therefore if set of paraphrasing rules contributes to more reliable translation evaluation, it can be said to be good?
</nextsent>
<nextsent>paraphrasing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1488">
<title id=" W03-1612.xml">paraphrasing rules for automatic evaluation of translation into japanese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several methods of paraphrasing have been studied.
</prevsent>
<prevsent>some of them aimat the preprocessing of machine translation (mita mura and nyberg, 2001; takahashi et al, 2001).they use paraphrasing to transform the input sentences so that the language-transferring routines can handle them easily.
</prevsent>
</prevsection>
<citsent citstr=" C02-1120 ">
another application of paraphrasing is to canonicalize many expressions that have the same semantics, supporting information retrieval or question answering (zukerman and raskutti, 2002; <papid> C02-1161 </papid>torisawa, 2002).<papid> C02-1120 </papid></citsent>
<aftsection>
<nextsent>paraphrasing techniques in these studies are considered to be useful, but they are difficult to evaluate.
</nextsent>
<nextsent>machine translation evaluation requires methods to judge whether two sentences have the same meaning even when they are syntactically different.
</nextsent>
<nextsent>therefore if set of paraphrasing rules contributes to more reliable translation evaluation, it can be said to be good?
</nextsent>
<nextsent>paraphrasing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1497">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>enumerating all parses is infeasible for large grammars; however, dynamic programming over packed chart can be usedto efficiently estimate the model parameters.
</prevsent>
<prevsent>we describe parellelised implementation which runs on beowulf cluster and allows the complete wsj penn treebank to be used for estimation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
statistical parsing models have recently been developed for combinatory categorial grammar (ccg, steedman (2000)) and used in wide-coverage parsers applied to the wsj penn treebank (clark et al., 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002).<papid> P02-1043 </papid></citsent>
<aftsection>
<nextsent>an attraction of ccg is its elegant treatment of coordination and extraction, allowing recovery of thelong-range dependencies inherent in these constructions.
</nextsent>
<nextsent>we would like the parsing model to includelong-range dependencies, but this introduces problems for generative parsing models similar to those described by abney (1997) <papid> J97-4005 </papid>for attribute-value grammars; hence hockenmaier and steedman do not include such dependencies in their model, and clarket al include the dependencies but use an inconsistent model.</nextsent>
<nextsent>following abney, we propose loglinear framework which incorporates long-range dependencies as features without loss of consistency.log-linear models have previously been applied to statistical parsing (johnson et al, 1999;<papid> P99-1069 </papid>toutanova et al, 2002; riezler et al, 2002; <papid> P02-1035 </papid>osborne, 2000).<papid> C00-1085 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1498">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>enumerating all parses is infeasible for large grammars; however, dynamic programming over packed chart can be usedto efficiently estimate the model parameters.
</prevsent>
<prevsent>we describe parellelised implementation which runs on beowulf cluster and allows the complete wsj penn treebank to be used for estimation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
statistical parsing models have recently been developed for combinatory categorial grammar (ccg, steedman (2000)) and used in wide-coverage parsers applied to the wsj penn treebank (clark et al., 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002).<papid> P02-1043 </papid></citsent>
<aftsection>
<nextsent>an attraction of ccg is its elegant treatment of coordination and extraction, allowing recovery of thelong-range dependencies inherent in these constructions.
</nextsent>
<nextsent>we would like the parsing model to includelong-range dependencies, but this introduces problems for generative parsing models similar to those described by abney (1997) <papid> J97-4005 </papid>for attribute-value grammars; hence hockenmaier and steedman do not include such dependencies in their model, and clarket al include the dependencies but use an inconsistent model.</nextsent>
<nextsent>following abney, we propose loglinear framework which incorporates long-range dependencies as features without loss of consistency.log-linear models have previously been applied to statistical parsing (johnson et al, 1999;<papid> P99-1069 </papid>toutanova et al, 2002; riezler et al, 2002; <papid> P02-1035 </papid>osborne, 2000).<papid> C00-1085 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1499">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical parsing models have recently been developed for combinatory categorial grammar (ccg, steedman (2000)) and used in wide-coverage parsers applied to the wsj penn treebank (clark et al., 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002).<papid> P02-1043 </papid></prevsent>
<prevsent>an attraction of ccg is its elegant treatment of coordination and extraction, allowing recovery of thelong-range dependencies inherent in these construc tions.</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
we would like the parsing model to includelong-range dependencies, but this introduces problems for generative parsing models similar to those described by abney (1997) <papid> J97-4005 </papid>for attribute-value grammars; hence hockenmaier and steedman do not include such dependencies in their model, and clarket al include the dependencies but use an inconsistent model.</citsent>
<aftsection>
<nextsent>following abney, we propose loglinear framework which incorporates long-range dependencies as features without loss of consistency.log-linear models have previously been applied to statistical parsing (johnson et al, 1999;<papid> P99-1069 </papid>toutanova et al, 2002; riezler et al, 2002; <papid> P02-1035 </papid>osborne, 2000).<papid> C00-1085 </papid></nextsent>
<nextsent>typically, these approaches have enumerated all possible parses for model estimation and finding the most probable parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1500">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an attraction of ccg is its elegant treatment of coordination and extraction, allowing recovery of thelong-range dependencies inherent in these constructions.
</prevsent>
<prevsent>we would like the parsing model to includelong-range dependencies, but this introduces problems for generative parsing models similar to those described by abney (1997) <papid> J97-4005 </papid>for attribute-value grammars; hence hockenmaier and steedman do not include such dependencies in their model, and clarket al include the dependencies but use an inconsistent model.</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
following abney, we propose loglinear framework which incorporates long-range dependencies as features without loss of consistency.log-linear models have previously been applied to statistical parsing (johnson et al, 1999;<papid> P99-1069 </papid>toutanova et al, 2002; riezler et al, 2002; <papid> P02-1035 </papid>osborne, 2000).<papid> C00-1085 </papid></citsent>
<aftsection>
<nextsent>typically, these approaches have enumerated all possible parses for model estimation and finding the most probable parse.
</nextsent>
<nextsent>for grammars extracted from the penn treebank (in our case ccgbank (hockenmaier, 2003)), enumerating all parses is infeasible.
</nextsent>
<nextsent>one approach to this problem is to sample the parse space for estimation, e.g.osborne (2000).<papid> C00-1085 </papid></nextsent>
<nextsent>in this paper we use dynamic programming technique applied to packed chart, similar to those proposed by geman and johnson (2002)<papid> P02-1036 </papid>and miyao and tsujii (2002), which efficiently estimates the model parameters over the complete space without enumerating parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1501">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an attraction of ccg is its elegant treatment of coordination and extraction, allowing recovery of thelong-range dependencies inherent in these constructions.
</prevsent>
<prevsent>we would like the parsing model to includelong-range dependencies, but this introduces problems for generative parsing models similar to those described by abney (1997) <papid> J97-4005 </papid>for attribute-value grammars; hence hockenmaier and steedman do not include such dependencies in their model, and clarket al include the dependencies but use an inconsistent model.</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
following abney, we propose loglinear framework which incorporates long-range dependencies as features without loss of consistency.log-linear models have previously been applied to statistical parsing (johnson et al, 1999;<papid> P99-1069 </papid>toutanova et al, 2002; riezler et al, 2002; <papid> P02-1035 </papid>osborne, 2000).<papid> C00-1085 </papid></citsent>
<aftsection>
<nextsent>typically, these approaches have enumerated all possible parses for model estimation and finding the most probable parse.
</nextsent>
<nextsent>for grammars extracted from the penn treebank (in our case ccgbank (hockenmaier, 2003)), enumerating all parses is infeasible.
</nextsent>
<nextsent>one approach to this problem is to sample the parse space for estimation, e.g.osborne (2000).<papid> C00-1085 </papid></nextsent>
<nextsent>in this paper we use dynamic programming technique applied to packed chart, similar to those proposed by geman and johnson (2002)<papid> P02-1036 </papid>and miyao and tsujii (2002), which efficiently estimates the model parameters over the complete space without enumerating parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1502">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an attraction of ccg is its elegant treatment of coordination and extraction, allowing recovery of thelong-range dependencies inherent in these constructions.
</prevsent>
<prevsent>we would like the parsing model to includelong-range dependencies, but this introduces problems for generative parsing models similar to those described by abney (1997) <papid> J97-4005 </papid>for attribute-value grammars; hence hockenmaier and steedman do not include such dependencies in their model, and clarket al include the dependencies but use an inconsistent model.</prevsent>
</prevsection>
<citsent citstr=" C00-1085 ">
following abney, we propose loglinear framework which incorporates long-range dependencies as features without loss of consistency.log-linear models have previously been applied to statistical parsing (johnson et al, 1999;<papid> P99-1069 </papid>toutanova et al, 2002; riezler et al, 2002; <papid> P02-1035 </papid>osborne, 2000).<papid> C00-1085 </papid></citsent>
<aftsection>
<nextsent>typically, these approaches have enumerated all possible parses for model estimation and finding the most probable parse.
</nextsent>
<nextsent>for grammars extracted from the penn treebank (in our case ccgbank (hockenmaier, 2003)), enumerating all parses is infeasible.
</nextsent>
<nextsent>one approach to this problem is to sample the parse space for estimation, e.g.osborne (2000).<papid> C00-1085 </papid></nextsent>
<nextsent>in this paper we use dynamic programming technique applied to packed chart, similar to those proposed by geman and johnson (2002)<papid> P02-1036 </papid>and miyao and tsujii (2002), which efficiently estimates the model parameters over the complete space without enumerating parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1504">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for grammars extracted from the penn treebank (in our case ccgbank (hockenmaier, 2003)), enumerating all parses is infeasible.
</prevsent>
<prevsent>one approach to this problem is to sample the parse space for estimation, e.g.osborne (2000).<papid> C00-1085 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
in this paper we use dynamic programming technique applied to packed chart, similar to those proposed by geman and johnson (2002)<papid> P02-1036 </papid>and miyao and tsujii (2002), which efficiently estimates the model parameters over the complete space without enumerating parses.</citsent>
<aftsection>
<nextsent>the estimation method is similar to the inside-outside algorithm used fores timating pcfg (lari and young, 1990).
</nextsent>
<nextsent>miyao and tsujii (2002) apply their estimation technique to an automatically extracted tree adjoining grammar using improved iterative scaling (iis, della pietra et al (1997)).
</nextsent>
<nextsent>however, their model has significant memory requirements which limits them to using 868 sentences as training data.
</nextsent>
<nextsent>we usea parallel ised version of generalised iterative scaling (gis, darroch and rat cliff (1972)) on beowulfcluster which allows the complete wsj penn tree bank to be used as training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1514">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> log-linear models for ccg.  </section>
<citcontext>
<prevsection>
<prevsent>is the set of possible parses for . the advantage of log-linear model is that the features can be arbitrary functions over parses.
</prevsent>
<prevsent>this means that any dependencies ? including overlapping and long-range dependencies ? can be included in the model, irrespective of whether those dependencies are independent.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the theory underlying log-linear models is described in della pietra et al (1997) and berger et al (1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>briefly, the log-linear form in (6) is derived by choosing the model with maximum entropy from set of models that satisfy certain set of constraints (rosenfeld, 1996).
</nextsent>
<nextsent>the constraints are that, for each feature fi: ? !;s p(s )p(!|s ) fi(!)
</nextsent>
<nextsent>= ? !;s p(!; ) fi(!)
</nextsent>
<nextsent>(8) where the sums are over all possible parse-sentence pairs and p(s ) is the relative frequency of sentence in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1516">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> estimation using gis.  </section>
<citcontext>
<prevsection>
<prevsent>fi ep(t) fi ) 1 (10) where (t) is the iteration index and the constant is defined as max !;s fi(!).
</prevsent>
<prevsent>in practice is maximised over the sentences in the training data.
</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
implementations of gis typically use correction fea ture?, but following curran and clark (2003) <papid> E03-1071 </papid>we donot use such feature, which simplifies the algo rithm.</citsent>
<aftsection>
<nextsent>calculating ep(t) fi requires summing over all derivations which include fi for each packed chart in the training data.
</nextsent>
<nextsent>the key to performing this sum efficiently is to write the sum in terms of inside and outside scores for each conjunctive node.
</nextsent>
<nextsent>the inside and outside scores can be defined recursively, as in the inside-outside algorithm for pcfgs.
</nextsent>
<nextsent>if the inside score for conjunctive node is denoted c, and the 5miyao and tsujii have single root conjunctive node; the disjunctive root nodes we define correspond to the roots of ccg derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1517">
<title id=" W03-1013.xml">loglinear models for wide coverage ccg parsing </title>
<section> estimation using gis.  </section>
<citcontext>
<prevsection>
<prevsent>c ? {d?|d??(c);d?,d} d? ?  fi(c) ? ?
</prevsent>
<prevsent>(15) the normalisation constant zs is the sum of the inside scores for the root disjunctive nodes: zs = ? drr dr (16) in order to calculate inside scores, the scores for daughter nodes need to be calculated before the scores for mother nodes (and vice versa for the out side scores).
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
this can easily be achieved by ordering the nodes in the bottom-up cky parsing order.note that the inside-outside approach can be combined with any maximum entropy estimation procedure, such as those evaluated by malouf (2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>finally, in order to avoid over fitting, we use gaussian prior on the parameters of the model (chenand rosenfeld, 1999), which requires slight modification to the update rule in (10).
</nextsent>
<nextsent>a gaussian prior also handles the problem of pseudo-maximal?
</nextsent>
<nextsent>features (johnson et al, 1999).<papid> P99-1069 </papid></nextsent>
<nextsent>the parser is based on clark et al (2002) <papid> P02-1042 </papid>and takesas input pos-tagged sentence with set of possible lexical categories assigned to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1523">
<title id=" W03-1303.xml">using domain specific verbs for term classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the precision of the classification method reached 64%.
</prevsent>
<prevsent>basic notions used when describing specific problem domain are concepts, classes and attributes (or features).
</prevsent>
</prevsection>
<citsent citstr=" C00-1077 ">
the identification of concepts, linguistically represented by domain-specific terms (maynard and ananiadou, 2000), <papid> C00-1077 </papid>is basic step in the automated acquisition of knowledge from textual documents.</citsent>
<aftsection>
<nextsent>textual documents describing new knowledge in an intensively expanding domain are swamped by new terms representing newly identified or created concepts.
</nextsent>
<nextsent>dynamic domains, such as biomedicine, cannot be represented by static models, since new discoveries give rise to the appearance of new terms.
</nextsent>
<nextsent>this makes the automatic term recognition (atr) tools essential assets for efficient knowledge acquisition.
</nextsent>
<nextsent>however, atr itself is not sufficient when it comes to organizing newly acquired knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1524">
<title id=" W02-1411.xml">acquisition of lexical paraphrases from texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>paraphrasing involves various types of transformations of expressions into the same language, and thus there is generally no all-purpose design and information resource.among the many types of paraphrasing, hand written construction may be best for syntactic paraphrasing knowledge or knowledge of functional words because the number of resulting phenomena can be counted.
</prevsent>
<prevsent>on the other hand,we need to acquire lexical paraphrasing knowledge automatically or efficiently, since there is an enormous number of phenomena observed for an enormous number of content words.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
some works, such as barzilay and mckeown (2001), <papid> P01-1008 </papid>have acquired paraphrasing knowledgeautomatically.</citsent>
<aftsection>
<nextsent>all of those works found differences from paraphrase corpus, where each expression is aligned to another expression (or more) with the same meaning and in the same language.
</nextsent>
<nextsent>unfortunately, there is no paraphrase corpus widely available except for few collections such as those prepared by shirai et al (2001) and zhang et al (2001).
</nextsent>
<nextsent>most of those works collected paraphrase corpora by employing special situations, such as multiple news resources from the same events or multiple translations of the same (and well-known) story inother languages.
</nextsent>
<nextsent>however, since these situations seem to be really special, we believe that the collection of many paraphrase corpora in the near future is quite hopeless.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1525">
<title id=" W02-1411.xml">acquisition of lexical paraphrases from texts </title>
<section> contextual similarity vs..  </section>
<citcontext>
<prevsection>
<prevsent>synonymy paraphrasability is the degree of replacability for two expressions 1 and 2, which are regarded as different from each other in some sense.
</prevsent>
<prevsent>this definition implies the notion that 1 should not be judged as the same (or similar) as 2 in the sense of meaning.
</prevsent>
</prevsection>
<citsent citstr=" P99-1062 ">
of course, similarity of meaning and paraphrasability are very closely correlated with each other, and kurohashi and sakai (1999) <papid> P99-1062 </papid>utilize this feature to paraphrase japanese expressions (in order to comprehend them more easily).</citsent>
<aftsection>
<nextsent>they use japanese dictionary written for humans (or more precisely,children) to replace part of the target expression with different one by judging its local context computed by thesaurus.
</nextsent>
<nextsent>we propose that replacability (obtained by the corpus, for example) is more important factor in judging the paraphrasability of expressions than their meaning as defined in dictionary.
</nextsent>
<nextsent>for example, words used only in some special situations, such as for children or in ancient documents, should not be used in paraphrase even though it has synonymy.on the contrary, even if synonymy is not satisfied, we still focus on expressions that are replaceable.
</nextsent>
<nextsent>hypernymy is one example of this.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1526">
<title id=" W02-1411.xml">acquisition of lexical paraphrases from texts </title>
<section> contextual similarity vs..  </section>
<citcontext>
<prevsection>
<prevsent>a hypernym is not paraphrase in strict sense due to the loss of information.
</prevsent>
<prevsent>however, this kind of paraphrasing is still useful from the engineering point of view.
</prevsent>
</prevsection>
<citsent citstr=" C02-1163 ">
for instance, these loose (and therefore many) paraphrases are more effective in the case of reluctant processing, where we must necessarily change an expression for various reasons such as our requirement in paraphrase-based machine translation (yamamoto, 2002).<papid> C02-1163 </papid></citsent>
<aftsection>
<nextsent>moreover, this kind of paraphrase loses nothing when it is used as anaphora or when it is trivial and out of major interest in the context used.
</nextsent>
<nextsent>not all hypernyms are always paraphrasable, so we cannot list this type of paraphrase from only thesaurus.
</nextsent>
<nextsent>this section describes our approach to acquiring paraphrase knowledge from text corpus.
</nextsent>
<nextsent>we use perl programming language to implement all of the following processes and experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1527">
<title id=" W02-1411.xml">acquisition of lexical paraphrases from texts </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in noun-noun sequences ? paraphrasing for case particles; in japanese, it may be possible to change particle under certain context.
</prevsent>
<prevsent>voice conversion ? different description of the same word, e.g., from chinese-origin word to native japanese word
</prevsent>
</prevsection>
<citsent citstr=" P97-1004 ">
lexical paraphrasing is very useful in information retrieval, since it is necessary to expand terms for improving retrieval coverage.jacquemin et al (1997) <papid> P97-1004 </papid>have proposed acquiring syntactic and morpho-syntactic variations of the multi-word terms using corpus-based approach.</citsent>
<aftsection>
<nextsent>they have searched for variation,i.e., similar expressions using (a part of) the in put words, such as technique for measurement against measurement technique, while our target is the paraphrase of single content word.
</nextsent>
<nextsent>the goal of our work is to obtain lexical knowledge for paraphrasing.
</nextsent>
<nextsent>for this purpose we use contextual similarity, which is also used in the sense similarity computation task in the fields of natural language processing, artificial intelligence, and cognitive science.
</nextsent>
<nextsent>moreover, the idea of corpus-based context extraction is basically the same and also used in the task of automatic construction of thesauri or sense determination of unknown words.although this is the first work to use context for paraphrase knowledge extraction, many previously reported works have used context for similarity calculation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1528">
<title id=" W02-1411.xml">acquisition of lexical paraphrases from texts </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>second, similarity is relative measure while paraphrasability is an absolute measure; in many cases, we can answer can 1 paraphrase to 2 ??, but it is hard to answer is 1 similar to 2 ??.
</prevsent>
<prevsent>in other words, it is important to collect paraphrases while it may be pointless to collect similar words, since the border for the former is clearer than that of the latter.the kind of information used for defining context is important.
</prevsent>
</prevsection>
<citsent citstr=" W00-0110 ">
for this question, naga matsu and tanaka (1996) used deep case (seen in semantically tagged corpus), and kanzaki et al(2000) <papid> W00-0110 </papid>only extracted relations of nominal modi fication.</citsent>
<aftsection>
<nextsent>the most closely related work in terms of similarity source is the work of grefenstette(1994), where they obtained subject-verb, verb object, adjective-noun, and noun-noun relations from corpus.
</nextsent>
<nextsent>in contrast, as discussed in subsection 3.1, we propose extracting all of the dependency relations around content words, i.e., nouns, verbs, and adjectives.
</nextsent>
<nextsent>this is the first attempt to introduce these features into context definition, and it is obvious that coverage of extracted pairs becomes wider by using various features.
</nextsent>
<nextsent>however, we have not conducted enough experiments to prove that these factors are effective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1529">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these methods typically relyon one-parallel corpora consisting of text pairs, one in each language?
</prevsent>
<prevsent>(but cf.
</prevsent>
</prevsection>
<citsent citstr=" W99-0602 ">
simard (1999); <papid> W99-0602 </papid>see section 5).</citsent>
<aftsection>
<nextsent>however, learning the kind of semantics-to-words mapping that we desire from one-parallel data alone is difficult even for humans.
</nextsent>
<nextsent>first, given the same semantic input, different authors may (and do) delete or insert information (see figure 1); hence, direct comparison between semantic text and single verbal ization may not provide enough information regarding their underlying correspondences.
</nextsent>
<nextsent>second, single verbalizationcertainly fails to convey the variety of potential linguistic realizations of the concept that an expressive lexical chooser would ideally have access to.
</nextsent>
<nextsent>the multiple-sequence idea our approach is motivated by an analogous situation that arises in computational biology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1530">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> dictionary induction.  </section>
<citcontext>
<prevsection>
<prevsent>and that suppose given assume start that prove slots end goalprem1 prem2 figure 4: slotted lattice, computed from the lattice in figure 2, for show-from(prem1, prem2, goal).
</prevsent>
<prevsent>3.1.1 paraphrase thesaurus creation recall that the paraphrase thesaurus plays role both in aligning verbalizations and in matching lattice nodes to semantic argumentvalues.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
the main idea behind our paraphrase thesaurus induction method, motivated by barzilay and mckeown (2001), <papid> P01-1008 </papid>is that paths through lattice sausages?</citsent>
<aftsection>
<nextsent>often correspond to alternate verbalizations of the same concept, since the sausage endpoints are contexts common to allthe sausage-interior paths.
</nextsent>
<nextsent>hence, to extract paraphrases, we first compute all pairwise alignments of parallel verbalizations, discarding those of scoreless than four in order to eliminate spurious matches.4parallel sausage-interior paths that appear in several alignments are recorded as paraphrases.
</nextsent>
<nextsent>then, we iterate, realigning each pair of sentences, but withpreviously-recognized paraphrases treated as identical, until no new paraphrases are discovered.
</nextsent>
<nextsent>while the majority of the derived paraphrases are single 3this may further change the topology by forcing other nodes to be removed as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1531">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>but our techniques can still be incorporated into such systems, because we can map verbalizations to the content planners output.
</prevsent>
<prevsent>hence, we believe our approach generalizes to other settings.previous research on statistical generation has addressed different problems.
</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
some systems learn from verbalizations annotated with semantic concepts (ratnaparkhi, 2000; <papid> A00-2026 </papid>oh and rudnicky, 2000); <papid> W00-0306 </papid>in contrast, we use un-annotated corpora.</citsent>
<aftsection>
<nextsent>other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></nextsent>
<nextsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypothe ses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1532">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>but our techniques can still be incorporated into such systems, because we can map verbalizations to the content planners output.
</prevsent>
<prevsent>hence, we believe our approach generalizes to other settings.previous research on statistical generation has addressed different problems.
</prevsent>
</prevsection>
<citsent citstr=" W00-0306 ">
some systems learn from verbalizations annotated with semantic concepts (ratnaparkhi, 2000; <papid> A00-2026 </papid>oh and rudnicky, 2000); <papid> W00-0306 </papid>in contrast, we use un-annotated corpora.</citsent>
<aftsection>
<nextsent>other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></nextsent>
<nextsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypothe ses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1533">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>hence, we believe our approach generalizes to other settings.previous research on statistical generation has addressed different problems.
</prevsent>
<prevsent>some systems learn from verbalizations annotated with semantic concepts (ratnaparkhi, 2000; <papid> A00-2026 </papid>oh and rudnicky, 2000); <papid> W00-0306 </papid>in contrast, we use un-annotated corpora.</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypotheses.
</nextsent>
<nextsent>mangu et al (2000) compress these lattices into confusion networks with structure reminiscent of our sausage graphs?, utilizing alignment criteria based on word identity and external information such as phonetic similarity.using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings (van zaanen, 2000) and in machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>melamed, 2000; <papid> J00-2004 </papid>och and ney, 2000) ? <papid> P00-1056 </papid>interestingly, statistical mt techniques have been used to derive lexico-semantic mappings in the reverse?</nextsent>
<nextsent>direction of language understanding rather than generation (papineni et al, 1997; macherey et al, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1534">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>hence, we believe our approach generalizes to other settings.previous research on statistical generation has addressed different problems.
</prevsent>
<prevsent>some systems learn from verbalizations annotated with semantic concepts (ratnaparkhi, 2000; <papid> A00-2026 </papid>oh and rudnicky, 2000); <papid> W00-0306 </papid>in contrast, we use un-annotated corpora.</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypotheses.
</nextsent>
<nextsent>mangu et al (2000) compress these lattices into confusion networks with structure reminiscent of our sausage graphs?, utilizing alignment criteria based on word identity and external information such as phonetic similarity.using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings (van zaanen, 2000) and in machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>melamed, 2000; <papid> J00-2004 </papid>och and ney, 2000) ? <papid> P00-1056 </papid>interestingly, statistical mt techniques have been used to derive lexico-semantic mappings in the reverse?</nextsent>
<nextsent>direction of language understanding rather than generation (papineni et al, 1997; macherey et al, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1535">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></prevsent>
<prevsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypothe ses.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
mangu et al (2000) compress these lattices into confusion networks with structure reminiscent of our sausage graphs?, utilizing alignment criteria based on word identity and external information such as phonetic similarity.using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings (van zaanen, 2000) and in machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>melamed, 2000; <papid> J00-2004 </papid>och and ney, 2000) ? <papid> P00-1056 </papid>interestingly, statistical mt techniques have been used to derive lexico-semantic mappings in the reverse?</citsent>
<aftsection>
<nextsent>direction of language understanding rather than generation (papineni et al, 1997; macherey et al, 2001).
</nextsent>
<nextsent>in preliminary study, applying ibm-style alignment models in black-box manner (i.e., without modifi cation) to our setting did not yield promising results (chong, 2002).
</nextsent>
<nextsent>on the other hand, mt systems can often model crossing alignment situations; these are rare in our data, but we hope to account for them in future work.while recent proposals for evaluation of mt systems have involved multi-parallel corpora (thompson and brew, 1996; papineni et al, 2002), <papid> P02-1040 </papid>statistical mt algorithms typically only use one-paralleldata.</nextsent>
<nextsent>simards (1999) trilingual (rather than multi parallel) corpus method, which also computes msas,is notable exception, but he reports mixed experimental results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1536">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></prevsent>
<prevsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypothe ses.</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
mangu et al (2000) compress these lattices into confusion networks with structure reminiscent of our sausage graphs?, utilizing alignment criteria based on word identity and external information such as phonetic similarity.using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings (van zaanen, 2000) and in machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>melamed, 2000; <papid> J00-2004 </papid>och and ney, 2000) ? <papid> P00-1056 </papid>interestingly, statistical mt techniques have been used to derive lexico-semantic mappings in the reverse?</citsent>
<aftsection>
<nextsent>direction of language understanding rather than generation (papineni et al, 1997; macherey et al, 2001).
</nextsent>
<nextsent>in preliminary study, applying ibm-style alignment models in black-box manner (i.e., without modifi cation) to our setting did not yield promising results (chong, 2002).
</nextsent>
<nextsent>on the other hand, mt systems can often model crossing alignment situations; these are rare in our data, but we hope to account for them in future work.while recent proposals for evaluation of mt systems have involved multi-parallel corpora (thompson and brew, 1996; papineni et al, 2002), <papid> P02-1040 </papid>statistical mt algorithms typically only use one-paralleldata.</nextsent>
<nextsent>simards (1999) trilingual (rather than multi parallel) corpus method, which also computes msas,is notable exception, but he reports mixed experimental results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1537">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other work focuses on surface realization ? choosing among different lexical and syntactic options supplied by the lexical chooser and sentence planner ? rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means(langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore and ram bow, 2000).<papid> C00-1007 </papid></prevsent>
<prevsent>an exciting direction for future research is to apply these statistical surface realization methods to the lattices our method produces.word lattices are commonly used in speech recognition to represent different transcription hypothe ses.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
mangu et al (2000) compress these lattices into confusion networks with structure reminiscent of our sausage graphs?, utilizing alignment criteria based on word identity and external information such as phonetic similarity.using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings (van zaanen, 2000) and in machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>melamed, 2000; <papid> J00-2004 </papid>och and ney, 2000) ? <papid> P00-1056 </papid>interestingly, statistical mt techniques have been used to derive lexico-semantic mappings in the reverse?</citsent>
<aftsection>
<nextsent>direction of language understanding rather than generation (papineni et al, 1997; macherey et al, 2001).
</nextsent>
<nextsent>in preliminary study, applying ibm-style alignment models in black-box manner (i.e., without modifi cation) to our setting did not yield promising results (chong, 2002).
</nextsent>
<nextsent>on the other hand, mt systems can often model crossing alignment situations; these are rare in our data, but we hope to account for them in future work.while recent proposals for evaluation of mt systems have involved multi-parallel corpora (thompson and brew, 1996; papineni et al, 2002), <papid> P02-1040 </papid>statistical mt algorithms typically only use one-paralleldata.</nextsent>
<nextsent>simards (1999) trilingual (rather than multi parallel) corpus method, which also computes msas,is notable exception, but he reports mixed experimental results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1538">
<title id=" W02-1022.xml">bootstrapping lexical choice via multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>direction of language understanding rather than generation (papineni et al, 1997; macherey et al, 2001).
</prevsent>
<prevsent>in preliminary study, applying ibm-style alignment models in black-box manner (i.e., without modifi cation) to our setting did not yield promising results (chong, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
on the other hand, mt systems can often model crossing alignment situations; these are rare in our data, but we hope to account for them in future work.while recent proposals for evaluation of mt systems have involved multi-parallel corpora (thompson and brew, 1996; papineni et al, 2002), <papid> P02-1040 </papid>statistical mt algorithms typically only use one-paralleldata.</citsent>
<aftsection>
<nextsent>simards (1999) trilingual (rather than multi parallel) corpus method, which also computes msas,is notable exception, but he reports mixed experimental results.
</nextsent>
<nextsent>in contrast, we have shown that through application of novel composition of alignment steps, we can leverage multi-parallel corpora to create high-quality mapping dictionaries supporting effective text generation.
</nextsent>
<nextsent>acknowledgments we thank stuart allen, eli barzilay, stephen chong, michael collins, bob constable, jon kleinberg, john lafferty, kathy mckeown, dan melamed, golan yona, the columbia nlp group, and the anonymous reviewers for many helpful comments.
</nextsent>
<nextsent>thanks also to the cornell nuprl and columbia nlp groups, hubie chen, and juanita hey erman for participating in our evaluation, and the nuprl group for generating verbalizations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1539">
<title id=" W03-0506.xml">a study for document summarization based on personal annotation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 concludes the paper with simple summary and future work.
</prevsent>
<prevsent>to summarize, is to reduce complexity of documents, hence, in length, while retaining some of the important information in the original documents.
</prevsent>
</prevsection>
<citsent citstr=" W97-0704 ">
titles, keywords, tables-of-contents and abstracts might all be considered as forms of summary; here, we consider summary as aset of sentences containing some of the essential information from the original document.a lot of approaches were proposed in text summarization, such as word frequency based method (luhn,1958), cue phrase method (edmundson, 1969), position based methods (edmundson, 1969; hovy and lin, 1997; <papid> W97-0704 </papid>teufel and moens, 1997).</citsent>
<aftsection>
<nextsent>at the same time, some machine learning methods were used to integrate different clues in documents.
</nextsent>
<nextsent>given corpus and its predefined summaries as training set, it is to identify the relationships between documents and their summaries, the sentences which satisfy the rules are the ones to be extracted (kupiec et al, 1995).other machine learning methods perform sentence clustering based on set of extracted features of sentences, and, choose representative sentence from each cluster, and combine them into summary according to their original order in the text (nomoto and matsumoto, 2001).
</nextsent>
<nextsent>most of the above techniques have the limitation swe have mentioned at the beginning, they failed to supply personalized summary which reflects the interests and preferences of different users.
</nextsent>
<nextsent>there were some work based on annotation (golovchinsky et al, 1999; price et al, 1998), but they mainly focus on supplying an authoring tool which gives instructions on how to do annotation; or annotation identification and extraction which is difficult since annotation may be done freely and randomly; or annotation based query which aims at query expansion basedon annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1540">
<title id=" W03-0506.xml">a study for document summarization based on personal annotation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there were some work based on annotation (golovchinsky et al, 1999; price et al, 1998), but they mainly focus on supplying an authoring tool which gives instructions on how to do annotation; or annotation identification and extraction which is difficult since annotation may be done freely and randomly; or annotation based query which aims at query expansion basedon annotations.
</prevsent>
<prevsent>but rarely people think of using annotation for summarization.
</prevsent>
</prevsection>
<citsent citstr=" P98-2151 ">
in fact, we only found one work about summarization based on annotation (nagao and hasida, 1998), <papid> P98-2151 </papid>but annotations there are defined on complex set of gda (global document annotation)tags, which is an xml-based tag set, and allows machines to automatically infer underlying structures of documents by parsing, and authors of www files can annotate their documents by those tags, but they are not studied further about how to affect the summarization.</citsent>
<aftsection>
<nextsent>since annotations reflect users opinions, different users may have different annotations; thus summa riza tions based on annotations are tailored to users?
</nextsent>
<nextsent>interests to some extent.
</nextsent>
<nextsent>therefore we will integrate annotations into our summarization framework, which is expected to supply personalized summaries forgiven users, and different from traditional uniform summary.
</nextsent>
<nextsent>here wemake an assumption that what are annotated is interesting or important compared to other parts of document, which is reasonable since this is common view about why users make annotations.in this paper, we mainly focus on the kind of annotations that are parts of the text in order to avoid complex manuscript recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1541">
<title id=" W02-1025.xml">a method for open vocabulary speech driven text retrieval </title>
<section> problem statement.  </section>
<citcontext>
<prevsection>
<prevsent>it is often the case that couple of million terms are indexed for single ir system.on the other hand, state-of-the-art speech recognition systems still need to limit the vocabulary size (i.e., the number of words in dictionary), dueto problems in estimating statistical language models (young, 1996) and constraints associated with hardware, such as memories.
</prevsent>
<prevsent>in addition, computation time is crucial for real-time usage, including speech-driven retrieval.
</prevsent>
</prevsection>
<citsent citstr=" H92-1073 ">
in view of these problems, for many languages the vocabulary size is limited to couple of ten thousands (itou et al , 1999; paul and baker, 1992; <papid> H92-1073 </papid>steeneken and van leeuwen, 1995),which is incomparably smaller than the size of indexes for practical ir systems.in addition, high-frequency words, such as functional words and common nouns, are usually included in dictionaries and recognized with high accuracy.</citsent>
<aftsection>
<nextsent>however, those words are not necessarily useful for retrieval.
</nextsent>
<nextsent>on the contrary, low-frequencywords appearing in specific documents are often effective query terms.
</nextsent>
<nextsent>to sum up, the oov problem is inherent in speech-driven retrieval, and we need to fill the gap between speech recognition and text retrieval interms of the vocabulary size.
</nextsent>
<nextsent>in this paper, we propose method to resolve this problem aiming at open-vocabulary speech-driven retrieval.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1542">
<title id=" W02-1025.xml">a method for open vocabulary speech driven text retrieval </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>table 2: non-interpolated average precision values, averaged over 30 queries, for different methods.
</prevsent>
<prevsent>speaker method 1 2 3 4 female #1 ? 0.2831 0.2834 0.3195 female #2 ? 0.2745 0.2443 0.2846 male #1 ? 0.3005 0.2987 0.3179 male #2 ? 0.2787 0.2675 0.2957 total 0.3486 0.2842 0.2734 0.3044
</prevsent>
</prevsection>
<citsent citstr=" H94-1074 ">
the method proposed by kupiec et al  (1994) <papid> H94-1074 </papid>and our method are similar in the sense that both methods use target collections as language models for speech recognition to realize open-vocabulary speech-driven retrieval.</citsent>
<aftsection>
<nextsent>kupiec et al method, which is based on word recognition and accepts only short queries, derives multiple transcription candidates (i.e., possible word combinations), and searches target collection for the most plausible word combination.
</nextsent>
<nextsent>however, in the case of longer queries, the number of candidates increases, and thus the searching cost is prohibitive.
</nextsent>
<nextsent>this is reason why operational speech recognition systems have to limit the vocabulary size.in contrast, our method, which is based on recent continuous speech recognition framework, can accept longer sentences.
</nextsent>
<nextsent>additionally, our method uses two-stage retrieval principle to limit search space in target collection, and disambiguates only detected oov words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1543">
<title id=" W02-1211.xml">constructing of a largescale chinese english parallel corpus </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>however, almost all bilingual corpora used in research are clear (nearly without sentence omission or insertion) and literal translation bilingual texts.
</prevsent>
<prevsent>the performance tends to deteriorate significantly when these approaches are applied to noisy complex corpora (with sentence omission or insertion, less literal translation).
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
there are basically three kinds of approaches on sentence alignment: the length-based approach (gale &amp; church 1991 <papid> P91-1023 </papid>and brown et al 1991), <papid> P91-1022 </papid>the lexical approach (key &amp; roscheisen 1993), and the combination of them (chen 1993, <papid> P93-1002 </papid>wu 1994 <papid> P94-1012 </papid>and langlais 1998, etc.).</citsent>
<aftsection>
<nextsent>the first published algorithms for aligning sentences in parallel texts are length-based approach proposed by gale &amp; church (1991) <papid> P91-1023 </papid>and brow et al(1991).</nextsent>
<nextsent>based on the observation that short sentences tend to be translated as short sentences and long sentences as long sentences, they calculate the most likely sentence correspondences as function of the relative length of the candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1544">
<title id=" W02-1211.xml">constructing of a largescale chinese english parallel corpus </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>however, almost all bilingual corpora used in research are clear (nearly without sentence omission or insertion) and literal translation bilingual texts.
</prevsent>
<prevsent>the performance tends to deteriorate significantly when these approaches are applied to noisy complex corpora (with sentence omission or insertion, less literal translation).
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
there are basically three kinds of approaches on sentence alignment: the length-based approach (gale &amp; church 1991 <papid> P91-1023 </papid>and brown et al 1991), <papid> P91-1022 </papid>the lexical approach (key &amp; roscheisen 1993), and the combination of them (chen 1993, <papid> P93-1002 </papid>wu 1994 <papid> P94-1012 </papid>and langlais 1998, etc.).</citsent>
<aftsection>
<nextsent>the first published algorithms for aligning sentences in parallel texts are length-based approach proposed by gale &amp; church (1991) <papid> P91-1023 </papid>and brow et al(1991).</nextsent>
<nextsent>based on the observation that short sentences tend to be translated as short sentences and long sentences as long sentences, they calculate the most likely sentence correspondences as function of the relative length of the candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1545">
<title id=" W02-1211.xml">constructing of a largescale chinese english parallel corpus </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>however, almost all bilingual corpora used in research are clear (nearly without sentence omission or insertion) and literal translation bilingual texts.
</prevsent>
<prevsent>the performance tends to deteriorate significantly when these approaches are applied to noisy complex corpora (with sentence omission or insertion, less literal translation).
</prevsent>
</prevsection>
<citsent citstr=" P93-1002 ">
there are basically three kinds of approaches on sentence alignment: the length-based approach (gale &amp; church 1991 <papid> P91-1023 </papid>and brown et al 1991), <papid> P91-1022 </papid>the lexical approach (key &amp; roscheisen 1993), and the combination of them (chen 1993, <papid> P93-1002 </papid>wu 1994 <papid> P94-1012 </papid>and langlais 1998, etc.).</citsent>
<aftsection>
<nextsent>the first published algorithms for aligning sentences in parallel texts are length-based approach proposed by gale &amp; church (1991) <papid> P91-1023 </papid>and brow et al(1991).</nextsent>
<nextsent>based on the observation that short sentences tend to be translated as short sentences and long sentences as long sentences, they calculate the most likely sentence correspondences as function of the relative length of the candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1546">
<title id=" W02-1211.xml">constructing of a largescale chinese english parallel corpus </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>however, almost all bilingual corpora used in research are clear (nearly without sentence omission or insertion) and literal translation bilingual texts.
</prevsent>
<prevsent>the performance tends to deteriorate significantly when these approaches are applied to noisy complex corpora (with sentence omission or insertion, less literal translation).
</prevsent>
</prevsection>
<citsent citstr=" P94-1012 ">
there are basically three kinds of approaches on sentence alignment: the length-based approach (gale &amp; church 1991 <papid> P91-1023 </papid>and brown et al 1991), <papid> P91-1022 </papid>the lexical approach (key &amp; roscheisen 1993), and the combination of them (chen 1993, <papid> P93-1002 </papid>wu 1994 <papid> P94-1012 </papid>and langlais 1998, etc.).</citsent>
<aftsection>
<nextsent>the first published algorithms for aligning sentences in parallel texts are length-based approach proposed by gale &amp; church (1991) <papid> P91-1023 </papid>and brow et al(1991).</nextsent>
<nextsent>based on the observation that short sentences tend to be translated as short sentences and long sentences as long sentences, they calculate the most likely sentence correspondences as function of the relative length of the candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1549">
<title id=" W02-1211.xml">constructing of a largescale chinese english parallel corpus </title>
<section> sentence alignment.  </section>
<citcontext>
<prevsection>
<prevsent>once the algorithm had accidentally mis-aligned pair sentence, it tends to be unable to correct itself and get back on track before the end of the paragraph.
</prevsent>
<prevsent>use alone, length-based alignment algorithms are therefore neither very robust nor reliable.
</prevsent>
</prevsection>
<citsent citstr=" J93-1006 ">
kay &amp; roscheisen (1993) <papid> J93-1006 </papid>use partial alignment of lexical items induce maximum likelihood at sentence level.</citsent>
<aftsection>
<nextsent>the method is reliable but time consuming.
</nextsent>
<nextsent>chen (1993) <papid> P93-1002 </papid>combines the length-based approach and lexicon-based approach together.</nextsent>
<nextsent>a translation model is used to estimate the cost of certain alignment, and the best alignment is found by using dynamic programming as the length-based method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1554">
<title id=" W02-1905.xml">extracting exact answers to questions based on structural links </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been significant progress and interest in qa research in recent years (voorhees 2000, pasca and harabagiu 2001).
</prevsent>
<prevsent>qa is different than search engines in two aspects: (i) instead of string of keyword search terms, the query is natural language question, necessitating question parsing, (ii) instead of list of documents or urls, list of candidate answers at phrase level or sentence level are expected to be returned in response to query, hence the need for text processing beyond keyword indexing, typically supported by natural language processing (nlp) and information extraction (ie) (chinchor and marsh 1998, hovy, hermjakob and lin 2001, li and srihari 2000).
</prevsent>
</prevsection>
<citsent citstr=" A00-1041 ">
examples of the use of nlp and ie in question answering include shallow parsing (kupiec, 1993), semantic parsing (litkowski 1999), named entity tagging (abney et al  2000, <papid> A00-1041 </papid>srihari and li 1999) and high-level ie (srihari and li, 2000).</citsent>
<aftsection>
<nextsent>identifying exact or phrase-level answers is much more challenging task than sentence-level answers.
</nextsent>
<nextsent>good performance on the latter can be achieved by using sophisticated passage retrieval techniques and/or shallow level nlp/ie processing (kwok et al  2001, clarke et al  2001).
</nextsent>
<nextsent>the phrase-level answer identification involves sophisticated nlp/ie and it is difficult to apply only ir techniques for this task (prager et al  1999).
</nextsent>
<nextsent>these two tasks are closely related.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1555">
<title id=" W03-0608.xml">why cant jose read the problem of learning semantic associations in a robot environment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as result, the learning problem is now unsupervised.
</prevsent>
<prevsent>for single training im age and particular word token, we must now learn both the probability of generating that word given an object description and the correct association to one of the regions with the image.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
fortunately, there is straightforward parallel between our object recognition formulation and the statistical machine translation problem of building lexicon from an aligned bitext (brown et al, 1993;<papid> J93-2003 </papid>al-onaizan et al, 1999).</citsent>
<aftsection>
<nextsent>throughout this paper, we reason about object recognition with this analogy in mind (duygulu et al, 2002).
</nextsent>
<nextsent>what other requirements should we consider?
</nextsent>
<nextsent>since our discussion involves autonomous agents, we should pursue dynamic data acquisition model.
</nextsent>
<nextsent>we can consider the problem of learning an object recognition model as an on-line conversation between the robot and the user, and it follows the robot should be able to participate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1556">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word (in dictionary or morphological variant), typically ignoring context.
</prevsent>
<prevsent>yet ku kich (1992) observed that about 25-50% of the spelling errors found in modern documents are either context-inappropriate misuses or substitutions of valid words (such as principal and principle)which are not detected by traditional spelling cor rectors.
</prevsent>
</prevsection>
<citsent citstr=" W95-0104 ">
previous work has addressed the problem of cssc from machine learning perspective, including bayesian and decision list models (gold ing, 1995), <papid> W95-0104 </papid>winnow (golding and roth, 1996) <papid> P96-1010 </papid>and transformation-based learning (mangu and brill, 1997).generally, both tasks involve the selection between relatively small set of alternatives per key word (e.g. sense ids such as church/building and church/institution or commonly confused spellings such as quiet and quite), and are dependent on local and long-distance collocational and syntactic patterns to resolve between the set of alterna tives.</citsent>
<aftsection>
<nextsent>thus both tasks can share common feature space, data representation and algorithm infrastructure.
</nextsent>
<nextsent>we present framework of doing so, while investigating the use of mixture models in conjunction with new error-correction technique as competitive alternatives to bayesian models.
</nextsent>
<nextsent>while several authors have observed the fundamental similarities between cssc and wsd (e.g. berleant, 1995 androth, 1998), to our knowledge no previous comparative empirical study has tackled these two problems in single unified framework.
</nextsent>
<nextsent>the problem of lexical disambiguation can be modeled as classification task, in which each instance of the word to be disambiguated (target word,henceforth), identified by its context, has to be labeled with one of the established sense labels
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1557">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word (in dictionary or morphological variant), typically ignoring context.
</prevsent>
<prevsent>yet ku kich (1992) observed that about 25-50% of the spelling errors found in modern documents are either context-inappropriate misuses or substitutions of valid words (such as principal and principle)which are not detected by traditional spelling cor rectors.
</prevsent>
</prevsection>
<citsent citstr=" P96-1010 ">
previous work has addressed the problem of cssc from machine learning perspective, including bayesian and decision list models (gold ing, 1995), <papid> W95-0104 </papid>winnow (golding and roth, 1996) <papid> P96-1010 </papid>and transformation-based learning (mangu and brill, 1997).generally, both tasks involve the selection between relatively small set of alternatives per key word (e.g. sense ids such as church/building and church/institution or commonly confused spellings such as quiet and quite), and are dependent on local and long-distance collocational and syntactic patterns to resolve between the set of alterna tives.</citsent>
<aftsection>
<nextsent>thus both tasks can share common feature space, data representation and algorithm infrastructure.
</nextsent>
<nextsent>we present framework of doing so, while investigating the use of mixture models in conjunction with new error-correction technique as competitive alternatives to bayesian models.
</nextsent>
<nextsent>while several authors have observed the fundamental similarities between cssc and wsd (e.g. berleant, 1995 androth, 1998), to our knowledge no previous comparative empirical study has tackled these two problems in single unified framework.
</nextsent>
<nextsent>the problem of lexical disambiguation can be modeled as classification task, in which each instance of the word to be disambiguated (target word,henceforth), identified by its context, has to be labeled with one of the established sense labels
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1559">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> problem formulation. feature space.  </section>
<citcontext>
<prevsection>
<prevsent>feature type word pos lemma context features context moved/vbd vbd move/v context into/in in into/i context the/dt dt the/d context other/jj jj other/j target bar/nn nn bar/n context with/in in with/i context my/prp$ prp$ my/p context pint/nn nn pint/n syntactic (predicate-argument) features object to moved/vbd vbd move/v modifier other/jj jj other/j bigram collocational features -1 bigram other/jj jj other/j +1 bigram with/in in with/in figure 1: example context for wsd senseval-2 target word bar (inventory of 21 senses) and extracted features tive approach in section 4.1.
</prevsent>
<prevsent>the contexts  are represented as collection of features.
</prevsent>
</prevsection>
<citsent citstr=" W96-0210 ">
previous work in wsd and cssc (golding, 1995; <papid> W95-0104 </papid>bruce et al, 1996; <papid> W96-0210 </papid>yarowsky, 1996; golding and roth, 1996; <papid> P96-1010 </papid>pedersen, 1998)has found diverse feature types to be useful, including inflected words, lemmas and part-of-speech(pos) in variety of collocational and syntactic relationships, including local bigrams and trigrams, predicate-argument relationships, and wide-context bag-of-words associations.</citsent>
<aftsection>
<nextsent>examples of the feature types we employ are illustrated in figures 1 and 2.
</nextsent>
<nextsent>the syntactic features are intended to capture the predicate-argument relationships in the syntactic window in which the target word occurs.
</nextsent>
<nextsent>different relations are considered depending on the target words pos.
</nextsent>
<nextsent>for nouns, these relations are: verb-object, subject-verb, modifier-noun, andnoun-modified_noun; for verbs: verb-object, verb particle/preposition, verb-prepositional_object; for adjectives: modifying_adjective-noun.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1562">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> mixture models (mm).  </section>
<citcontext>
<prevsection>
<prevsent>feature type word pos lemma context features context presents vbz present/v context another dt another/d target {peace,piece} nn /n context of in of/i context the dt the/d context problem nn problem/n syntactic (predicate-argument) features object to presents vbz present/v modifier problem nn problem/n bigram collocational features -1 bigram another dt another/d +1 bigram of in of/i bigram pos environmentpos-2-1 - vbz+dt pos+1+2 - in+dt figure 2: example context for the spelling confusion set {piece,peace} and extracted features
</prevsent>
<prevsent>we investigate in this section direct statistical model that uses the same starting point as the algorithm presented in walker (1987).
</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
we then compare the functionality and the performance of this model to those of the widely used nave bayes model for the wsd task (gale et al, 1992; mooney, 1996;<papid> W96-0208 </papid>pedersen, 1998), enhanced with the full richer feature space beyond the traditional unordered bag-of words.</citsent>
<aftsection>
<nextsent>algorithm 1 nave bayes model 5 +l   8
</nextsent>
<nextsent>k 5 98nm 57  98 57  8 o
</nextsent>
<nextsent>(1) 5 98nm prq 1sutwvyx 57z 98 [ /]\^13 5 _b8nm prq 1 sut`vyx.
</nextsent>
<nextsent>k 57z _b8 (2) it is known that bayes decision rule is optimal if the distribution of the data of each class is known(duda and hart, 1973, ch.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1564">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the adaboost-enhanced mixture model is called adamixt henceforth.
</prevsent>
<prevsent>we present comparative study for four languages(english, swedish, spanish, and basque) by performing 5-fold cross-validation on the senseval-2 lexical-sample training data, using the fine-grained sense inventory.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
for english and swedish, for which pos-tagged training data was available to us, the fntbl algorithm (ngai and florian, 2001) <papid> N01-1006 </papid>based on brill (1995) <papid> J95-4004 </papid>was used to annotate the data, while for spanish mildly-supervised pos-tagging system similar to the one presented in cucerzan and yarowsky (2000) <papid> P00-1035 </papid>was employed.</citsent>
<aftsection>
<nextsent>we also present the results obtained by the different algorithms on another wsd standard set, senseval-1, also by performing 5-fold cross validation on the original training data.
</nextsent>
<nextsent>for cssc, we tested our system on the identical data from the brown corpus used by golding (1995), <papid> W95-0104 </papid>golding and roth (1996) <papid> P96-1010 </papid>andmangu and brill (1997).</nextsent>
<nextsent>finally, we present the results obtained by the investigated methods on single run on the senseval-1 and senseval-2 test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1565">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the adaboost-enhanced mixture model is called adamixt henceforth.
</prevsent>
<prevsent>we present comparative study for four languages(english, swedish, spanish, and basque) by performing 5-fold cross-validation on the senseval-2 lexical-sample training data, using the fine-grained sense inventory.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
for english and swedish, for which pos-tagged training data was available to us, the fntbl algorithm (ngai and florian, 2001) <papid> N01-1006 </papid>based on brill (1995) <papid> J95-4004 </papid>was used to annotate the data, while for spanish mildly-supervised pos-tagging system similar to the one presented in cucerzan and yarowsky (2000) <papid> P00-1035 </papid>was employed.</citsent>
<aftsection>
<nextsent>we also present the results obtained by the different algorithms on another wsd standard set, senseval-1, also by performing 5-fold cross validation on the original training data.
</nextsent>
<nextsent>for cssc, we tested our system on the identical data from the brown corpus used by golding (1995), <papid> W95-0104 </papid>golding and roth (1996) <papid> P96-1010 </papid>andmangu and brill (1997).</nextsent>
<nextsent>finally, we present the results obtained by the investigated methods on single run on the senseval-1 and senseval-2 test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1566">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the adaboost-enhanced mixture model is called adamixt henceforth.
</prevsent>
<prevsent>we present comparative study for four languages(english, swedish, spanish, and basque) by performing 5-fold cross-validation on the senseval-2 lexical-sample training data, using the fine-grained sense inventory.
</prevsent>
</prevsection>
<citsent citstr=" P00-1035 ">
for english and swedish, for which pos-tagged training data was available to us, the fntbl algorithm (ngai and florian, 2001) <papid> N01-1006 </papid>based on brill (1995) <papid> J95-4004 </papid>was used to annotate the data, while for spanish mildly-supervised pos-tagging system similar to the one presented in cucerzan and yarowsky (2000) <papid> P00-1035 </papid>was employed.</citsent>
<aftsection>
<nextsent>we also present the results obtained by the different algorithms on another wsd standard set, senseval-1, also by performing 5-fold cross validation on the original training data.
</nextsent>
<nextsent>for cssc, we tested our system on the identical data from the brown corpus used by golding (1995), <papid> W95-0104 </papid>golding and roth (1996) <papid> P96-1010 </papid>andmangu and brill (1997).</nextsent>
<nextsent>finally, we present the results obtained by the investigated methods on single run on the senseval-1 and senseval-2 test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1572">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>another important aspect that can test size m.l. bayes mm adamixt mmvc accept 50 70.0 92.0 90.0 90.0 94.2 affect 49 91.8 95.9 98.0 98.0 93.9 among 186 71.5 80.6 78.5 81.2 80.6 amount 123 71.5 79.7 79.7 82.9 83.7 begin 146 93.2 96.6 96.6 97.3 96.6 country 62 91.9 93.5 95.2 93.5 93.5 lead 49 46.9 93.9 91.8 95.9 91.8 past 74 68.9 86.5 93.2 93.2 93.2 peace 50 44.0 78.0 80.0 78.0 80.0 principal 34 58.8 82.3 88.2 85.3 88.2 quiet 66 83.3 93.9 93.9 93.9 95.5 raise 39 64.1 87.2 84.6 84.6 87.2 than 514 63.4 96.9 96.5 96.5 96.5 weather 61 86.9 98.4 95.1 96.7 98.4 overall 1503 71.1 91.2 91.2 91.8 92.2 table 4: results on the standard 14 cssc datasets be seen in table 4 is that there was no model that constantly performed best in all situations, suggesting the advantage of developing diverse space of models for classifier combination.
</prevsent>
<prevsent>5.4 using mmvc in classifier combination.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
the investigated mmvc model proves to be very effective participant in classifier combination, with substantially different output to nave bayes (9.6% averaged complementary rate, as defined inbrill and wu (1998)).<papid> P98-1029 </papid></citsent>
<aftsection>
<nextsent>table 5 shows the improvement obtained by adding the mmvc modelto empirically the best voting system we had using bayes, bayes ratio, tbl and decision lists (all classifier combination methods tried and their results are presented exhaustively in florian and yarowsky (2002)).<papid> W02-1004 </papid></nextsent>
<nextsent>the improvement is significant in both cases, as measured by paired mcnemar test: ffi w?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1573">
<title id=" W02-1005.xml">augmented mixture models for lexical disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>5.4 using mmvc in classifier combination.
</prevsent>
<prevsent>the investigated mmvc model proves to be very effective participant in classifier combination, with substantially different output to nave bayes (9.6% averaged complementary rate, as defined inbrill and wu (1998)).<papid> P98-1029 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1004 ">
table 5 shows the improvement obtained by adding the mmvc modelto empirically the best voting system we had using bayes, bayes ratio, tbl and decision lists (all classifier combination methods tried and their results are presented exhaustively in florian and yarowsky (2002)).<papid> W02-1004 </papid></citsent>
<aftsection>
<nextsent>the improvement is significant in both cases, as measured by paired mcnemar test: ffi w?
</nextsent>
<nextsent> ffi fl ? ?
</nextsent>
<nextsent>for senseval-1 data, ffi ??
</nextsent>
<nextsent> ffi fl ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1574">
<title id=" W03-1201.xml">question answering via bayesian inference on lexical relations </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>for each question, we retrieve the top {| documents using standard tfidf-based ir engine such assmart.
</prevsent>
<prevsent>we used the question set and corresponding top 50 document collection from trec 2001 for our experiments.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we used mxpost (ratnaparkhi, 1996), <papid> W96-0213 </papid>maximum entropy based pos tagger.</citsent>
<aftsection>
<nextsent>the part of speech tag is used while mapping document and question terms to their corresponding nodes in the bbn.
</nextsent>
<nextsent>the passage length we chose was  ~}| words.
</nextsent>
<nextsent>unless otherwise stated explicitly, the maximum 6height upto which the bbn was used for in ferenc ing for each q-passage pair can be assumed to be  . 5.2 evaluation.
</nextsent>
<nextsent>trec qa evaluation has two runs based on the length of system response to question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1575">
<title id=" W02-0906.xml">learning argument adjunct dictinction for basque </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years considerable effort has been done on the acquisition of lexical information.
</prevsent>
<prevsent>as several authors point out, this information is useful for wide range of applications.
</prevsent>
</prevsection>
<citsent citstr=" W98-1114 ">
for example, j. carroll et al  (1998) <papid> W98-1114 </papid>show how adding subcategorization information improves the performance of parser.</citsent>
<aftsection>
<nextsent>with this in mind our aim is to obtain system that automatically discriminates between subcategorized elements of verbs (arguments) and non-subcategorized ones (adjuncts).
</nextsent>
<nextsent>we have evaluated our system in two ways: comparing the results to gold standard and estimating the coverage over sentences in the corpus.
</nextsent>
<nextsent>the purpose was to find out which was the impact of each approach on this particular task.
</nextsent>
<nextsent>the two methods of evaluation yield significantly different results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1576">
<title id=" W02-0906.xml">learning argument adjunct dictinction for basque </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the contrary, the elements belonging to the central part of the continuum can be easily misclassified.
</prevsent>
<prevsent>for further reference see c. schutze (1995), j.m. gawron (1986), c. verspoor (1997), j. grimshaw (1990), and n. chomsky (1995).
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
from the different diagnostics proposed in the literature some are quite consistent among various authors (r. grishman et al  1994, <papid> C94-1042 </papid>c. pollard and i. sag 1987, c. verspoor 1997).</citsent>
<aftsection>
<nextsent>1) the obligatoriness condition.
</nextsent>
<nextsent>when verb demands obligatorily the appearance of an element, this element will be an argument.
</nextsent>
<nextsent>a. john put the book on the table b. *john put the book 2) frequency.
</nextsent>
<nextsent>arguments of verb occur more frequently with that verb than with the other verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1577">
<title id=" W02-0906.xml">learning argument adjunct dictinction for basque </title>
<section> the acquisition process.  </section>
<citcontext>
<prevsection>
<prevsent>correspondence between english prepositions and basque postpositions.
</prevsent>
<prevsent>english basque a. to dative (suffix) alative (suffix) final ablative (suffix) b. like -en gisa (suffix) gisa bezala legez ? 22 types of sentential complements (for instance, english that complementizer corresponds to several subordination suffixes: -la, -n, -na, -nik).
</prevsent>
</prevsection>
<citsent citstr=" J93-2002 ">
this shows to which extent the range of arguments is fine grained, in contrast to other works where the range is at the categorial level, such as np or pp (m. brent 1993, <papid> J93-2002 </papid>c. manning 1993, <papid> P93-1032 </papid>p. merlo &amp; m. leybold 2001).</citsent>
<aftsection>
<nextsent>due to the complexity carried by having such high number of cases, we decided to gather post positions that are semantically equivalent or almost equivalent (for example, english between and among).
</nextsent>
<nextsent>even if there are some semantic differences between them they do not seem to be relevant at the syntactic level.
</nextsent>
<nextsent>some linguists were in charge of completing this grouping task.
</nextsent>
<nextsent>even considering the risk of making mistakes when grouping the cases, we concluded that the loss of accuracy due to having too sparse data (consequence of having many cases) would be worse than the noise introduced by any mistake in the grouping.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1578">
<title id=" W02-0906.xml">learning argument adjunct dictinction for basque </title>
<section> the acquisition process.  </section>
<citcontext>
<prevsection>
<prevsent>correspondence between english prepositions and basque postpositions.
</prevsent>
<prevsent>english basque a. to dative (suffix) alative (suffix) final ablative (suffix) b. like -en gisa (suffix) gisa bezala legez ? 22 types of sentential complements (for instance, english that complementizer corresponds to several subordination suffixes: -la, -n, -na, -nik).
</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
this shows to which extent the range of arguments is fine grained, in contrast to other works where the range is at the categorial level, such as np or pp (m. brent 1993, <papid> J93-2002 </papid>c. manning 1993, <papid> P93-1032 </papid>p. merlo &amp; m. leybold 2001).</citsent>
<aftsection>
<nextsent>due to the complexity carried by having such high number of cases, we decided to gather post positions that are semantically equivalent or almost equivalent (for example, english between and among).
</nextsent>
<nextsent>even if there are some semantic differences between them they do not seem to be relevant at the syntactic level.
</nextsent>
<nextsent>some linguists were in charge of completing this grouping task.
</nextsent>
<nextsent>even considering the risk of making mistakes when grouping the cases, we concluded that the loss of accuracy due to having too sparse data (consequence of having many cases) would be worse than the noise introduced by any mistake in the grouping.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1579">
<title id=" W02-0906.xml">learning argument adjunct dictinction for basque </title>
<section> the acquisition process.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting set contained 48 cases.
</prevsent>
<prevsent>the complexity is reduced but it is still considerable.
</prevsent>
</prevsection>
<citsent citstr=" C00-2100 ">
most of the work on automatic acquisition of subcategorization information (j. carroll &amp; t. briscoe 1997, a. sarkar &amp; d. zeman 2000, <papid> C00-2100 </papid>a. korhonen 2001) apply statistical methods (hypothesis testing).</citsent>
<aftsection>
<nextsent>basically the idea is the following: they get  possible subcategorization frames  from automatically parsed data (either completely or partially parsed) or from syntactically annotated corpus.
</nextsent>
<nextsent>afterwards statistical filter is employed to decide whether those  possible frames  are or not real subcategorization frames.
</nextsent>
<nextsent>these statistical methods can be problematic mostly because they perform badly on sparse data.
</nextsent>
<nextsent>in order to avoid as much as possible data sparseness, we decided to design system that learns which are the arguments of given verb instead of learning whole frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1589">
<title id=" W03-0906.xml">entailment intensionality and text understanding </title>
<section> intensionality.  </section>
<citcontext>
<prevsection>
<prevsent>in (condoravdi et al, 2001) we argued at some length that preserving first-order analysis along the lines suggested by (hirst, 1991) ? through the introduction of explicit existence predicates (6c) ? is at best partial solution.
</prevsent>
<prevsent>not only are identity criteria for non-existent entities problematic, but (6c) also fails to capture significant monotonicity entailments: corrosion preventing continuous contact does not imply that corrosion prevents contact of any form; but first order inference allows one to drop the flfi fl##fl$! conjunct from (6c),yielding the representation one would expect for corrosion prevented contact.
</prevsent>
</prevsection>
<citsent citstr=" P85-1008 ">
we do not completely rule out the possibility that some more sophisticated, onto logically promiscuous, first-order analysis (perhaps along the lines of (hobbs,1985)) <papid> P85-1008 </papid>might account for these kinds of monotonicity in ferences.</citsent>
<aftsection>
<nextsent>but more overtly intensional analysis like (7) does not face this problem in the first place.
</nextsent>
<nextsent>(7)
</nextsent>
<nextsent>  &amp;( )+*)+flfi
</nextsent>
<nextsent>   + flfiffi fi !ff flfi fl##fl$! in (7) we assume that &amp;( )+*)+flfi carries lexical entailment that its second, propositional, argument is false.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1590">
<title id=" W03-0906.xml">entailment intensionality and text understanding </title>
<section> feasibility of ecd.  </section>
<citcontext>
<prevsection>
<prevsent>document representations undergo (statistically filtered) pairwise comparison to identify sentences within document pairs related by contradiction or entailment.
</prevsent>
<prevsent>we will describe the mapping and the comparison in turn.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
the first stage of mapping uses broad coverage, hand coded lexical functional grammar of english (butt etal., 1998) and the parser from the xerox linguistic environment (xle) (maxwell and kaplan, 1993) <papid> J93-4001 </papid>to parse the documents.</citsent>
<aftsection>
<nextsent>parsing is robust in the sense that every sentence receives functional-structure analysis, encoding grammatical ized predicate-argument structure.
</nextsent>
<nextsent>inabout 25% of cases the functional-structures are fragmentary, either because of coverage gaps in the grammar or because of poor spelling and punctuation (to which the technicians writing the tips are prone).
</nextsent>
<nextsent>fragments comprise longest span structures for constituents such as s, np or pp that have been successfully analysed by the grammar.
</nextsent>
<nextsent>ambiguity management via packing (maxwell and kaplan, 1989) allows the parser to efficiently5 find all possible analyses of each sentence according to the grammar, and represent the alternatives in compact, structure-shared form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1591">
<title id=" W03-0906.xml">entailment intensionality and text understanding </title>
<section> feasibility of ecd.  </section>
<citcontext>
<prevsection>
<prevsent>fragments comprise longest span structures for constituents such as s, np or pp that have been successfully analysed by the grammar.
</prevsent>
<prevsent>ambiguity management via packing (maxwell and kaplan, 1989) allows the parser to efficiently5 find all possible analyses of each sentence according to the grammar, and represent the alternatives in compact, structure-shared form.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
evaluation of essentially the same grammar on dependency annotated subset of section 23 of the upenn wall street journal gives the accuracy ofbest parses as 85%, increasing by another 4% for non fragmentary analyses (riezler et al, 2002).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>stochastic selection of the most probable parse (not necessarily the best parse) gives an accuracy of 80%.
</nextsent>
<nextsent>initial semantic interpretation is via an implementation of glue semantics?, which uses linear logic deduction to assemble the meanings of words and phrases in syntactically analysed sentence (dalrymple, 1999).
</nextsent>
<nextsent>semantic interpretation preserves the ambiguity packing in syntactic analysis (though currently not in an algorithmicallyoptimal way), deals with such things as quantifier scoping, and incorporates lexico-semantic information not relevant to parsing.despite theoretical proposals for dealing with anaphora and ellipsis in glue interpret ion, e.g.
</nextsent>
<nextsent>(crouch, 1999), this has not currently been implemented;hooks are placed in the representation to mark where subsequent canonical ization needs to resolve textual and domain dependencies like pronouns and compound noun interpretations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1592">
<title id=" W03-0906.xml">entailment intensionality and text understanding </title>
<section> feasibility of ecd.  </section>
<citcontext>
<prevsection>
<prevsent>having paired the contextual structures, limited onto logical inference is then used to detect contradictions or ent ailments between the contents of matched contexts.in summary, the robust application of detailed, hand coded rules to the syntactic and semantic analysis of open texts appears feasible, with syntax somewhat more advanced.
</prevsent>
<prevsent>similar observations have been made by other researchers, e.g.
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
(siegel and bender, 2002).<papid> W02-1210 </papid></citsent>
<aftsection>
<nextsent>knowledge based canonical ization is less well advanced.
</nextsent>
<nextsent>in part, progress depends on the construction of rules in many ways similar to the grammar rules and lexical entries of syntactic analysis.
</nextsent>
<nextsent>progress also depends on the construction of appropriate ontologies.
</nextsent>
<nextsent>we have argued that entailment and contradiction detection (ecd) should be included as one of number of metrics for evaluating text understanding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1594">
<title id=" W03-1304.xml">enhancing performance of protein name recognizers using collocation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in famous message understanding competition muc (darpa, 1998), named entities extraction, including organizations, people, and locations, along with date/time expressions and monetary and percentage expressions, is one of the evaluation tasks.
</prevsent>
<prevsent>several approaches have been proposed to capture these types of terms.
</prevsent>
</prevsection>
<citsent citstr=" C96-1039 ">
for example, corpus-based methods are employed to extract chinese personal names, and rule-based methods are used to extract chinese date/time expressions and monetary and percentage expressions (chen and lee, 1996; <papid> C96-1039 </papid>chen, et al, 1998).</citsent>
<aftsection>
<nextsent>corpus-based approach is adopted because large personal name database is available for training.
</nextsent>
<nextsent>in contrast, rules which have good coverage exist for date/time expressions, so the rule-based approach is adopted.
</nextsent>
<nextsent>in the past, named entities extraction mainly focuses on general domains.
</nextsent>
<nextsent>recently, large amount of scientific documents has been published, in particular for biomedical domains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1595">
<title id=" W03-1304.xml">enhancing performance of protein name recognizers using collocation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of their goals is to construct knowledge base automatically and to find new information embedded in documents (craven and kumlien, 1999).
</prevsent>
<prevsent>similar information extraction works have been explored on this domain.
</prevsent>
</prevsection>
<citsent citstr=" C00-1030 ">
named entities like protein names, gene names, drug names, disease names, and so on, were recognized (collier, et al, 2000; <papid> C00-1030 </papid>fukuda, et al, 1998; olsson, et al, 2002; <papid> C02-1110 </papid>rindflesch, et al, 2000).</citsent>
<aftsection>
<nextsent>besides, the relationships among these entities, e.g., protein-protein, protein-gene, drug-gene, drug-disease, etc., were extracted (blaschke, et al, 1999; frideman, et al, 2001; hou and chen, 2002; marcotte, et al, 2001; ng and wong, 1999; park, et al, 2001; rindflesch, et al, 2000; thomas, et al, 2000; wong, 2001).
</nextsent>
<nextsent>collocation denotes two or more words having strong relationships (manning and schutze, 1999).
</nextsent>
<nextsent>the related technologies have been applied to terminological extraction, natural language generation, parsing, and so on.
</nextsent>
<nextsent>this paper deals with special collocation in biological domain ? say, protein collocation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1596">
<title id=" W03-1304.xml">enhancing performance of protein name recognizers using collocation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of their goals is to construct knowledge base automatically and to find new information embedded in documents (craven and kumlien, 1999).
</prevsent>
<prevsent>similar information extraction works have been explored on this domain.
</prevsent>
</prevsection>
<citsent citstr=" C02-1110 ">
named entities like protein names, gene names, drug names, disease names, and so on, were recognized (collier, et al, 2000; <papid> C00-1030 </papid>fukuda, et al, 1998; olsson, et al, 2002; <papid> C02-1110 </papid>rindflesch, et al, 2000).</citsent>
<aftsection>
<nextsent>besides, the relationships among these entities, e.g., protein-protein, protein-gene, drug-gene, drug-disease, etc., were extracted (blaschke, et al, 1999; frideman, et al, 2001; hou and chen, 2002; marcotte, et al, 2001; ng and wong, 1999; park, et al, 2001; rindflesch, et al, 2000; thomas, et al, 2000; wong, 2001).
</nextsent>
<nextsent>collocation denotes two or more words having strong relationships (manning and schutze, 1999).
</nextsent>
<nextsent>the related technologies have been applied to terminological extraction, natural language generation, parsing, and so on.
</nextsent>
<nextsent>this paper deals with special collocation in biological domain ? say, protein collocation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1603">
<title id=" W03-1604.xml">exploiting paraphrases in a question answering system </title>
<section> comparatives vs superlatives..  </section>
<citcontext>
<prevsection>
<prevsent>/ thimphu is capital of what country?
</prevsent>
<prevsent>of course combinations of the different types are possible, e.g. oswald killed kennedy / kennedy was assassinated by oswald is combination of (1) and (2).different types of knowledge and different linguistic resources are needed to deal with each of the above types.
</prevsent>
</prevsection>
<citsent citstr=" W98-0604 ">
while type (1) can be dealt with using resource such as wordnet (fellbaum, 1998),type (2) needs effective parsing and mapping of syntactic structures into common deeper structure, possibly using repository of nominalisations like nomlex (meyers et al , 1998).<papid> W98-0604 </papid></citsent>
<aftsection>
<nextsent>more complex approaches are needed for the other types, up to type (6) where generic world knowledge is required, for instance to know that being capital of country implies being located in that country.
</nextsent>
<nextsent>1 such world knowledge could be expressed in the form of axioms, like the following: (x costs y) iff (the price of is y) in this paper we focus on the role of paraphrases in question answering (qa) system targeted at 1note that the reverse is not true, and therefore this is not perfect paraphrase.technical manuals.
</nextsent>
<nextsent>technical documentation is characterised by vast amounts of domain-specific terminology, which needs to be exploited for providing intelligent access to the information contained in the manuals (rinaldi et al , 2002b).
</nextsent>
<nextsent>the approach takenby qa systems is to allow user to ask query (for mulated in natural language) and have the system search background collection of documents in orderto locate an answer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1604">
<title id=" W03-1604.xml">exploiting paraphrases in a question answering system </title>
<section> comparatives vs superlatives..  </section>
<citcontext>
<prevsection>
<prevsent>clearly in some situations (e.g. processing incoming news) such an approach might not be feasible and paragraph indexing techniques would needto be used.
</prevsent>
<prevsent>our current approach is particularly targeted to small and medium sized collections.
</prevsent>
</prevsection>
<citsent citstr=" W03-1801 ">
in an initial phase all multi-word expressions from the domain are collected and structured in an external resource, which we will refer to as the term base (rinaldi et al , 2003; dowdall et al , 2003).<papid> W03-1801 </papid>the document sentences (and user queries) are syntactically processed with the link grammar (lg) parser (sleator and temperley, 1993) which uses 3http://www.ifi.unizh.ch/cl/extrans/4still considerably smaller than the size of the document collections used for trec grammar with wide coverage of english and has robust treatment of ungrammatical sentences and unknown words.</citsent>
<aftsection>
<nextsent>the multi-word terms from the thesaurus are identified and passed to the parser as single tokens.
</nextsent>
<nextsent>this prevents (futile) analysis of the internal structure of terms (see figure 1), simplifying parsing by 46%.
</nextsent>
<nextsent>this solves the first of the problems that we have identified in the introduction (the parsing problem?).in later stages of processing, corpus-based approach (brill and resnik, 1994) <papid> C94-2195 </papid>is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions.</nextsent>
<nextsent>extrans adopts an anaphora resolution algorithm(molla?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1605">
<title id=" W03-1604.xml">exploiting paraphrases in a question answering system </title>
<section> comparatives vs superlatives..  </section>
<citcontext>
<prevsection>
<prevsent>the multi-word terms from the thesaurus are identified and passed to the parser as single tokens.
</prevsent>
<prevsent>this prevents (futile) analysis of the internal structure of terms (see figure 1), simplifying parsing by 46%.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
this solves the first of the problems that we have identified in the introduction (the parsing problem?).in later stages of processing, corpus-based approach (brill and resnik, 1994) <papid> C94-2195 </papid>is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions.</citsent>
<aftsection>
<nextsent>extrans adopts an anaphora resolution algorithm(molla?
</nextsent>
<nextsent>et al , 2003) that is based on lappin and le ass?
</nextsent>
<nextsent>approach (lappin and leass, 1994).<papid> J94-4002 </papid></nextsent>
<nextsent>the original algorithm, which was applied to the syntactic structures generated by mccords slot grammar (mc cord et al , 1992), has been ported to the output of link grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1606">
<title id=" W03-1604.xml">exploiting paraphrases in a question answering system </title>
<section> comparatives vs superlatives..  </section>
<citcontext>
<prevsection>
<prevsent>extrans adopts an anaphora resolution algorithm(molla?
</prevsent>
<prevsent>et al , 2003) that is based on lappin and le ass?
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
approach (lappin and leass, 1994).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>the original algorithm, which was applied to the syntactic structures generated by mccords slot grammar (mc cord et al , 1992), has been ported to the output of link grammar.
</nextsent>
<nextsent>so far the resolution is restricted to sentence-internal pronouns but the same algorithm can be applied to sentence-external pronouns too.
</nextsent>
<nextsent>a lexicon of nominalisations based on nomlex (meyers et al , 1998) <papid> W98-0604 </papid>is used for the most important cases.</nextsent>
<nextsent>the main problem here is that the semantic relationship between the base words (mostly, but not exclusively, verbs) and the derived words (mostly,but not exclusively, nouns) is not sufficiently systematic to allow derivation lexicon to be compiled automatically.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1608">
<title id=" W02-1118.xml">sorry what was your name again or how to overcome the tip ofthe tongue problem with the help of a computer </title>
<section> word access in natural-language.  </section>
<citcontext>
<prevsection>
<prevsent>the approach taken is generic, hence, it applies not only within this particular context.
</prevsent>
<prevsent>word access being fundamental task in language production, one might wonder what could be learned by gleaning at work done in the context of automatic text generation.
</prevsent>
</prevsection>
<citsent citstr=" C88-2149 ">
generationa lot of (natural language generation) researchers have been interested in lexical issues during the last fifteen years or so.2 yet despite this enormous body of work, the issue of word access has not been addressed at all within this community, not even inwards extensive problem catalog (ward 1988).<papid> C88-2149 </papid></citsent>
<aftsection>
<nextsent>while from strict computational linguistic point of view, the whole matter may benon issue,3 however, if we address the problem of lexicalization from psycho linguistic or man-machine interaction point of view 2 for excellent surveys see (robin, 1990; wanner 1996).
</nextsent>
<nextsent>3 most programs running serially, there is no such thing as competition.
</nextsent>
<nextsent>hence, problems like interference , confusion or forgetting do not occur.
</nextsent>
<nextsent>furthermore, computers having perfect memory,stored information can generally be easily accessed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1609">
<title id=" W02-0801.xml">a multilingual approach to disambiguate prepositions and case suffixes </title>
<section> method for disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>made turning ??).
</prevsent>
<prevsent>looking up the bilingual dictionaries for translation requires lemmatization and part of speech tagging.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
for english we use the tnt pos tagger (brants, 2000) <papid> A00-1031 </papid>and wordnet for lemmatization (miller et al, 1990).</citsent>
<aftsection>
<nextsent>for spanish we use (atserias et al, 1998).
</nextsent>
<nextsent>2.4 disambiguation.
</nextsent>
<nextsent>for each basque case suffix, spanish preposition and english preposition we have list of interpretations (cf.
</nextsent>
<nextsent>table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1610">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we report on the sum project which applies automatic summarisation techniques to the legal domain.
</prevsent>
</prevsection>
<citsent citstr=" J02-4002 ">
we pursue methodology based on teufel and moens (2002) <papid> J02-4002 </papid>where sentences are classified according to their argumentativerole.</citsent>
<aftsection>
<nextsent>we describe some experiments with judgments of the house of lords where we have performed automatic linguistic annotation of asmall sample set in order to explore correlations between linguistic features and argumentative roles.
</nextsent>
<nextsent>we use state-of-the-art nlp techniques to perform the linguistic annotation using xml-based tools and combination of rule based and statistical methods.
</nextsent>
<nextsent>we focus here on the predictive capacity of tense and aspect features for classifier.
</nextsent>
<nextsent>law reports form the most important part of lawyers or law students reading matter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1613">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> automatic summarisation.  </section>
<citcontext>
<prevsection>
<prevsent>previous work on summarisation has concentrated on the domain of scientific papers.
</prevsent>
<prevsent>this has lent itself to automatic text summarisation because documents of this genre tend to be structured in predictable ways and to contain formalised language which can aid the summari sation process (e.g. cue phrases such as the importance of?, to summarise?, we disagree?)
</prevsent>
</prevsection>
<citsent citstr=" W00-1302 ">
(teufel and moens, 2002), (<papid> J02-4002 </papid>teufel and moens, 2000).<papid> W00-1302 </papid></citsent>
<aftsection>
<nextsent>although there is significant distance in style between scientific articles and legal texts, we have found it useful to build upon the work of teufel and moens (teufel and moens, 2002; <papid> J02-4002 </papid>teufel and moens, 1997) and to pursue the methodology of investigating the usefulness of range of features in determining the argumentative role of sentence.</nextsent>
<nextsent>sparck jones (1999) has argued that most practically oriented work on automated summarisation can be classified as either based on text extraction or fact extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1615">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> automatic summarisation.  </section>
<citcontext>
<prevsection>
<prevsent>in collection of relevant texts, decide for every sentence which argumentative role best describes it; this process is called argumentative zoning?.
</prevsent>
<prevsent>our annotation scheme, like our general approach, is motivated by successful incorporation of rhetorical information in the domain of scientific articles.
</prevsent>
</prevsection>
<citsent citstr=" E99-1015 ">
teufel et al(1999) <papid> E99-1015 </papid>argue that regularities in the argumentative structure of research article follow from the authors?</citsent>
<aftsection>
<nextsent>primary communicative goal.
</nextsent>
<nextsent>in scientific texts, the authors goal is to convince their audience that they have provided acontribution to science.
</nextsent>
<nextsent>from this goal follow highly predictable sub-goals, the basic scheme of which was introduced in section 2.1 for the legal domain, the communicative goal is slightly different; the authors primary communicative goal is to convince his/her peers that their position is legally sound, having considered the case with regards to all relevant points of law.
</nextsent>
<nextsent>a different set of sub-goals follows (refer to table 1).3 we annotated five randomly selected appeals cases forthe purpose of preliminary analysis of our linguistic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1616">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> linguistic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the core program in our pipelines is the lt ttt program fsgmatch, general purpose transducer which processes an input stream and rewrites it using rules provided in hand-written grammar file, where the rewrite usually takes the form of the addition of xml mark-up.
</prevsent>
<prevsent>typically, fsgmatch rules specify patterns over sequences of xml elements or use regular expression language to identify patterns inside the character strings (pcdata) which are the content of elements.
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
the other main lt ttt program is ltpos, statistical combined part-of-speech (pos) tagger and sentence identifier (mikheev, 1997).<papid> J97-3003 </papid></citsent>
<aftsection>
<nextsent>the first step in the linguistic annotation process uses fsgmatch to segment the contents of the paragraphs into word tokens encoded in the xml as elements.
</nextsent>
<nextsent>once the word tokens have been identified, the next step uses ltpos to mark up the sentences as sent elements and tens asp voic mod proposes pres simp act no was brought past simp pass no would supersede pres simp act yes to grant inf simp act no might have occurred pres perf act yes had been cancelled past perf pass no table 2: tense, aspect, voice and modality features to add part of speech attributes to word tokens (e.g.  c=nn? opinion /w  is word of category noun).
</nextsent>
<nextsent>note that the tagset used by ltpos is the penn treebank tagset (marcu et al, 1994).the following step performs level of shallow syntactic processing known as chunking?.
</nextsent>
<nextsent>this is method of partially identifying constituent structure which stops short of the fully connected parse trees which are typically produced by traditional syntactic parsers/grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1617">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> linguistic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>in phase two, we predict clause ends.
</prevsent>
<prevsent>in the final step, phase three, an embedded clause structure is inferred from these start and end predictions.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the first two phases are approached as straightforward classification in maximum entropy framework (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>the maximum entropy algorithm produces distribution
</nextsent>
<nextsent>   based on set of labelled training examples, where x is the vector of active features.
</nextsent>
<nextsent>in evaluation mode, we select the class label that maximises   . the features we use include words, part-of-speechtags, and chunk tags within set window.
</nextsent>
<nextsent>the classifier also incorporates features that generalise about long distance dependencies such as sequential patterns of individual attributes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1618">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> linguistic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the actual segmentation algorithm then chooses clause candidates one-by-one in order of confidence.
</prevsent>
<prevsent>remaining candidates that have crossed brackets with the chosen clause are removed from consideration at each iteration.we obtained further improvement (our score increased from 73.94 to 76.99) by training on hand annotated pos and chunk data from the treebank.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
table 3 compares precision, recall, and scores for our system with conll-2001 results training on sections 15-18 of the penn treebank and testing on section 21 (marcus et al., 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the score is more than 10 points above the average scores, failing to surpass only the best performing conll system.
</nextsent>
<nextsent>once clause boundaries have been determined, they are used to identify sentences main verb group.
</nextsent>
<nextsent>a verb group that is at the top level according to the clause segmentation is considered stronger candidate than any embedded verb group (i.e. verb group that is part of subordinate clause).
</nextsent>
<nextsent>in addition, there are several other heuristics encoded in the algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1620">
<title id=" W03-0505.xml">summarising legal texts sentential tense and argumentative roles </title>
<section> linguistic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>in these cases, the actual main verb group may or may not be present when the main verb identification algorithm is run.
</prevsent>
<prevsent>sentence segmentation is an interesting problem in its own right.
</prevsent>
</prevsection>
<citsent citstr=" J02-3002 ">
a state-of-the-art approach is included in our xml pipeline (mikheev, 2002).<papid> J02-3002 </papid></citsent>
<aftsection>
<nextsent>though we may get slightly better performance if we tailor the segmentation algorithm to our domain, in random sample of 100 sentences, there were only 4 cases of bad segmentation.
</nextsent>
<nextsent>background case own past -0.135 0.356 -0.261 pres 0.105 -0.301 0.228 table 5: correlation between the categories in our basic rhetorical scheme and sentential tense information.
</nextsent>
<nextsent>the correlation coefficient is statistical measure of related-ness?.
</nextsent>
<nextsent>values fall in the range
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1621">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for the automatic understanding of written or spoken natural language it is crucial to be able to identify the entities referred to by referring expressions.
</prevsent>
<prevsent>the most common and thus most important types of referring expressions are pronouns and definite noun phrases (nps).
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
supervised machine learning algorithms have been used for pronoun resolution (ge et al, 1998) <papid> W98-1119 </papid>and for the resolution of definite nps (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>an unsupervised approach to the resolution of definite nps was applied by cardie and wagstaff (1999).<papid> W99-0611 </papid></nextsent>
<nextsent>however, though machine learning algorithms may deduce to make best use of given set of features forgiven problem, it is linguistic question and non-trivial task to identify set of features which describe the data sufficiently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1622">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for the automatic understanding of written or spoken natural language it is crucial to be able to identify the entities referred to by referring expressions.
</prevsent>
<prevsent>the most common and thus most important types of referring expressions are pronouns and definite noun phrases (nps).
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
supervised machine learning algorithms have been used for pronoun resolution (ge et al, 1998) <papid> W98-1119 </papid>and for the resolution of definite nps (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>an unsupervised approach to the resolution of definite nps was applied by cardie and wagstaff (1999).<papid> W99-0611 </papid></nextsent>
<nextsent>however, though machine learning algorithms may deduce to make best use of given set of features forgiven problem, it is linguistic question and non-trivial task to identify set of features which describe the data sufficiently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1623">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the most common and thus most important types of referring expressions are pronouns and definite noun phrases (nps).
</prevsent>
<prevsent>supervised machine learning algorithms have been used for pronoun resolution (ge et al, 1998) <papid> W98-1119 </papid>and for the resolution of definite nps (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al, 2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0611 ">
an unsupervised approach to the resolution of definite nps was applied by cardie and wagstaff (1999).<papid> W99-0611 </papid></citsent>
<aftsection>
<nextsent>however, though machine learning algorithms may deduce to make best use of given set of features forgiven problem, it is linguistic question and non-trivial task to identify set of features which describe the data sufficiently.
</nextsent>
<nextsent>we report on experiments in the resolution of anaphoric expressions in general, including definite noun phrases, proper names, and personal, possessive and demonstrative pronouns.
</nextsent>
<nextsent>based on the work mentioned above we started with feature set including np-level and coreference-level features.
</nextsent>
<nextsent>applied to the whole dataset these features led only to moderate results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1626">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> features for reference resolution in.  </section>
<citcontext>
<prevsection>
<prevsent>and features which focus on the anaphoric relation (e.g. do both share common np?).
</prevsent>
<prevsent>it was criticized (soon et al, 2001) <papid> J01-4004 </papid>that the features used by mccarthy and lehnert (1995) are highly idiosyncratic and applicable only to one particular domain.</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
mccarthy and lehnert (1995) achieved results of about 86% f-measure (evaluated according to vilain et al (1995)) <papid> M95-1005 </papid>on the muc-5 data set.however, only defined subset of all possible reference resolution cases was considered relevant inthe muc-5 task description, e.g., only entity refer ences.</citsent>
<aftsection>
<nextsent>for this case, the domain-dependent features may have been particularly important, making it difficult to compare the results of this approach tooth ers working on less restricted domains.
</nextsent>
<nextsent>soon et al (2001)<papid> J01-4004 </papid>use twelve features (see table 1).</nextsent>
<nextsent>soon et al (2001)<papid> J01-4004 </papid>show part of their decision tree in which the weak string identity feature (i.e.identity after determiners have been removed) appears to be the most important one.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1645">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>number agreement between anaphor and antecedent ? semantic class agreement between anaphor and antecedent ? gender agreement between anaphor and antecedent ? anaphor and antecedent are both proper names?
</prevsent>
<prevsent>an alias feature (used for proper names and acronyms) ? an appositive feature table 1: features used by soon et al ? position (nps are numbered sequentially) ? pronoun type (nom., acc., possessive, ambiguous) ? article (indefinite, definite, none) ? appositive (yes, no) ? number (singular, plural) ? proper name (yes, no) ? semantic class (based on wordnet: time, city, animal,human, object; based on separate algorithm: number, money, company) ? gender (masculine, feminine, either, neuter) ? animacy (anim, inanim) table 2: features used by cardie and wagstaff kens.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the texts were pos-tagged using tnt (brants,2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>a basic identification of markables (refer ring expressions, i.e. nps) was obtained by using the np-chunker chunkie (skut and brants, 1998).<papid> W98-1117 </papid></nextsent>
<nextsent>the pos-tagger was also used for assigning attributes like e.g. the np form to markables.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1646">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>an alias feature (used for proper names and acronyms) ? an appositive feature table 1: features used by soon et al ? position (nps are numbered sequentially) ? pronoun type (nom., acc., possessive, ambiguous) ? article (indefinite, definite, none) ? appositive (yes, no) ? number (singular, plural) ? proper name (yes, no) ? semantic class (based on wordnet: time, city, animal,human, object; based on separate algorithm: number, money, company) ? gender (masculine, feminine, either, neuter) ? animacy (anim, inanim) table 2: features used by cardie and wagstaff kens.
</prevsent>
<prevsent>the texts were pos-tagged using tnt (brants,2000).<papid> A00-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" W98-1117 ">
a basic identification of markables (refer ring expressions, i.e. nps) was obtained by using the np-chunker chunkie (skut and brants, 1998).<papid> W98-1117 </papid></citsent>
<aftsection>
<nextsent>the pos-tagger was also used for assigning attributes like e.g. the np form to markables.
</nextsent>
<nextsent>the automatic annotation was followed by manual correction and annotation phase in which the markables were annotated with further tags (e.g. semantic class).
</nextsent>
<nextsent>in this phase manual coreference annotation was performed as well.
</nextsent>
<nextsent>in our annotation coreference is represented in terms of member attribute on markables.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1647">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>markables with the same value in this attribute are considered co referring expressions.
</prevsent>
<prevsent>the annotation was performed by two students.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the reliability of the annotations was checked using the kappa statistic (car letta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>3.2 data generation.
</nextsent>
<nextsent>the problem of coreference resolution can easily be formulated as binary classification: given pairof potential anaphor and potential antecedent, classify as positive if the antecedent is in fact the closest antecedent, and as negative otherwise.
</nextsent>
<nextsent>in anaphoric chains only the immediately adjacent pairs are classified as positive.
</nextsent>
<nextsent>we generated data suitable as in put to machine learning algorithm from our corpus using straightforward algorithm which combined potential anaphors and their potential antecedents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1651">
<title id=" W02-1040.xml">the influence of minimum edit distance on reference resolution </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>what is needed is weakened form of the string ident and substring match features.
</prevsent>
<prevsent>soon et al (2001)<papid> J01-4004 </papid>removed determiners before comparing the strings.</prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
other researchers like vieira and poesio (2000) <papid> J00-4003 </papid>used information about the syntactic structure and compared only the syntactic heads of the phrases.</citsent>
<aftsection>
<nextsent>however, the feature used by soon et al (2001)<papid> J01-4004 </papid>is neither sufficient nor language dependent, the one used by vieira and poesio (2000) <papid> J00-4003 </papid>is not cheap since it relies on syntactic analysis.</nextsent>
<nextsent>we were looking for feature which gave usthe improvements of the features used by other researchers without their associated costs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1665">
<title id=" W03-1204.xml">evaluation of features for sentence extraction on different types of corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>he manually assigned parameter values to integrate features for estimating the significance scores of sentences.
</prevsent>
<prevsent>on the other hand, machine learning methods can also be applied to integrate features.
</prevsent>
</prevsection>
<citsent citstr=" P98-1009 ">
for sentence extraction from training data, kupiec et al (1995) and aone et al (1998) <papid> P98-1009 </papid>used bayes?</citsent>
<aftsection>
<nextsent>rule, lin (1999)and nomoto and matsumoto (1997) generated decision tree, and hirao et al (2002) <papid> C02-1053 </papid>generated an svm.</nextsent>
<nextsent>in this paper, we not only show evaluation results for our sentence extraction system using combinations of features but also analyze the features for different types of corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1666">
<title id=" W03-1204.xml">evaluation of features for sentence extraction on different types of corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, machine learning methods can also be applied to integrate features.
</prevsent>
<prevsent>for sentence extraction from training data, kupiec et al (1995) and aone et al (1998) <papid> P98-1009 </papid>used bayes?</prevsent>
</prevsection>
<citsent citstr=" C02-1053 ">
rule, lin (1999)and nomoto and matsumoto (1997) generated decision tree, and hirao et al (2002) <papid> C02-1053 </papid>generated an svm.</citsent>
<aftsection>
<nextsent>in this paper, we not only show evaluation results for our sentence extraction system using combinations of features but also analyze the features for different types of corpora.
</nextsent>
<nextsent>the analysis gives us some indication about how to use these features and how to combine them.
</nextsent>
<nextsent>the summarization data we used for this research were prepared from japanese newspaper articles, japanese lectures, and english newspaper articles.by using these three types of data, we could compare two languages and also two different types of corpora, written corpus and speech corpus.
</nextsent>
<nextsent>2.1 summarization data from japanese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1668">
<title id=" W03-1204.xml">evaluation of features for sentence extraction on different types of corpora </title>
<section> overview of our sentence extraction.  </section>
<citcontext>
<prevsection>
<prevsent>only the term frequency was used fornes, because we judged that the document frequency for an entity was usually quite small, thereby making the differences between entities negligible.
</prevsent>
<prevsent>3.1.5 patterns for the duc data, we used dependency patterns as type of scoring function.
</prevsent>
</prevsection>
<citsent citstr=" H01-1009 ">
these patterns were extracted by pattern discovery during information extraction (sudo et al, 2001).<papid> H01-1009 </papid></citsent>
<aftsection>
<nextsent>the details of this approach are not explained here, because this feature is not among the features we analyze in section 5.
</nextsent>
<nextsent>the definition of the function appears in (nobata et al., 2002).
</nextsent>
<nextsent>3.2 optimal weight.
</nextsent>
<nextsent>our system set weights for each scoring function in order to calculate the total score of sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1671">
<title id=" W03-0418.xml">identifying events using similarity and context </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>second, recent work in semantic lexicon learning is similar to our work, although it focuses on learning related words, not related clauses.
</prevsent>
<prevsent>in addition, extraction patterns and case frames bear some resemblance to our events.
</prevsent>
</prevsection>
<citsent citstr=" W98-1106 ">
riloff and schmelzenbachs work (1998) <papid> W98-1106 </papid>is an example of this line of research.</citsent>
<aftsection>
<nextsent>however, events use contextual information about other events, unlike extraction patterns and case frames.the idea of script originated with schank and abelson (1977) through research on human knowledge structures, and was demonstrated in the sam system (cullingford, 1978).
</nextsent>
<nextsent>later work includes manual creation of variety of knowledge structures including scripts to understand stories (lehnert et al, 1983), application of manually generated scripts to the processing of newswire stories (dejong, 1982), and combination of applying manually generated scripts to information retrieval and applying genetic algorithms to adjusting existing scripts (mauldin, 1989).semantic lexicons have been the focus of much research.
</nextsent>
<nextsent>wordnet (fellbaum, 1998) is prominent example of manually generated lexicon.
</nextsent>
<nextsent>two recent projects in learning semantic lexicons apply automated techniques to small set of human provided seed words to create lists of words that the systems assign to the same semantic category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1672">
<title id=" W03-0418.xml">identifying events using similarity and context </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>phillips (2002) mines syntactic structures.
</prevsent>
<prevsent>other researchers have also clustered words to create semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
lin (1998) <papid> P98-2127 </papid>created thesaurus using syntactic relationships with other words.rooth et al (1999) <papid> P99-1014 </papid>used clustering to create clusters similar to levin verb classes (levin, 1993).</citsent>
<aftsection>
<nextsent>pereira, tishby and lee (1993) clustered words according to context.
</nextsent>
<nextsent>both of our criteria play essential roles in the event generation process.
</nextsent>
<nextsent>using similarity alone would combine all clauses that, while similar on the surface, actually are referring to different types of occurrences.
</nextsent>
<nextsent>using context alone would combine all clauses encountered in the same position relative to some other clause.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1673">
<title id=" W03-0418.xml">identifying events using similarity and context </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>phillips (2002) mines syntactic structures.
</prevsent>
<prevsent>other researchers have also clustered words to create semantic lexicons.
</prevsent>
</prevsection>
<citsent citstr=" P99-1014 ">
lin (1998) <papid> P98-2127 </papid>created thesaurus using syntactic relationships with other words.rooth et al (1999) <papid> P99-1014 </papid>used clustering to create clusters similar to levin verb classes (levin, 1993).</citsent>
<aftsection>
<nextsent>pereira, tishby and lee (1993) clustered words according to context.
</nextsent>
<nextsent>both of our criteria play essential roles in the event generation process.
</nextsent>
<nextsent>using similarity alone would combine all clauses that, while similar on the surface, actually are referring to different types of occurrences.
</nextsent>
<nextsent>using context alone would combine all clauses encountered in the same position relative to some other clause.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1674">
<title id=" W03-0205.xml">a comparison of tutor and student behavior in speech versus text based tutoring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>prior studies have shown considerable benefits of human-human tutoring through spoken interactions (lemke, 1990; chi et al, 1994).
</prevsent>
<prevsent>(hausmann and chi,2002) has shown that spontaneous self-explanation occurs much more frequently in spoken tutoring then intext based tutoring, suggesting that typing requires additional cognitive capacity and thus reduces the cognitive resources available for spontaneous self-explanation.
</prevsent>
</prevsection>
<citsent citstr=" W01-1609 ">
other research projects (mostow and aist, 2001; fryet al, 2001) <papid> W01-1609 </papid>have shown that basic spoken natural language capabilities can be implemented quite effectively in computer tutoring systems.</citsent>
<aftsection>
<nextsent>moreover, speech contains prosodic and acoustic information which has been shown to improve the accuracy of predicting emotional states (ang et al, 2002; batliner et al, 2000) and user responses to system errors (litman et al, 2001) <papid> P01-1048 </papid>that are useful for triggering system adaptation.</nextsent>
<nextsent>we are thus currently developing speech based dialogue system that uses text based system (vanlehn et al, 2002) as itsback-end?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1675">
<title id=" W03-0205.xml">a comparison of tutor and student behavior in speech versus text based tutoring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(hausmann and chi,2002) has shown that spontaneous self-explanation occurs much more frequently in spoken tutoring then intext based tutoring, suggesting that typing requires additional cognitive capacity and thus reduces the cognitive resources available for spontaneous self-explanation.
</prevsent>
<prevsent>other research projects (mostow and aist, 2001; fryet al, 2001) <papid> W01-1609 </papid>have shown that basic spoken natural language capabilities can be implemented quite effectively in computer tutoring systems.</prevsent>
</prevsection>
<citsent citstr=" P01-1048 ">
moreover, speech contains prosodic and acoustic information which has been shown to improve the accuracy of predicting emotional states (ang et al, 2002; batliner et al, 2000) and user responses to system errors (litman et al, 2001) <papid> P01-1048 </papid>that are useful for triggering system adaptation.</citsent>
<aftsection>
<nextsent>we are thus currently developing speech based dialogue system that uses text based system (vanlehn et al, 2002) as itsback-end?.
</nextsent>
<nextsent>these systems and their goals will be discussed in section 2.
</nextsent>
<nextsent>we expect that the different modalities used by these systems (e.g. text based vs speech based) will display interesting differences with respect to the characteristics of dialogue interaction that may determine their relative merits with respect to increasing student performance.
</nextsent>
<nextsent>although human-computer data from the speech based system is not yet available for comparison, we have collected parallel human-human corpora both for text based and speech based tutoring, as discussed in sections 3-4,and these corpora already display similarities and differences with respect to features of their dialogue interactions, as discussed in section 5, that are wholly modality based and that will likely be displayed to an even greater extent in the comparable human-computer data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1676">
<title id=" W03-0205.xml">a comparison of tutor and student behavior in speech versus text based tutoring </title>
<section> why2-atlas and itspoke dialogue.  </section>
<citcontext>
<prevsection>
<prevsent>for example, speech contains rich acoustic and prosodic information about the speakers current emotional state that isnt present in typed dialogue.
</prevsent>
<prevsent>connections between learning and emotion have been well documented (coles, 1999), so it seems likely that the success of computer-based tutoring systems could be greatly increased if they were capable of predicting and adapting to student emotional states,e.g. reinforcing positive states, while rectifying negative states (evens, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N03-2018 ">
preliminary machine learning experiments involving emotion annotation and automatic feature extraction from our corpus suggest thatitspoke can indeed be enhanced to automatically predict and adapt to student emotional states (litman et al, 2003).<papid> N03-2018 </papid></citsent>
<aftsection>
<nextsent>the why2-atlas human-human typed tutoring corpus is collection of typed tutoring dialogues between (human) tutor and student collected via typed interface, which the tutor plays the same role that why2-atlas is designed to perform.
</nextsent>
<nextsent>the experimental procedure is as follows: 1) students are given pretest measuring their knowledge of physics, 2) students are asked to read through small document of background material, 3) students work through set of up to 10 why2-atlas training problems with the human tutor, and 4) students are givena post-test that is similar to the pretest.
</nextsent>
<nextsent>the entire experiment takes no more than 15 hours per student, and is usually performed in 1-3 sessions of no more than 4 hours each.
</nextsent>
<nextsent>data collection began in the fall 2002 semester and is continuing in the spring 2003 semester.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1677">
<title id=" W02-1607.xml">building a training corpus for word sense disambiguation in englishtovietnamese machine translation </title>
<section> normalizing  english-.  </section>
<citcontext>
<prevsection>
<prevsent>bao. in which, first characters are reference numbers indicating its sources and the position of sentence in texts.
</prevsent>
<prevsent>because most of our bilingual corpus are manually typed, we haven used automatic sentential alignment.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
automatic sentential alignment (gale and church, 1991) <papid> P91-1023 </papid>will be necessary if we have already had online bilingual texts.</citsent>
<aftsection>
<nextsent>3.2 spelling checker of bilingual corpus.
</nextsent>
<nextsent>after aligning sentences, we check the spell of english words and vietnamese words automatically.
</nextsent>
<nextsent>here, we have met another drawback in processing the vietnamese word segmentation because vietnamese words (similar to chinese words) are not delimited by spaces (dien dinh, 2001).
</nextsent>
<nextsent>however, our spelling checker is able to detect non-existent words in english or vietnamese only.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1678">
<title id=" W03-1019.xml">investigating loss functions and optimization methods for discriminative learning of label sequences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>until recent years, generative models were the most common approach for many nlp tasks.
</prevsent>
<prevsent>recently,there is growing interest on discriminative models in the nlp community, and these models were shown to be successful for different tasks(laffertyet al, 2001; ratnaparkhi, 1999; collins, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W02-1002 ">
discriminative models do not only have theoretical advantages over generative models, as we discuss in section 2, but they are also shown to be empirically favorable over generative models when features and objective functions are fixed (klein and manning, 2002).<papid> W02-1002 </papid></citsent>
<aftsection>
<nextsent>in this paper, we use discriminative models to investigate the optimization of different objective functions by variety of optimization methods.
</nextsent>
<nextsent>wefocus on label sequence learning tasks.
</nextsent>
<nextsent>part-ofspeech (pos) tagging and named entity recognition (ner) are the most studied applications among these tasks.
</nextsent>
<nextsent>however, there are many others, such as chunking, pitch accent prediction and speech edit detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1679">
<title id=" W03-1019.xml">investigating loss functions and optimization methods for discriminative learning of label sequences </title>
<section> discriminative modeling of label.  </section>
<citcontext>
<prevsection>
<prevsent>however, if we incorporate information about the neighboring words and/or information about more detailed characteristics of the current word directly to our model,rather than propagating it through the previous labels, we may hope to learn better classifier.many different models, such as maximum entropy markov models (memms) (mccallum et al, 2000), projection based markov models (pmms)(punyakanok and roth, 2000) and conditional random fields (crfs) (lafferty et al, 2001), have been proposed to overcome these problems.
</prevsent>
<prevsent>the common property of these models is their discriminative approach.
</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
they model the probability distribution of the label sequences given the observation sequences: ) ff+*   . the best performing models of label sequence learning are memms or pmms (also known as maximum entropy models) whose features are carefully designed for the specific tasks (ratnaparkhi, 1999; toutanova and manning, 2000).<papid> W00-1308 </papid></citsent>
<aftsection>
<nextsent>however, maximum entropy models suffer from the so called label bias problem, the problem of making local decisions (lafferty et al, 2001).
</nextsent>
<nextsent>lafferty et al (2001) show that crfs overcome the label-bias problem and outperform memms in pos tagging.
</nextsent>
<nextsent>crfs define probability distribution over the whole sequence ff , globally conditioning over the whole observation sequence  (figure 1b).
</nextsent>
<nextsent>be cause they condition on the observation (as opposed to generating it), they can use overlapping features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1681">
<title id=" W03-1019.xml">investigating loss functions and optimization methods for discriminative learning of label sequences </title>
<section> comparison of the four loss functions.  </section>
<citcontext>
<prevsection>
<prevsent>we experimented with different regularizationterms.
</prevsent>
<prevsent>as expected, we observed that the regularization term increases the accuracy, especially when the training data is small; but we did not observe much difference when we used different regularization terms.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
the results we report are with the gaussian prior regularization term described in (johnson et al, 1999).<papid> P99-1069 </papid>our goal in this paper is not to build the best tagger or recognizer, but to compare different loss functions and optimization methods.</citsent>
<aftsection>
<nextsent>since we did not spend much effort on designing the most useful features, our results are slightly worse than, but comparable to the best performing models.
</nextsent>
<nextsent>we extracted corpora of different sizes (ranging from 300 sentences to the complete corpus) and ran experiments optimizing the four loss functions using different feature sets.
</nextsent>
<nextsent>in table 1 and table 2,we report the accuracy of predicting every individual label.
</nextsent>
<nextsent>it can be seen that the test accuracy obtained by different loss functions lie within relatively small range and the best performance depends on what kind of features are included in the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1682">
<title id=" W03-1019.xml">investigating loss functions and optimization methods for discriminative learning of label sequences </title>
<section> optimization methods.  </section>
<citcontext>
<prevsection>
<prevsent>if the distribution is peaked, one label is more likely than others and the contribution of this label dominates the expectation values.
</prevsent>
<prevsent>if we assume this is the case, i.e. we make viterbi assumption, we can calculatea good approximation of the gradients by considering only the most likely, i.e. the best label sequence according to the current model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
the following on line perceptron algorithm (algorithm 1), presented in (collins, 2002), <papid> P02-1062 </papid>uses these two approximations: algorithm 1 label sequence perceptron algorithm . 1: initialize  </citsent>
<aftsection>
<nextsent>    2: repeat 3: for all training patterns    do 4: compute ff      ff       ff  5: if ff    ff then 6:     8       ff    3        ff  7: end if 8: end for 9: until stopping criteria at each iteration, the perceptron algorithm calculates an approximation of the gradient of the sequential log-loss function (eq.
</nextsent>
<nextsent>3) based on the current training instance.
</nextsent>
<nextsent>the batch version of this algorithm is closer approximation of the optimization of sequential log-loss, since the only approximation is the viterbi assumption.
</nextsent>
<nextsent>the stopping criteria may be convergence, or fixed number of iterations over the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1683">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>whenever two entities of type xxx are immediately next to each other, the first word of the second entity will be tagged b-xxx in order to show that it starts another entity.
</prevsent>
<prevsent>the data contains entities of four types: persons (per),organizations (org), locations (loc) and miscellaneous names (misc).
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
this tagging scheme is the iob scheme originally put forward by ramshaw and marcus (1995).<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>we assume that named entities are non-recursive and non-overlapping.
</nextsent>
<nextsent>when named entity is embedded in another named entity, usually only the top level entity has been annotated.
</nextsent>
<nextsent>table 2 contains an overview of the number of named entities in each data file.
</nextsent>
<nextsent>2.4 evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1684">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>the most frequently applied technique in the conll-2003 shared task is the maximum entropy model.
</prevsent>
<prevsent>five systems used this statistical learning method.
</prevsent>
</prevsection>
<citsent citstr=" W03-0420 ">
three systems used maximum entropy models in isolation (bender et al, 2003; <papid> W03-0420 </papid>chieu and ng, 2003; curran and clark, 2003).<papid> W03-0424 </papid></citsent>
<aftsection>
<nextsent>two more systems used them in combination with other techniques (florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003).<papid> W03-0428 </papid></nextsent>
<nextsent>maximum entropy models seem to be good choice for this kind of task: the top three results for english and the top two results for german were obtained by participants who employed them in one way or another.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1686">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>the most frequently applied technique in the conll-2003 shared task is the maximum entropy model.
</prevsent>
<prevsent>five systems used this statistical learning method.
</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
three systems used maximum entropy models in isolation (bender et al, 2003; <papid> W03-0420 </papid>chieu and ng, 2003; curran and clark, 2003).<papid> W03-0424 </papid></citsent>
<aftsection>
<nextsent>two more systems used them in combination with other techniques (florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003).<papid> W03-0428 </papid></nextsent>
<nextsent>maximum entropy models seem to be good choice for this kind of task: the top three results for english and the top two results for german were obtained by participants who employed them in one way or another.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1687">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>five systems used this statistical learning method.
</prevsent>
<prevsent>three systems used maximum entropy models in isolation (bender et al, 2003; <papid> W03-0420 </papid>chieu and ng, 2003; curran and clark, 2003).<papid> W03-0424 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
two more systems used them in combination with other techniques (florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003).<papid> W03-0428 </papid></citsent>
<aftsection>
<nextsent>maximum entropy models seem to be good choice for this kind of task: the top three results for english and the top two results for german were obtained by participants who employed them in one way or another.
</nextsent>
<nextsent>hidden markov models were employed by four ofthe systems that took part in the shared task (flo rian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003; <papid> W03-0428 </papid>mayfield et al, 2003; <papid> W03-0429 </papid>whitelaw and patrick, 2003).<papid> W03-0432 </papid></nextsent>
<nextsent>however, they were always used in combination with other learningtechniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1689">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>five systems used this statistical learning method.
</prevsent>
<prevsent>three systems used maximum entropy models in isolation (bender et al, 2003; <papid> W03-0420 </papid>chieu and ng, 2003; curran and clark, 2003).<papid> W03-0424 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0428 ">
two more systems used them in combination with other techniques (florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003).<papid> W03-0428 </papid></citsent>
<aftsection>
<nextsent>maximum entropy models seem to be good choice for this kind of task: the top three results for english and the top two results for german were obtained by participants who employed them in one way or another.
</nextsent>
<nextsent>hidden markov models were employed by four ofthe systems that took part in the shared task (flo rian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003; <papid> W03-0428 </papid>mayfield et al, 2003; <papid> W03-0429 </papid>whitelaw and patrick, 2003).<papid> W03-0432 </papid></nextsent>
<nextsent>however, they were always used in combination with other learningtechniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1693">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>two more systems used them in combination with other techniques (florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003).<papid> W03-0428 </papid></prevsent>
<prevsent>maximum entropy models seem to be good choice for this kind of task: the top three results for english and the top two results for german were obtained by participants who employed them in one way or another.</prevsent>
</prevsection>
<citsent citstr=" W03-0429 ">
hidden markov models were employed by four ofthe systems that took part in the shared task (flo rian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003; <papid> W03-0428 </papid>mayfield et al, 2003; <papid> W03-0429 </papid>whitelaw and patrick, 2003).<papid> W03-0432 </papid></citsent>
<aftsection>
<nextsent>however, they were always used in combination with other learningtechniques.
</nextsent>
<nextsent>klein et al (2003) <papid> W03-0428 </papid>also applied the related conditional markov models for combining clas sifiers.learning methods that were based on connection ist approaches were applied by four systems.</nextsent>
<nextsent>zhang and johnson (2003) <papid> W03-0434 </papid>used robust risk minimization, which is winnow technique.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1695">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>two more systems used them in combination with other techniques (florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003).<papid> W03-0428 </papid></prevsent>
<prevsent>maximum entropy models seem to be good choice for this kind of task: the top three results for english and the top two results for german were obtained by participants who employed them in one way or another.</prevsent>
</prevsection>
<citsent citstr=" W03-0432 ">
hidden markov models were employed by four ofthe systems that took part in the shared task (flo rian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003; <papid> W03-0428 </papid>mayfield et al, 2003; <papid> W03-0429 </papid>whitelaw and patrick, 2003).<papid> W03-0432 </papid></citsent>
<aftsection>
<nextsent>however, they were always used in combination with other learningtechniques.
</nextsent>
<nextsent>klein et al (2003) <papid> W03-0428 </papid>also applied the related conditional markov models for combining clas sifiers.learning methods that were based on connection ist approaches were applied by four systems.</nextsent>
<nextsent>zhang and johnson (2003) <papid> W03-0434 </papid>used robust risk minimization, which is winnow technique.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1700">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>however, they were always used in combination with other learningtechniques.
</prevsent>
<prevsent>klein et al (2003) <papid> W03-0428 </papid>also applied the related conditional markov models for combining clas sifiers.learning methods that were based on connection ist approaches were applied by four systems.</prevsent>
</prevsection>
<citsent citstr=" W03-0434 ">
zhang and johnson (2003) <papid> W03-0434 </papid>used robust risk minimization, which is winnow technique.</citsent>
<aftsection>
<nextsent>florian et al (2003) <papid> W03-0425 </papid>employed the same technique in combination of learners.</nextsent>
<nextsent>voted perceptrons were applied to the shared task data by carreras et al (2003<papid> W03-0422 </papid>a) and hammerton used recurrent neural network (long short-term memory) for finding named entities.other learning approaches were employed less fre quently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1706">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>zhang and johnson (2003) <papid> W03-0434 </papid>used robust risk minimization, which is winnow technique.</prevsent>
<prevsent>florian et al (2003) <papid> W03-0425 </papid>employed the same technique in combination of learners.</prevsent>
</prevsection>
<citsent citstr=" W03-0422 ">
voted perceptrons were applied to the shared task data by carreras et al (2003<papid> W03-0422 </papid>a) and hammerton used recurrent neural network (long short-term memory) for finding named entities.other learning approaches were employed less fre quently.</citsent>
<aftsection>
<nextsent>two teams used adaboost.mh (carreras et al, 2003<papid> W03-0422 </papid>b; wu et al, 2003) <papid> W03-0433 </papid>and two other groups employed memory-based learning (de meulder and daelemans, 2003; hendrickx and vanden bosch, 2003).</nextsent>
<nextsent>transformation-based learning (florian et al., 2003), <papid> W03-0425 </papid>support vector machines (mayfield et al, 2003) <papid> W03-0429 </papid>and conditional random fields (mccallum and li, 2003) <papid> W03-0430 </papid>were applied by one system each.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1712">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>florian et al (2003) <papid> W03-0425 </papid>employed the same technique in combination of learners.</prevsent>
<prevsent>voted perceptrons were applied to the shared task data by carreras et al (2003<papid> W03-0422 </papid>a) and hammerton used recurrent neural network (long short-term memory) for finding named entities.other learning approaches were employed less fre quently.</prevsent>
</prevsection>
<citsent citstr=" W03-0433 ">
two teams used adaboost.mh (carreras et al, 2003<papid> W03-0422 </papid>b; wu et al, 2003) <papid> W03-0433 </papid>and two other groups employed memory-based learning (de meulder and daelemans, 2003; hendrickx and vanden bosch, 2003).</citsent>
<aftsection>
<nextsent>transformation-based learning (florian et al., 2003), <papid> W03-0425 </papid>support vector machines (mayfield et al, 2003) <papid> W03-0429 </papid>and conditional random fields (mccallum and li, 2003) <papid> W03-0430 </papid>were applied by one system each.</nextsent>
<nextsent>combination of different learning systems has proven to be good method for obtaining excellentresults.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1715">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>voted perceptrons were applied to the shared task data by carreras et al (2003<papid> W03-0422 </papid>a) and hammerton used recurrent neural network (long short-term memory) for finding named entities.other learning approaches were employed less fre quently.</prevsent>
<prevsent>two teams used adaboost.mh (carreras et al, 2003<papid> W03-0422 </papid>b; wu et al, 2003) <papid> W03-0433 </papid>and two other groups employed memory-based learning (de meulder and daelemans, 2003; hendrickx and vanden bosch, 2003).</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
transformation-based learning (florian et al., 2003), <papid> W03-0425 </papid>support vector machines (mayfield et al, 2003) <papid> W03-0429 </papid>and conditional random fields (mccallum and li, 2003) <papid> W03-0430 </papid>were applied by one system each.</citsent>
<aftsection>
<nextsent>combination of different learning systems has proven to be good method for obtaining excellentresults.
</nextsent>
<nextsent>five participating groups have applied system combination.
</nextsent>
<nextsent>florian et al (2003) <papid> W03-0425 </papid>tested different methods for combining the results of four systems and found that robust risk minimization workedbest.</nextsent>
<nextsent>klein et al (2003) <papid> W03-0428 </papid>employed stacked learning system which contains hidden markov models, maximum entropy models and conditional markov models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1726">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>klein et al (2003) <papid> W03-0428 </papid>employed stacked learning system which contains hidden markov models, maximum entropy models and conditional markov models.</prevsent>
<prevsent>mayfield et al (2003) <papid> W03-0429 </papid>stacked two learners and obtained better performance.</prevsent>
</prevsection>
<citsent citstr=" W03-0431 ">
wu et al (2003) <papid> W03-0433 </papid>applied both stacking and voting to three learners.munro et al (2003) <papid> W03-0431 </papid>employed both voting and bagging for combining classifiers.</citsent>
<aftsection>
<nextsent>3.2 features.
</nextsent>
<nextsent>the choice of the learning approach is important for obtaining good system for recognizing named entities.
</nextsent>
<nextsent>however, in the conll-2002 shared task wefound out that choice of features is at least as important.
</nextsent>
<nextsent>an overview of some of the types of features chosen by the shared task participants, can be found in table 3.all participants used lexical features (words) except for whitelaw and patrick (2003) <papid> W03-0432 </papid>who implemented character-based method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1744">
<title id=" W03-0419.xml">introduction to the conll2003 shared task language independent named entity recognition </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>we assume that performance is significantly different from performance if is not within the center 90% of the distribution of b. the performances of the sixteen systems on thetwo test datasets can be found in table 5.
</prevsent>
<prevsent>for english, the combined classifier of florian et al (2003) <papid> W03-0425 </papid>achieved the highest overall f?=1 rate.</prevsent>
</prevsection>
<citsent citstr=" W03-0423 ">
however, the difference between their performance and that of the maximum entropy approach of chieu and ng (2003) <papid> W03-0423 </papid>is not significant.</citsent>
<aftsection>
<nextsent>an important feature of the best system that other participants did not use, was the inclusion of the output of two externally trained named entity recognizers in the combination process.
</nextsent>
<nextsent>florian et al (2003) <papid> W03-0425 </papid>have also obtained the highestf?=1 rate for the german data.</nextsent>
<nextsent>here there is no significant difference between them and the systems of klein et al (2003) <papid> W03-0428 </papid>and zhang and johnson (2003).<papid> W03-0434 </papid>we have combined the results of the sixteen system in order to see if there was room for improve ment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1780">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> automatic lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>each class is described by vector of features.
</prevsent>
<prevsent>aclass of features that intuitively carry semantic information are collocations, i.e., words that co-occur with the nouns of interest in corpus.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
collocations have been widely used for tasks such as word sense disambiguation (wsd) (yarowsky, 1995), <papid> P95-1026 </papid>information extraction (ie) (riloff, 1996), and named-entity recognition (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>the choice of collocations can be conditioned in many ways: according to syntactic relations with the target word, syntactic category, distance from the target, and so on.
</nextsent>
<nextsent>we use very simple set of collocations: each word   that appears within (*) positions from noun + is feature.
</nextsent>
<nextsent>each occurrence, or token, ,of + , +.- , is then characterized by vector of feature counts +/- . the vector representation of the noun type + is the sum of all the vectors representing the contexts in which it occurs.
</nextsent>
<nextsent>overall the vector representation for each class in the dictionary is the sum of the vectors of all nouns that are members of the class  1032 46587 2 + while the vector representation of an unknown noun is the sum of the feature vectors of the contexts in which it occurred  90 2+: the corpus that we used to collect the statistics about collocations is the set of articles from the 1989 wall street journal (about 4 million words) in the bllip99 corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1781">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> automatic lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>each class is described by vector of features.
</prevsent>
<prevsent>aclass of features that intuitively carry semantic information are collocations, i.e., words that co-occur with the nouns of interest in corpus.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
collocations have been widely used for tasks such as word sense disambiguation (wsd) (yarowsky, 1995), <papid> P95-1026 </papid>information extraction (ie) (riloff, 1996), and named-entity recognition (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>the choice of collocations can be conditioned in many ways: according to syntactic relations with the target word, syntactic category, distance from the target, and so on.
</nextsent>
<nextsent>we use very simple set of collocations: each word   that appears within (*) positions from noun + is feature.
</nextsent>
<nextsent>each occurrence, or token, ,of + , +.- , is then characterized by vector of feature counts +/- . the vector representation of the noun type + is the sum of all the vectors representing the contexts in which it occurs.
</nextsent>
<nextsent>overall the vector representation for each class in the dictionary is the sum of the vectors of all nouns that are members of the class  1032 46587 2 + while the vector representation of an unknown noun is the sum of the feature vectors of the contexts in which it occurred  90 2+: the corpus that we used to collect the statistics about collocations is the set of articles from the 1989 wall street journal (about 4 million words) in the bllip99 corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1782">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>one problem that we noticed is that there are several cases of nouns that have intuitively meaningful suffixes or prefixes that are not present in our hand-coded lists.
</prevsent>
<prevsent>a possible solution to his problem might be the use of more general morphological rules like those used in part-of-speech tagging models (e.g., 1 2 3 4 5 30 40 50 60 70 80 90 100 level rr r rand base boost_s nntfidf nb boost_m figure 6: comparison of all models for ? 03_baba??
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
.ratnaparkhi (1996)), <papid> W96-0213 </papid>where all suffixes up to certain length are included.</citsent>
<aftsection>
<nextsent>we observed also cases of recurrent confusion between classes.
</nextsent>
<nextsent>for example between act and abstraction (or their subor dinates), e.g., for the noun modernization, possibly because the suffix is common in both cases.another measure of the importance of morphological features is the ratio of their use with respect to that of collocations.
</nextsent>
<nextsent>in the first 100 rounds of  ?bb? ? , at level 5, 77% of the features selected are morphological, 69% in the first 200 rounds.
</nextsent>
<nextsent>as figures 4 and 5 show these early rounds are usually the ones in which most of the error is reduced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1784">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>foul-up (granger, 1977) is one of these early models that tries to deterministically maximize the expectations built into its knowledge base.
</prevsent>
<prevsent>jacobs and zernik (1988) introduced the idea of using morphological information, together with other sources, to guess the meaning of unknownwords.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
hastings and lytinen (1994) investigated attacking the lexical acquisition problem with system that relies mainly on taxonomic information.in the last decade or so research on lexical semantics has focused more on sub-problems like word sense disambiguation (yarowsky, 1995; <papid> P95-1026 </papid>stevenson and wilks, 2001), <papid> J01-3001 </papid>named entity recognition (collins and singer, 1999), <papid> W99-0613 </papid>and vocabulary construction for information extraction (riloff, 1996).</citsent>
<aftsection>
<nextsent>all of these can be seen as sub-tasks, because the space of possible classes for each word is restricted.
</nextsent>
<nextsent>in wsd the possible classes for word are its possible senses; in named entity recognition or ie the number of classes is limited to the fixed (usually small) number the task focuses on.
</nextsent>
<nextsent>other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns ofthe kind x, and other zs?, as in the phrase blue jays, robins and other birds?.
</nextsent>
<nextsent>these types of models have been used for hyponym discovery (hearst,1992; <papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>meronym discovery (berland and charniak, 1999), <papid> P99-1008 </papid>and hierarchy building (caraballo, 1999).<papid> P99-1016 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1786">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in wsd the possible classes for word are its possible senses; in named entity recognition or ie the number of classes is limited to the fixed (usually small) number the task focuses on.
</prevsent>
<prevsent>other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns ofthe kind x, and other zs?, as in the phrase blue jays, robins and other birds?.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
these types of models have been used for hyponym discovery (hearst,1992; <papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>meronym discovery (berland and charniak, 1999), <papid> P99-1008 </papid>and hierarchy building (caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>these methods are very interesting but of limited applicability, because nouns that do not appear in known lexico-syntactic patterns cannot be learned.
</nextsent>
<nextsent>all the approaches cited above focus on some aspect of the problem of lexical acquisition.
</nextsent>
<nextsent>what we learn from them is that information about the meaning of words comes in very different forms.
</nextsent>
<nextsent>one thing that needs to be investigated is the design of better sets of features that encode the information that has been found useful in these studies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1787">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in wsd the possible classes for word are its possible senses; in named entity recognition or ie the number of classes is limited to the fixed (usually small) number the task focuses on.
</prevsent>
<prevsent>other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns ofthe kind x, and other zs?, as in the phrase blue jays, robins and other birds?.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
these types of models have been used for hyponym discovery (hearst,1992; <papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>meronym discovery (berland and charniak, 1999), <papid> P99-1008 </papid>and hierarchy building (caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>these methods are very interesting but of limited applicability, because nouns that do not appear in known lexico-syntactic patterns cannot be learned.
</nextsent>
<nextsent>all the approaches cited above focus on some aspect of the problem of lexical acquisition.
</nextsent>
<nextsent>what we learn from them is that information about the meaning of words comes in very different forms.
</nextsent>
<nextsent>one thing that needs to be investigated is the design of better sets of features that encode the information that has been found useful in these studies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1788">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in wsd the possible classes for word are its possible senses; in named entity recognition or ie the number of classes is limited to the fixed (usually small) number the task focuses on.
</prevsent>
<prevsent>other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns ofthe kind x, and other zs?, as in the phrase blue jays, robins and other birds?.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
these types of models have been used for hyponym discovery (hearst,1992; <papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>meronym discovery (berland and charniak, 1999), <papid> P99-1008 </papid>and hierarchy building (caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>these methods are very interesting but of limited applicability, because nouns that do not appear in known lexico-syntactic patterns cannot be learned.
</nextsent>
<nextsent>all the approaches cited above focus on some aspect of the problem of lexical acquisition.
</nextsent>
<nextsent>what we learn from them is that information about the meaning of words comes in very different forms.
</nextsent>
<nextsent>one thing that needs to be investigated is the design of better sets of features that encode the information that has been found useful in these studies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1789">
<title id=" W02-0903.xml">boosting automatic lexical acquisition with morphological information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in wsd the possible classes for word are its possible senses; in named entity recognition or ie the number of classes is limited to the fixed (usually small) number the task focuses on.
</prevsent>
<prevsent>other kinds of models that have been studied in the context of lexical acquisition are those based on lexico-syntactic patterns ofthe kind x, and other zs?, as in the phrase blue jays, robins and other birds?.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
these types of models have been used for hyponym discovery (hearst,1992; <papid> C92-2082 </papid>roark and charniak, 1998), <papid> P98-2182 </papid>meronym discovery (berland and charniak, 1999), <papid> P99-1008 </papid>and hierarchy building (caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>these methods are very interesting but of limited applicability, because nouns that do not appear in known lexico-syntactic patterns cannot be learned.
</nextsent>
<nextsent>all the approaches cited above focus on some aspect of the problem of lexical acquisition.
</nextsent>
<nextsent>what we learn from them is that information about the meaning of words comes in very different forms.
</nextsent>
<nextsent>one thing that needs to be investigated is the design of better sets of features that encode the information that has been found useful in these studies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1790">
<title id=" W03-1508.xml">transliteration of proper names in cross lingual information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several techniques have been proposed in the recent past for name transliteration.
</prevsent>
<prevsent>rather than providing comprehensive survey we highlight few representative approaches here.
</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
finite state transducers that implement transformation rules for back-transliteration from japanese to english have been described by knight and graehl (1997), <papid> P97-1017 </papid>and extended to arabic by glover-stalls and knight (1998).</citsent>
<aftsection>
<nextsent>in both cases, the goal is to recognize words in japanese or arabic text which hap figure 1: four steps in english-to-chinese transliteration of names.
</nextsent>
<nextsent>pen to be transliterations of english names.
</nextsent>
<nextsent>if the orthography of language is strongly phonetic, as is the case for korean, then one may use relatively simple hidden markov models to transform english pronunciations, as shown by jung et al (2000).<papid> C00-1056 </papid></nextsent>
<nextsent>the work closest to our application scenario, and the onewith which we will be making several direct comparisons, is that of meng et al (2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1791">
<title id=" W03-1508.xml">transliteration of proper names in cross lingual information retrieval </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in both cases, the goal is to recognize words in japanese or arabic text which hap figure 1: four steps in english-to-chinese transliteration of names.
</prevsent>
<prevsent>pen to be transliterations of english names.
</prevsent>
</prevsection>
<citsent citstr=" C00-1056 ">
if the orthography of language is strongly phonetic, as is the case for korean, then one may use relatively simple hidden markov models to transform english pronunciations, as shown by jung et al (2000).<papid> C00-1056 </papid></citsent>
<aftsection>
<nextsent>the work closest to our application scenario, and the onewith which we will be making several direct comparisons, is that of meng et al (2001).
</nextsent>
<nextsent>in their work,a set of hand-crafted transformations for locally editing the phonemic spelling of an english word to conform to rules of mandarin syllabification are used to seed transformation-based learning algorithm.
</nextsent>
<nextsent>the algorithm examines some data and learns the proper sequence of application of the transformations to convert an english phoneme sequence to mandarin syllable sequence.
</nextsent>
<nextsent>our paper describes data driven counterpart to this technique, in which cascade of two source-channel translation models is used to go from english names to their chinese transliteration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1792">
<title id=" W03-1508.xml">transliteration of proper names in cross lingual information retrieval </title>
<section> translation system description.  </section>
<citcontext>
<prevsection>
<prevsent>are deterministic transformations,while steps 2.
</prevsent>
<prevsent>and 4.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
are accomplished using statistical means.the ibm source-channel model for statistical machine translation (p. brown et al , 1993) <papid> J93-2003 </papid>plays central role in our system.</citsent>
<aftsection>
<nextsent>we therefore describe it very briefly here for completeness.
</nextsent>
<nextsent>in this model,   word foreign language sentence
</nextsent>
<nextsent>       is modeled as the output of noisy channel?
</nextsent>
<nextsent>whose input is its correct  -word english translation       , and having observed the channel out put
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1793">
<title id=" W02-1203.xml">urdu and the parallel grammar project </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W02-1503 ">
we report on the role of the urdu grammar in the parallel grammar (pargram) project (butt et al, 1999; butt et al, 2002).<papid> W02-1503 </papid>1 the pargram project was designed to use single grammar development platform and unified methodology of grammar writing to develop large-scale grammars for typologi cally different languages.</citsent>
<aftsection>
<nextsent>at the beginning of the project, three typo logically similar european grammars were implemented.
</nextsent>
<nextsent>the addition of two asian languages, urdu and japanese, has shown that the basic analysis decisions made for the european languages can be applied to typo logically distinct languages.
</nextsent>
<nextsent>however, the asian languages required the addition of small number of new standard analyses to cover constructions and analysis technique snot found in the european languages.
</nextsent>
<nextsent>with these additional standards, the pargram project can now be applied to other typo logically distinct languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1797">
<title id=" W02-1203.xml">urdu and the parallel grammar project </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the pargram project uses the xle parser1we would like to thank mary dalrymple, ron kaplan, hiroshi masuichi, and tomoko ohkuma for their comments.
</prevsent>
<prevsent>2norwegian was also added at this time.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
and grammar development platform (maxwell and kaplan, 1993) <papid> J93-4001 </papid>to develop deep grammars for six languages.</citsent>
<aftsection>
<nextsent>all of the grammars use the lexical-functional grammar (lfg) formalism which produces c(onstituent)-structures (trees) and f(unctional)-structures (avms) as syntactic analyses.
</nextsent>
<nextsent>lfg assumes version of chomskys universal grammar hypothesis, namely that all languages are governed by similar underlying structures.
</nextsent>
<nextsent>within lfg, f-structures encode language universal level of analysis, allowing for cross-linguistic parallelism.the pargram project aims to test the lfg formalism for its universality and coverage limitations and to see how far parallelism can be maintained across languages.
</nextsent>
<nextsent>where possible, the analyses produced for similar constructions in each language are parallel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1798">
<title id=" W02-1203.xml">urdu and the parallel grammar project </title>
<section> morphology.  </section>
<citcontext>
<prevsection>
<prevsent>for the original three languages, such morphologies were readily available.
</prevsent>
<prevsent>as they had been developed for information extraction applications instead of deep grammar applications, there were some minor problems, but the coverage of these morphologiesis excellent.
</prevsent>
</prevsection>
<citsent citstr=" C00-1004 ">
an efficient, broad-coverage morphology was also available for japanese (asahara and matsumoto, 2000) <papid> C00-1004 </papid>and was integrated into the grammar.</citsent>
<aftsection>
<nextsent>this has aided in the japanese grammar rapidly achieving broad coverage.
</nextsent>
<nextsent>it has also helped control ambiguity because in the case of japanese, the morphology determines the part of speech of each word in the string with very little ambiguity.while some morphological analyzers already exist for hindi,3 e.g., as part of the tools developed at the language technologies research centre (ltrc), iit hyderabad (http://www.iiit.net/ltrc/index.html), they are not immediately compatible with the xle grammar development platform, nor is it clear that the morphological analyses they produce conform to the standards and methods developed within the pargram project.
</nextsent>
<nextsent>as such, part of the urdu project is to build finite-state morphology that will serve as resource to the urdu grammar and could be used in other applications.the development of the urdu morphology involves two step process.
</nextsent>
<nextsent>the first step is to determine the morphological class of words and theirsubtypes in urdu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1799">
<title id=" W02-1203.xml">urdu and the parallel grammar project </title>
<section> grammar.  </section>
<citcontext>
<prevsection>
<prevsent>(10) a. [anjum ne] [saddaf ko] [citthi] anjum.f=erg saddaf.f=dat note.f.nom [likhne di] write-inf.obl give-perf.f.sg anjum let saddaf write note.?
</prevsent>
<prevsent>b. anjum ne di saddaf ko [citthi likhne] c. anjum ne [citthi likhne] saddaf ko di the manipulation of predicational structures in the lexicon via lexical rules (as is done for the english passive, for example), is therefore inadequate for complex predication.
</prevsent>
</prevsection>
<citsent citstr=" E93-1024 ">
based on the needs of the urdu grammar, xle has been modified to allow the analysis of complex predicates via the restriction operator (kaplan and wedekind, 1993) <papid> E93-1024 </papid>in conjunction with predicate composition in the syntax.</citsent>
<aftsection>
<nextsent>these new tools are currently being tested by the implementation of the new complex predicates analysis.
</nextsent>
<nextsent>one issue that has not been dealt with in the urdu grammar is the different script systems used for urdu and hindi.
</nextsent>
<nextsent>as seen in the previous discussions and the figures, transcription into latin ascii is currently used by the urdu grammar.
</nextsent>
<nextsent>this is not limitation of the xle system: the japanese grammar has successfully integrated japanese kana and kanji into their grammar.the approach taken by the urdu grammar is different from that of the japanese, largely because two scripts are involved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1800">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>starting with no human translations from german to english we produce german to english translation model with 45%accuracy using parallel corpora in other languages.
</prevsent>
<prevsent>this suggests the method may be useful in the creation of parallel corpora for languages with scarce resources.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
statistical translation models (such as those formulated inbrown et al (1993)) <papid> J93-2003 </papid>are trained from bilingual sentence aligned texts.</citsent>
<aftsection>
<nextsent>the bilingual data used for constructing translation models is often gathered from government documents produced in multiple languages.
</nextsent>
<nextsent>for example, the candide system (berger et al, 1994) <papid> H94-1028 </papid>was trained on ten years?</nextsent>
<nextsent>worth of canadian parliament proceedings, which consists of 2.87 million parallel sentences in french and english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1801">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical translation models (such as those formulated inbrown et al (1993)) <papid> J93-2003 </papid>are trained from bilingual sentence aligned texts.</prevsent>
<prevsent>the bilingual data used for constructing translation models is often gathered from government documents produced in multiple languages.</prevsent>
</prevsection>
<citsent citstr=" H94-1028 ">
for example, the candide system (berger et al, 1994) <papid> H94-1028 </papid>was trained on ten years?</citsent>
<aftsection>
<nextsent>worth of canadian parliament proceedings, which consists of 2.87 million parallel sentences in french and english.
</nextsent>
<nextsent>while the candide system was widely regarded as successful, its success is not indicative of the potential for statistical translation between arbitrary language pairs.
</nextsent>
<nextsent>the reason for this is that collections of parallel texts as large as the canadian hansa rds are rare.
</nextsent>
<nextsent>al-onaizan et al (2000) explains in simple terms the reasons that using large amounts of training data ensures translation quality: if program sees particular word or phrase one thousand times during training, it is more likely to learn correct translation than if sees it ten times, or once, or never.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1802">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or en espanol?
</prevsent>
<prevsent>then the page linked to is treated as candidate translation of the english page.
</prevsent>
</prevsection>
<citsent citstr=" W02-1013 ">
further checks verify the plausibility of its being translation (smith, 2002).<papid> W02-1013 </papid></citsent>
<aftsection>
<nextsent>instead of attempting to gather new translations fromthe web, we describe an alternate method for automatically creating parallel corpora.
</nextsent>
<nextsent>specifically, we examine the use of existing translations as resource to bootstrap more training data, and to create data for new language pairs.
</nextsent>
<nextsent>we generate translation models from existing data and use them to produce translations of new sen 4446485052545658606264 1000 0 20000 30000 40000 50000 60000 70000 80000 90000 10000 0 accuracy (100 - word error rate) trainin corpus siz (numb er of sentence airs) germa frenc spanis figure 1: translation accuracy plotted against training corpus size tences.
</nextsent>
<nextsent>incorporating this machine-created parallel data to the original set, and retraining the translation models improves the translation accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1803">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we generate translation models from existing data and use them to produce translations of new sen 4446485052545658606264 1000 0 20000 30000 40000 50000 60000 70000 80000 90000 10000 0 accuracy (100 - word error rate) trainin corpus siz (numb er of sentence airs) germa frenc spanis figure 1: translation accuracy plotted against training corpus size tences.
</prevsent>
<prevsent>incorporating this machine-created parallel data to the original set, and retraining the translation models improves the translation accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
to perform the retraining we use co-training (blum and mitchell, 1998; abney, 2002) <papid> P02-1046 </papid>which is weakly supervised learning technique that relies on having distinct views of the items being classified.</citsent>
<aftsection>
<nextsent>the views that we employ for co-training are multiple source documents.section 2 motivates the use of weakly supervised learning, and introduces co-training for machine translation.section 3 reports our experimental results.
</nextsent>
<nextsent>one experiment shows that co-training can modestly benefit translation systems trained from similarly sized corpora.
</nextsent>
<nextsent>asecond experiment shows that co-training can have dramatic benefit when the size of initial training corpora aremismatched.
</nextsent>
<nextsent>this suggests that co-training for statistical machine translation is especially useful for languages with impoverished training corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1804">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> co-training for statistical machine.  </section>
<citcontext>
<prevsection>
<prevsent>two conflicting factors make this reliance on annotated training data problem: ? the accuracy of machine learning improves as more data is available (as we have shown for statistical machine translation in figure 1).?
</prevsent>
<prevsent>annotated training data usually has some cost associated with its creation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
this cost can often be substantial, as with the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>there has recently been considerable interest in weakly supervised learning within the statistical nlp community.
</nextsent>
<nextsent>the goal of weakly supervised learning is to reduce the cost of creating new annotated corpora by (semi-) automating the process.
</nextsent>
<nextsent>co-training is weakly supervised learning techniques which uses an initially small amount of human labeled data to automatically bootstrap larger sets of machine labeled training data.
</nextsent>
<nextsent>in co-training implementations multiple learners are used to label new examples andre trained on some of each others labeled examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1805">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> co-training for statistical machine.  </section>
<citcontext>
<prevsection>
<prevsent>because languages vary in how they use morphology (some languages have grammatical gender whereas others dont) one languages translation model might have the translation of particular word form whereas anothers would not.
</prevsent>
<prevsent>thus co-training can increase the inventory ofword forms and reduce the problem that morphology poses to simple statistical translation models.?
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
improved word order ? significant source of errors in statistical machine translation is the word reordering problem (och et al, 1999).<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>the word order between related languages is often similar while word order between distant language may differ significantly.
</nextsent>
<nextsent>by including more examples through co training with related languages, the translation models for distant languages will better learn word order mappings to the target language.in all these cases the diversity afforded by multiple translation models increases the chances that the machine translated sentences added to the initial bilingual corpora will be accurate.
</nextsent>
<nextsent>our co-training algorithm allows many source languages to be used.
</nextsent>
<nextsent>in order to conduct co-training experiments we first needed to assemble appropriate corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1806">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>whereas och and ney use multiple source strings to improve thequality of one translation only, our co-training method attempts to improve the accuracy of all translation models by bootstrapping more training data from multiple source documents.
</prevsent>
<prevsent>3.1 software.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
the software that we used to train the statistical models and to produce the translations was giza++ (ochand ney, 2000), <papid> P00-1056 </papid>the cmu-cambridge language modeling toolkit (clarkson and rosenfeld, 1997), and the isi rewrite decoder.</citsent>
<aftsection>
<nextsent>the sizes of the language models usedin each experiment were fixed throughout, in order to ensure that any gains that were made were not due to the trivial reason of the language model improving (which could be done by building larger monolingual corpus of the target language).
</nextsent>
<nextsent>the experiments that we conducted used giza++ to produce ibm model 4 translation models.
</nextsent>
<nextsent>it should be observed, however, that our co-training algorithm is entirely general and may be applied to any formulation of statistical machine translation which relies on parallel round number translation pair 0 1 2 3 french english 55.2 56.3 57.0 55.5 spanish english 57.2 57.8 57.6 56.9 german english 45.1 46.3 47.4 47.6 italian english 53.8 54.0 53.6 53.5 portuguese eng 55.2 55.2 55.7 54.3 table 1: co-training results over three rounds corpora for its training data.
</nextsent>
<nextsent>3.2 evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1807">
<title id=" W03-0310.xml">bootstrapping parallel corpora </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the table indicates that gains may be had from co-training.
</prevsent>
<prevsent>each of the translation models improves over its initial training size at some point in the co-training.
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
the german to english translation model improves the most ? exhibiting 2.5% improvement in accuracy.the table further indicates that co-training forma chine translation suffers the same problem reported in pierce and cardie (2001): <papid> W01-0501 </papid>gains above the accuracy ofthe initial corpus are achieved, but decline as after certain number of machine translations are added to the training set.</citsent>
<aftsection>
<nextsent>this could be due in part to the manner in items are selected for each round.
</nextsent>
<nextsent>because the best translations are transferred from the candidate pool to the 2727.52828.52929.530 100 00 15000 20000 25000 30000 35000 40000 accuracy (100 - word error rate) trainin corpus siz (numb er of sentence airs)coachin of erman figure 3: coaching?
</nextsent>
<nextsent>of german to english by french to english translation model 43.84444.244.444.644.84545.2 100 000 15000 0 20000 0 25000 0 30000 0 35000 0 40000 0 accuracy (100 - word error rate) trainin corpus siz (numb er of sentence airs)coachin of erman figure 4: coaching?
</nextsent>
<nextsent>of german to english by multiple translation model straining pool at each round the number of easy?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1808">
<title id=" W03-0309.xml">the duluth word alignment system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also varied the model 2 distortion parameters among the values 2, 4,and 6, but did not observe any significant differences in performance as result.
</prevsent>
<prevsent>word alignment is crucial part of any machine translation system, since it is the process of determining which words in given source and target language sentence pair are translations of each other.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
this is token level task, meaning that each word (token) in the source text is aligned with its corresponding translation in the target text.the duluth word alignment system is perl implementation of ibm model 2 (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>it learns probabilistic model from sentence aligned parallel text that can then be used to align the words in another such text (that was not part of the training process).
</nextsent>
<nextsent>a parallel text consists of source language text andits translation into some target language.
</nextsent>
<nextsent>if we have determined which sentences are translations of each other then the text is said to be sentence aligned, where we call source and target language sentence that are translations of each other sentence pair.(brown et al, 1993) <papid> J93-2003 </papid>introduced five statistical translation models (ibm models 1 ? 5).</nextsent>
<nextsent>in general statistical machine translation system is composed of three com ponents: language model, translation model, and decoder (brown et al, 1988).<papid> C88-1016 </papid>the language model tells how probable given sentence is in the source language, the translation model indicates how likely it is that particular target sentence is translation of given source sentence, and the decode ris what actually takes source sentence as input and produces its translation as output.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1810">
<title id=" W03-0309.xml">the duluth word alignment system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a parallel text consists of source language text andits translation into some target language.
</prevsent>
<prevsent>if we have determined which sentences are translations of each other then the text is said to be sentence aligned, where we call source and target language sentence that are translations of each other sentence pair.(brown et al, 1993) <papid> J93-2003 </papid>introduced five statistical translation models (ibm models 1 ? 5).</prevsent>
</prevsection>
<citsent citstr=" C88-1016 ">
in general statistical machine translation system is composed of three com ponents: language model, translation model, and decoder (brown et al, 1988).<papid> C88-1016 </papid>the language model tells how probable given sentence is in the source language, the translation model indicates how likely it is that particular target sentence is translation of given source sentence, and the decode ris what actually takes source sentence as input and produces its translation as output.</citsent>
<aftsection>
<nextsent>our focus is on translation models, since that is where word alignment is carried out.
</nextsent>
<nextsent>the ibm models start very simply and grow steadily more complex.
</nextsent>
<nextsent>ibm model 1 is based solely on the probability that given word in the source language translates as particular word in the target language.
</nextsent>
<nextsent>thus, word in the first position of the source sentence is just as likely to translate to word in the target sentence that is in the first position versus one at the last position.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1811">
<title id=" W03-0309.xml">the duluth word alignment system </title>
<section> system components.  </section>
<citcontext>
<prevsection>
<prevsent>the plain2snt program converts raw sentence aligned parallel text into the snt format, where each word type in the source and target text is represented as unique integer.
</prevsent>
<prevsent>this program also outputs two vocabulary files for the source and target languages that list the word types and their integer values.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
this is closely modeled after what is done in the giza++ toolkit (och and ney, 2000<papid> P00-1056 </papid>b).</citsent>
<aftsection>
<nextsent>the snt2matrix program takes the snt file from plain2snt as input and outputs two files.
</nextsent>
<nextsent>the first is anadjacency list of possible word translations for each sentence pair.
</nextsent>
<nextsent>the second file consists of table of alignment positions that were observed in the training corpora.
</nextsent>
<nextsent>the value of the distortion factor determines which positions may be aligned with each other.the program model2 implements ibm model 2 as discussed in the previous section.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1819">
<title id=" W03-1721.xml">chinese word segmentation using minimal linguistic knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for short) and the beijing university corpus (  for short).
</prevsent>
<prevsent>we will refer to the segmented texts in the training corpus as the training data, and to both the unsegmented testing texts and the segmented texts (the reference texts) as the testing data.
</prevsent>
</prevsection>
<citsent citstr=" W03-1719 ">
for details on the word segmentation bakeoff, see (sproat and emerson, 2003).<papid> W03-1719 </papid></citsent>
<aftsection>
<nextsent>new texts are segmented in four steps which are described in this section.
</nextsent>
<nextsent>new words are automatically extracted fromthe unsegmented testing texts and added to the base dictionary consisting of words from the training data before the testing texts are segmented, line by line.
</nextsent>
<nextsent>2.1 base segmentation algorithm.
</nextsent>
<nextsent>given dictionary and sentence, our base segmentation algorithm finds all possible segment ations of the sentence with respect to the dictionary, computes the probability of each segmentation, and chooses the segmentation with the highest probability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1821">
<title id=" W02-0712.xml">automatic interpretation system integrating freestyle sentence translation and parallel text based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a speech-to-speech translation system must integrate at least three components ? speech recognition, machine translation, and speech synthesis.
</prevsent>
<prevsent>in practice, each component does not always output the correct result for various inputs, and an error in one component often leads to an incorrect result being produced by the total system even for limited domain.
</prevsent>
</prevsection>
<citsent citstr=" P98-1070 ">
clearly, we need ways to complementspeech-to-speech translation systems that cannot reliably produce correct result.although some robust methods that make the erroneous results of other components acceptable have been proposed (yumi et al, 1997; furuse et al, 1998), <papid> P98-1070 </papid>there is no guarantee that the final output from system will be appropriate even with these methods.</citsent>
<aftsection>
<nextsent>to deal with this problem, we have taken more practical approach to developing an automatic interpretation system where the user can obtain correct result instead of having to apply additional operations and judgment.
</nextsent>
<nextsent>in actual use of speech-to-speech translation system, an error in the speech-recognition or speech synthesis components is not large problem if the system has screen that displays each result.
</nextsent>
<nextsent>theuser of the system can correct errors in the recognition result on the screen, and can communicate by showing the other person the translated sentence on the screen.on the other hand, an error in the machine translation component is critical because user who is not familiar with the target language is unlikely to notice the error in some cases.
</nextsent>
<nextsent>when nonsensical sentence is generated by machine translation, the user may realize that the listener does not understand the translated sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1822">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and further restrict our attention to single-particlevpcs (i.e. we ignore vpcs such as get al ng to gether).
</prevsent>
<prevsent>we define vpcs to optionally select for an np complement, i.e. to occur both transit ively (e.g. hand in the paper) and intransitively (e.g. battle on).
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
one aspect of vpcs that makes them difficult to extract (cited in, e.g., smadja (1993)) <papid> J93-1007 </papid>is that the verb and particle can be non-contiguous, e.g. hand the paper in and battle right on.</citsent>
<aftsection>
<nextsent>this sets them apart from conventional collocations and terminology (see, e.g., manning and schutze (1999) and mckeown andra dev (2000)) in that they cannot be captured effectively using n-grams, due to the variability in the number and type of words potentially interceding between the verb and particle.
</nextsent>
<nextsent>we are aiming for an extraction technique which is applicable to any raw text corpus, allowing us to tune grammars to novel domains.
</nextsent>
<nextsent>any linguistic annotation required during the extraction process, therefore, is produced through automatic means,and it is only for reasons of accessibility and comparability with other research that we choose to work over the wall street journal section of the penn treebank (marcus et al , 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>that is, other than in establishing upper bounds on the performance of the different extraction methods, we use only the raw text component of the treebank.in this paper, we first outline distinguishing features of vpcs relevant to the extraction process (?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1823">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this sets them apart from conventional collocations and terminology (see, e.g., manning and schutze (1999) and mckeown andra dev (2000)) in that they cannot be captured effectively using n-grams, due to the variability in the number and type of words potentially interceding between the verb and particle.
</prevsent>
<prevsent>we are aiming for an extraction technique which is applicable to any raw text corpus, allowing us to tune grammars to novel domains.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
any linguistic annotation required during the extraction process, therefore, is produced through automatic means,and it is only for reasons of accessibility and comparability with other research that we choose to work over the wall street journal section of the penn treebank (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>that is, other than in establishing upper bounds on the performance of the different extraction methods, we use only the raw text component of the treebank.in this paper, we first outline distinguishing features of vpcs relevant to the extraction process (?
</nextsent>
<nextsent>2).
</nextsent>
<nextsent>we then present and evaluate number of simple methods for extracting vpcs based on, respectively, pos tagging (?
</nextsent>
<nextsent>3), the output of full text chunk parser (?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1824">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> method-1: simple pos-based.  </section>
<citcontext>
<prevsection>
<prevsent>we thus discount all particles which are more than 5 words from their governing verb.
</prevsent>
<prevsent>additionally, we extracted set of 73 canonical particles from the lingo-erg, and used this to filter out extraneous particles in the pos data.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
in line with our assumption of raw text to extract over, we use the brill tagger (brill, 1995) <papid> J95-4004 </papid>to automatically tag the wsj, rather than making use of the manual pos annotation provided in the penn treebank.</citsent>
<aftsection>
<nextsent>we further lemmatise the data using morph (minnen et al , 2001) and extract vpcs based on the brill tags.
</nextsent>
<nextsent>this produces total of 135 vpcs, which we evaluate according to the standard metrics of precision (prec), recall (rec) and f-score (f?=1).note that here and for the remainder of this paper, precision is calculated according to the manual annotation for the combined total of 4,173 vpc candidate types extracted by the various methods described in this paper, whereas recall is relative to the 62 attested vpcs from the alvey tools data as described above.
</nextsent>
<nextsent>as indicated in the first line of table 1 (brill?), the simple pos-based method results in precision of 1.000, recall of 0.177 and f-score of 0.301.in order to determine the upper bound on performance for this method, we ran the extraction method over the original tagging from the penn treebank.
</nextsent>
<nextsent>this resulted in an f-score of 0.774 (penn? in table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1825">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> method-1: simple pos-based.  </section>
<citcontext>
<prevsection>
<prevsent>as indicated in the first line of table 1 (brill?), the simple pos-based method results in precision of 1.000, recall of 0.177 and f-score of 0.301.in order to determine the upper bound on performance for this method, we ran the extraction method over the original tagging from the penn treebank.
</prevsent>
<prevsent>this resulted in an f-score of 0.774 (penn? in table 1).
</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
the primary reason for the large disparity between the brill tagger output and original penn treebank annotation is that it is notoriously difficult to differentiate between particles, prepositions and adverbs (toutanova and manning, 2000).<papid> W00-1308 </papid></citsent>
<aftsection>
<nextsent>over the wsj, the brill tagger achieves amodest tag recall of 0.103 for particles, and tag precision of 0.838.
</nextsent>
<nextsent>that is, it is highly conservative in allocating particle tags, to the extent that it recognises only two particle types for the whole of the wsj: out and down.
</nextsent>
<nextsent>extraction to overcome the shortcomings of the brill tagger in identifying particles, we next look to full chunk 2note, this is the same as the maximum span length of 5 used by smadja (1993), <papid> J93-1007 </papid>and above the maximum attested np length of 3 from our corpus study (see section 2.2).</nextsent>
<nextsent>wsj conll prec rec f?=1 prec rec f?=1 0.889 0.911 0.900 0.912 0.925 0.919 table 2: chunking performance parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1827">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> method-2: simple chunk-based.  </section>
<citcontext>
<prevsection>
<prevsent>it is therefore possible to adopt an analogous approach to that from method-1, in identifying particle chunks then working back to locate the verb each particle chunk is associated with.
</prevsent>
<prevsent>4.1 chunk parsing method.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
in order to chunk parse the wsj, we first tagged the full wsj and brown corpora using the brill tagger, and then converted them into chunks based on the original penn treebank parse trees, with the aid of the conversion script used in preparing theconll-2000 shared task data.3 we next lemma tised the data using morph (minnen et al , 2000),<papid> W00-1427 </papid>and chunk parsed the wsj with timbl 4.1 (daelemans et al , 2001) using the brown corpus as training data.</citsent>
<aftsection>
<nextsent>timbl is memory-based classification system based on the k-nearest neighbour algorithm, which takes as training dataset of fixed-lengthfeature vectors pre-classified according to an information field.
</nextsent>
<nextsent>for each test instance described overthe same feature vector, it then returns the neigh bours?
</nextsent>
<nextsent>at the k-nearest distances to the test instance and classifies the test instance according to the class distribution over those neighbours.
</nextsent>
<nextsent>timbl provides powerful functionality for determining the relative distance between different values of given feature in the form of mvdm, and also supports weighted voting between neighbours in classifying inputs, e.g. in the form of inverse distance weighting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1828">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> method-2: simple chunk-based.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluated the basic timbl method over both the full wsj data, training on the brown section of the penn treebank, and over the original shared task data from conll-2000, the results for which are presented in table 2.
</prevsent>
<prevsent>note that, similarly to the conll-2000 shared task, precision, recall and 3note that the gold standard chunk data for the wsj wasused only in evaluation of chunking performance, and to establish upper bounds on the performance of the various extraction methods.
</prevsent>
</prevsection>
<citsent citstr=" W00-0735 ">
4based on the results of veenstra and vanden bosch (2000) <papid> W00-0735 </papid>and the observation that mvdm is temperamental over sparse data (i.e. word lemmata).</citsent>
<aftsection>
<nextsent>chunker correct extracted prec rec f?=1 timbl 695854 0.772 0.548 0.641 penn 651760 0.857 0.694 0.766 table 3: chunk tag-based extraction results f-score are all evaluated at the chunk rather thanthe word level.
</nextsent>
<nextsent>the f-score of 0.919 for the conll 2000 data is roughly the median score attained by systems performing in the original task, and slightly higher than the f-score of 0.915 reported by veenstra and vanden bosch (2000), due to the use of word lemmata rather than surface forms, and also inverse distance weighting.
</nextsent>
<nextsent>the reason for the drop off in performance between the conll data and the full wsj is due to the conll training and test data coming from homogeneous data source, namely subsection of the wsj, but the brown corpus being used as the training data in chunking the full extent of the wsj.
</nextsent>
<nextsent>4.2 extraction method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1829">
<title id=" W02-2001.xml">extracting the un extractable a case study on verb particles </title>
<section> method-3: chunk grammar-based.  </section>
<citcontext>
<prevsection>
<prevsent>as case in point, the vp hand the paper in here could take any of the following structures: (1) hand [the paper] [in] [here] (transitive vpc hand in with adjunct np here), (2) hand [the paper] [inhere] (transitive prepositional verb hand in or simple transitive verb with pp adjunct), and (3) hand [the paper in here] (simple transitive verb).
</prevsent>
<prevsent>in such cases, we can choose to either (a) avoid committing ourselves to any one analysis, and ignore all such ambiguous cases, or (b) use some means to resolve the attachment ambiguity (i.e. whether the np is governed by the verb, resulting in vpc, or the preposition, resulting in prepositional verb or free verb preposition combination).
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
in the latter case, we use an unsupervised attachment disambiguation method, based on the log-likelihood ratio (llr?, dunning (1993)).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>that is, we use the chunker output to enumerate all the verb preposition, preposition?
</nextsent>
<nextsent>noun and verb noun bigrams in thewsj data, based on chunk heads rather than strict word bigrams.
</nextsent>
<nextsent>we then use frequency data to pre-calculate the llr foreach such type.
</nextsent>
<nextsent>in the case that the verb and par ticle?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1831">
<title id=" W02-1504.xml">machine translation as a testbed for multilingual analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the question of how to test natural language analysis systems has been central to all natural language work in the past two decades.
</prevsent>
<prevsent>it is difficult question, for which researchers have found only partial answers.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the most common answer is component testing, where the component is compared against standard of goodness, usually the penn treebank for english (marcus et al., 1993), <papid> J93-2004 </papid>allowing numerical score of precision and recall (e.g. collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>such methods have limitations, however, and need to be supplemented by additional methods.
</nextsent>
<nextsent>one limitation is the availability of annotated corpora, which do not exist for all languages.
</nextsent>
<nextsent>secondly, comparison to an annotated corpus can only measure how well system produces the kind of analysis for which the corpus is annotated, e.g. labeled bracketing of surface syntax.
</nextsent>
<nextsent>evaluation of analysis of deeper, more semantically descriptive, levels requires additional annotated corpora, which may not exist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1832">
<title id=" W02-1504.xml">machine translation as a testbed for multilingual analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the question of how to test natural language analysis systems has been central to all natural language work in the past two decades.
</prevsent>
<prevsent>it is difficult question, for which researchers have found only partial answers.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
the most common answer is component testing, where the component is compared against standard of goodness, usually the penn treebank for english (marcus et al., 1993), <papid> J93-2004 </papid>allowing numerical score of precision and recall (e.g. collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>such methods have limitations, however, and need to be supplemented by additional methods.
</nextsent>
<nextsent>one limitation is the availability of annotated corpora, which do not exist for all languages.
</nextsent>
<nextsent>secondly, comparison to an annotated corpus can only measure how well system produces the kind of analysis for which the corpus is annotated, e.g. labeled bracketing of surface syntax.
</nextsent>
<nextsent>evaluation of analysis of deeper, more semantically descriptive, levels requires additional annotated corpora, which may not exist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1833">
<title id=" W02-1504.xml">machine translation as a testbed for multilingual analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multi-lingual applications such as mt allow evaluation of system components that overcomes the limitations mentioned above, and therefore serves as useful complement to other evaluation techniques.
</prevsent>
<prevsent>another significant advantage to using mt as testbed for the analysis system is that it prioritizes analysis problems, highlighting those problems that have the greatest negative effect on translation output.
</prevsent>
</prevsection>
<citsent citstr=" W97-0908 ">
in this paper, we give an overview of nlpwin, multi-application natural language analysis and generation system underdevelopment at microsoft research (jensen et al, 1993; gamon et al, 1997; <papid> W97-0908 </papid>heidorn 2000), incorporating analysis systems for 7 languages (chinese, english, french, german, japanese, korean and spanish).</citsent>
<aftsection>
<nextsent>our discussion focuses on description of the three components of the analysis system (called sketch, portrait and logical form) with particular emphasis on the logical form derived as the end product, which serves as the medium for transfer in our mt system.
</nextsent>
<nextsent>we also give an overview of the architecture of the msr-mt system, and of the evaluation we use to measure correctness of the translations.
</nextsent>
<nextsent>we demonstrate the correlation between the scores assigned to translation outputs and the correctness of the analysis, using as illustration two language pairs at different stages of development: spanish english (se) translation, as testbed for the spanish analysis system, and french-english (fe) translation, as testbed for the french analysis system.
</nextsent>
<nextsent>nlpwin analysis produces three representations for the input sentence: sketch, portrait and logical form1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1834">
<title id=" W02-1504.xml">machine translation as a testbed for multilingual analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the lf of (1) is shown in figure 3.
</prevsent>
<prevsent>note that the surface subject of the passive is rendered as the dobj (deep object) in lf, and the par-phrase as the dsub (deep subject).
</prevsent>
</prevsection>
<citsent citstr=" W02-1510 ">
figure 3 : lf analysis of (1) modifications to any of the analysis components are tested using monolingual regression files containing thousands of analyzed sentences; differences caused by the modification are examined manually by the linguist responsible for the change (suzuki, 2002).<papid> W02-1510 </papid></citsent>
<aftsection>
<nextsent>this process serves as an initial screening to ensure that modifications to the analysis have the desired effect.
</nextsent>
<nextsent>3 msr-mt. in this section we review the basics of the msr mt translation system and its evaluation.
</nextsent>
<nextsent>the reader is referred to pinkham et al (2001) and richardson et al (2001) for further details on the french and spanish versions of the system.
</nextsent>
<nextsent>the overall architecture and basic component structure representation of campbell and suzuki (2002).<papid> W02-1510 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1836">
<title id=" W02-1504.xml">machine translation as a testbed for multilingual analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>3.1 overview.
</prevsent>
<prevsent>msr-mt uses the broad coverage analysis system described in section 2, large multi-purpose source-language dictionary, learned bilingual dictionary, an application independent target language generation component and transfer component.
</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
the transfer component consists of transfer patterns automatically acquired from sentence aligned bilingual corpora (described below) using an alignment algorithm described in detail in menezes and richardson (2001).<papid> W01-1406 </papid></citsent>
<aftsection>
<nextsent>training takes place on aligned sentences which have been analyzed by the source- and target-language analysis systems to yield logical forms.
</nextsent>
<nextsent>the logical form structures, when aligned, allow the extraction of lexical and structural translation correspondences which are stored for use at runtime in the transfer database.
</nextsent>
<nextsent>see figure 4 for an overview of the training process.
</nextsent>
<nextsent>the transfer database is trained on 350,000 pairs of aligned sentences from computer manuals for se, and 500,000 pairs of aligned canadian parliamentary data (the hansard corpus) for fe.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1837">
<title id=" W03-1028.xml">improved automatic keyword extraction given more linguistic knowledge </title>
<section> points of departure.  </section>
<citcontext>
<prevsection>
<prevsent>frequency.
</prevsent>
<prevsent>boguraev and kennedy (1999) extract technical terms based on the noun phrase patterns suggested by justeson and katz (1995); these terms are then the basis for headline-like characterisation of document.
</prevsent>
</prevsection>
<citsent citstr=" C94-1084 ">
the final example given in this paper is daille et al (1994) <papid> C94-1084 </papid>who apply statistical filters onthe extracted noun phrases.</citsent>
<aftsection>
<nextsent>in that study it is concluded that term frequency is the best filter candidate of the scores investigated.
</nextsent>
<nextsent>when pos patterns are used to extract potential terms, the problem lies in how to restrict the number of terms, and only keep the ones that are relevant.
</nextsent>
<nextsent>in the case of professional indexing, the terms are normally limited to domain-specific thesaurus, but not to those present only in the document to which they are assigned.
</nextsent>
<nextsent>for example, steinberger (2001) presents work where as first step, all lemmas after stop word removal in document are ranked according to the log-likelihood ratio, thus list of content descriptors is obtained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1838">
<title id=" W03-1801.xml">complex structuring of term variants for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper demonstrates how the combination ofthese two methodologies provide sophisticated access to technical domains.
</prevsent>
<prevsent>nominal compounds are inherently ambiguous on both the syntactic and semantic fronts.
</prevsent>
</prevsection>
<citsent citstr=" P84-1109 ">
whilst the number of syntactic possibilities increase exponentially with word length (isabelle, 1984), <papid> P84-1109 </papid>semantic interpretation is at best contextually dependent and inthe worst cases determined by extra-linguistic (prag matic) factors.</citsent>
<aftsection>
<nextsent>1technical documentation is an attractive domain in which to explore nominal compounds for two reasons.
</nextsent>
<nextsent>first, they present an abundance of compounds, secondly they restrict semantic interpretation by excluding compounds with opaque(extra-linguistic) interpretation.
</nextsent>
<nextsent>the result is multiword terms (mwt) which are both compositional,their formation is function of their constituent elements (kageura, 2002) and endo centric, the compound is hyponym of its head (barker and szpakowicz, 1998).<papid> P98-1015 </papid></nextsent>
<nextsent>1 for example, \apple juice place  (levi, 1979) this paper addresses the issue of structuring themulti-word terms (mwts) for question answering (qa) in technical domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1839">
<title id=" W03-1801.xml">complex structuring of term variants for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1technical documentation is an attractive domain in which to explore nominal compounds for two reasons.
</prevsent>
<prevsent>first, they present an abundance of compounds, secondly they restrict semantic interpretation by excluding compounds with opaque(extra-linguistic) interpretation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
the result is multiword terms (mwt) which are both compositional,their formation is function of their constituent elements (kageura, 2002) and endo centric, the compound is hyponym of its head (barker and szpakowicz, 1998).<papid> P98-1015 </papid></citsent>
<aftsection>
<nextsent>1 for example, \apple juice place  (levi, 1979) this paper addresses the issue of structuring themulti-word terms (mwts) for question answering (qa) in technical domains.
</nextsent>
<nextsent>the central problem is that unfamiliarity with mwts that characterize such domains creates an eective barrier against users nding answers.
</nextsent>
<nextsent>section 2 outlines the domain of focus, themwt extraction method and examples characteristic mwts.
</nextsent>
<nextsent>section 3 explores the qa task in technical domains by describing the extrans system,and how it structures the mwts for the task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1841">
<title id=" W03-1801.xml">complex structuring of term variants for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the importance of multi-word expressions (mwe)in various natural language tasks such as automatic indexing, machine translation, information retrieval/extraction and technology watch need no longer be proved.the multi-word expression project aims at studying the properties of wide range of expressions including collocations, metaphors and terminology.the motivation is in explicitly de ning the characteristics of such phrases.
</prevsent>
<prevsent>the results of the project will suggest ecient strategies for overcoming the problems mwes cause for nlp applications (sag et al, 2002) much work has been dedicated to the process of nominal compounding (levi, 1979) and the semantic interpretation of nominal compounds (downing, 1977) (finin, 1980).
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
other works have addressed the speci problem of extracting nominal multiword expressions for ir applications (evans et al, 1992) (smeaton and sheridan, 1992) (smadja, 1993)<papid> J93-1007 </papid>or of representing them semantically in order to enhance ir systems (popowich et al, 1992) (<papid> C92-1011 </papid>gay and croft, 1990).many systems are dedicated towards structuring terminology for ontology building or terminology knowledge base construction (aussenac-gilles et al, 2003).</citsent>
<aftsection>
<nextsent>these approaches use the corpus to identify linguistic markers which in turn pointto certain semantic relations between terms (hypernym/hyponym, synonyms, meronyms).
</nextsent>
<nextsent>the approaches we describe are dierent in that relations are gained through syntactic variations between the terms.active research by the computational terminology community (jacquemin, 2001) (bourigault etal., 2001) (pearson, 1998) has highlighted the importance of discourse as means of capturing the essence of terms, hence as good basis for structuring them.
</nextsent>
<nextsent>jacquemin extensive study has also highlighted the fact that terms are given to variations in discourse, so any endeavor to capture there lations between terminological units should integrate the variation paradigm.
</nextsent>
<nextsent>de ning and identifying semantic relations between terms is problematic but can be utilized as part of the qa process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1842">
<title id=" W03-1801.xml">complex structuring of term variants for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the importance of multi-word expressions (mwe)in various natural language tasks such as automatic indexing, machine translation, information retrieval/extraction and technology watch need no longer be proved.the multi-word expression project aims at studying the properties of wide range of expressions including collocations, metaphors and terminology.the motivation is in explicitly de ning the characteristics of such phrases.
</prevsent>
<prevsent>the results of the project will suggest ecient strategies for overcoming the problems mwes cause for nlp applications (sag et al, 2002) much work has been dedicated to the process of nominal compounding (levi, 1979) and the semantic interpretation of nominal compounds (downing, 1977) (finin, 1980).
</prevsent>
</prevsection>
<citsent citstr=" C92-1011 ">
other works have addressed the speci problem of extracting nominal multiword expressions for ir applications (evans et al, 1992) (smeaton and sheridan, 1992) (smadja, 1993)<papid> J93-1007 </papid>or of representing them semantically in order to enhance ir systems (popowich et al, 1992) (<papid> C92-1011 </papid>gay and croft, 1990).many systems are dedicated towards structuring terminology for ontology building or terminology knowledge base construction (aussenac-gilles et al, 2003).</citsent>
<aftsection>
<nextsent>these approaches use the corpus to identify linguistic markers which in turn pointto certain semantic relations between terms (hypernym/hyponym, synonyms, meronyms).
</nextsent>
<nextsent>the approaches we describe are dierent in that relations are gained through syntactic variations between the terms.active research by the computational terminology community (jacquemin, 2001) (bourigault etal., 2001) (pearson, 1998) has highlighted the importance of discourse as means of capturing the essence of terms, hence as good basis for structuring them.
</nextsent>
<nextsent>jacquemin extensive study has also highlighted the fact that terms are given to variations in discourse, so any endeavor to capture there lations between terminological units should integrate the variation paradigm.
</nextsent>
<nextsent>de ning and identifying semantic relations between terms is problematic but can be utilized as part of the qa process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1843">
<title id=" W02-1018.xml">a phrase based joint probability model for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>we present joint probability model for statistical machine translation, which automatically learns word and phrase equivalents from bilingual corpora.
</prevsent>
<prevsent>translations produced with parameters estimated using the joint model are more accurate than translations produced using ibm model 4.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
most of the noisy-channel-based models used in statistical machine translation (mt) (brown et al, 1993) <papid> J93-2003 </papid>are conditional probability models.</citsent>
<aftsection>
<nextsent>in the noisy-channel framework, each source sentence in parallel corpus is assumed to generate?
</nextsent>
<nextsent>a target sentence by means of stochastic process, whose parameters are estimated using traditional em techniques (dempster et al, 1977).
</nextsent>
<nextsent>the generative model explains how source words are mapped into target words and how target words are re-ordered to yield well-formed target sentences.
</nextsent>
<nextsent>a variety of methods are used to account for the re-orderingstage: word-based (brown et al, 1993), <papid> J93-2003 </papid>template based (och et al, 1999), <papid> W99-0604 </papid>and syntax-based (yamada and knight, 2001), <papid> P01-1067 </papid>to name just few.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1846">
<title id=" W02-1018.xml">a phrase based joint probability model for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>a target sentence by means of stochastic process, whose parameters are estimated using traditional em techniques (dempster et al, 1977).
</prevsent>
<prevsent>the generative model explains how source words are mapped into target words and how target words are re-ordered to yield well-formed target sentences.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
a variety of methods are used to account for the re-orderingstage: word-based (brown et al, 1993), <papid> J93-2003 </papid>template based (och et al, 1999), <papid> W99-0604 </papid>and syntax-based (yamada and knight, 2001), <papid> P01-1067 </papid>to name just few.</citsent>
<aftsection>
<nextsent>although these models use different generative processes to explain how translated words are re-ordered in target language, at the lexical level they are quite sim ilar; all these models assume that source words are individually translated into target words.1 1the individual words may contain non-existent element, called null.we suspect that mt researchers have so far chosen to automatically learn translation lexicons defined only over words for primarily pragmatic reasons.
</nextsent>
<nextsent>large scale bilingual corpora with vocabularies in the range of hundreds of thousands yield very large translation lexicons.
</nextsent>
<nextsent>tuning the probabilities associated with these large lexicons is difficult enough task to deter one from trying to scale up to learning phrase-based lexicons.
</nextsent>
<nextsent>unfortunately, trading space requirements and efficiency for explanatory power often yields non-intuitive results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1847">
<title id=" W02-1018.xml">a phrase based joint probability model for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>a target sentence by means of stochastic process, whose parameters are estimated using traditional em techniques (dempster et al, 1977).
</prevsent>
<prevsent>the generative model explains how source words are mapped into target words and how target words are re-ordered to yield well-formed target sentences.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
a variety of methods are used to account for the re-orderingstage: word-based (brown et al, 1993), <papid> J93-2003 </papid>template based (och et al, 1999), <papid> W99-0604 </papid>and syntax-based (yamada and knight, 2001), <papid> P01-1067 </papid>to name just few.</citsent>
<aftsection>
<nextsent>although these models use different generative processes to explain how translated words are re-ordered in target language, at the lexical level they are quite sim ilar; all these models assume that source words are individually translated into target words.1 1the individual words may contain non-existent element, called null.we suspect that mt researchers have so far chosen to automatically learn translation lexicons defined only over words for primarily pragmatic reasons.
</nextsent>
<nextsent>large scale bilingual corpora with vocabularies in the range of hundreds of thousands yield very large translation lexicons.
</nextsent>
<nextsent>tuning the probabilities associated with these large lexicons is difficult enough task to deter one from trying to scale up to learning phrase-based lexicons.
</nextsent>
<nextsent>unfortunately, trading space requirements and efficiency for explanatory power often yields non-intuitive results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1854">
<title id=" W02-1018.xml">a phrase based joint probability model for statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>for example, melamed (2001) uses word level alignments in order to learn translations of non compositional compounds.
</prevsent>
<prevsent>och and ney (1999) learn phrase-to-phrase mappings involving word classes, which they call templates?, and exploit them in statistical machine translation system.
</prevsent>
</prevsection>
<citsent citstr=" P01-1050 ">
andmarcu (2001) <papid> P01-1050 </papid>extracts phrase translations from automatically aligned corpora and uses them in conjunction with word-for-word statistical translation system.</citsent>
<aftsection>
<nextsent>however, none of these approaches learn simultaneously the translation of phrases/templates and the translation of words.
</nextsent>
<nextsent>as consequence, there is chance that the learning procedure will not discover phrase-level patterns that occur often in thedata.
</nextsent>
<nextsent>in our approach, phrases are not treated differently from individual words, and as consequence the likelihood of the em algorithm converging to better local maximum is increased.
</nextsent>
<nextsent>working with phrase translations that are learned independent of translation model can also affect the decoder performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1858">
<title id=" W03-1609.xml">paraphrase acquisition for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we tried to obtain more varied paraphrases.
</prevsent>
<prevsent>although our current method is intended for use in information extraction, we think the same approach can be applied to obtain paraphrases for other purposes, such as machine translation or text summa rization.there have been several attempts to obtain paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
(barzilay and mckeown, 2001) <papid> P01-1008 </papid>applied text alignment to parallel translations of single text and used part-of-speech tagger to obtain paraphrases.</citsent>
<aftsection>
<nextsent>(lin and pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions.
</nextsent>
<nextsent>(pang et al, 2003) <papid> N03-1024 </papid>also used text alignment and obtained finite state automaton which generates paraphrases.</nextsent>
<nextsent>(ravichandran and hovy, 2002) <papid> P02-1006 </papid>used pairs of questions and answer sto obtain varied patterns which give the same an swer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1859">
<title id=" W03-1609.xml">paraphrase acquisition for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(barzilay and mckeown, 2001) <papid> P01-1008 </papid>applied text alignment to parallel translations of single text and used part-of-speech tagger to obtain paraphrases.</prevsent>
<prevsent>(lin and pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions.</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
(pang et al, 2003) <papid> N03-1024 </papid>also used text alignment and obtained finite state automaton which generates paraphrases.</citsent>
<aftsection>
<nextsent>(ravichandran and hovy, 2002) <papid> P02-1006 </papid>used pairs of questions and answer sto obtain varied patterns which give the same an swer.</nextsent>
<nextsent>our approach is different from these works in that we used comparable news articles as source of paraphrases and used named entity tagging and dependency analysis to extract corresponding expres sions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1860">
<title id=" W03-1609.xml">paraphrase acquisition for information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(lin and pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions.
</prevsent>
<prevsent>(pang et al, 2003) <papid> N03-1024 </papid>also used text alignment and obtained finite state automaton which generates paraphrases.</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
(ravichandran and hovy, 2002) <papid> P02-1006 </papid>used pairs of questions and answer sto obtain varied patterns which give the same an swer.</citsent>
<aftsection>
<nextsent>our approach is different from these works in that we used comparable news articles as source of paraphrases and used named entity tagging and dependency analysis to extract corresponding expressions.
</nextsent>
<nextsent>acquisition our main goal is to obtain pattern clusters for ie,which consist of sets of equivalent patterns capturing the same information.
</nextsent>
<nextsent>so we tried to discover paraphrases contained in japanese news articles for specific domain.
</nextsent>
<nextsent>our basic idea is to search news articles from the same day.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1861">
<title id=" W03-1609.xml">paraphrase acquisition for information extraction </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>first we collected articles for specific do main from two different newspapers (mainichi and nikkei).
</prevsent>
<prevsent>then we used japanese part-of-speech tagger (kurohashi and nagao, 1998) and extended named entity tagger to process documents, and put them into topic detection and tracking system.
</prevsent>
</prevsection>
<citsent citstr=" P00-1042 ">
in this experiment, we used modified version of japanese extended named entity tagger (uchimotoet al, 2000).<papid> P00-1042 </papid></citsent>
<aftsection>
<nextsent>this tagger tags person names, organization names, locations, dates, times and numbers.
</nextsent>
<nextsent>article pairs: obtained correct system 195 156 (80%) sentence pairs: (from top 20 article pairs) obtained correct manual 93 93 w/o coref.
</nextsent>
<nextsent>55 41 (75%) coref.
</nextsent>
<nextsent>75 52 (69%) paraphrase pairs: obtained correct w/o coref.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1862">
<title id=" W02-1507.xml">a classification of grammar development strategies </title>
<section> type grammars: hand-crafted.  </section>
<citcontext>
<prevsection>
<prevsent>the xtag grammar for english, which is freely downloadable from the project homepage 2 (alongwith tools such as parser and an extensive doc umentation), has been under constant development for approximately 15 years.
</prevsent>
<prevsent>it consists of more than 1200 elementary trees (1000 for verbs) and has been tested on real text and test suites.
</prevsent>
</prevsection>
<citsent citstr=" C94-2149 ">
for instance, (doran et al, 1994) <papid> C94-2149 </papid>report that 61% of 1367 grammatical sentences from the tsnlp test-suite (lehman and al, 1996) were parsed with an early version of the grammar.</citsent>
<aftsection>
<nextsent>more recently, (prasad and sarkar, 2000) evaluated the coverage of the grammar onthe weather corpus?, which contained rather complex sentences with an average length of 20 words per sentence, as well as on the csli lkb test suite?
</nextsent>
<nextsent>(copestake, 1999).
</nextsent>
<nextsent>in addition, in order to 2http://www.cis.upenn.edu/ xtag/high level of syntactic ab stractionlow level of syntactic abstraction hand-crafted type a: type c: traditional hand-crafted grammarshand-crafted level of syntactic abstraction automatically generated grammars automatically acquired type b: type d:traditional treebank extracted grammars automatically acquired level of syntactic abstraction automatically generated grammar table 1: classification of grammars evaluate the range of syntactic phenomena covered by the xtag grammar, an internal test-suite which contains all the example sentences (grammatical and ungrammatical) from the continually updated documentation of the grammar is distributed with the grammar.
</nextsent>
<nextsent>(prasad and sarkar, 2000) argue that constant evaluation is useful not only to get an idea of the coverage of grammar, but also as way to continuously improve and enrich the grammar 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1863">
<title id=" W02-1507.xml">a classification of grammar development strategies </title>
<section> type grammars: automatically.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, the xtag grammar for english comes with very detailed documentation, which has proved extremely helpful to devise increasingly automated approaches to grammar development (see sections below) 4.
</prevsent>
<prevsent>extracted to remedy some of these problems, type grammars (i.e. automatically acquired, mostly from annotated corpora) have been developed.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
for instance(chiang, 2000), (<papid> P00-1058 </papid>xia, 2001) (chen, 2001) all automatically acquire large tags for english from thepenn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>however, despite an improvement in coverage, new problems arise with this type of grammars : availability of annotated data which is large enough to avoid sparse data problems, possible lack of linguistic adequacy,extraction of potentially unreasonably large grammars (slows down parsing and increases ambiguity),4perhaps fully hand-crafted grammars can be used in practice on limited domains, e.g. the weather corpus.
</nextsent>
<nextsent>however, degree of automation is useful even in those cases, if only to insure consistency and avoid some maintenance problems.
</nextsent>
<nextsent>lack of domain and framework independence (e.g. agr ammar extracted from the penn treebank will reflect the linguistic choices and the annotation errors made when annotating the treebank).
</nextsent>
<nextsent>we give two examples of problems encountered when automatically extracting tag grammars: the extraction of wrong domain of locality; and the problem of sparse-data regarding the integration of the lexicon with the grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1864">
<title id=" W02-1507.xml">a classification of grammar development strategies </title>
<section> type grammars: automatically.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, the xtag grammar for english comes with very detailed documentation, which has proved extremely helpful to devise increasingly automated approaches to grammar development (see sections below) 4.
</prevsent>
<prevsent>extracted to remedy some of these problems, type grammars (i.e. automatically acquired, mostly from annotated corpora) have been developed.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for instance(chiang, 2000), (<papid> P00-1058 </papid>xia, 2001) (chen, 2001) all automatically acquire large tags for english from thepenn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>however, despite an improvement in coverage, new problems arise with this type of grammars : availability of annotated data which is large enough to avoid sparse data problems, possible lack of linguistic adequacy,extraction of potentially unreasonably large grammars (slows down parsing and increases ambiguity),4perhaps fully hand-crafted grammars can be used in practice on limited domains, e.g. the weather corpus.
</nextsent>
<nextsent>however, degree of automation is useful even in those cases, if only to insure consistency and avoid some maintenance problems.
</nextsent>
<nextsent>lack of domain and framework independence (e.g. agr ammar extracted from the penn treebank will reflect the linguistic choices and the annotation errors made when annotating the treebank).
</nextsent>
<nextsent>we give two examples of problems encountered when automatically extracting tag grammars: the extraction of wrong domain of locality; and the problem of sparse-data regarding the integration of the lexicon with the grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1866">
<title id=" W02-1507.xml">a classification of grammar development strategies </title>
<section> type grammars.  </section>
<citcontext>
<prevsection>
<prevsent>this is especially noticeable within the tag framework from the fact that in tag hand-crafted grammar the grammar rules are grouped into tree families?, withone family for each subcategorization frame (transitive, in transitive, ditransitive, etc.), whereas automatically extracted tags do not currently group trees into families.
</prevsent>
<prevsent>to remedy the lack of coverage and maintenance problems linked to hand-crafted grammars, as well as the lack of generalization and linguistic adequacy of automatically extracted grammars, new syntactic levels of abstraction are defined.
</prevsent>
</prevsection>
<citsent citstr=" C02-1153 ">
in the context of tags, one can cite the notion of meta rules (becker, 2000), (prolo, 2002)<papid> C02-1153 </papid>8, and the notion of meta grammar (candito, 1996), (xia, 2001).</citsent>
<aftsection>
<nextsent>7this subdivision avoids an combinatoric explosion in the number of rules if the grammar was fully lexicalized 8for other meta rule based approaches based on the datr formalism, see (carroll et al, 2000) or (evans et al, 2000) 4.1 metarules.
</nextsent>
<nextsent>a meta rule works as pattern-matching tool on trees.
</nextsent>
<nextsent>it takes as input an elementary tree and outputs new, generally more complex, elementary tree.
</nextsent>
<nextsent>therefore, in order to create tag, one can start from one canonical elementary treefor each subcategorization frame and finite number of meta rules which model syntactic transformations (e.g. passive, wh-questions etc) and automatically generate full-size grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1871">
<title id=" W02-1507.xml">a classification of grammar development strategies </title>
<section> type grammars.  </section>
<citcontext>
<prevsection>
<prevsent>the same technique is used to acquire the valency alternation for each verb, and non canonical syntactic realizations of verb arguments(wh extractions etc...).
</prevsent>
<prevsent>this amounts to extracting hypertags?
</prevsent>
</prevsection>
<citsent citstr=" C00-1065 ">
(kinyon, 2000) <papid> C00-1065 </papid>from the treebank, transforming these hyper tags into meta grammar, and automatically generating tag from the mg.</citsent>
<aftsection>
<nextsent>an example of extraction may be seen on figure 4 :expose appears here in reduced-relative construction.
</nextsent>
<nextsent>however, from the trace occupying the canonical position of direct object, the program ret rives the correct subcategorization frame (i.e. tree family) for this verb.
</nextsent>
<nextsent>hence, just this occurence of expose correctly extracts the mg nodes from which both the canonical tree?
</nextsent>
<nextsent>and the reduced relative tree?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1872">
<title id=" W02-1812.xml">a word segmentation method with dynamic adapting to text using inductive learning </title>
<section> instruction.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P98-2206 ">
in nlp applications, word segmentation of non segmented language is very necessary initial stage(sun et al, 1998).<papid> P98-2206 </papid></citsent>
<aftsection>
<nextsent>in the other hands,with the development of the internet and popularization of computers, large amount of text information in different languages on the internet are increasing explosively, so it is necessary to develop common method to deal with multi-language(yamasita and matsumoto,2000).
</nextsent>
<nextsent>furthermore, the standard of word segmentation is dependent on user and destination of use(sproat et al, 1996), so that it is necessary that word segmentation can adapt users, can deal with multi languages.
</nextsent>
<nextsent>in our method, we extract recursively common character string that occur frequently in text and call it common part.
</nextsent>
<nextsent>when some common parts contain still same character strings, furthermore we extract the same character string as high dimensional common parts and the remain parts is called different parts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1873">
<title id=" W02-1032.xml">exploiting headword dependency and predictive clustering for language modeling </title>
<section> using clusters.  </section>
<citcontext>
<prevsection>
<prevsent>wi: function word 3.3 finding clusters: model estimation.
</prevsent>
<prevsent>in constructing clustering models, two factors were considered: how to find optimal clusters, and the optimal number of clusters.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
the clusters were found automatically by attempting to minimize perplexity (brown et al, 1992).<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>in particular, for predictive clustering models, we tried to minimize the perplexity of the training data of )|()|( 1 iiii wwpwwp ??
</nextsent>
<nextsent>letting be the size of the training data, we have ? = ? ?
</nextsent>
<nextsent>n iiii wwpwwp 1 1 )|()|( ? = ? ?
</nextsent>
<nextsent>?= i ii ii wp wwp wp wwp 1 1 1 )( )( )( )( ? = ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1874">
<title id=" W02-1032.xml">exploiting headword dependency and predictive clustering for language modeling </title>
<section> relation to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>first, the performance of slm is contingent on the amount and quality of syntactically annotated training data, but such data may not always be available.
</prevsent>
<prevsent>second, slms are very time-intensive, both in their training and use.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
charniak (2001) <papid> P01-1017 </papid>and roark (2001) <papid> J01-2004 </papid>also present language models based on syntactic dependency structure, which use lexicalized pcfgs that sum over the derivation probabilities.</citsent>
<aftsection>
<nextsent>they both report improvements in perplexity over chelba and jelinek (2000) on the wall street journal section of the penn treebank data, suggesting that syntactic structure can be further exploited for language modeling.
</nextsent>
<nextsent>the kind of linguistic structure used in our models is significantly more modest than that provided by parser-based models, yet offers practical benefits for realistic applications, as shown in the next section.
</nextsent>
<nextsent>the most common metric for evaluating language model is perplexity.
</nextsent>
<nextsent>perplexity can be roughly interpreted as the expected branching factor of the test document when presented to language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1875">
<title id=" W02-1032.xml">exploiting headword dependency and predictive clustering for language modeling </title>
<section> relation to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>first, the performance of slm is contingent on the amount and quality of syntactically annotated training data, but such data may not always be available.
</prevsent>
<prevsent>second, slms are very time-intensive, both in their training and use.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
charniak (2001) <papid> P01-1017 </papid>and roark (2001) <papid> J01-2004 </papid>also present language models based on syntactic dependency structure, which use lexicalized pcfgs that sum over the derivation probabilities.</citsent>
<aftsection>
<nextsent>they both report improvements in perplexity over chelba and jelinek (2000) on the wall street journal section of the penn treebank data, suggesting that syntactic structure can be further exploited for language modeling.
</nextsent>
<nextsent>the kind of linguistic structure used in our models is significantly more modest than that provided by parser-based models, yet offers practical benefits for realistic applications, as shown in the next section.
</nextsent>
<nextsent>the most common metric for evaluating language model is perplexity.
</nextsent>
<nextsent>perplexity can be roughly interpreted as the expected branching factor of the test document when presented to language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1876">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare the performance of the learned pcfg grammars and loglinear models over the same features.
</prevsent>
<prevsent>hand-built nlp grammars frequently have depth of linguistic representation and constraints not present in current treebanks, giving them potential importance for tasks requiring deeper processing.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
on the other hand, these manually built grammars need to solve the disambiguation problem to be practically usable.this paper presents work on the problem of probabilistic parse selection from among set of alternatives licensed by hand-built grammar in the context of the newly developed redwoods hpsg treebank (oepen et al, 2002).<papid> C02-2025 </papid></citsent>
<aftsection>
<nextsent>hpsg (head-drivenphrase structure grammar) is modern constraint based lexical ist (unification) grammar, described in pollard and sag (1994).the redwoods treebank makes available syntactic and semantic analyses of much greater depth than, for example, the penn treebank.
</nextsent>
<nextsent>therefore there are large number of features available that could be used by stochastic models for disambiguation.
</nextsent>
<nextsent>other researchers have worked on extracting features useful for disambiguation from unification grammar analyses and have built loglinear models a.k.a. stochastic unification based grammars (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000).<papid> P00-1061 </papid></nextsent>
<nextsent>herewe also use loglinear models to estimate conditional probabilities of sentence analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1878">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hpsg (head-drivenphrase structure grammar) is modern constraint based lexical ist (unification) grammar, described in pollard and sag (1994).the redwoods treebank makes available syntactic and semantic analyses of much greater depth than, for example, the penn treebank.
</prevsent>
<prevsent>therefore there are large number of features available that could be used by stochastic models for disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
other researchers have worked on extracting features useful for disambiguation from unification grammar analyses and have built loglinear models a.k.a. stochastic unification based grammars (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000).<papid> P00-1061 </papid></citsent>
<aftsection>
<nextsent>herewe also use loglinear models to estimate conditional probabilities of sentence analyses.
</nextsent>
<nextsent>since feature selection is almost prohibitive for these models, because of high computational costs, we usepcfg models to select features for loglinear models.
</nextsent>
<nextsent>even though this method may be expected to besuboptimal, it proves to be useful.
</nextsent>
<nextsent>we select features for pcfgs using decision trees and use the same features in conditional loglinear model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1879">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hpsg (head-drivenphrase structure grammar) is modern constraint based lexical ist (unification) grammar, described in pollard and sag (1994).the redwoods treebank makes available syntactic and semantic analyses of much greater depth than, for example, the penn treebank.
</prevsent>
<prevsent>therefore there are large number of features available that could be used by stochastic models for disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
other researchers have worked on extracting features useful for disambiguation from unification grammar analyses and have built loglinear models a.k.a. stochastic unification based grammars (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000).<papid> P00-1061 </papid></citsent>
<aftsection>
<nextsent>herewe also use loglinear models to estimate conditional probabilities of sentence analyses.
</nextsent>
<nextsent>since feature selection is almost prohibitive for these models, because of high computational costs, we usepcfg models to select features for loglinear models.
</nextsent>
<nextsent>even though this method may be expected to besuboptimal, it proves to be useful.
</nextsent>
<nextsent>we select features for pcfgs using decision trees and use the same features in conditional loglinear model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1880">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare the performance of the two models using equivalent features.
</prevsent>
<prevsent>our pcfg models are comparable to branching process models for parsing the penn treebank, inwhich the next state of the model depends on history of features.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in most recent parsing work the history consists of small number of manually selected features (charniak, 1997; collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>other researchers have proposed automatically selecting the conditioning information for various states of the model, thus potentially increasing greatly the space of possible features and selectively choosing the best predictors for each situation.
</nextsent>
<nextsent>decision trees have been applied for feature selection for statistical parsing models by magerman (1995) <papid> P95-1037 </papid>and haruno et al.</nextsent>
<nextsent>(1998).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1881">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in most recent parsing work the history consists of small number of manually selected features (charniak, 1997; collins, 1997).<papid> P97-1003 </papid></prevsent>
<prevsent>other researchers have proposed automatically selecting the conditioning information for various states of the model, thus potentially increasing greatly the space of possible features and selectively choosing the best predictors for each situation.</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
decision trees have been applied for feature selection for statistical parsing models by magerman (1995) <papid> P95-1037 </papid>and haruno et al.</citsent>
<aftsection>
<nextsent>(1998).
</nextsent>
<nextsent>another example of automatic feature selection for parsing is in the context of deterministic parsing model that chooses parse actions based on automatically induced decision structures over very rich feature set (hermjakob and mooney, 1997).<papid> P97-1062 </papid>our experiments in feature selection using decision trees suggest that single decision trees may notbe able to make optimal use of large number of relevant features.</nextsent>
<nextsent>this may be due to the greedy search procedures or to the fact that trees combine information from different features only through partitioning of the space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1882">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>decision trees have been applied for feature selection for statistical parsing models by magerman (1995) <papid> P95-1037 </papid>and haruno et al.</prevsent>
<prevsent>(1998).</prevsent>
</prevsection>
<citsent citstr=" P97-1062 ">
another example of automatic feature selection for parsing is in the context of deterministic parsing model that chooses parse actions based on automatically induced decision structures over very rich feature set (hermjakob and mooney, 1997).<papid> P97-1062 </papid>our experiments in feature selection using decision trees suggest that single decision trees may notbe able to make optimal use of large number of relevant features.</citsent>
<aftsection>
<nextsent>this may be due to the greedy search procedures or to the fact that trees combine information from different features only through partitioning of the space.
</nextsent>
<nextsent>for example they have difficulty in weighing evidence from different features without fully partitioning the space.
</nextsent>
<nextsent>a common approach to overcoming some of the problems with decision trees ? such as reducing their variance or increasing their representational power ? has been building ensembles of decision trees by, for example, bagging (breiman, 1996) or boosting (freund and schapire, 1996).
</nextsent>
<nextsent>haruno etal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1884">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> characteristics of the treebank and.  </section>
<citcontext>
<prevsection>
<prevsent>the current preliminary version contains 10,000 sentences of spoken dialog material drawn from the verb mobil project.the redwoods treebank makes available the entire hpsg signs for sentence analyses, but we have used in our experiments only small subsets of thisrepresentation.
</prevsent>
<prevsent>these are (i) derivation trees composed of identifiers of lexical items and constructions used to build the analysis, and (ii) semantic dependency trees which encode semantic head-to head relations.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
the redwoods treebank provides deeper semantics expressed in the minimum recur sion semantics formalism (copestake et al, 2001), <papid> P01-1019 </papid>but in the present experiments we have not explored this fully.the nodes in the derivation trees represent combining rule schemas of the hpsg grammar, and not imper hcomp hcomp bse_verb_infl let_v1 let us us bse_verb_infl see_v3 see figure 1: derivation tree for the sentence let us see phrasal categories of the standard sort.</citsent>
<aftsection>
<nextsent>the whole hpsg analyses can be recreated from the derivation trees, using the grammar.
</nextsent>
<nextsent>the pre terminals of the derivation trees are lexical labels.
</nextsent>
<nextsent>these aremuch finer grained than penn treebank pre terminals tags, and more akin to those used in tree adjoining grammar models (bangalore and joshi,1999).<papid> J99-2004 </papid></nextsent>
<nextsent>there are total of about 8, 000 lexical labels occurring in the treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1885">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> characteristics of the treebank and.  </section>
<citcontext>
<prevsection>
<prevsent>the whole hpsg analyses can be recreated from the derivation trees, using the grammar.
</prevsent>
<prevsent>the pre terminals of the derivation trees are lexical labels.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
these aremuch finer grained than penn treebank pre terminals tags, and more akin to those used in tree adjoining grammar models (bangalore and joshi,1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>there are total of about 8, 000 lexical labels occurring in the treebank.
</nextsent>
<nextsent>one might conjecture that super tagging approach could go longway toward parse disambiguation.
</nextsent>
<nextsent>however, an upper bound for such an approach for our corpus is below 55 percent parse selection accuracy, which is the accuracy of an oracle tagger that chooses at random among the parses having the correct tag sequence (oepen et al, 2002).<papid> C02-2025 </papid></nextsent>
<nextsent>the semantic dependency trees are labelled with relations most of which correspond to words in thesentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1889">
<title id=" W02-2030.xml">feature selection for a rich hpsg grammar using decision trees </title>
<section> models.  </section>
<citcontext>
<prevsection>
<prevsent>a simple pcfg is reasonably effective to the extent that important dependencies are jointly expressed in local tree, as is mostly the case for the much flatter representations used in the penn treebank.
</prevsent>
<prevsent>here, this is not the case, and the inclusion of ancestor nodes in the history makes necessary information more often local in our models.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
grandparent annotation was used previously by charniak and carroll (1994) and johnson (1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>no. name example 0 node label hcomp.
</nextsent>
<nextsent>1 parent node label hcomp.
</nextsent>
<nextsent>2 node direction left.
</nextsent>
<nextsent>3 parent node direction none.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1893">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>among these techniques, example-based (e.g.
</prevsent>
<prevsent>(brown, 1997)) and statistical (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
(brown et al,1990; <papid> J90-2002 </papid>brown et al, 1993)) <papid> J93-2003 </papid>are best known and stud ied.</citsent>
<aftsection>
<nextsent>they aim at extracting information from bilingual text and building translation systems automatically.
</nextsent>
<nextsent>this empirical approach overcomes the development bottleneck that traditional transfer- and interlingua-based approaches face.
</nextsent>
<nextsent>what used to take years of human development time can now be achieved in fraction of the time with similar accuracy.
</nextsent>
<nextsent>however, in studying such empirical approaches and the output of the resulting systems,there have been calls for the re-incorporation of more linguistic intuition and/or knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1894">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>among these techniques, example-based (e.g.
</prevsent>
<prevsent>(brown, 1997)) and statistical (e.g.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
(brown et al,1990; <papid> J90-2002 </papid>brown et al, 1993)) <papid> J93-2003 </papid>are best known and stud ied.</citsent>
<aftsection>
<nextsent>they aim at extracting information from bilingual text and building translation systems automatically.
</nextsent>
<nextsent>this empirical approach overcomes the development bottleneck that traditional transfer- and interlingua-based approaches face.
</nextsent>
<nextsent>what used to take years of human development time can now be achieved in fraction of the time with similar accuracy.
</nextsent>
<nextsent>however, in studying such empirical approaches and the output of the resulting systems,there have been calls for the re-incorporation of more linguistic intuition and/or knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1895">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>what used to take years of human development time can now be achieved in fraction of the time with similar accuracy.
</prevsent>
<prevsent>however, in studying such empirical approaches and the output of the resulting systems,there have been calls for the re-incorporation of more linguistic intuition and/or knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
one notable example in this context is (yamada and knight, 2001; <papid> P01-1067 </papid>yamada and knight, 2002), <papid> P02-1039 </papid>who introduce syntactic knowledge into their statistical translation model.</citsent>
<aftsection>
<nextsent>our approach goes in similar direction.
</nextsent>
<nextsent>the avenue system (carbonell et al, 2002) infers syntactic transfer rules similar to the ones human grammar writer would produce.
</nextsent>
<nextsent>the training data is bilingual text, and learning is facilitated by the usageof linguistic information (e.g. parses, feature information).
</nextsent>
<nextsent>we focus primarily on resource-rich/resource poor situations, i.e. on language pairs where for one of the languages resources such as parser are available, but not for the other language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1896">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>what used to take years of human development time can now be achieved in fraction of the time with similar accuracy.
</prevsent>
<prevsent>however, in studying such empirical approaches and the output of the resulting systems,there have been calls for the re-incorporation of more linguistic intuition and/or knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
one notable example in this context is (yamada and knight, 2001; <papid> P01-1067 </papid>yamada and knight, 2002), <papid> P02-1039 </papid>who introduce syntactic knowledge into their statistical translation model.</citsent>
<aftsection>
<nextsent>our approach goes in similar direction.
</nextsent>
<nextsent>the avenue system (carbonell et al, 2002) infers syntactic transfer rules similar to the ones human grammar writer would produce.
</nextsent>
<nextsent>the training data is bilingual text, and learning is facilitated by the usageof linguistic information (e.g. parses, feature information).
</nextsent>
<nextsent>we focus primarily on resource-rich/resource poor situations, i.e. on language pairs where for one of the languages resources such as parser are available, but not for the other language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1897">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the process is fully automatic, thus eliminating the need for human expertise in given language.
</prevsent>
<prevsent>our main idea is based on using bilingual corpus between english and target language.in our experiments, we report results for french as the target language.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we annotate the english side of the corpus with pos tags, using the brill tagger (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>we further utilize statistical bilingual (english   french) dictionary in order to find candidates translations for particular english words.
</nextsent>
<nextsent>our work falls in line with the bilingual analysis described in (yarowsky and ngai, 2001;<papid> N01-1026 </papid>yarowsky et al, 2001).<papid> H01-1035 </papid></nextsent>
<nextsent>while we use different approach and tackle different problem, the major reasoning steps are the same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1898">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>we annotate the english side of the corpus with pos tags, using the brill tagger (brill, 1995).<papid> J95-4004 </papid></prevsent>
<prevsent>we further utilize statistical bilingual (english   french) dictionary in order to find candidates translations for particular english words.</prevsent>
</prevsection>
<citsent citstr=" N01-1026 ">
our work falls in line with the bilingual analysis described in (yarowsky and ngai, 2001;<papid> N01-1026 </papid>yarowsky et al, 2001).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>while we use different approach and tackle different problem, the major reasoning steps are the same.
</nextsent>
<nextsent>(yarowsky and ngai, 2001) <papid> N01-1026 </papid>aim at pos tagging target language corpus using english pos tags as well as estimation of lexical priors (i.e. what pos tags can word have with what probability) and tag sequence model.</nextsent>
<nextsent>the authors further report results on matching inflected verb forms in the target language with infinitive verbs, as well as on noun phrase chunking.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1899">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> introduction and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>we annotate the english side of the corpus with pos tags, using the brill tagger (brill, 1995).<papid> J95-4004 </papid></prevsent>
<prevsent>we further utilize statistical bilingual (english   french) dictionary in order to find candidates translations for particular english words.</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
our work falls in line with the bilingual analysis described in (yarowsky and ngai, 2001;<papid> N01-1026 </papid>yarowsky et al, 2001).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>while we use different approach and tackle different problem, the major reasoning steps are the same.
</nextsent>
<nextsent>(yarowsky and ngai, 2001) <papid> N01-1026 </papid>aim at pos tagging target language corpus using english pos tags as well as estimation of lexical priors (i.e. what pos tags can word have with what probability) and tag sequence model.</nextsent>
<nextsent>the authors further report results on matching inflected verb forms in the target language with infinitive verbs, as well as on noun phrase chunking.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1913">
<title id=" W03-0414.xml">using smart bilingual projection to feature tag a monolingual dictionary </title>
<section> morpheme role assignment.  </section>
<citcontext>
<prevsection>
<prevsent>another strength of our approach is that we make no assumption about the contiguity of the morphemes.
</prevsent>
<prevsent>related work on morphology generally makes this assumption (e.g.
</prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
(goldsmith, 1995)), with the notable exception of (schone and jurafsky, 2001).<papid> N01-1024 </papid></citsent>
<aftsection>
<nextsent>while in the current experiments the non-contiguity possibility is not reflected in the results, it can become important when applying the algorithm to other languages such as german.
</nextsent>
<nextsent>we begin by conjecturing that most morphemes willnot be longer than four characters, and learn only patterns up to that length.
</nextsent>
<nextsent>our algorithm starts by extracting all patterns in the training data of up to four characters, however restricting its attention to the dimensions in       . if      contains more than 4 dimensions, the algorithm works only with those 4 dimensions that had the greatest impact.
</nextsent>
<nextsent>all 1, 2, 3, and 4 character combinations that occur in the training data are listed together with how often they occur.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1914">
<title id=" W02-0808.xml">sense discrimination with parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this idea would seem to provide an answer, at least in part, to the problem of determining different senses of word: intuitively, one assumes that if another language lexicalizes word in two or more ways, there must be conceptual motivation.
</prevsent>
<prevsent>if we look at enough languages, we would be likely to find the significant lexical differences that delimit different senses of word.
</prevsent>
</prevsection>
<citsent citstr=" P91-1017 ">
several studies have used parallel texts for wsd (e.g., gale et al, 1993; dagan et al, 1991; <papid> P91-1017 </papid>dagan and itai, 1994) <papid> J94-4003 </papid>as well as to define semantic properties of and relations among lexemes (dyvik, 1998).</citsent>
<aftsection>
<nextsent>more recently, two studies have examined the use of cross-lingual lexicalization as criterion for validating sense distinctions: ide (1999) used translation equivalents derived from aligned versions of orwells nineteen eighty-four among five languages from four different languages families, while resnik and yarowsky (2000) used translations generated by native speakers presented with isolated sentences in english.
</nextsent>
<nextsent>in both of these studies, translation information was used to validate sense distinctions provided in lexicons such as wordnet (miller et al, 1990).
</nextsent>
<nextsent>although the results are promising, especially for coarse grained sense distinctions, they rest on the acceptance of previously established set of senses.
</nextsent>
<nextsent>given the substantial divergences among sense distinctions in dictionaries and lexicons, together with the ongoing debate within the wsd community concerning which sense distinctions, if any, are appropriate for language processing applications, fitting cross-linguistic information to pre-established sense inventories may not be the optimal approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1915">
<title id=" W02-0808.xml">sense discrimination with parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this idea would seem to provide an answer, at least in part, to the problem of determining different senses of word: intuitively, one assumes that if another language lexicalizes word in two or more ways, there must be conceptual motivation.
</prevsent>
<prevsent>if we look at enough languages, we would be likely to find the significant lexical differences that delimit different senses of word.
</prevsent>
</prevsection>
<citsent citstr=" J94-4003 ">
several studies have used parallel texts for wsd (e.g., gale et al, 1993; dagan et al, 1991; <papid> P91-1017 </papid>dagan and itai, 1994) <papid> J94-4003 </papid>as well as to define semantic properties of and relations among lexemes (dyvik, 1998).</citsent>
<aftsection>
<nextsent>more recently, two studies have examined the use of cross-lingual lexicalization as criterion for validating sense distinctions: ide (1999) used translation equivalents derived from aligned versions of orwells nineteen eighty-four among five languages from four different languages families, while resnik and yarowsky (2000) used translations generated by native speakers presented with isolated sentences in english.
</nextsent>
<nextsent>in both of these studies, translation information was used to validate sense distinctions provided in lexicons such as wordnet (miller et al, 1990).
</nextsent>
<nextsent>although the results are promising, especially for coarse grained sense distinctions, they rest on the acceptance of previously established set of senses.
</nextsent>
<nextsent>given the substantial divergences among sense distinctions in dictionaries and lexicons, together with the ongoing debate within the wsd community concerning which sense distinctions, if any, are appropriate for language processing applications, fitting cross-linguistic information to pre-established sense inventories may not be the optimal approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1916">
<title id=" W02-0808.xml">sense discrimination with parallel corpora </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>a mirror; usually ladies  dressing mirror 6.
</prevsent>
<prevsent>glassware collectively;  she collected old glass  figure 2 : wordnet 1.6 senses for glass (noun) the results of the first experiment are summarized in table 1, which shows the percentage of agreement between the cluster algorithm and each annotator, between the two annotators, and for the algorithm and both annotators taken together.
</prevsent>
</prevsection>
<citsent citstr=" W99-0502 ">
4 the percentages are similar to those reported in earlier work; for example, ng et al (1999) <papid> W99-0502 </papid>achieved raw percentage score of 58% agreement among annotators tagging nouns with wordnet 1.6 senses.</citsent>
<aftsection>
<nextsent>cluster/annotator 1 66.7% cluster/annotator 2 63.6% annotator 1/annotator 2 76.3% cluster/annotator 1/ annotator 2 53.4% table 1 : levels of agreement 2.2 second experiment.
</nextsent>
<nextsent>comparison of sense differentiation achieved using translation equivalents, as determined by the clustering algorithm, with those assigned by human annotators suggests that use of translation equivalents for word sense tagging and disambiguation is worth pursuing.
</nextsent>
<nextsent>agreement levels are comparable to (and in some cases higher than) those obtained in earlier studies tagging with wordnet senses.
</nextsent>
<nextsent>furthermore, the pairwise difference in agreement between the human annotators and the annotators and the clustering algorithm is only 10-13%, which is also similar to scores obtained in other studies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1917">
<title id=" W02-0808.xml">sense discrimination with parallel corpora </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>vs. hand?, boot?, glass?, girl?, etc.).
</prevsent>
<prevsent>we chose nouns that occur minimum of 10 times in the corpus, have no undetermined translations and atleast five different translations in the six non english languages, and have the log likelihood score of at least 18; that is: ll(t , s ) = ? ?
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
= = 2 1 ij 2 1i n*2 * j**i **ij n*n n*n log ? 18 where ij stands for the number of times t and s have been seen together in aligned sentences, i* and *j stand for the number occurrences of t and s, respectively, and ** represents the total 4 we computed raw percentages only; common measures of annotator agreement such as the kappa statistic (carletta,1996) <papid> J96-2004 </papid>proved to be inappropriate for our two-category (yes no?) classification scheme.</citsent>
<aftsection>
<nextsent>_____|-  (1) |-----| |-  (1) | |_____|---  (1) | |___|-  (1) | |-  (1) | |---  (1) |----| | _|-  (1) | | | |-| |-  (1) | | |---| |-| |-  (1) | | | | |-| |-  (1) | |-----| | |-| |-  (1) |--| | |---| |-  (1) | | | |-  (1) | | |___|---  (6) | | |___|-----  (1) | | |-----  (1) | | _____|-----  (1) -| |----| |-----  (5) | |-----  (4) | |---  (2) | |---| _|-  (2) | | | |-| |-  (2) | | |---| |-  (2) |--| |-  (2) | |-----  (2) | | ___|-----  (2) |---| |----| |-----  (2) | | | _|-  (2) | | |---| |-  (2) |-----| |-  (2) | ____|-  (3) |----| |-  (2) | _|-  (2) |----| |-  (2) |-  (2) number of potential translation equivalents in the parallel corpus.
</nextsent>
<nextsent>the ll score is set at maximum value to ensure high precision for the extracted translation equivalents, which minimizes sense clustering errors due to incorrect word alignment.
</nextsent>
<nextsent>table 2 summarizes the data.
</nextsent>
<nextsent>no. of words 76 no.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1918">
<title id=" W02-0808.xml">sense discrimination with parallel corpora </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>we also experimented with eliminating the data for non-contributing?
</prevsent>
<prevsent>languages (i.e., languages for which there is only one translation for the target word); this was ultimately abandoned because it worsened results by amplifying the effect of synonymous translations in other languages.
</prevsent>
</prevsection>
<citsent citstr=" W99-0627 ">
finally, we compared the use of weighted vs. unweighted clustering algorithms (see, e.g., yarowsky and florian, 1999) <papid> W99-0627 </papid>and determined that results were improved using weighted clustering.</citsent>
<aftsection>
<nextsent>the clusters produced by each pair of classifiers (human or machine) were mapped for maximum overlap; differences were considered as divergences.
</nextsent>
<nextsent>the agreement between two different classifications was computed as the number of common occurrences in the corresponding clusters of the two classifications divided by the total number of the occurrences of the target word.
</nextsent>
<nextsent>for example, the word movement occurs 40 times in the corpus; both the gold standard?
</nextsent>
<nextsent>and the algorithm identified four clusters, but the distribution of the 40 occurrences was substantially different, as summarized in table 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1919">
<title id=" W02-0808.xml">sense discrimination with parallel corpora </title>
<section> discussion and further work.  </section>
<citcontext>
<prevsection>
<prevsent>a by-product of applying our method is that once words in text in one language are tagged using this method, different senses of the corresponding translations in the parallel texts are also identified, potentially providing source of information for use in other language processing tasks and for building resources in the parallel languages (e.g., wordnets for the eastern european languages in our study).
</prevsent>
<prevsent>in addition, if different senses of target words are identified in parallel texts, contextual information for different senses of word can be gathered for use in disambiguating other, unrelated texts.
</prevsent>
</prevsection>
<citsent citstr=" C94-1097 ">
the greatest obstacle to application of this approach is, obviously, the lack of parallel corpora: existing freely available parallel corpora including several languages are typically small (e.g., the orwell), domain dependent (e.g. the multext journal of the commission (joc) corpus; ide and vronis, 1994), <papid> C94-1097 </papid>and/or represent highly stylized language (e.g. the bible; resnik et al, 1999).</citsent>
<aftsection>
<nextsent>appropriate parallel data including asian languages is virtually non-existent.
</nextsent>
<nextsent>given that our method applies only to words for which different senses are lexicalized differently in at least one other language, its broad application depends on the future availability of large-scale parallel corpora including variety of language types.
</nextsent>
<nextsent>many studies have pointed out that coarser-grained sense distinctions can be assigned more reliably by human annotators than finer distinctions such as those in wordnet.
</nextsent>
<nextsent>in our study, the granularity of the sense distinctions was largely ignored, except insofar as we attempted to cut off the number of clusters produced by the algorithm at value similar to the number identified by the annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1920">
<title id=" W02-2007.xml">language independent ner using a unified model of internal and contextual evidence </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>f-measure exceeds 77 in spanish and 72 in dutch.
</prevsent>
<prevsent>our aim has been to build maximally language independent system for named-entity recognition using minimal supervision or knowledge of the source language.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
the core model utilized, extended and evaluated here is based on cucerzan and yarowsky (1999).<papid> W99-0612 </papid></citsent>
<aftsection>
<nextsent>it assumes that only an entity exemplar list is provided as bootstrapping seed set.
</nextsent>
<nextsent>for the particular task of conll-2002, the seed entities are extracted from the provided annotated corpus.
</nextsent>
<nextsent>as consequence, the seed examples maybe ambiguous and the system must therefore handle seeds with probability distribution over entity classes rather than unambiguous seeds.
</nextsent>
<nextsent>another consequence is that this approach of extracting only the entity seeds from the annotated text does not usethe full potential of the training data, ignoring contextual information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1922">
<title id=" W02-2007.xml">language independent ner using a unified model of internal and contextual evidence </title>
<section> one sense per discourse.  </section>
<citcontext>
<prevsection>
<prevsent>but, as noted by katz (1996), newly introduced entity will be repeated, if not for breaking the monotonous effect of pronoun use, then for g g g g g h h h h i i i i i i i i j j j j j j j j k k k k k k k k k k k k k k k k k k k k k l l l l l l l l l l l l l l l l l l l l m m m m n n n n topic boundary topic boundary topic boundary soft boundary topic boundary topic boundary soft boundary entity candidate other occurences of word position in the corpus posit io na s im ila ri tyfigure 3: using contextual clues from all instances of an entity candidate in the corpus.
</prevsent>
<prevsent>each instance is depicted as disc with the diameter representing the confidence of the classification of that instance using word-internal and local contextual information.emphasis and clarity?.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
we use this property in conjunction with the one sense per discourse tendency noted by gale et al (1992).<papid> H92-1045 </papid></citsent>
<aftsection>
<nextsent>the later paradigm is not directly usable when analyzing large corpus in which there are no document boundaries, like theone provided for spanish.
</nextsent>
<nextsent>therefore, segmentation process needs to be employed, so that all the instances of name in segment have high probability of belonging to the same class.
</nextsent>
<nextsent>our approach is to consider soft?
</nextsent>
<nextsent>segmentation, which is word dependent and does not compute topic/documentboundaries but regions for which the contextual information for all instances of word can be used jointly when making decision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1923">
<title id=" W02-2007.xml">language independent ner using a unified model of internal and contextual evidence </title>
<section> one sense per discourse.  </section>
<citcontext>
<prevsection>
<prevsent>our approach is to consider soft?
</prevsent>
<prevsent>segmentation, which is word dependent and does not compute topic/documentboundaries but regions for which the contextual information for all instances of word can be used jointly when making decision.
</prevsent>
</prevsection>
<citsent citstr=" W97-0305 ">
this is view edas an alternative to the classical topic segmentation approach and can be used in conjunction with language-independent segmentation system (figure 3) like the one presented by richmond et al (1997).<papid> W97-0305 </papid>after estimating the class probability distributions for all instances of entity candidates in the corpus, re-estimation step is employed.</citsent>
<aftsection>
<nextsent>the probability of an entity class p given an entity candidate at position rsutv is re-computed using the formula: xzy[ p]\ q_^`rsutv acbed fhgjikml don x$[ p]\ qp^`rqst a0r ts7t [ rsutv ^`rsut aurovswyx [ qp^`rsut a (2) where rsut ^mzzz^`rsut iare the positions of all instances of in the corpus, t5s is the positional similarity, encoding the physical distance and topic (if topic or document boundary information exists), conf is the classification confidence of each instance (inverse proportional to the the x$[{|} t~\ qp^`rsut a ,  is normalization factor.
</nextsent>
<nextsent>there are two major alternatives for handlingmultiple-word entities.
</nextsent>
<nextsent>a first approach is to tok enize the text and classify each individual word as being or not part of an entity, process followed by an entity as semblance algorithm.
</nextsent>
<nextsent>a second alternative is_b_candidate is_i_candidate is_e_candidate figure 4: the structure of an entity candidate represented as an automaton with two final states is to consider chunking algorithm that identifies entity candidates and classify each of the chunks as person, location, organization, miscellaneous, or non-entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1924">
<title id=" W02-2007.xml">language independent ner using a unified model of internal and contextual evidence </title>
<section> entity identification / multiple-word entities.  </section>
<citcontext>
<prevsection>
<prevsent>a string is considered an entity candidate if it has the structure shown in figure 4.
</prevsent>
<prevsent>an extension of the system also makes use ofpart-of-speech (pos) tags.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
we used the provided pos annotation in dutch (daelemans et al, 1996) <papid> W96-0102 </papid>and minimally supervised tagger (yarowsky and cucerzan, 2002) for spanish to restrict the space of words accepted by the discriminators (e.g. is_b_candidate rejects prepositions, conjunctions, pronouns, adverbs, and those determiners that are the first word in the sentence).</citsent>
<aftsection>
<nextsent>the core algorithm can be divided into eight stages,which are summarized in figure 5.
</nextsent>
<nextsent>the bootstrapping stage (5) uses the initial or current entity assignments to estimate the class conditional distributions for both entities and contexts along their trie paths, and then re-estimates the distributions of the contexts/entity-candidates to which they are linked, recursively, until all accessible nodes are reached, as presented in cucerzan and yarowsky (1999).<papid> W99-0612 </papid></nextsent>
<nextsent>1 extract the entity (and context) seed sets from the annotated data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1927">
<title id=" W02-1208.xml">automatic word spacing using hidden markov model for refining korean text corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>especially, it is much more confused in the case of having no in uence on understanding the meaning of sentence.
</prevsent>
<prevsent>in this paper, we propose word spacing model 1 using an hmm.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
hmm is widely used statistical model to solve various nlp problems such as pos tagging(charniak et al, 1993; merialdo, 1994; <papid> J94-2001 </papid>kim et al, 1998a; lee, 1999).we regard the word spacing problem as classi cation problem such as the pos tagging prob lem.</citsent>
<aftsection>
<nextsent>when using an hmm for automatic word spacing task, raw texts can be used as training 1strictly speaking, our model described here is an eo jeol spacing model rather than word spacing model because spacing unit of korean is eojeol.
</nextsent>
<nextsent>but we in this paper do not distinguish between eojeol and word for convenience.
</nextsent>
<nextsent>therefore, we use the term \word  as word, spacing unit in english.
</nextsent>
<nextsent>      eojeol word morpheme proper noun : person name post position noun : story noun : book post position verb : read pre final ending ending figure 1: constitution of the sentence \o^=??  sl???`?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1928">
<title id=" W03-0101.xml">experiments with geographic knowledge for information extraction </title>
<section> the kim platform.  </section>
<citcontext>
<prevsection>
<prevsent>the kim platform provides novel knowledge and information management (kim1) infrastructure and services for automatic semantic annotation, indexing andre trieval of unstructured and semi-structured content.
</prevsent>
<prevsent>the ontologies and knowledge bases are kept in semantic 1kim, see http://www.ontotext.com/kim figure 1: kim platform repositories based on cutting edge semantic web technology and standards, including rdf(s) repositories2, ontology middleware3 (kiryakov et al 2002) and reason ing4.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
it provides mature infrastructure for scalable andcustomizable information extraction as well as annotation and document management, based on gate (cun ningham et al, 2002).<papid> P02-1022 </papid></citsent>
<aftsection>
<nextsent>gate, general architecture for text engineering, is developed by the sheffield nlp group and has been used in many language processingprojects; in particular for information extraction in variety of languages (maynard and cunningham, 2003).
</nextsent>
<nextsent>an essential idea for kim is the semantic (or entity)annotation, depicted on figure 1.
</nextsent>
<nextsent>it can be seen as classical named-entity recognition and annotation process.
</nextsent>
<nextsent>however, in contrast to most of the existing ie system, kim provides for each entity reference in the text (i) pointer (uri) to the most specific class in the ontology and (ii) pointer to the specific instance in the knowledge base.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1929">
<title id=" W02-0811.xml">combining heterogeneous classifiers for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we present an analysis of the combination, examining how ensemble performance depends on error independence and task difficulty.
</prevsent>
<prevsent>the problem of supervised word sense disambiguation (wsd) has been approached using many different classification algorithms, including naive-bayes, decision trees, decision lists, and memory-basedlearners.
</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
while it is unquestionable that certain algorithms are better suited to the wsd problem than others (for comparison, see mooney (1996)), <papid> W96-0208 </papid>itseems that, given similar input features, various algorithms exhibit roughly similar accuracies.1 this was supported by the senseval-2 results, where athis paper is based on work supported in part by the national science foundation under grants iis-0085896 and iis 9982226, by an nsf graduate fellowship, and by the research collaboration between ntt communication science laboratories, nippon telegraph and telephone corporation and csli, stanford university.1in fact, we have observed that differences between implementations of single classifier type, such as smoothing or window size, impacted accuracy far more than the choice of classification algorithm.</citsent>
<aftsection>
<nextsent>large fraction of systems had scores clustered in fairly narrow region (senseval-2, 2001).
</nextsent>
<nextsent>we began building our system with 23 supervised wsd systems, each submitted by student taking the natural language processing course (cs224n) at stanford university in spring 2000.
</nextsent>
<nextsent>students were free to implement whatever wsd method they chose.
</nextsent>
<nextsent>while most implemented variants of naive-bayes,others implemented range of other methods, including n-gram models, vector space models, and memory-based learners.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1930">
<title id=" W02-0811.xml">combining heterogeneous classifiers for word sense disambiguation </title>
<section> the system.  </section>
<citcontext>
<prevsection>
<prevsent>, sk) also maximizes the vote: v(s) = ? i?(si = s) the indicators ? are true for exactly one sense, and correspond to the simple i defined above.4 the sense with the largest vote v(s) will be the sense with the highest posterior probability p(s|s1, . . .
</prevsent>
<prevsent>sk) and will be chosen.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
for the maximum entropy classifier, we estimate the weights by maximizing the likelihood of held out set, using the standard iis algorithm (berger et al., 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>for both weighted schemes, we found that stopping the iterative procedures before convergence gave better results.
</nextsent>
<nextsent>iis was halted after 50 rounds, while em was halted after single round.
</nextsent>
<nextsent>both methods were initial ized to uniform starting weights.
</nextsent>
<nextsent>more importantly than changing the exact weight estimates, moving from method to method triggers broad qualitative changes in what kind of weights are allowed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1931">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>subjective language has been previously studied in fields such as linguistics, literary theory, psychology, and content analysis.
</prevsent>
<prevsent>some manually-developed knowledge resources exist, but there is no comprehensive dictionary of subjective language.
</prevsent>
</prevsection>
<citsent citstr=" W02-1028 ">
meta-bootstrapping (riloff and jones, 1999) andbasilisk (thelen and riloff, 2002) <papid> W02-1028 </papid>are bootstrapping algorithms that use automatically generated extraction patterns to identify words belonging to semantic cate gory.</citsent>
<aftsection>
<nextsent>we hypothesized that extraction patterns could also identify subjective words.
</nextsent>
<nextsent>for example, the pattern expressed  direct object ?
</nextsent>
<nextsent>often extracts subjective nouns, such as concern?, hope?, and support?.
</nextsent>
<nextsent>furthermore, these bootstrapping algorithms require onlya handful of seed words and unannotated texts for train ing; no annotated data is needed at all.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1933">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we use the meta-bootstrapping and basilisk algorithms to learn lists of subjective nouns from large collection of unannotated texts.
</prevsent>
<prevsent>then we train subjectivity classifier on small set of annotated data, using the subjective nouns as features along with some other previously identified subjectivity features.
</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
our experimental results show that the subjectivity classifier performs well (77% recall with 81% precision) and that the learned nouns improve upon previous state-of-the-art subjectivity results (wiebe et al, 1999).<papid> P99-1032 </papid></citsent>
<aftsection>
<nextsent>2.1 the annotation scheme.
</nextsent>
<nextsent>in 2002, an annotation scheme was developed for u.s. government-sponsored project with ateam of 10 researchers (the annotation instructions and project reports are available on the web at http://www.cs.pitt.edu/wiebe/pubs/ardasummer02/).
</nextsent>
<nextsent>edmonton, may-june 2003 held at hlt-naacl 2003 , pp.
</nextsent>
<nextsent>25-32 proceeings of the seventh conll conference the scheme was inspired by work in linguistics and literary theory on subjectivity, which focuses on how opinions, emotions, etc. are expressed linguistically in context (banfield, 1982).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1940">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> creating subjectivity classifiers.  </section>
<citcontext>
<prevsection>
<prevsent>wbo also includes binary feature for each of the following: the presence in the sentence of pronoun, an adjective, cardinal number, modal other than will, and an adverb other than not.
</prevsent>
<prevsent>we also added manually-developed features found byother researchers.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
we created 14 feature sets representing some classes from (levin, 1993; ballmer and brennenstuhl, 1981), some framenet lemmas with frame element experiencer (baker et al, 1998), <papid> P98-1013 </papid>adjectives manually annotated for polarity (hatzivassiloglou and mckeown, 1997), <papid> P97-1023 </papid>and some subjectivity clues listed in (wiebe, 1990).</citsent>
<aftsection>
<nextsent>we represented each set as three-valued feature based on the presence of 0, 1, or ? 2 members of the set.
</nextsent>
<nextsent>we will refer to these as the manual features.
</nextsent>
<nextsent>4.3 discourse features.
</nextsent>
<nextsent>we created discourse features to capture the density ofclues in the text surrounding sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1941">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> creating subjectivity classifiers.  </section>
<citcontext>
<prevsection>
<prevsent>wbo also includes binary feature for each of the following: the presence in the sentence of pronoun, an adjective, cardinal number, modal other than will, and an adverb other than not.
</prevsent>
<prevsent>we also added manually-developed features found byother researchers.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
we created 14 feature sets representing some classes from (levin, 1993; ballmer and brennenstuhl, 1981), some framenet lemmas with frame element experiencer (baker et al, 1998), <papid> P98-1013 </papid>adjectives manually annotated for polarity (hatzivassiloglou and mckeown, 1997), <papid> P97-1023 </papid>and some subjectivity clues listed in (wiebe, 1990).</citsent>
<aftsection>
<nextsent>we represented each set as three-valued feature based on the presence of 0, 1, or ? 2 members of the set.
</nextsent>
<nextsent>we will refer to these as the manual features.
</nextsent>
<nextsent>4.3 discourse features.
</nextsent>
<nextsent>we created discourse features to capture the density ofclues in the text surrounding sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1945">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> creating subjectivity classifiers.  </section>
<citcontext>
<prevsection>
<prevsent>row (2) is naive bayes classifier that uses the wbo features, which performed well in prior research on sentence-level subjectivity classification (wiebe et al, 1999).<papid> P99-1032 </papid></prevsent>
<prevsent>row (1)shows naive bayes classifier that uses unigram bag-of words features, with one binary feature for the absence or presence in the sentence of each word that appeared during training.</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
pang et al (2002) <papid> W02-1011 </papid>reported that similar experiment produced their best results on related classification task.</citsent>
<aftsection>
<nextsent>the difference inaccuracy between rows (1) and (2) is not statistically significant (bag-of-words higher precision is balanced by wbos higher recall).
</nextsent>
<nextsent>next, we trained naive bayes classifier using only the subjnoun features.
</nextsent>
<nextsent>this classifier achieved good precision (77%) but only moderate recall (64%).
</nextsent>
<nextsent>upon further inspection, we discovered that the subjective nouns are good subjectivity indicators when they appear, but not every subjective sentence contains one of them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1946">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this approach could support applications for which precision is paramount.
</prevsent>
<prevsent>several types of research have involved document-levelsubjectivity classification.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
some work identifies inflammatory texts (e.g., (spertus, 1997)) or classifies reviews as positive or negative ((turney, 2002; <papid> P02-1053 </papid>pang et al, 2002)).<papid> W02-1011 </papid>tongs system (tong, 2001) generates sentiment timelines, tracking online discussions and creating graphs of positive and negative opinion messages over time.</citsent>
<aftsection>
<nextsent>research in genre classification may include recognition of subjective genres such as editorials (e.g., (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al, 1997; <papid> P97-1005 </papid>wiebe et al, 2001)).</nextsent>
<nextsent>in contrast, our work classifies individual sentences, as does the research in (wiebe et al, 1999).<papid> P99-1032 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1948">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several types of research have involved document-levelsubjectivity classification.
</prevsent>
<prevsent>some work identifies inflammatory texts (e.g., (spertus, 1997)) or classifies reviews as positive or negative ((turney, 2002; <papid> P02-1053 </papid>pang et al, 2002)).<papid> W02-1011 </papid>tongs system (tong, 2001) generates sentiment timelines, tracking online discussions and creating graphs of positive and negative opinion messages over time.</prevsent>
</prevsection>
<citsent citstr=" C94-2174 ">
research in genre classification may include recognition of subjective genres such as editorials (e.g., (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al, 1997; <papid> P97-1005 </papid>wiebe et al, 2001)).</citsent>
<aftsection>
<nextsent>in contrast, our work classifies individual sentences, as does the research in (wiebe et al, 1999).<papid> P99-1032 </papid></nextsent>
<nextsent>sentence-levelsubjectivity classification is useful because most documents contain mix of subjective and objective sen tences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1949">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several types of research have involved document-levelsubjectivity classification.
</prevsent>
<prevsent>some work identifies inflammatory texts (e.g., (spertus, 1997)) or classifies reviews as positive or negative ((turney, 2002; <papid> P02-1053 </papid>pang et al, 2002)).<papid> W02-1011 </papid>tongs system (tong, 2001) generates sentiment timelines, tracking online discussions and creating graphs of positive and negative opinion messages over time.</prevsent>
</prevsection>
<citsent citstr=" P97-1005 ">
research in genre classification may include recognition of subjective genres such as editorials (e.g., (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al, 1997; <papid> P97-1005 </papid>wiebe et al, 2001)).</citsent>
<aftsection>
<nextsent>in contrast, our work classifies individual sentences, as does the research in (wiebe et al, 1999).<papid> P99-1032 </papid></nextsent>
<nextsent>sentence-levelsubjectivity classification is useful because most documents contain mix of subjective and objective sen tences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1960">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(turney, 2002) <papid> P02-1053 </papid>used patterns representing part-of-speech sequences, (hatzivassiloglou and mckeown, 1997) <papid> P97-1023 </papid>recognized adjectival phrases, and (wiebe et al, 2001) learned n-grams.</prevsent>
<prevsent>the extraction patterns used in our research are linguistically richer patterns, requiring shallow parsing and syntactic role assign ment.</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
in recent years several techniques have been developed for semantic lexicon creation (e.g., (hearst, 1992; <papid> C92-2082 </papid>riloffand shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998; <papid> P98-2182 </papid>caraballo, 1999)).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>semantic word learning is different from subjective word learning, but we have shown that meta bootstrapping and basilisk could be successfully applied to subjectivity learning.
</nextsent>
<nextsent>perhaps some of these other methods could also be used to learn subjective words.
</nextsent>
<nextsent>this research produced interesting insights as well as performance results.
</nextsent>
<nextsent>first, we demonstrated that weakly supervised bootstrapping techniques can learn subjective terms from unannotated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1961">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(turney, 2002) <papid> P02-1053 </papid>used patterns representing part-of-speech sequences, (hatzivassiloglou and mckeown, 1997) <papid> P97-1023 </papid>recognized adjectival phrases, and (wiebe et al, 2001) learned n-grams.</prevsent>
<prevsent>the extraction patterns used in our research are linguistically richer patterns, requiring shallow parsing and syntactic role assign ment.</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
in recent years several techniques have been developed for semantic lexicon creation (e.g., (hearst, 1992; <papid> C92-2082 </papid>riloffand shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998; <papid> P98-2182 </papid>caraballo, 1999)).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>semantic word learning is different from subjective word learning, but we have shown that meta bootstrapping and basilisk could be successfully applied to subjectivity learning.
</nextsent>
<nextsent>perhaps some of these other methods could also be used to learn subjective words.
</nextsent>
<nextsent>this research produced interesting insights as well as performance results.
</nextsent>
<nextsent>first, we demonstrated that weakly supervised bootstrapping techniques can learn subjective terms from unannotated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1962">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(turney, 2002) <papid> P02-1053 </papid>used patterns representing part-of-speech sequences, (hatzivassiloglou and mckeown, 1997) <papid> P97-1023 </papid>recognized adjectival phrases, and (wiebe et al, 2001) learned n-grams.</prevsent>
<prevsent>the extraction patterns used in our research are linguistically richer patterns, requiring shallow parsing and syntactic role assign ment.</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
in recent years several techniques have been developed for semantic lexicon creation (e.g., (hearst, 1992; <papid> C92-2082 </papid>riloffand shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998; <papid> P98-2182 </papid>caraballo, 1999)).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>semantic word learning is different from subjective word learning, but we have shown that meta bootstrapping and basilisk could be successfully applied to subjectivity learning.
</nextsent>
<nextsent>perhaps some of these other methods could also be used to learn subjective words.
</nextsent>
<nextsent>this research produced interesting insights as well as performance results.
</nextsent>
<nextsent>first, we demonstrated that weakly supervised bootstrapping techniques can learn subjective terms from unannotated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1963">
<title id=" W03-0404.xml">learning subjective nouns using extraction pattern bootstrapping </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(turney, 2002) <papid> P02-1053 </papid>used patterns representing part-of-speech sequences, (hatzivassiloglou and mckeown, 1997) <papid> P97-1023 </papid>recognized adjectival phrases, and (wiebe et al, 2001) learned n-grams.</prevsent>
<prevsent>the extraction patterns used in our research are linguistically richer patterns, requiring shallow parsing and syntactic role assign ment.</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
in recent years several techniques have been developed for semantic lexicon creation (e.g., (hearst, 1992; <papid> C92-2082 </papid>riloffand shepherd, 1997; <papid> W97-0313 </papid>roark and charniak, 1998; <papid> P98-2182 </papid>caraballo, 1999)).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>semantic word learning is different from subjective word learning, but we have shown that meta bootstrapping and basilisk could be successfully applied to subjectivity learning.
</nextsent>
<nextsent>perhaps some of these other methods could also be used to learn subjective words.
</nextsent>
<nextsent>this research produced interesting insights as well as performance results.
</nextsent>
<nextsent>first, we demonstrated that weakly supervised bootstrapping techniques can learn subjective terms from unannotated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1964">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>language processing (emnlp), philadelphia, july 2002, pp.
</prevsent>
<prevsent>41-48.
</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
proceedings of the conference on empirical methods in natural learning algorithms (mooney, 1996; <papid> W96-0208 </papid>pedersen and bruce, 1997) tend to base their comparison on onlyone word or at most dozen words.</citsent>
<aftsection>
<nextsent>ng (1997) <papid> W97-0323 </papid>compared two learning algorithms, k-nearest neighbor and naive bayes, on the dso corpus (191 words).</nextsent>
<nextsent>escudero et al (2000) <papid> W00-1322 </papid>evaluated k-nearest neighbor,naive bayes, winnow-based, and lazy boosting algorithms on the dso corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1965">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>41-48.
</prevsent>
<prevsent>proceedings of the conference on empirical methods in natural learning algorithms (mooney, 1996; <papid> W96-0208 </papid>pedersen and bruce, 1997) tend to base their comparison on onlyone word or at most dozen words.</prevsent>
</prevsection>
<citsent citstr=" W97-0323 ">
ng (1997) <papid> W97-0323 </papid>compared two learning algorithms, k-nearest neighbor and naive bayes, on the dso corpus (191 words).</citsent>
<aftsection>
<nextsent>escudero et al (2000) <papid> W00-1322 </papid>evaluated k-nearest neighbor,naive bayes, winnow-based, and lazy boosting algorithms on the dso corpus.</nextsent>
<nextsent>the recent work of pedersen (2001<papid> N01-1011 </papid>a) and zavrel et al (2000) evaluateda variety of learning algorithms on the senseval1 data set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1966">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>proceedings of the conference on empirical methods in natural learning algorithms (mooney, 1996; <papid> W96-0208 </papid>pedersen and bruce, 1997) tend to base their comparison on onlyone word or at most dozen words.</prevsent>
<prevsent>ng (1997) <papid> W97-0323 </papid>compared two learning algorithms, k-nearest neighbor and naive bayes, on the dso corpus (191 words).</prevsent>
</prevsection>
<citsent citstr=" W00-1322 ">
escudero et al (2000) <papid> W00-1322 </papid>evaluated k-nearest neighbor,naive bayes, winnow-based, and lazy boosting algorithms on the dso corpus.</citsent>
<aftsection>
<nextsent>the recent work of pedersen (2001<papid> N01-1011 </papid>a) and zavrel et al (2000) evaluateda variety of learning algorithms on the senseval1 data set.</nextsent>
<nextsent>however, all of these research efforts concentrate only on evaluating different learning algorithms, without systematically considering their interaction with knowledge sources.ng and lee (1996) <papid> P96-1006 </papid>reported the relative contribution of different knowledge sources, but on only oneword interest?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1967">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>ng (1997) <papid> W97-0323 </papid>compared two learning algorithms, k-nearest neighbor and naive bayes, on the dso corpus (191 words).</prevsent>
<prevsent>escudero et al (2000) <papid> W00-1322 </papid>evaluated k-nearest neighbor,naive bayes, winnow-based, and lazy boosting algorithms on the dso corpus.</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
the recent work of pedersen (2001<papid> N01-1011 </papid>a) and zavrel et al (2000) evaluateda variety of learning algorithms on the senseval1 data set.</citsent>
<aftsection>
<nextsent>however, all of these research efforts concentrate only on evaluating different learning algorithms, without systematically considering their interaction with knowledge sources.ng and lee (1996) <papid> P96-1006 </papid>reported the relative contribution of different knowledge sources, but on only oneword interest?.</nextsent>
<nextsent>stevenson and wilks (2001) <papid> J01-3001 </papid>investigated the interaction of knowledge sources, such as part-of-speech, dictionary definition, subject codes, etc. on wsd.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1968">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>escudero et al (2000) <papid> W00-1322 </papid>evaluated k-nearest neighbor,naive bayes, winnow-based, and lazy boosting algorithms on the dso corpus.</prevsent>
<prevsent>the recent work of pedersen (2001<papid> N01-1011 </papid>a) and zavrel et al (2000) evaluateda variety of learning algorithms on the senseval1 data set.</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
however, all of these research efforts concentrate only on evaluating different learning algorithms, without systematically considering their interaction with knowledge sources.ng and lee (1996) <papid> P96-1006 </papid>reported the relative contribution of different knowledge sources, but on only oneword interest?.</citsent>
<aftsection>
<nextsent>stevenson and wilks (2001) <papid> J01-3001 </papid>investigated the interaction of knowledge sources, such as part-of-speech, dictionary definition, subject codes, etc. on wsd.</nextsent>
<nextsent>however, they do not evaluate their method on common benchmark dataset, and there is no exploration on the interaction of knowledge sources with different learning algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1970">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the recent work of pedersen (2001<papid> N01-1011 </papid>a) and zavrel et al (2000) evaluateda variety of learning algorithms on the senseval1 data set.</prevsent>
<prevsent>however, all of these research efforts concentrate only on evaluating different learning algorithms, without systematically considering their interaction with knowledge sources.ng and lee (1996) <papid> P96-1006 </papid>reported the relative contribution of different knowledge sources, but on only oneword interest?.</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
stevenson and wilks (2001) <papid> J01-3001 </papid>investigated the interaction of knowledge sources, such as part-of-speech, dictionary definition, subject codes, etc. on wsd.</citsent>
<aftsection>
<nextsent>however, they do not evaluate their method on common benchmark dataset, and there is no exploration on the interaction of knowledge sources with different learning algorithms.
</nextsent>
<nextsent>participating systems at senseval-1 andsenseval-2 tend to report accuracy using particular set of knowledge sources and some particular learning algorithm, without investigating the effect of varying knowledge sources and learning algorithms.
</nextsent>
<nextsent>in senseval-2, the various duluth systems (pedersen, 2001<papid> N01-1011 </papid>b) attempted to investigate whether features or learning algorithms are more important.</nextsent>
<nextsent>however, relative contribution of knowledge sources was not reported and only two main types of algorithms (naive bayes and decision tree) were tested.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1972">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>each training (or test) context of  generates one training (or test) feature vector.
</prevsent>
<prevsent>3.1 part-of-speech (pos) of neighboring.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
words we use 7 features to encode this knowledge source:              , where  (  ) is the pos of the  th token to the left (right) of  , and  is the pos of  . token can be word or punctuation symbol, and each of these neighboring tokens must be in the same sentence as  . we use asentence segmentation program (reynar and ratnaparkhi, 1997) <papid> A97-1004 </papid>and pos tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to segment the tokens surrounding  into sentences and assign pos tags to these tokens.</citsent>
<aftsection>
<nextsent>for example, to disambiguate the word bars in the pos-tagged sentence reid/nnp saw/vbd me/prp looking/vbg at/in the/dt iron/nn bars/nns ./.?, the pos feature vector is fiff  flffi  ff!ff  ff!ff#  %$&amp;( %( *) where   denotes the pos tag of null token.
</nextsent>
<nextsent>3.2 single words in the surrounding context.
</nextsent>
<nextsent>for this knowledge source, we consider all single words (unigrams) in the surrounding context of  , and these words can be in different sentence from . for each training or test example, the senseval datasets provide up to few sentences as the surrounding context.
</nextsent>
<nextsent>in the results reported in this paper, we consider all words in the provided context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1973">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>each training (or test) context of  generates one training (or test) feature vector.
</prevsent>
<prevsent>3.1 part-of-speech (pos) of neighboring.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
words we use 7 features to encode this knowledge source:              , where  (  ) is the pos of the  th token to the left (right) of  , and  is the pos of  . token can be word or punctuation symbol, and each of these neighboring tokens must be in the same sentence as  . we use asentence segmentation program (reynar and ratnaparkhi, 1997) <papid> A97-1004 </papid>and pos tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to segment the tokens surrounding  into sentences and assign pos tags to these tokens.</citsent>
<aftsection>
<nextsent>for example, to disambiguate the word bars in the pos-tagged sentence reid/nnp saw/vbd me/prp looking/vbg at/in the/dt iron/nn bars/nns ./.?, the pos feature vector is fiff  flffi  ff!ff  ff!ff#  %$&amp;( %( *) where   denotes the pos tag of null token.
</nextsent>
<nextsent>3.2 single words in the surrounding context.
</nextsent>
<nextsent>for this knowledge source, we consider all single words (unigrams) in the surrounding context of  , and these words can be in different sentence from . for each training or test example, the senseval datasets provide up to few sentences as the surrounding context.
</nextsent>
<nextsent>in the results reported in this paper, we consider all words in the provided context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1980">
<title id=" W02-1006.xml">an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation </title>
<section> knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>is the iron.
</prevsent>
<prevsent>1(a) attention (noun) 1(b) he turned his attention to the workbench . 1(c)  turned, vbd, active, left ) 2(a) turned (verb) 2(b) he turned his attention to the workbench . 2(c)  he, attention, prp, nn, vbd, active ) 3(a) green (adj) 3(b) the modern tram is green machine . 3(c)  machine, nn ) table 1: examples of syntactic relations (assuming no feature selection) 3.4 syntactic relations.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we first parse the sentence containing  with statistical parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>the constituent tree structure generated by charniaks parser is then converted into dependency tree in which every word points to parent headword.
</nextsent>
<nextsent>for example, in the sentence reid saw me looking at the iron bars .?, the word reid points to the parent headword saw.
</nextsent>
<nextsent>similarly, the word me also points to the parent headword saw.we use different types of syntactic relations, depending on the pos of  . if  is noun, we use four features: its parent headword ? , the pos of ? , the voice of ?
</nextsent>
<nextsent>(active, passive, or   if ? is not verb), and the relative position of ? from  (whether ? is to the left or right of  ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1985">
<title id=" W03-0409.xml">exceptionality and natural language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iscorr and status both deal with user corrections which is quite different from predicting speech recognition errors (handled in werbin and cabin).
</prevsent>
<prevsent>moreover, one will expect very little noise or no noise at all when manually annotating werbin and cabin.
</prevsent>
</prevsection>
<citsent citstr=" A00-2029 ">
for more information on our tasks and features, see (litman et al, 2000; <papid> A00-2029 </papid>hirschberg et al, 2001; <papid> N01-1027 </papid>litman et al, 2001).<papid> P01-1048 </papid></citsent>
<aftsection>
<nextsent>there are number of dimensions where our tasks differ from the tasks from the previous study.
</nextsent>
<nextsent>first of all our datasets are smaller (2,328 instances compared with at least 23,898).
</nextsent>
<nextsent>second, the number of features used is much bigger than the previous study (141 compared with 4-11).
</nextsent>
<nextsent>moreover, many features from our datasets are numeric while the previous study had none.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1986">
<title id=" W03-0409.xml">exceptionality and natural language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iscorr and status both deal with user corrections which is quite different from predicting speech recognition errors (handled in werbin and cabin).
</prevsent>
<prevsent>moreover, one will expect very little noise or no noise at all when manually annotating werbin and cabin.
</prevsent>
</prevsection>
<citsent citstr=" N01-1027 ">
for more information on our tasks and features, see (litman et al, 2000; <papid> A00-2029 </papid>hirschberg et al, 2001; <papid> N01-1027 </papid>litman et al, 2001).<papid> P01-1048 </papid></citsent>
<aftsection>
<nextsent>there are number of dimensions where our tasks differ from the tasks from the previous study.
</nextsent>
<nextsent>first of all our datasets are smaller (2,328 instances compared with at least 23,898).
</nextsent>
<nextsent>second, the number of features used is much bigger than the previous study (141 compared with 4-11).
</nextsent>
<nextsent>moreover, many features from our datasets are numeric while the previous study had none.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1987">
<title id=" W03-0409.xml">exceptionality and natural language learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iscorr and status both deal with user corrections which is quite different from predicting speech recognition errors (handled in werbin and cabin).
</prevsent>
<prevsent>moreover, one will expect very little noise or no noise at all when manually annotating werbin and cabin.
</prevsent>
</prevsection>
<citsent citstr=" P01-1048 ">
for more information on our tasks and features, see (litman et al, 2000; <papid> A00-2029 </papid>hirschberg et al, 2001; <papid> N01-1027 </papid>litman et al, 2001).<papid> P01-1048 </papid></citsent>
<aftsection>
<nextsent>there are number of dimensions where our tasks differ from the tasks from the previous study.
</nextsent>
<nextsent>first of all our datasets are smaller (2,328 instances compared with at least 23,898).
</nextsent>
<nextsent>second, the number of features used is much bigger than the previous study (141 compared with 4-11).
</nextsent>
<nextsent>moreover, many features from our datasets are numeric while the previous study had none.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1988">
<title id=" W02-0814.xml">evaluating the results of a memory based word expert approach to unrestricted word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task of word sense disambiguation (wsd) is to assign sense label to word in context.
</prevsent>
<prevsent>both knowledge-based and statistical methods have been applied to the problem.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
see (ide and veronis, 1998) <papid> J98-1001 </papid>for an introduction to the area.</citsent>
<aftsection>
<nextsent>recently (bothsenseval competitions), various machine learning (ml) approaches have been demonstrated to produce relatively successful wsd systems, e.g.memory-based learning (ng and lee, 1996; <papid> P96-1006 </papid>veenstra et al, 2000), decision lists (yarowsky, 2000), boosting (escudero et al, 2000).in this paper, we evaluate the results of memory based learning approach to wsd.</nextsent>
<nextsent>we ask ourselves whether we can learn lessons from the errors made in the senseval-2 competition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1989">
<title id=" W02-0814.xml">evaluating the results of a memory based word expert approach to unrestricted word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both knowledge-based and statistical methods have been applied to the problem.
</prevsent>
<prevsent>see (ide and veronis, 1998) <papid> J98-1001 </papid>for an introduction to the area.</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
recently (bothsenseval competitions), various machine learning (ml) approaches have been demonstrated to produce relatively successful wsd systems, e.g.memory-based learning (ng and lee, 1996; <papid> P96-1006 </papid>veenstra et al, 2000), decision lists (yarowsky, 2000), boosting (escudero et al, 2000).in this paper, we evaluate the results of memory based learning approach to wsd.</citsent>
<aftsection>
<nextsent>we ask ourselves whether we can learn lessons from the errors made in the senseval-2 competition.
</nextsent>
<nextsent>more particularly,we are interested whether there are words or categories of words which are more difficult to predict than other words.
</nextsent>
<nextsent>if so, do these words have certain characteristic features?
</nextsent>
<nextsent>we furthermore investigate the interaction between the use of different information sources and the part-of-speech categories of the ambiguous words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1990">
<title id=" W02-0814.xml">evaluating the results of a memory based word expert approach to unrestricted word sense disambiguation </title>
<section> memory-based word-experts.  </section>
<citcontext>
<prevsection>
<prevsent>no mapping was performed between both versions of wordnet.
</prevsent>
<prevsent>for both the training and the test corpus, only the word forms were used and tokenization, lemmatization and pos-tagging were done with our own software.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
for the part of speech tagging, the memory-based tagger mbt (daelemans et al, 1996), <papid> W96-0102 </papid>trained on the wall street journal corpus2, was used.</citsent>
<aftsection>
<nextsent>on the basis of word and pos information, lemmatization (van den bosch and daelemans, 1999) was done.
</nextsent>
<nextsent>after this preprocessing stage, all word-experts were built.
</nextsent>
<nextsent>this process was guided by wordnet1.7: for every combination of word form and pos, wordnet1.7 was consulted to determine whether this combination had one or more possible senses.
</nextsent>
<nextsent>in case of only one possible sense (about 20% of the test words), the appropriate sense was assigned.in case of more possible senses, minimal threshold of ten occurrences in the semcor training data was determined, since 10-fold cross-validation was used for testing in all experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1992">
<title id=" W02-0814.xml">evaluating the results of a memory based word expert approach to unrestricted word sense disambiguation </title>
<section> evaluation of the results.  </section>
<citcontext>
<prevsection>
<prevsent>these results indicate it would be interesting to work towards more coarse-grained granularity of the distinction between word senses.
</prevsent>
<prevsent>we believe that this would increase performance of the wsd systems and make them possible candidate for integration in practical applications such as machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
this is also shown by stevenson and wilks (2001), <papid> J01-3001 </papid>who used the long man dictionary of contemporary english (ldoce) as sense inventory.</citsent>
<aftsection>
<nextsent>in ldoce, the senses for each word type are grouped into sets of senses with related meanings (homographs).
</nextsent>
<nextsent>senses which are far enough apart are grouped into separate homographs.
</nextsent>
<nextsent>the vast majority of homo graphs in ldoce are marked with single part-of-speech.
</nextsent>
<nextsent>this makes the task of wsd partly part-of-speech tagging task, which is generally held to be an easier task than word sense disambiguation: on corpus of 5 articles in the wall street journal, their system already correctly classifies 87.4% of the words when only using pos information (baseline: 78%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1993">
<title id=" W02-0814.xml">evaluating the results of a memory based word expert approach to unrestricted word sense disambiguation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>but we furthermore concluded that the fluctuations inaccuracy largely depend on the polysemy and entropy of the ambiguous words.
</prevsent>
<prevsent>on the basis of these results, we conclude that more coarse-grained granularity of the distinction between word senses would increase performance of the wsd systems and make them apos sible candidate for integration in practical applications such as machine translation systems.when evaluating our system on the test set, accuracy dropped by nearly 20% compared to scores on the train set, which could be largely explained by lack of training material for many senses.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
so the creation of more annotated data is necesssary and will certainly cause major improvements of current wsd systems and nlp systems in general (see also (banko and brill, 2001)).<papid> P01-1005 </papid></citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1994">
<title id=" W03-1202.xml">using thematic information in statistical headline generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>examples of recent systems include kupiec et al.
</prevsent>
<prevsent>(1995) and brandow et al (1995).
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
for examples of work in producing abstract-like summaries, see radev and mckeown (1998), <papid> J98-3005 </papid>which combines work in information extraction 1 theme is term that is used in many ways by many researchers, and generally without any kind of formal definition.</citsent>
<aftsection>
<nextsent>our use of the term here is akin to the notion that underlies work on text segmentation, where sentences naturally cluster in terms of their aboutness?.
</nextsent>
<nextsent>and natural language processing.
</nextsent>
<nextsent>hybrid methods for abstract-like summarisation which combine statistical and symbolic approaches have also been explored; see, for example, mckeown et al (1999), jing and mckeown (1999), and hovy and lin (1997).<papid> W97-0704 </papid></nextsent>
<nextsent>statistical single sentence summarisation has been explored by number of researchers (see for example, witbrock and mittal, 1999; zajic et al., 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1995">
<title id=" W03-1202.xml">using thematic information in statistical headline generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our use of the term here is akin to the notion that underlies work on text segmentation, where sentences naturally cluster in terms of their aboutness?.
</prevsent>
<prevsent>and natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W97-0704 ">
hybrid methods for abstract-like summarisation which combine statistical and symbolic approaches have also been explored; see, for example, mckeown et al (1999), jing and mckeown (1999), and hovy and lin (1997).<papid> W97-0704 </papid></citsent>
<aftsection>
<nextsent>statistical single sentence summarisation has been explored by number of researchers (see for example, witbrock and mittal, 1999; zajic et al., 2002).
</nextsent>
<nextsent>we build on the approach employed by witbrock and mittal (1999) which we will describe in more detail in section 3.
</nextsent>
<nextsent>interestingly, in the work of witbrock and mittal (1999), the selection of words for inclusion in the headline is decided solely on the basis of corpus statistics and does not use statistical information about the distribution of words in the document itself.
</nextsent>
<nextsent>our work differs in that we utilise an svd analysis to provide information about the document to be summarized, specifically its main theme.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1996">
<title id=" W03-1202.xml">using thematic information in statistical headline generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they present theme interpretation of the svd analysis, as it is used for discourse segmentation, upon which our use of the technique is based.
</prevsent>
<prevsent>however, gong and liu use svd for creating sentence extraction summaries, not for generating single sentence summary by re-using words.
</prevsent>
</prevsection>
<citsent citstr=" P00-1041 ">
in subsequent work to witbrock and mittal (1999), banko et al (2000) <papid> P00-1041 </papid>describe the use of information about the position of words within four quarters of the source document.</citsent>
<aftsection>
<nextsent>the headline candidacy score of word is weighted by its position in one of quarters.
</nextsent>
<nextsent>we interpret this use of position information as means of guiding the generation of headline towards the central theme of the document, which for news articles typically occurs in the first quarter.
</nextsent>
<nextsent>svd potentially offers more general mechanism for handling the discovery of the central themes and their positions within the document.
</nextsent>
<nextsent>jin et al (2002) have also examined statistical model for headlines in the context of an information retrieval application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z1997">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> introduction: why parsing characters?.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W00-1201 ">
after linguistic data consortium (ldc) released the chinese treebank (ctb) developed at upenn (xia et al, 2000), various statistical chinese parsers (bikel and chiang, 2000; <papid> W00-1201 </papid>xu et al, 2002)have been built.</citsent>
<aftsection>
<nextsent>techniques used in parsing english have been shown working fairly well when applied to parsing chinese text.
</nextsent>
<nextsent>as there is no word boundary in written chinese text, ctb is manually segmented into words and then labeled.
</nextsent>
<nextsent>parsers described in (bikel and chiang, 2000) <papid> W00-1201 </papid>and (xu et al, 2002) operate at word-level with the assumption that input sentences are pre-segmented.the paper studies the problem of parsing chinese unsegmented sentences.</nextsent>
<nextsent>the first motivation is that character-based parser can be used directly in natural language applications that operate at character level, whereas word-based parser requires separate word-segmenter.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2003">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> introduction: why parsing characters?.  </section>
<citcontext>
<prevsection>
<prevsent>the second and more important reason is that the availability of ctb,a large corpus with high quality syntactic annotations, provides us with an opportunity to create highly-accurate word-segmenter.
</prevsent>
<prevsent>it is widely known that chinese word-segmentation is hard problem.
</prevsent>
</prevsection>
<citsent citstr=" A94-1030 ">
there are multiple studies (wu and fung, 1994;<papid> A94-1030 </papid>sproat et al, 1996; <papid> J96-3004 </papid>luo and roukos, 1996) <papid> P96-1019 </papid>showing that the agreement between two (untrained) native speakers is about upper   to lower    . the agreement between multiple human subject sis even lower (wu and fung, 1994).<papid> A94-1030 </papid></citsent>
<aftsection>
<nextsent>the reason is that human subjects may differ in segmenting things like personal names (whether family and given names should be one or two words), number and measure units and compound words, although these ambiguities do not change human beings understanding of sentence.
</nextsent>
<nextsent>low agreement between humans affects directly evaluation of machines?
</nextsent>
<nextsent>performance (wu and fung, 1994) <papid> A94-1030 </papid>as itis hard to define gold standard.</nextsent>
<nextsent>it does not necessarily imply that machines cannot do better thanhumans.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2004">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> introduction: why parsing characters?.  </section>
<citcontext>
<prevsection>
<prevsent>the second and more important reason is that the availability of ctb,a large corpus with high quality syntactic annotations, provides us with an opportunity to create highly-accurate word-segmenter.
</prevsent>
<prevsent>it is widely known that chinese word-segmentation is hard problem.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
there are multiple studies (wu and fung, 1994;<papid> A94-1030 </papid>sproat et al, 1996; <papid> J96-3004 </papid>luo and roukos, 1996) <papid> P96-1019 </papid>showing that the agreement between two (untrained) native speakers is about upper   to lower    . the agreement between multiple human subject sis even lower (wu and fung, 1994).<papid> A94-1030 </papid></citsent>
<aftsection>
<nextsent>the reason is that human subjects may differ in segmenting things like personal names (whether family and given names should be one or two words), number and measure units and compound words, although these ambiguities do not change human beings understanding of sentence.
</nextsent>
<nextsent>low agreement between humans affects directly evaluation of machines?
</nextsent>
<nextsent>performance (wu and fung, 1994) <papid> A94-1030 </papid>as itis hard to define gold standard.</nextsent>
<nextsent>it does not necessarily imply that machines cannot do better thanhumans.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2006">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> introduction: why parsing characters?.  </section>
<citcontext>
<prevsection>
<prevsent>the second and more important reason is that the availability of ctb,a large corpus with high quality syntactic annotations, provides us with an opportunity to create highly-accurate word-segmenter.
</prevsent>
<prevsent>it is widely known that chinese word-segmentation is hard problem.
</prevsent>
</prevsection>
<citsent citstr=" P96-1019 ">
there are multiple studies (wu and fung, 1994;<papid> A94-1030 </papid>sproat et al, 1996; <papid> J96-3004 </papid>luo and roukos, 1996) <papid> P96-1019 </papid>showing that the agreement between two (untrained) native speakers is about upper   to lower    . the agreement between multiple human subject sis even lower (wu and fung, 1994).<papid> A94-1030 </papid></citsent>
<aftsection>
<nextsent>the reason is that human subjects may differ in segmenting things like personal names (whether family and given names should be one or two words), number and measure units and compound words, although these ambiguities do not change human beings understanding of sentence.
</nextsent>
<nextsent>low agreement between humans affects directly evaluation of machines?
</nextsent>
<nextsent>performance (wu and fung, 1994) <papid> A94-1030 </papid>as itis hard to define gold standard.</nextsent>
<nextsent>it does not necessarily imply that machines cannot do better thanhumans.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2010">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> introduction: why parsing characters?.  </section>
<citcontext>
<prevsection>
<prevsent>we derive character-level tags fromword-level pos tags and encode word-boundary information with positional tag.
</prevsent>
<prevsent>word-level poss become constituent label in character-based trees.
</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
a maximum entropy parser (ratnaparkhi, 1997)<papid> W97-0301 </papid>parser is then built and tested.</citsent>
<aftsection>
<nextsent>many language independent feature templates in the english pars ercan be reused.
</nextsent>
<nextsent>lexical features, which are language dependent, are used to further improve the baseline models trained with language-independent features only.
</nextsent>
<nextsent>word-segmentation results will be presented and it will be shown that poss are very helpful while higher-level syntactic structures are of little use to word-segmentation ? at least in the way they are used in the parser.
</nextsent>
<nextsent>ctb is manually segmented and is tokenized at word level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2012">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> model and features.  </section>
<citcontext>
<prevsection>
<prevsent>actions, i.e., / 0213465 %7&amp;98 3 *,;: 8 = 3@a5cb 5- . the parse actions 8 021 5 are an ordered sequence, where d+e is the number of actions associated with the parse ( . the mapping from parse tree to its unique sequence of actions is 1-to-1.
</prevsent>
<prevsent>each parse action is either tagging word, chunking tagged words, extending an existing constituent to another constituent, or checking whether an open constituent should be closed.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
each component model takes the exponential form: %7&amp;98 3 *,;: 8 = 3@a5cb 5 -.f ghikjmlonqp nrn &s;,;: 8t= 3@a5cb 5 : 8 3 -vu &s;,;: 8t= 3@a5cb 5 : (2) where &s;,;: 8 = 3)a5cb 5 - is normalization term to ensure that %7&amp;98 3 *,x: 8 = 3)a5cb 5 - is probability, rn &s;,;: 8 = 3@a5cb 5 : 8 3 - is feature function (often binary) and n is the weight of rn . given set of features and corpus of training data, there exist efficient training algorithms (dar roch and rat cliff, 1972; berger et al, 1996) <papid> J96-1002 </papid>to find the optimal parameters p nz . the art of build inga maximum entropy parser then reduces to choosing good?</citsent>
<aftsection>
<nextsent>features.
</nextsent>
<nextsent>we break features used in this study into two categories.
</nextsent>
<nextsent>the first set of features are derived from predefined templates.
</nextsent>
<nextsent>when these templates are applied to training data, features are generated automatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2020">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> g 5 ??: 8dw </section>
<citcontext>
<prevsection>
<prevsent>5 related work.
</prevsent>
<prevsent>bikel and chiang (2000) <papid> W00-1201 </papid>and xu et al (2002) construct word-based statistical parsers on the first release of chinese treebank, which has about 100k words, roughly half of the training data used in this study.</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
bikel and chiang (2000) <papid> W00-1201 </papid>in fact contains twoparsers: one is lexicalized probabilistic context free grammar (pcfg) similar to (collins, 1997); <papid> P97-1003 </papid>the other is based on statistical tag (chiang, 2000).<papid> P00-1058 </papid>about  ? f-measure is reported in (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>xu et al (2002) is also based on pcfg, but enhanced with lexical features derived from the asbc corpus2 . xu et al (2002) reports an overall f-measure    when the same training and test set as (bikel and chiang, 2000) <papid> W00-1201 </papid>are used.</nextsent>
<nextsent>since our parser operates at character level, and more training data is used, the best results are not directly comparable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2022">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> g 5 ??: 8dw </section>
<citcontext>
<prevsection>
<prevsent>5 related work.
</prevsent>
<prevsent>bikel and chiang (2000) <papid> W00-1201 </papid>and xu et al (2002) construct word-based statistical parsers on the first release of chinese treebank, which has about 100k words, roughly half of the training data used in this study.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
bikel and chiang (2000) <papid> W00-1201 </papid>in fact contains twoparsers: one is lexicalized probabilistic context free grammar (pcfg) similar to (collins, 1997); <papid> P97-1003 </papid>the other is based on statistical tag (chiang, 2000).<papid> P00-1058 </papid>about  ? f-measure is reported in (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>xu et al (2002) is also based on pcfg, but enhanced with lexical features derived from the asbc corpus2 . xu et al (2002) reports an overall f-measure    when the same training and test set as (bikel and chiang, 2000) <papid> W00-1201 </papid>are used.</nextsent>
<nextsent>since our parser operates at character level, and more training data is used, the best results are not directly comparable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2035">
<title id=" W03-1025.xml">a maximum entropy chinese character based parser </title>
<section> g 5 ??: 8dw </section>
<citcontext>
<prevsection>
<prevsent>wu and tseng (1993) contains good problem statement of chinese word segmentation and also outlines few segmentation algorithms.
</prevsent>
<prevsent>our method is supervised in that the training data is manually labeled.
</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
palmer (1997) <papid> P97-1041 </papid>uses transform-based learning (tbl) to correct an initial segmentation.</citsent>
<aftsection>
<nextsent>sproat et al (1996) <papid> J96-3004 </papid>employs stochastic finite state machines to find word bound aries.</nextsent>
<nextsent>luo and roukos (1996) <papid> P96-1019 </papid>proposes to use alan guage model to select from ambiguous wordsegmentations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2038">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, we develop both two-step approach which combines trace tagger with state-of-the-art lexicalized parserand one-step approach which finds non local dependencies while parsing.
</prevsent>
<prevsent>we find that the former outperforms the latter be cause it makes better use of the features we isolate.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
many broad-coverage statistical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999; bod, 2001) <papid> P01-1010 </papid>are not able to give full interpretation for sentences such as: (1) it is difficult to guess what she wants to buy.</citsent>
<aftsection>
<nextsent>building the semantic interpretation of this sentence requires recovering three non-local relations: (i) the object of buy is what ;1 (ii) the subject of buy is she;and (iii) guess does not have subject in the sen tence.three approaches have been proposed to detect such relations: (i) post-processing the output of parser not designed to detect extraction sites(johnson, 2002); (<papid> P02-1018 </papid>ii) integrating antecedent recovery into the parser (henceforth in-processing) by either enriching syntactically simple model (collins, 1999) or using more powerful syntactic framework 1collins (1999) can handle this case (model 3).(clark et al, 2002; <papid> P02-1042 </papid>riezler et al, 2002); <papid> P02-1035 </papid>and (iii) detecting non-local dependencies as pre-processing step before parsing (dienes and dubey, 2003).<papid> P03-1055 </papid></nextsent>
<nextsent>while the pre-processing approach is reported to give state-of-the-art performance using un lexicalized parsers, it has not been tested using lexicalized models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2039">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, we develop both two-step approach which combines trace tagger with state-of-the-art lexicalized parserand one-step approach which finds non local dependencies while parsing.
</prevsent>
<prevsent>we find that the former outperforms the latter be cause it makes better use of the features we isolate.
</prevsent>
</prevsection>
<citsent citstr=" P01-1010 ">
many broad-coverage statistical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999; bod, 2001) <papid> P01-1010 </papid>are not able to give full interpretation for sentences such as: (1) it is difficult to guess what she wants to buy.</citsent>
<aftsection>
<nextsent>building the semantic interpretation of this sentence requires recovering three non-local relations: (i) the object of buy is what ;1 (ii) the subject of buy is she;and (iii) guess does not have subject in the sen tence.three approaches have been proposed to detect such relations: (i) post-processing the output of parser not designed to detect extraction sites(johnson, 2002); (<papid> P02-1018 </papid>ii) integrating antecedent recovery into the parser (henceforth in-processing) by either enriching syntactically simple model (collins, 1999) or using more powerful syntactic framework 1collins (1999) can handle this case (model 3).(clark et al, 2002; <papid> P02-1042 </papid>riezler et al, 2002); <papid> P02-1035 </papid>and (iii) detecting non-local dependencies as pre-processing step before parsing (dienes and dubey, 2003).<papid> P03-1055 </papid></nextsent>
<nextsent>while the pre-processing approach is reported to give state-of-the-art performance using un lexicalized parsers, it has not been tested using lexicalized models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2040">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we find that the former outperforms the latter be cause it makes better use of the features we isolate.
</prevsent>
<prevsent>many broad-coverage statistical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999; bod, 2001) <papid> P01-1010 </papid>are not able to give full interpretation for sentences such as: (1) it is difficult to guess what she wants to buy.</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
building the semantic interpretation of this sentence requires recovering three non-local relations: (i) the object of buy is what ;1 (ii) the subject of buy is she;and (iii) guess does not have subject in the sen tence.three approaches have been proposed to detect such relations: (i) post-processing the output of parser not designed to detect extraction sites(johnson, 2002); (<papid> P02-1018 </papid>ii) integrating antecedent recovery into the parser (henceforth in-processing) by either enriching syntactically simple model (collins, 1999) or using more powerful syntactic framework 1collins (1999) can handle this case (model 3).(clark et al, 2002; <papid> P02-1042 </papid>riezler et al, 2002); <papid> P02-1035 </papid>and (iii) detecting non-local dependencies as pre-processing step before parsing (dienes and dubey, 2003).<papid> P03-1055 </papid></citsent>
<aftsection>
<nextsent>while the pre-processing approach is reported to give state-of-the-art performance using un lexicalized parsers, it has not been tested using lexicalized models.
</nextsent>
<nextsent>our main claim is that that thepre-processing approach, coupled with lexicalized parser outperforms both state-of-the-art postprocessing and in-processing.
</nextsent>
<nextsent>however, we show that model 3 of collins (1999) can be generalized to handle all types of long-distance dependencies with performance close to the pre-processing architecture.
</nextsent>
<nextsent>a general contribution of this paper is that it gives important insights about the nature of the problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2041">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we find that the former outperforms the latter be cause it makes better use of the features we isolate.
</prevsent>
<prevsent>many broad-coverage statistical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999; bod, 2001) <papid> P01-1010 </papid>are not able to give full interpretation for sentences such as: (1) it is difficult to guess what she wants to buy.</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
building the semantic interpretation of this sentence requires recovering three non-local relations: (i) the object of buy is what ;1 (ii) the subject of buy is she;and (iii) guess does not have subject in the sen tence.three approaches have been proposed to detect such relations: (i) post-processing the output of parser not designed to detect extraction sites(johnson, 2002); (<papid> P02-1018 </papid>ii) integrating antecedent recovery into the parser (henceforth in-processing) by either enriching syntactically simple model (collins, 1999) or using more powerful syntactic framework 1collins (1999) can handle this case (model 3).(clark et al, 2002; <papid> P02-1042 </papid>riezler et al, 2002); <papid> P02-1035 </papid>and (iii) detecting non-local dependencies as pre-processing step before parsing (dienes and dubey, 2003).<papid> P03-1055 </papid></citsent>
<aftsection>
<nextsent>while the pre-processing approach is reported to give state-of-the-art performance using un lexicalized parsers, it has not been tested using lexicalized models.
</nextsent>
<nextsent>our main claim is that that thepre-processing approach, coupled with lexicalized parser outperforms both state-of-the-art postprocessing and in-processing.
</nextsent>
<nextsent>however, we show that model 3 of collins (1999) can be generalized to handle all types of long-distance dependencies with performance close to the pre-processing architecture.
</nextsent>
<nextsent>a general contribution of this paper is that it gives important insights about the nature of the problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2042">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we find that the former outperforms the latter be cause it makes better use of the features we isolate.
</prevsent>
<prevsent>many broad-coverage statistical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999; bod, 2001) <papid> P01-1010 </papid>are not able to give full interpretation for sentences such as: (1) it is difficult to guess what she wants to buy.</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
building the semantic interpretation of this sentence requires recovering three non-local relations: (i) the object of buy is what ;1 (ii) the subject of buy is she;and (iii) guess does not have subject in the sen tence.three approaches have been proposed to detect such relations: (i) post-processing the output of parser not designed to detect extraction sites(johnson, 2002); (<papid> P02-1018 </papid>ii) integrating antecedent recovery into the parser (henceforth in-processing) by either enriching syntactically simple model (collins, 1999) or using more powerful syntactic framework 1collins (1999) can handle this case (model 3).(clark et al, 2002; <papid> P02-1042 </papid>riezler et al, 2002); <papid> P02-1035 </papid>and (iii) detecting non-local dependencies as pre-processing step before parsing (dienes and dubey, 2003).<papid> P03-1055 </papid></citsent>
<aftsection>
<nextsent>while the pre-processing approach is reported to give state-of-the-art performance using un lexicalized parsers, it has not been tested using lexicalized models.
</nextsent>
<nextsent>our main claim is that that thepre-processing approach, coupled with lexicalized parser outperforms both state-of-the-art postprocessing and in-processing.
</nextsent>
<nextsent>however, we show that model 3 of collins (1999) can be generalized to handle all types of long-distance dependencies with performance close to the pre-processing architecture.
</nextsent>
<nextsent>a general contribution of this paper is that it gives important insights about the nature of the problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2043">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we find that the former outperforms the latter be cause it makes better use of the features we isolate.
</prevsent>
<prevsent>many broad-coverage statistical parsers (charniak, 2000; <papid> A00-2018 </papid>collins, 1999; bod, 2001) <papid> P01-1010 </papid>are not able to give full interpretation for sentences such as: (1) it is difficult to guess what she wants to buy.</prevsent>
</prevsection>
<citsent citstr=" P03-1055 ">
building the semantic interpretation of this sentence requires recovering three non-local relations: (i) the object of buy is what ;1 (ii) the subject of buy is she;and (iii) guess does not have subject in the sen tence.three approaches have been proposed to detect such relations: (i) post-processing the output of parser not designed to detect extraction sites(johnson, 2002); (<papid> P02-1018 </papid>ii) integrating antecedent recovery into the parser (henceforth in-processing) by either enriching syntactically simple model (collins, 1999) or using more powerful syntactic framework 1collins (1999) can handle this case (model 3).(clark et al, 2002; <papid> P02-1042 </papid>riezler et al, 2002); <papid> P02-1035 </papid>and (iii) detecting non-local dependencies as pre-processing step before parsing (dienes and dubey, 2003).<papid> P03-1055 </papid></citsent>
<aftsection>
<nextsent>while the pre-processing approach is reported to give state-of-the-art performance using un lexicalized parsers, it has not been tested using lexicalized models.
</nextsent>
<nextsent>our main claim is that that thepre-processing approach, coupled with lexicalized parser outperforms both state-of-the-art postprocessing and in-processing.
</nextsent>
<nextsent>however, we show that model 3 of collins (1999) can be generalized to handle all types of long-distance dependencies with performance close to the pre-processing architecture.
</nextsent>
<nextsent>a general contribution of this paper is that it gives important insights about the nature of the problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2060">
<title id=" W03-1005.xml">antecedent recovery experiments with a trace tagger </title>
<section> antecedent recovery.  </section>
<citcontext>
<prevsection>
<prevsent>this metric works by treating ees and their antecedents as four tuples, consisting of the type of the ee, its location,the type of its antecedent and the location(s) (begin ning and end) of the antecedent.
</prevsent>
<prevsent>an antecedent is correctly recovered if all four values match the goldstandard.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
we calculate the precision, recall, and score; however for brevitys sake we only report the f-score for most experiments in this section.in addition to antecedent recovery, we also report parsing accuracy, using the bracketing f-score, the combined measure of parseval-style labeled bracketing precision and recall (magerman, 1995).<papid> P95-1037 </papid></citsent>
<aftsection>
<nextsent>4.4 results.
</nextsent>
<nextsent>the results of the experiments are summarized in table 3.
</nextsent>
<nextsent>unlex and lex refer to the unlexicalizedand lexicalized models, respectively.
</nextsent>
<nextsent>in the upper bound case, perfect, the f-score for antecedent recovery is quite high in both the un lexicalized and lexicalized cases: 91.4% and 93.3%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2084">
<title id=" W02-1814.xml">extracting pronunciation translated names from chinese texts using bootstrapping approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to take advantage of that, we need to tackle two major problems.
</prevsent>
<prevsent>the first is how to gather sufficient distinct p-names from the internet, and the second is how to use the available resources to derive reliable statistical information to characterize the p-names.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
the problem of gathering sufficient reliable information from small initial set of seed resources has been tackled in bootstrapping research for information extraction (agichtein and gravano, 2000; brin, 1998; collins and singer, 1999; <papid> W99-0613 </papid>mihalcea and moldovan, 2001; riloff and jones, 1999).</citsent>
<aftsection>
<nextsent>bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the internet using minimum manual labor.
</nextsent>
<nextsent>given the lack of annotated training samples for p-name extraction, this paper introduces bootstrapping algorithm, called pn-finder.
</nextsent>
<nextsent>it starts from small set of seed samples, and iteratively locates, extracts and classifies the new and more p-names.
</nextsent>
<nextsent>it works in conjunction with general chinese named entity recognizer (chua and liu, 2002) to extract general named entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2085">
<title id=" W03-1718.xml">single character chinese named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare all proposed approaches, showing that the source channel model performs the best in most cases.
</prevsent>
<prevsent>the research of named entity recognition (ner) becomes very popular in recent years due to its wide applications and the message understanding conference (muc) which provides standard testbed for ner evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
recent research on english ner includes (collins, 2002; <papid> P02-1062 </papid>isozaki, 2002; zhou, 2002; etc.).</citsent>
<aftsection>
<nextsent>chinese ner research includes (liu, 2001; zheng, 2000; yu, 1998; chen, 1998; shen, 1995; sun, 1994; zhang, 1992 etc.) in chinese nes, there is special kind of ne, called single character named entity (scne), on which there is little in-depth research.
</nextsent>
<nextsent>scne is ne composed of only one chinese character, such as the location name ?   ?
</nextsent>
<nextsent>(zhong1,china) and ?
</nextsent>
<nextsent>(e2,russia) in the phrase ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2086">
<title id=" W03-1718.xml">single character chinese named entity recognition </title>
<section> character-based classifiers.  </section>
<citcontext>
<prevsection>
<prevsent>(5) where   is weight of the feature fi , and z(x) is normalization factor.
</prevsent>
<prevsent>weights (  ) are estimated using the maximum entropy principle: to satisfy constraints on observed data and assume uniform distribution (with the maximum entropy) on unseen data.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the training algorithm we used is the improved iterative scaling (iis) described in (berger et al 1996)<papid> J96-1002 </papid>3.</citsent>
<aftsection>
<nextsent>the context features include six charac ters: three on the left of the scne, and three on the right.
</nextsent>
<nextsent>given the context features, the me classifier would estimate the probability of the candidate being scne.
</nextsent>
<nextsent>in our example, we treat candidates with the probability larger than 0.5 as scnes.
</nextsent>
<nextsent>to get the precision-recall curve, we can vary the probability threshold from 0.1 to 0.9.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2088">
<title id=" W03-1727.xml">chinese word segmentation in msrnlp </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the expanded word lattice built in 1.2 is inspected to detect spots of possible oov new words.
</prevsent>
<prevsent>typical spots of this kind are sequences of single characters that are not subsumed by longer words.
</prevsent>
</prevsection>
<citsent citstr=" W00-1207 ">
we then use the following information to propose new words (wu and jiang, 2000).<papid> W00-1207 </papid></citsent>
<aftsection>
<nextsent>the probability of the character string being sequence of independent words; ? the morphological and syntactic properties of the characters; ? word formation rules; ? behavior of each character in existing words (e.g. how likely is this character to be used as the second character of two character verb).
</nextsent>
<nextsent>the context in which the characters appear.
</nextsent>
<nextsent>the proposed new words are added to the word lattice and they will get used if no successful parse can be obtained without them.
</nextsent>
<nextsent>when new word proposed this way has been verified by the parser (i.e. used in successful parse) more than times, it will automatically become an entry in the dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2089">
<title id=" W03-1727.xml">chinese word segmentation in msrnlp </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>when new word proposed this way has been verified by the parser (i.e. used in successful parse) more than times, it will automatically become an entry in the dictionary.
</prevsent>
<prevsent>from then on, this word can be looked up directly from the dictionary instead of being proposed online.
</prevsent>
</prevsection>
<citsent citstr=" C02-2002 ">
this kind of dynamic lexical acquisition has been presented in wu et al(2002).<papid> C02-2002 </papid></citsent>
<aftsection>
<nextsent>1.4 word lattice pruning.
</nextsent>
<nextsent>now that all the possible words are in the word lattice, both statistical and linguistic methods are applied to eliminate certain paths.
</nextsent>
<nextsent>for instance, those paths that contain one or more bound morphemes are pruned away.
</nextsent>
<nextsent>single characters that are subsumed by longer words are also thrown out if their independent word probabilities are very low.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2090">
<title id=" W03-1307.xml">effective adaptation of hidden markov model based named entity recognizer for biomedical domain </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the research in biomedical domain has grown rapidly in recent years, huge amount of nature language resources have been developed and be come rich knowledge base.
</prevsent>
<prevsent>the technique of named entity (ne) recognition (ner) is strongly demanded to be applied in biomedical domain.
</prevsent>
</prevsection>
<citsent citstr=" P02-1060 ">
since in previous work, many ner systems have been applied successfully in newswire domain (zhou and su 2002; <papid> P02-1060 </papid>bikel et al 1999; borthwich et al. 1999), more and more explorations have been done to port existing ner system into biomedical domain (kazama et al 2002; <papid> W02-0301 </papid>takeuchi et al 2002; nobata et al 1999 and 2000; collier et al 2000; <papid> C00-1030 </papid>gaizauskas et al 2000; fukuda et al 1998; proux et al 1998).</citsent>
<aftsection>
<nextsent>however, compared with those in newswire domain, these systems havent got high performance.
</nextsent>
<nextsent>it is probably because of the following factors of biomedical ne (zhang et al 2003): 1.
</nextsent>
<nextsent>some modifiers are often before basic nes,.
</nextsent>
<nextsent>e.g. activated cell lines, and sometimes biomedical nes are very long, e.g. 47 kda sterol regulatory element binding factor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2091">
<title id=" W03-1307.xml">effective adaptation of hidden markov model based named entity recognizer for biomedical domain </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the research in biomedical domain has grown rapidly in recent years, huge amount of nature language resources have been developed and be come rich knowledge base.
</prevsent>
<prevsent>the technique of named entity (ne) recognition (ner) is strongly demanded to be applied in biomedical domain.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
since in previous work, many ner systems have been applied successfully in newswire domain (zhou and su 2002; <papid> P02-1060 </papid>bikel et al 1999; borthwich et al. 1999), more and more explorations have been done to port existing ner system into biomedical domain (kazama et al 2002; <papid> W02-0301 </papid>takeuchi et al 2002; nobata et al 1999 and 2000; collier et al 2000; <papid> C00-1030 </papid>gaizauskas et al 2000; fukuda et al 1998; proux et al 1998).</citsent>
<aftsection>
<nextsent>however, compared with those in newswire domain, these systems havent got high performance.
</nextsent>
<nextsent>it is probably because of the following factors of biomedical ne (zhang et al 2003): 1.
</nextsent>
<nextsent>some modifiers are often before basic nes,.
</nextsent>
<nextsent>e.g. activated cell lines, and sometimes biomedical nes are very long, e.g. 47 kda sterol regulatory element binding factor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2092">
<title id=" W03-1307.xml">effective adaptation of hidden markov model based named entity recognizer for biomedical domain </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the research in biomedical domain has grown rapidly in recent years, huge amount of nature language resources have been developed and be come rich knowledge base.
</prevsent>
<prevsent>the technique of named entity (ne) recognition (ner) is strongly demanded to be applied in biomedical domain.
</prevsent>
</prevsection>
<citsent citstr=" C00-1030 ">
since in previous work, many ner systems have been applied successfully in newswire domain (zhou and su 2002; <papid> P02-1060 </papid>bikel et al 1999; borthwich et al. 1999), more and more explorations have been done to port existing ner system into biomedical domain (kazama et al 2002; <papid> W02-0301 </papid>takeuchi et al 2002; nobata et al 1999 and 2000; collier et al 2000; <papid> C00-1030 </papid>gaizauskas et al 2000; fukuda et al 1998; proux et al 1998).</citsent>
<aftsection>
<nextsent>however, compared with those in newswire domain, these systems havent got high performance.
</nextsent>
<nextsent>it is probably because of the following factors of biomedical ne (zhang et al 2003): 1.
</nextsent>
<nextsent>some modifiers are often before basic nes,.
</nextsent>
<nextsent>e.g. activated cell lines, and sometimes biomedical nes are very long, e.g. 47 kda sterol regulatory element binding factor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2116">
<title id=" W03-1307.xml">effective adaptation of hidden markov model based named entity recognizer for biomedical domain </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore, some constraints on the boundary category and entity category between two consecutive tags are applied to filter the invalid ne tags (zhou and su 2002).<papid> P02-1060 </papid></prevsent>
<prevsent>feature set simple deterministic features (fsd) the purpose of simple deterministic features is to capture the capitalization, digital ization and word formation information.</prevsent>
</prevsection>
<citsent citstr=" W02-2029 ">
this kind of features have been widely used in both newswire ner system, such as (zhou and su 2002), <papid> P02-1060 </papid>and biomedical ner system, such as (nobata et al 1999; gaizauskas et al. 2000; collier et al 2000; <papid> C00-1030 </papid>takeuchi and collier 2002; <papid> W02-2029 </papid>kazama et al 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>based on the characteristics of biomedical nes, we designed simple deterministic features manually.
</nextsent>
<nextsent>table 1 shows the simple deterministic features with descending order of priority.
</nextsent>
<nextsent>fsd name example comma , dot . lrb ( rrb ) lsb [ rsb ] roman digit ii greek letter beta stop word in, at atcgsequence aacaaag one digit 5 all digits 60 digitcommadigit 1,25 digitdotdigit 0.5 onecap allcaps csf caplowalpha all capmixalpha igm lowmixalpha kda alphadigitalpha h2a alpha digit t4 digitalphadigit 6c2 digit alpha 19d table 1: simple deterministic features from table 1, we can find that: 1.
</nextsent>
<nextsent>features such as comma, dot, stop word, etc..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2131">
<title id=" W03-1307.xml">effective adaptation of hidden markov model based named entity recognizer for biomedical domain </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, we reconsidered the pos tagging.
</prevsent>
<prevsent>in previous research, (kazama et al 2002) <papid> W02-0301 </papid>make use of pos information and conclude that it only slightly improves performance.</prevsent>
</prevsection>
<citsent citstr=" W00-0904 ">
moreover, (collier et al 2000; <papid> C00-1030 </papid>nobata et al 2000; <papid> W00-0904 </papid>takeuchi and collier.</citsent>
<aftsection>
<nextsent>2002) dont incorporate pos information in their systems.
</nextsent>
<nextsent>the probable reason explained by them is that since pos tagger they used is trained on newswire articles, the assigned pos tags are often incorrect in biomedical documents.
</nextsent>
<nextsent>on the whole, it can be concluded that pos information hasnt been well used in previous work.
</nextsent>
<nextsent>in our experiment, pos tagger was trained using 80% of genia v2.1 corpus (536 abstracts, 123k words) and evaluated on the rest 20% (134 abstracts, 29k words).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2147">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>one of the source languages we examine in this paper, arabic,has canonical sentence-level order of verb-subject object, which means that translation into english (with standard ordering of subject-verb-object) commonly requires motion of entire phrasal constituents, which isnot true of french-to-english translation, to cite one language pair whose characteristics have wielded great influence in the history of work on statistical machine translation.
</prevsent>
<prevsent>a key motivation for and objective of this work was to build translation model and feature space to handle the above-described phenomenon effectively.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
statistical machine translation, as pioneered by ibm(e.g. brown et al, 1993), <papid> J93-2003 </papid>is grounded in the noisy channel model.</citsent>
<aftsection>
<nextsent>and similar to the related channel problems of speech and handwriting recognition, the original smt language pair french-english exhibits relatively close linear correlation in source and target sequence.
</nextsent>
<nextsent>much common local motion that is observed for french, such as adjective-noun swapping, is adequately modeled bythe relative-position-based distortion models of the classic ibm approach.
</nextsent>
<nextsent>unfortunately, these distortion models are less effective for languages such as japanese or arabic, which have substantially different top-level sentential word orders from english, and hence longer distance constituent motion.
</nextsent>
<nextsent>wu (1997) <papid> J97-3002 </papid>and jones and havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree con stituents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2148">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>much common local motion that is observed for french, such as adjective-noun swapping, is adequately modeled bythe relative-position-based distortion models of the classic ibm approach.
</prevsent>
<prevsent>unfortunately, these distortion models are less effective for languages such as japanese or arabic, which have substantially different top-level sentential word orders from english, and hence longer distance constituent motion.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu (1997) <papid> J97-3002 </papid>and jones and havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree con stituents.</citsent>
<aftsection>
<nextsent>yamada and knight (2000), yamada and knight (2001) <papid> P01-1067 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>have effectively extended such syntactic transduction models to fully functional smt systems, based on channel model tree transducers and finite state head transducers respectively.</nextsent>
<nextsent>while these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses.in contrast, och et al (1999) <papid> W99-0604 </papid>have avoided the constraints of tree-based syntactic models and allow the relatively flat motion of empirically derived phrasal chunks,which need not adhere to traditional constituent bound aries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2149">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, these distortion models are less effective for languages such as japanese or arabic, which have substantially different top-level sentential word orders from english, and hence longer distance constituent motion.
</prevsent>
<prevsent>wu (1997) <papid> J97-3002 </papid>and jones and havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree con stituents.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
yamada and knight (2000), yamada and knight (2001) <papid> P01-1067 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>have effectively extended such syntactic transduction models to fully functional smt systems, based on channel model tree transducers and finite state head transducers respectively.</citsent>
<aftsection>
<nextsent>while these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses.in contrast, och et al (1999) <papid> W99-0604 </papid>have avoided the constraints of tree-based syntactic models and allow the relatively flat motion of empirically derived phrasal chunks,which need not adhere to traditional constituent bound aries.</nextsent>
<nextsent>our current paper takes middle path, by grounding motion in syntactic transduction, but in much flatter 2level model of syntactic analysis, based on flat embedded noun-phrases in flat sentential constituent-basedchunk sequence that can be driven by syntactic bracket ers and pos tag models rather than full parser, facilitating its transfer to lower density languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2150">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, these distortion models are less effective for languages such as japanese or arabic, which have substantially different top-level sentential word orders from english, and hence longer distance constituent motion.
</prevsent>
<prevsent>wu (1997) <papid> J97-3002 </papid>and jones and havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree con stituents.</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
yamada and knight (2000), yamada and knight (2001) <papid> P01-1067 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>have effectively extended such syntactic transduction models to fully functional smt systems, based on channel model tree transducers and finite state head transducers respectively.</citsent>
<aftsection>
<nextsent>while these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses.in contrast, och et al (1999) <papid> W99-0604 </papid>have avoided the constraints of tree-based syntactic models and allow the relatively flat motion of empirically derived phrasal chunks,which need not adhere to traditional constituent bound aries.</nextsent>
<nextsent>our current paper takes middle path, by grounding motion in syntactic transduction, but in much flatter 2level model of syntactic analysis, based on flat embedded noun-phrases in flat sentential constituent-basedchunk sequence that can be driven by syntactic bracket ers and pos tag models rather than full parser, facilitating its transfer to lower density languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2151">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>wu (1997) <papid> J97-3002 </papid>and jones and havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree con stituents.</prevsent>
<prevsent>yamada and knight (2000), yamada and knight (2001) <papid> P01-1067 </papid>and alshawi et al (2000) <papid> J00-1004 </papid>have effectively extended such syntactic transduction models to fully functional smt systems, based on channel model tree transducers and finite state head transducers respectively.</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
while these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses.in contrast, och et al (1999) <papid> W99-0604 </papid>have avoided the constraints of tree-based syntactic models and allow the relatively flat motion of empirically derived phrasal chunks,which need not adhere to traditional constituent bound aries.</citsent>
<aftsection>
<nextsent>our current paper takes middle path, by grounding motion in syntactic transduction, but in much flatter 2level model of syntactic analysis, based on flat embedded noun-phrases in flat sentential constituent-basedchunk sequence that can be driven by syntactic bracket ers and pos tag models rather than full parser, facilitating its transfer to lower density languages.
</nextsent>
<nextsent>the flatter2-level structures also better support transductions conditioned to full sentential context than do deeply embedded tree models, while retaining the empirically observed advantages of translation ordering independence of noun phrases.
</nextsent>
<nextsent>another improvement over och et aland yamada and knight is the use of the finite state machine (fsm) modelling framework (e.g. bangalore and riccardi, 2000), <papid> W00-0508 </papid>which offers the considerable advantage of flexible framework for decoding, as well as representation which is suitable for the fixed two-level phrasal modelling employed here.finally, the original cross-part-of-speech lexical coercion models presented in section 4.3.3 have related work in the primarily-syntactic coercion models utilized by dorr and habash (2002) and habash and door (2003),although their induction and modelling are quite different from the approach here.</nextsent>
<nextsent>as in other smt approaches, the primary training resource is sentence-aligned parallel bilingual corpus.we further require that each side of the corpus be part of-speech (pos) tagged and phrase chunked; our lab has previously developed techniques for rapid training of such tools (cucerzan and yarowsky, 2002).<papid> W02-2006 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2152">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> prior work.  </section>
<citcontext>
<prevsection>
<prevsent>our current paper takes middle path, by grounding motion in syntactic transduction, but in much flatter 2level model of syntactic analysis, based on flat embedded noun-phrases in flat sentential constituent-basedchunk sequence that can be driven by syntactic bracket ers and pos tag models rather than full parser, facilitating its transfer to lower density languages.
</prevsent>
<prevsent>the flatter2-level structures also better support transductions conditioned to full sentential context than do deeply embedded tree models, while retaining the empirically observed advantages of translation ordering independence of noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" W00-0508 ">
another improvement over och et aland yamada and knight is the use of the finite state machine (fsm) modelling framework (e.g. bangalore and riccardi, 2000), <papid> W00-0508 </papid>which offers the considerable advantage of flexible framework for decoding, as well as representation which is suitable for the fixed two-level phrasal modelling employed here.finally, the original cross-part-of-speech lexical coercion models presented in section 4.3.3 have related work in the primarily-syntactic coercion models utilized by dorr and habash (2002) and habash and door (2003),although their induction and modelling are quite different from the approach here.</citsent>
<aftsection>
<nextsent>as in other smt approaches, the primary training resource is sentence-aligned parallel bilingual corpus.we further require that each side of the corpus be part of-speech (pos) tagged and phrase chunked; our lab has previously developed techniques for rapid training of such tools (cucerzan and yarowsky, 2002).<papid> W02-2006 </papid></nextsent>
<nextsent>our translation experiments were carried out on two languages: arabic and french.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2153">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>the flatter2-level structures also better support transductions conditioned to full sentential context than do deeply embedded tree models, while retaining the empirically observed advantages of translation ordering independence of noun phrases.
</prevsent>
<prevsent>another improvement over och et aland yamada and knight is the use of the finite state machine (fsm) modelling framework (e.g. bangalore and riccardi, 2000), <papid> W00-0508 </papid>which offers the considerable advantage of flexible framework for decoding, as well as representation which is suitable for the fixed two-level phrasal modelling employed here.finally, the original cross-part-of-speech lexical coercion models presented in section 4.3.3 have related work in the primarily-syntactic coercion models utilized by dorr and habash (2002) and habash and door (2003),although their induction and modelling are quite different from the approach here.</prevsent>
</prevsection>
<citsent citstr=" W02-2006 ">
as in other smt approaches, the primary training resource is sentence-aligned parallel bilingual corpus.we further require that each side of the corpus be part of-speech (pos) tagged and phrase chunked; our lab has previously developed techniques for rapid training of such tools (cucerzan and yarowsky, 2002).<papid> W02-2006 </papid></citsent>
<aftsection>
<nextsent>our translation experiments were carried out on two languages: arabic and french.
</nextsent>
<nextsent>the arabic training corpus was subset of the united nations (un) parallel corpus whichis being made available by the linguistic data consortium.
</nextsent>
<nextsent>for french-english training, we used portion ofthe canadian hansards.
</nextsent>
<nextsent>both corpora utilized sentence level alignments publicly distributed by the linguistic data consortium.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2154">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>for french-english training, we used portion ofthe canadian hansards.
</prevsent>
<prevsent>both corpora utilized sentence level alignments publicly distributed by the linguistic data consortium.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
pos tagging and phrase chunking in english were done using the trained systems provided with the fntbl toolkit (ngai and florian, 2001); <papid> N01-1006 </papid>both were trained from the annotated penn treebank corpus (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>french pos tagging was done using the trained french lexical tagger also provided with the fntbl software.
</nextsent>
<nextsent>for arabic, we used colleagues pos tagger and tokenizer (clitic separation was also performed prior topos tagging), which was rapidly developed in our laboratory.
</nextsent>
<nextsent>simple regular-expression-based phrase chun kers were developed by the authors for both arabic and french, requiring less than person-day each using existing multilingual learning tools.
</nextsent>
<nextsent>a further input to our system is set of word alignment links on the parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2155">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>for french-english training, we used portion ofthe canadian hansards.
</prevsent>
<prevsent>both corpora utilized sentence level alignments publicly distributed by the linguistic data consortium.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
pos tagging and phrase chunking in english were done using the trained systems provided with the fntbl toolkit (ngai and florian, 2001); <papid> N01-1006 </papid>both were trained from the annotated penn treebank corpus (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>french pos tagging was done using the trained french lexical tagger also provided with the fntbl software.
</nextsent>
<nextsent>for arabic, we used colleagues pos tagger and tokenizer (clitic separation was also performed prior topos tagging), which was rapidly developed in our laboratory.
</nextsent>
<nextsent>simple regular-expression-based phrase chun kers were developed by the authors for both arabic and french, requiring less than person-day each using existing multilingual learning tools.
</nextsent>
<nextsent>a further input to our system is set of word alignment links on the parallel corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2156">
<title id=" W03-1002.xml">statistical machine translation using coercive two level syntactic transduction </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>these are used to compute word translation probabilities and phrasal alignments.
</prevsent>
<prevsent>the word alignments can in principle come from any source: dictionary, specialized alignment program, or another smt system.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we used alignments generated by giza++ (och and ney, 2000) <papid> P00-1056 </papid>by running it in both directions (e.g., arabic ? english and english ? arabic) on our parallel corpora.</citsent>
<aftsection>
<nextsent>the union of these bidirectional alignments was used to compute cross-language phrase correspondences by simple majority voting, and for purposes of estimating word translation probabilities, each link in this union was treated as an independent instance of word translation.
</nextsent>
<nextsent>now we turn to detailed description of the proposed translation model.
</nextsent>
<nextsent>the exposition will give formal specification and also will follow running example throughout, using one of the actual arabic test set sentences.
</nextsent>
<nextsent>this example, its gloss, system translation and reference human translation are shown in table 1.the translation model (tm) we describe is trained directly from counts in the data, and is direct model, nota noisy channel model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2160">
<title id=" W03-1210.xml">automatic detection of causal relations for question answering </title>
<section> previous work in computational.  </section>
<citcontext>
<prevsection>
<prevsent>many previous studies have attempted to extract implicit inter-sentential cause-effect relations from text using knowledge-based inferences (joskowiscz et al 1989), (kaplan 1991).
</prevsent>
<prevsent>these studies were based on hand-coded, domain-specific knowledge bases difficult to scale up for realistic applications.
</prevsent>
</prevsection>
<citsent citstr=" P00-1043 ">
more recently, other researchers (garcia 1997),(khoo et al 2000) <papid> P00-1043 </papid>used linguistic patterns to identify explicit causation relations in text without any knowledge-based inference.</citsent>
<aftsection>
<nextsent>garcia used french texts to capture causation relationships through linguistic indicators organized in semantic model which classifies causative verbal patterns.
</nextsent>
<nextsent>she found 25 causal relations with an approach based on the force dynamics?
</nextsent>
<nextsent>of leonard talmy claiming precision of 85%.khoo at al. used predefined verbal linguistic patterns to extract cause-effect information from business and medical newspaper texts.
</nextsent>
<nextsent>they presented simple computational method based on set of partially parsed linguistic patterns that usually indicate the presence of causal relationship.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2162">
<title id=" W03-1210.xml">automatic detection of causal relations for question answering </title>
<section> previous work in computational.  </section>
<citcontext>
<prevsection>
<prevsent>according to the philosophy researcher jaegwon kim (kim 1993), any discussion of causation implies an onto logical framework of entities among which causal relations are to hold,and also an accompanying logical and semanti cal framework in which these entities can be talked about?.
</prevsent>
<prevsent>he argues that the entities that represent either causes or effects are often events, but also conditions, states, phenomena, processes, and sometimes even facts, and that coherent causal talk is possible only within coherent onto logical framework of such states of affairs.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
many researchers ((blaheta and charniak 2000), (<papid> A00-2031 </papid>gildea and jurafsky 2000), <papid> P00-1065 </papid>showed that lexical and syntactic information is very useful for predicate argument recognition tasks, such as semantic roles.</citsent>
<aftsection>
<nextsent>however, lexical and syntactic information alone is not sufficient for the detection of complex semantic relations, such as cause.based on these consider ents and on our observations of the english texts, we selected list of 19 features which are divided here into two categories: lexical and semantic features.the lexical feature is represented by the causation verb in the pattern considered.
</nextsent>
<nextsent>as verb senses in wordnet are fine grained providing large list of semantic hierarchies the verb can belong to, we decided to use only the lexical information the verb provides.
</nextsent>
<nextsent>the values of this feature are represented by the 60 verbs detected with the procedure described in section 4.1.
</nextsent>
<nextsent>this feature is very important, as our intention here is to capture the semantic information brought by the verb in combination with the subject and object noun phrases that attach to it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2164">
<title id=" W03-1210.xml">automatic detection of causal relations for question answering </title>
<section> previous work in computational.  </section>
<citcontext>
<prevsection>
<prevsent>according to the philosophy researcher jaegwon kim (kim 1993), any discussion of causation implies an onto logical framework of entities among which causal relations are to hold,and also an accompanying logical and semanti cal framework in which these entities can be talked about?.
</prevsent>
<prevsent>he argues that the entities that represent either causes or effects are often events, but also conditions, states, phenomena, processes, and sometimes even facts, and that coherent causal talk is possible only within coherent onto logical framework of such states of affairs.
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
many researchers ((blaheta and charniak 2000), (<papid> A00-2031 </papid>gildea and jurafsky 2000), <papid> P00-1065 </papid>showed that lexical and syntactic information is very useful for predicate argument recognition tasks, such as semantic roles.</citsent>
<aftsection>
<nextsent>however, lexical and syntactic information alone is not sufficient for the detection of complex semantic relations, such as cause.based on these consider ents and on our observations of the english texts, we selected list of 19 features which are divided here into two categories: lexical and semantic features.the lexical feature is represented by the causation verb in the pattern considered.
</nextsent>
<nextsent>as verb senses in wordnet are fine grained providing large list of semantic hierarchies the verb can belong to, we decided to use only the lexical information the verb provides.
</nextsent>
<nextsent>the values of this feature are represented by the 60 verbs detected with the procedure described in section 4.1.
</nextsent>
<nextsent>this feature is very important, as our intention here is to capture the semantic information brought by the verb in combination with the subject and object noun phrases that attach to it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2167">
<title id=" W03-0504.xml">summarization of noisy documents a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, gotoh andrenals propose finite state modeling approach to extract sentence boundary information from text and audio sources, using both n-gram and pause duration information (gotoh and renals, 2000).
</prevsent>
<prevsent>they found that precision and recall of over 70% could be achieved by combining both kinds of features.
</prevsent>
</prevsection>
<citsent citstr=" H01-1034 ">
palmer and ostendorf describe an approach for improving named entity extraction by explicitly modeling speech recognition errors through the use of statistics annotated with confidence scores (palmerand ostendorf, 2001).<papid> H01-1034 </papid></citsent>
<aftsection>
<nextsent>hori and furui summarize broadcast news speech by extracting words from automatic transcripts using word significance measure, confidence score, linguistic likelihood, and word concatenation probability (hori and furui, 2001).
</nextsent>
<nextsent>there has been much less work, however, in the case of noise induced by optical character recognition.
</nextsent>
<nextsent>early papers by taghva, et al show that moderate error rate shave little impact on the effectiveness of traditional information retrieval measures (taghva et al, 1996a; taghva et al, 1996b), but this conclusion does not seem to applyto the task of summarization.
</nextsent>
<nextsent>miller, et al study the performance of named entity extraction under variety of scenarios involving both asr and ocr output (miller et al., 2000), <papid> A00-1044 </papid>although speech is their primary interest.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2168">
<title id=" W03-0504.xml">summarization of noisy documents a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there has been much less work, however, in the case of noise induced by optical character recognition.
</prevsent>
<prevsent>early papers by taghva, et al show that moderate error rate shave little impact on the effectiveness of traditional information retrieval measures (taghva et al, 1996a; taghva et al, 1996b), but this conclusion does not seem to applyto the task of summarization.
</prevsent>
</prevsection>
<citsent citstr=" A00-1044 ">
miller, et al study the performance of named entity extraction under variety of scenarios involving both asr and ocr output (miller et al., 2000), <papid> A00-1044 </papid>although speech is their primary interest.</citsent>
<aftsection>
<nextsent>they found that by training their system on both clean and noisy input material, performance degraded linearly as afunction of word error rates.
</nextsent>
<nextsent>they also note in their pa per: to our knowledge, no other information extraction technology has been applied to ocr material?
</nextsent>
<nextsent>(pg.
</nextsent>
<nextsent>322).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2169">
<title id=" W03-0504.xml">summarization of noisy documents a pilot study </title>
<section> results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>ocr.clean 0.990 0.882 0.869 0.506 0.963 0.874 ocr.light 0.897 0.829 0.556 0.668 0.731 0.679 ocr.dark 0.934 0.739 0.607 0.539 0.776 0.608 ocr.fax 0.969 0.939 0.781 0.561 0.888 0.879 ocr.skew 0.991 0.879 0.961 0.496 0.963 0.869 3.2 sentence boundary errors.
</prevsent>
<prevsent>since most summarization systems relyon sentence extraction, it is important to identify sentence boundariescorrectly.
</prevsent>
</prevsection>
<citsent citstr=" J97-2002 ">
for clean text, the reported accuracy of sentence boundary detection is usually above 95% (palmer and hearst, 1997; <papid> J97-2002 </papid>reyner and ratnaparkhi, 1997; riley, 1989).<papid> H89-2048 </papid></citsent>
<aftsection>
<nextsent>however, detecting sentence boundaries in noisy documents is serious challenge since punctuation and capitalization, which are important features in sentence boundary detection, are unreliable in noisy documents.
</nextsent>
<nextsent>as we have just noted, punctuation errors arise frequently in the ocr output of degraded page images.
</nextsent>
<nextsent>we tested two tokenizers: one is rule-based system and the other is decision tree system.
</nextsent>
<nextsent>the experimental results show that for the clean text, the two systems perform almost equally well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2170">
<title id=" W03-0504.xml">summarization of noisy documents a pilot study </title>
<section> results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>ocr.clean 0.990 0.882 0.869 0.506 0.963 0.874 ocr.light 0.897 0.829 0.556 0.668 0.731 0.679 ocr.dark 0.934 0.739 0.607 0.539 0.776 0.608 ocr.fax 0.969 0.939 0.781 0.561 0.888 0.879 ocr.skew 0.991 0.879 0.961 0.496 0.963 0.869 3.2 sentence boundary errors.
</prevsent>
<prevsent>since most summarization systems relyon sentence extraction, it is important to identify sentence boundariescorrectly.
</prevsent>
</prevsection>
<citsent citstr=" H89-2048 ">
for clean text, the reported accuracy of sentence boundary detection is usually above 95% (palmer and hearst, 1997; <papid> J97-2002 </papid>reyner and ratnaparkhi, 1997; riley, 1989).<papid> H89-2048 </papid></citsent>
<aftsection>
<nextsent>however, detecting sentence boundaries in noisy documents is serious challenge since punctuation and capitalization, which are important features in sentence boundary detection, are unreliable in noisy documents.
</nextsent>
<nextsent>as we have just noted, punctuation errors arise frequently in the ocr output of degraded page images.
</nextsent>
<nextsent>we tested two tokenizers: one is rule-based system and the other is decision tree system.
</nextsent>
<nextsent>the experimental results show that for the clean text, the two systems perform almost equally well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2171">
<title id=" W03-1715.xml">abductive explanation based learning improves parsing accuracy and efficiency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>rule-based approaches use abstract category labels.
</prevsent>
<prevsent>1this research has been carried out within logos gaiasproject, which integrates nlp technologies into internet based natural language learning platform (streiter et al, 2003).example-based parsing generalizes examples during compilation time, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P98-1022 ">
(bod and kaplan, 1998), <papid> P98-1022 </papid>or performs similarity-based fuzzy match duringruntime (zavrel and daelemans, 1997).</citsent>
<aftsection>
<nextsent>both techniques may be computationally demanding, their effect on parsing however is quite different, c.f.
</nextsent>
<nextsent>(stre iter, 2002a).
</nextsent>
<nextsent>explanation-based learning (ebl) is method tospeed-up rule-based parsing via the caching of examples.
</nextsent>
<nextsent>ebl however trades speed for accuracy.for many systems, small loss inaccuracy is accept able if an order of magnitude less computing timeis required.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2172">
<title id=" W03-1715.xml">abductive explanation based learning improves parsing accuracy and efficiency </title>
<section> experiments in ebl.  </section>
<citcontext>
<prevsection>
<prevsent>then the parsing accuracy and speed is tested against the same training corpus ( g!f = qb = ?\g  m$`rn?
</prevsent>
<prevsent>9i?`_ria; (recall,precision,f-score,time)).
</prevsent>
</prevsection>
<citsent citstr=" W00-1205 ">
sections of the chinese sinica treebank (huanget al, 2000) <papid> W00-1205 </papid>are used as seed-treebank and gold standard for parsing evaluation.</citsent>
<aftsection>
<nextsent>seed-corpora range between 1.000 and 20.000 trees.
</nextsent>
<nextsent>we train them to the parser octopus (streiter, 2002a).
</nextsent>
<nextsent>this parser integrates memory- deduction- and abduction-based parsing in hierarchy of preferences, starting from 1 memory-based parsing, 2 non-recursive deductive parsing, 3 recursive deductive parsing and 5 finally abductive parsing (fig.
</nextsent>
<nextsent>2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2173">
<title id=" W03-1715.xml">abductive explanation based learning improves parsing accuracy and efficiency </title>
<section> experiments in ebl.  </section>
<citcontext>
<prevsection>
<prevsent>// e;s?  88?
</prevsent>
<prevsent>. the corpus used is subset of.
</prevsent>
</prevsection>
<citsent citstr=" C92-4194 ">
the 5 million word sinica corpus (huang and chen, 1992).<papid> C92-4194 </papid>for every fi w+v the parser produces one parse tree zx  fih =  and an explanation.</citsent>
<aftsection>
<nextsent>the explanation has the form of derivation tree in tags, c.f (joshi, 2003).
</nextsent>
<nextsent>the deduction and abduction steps are visible in the explanation.
</nextsent>
<nextsent>filters apply on the explanation and create sub-corpora that belong to one inference type.
</nextsent>
<nextsent>the first filter requires the explanation to contain only one non-recursive deduction, i.e. only parsing step 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2174">
<title id=" W03-0503.xml">multi document summarization using off the shelf compression software </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multi document summarizationa standard way for producing summaries of text documents is sentence extraction.
</prevsent>
<prevsent>in sentence extraction, the summary of document (or cluster of related docu ments) is subset of the sentences in the original text (mani, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
a number of techniques for choosing the right sentences to extract have been proposed in the literature, ranging from word counts (luhn, 1958), key phrases(edmundson, 1969), naive bayesian classification (ku piec et al , 1995), lexical chains (barzilay and elhadad, 1997), <papid> W97-0703 </papid>topic signatures (hovy and lin, 1999) and cluster centro ids (radev et al , 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>most techniques for sentence extraction compute score for each individual sentence, although some recent work has started to pay attention to interactions betweensentences.
</nextsent>
<nextsent>on the other hand, and particularly in multi document summarization, some sentences may be redundant in the presence of others and such redundancy should lead to lower score for each sentence proportional to the degree of overlap with other sentences in the summary.
</nextsent>
<nextsent>the maximal marginal relevance (mmr) method (carbonell and goldstein, 1998) does just that.in this paper, we are taking the idea of penalizing redundancy for multi-document summaries further.
</nextsent>
<nextsent>wewant to explore existing techniques for identifying redundant information and using them for producing better summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2175">
<title id=" W03-0503.xml">multi document summarization using off the shelf compression software </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>multi document summarizationa standard way for producing summaries of text documents is sentence extraction.
</prevsent>
<prevsent>in sentence extraction, the summary of document (or cluster of related docu ments) is subset of the sentences in the original text (mani, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
a number of techniques for choosing the right sentences to extract have been proposed in the literature, ranging from word counts (luhn, 1958), key phrases(edmundson, 1969), naive bayesian classification (ku piec et al , 1995), lexical chains (barzilay and elhadad, 1997), <papid> W97-0703 </papid>topic signatures (hovy and lin, 1999) and cluster centro ids (radev et al , 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>most techniques for sentence extraction compute score for each individual sentence, although some recent work has started to pay attention to interactions betweensentences.
</nextsent>
<nextsent>on the other hand, and particularly in multi document summarization, some sentences may be redundant in the presence of others and such redundancy should lead to lower score for each sentence proportional to the degree of overlap with other sentences in the summary.
</nextsent>
<nextsent>the maximal marginal relevance (mmr) method (carbonell and goldstein, 1998) does just that.in this paper, we are taking the idea of penalizing redundancy for multi-document summaries further.
</nextsent>
<nextsent>wewant to explore existing techniques for identifying redundant information and using them for producing better summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2177">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>without question type, that is, the result of question classification, it would be much more difficult or even nearly infeasible to select correct answers from among the possible answer candidates, which would necessarily be all of the noun phrases or named entities in the texts.
</prevsent>
<prevsent>question classification provides the benefit of powerful restriction that reduces to practical number of the answer candidates that should be evaluated in the answer selection process.
</prevsent>
</prevsection>
<citsent citstr=" W01-1203 ">
this work develops machine learning approach to question classification (harabagiu et al, 2000; hermjakob, 2001; <papid> W01-1203 </papid>li and roth, 2002).<papid> C02-1150 </papid></citsent>
<aftsection>
<nextsent>we use the hierarchical directed acyclic graph (hdag) kernel (suzuki et al, 2003), <papid> P03-1005 </papid>which is suited to handle structured natural language data.</nextsent>
<nextsent>it can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2178">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>without question type, that is, the result of question classification, it would be much more difficult or even nearly infeasible to select correct answers from among the possible answer candidates, which would necessarily be all of the noun phrases or named entities in the texts.
</prevsent>
<prevsent>question classification provides the benefit of powerful restriction that reduces to practical number of the answer candidates that should be evaluated in the answer selection process.
</prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
this work develops machine learning approach to question classification (harabagiu et al, 2000; hermjakob, 2001; <papid> W01-1203 </papid>li and roth, 2002).<papid> C02-1150 </papid></citsent>
<aftsection>
<nextsent>we use the hierarchical directed acyclic graph (hdag) kernel (suzuki et al, 2003), <papid> P03-1005 </papid>which is suited to handle structured natural language data.</nextsent>
<nextsent>it can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2181">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>question classification provides the benefit of powerful restriction that reduces to practical number of the answer candidates that should be evaluated in the answer selection process.
</prevsent>
<prevsent>this work develops machine learning approach to question classification (harabagiu et al, 2000; hermjakob, 2001; <papid> W01-1203 </papid>li and roth, 2002).<papid> C02-1150 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
we use the hierarchical directed acyclic graph (hdag) kernel (suzuki et al, 2003), <papid> P03-1005 </papid>which is suited to handle structured natural language data.</citsent>
<aftsection>
<nextsent>it can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors.
</nextsent>
<nextsent>this framework is useful for question classification because the works of (li and roth, 2002; <papid> C02-1150 </papid>suzuki et al, 2002<papid> C02-1119 </papid>a) showed that richer information, such as structural and semantical information inside given question, improves the question classification performance over using the information of just simple key terms.in section 2, we present the question classification problem.</nextsent>
<nextsent>in section 3, we explain our proposed method for question classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2183">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we use the hierarchical directed acyclic graph (hdag) kernel (suzuki et al, 2003), <papid> P03-1005 </papid>which is suited to handle structured natural language data.</prevsent>
<prevsent>it can handle structures within texts as the features of texts without converting the structures to the explicit representation of numerical feature vectors.</prevsent>
</prevsection>
<citsent citstr=" C02-1119 ">
this framework is useful for question classification because the works of (li and roth, 2002; <papid> C02-1150 </papid>suzuki et al, 2002<papid> C02-1119 </papid>a) showed that richer information, such as structural and semantical information inside given question, improves the question classification performance over using the information of just simple key terms.in section 2, we present the question classification problem.</citsent>
<aftsection>
<nextsent>in section 3, we explain our proposed method for question classification.
</nextsent>
<nextsent>finally, in section 4, we describe our experiment and results.
</nextsent>
<nextsent>question classification is defined as task that maps given question to more than one of  question types (classes).
</nextsent>
<nextsent>in the general concept of qa systems, the result of question classification is used in downstream process, answer selection, to select correct answer from among the large number of answer candidates that are extracted from the source documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2186">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> question classification.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of the trec qa-track, most system shave their own question taxonomy, and these are reconstructed year by year.
</prevsent>
<prevsent>for example, (ittycheriah et al, 2001) defined 31 original question types in two levels of hierarchical structure.
</prevsent>
</prevsection>
<citsent citstr=" H01-1069 ">
(harabagiu et al., 2000) also defined large hierarchical question taxonomy, and (hovy et al, 2001) <papid> H01-1069 </papid>defined 141 question types of hierarchical question taxonomy.</citsent>
<aftsection>
<nextsent>within all of these taxonomies, question types are defined from the viewpoint of the target intention ofthe given questions, and they have hierarchical structures, even though these question taxonomies are defined by different researchers.
</nextsent>
<nextsent>this because the purpose of question classification is to reduce the large number of answer candidates by restricting the target intention via question types.
</nextsent>
<nextsent>moreover, it is very useful to handle question taxonomy constructed in hierarchical structure in the downstream processes.
</nextsent>
<nextsent>thus, question types should be the target intention and constructed in hierarchical structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2198">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> government 38.  </section>
<citcontext>
<prevsection>
<prevsent>words, named entities and semantic information (w+n+s) the words were analyzed in basic form, and the semantic information was obtained from the goi taikei?
</prevsent>
<prevsent>(ikehara et al, 1997), which is similar to wordnet in english.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
words, chunks and their relations in the texts were analyzed by cabocha (kudoand matsumoto, 2002), <papid> W02-2016 </papid>and named entities were analyzed by the svm-based ne tagger (isozaki and kazawa, 2002).<papid> C02-1054 </papid></citsent>
<aftsection>
<nextsent>note that even when using the same feature sets,method of how to construct feature spaces are entirely different between hdag and bow.
</nextsent>
<nextsent>4.5 evaluation method.
</nextsent>
<nextsent>we evaluated the 5011 questions by using fivefold cross-validation and used the following two approaches to evaluate the performance.table 3: results of question classification experiment by five-fold cross-validation macc w+n w+s w+n+s hdag-svm 0.862 0.871 0.877 0.882 bow(d2)-svm 0.841 0.847 0.847 0.856 bow(d1)-svm 0.839 0.843 0.837 0.851 bow-snow 0.760 0.774 0.800 0.808 qacc w+n w+s w+n+s hdag-svm 0.730 0.736 0.742 0.749 bow(d2)-svm 0.678 0.691 0.686 0.704 bow(d1)-svm 0.679 0.686 0.671 0.694 bow-snow 0.562 0.573 0.614 0.626 1.
</nextsent>
<nextsent>average accuracy of each one-vs-rest model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2199">
<title id=" W03-1208.xml">question classification using hdag kernel </title>
<section> government 38.  </section>
<citcontext>
<prevsection>
<prevsent>words, named entities and semantic information (w+n+s) the words were analyzed in basic form, and the semantic information was obtained from the goi taikei?
</prevsent>
<prevsent>(ikehara et al, 1997), which is similar to wordnet in english.
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
words, chunks and their relations in the texts were analyzed by cabocha (kudoand matsumoto, 2002), <papid> W02-2016 </papid>and named entities were analyzed by the svm-based ne tagger (isozaki and kazawa, 2002).<papid> C02-1054 </papid></citsent>
<aftsection>
<nextsent>note that even when using the same feature sets,method of how to construct feature spaces are entirely different between hdag and bow.
</nextsent>
<nextsent>4.5 evaluation method.
</nextsent>
<nextsent>we evaluated the 5011 questions by using fivefold cross-validation and used the following two approaches to evaluate the performance.table 3: results of question classification experiment by five-fold cross-validation macc w+n w+s w+n+s hdag-svm 0.862 0.871 0.877 0.882 bow(d2)-svm 0.841 0.847 0.847 0.856 bow(d1)-svm 0.839 0.843 0.837 0.851 bow-snow 0.760 0.774 0.800 0.808 qacc w+n w+s w+n+s hdag-svm 0.730 0.736 0.742 0.749 bow(d2)-svm 0.678 0.691 0.686 0.704 bow(d1)-svm 0.679 0.686 0.671 0.694 bow-snow 0.562 0.573 0.614 0.626 1.
</nextsent>
<nextsent>average accuracy of each one-vs-rest model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2203">
<title id=" W02-1013.xml">from words to corpora recognizing translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental results are shown on two tasks: search for matching thirty-word segments in corpus where some segments are mutual translations, and classification of candidate pairs of web pages that may or may not be translations of each other.
</prevsent>
<prevsent>the latter results compare competitively with previous, document-structure-based approaches to the same problem.
</prevsent>
</prevsection>
<citsent citstr=" H94-1028 ">
as in most areas of natural language processing, recent approaches to machine translation have turned increasingly to statistical modeling of the phenomenon (translation models) (bergeret al , 1994).<papid> H94-1028 </papid></citsent>
<aftsection>
<nextsent>such models are learned automatically from data, typically parallel corpora: texts in two or more languages that are mutual translations.
</nextsent>
<nextsent>as computational resources have become more powerful and less expensive, the task of training translation models has become feasible (al-onaizan et al , 1999), as has the task of translating (or decoding?)
</nextsent>
<nextsent>text using such models (germann et al , 2001).<papid> P01-1030 </papid></nextsent>
<nextsent>however,the success of the statistical approach to translation (and also to other multilingual applications that utilize parallel text) hangs crucially on the quality, quantity, and diversity of data used in parameter estimation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2204">
<title id=" W02-1013.xml">from words to corpora recognizing translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such models are learned automatically from data, typically parallel corpora: texts in two or more languages that are mutual translations.
</prevsent>
<prevsent>as computational resources have become more powerful and less expensive, the task of training translation models has become feasible (al-onaizan et al , 1999), as has the task of translating (or decoding?)
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
text using such models (germann et al , 2001).<papid> P01-1030 </papid></citsent>
<aftsection>
<nextsent>however,the success of the statistical approach to translation (and also to other multilingual applications that utilize parallel text) hangs crucially on the quality, quantity, and diversity of data used in parameter estimation.
</nextsent>
<nextsent>if translation is generative process, then one might consider its reverse process of recognition: given two documents, might it be determined fully automatically whether they are translations of each other the ability to detect translations of document has numerous applications.
</nextsent>
<nextsent>the most obvious is as means to build parallel corpus from set of multilingual documents that contains some translation pairs.
</nextsent>
<nextsent>examples include mining the world-wide web for parallel text(resnik, 1999; <papid> P99-1068 </papid>nie et al , 1999; ma and liberman, 1999) and building parallel corpora from comparable corpora such as multilingual collections of news reports.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2205">
<title id=" W02-1013.xml">from words to corpora recognizing translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if translation is generative process, then one might consider its reverse process of recognition: given two documents, might it be determined fully automatically whether they are translations of each other the ability to detect translations of document has numerous applications.
</prevsent>
<prevsent>the most obvious is as means to build parallel corpus from set of multilingual documents that contains some translation pairs.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
examples include mining the world-wide web for parallel text(resnik, 1999; <papid> P99-1068 </papid>nie et al , 1999; ma and liberman, 1999) and building parallel corpora from comparable corpora such as multilingual collections of news reports.</citsent>
<aftsection>
<nextsent>another use of translation detection might be as an aid in alignment tasks at any level.
</nextsent>
<nextsent>for example, consider the task of aligning np chunks (and perhaps also the extra-np material) in an np-bracketed parallel corpus; chunk-level similarity score (fluhr et al , 2000) built from word-level model could be incorporated into framework that involves bootstrapping more complex models of translation from simpler ones (berger etal., 1994).<papid> H94-1028 </papid></nextsent>
<nextsent>finally, reliable cross-lingual duplicate detection might improve performance in best multilingual information retrieval systems; at the same time, by detecting the existence of translation in multilingual corpus, the cost of translating document of interest is eliminated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2209">
<title id=" W02-1013.xml">from words to corpora recognizing translation </title>
<section> quantifying similarity.  </section>
<citcontext>
<prevsection>
<prevsent>the next step is to compute the probability ofthe most probable sequence that could have accounted for the two texts.
</prevsent>
<prevsent>all permutations ofa given link sequence will have the same probability (since the links are generated independently), so the order of the sequence is not important.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
as noted by melamed (2000), <papid> J00-2004 </papid>under the assumption that the quality of link collection is the sum of the quality of the links, then this problem of finding the best set oflinks is equivalent to the maximum-weighted bi partite matching (mwbm) problem: given weighted bipartite graph = (v1 ? v2, e) with |v1| = |v2| and edge weights ci,j(i ? v1, ? v2), 1i use the term text?</citsent>
<aftsection>
<nextsent>to refer to piece of text of any length.find matching ? such that each vertex has at most one edge in , and ? em ci,jis maximized.
</nextsent>
<nextsent>the fastest known mwbm algorithm runs in o(ve + v2 log v) time (ahuja et al , 1993).
</nextsent>
<nextsent>applied to this problem, that is o(max(|x|, |y |)3).
</nextsent>
<nextsent>the similarity score should be high when many of the link tokens in the best link collection do not involve null tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2223">
<title id=" W03-1119.xml">a sentence reduction using syntax control </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mani and maybury also present process of writing reduced sentence by reversing the original sentence with set of revised rules to improve the performance of summarization.
</prevsent>
<prevsent>(inderject mani and mark maybury, 1999).
</prevsent>
</prevsection>
<citsent citstr=" A00-1043 ">
jing and mckeown(h. jing, 2000) <papid> A00-1043 </papid>studied new method to remove extraneous phrase from sentences by using multiple source of knowledge to decide which phrase in the sentences can be removed.</citsent>
<aftsection>
<nextsent>the multiple sources include syntactic knowledge, context information and statistic computed from corpus that consists of examples written by human professional.
</nextsent>
<nextsent>their method prevented removing some phrases that were relative to its context around and produced grammatical sentence.
</nextsent>
<nextsent>recently, knight and marcu(k.knight andd.marcu, 2002) demonstrated two methods for sentence compression problem, which are similar to sentence reduction one.
</nextsent>
<nextsent>they devised both noisy channel and decision tree approach to the problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2224">
<title id=" W03-1119.xml">a sentence reduction using syntax control </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the noisy-channel framework has been used in many applications, including speech recognition, machine translation, and information retrieval.
</prevsent>
<prevsent>the decision tree approach has been used in parsing sentence.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
(d. magerman, 1995)(<papid> P95-1037 </papid>ulf hermijakob andj.mooney, 1997) to define the rhetorical of text documents (daniel marcu, 1999).<papid> P99-1047 </papid></citsent>
<aftsection>
<nextsent>most of the previous methods only produce short sentence whose word order is the same as that of the original sentence, and in the same language, e.g., english.
</nextsent>
<nextsent>when nonnative speaker reduce long sentence in foreign language, they usually try to link the meaning of words within the original sentence into meanings in their language.
</nextsent>
<nextsent>in addition, in some cases, the reduced sentence and the original sentence had their word order are difference.
</nextsent>
<nextsent>therefore, two reduced sentences are performed by non-nativespeaker, one is the reduced sentence in foreign language and another is in their language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2225">
<title id=" W03-1119.xml">a sentence reduction using syntax control </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the noisy-channel framework has been used in many applications, including speech recognition, machine translation, and information retrieval.
</prevsent>
<prevsent>the decision tree approach has been used in parsing sentence.
</prevsent>
</prevsection>
<citsent citstr=" P99-1047 ">
(d. magerman, 1995)(<papid> P95-1037 </papid>ulf hermijakob andj.mooney, 1997) to define the rhetorical of text documents (daniel marcu, 1999).<papid> P99-1047 </papid></citsent>
<aftsection>
<nextsent>most of the previous methods only produce short sentence whose word order is the same as that of the original sentence, and in the same language, e.g., english.
</nextsent>
<nextsent>when nonnative speaker reduce long sentence in foreign language, they usually try to link the meaning of words within the original sentence into meanings in their language.
</nextsent>
<nextsent>in addition, in some cases, the reduced sentence and the original sentence had their word order are difference.
</nextsent>
<nextsent>therefore, two reduced sentences are performed by non-nativespeaker, one is the reduced sentence in foreign language and another is in their language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2226">
<title id=" W03-1313.xml">encoding biomedical resources in tei the case of the genia corpus </title>
<section> characteristics of biomedical texts.  </section>
<citcontext>
<prevsection>
<prevsent>as all other levels of linguistic markup make direct or direct reference to the token stream of the text, so if this is incorrect, errors will propagate to all other annotations.it is also interesting to note that current annotation practice is more and more leaning toward stand off markup, i.e., annotations that are separated from the primary data (text) and make reference to it only via pointers.
</prevsent>
<prevsent>however, it is beneficial to have some markup in the primary data to which it is possible to refer, and this markup is, almost exclusivelly, that of tokens; see e.g., (freese et al , 2003).
</prevsent>
</prevsection>
<citsent citstr=" W02-1706 ">
version v1.1 of genia has been also annotated with ltg tools (grover et al , 2002).<papid> W02-1706 </papid></citsent>
<aftsection>
<nextsent>in short, the corpus is token ised, and then part-of-speech tagged with two taggers, each one using different tagset, and the nouns and verbs lemmatised.
</nextsent>
<nextsent>additionally,the deverbal nominalisations are assigned their verbal stems.
</nextsent>
<nextsent>the conversion to tei is also able to handle this additional markup, by using the tei.analysis module.
</nextsent>
<nextsent>the word and punctuation tokens are encode das w? and c? elements respectively, which are further marked with type and lemma and the locally defined c1, c2 and vstem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2227">
<title id=" W03-1729.xml">sys trans chinese word segmentation </title>
<section> discussion of the bakeoff.  </section>
<citcontext>
<prevsection>
<prevsent>although the ranking of the systran segmenter is different in the four open tracks, sys trans segmentation performance is quite comparable across the four corpora.
</prevsent>
<prevsent>this is to be compared to the scores obtained by other participants, where good performance was typically obtained on one corpus only.
</prevsent>
</prevsection>
<citsent citstr=" W03-1719 ">
systran scores for the 4 tracks are shown in table 3 (sproat and emerson, 2003).<papid> W03-1719 </papid></citsent>
<aftsection>
<nextsent>track p roov riv aso 0.915 0.894 0.904 0.426 0.926 ctbo 0.891 0.877 0.884 0.733 0.925 hko 0.898 0.860 0.879 0.616 0.920 pko 0.905 0.869 0.886 0.503 0.934 table 3.
</nextsent>
<nextsent>sys trans scores in the bakeoff 3.2 discussions.
</nextsent>
<nextsent>the segmentation differences between the reference corpora and sys trans results are further analyzed.
</nextsent>
<nextsent>table 4 shows the partition of divergences between oas, cas-t, and cas-r strings:3 total same oas cas-t cas-r aso 11,985 10,970 76 448 491 ctbo 39,922 35,561 231 2,419 1,711 hko 34,959 31,397 217 1,436 1,909 pko 17,194 15,554 82 615 943 table 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2228">
<title id=" W02-1815.xml">combining classifiers for chinese word segmentation </title>
<section> combining classifiers for.  </section>
<citcontext>
<prevsection>
<prevsent>compared with dictionary based approaches, machine-learning approaches have the advantage of not needing dictionary and thus are more suitable for use on naturally occurring chinese text.
</prevsent>
<prevsent>in this paper we report results of supervised machine-learning approach towards chinese word segmentation that combines two fairly standard machine learningmodels.we show that this approach is very promising compared with dictionary-based approaches as well as other machine-learning approaches that have been reported in the literature.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
chinesewordsegmentation thetwomachine-learningmodelsweuseinthis work are the maximum entropy model (ratnaparkhi 1996) <papid> W96-0213 </papid>and the error-driven transformation-based learning model (brill 1994).weusetheformerasthemainworkhorse and the latter to correct some of the errors producedbytheformer.</citsent>
<aftsection>
<nextsent>2.1reformulatingwordsegmentation asataggingproblem before we apply the machine-learning algorithms we first convert the manually segmented words in the corpus into tagged sequence of chinese characters.
</nextsent>
<nextsent>to do this, we tageachcharacterwithoneofthefourtags,ll, rr, mm and lr, depending on its position withinaword.itistaggedllifitoccursonthe leftboundaryofaword,and formsawordwith thecharacter(s)onitsright.
</nextsent>
<nextsent>it is taggedrrif it occurs on the right boundary of word, and formsawordwith thecharacter(s)on its left.
</nextsent>
<nextsent>it istaggedmmifitoccursinthemiddleofaword.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2230">
<title id=" W02-1815.xml">combining classifiers for chinese word segmentation </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>in the third experiment we combined the maximum entropy model with the error-driven transformation based model.
</prevsent>
<prevsent>we used the error-driven transformation-based model to learn set of rules to correct the errors produced by the maximumentropymodel.thedataweusedare fromthepennchinesetreebank(xia etal.
</prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
2000, xue et al. 2002) <papid> C02-1145 </papid>and they consist of xinhua newswire articles.</citsent>
<aftsection>
<nextsent>we took 250,389 words (426,292charactersor hanzi)worthofmanually segmented data and divided them into two chunks.
</nextsent>
<nextsent>the first chunk has 237,791 words (404,680 chinese characters) and is used as training data.
</nextsent>
<nextsent>the second chunk has 12,598 words (21,612characters)and isusedas testing data.
</nextsent>
<nextsent>these data are used in all three of our experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2231">
<title id=" W02-1815.xml">combining classifiers for chinese word segmentation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>our accuracy is much higher that those reported in hockenmaier andbrew (1998) andxue (2001), who used error-driven transformation-based learning to learn set of n-gram rules to do seriesofmergeandsplitoperationsondatafrom xinhuanews,thesamedatasourceasours.
</prevsent>
<prevsent>the results they reported are 87.9% (trained on 100,000 words) and 90.2% (trained on 80,000 words) respectively, measured by the balanced f-score.
</prevsent>
</prevsection>
<citsent citstr=" J00-3004 ">
using statistical model called prediction by partial matching (ppm), teahan et al (2000) <papid> J00-3004 </papid>reported significantly better result.themodel was trained on million words fromguo jin mandarinchinesephcorpusand tested on five 500-segmentfiles.thereportedf-scoresareina range between 89.4% and 98.6%, averaging 94.4%.</citsent>
<aftsection>
<nextsent>since the data are also from xinhua newswire, some comparison can be made between our results and this model.
</nextsent>
<nextsent>with less training data, our results are slightly higher (by 0.48%) when using just the maximum entropy model.
</nextsent>
<nextsent>when this model is combined with the error-driven transformation-based learning model, our accuracy is higher by 0.77%.
</nextsent>
<nextsent>still, this comparison is just preliminary since different segmentation standards can also affect segmentationaccuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2232">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntactic structure helps us understand the semantic relationships between words.
</prevsent>
<prevsent>given text corpus, we can use knowledge about syntactic structures to obtain semantic knowledge.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
for example,hearst (hearst, 1992) <papid> C92-2082 </papid>learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as np, np, and other nps?, and roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>generated semantically related words by applying statistical measures to syntactic contexts involving apposi tives, lists, and conjunctions.</citsent>
<aftsection>
<nextsent>exploiting syntactic structures to learn semantic knowledge holds great promise, but can run into problems.
</nextsent>
<nextsent>first, lexico-syntactic expressions that explicitly indicate semantic relationships (e.g., np, np, and other nps?)
</nextsent>
<nextsent>are reliable but lot of semantic information occurs outside these expressions.
</nextsent>
<nextsent>second, general syntactic structures (e.g., lists and conjunctions) capture wide range of semantic relationships.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2234">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntactic structure helps us understand the semantic relationships between words.
</prevsent>
<prevsent>given text corpus, we can use knowledge about syntactic structures to obtain semantic knowledge.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
for example,hearst (hearst, 1992) <papid> C92-2082 </papid>learned hyponymy relationships by collecting words in lexico-syntactic expressions, such as np, np, and other nps?, and roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>generated semantically related words by applying statistical measures to syntactic contexts involving apposi tives, lists, and conjunctions.</citsent>
<aftsection>
<nextsent>exploiting syntactic structures to learn semantic knowledge holds great promise, but can run into problems.
</nextsent>
<nextsent>first, lexico-syntactic expressions that explicitly indicate semantic relationships (e.g., np, np, and other nps?)
</nextsent>
<nextsent>are reliable but lot of semantic information occurs outside these expressions.
</nextsent>
<nextsent>second, general syntactic structures (e.g., lists and conjunctions) capture wide range of semantic relationships.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2238">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, general syntactic structures (e.g., lists and conjunctions) capture wide range of semantic relationships.
</prevsent>
<prevsent>for example, conjunctions frequently join items of the same semantic class (e.g., catsand dogs?), but they can also join different semantic classes (e.g., fire and ice?).
</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
some researchers (roark and charniak, 1998; <papid> P98-2182 </papid>riloff and shepherd, 1997) <papid> W97-0313 </papid>have applied statistical methods to identify the strongest semantic associations.</citsent>
<aftsection>
<nextsent>this approach has produced reasonable results, but the accuracy ofthese techniques still leaves much room for improvement.
</nextsent>
<nextsent>we adopt an intermediate approach that learns semantic lexicons using strong syntactic heuristics, which are both common and reliable.
</nextsent>
<nextsent>we have identified certain types of appositives, compound nouns, and identity (isa) clauses that indicate specific semantic associations between words.
</nextsent>
<nextsent>we embed syntactic heuristics in bootstrapping process and present empirical results demonstrating that this bootstrapping process produces high-quality semantic lexicons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2240">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>language processing (emnlp), philadelphia, july 2002, pp.
</prevsent>
<prevsent>125-132.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
proceedings of the conference on empirical methods in natural guage processing tasks, including anaphora resolution (aone and bennett, 1996; mccarthy and lehnert, 1995), prepositional phrase attachment (brilland resnik, 1994), <papid> C94-2195 </papid>information extraction (soder land et al, 1995; riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>and question answering (harabagiu et al, 2000; hirschman et al, 1999).<papid> P99-1042 </papid>some general-purposes semantic dictionaries already exist, such as wordnet (miller, 1990).</citsent>
<aftsection>
<nextsent>wordnet has been used for many applications, but it may not contain the vocabulary and jargon needed for specialized domains.
</nextsent>
<nextsent>for example, wordnet does not contain much of the vocabulary found in medicaltexts.
</nextsent>
<nextsent>in previous research on semantic lexicon induction, roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>showed that 3 of every 5 words learned bytheir system were not present in wordnet.</nextsent>
<nextsent>furthermore, they used relatively un specialized text cor pora: wall street journal articles and terrorism newsstories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2241">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>language processing (emnlp), philadelphia, july 2002, pp.
</prevsent>
<prevsent>125-132.
</prevsent>
</prevsection>
<citsent citstr=" W98-1106 ">
proceedings of the conference on empirical methods in natural guage processing tasks, including anaphora resolution (aone and bennett, 1996; mccarthy and lehnert, 1995), prepositional phrase attachment (brilland resnik, 1994), <papid> C94-2195 </papid>information extraction (soder land et al, 1995; riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>and question answering (harabagiu et al, 2000; hirschman et al, 1999).<papid> P99-1042 </papid>some general-purposes semantic dictionaries already exist, such as wordnet (miller, 1990).</citsent>
<aftsection>
<nextsent>wordnet has been used for many applications, but it may not contain the vocabulary and jargon needed for specialized domains.
</nextsent>
<nextsent>for example, wordnet does not contain much of the vocabulary found in medicaltexts.
</nextsent>
<nextsent>in previous research on semantic lexicon induction, roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>showed that 3 of every 5 words learned bytheir system were not present in wordnet.</nextsent>
<nextsent>furthermore, they used relatively un specialized text cor pora: wall street journal articles and terrorism newsstories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2242">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>language processing (emnlp), philadelphia, july 2002, pp.
</prevsent>
<prevsent>125-132.
</prevsent>
</prevsection>
<citsent citstr=" P99-1042 ">
proceedings of the conference on empirical methods in natural guage processing tasks, including anaphora resolution (aone and bennett, 1996; mccarthy and lehnert, 1995), prepositional phrase attachment (brilland resnik, 1994), <papid> C94-2195 </papid>information extraction (soder land et al, 1995; riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>and question answering (harabagiu et al, 2000; hirschman et al, 1999).<papid> P99-1042 </papid>some general-purposes semantic dictionaries already exist, such as wordnet (miller, 1990).</citsent>
<aftsection>
<nextsent>wordnet has been used for many applications, but it may not contain the vocabulary and jargon needed for specialized domains.
</nextsent>
<nextsent>for example, wordnet does not contain much of the vocabulary found in medicaltexts.
</nextsent>
<nextsent>in previous research on semantic lexicon induction, roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>showed that 3 of every 5 words learned bytheir system were not present in wordnet.</nextsent>
<nextsent>furthermore, they used relatively un specialized text cor pora: wall street journal articles and terrorism newsstories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2248">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>hearsts work is similar in spirit to ourwork in that her system identified reliable syntactic structures that explicitly reveal semantic associations.
</prevsent>
<prevsent>meta-bootstrapping (riloff and jones, 1999)is semantic lexicon learning technique very different from ours which utilizes information extraction patterns to identify semantically related contexts.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
named entity recognizers (e.g., (bikel et al, 1997; <papid> A97-1029 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)) <papid> W99-0612 </papid>can be trained to recognize proper names associated with semantic categories such as person or organization, but they typically are not aimed at learning common nouns such as surgeon?</citsent>
<aftsection>
<nextsent>or drugmaker?.
</nextsent>
<nextsent>several researchers have used some of the same syntactic structures that we exploit in our research,namely appositives and compound nouns.
</nextsent>
<nextsent>forex ample, riloff and shepherd (riloff and shepherd, 1997) <papid> W97-0313 </papid>developed statistical co-occurrence model for semantic lexicon induction that was designed with these structures in mind.</nextsent>
<nextsent>roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>followed up on this work by using parser to explicitly capture these structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2249">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>hearsts work is similar in spirit to ourwork in that her system identified reliable syntactic structures that explicitly reveal semantic associations.
</prevsent>
<prevsent>meta-bootstrapping (riloff and jones, 1999)is semantic lexicon learning technique very different from ours which utilizes information extraction patterns to identify semantically related contexts.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
named entity recognizers (e.g., (bikel et al, 1997; <papid> A97-1029 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)) <papid> W99-0612 </papid>can be trained to recognize proper names associated with semantic categories such as person or organization, but they typically are not aimed at learning common nouns such as surgeon?</citsent>
<aftsection>
<nextsent>or drugmaker?.
</nextsent>
<nextsent>several researchers have used some of the same syntactic structures that we exploit in our research,namely appositives and compound nouns.
</nextsent>
<nextsent>forex ample, riloff and shepherd (riloff and shepherd, 1997) <papid> W97-0313 </papid>developed statistical co-occurrence model for semantic lexicon induction that was designed with these structures in mind.</nextsent>
<nextsent>roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>followed up on this work by using parser to explicitly capture these structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2250">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>hearsts work is similar in spirit to ourwork in that her system identified reliable syntactic structures that explicitly reveal semantic associations.
</prevsent>
<prevsent>meta-bootstrapping (riloff and jones, 1999)is semantic lexicon learning technique very different from ours which utilizes information extraction patterns to identify semantically related contexts.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
named entity recognizers (e.g., (bikel et al, 1997; <papid> A97-1029 </papid>collins and singer, 1999; <papid> W99-0613 </papid>cucerzan and yarowsky, 1999)) <papid> W99-0612 </papid>can be trained to recognize proper names associated with semantic categories such as person or organization, but they typically are not aimed at learning common nouns such as surgeon?</citsent>
<aftsection>
<nextsent>or drugmaker?.
</nextsent>
<nextsent>several researchers have used some of the same syntactic structures that we exploit in our research,namely appositives and compound nouns.
</nextsent>
<nextsent>forex ample, riloff and shepherd (riloff and shepherd, 1997) <papid> W97-0313 </papid>developed statistical co-occurrence model for semantic lexicon induction that was designed with these structures in mind.</nextsent>
<nextsent>roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>followed up on this work by using parser to explicitly capture these structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2256">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> semantic lexicon learning.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample, riloff and shepherd (riloff and shepherd, 1997) <papid> W97-0313 </papid>developed statistical co-occurrence model for semantic lexicon induction that was designed with these structures in mind.</prevsent>
<prevsent>roark and charniak (roark and charniak, 1998) <papid> P98-2182 </papid>followed up on this work by using parser to explicitly capture these structures.</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
caraballo (caraballo, 1999) <papid> P99-1016 </papid>also exploited these syntactic structures and applied co sine vector model to produce semantic groupings.</citsent>
<aftsection>
<nextsent>inour view, these previous systems used weak?
</nextsent>
<nextsent>syntactic models because the syntactic structures sometimes identified desirable semantic associations and sometimes did not.
</nextsent>
<nextsent>to compensate, statistical models were used to separate the meaningful semantic associations from the spurious ones.
</nextsent>
<nextsent>in contrast, our work aims to identify strong?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2257">
<title id=" W02-1017.xml">exploiting strong syntactic heuristics and co training to learn semantic lexicons </title>
<section> a bootstrapping model that exploits </section>
<citcontext>
<prevsection>
<prevsent>3.3 experimental results.
</prevsent>
<prevsent>we evaluated our system on several semantic categories in two domains.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in one set of experiments,we generated lexicons for people and organizations using 2500 wall street journal articles fromthe penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>in the second set of experiments, we generated lexicons for people, organizations, and products using approximately 1350 press releases from pharmaceutical companies.2 our seeding consisted of 5 proper nouns and 5 general nouns for each semantic category.
</nextsent>
<nextsent>we used threshold of 25% for the evidence measure and 5 forthe exclusivity ratio.
</nextsent>
<nextsent>we ran the bootstrapping process until no new words were learned, which ranged from 6-14 iterations depending on the category and syntactic structure.
</nextsent>
<nextsent>table 1 shows 10 examples of words learned for each semantic category in each domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2258">
<title id=" W02-1107.xml">classification of adjectival and nonadjectival nouns based on their semantic behavior by using a self organizing semantic map </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose method for fundamental research to construct an organized lexicon, in which we classify words depending on not only their part of speech, but also their semantic categories.
</prevsent>
<prevsent>we applied both neural network model and linguistic method, that is syntactic information, to large corpora and extracted necessary information.
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
to extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures (hindle 1990, <papid> P90-1034 </papid>hatzivassiloglou 1993 and tokunaga 1995), response time to associate synonyms and antonyms in psychological experiments (gross 1989), or extracting related words automatically from corpora (grefensette 1994).</citsent>
<aftsection>
<nextsent>most lexical classification is based on parts of speech, as they have very important semantic information.
</nextsent>
<nextsent>for examples, typically, an adjective refers to an attribute, verb refers to motion or an event, and noun refers to an object.
</nextsent>
<nextsent>however, in real data, semantic function of part of speech is not defined rigidly, as shown in the above examples.
</nextsent>
<nextsent>inspite of different parts of speech, they sometimes represent the same or very similar semantic functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2259">
<title id=" W02-1107.xml">classification of adjectival and nonadjectival nouns based on their semantic behavior by using a self organizing semantic map </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is important for developing high quality natural language processing systems to establish an objective method to represent relationship between words not only by part of speech but also by semantic functions.
</prevsent>
<prevsent>however, it is very difficult to extract this type of linguistic phenomena from real data automatically.
</prevsent>
</prevsection>
<citsent citstr=" P99-1063 ">
we used syntactic and semantic patterns in our previous work (isahara and kanzaki 1999) <papid> P99-1063 </papid>in order to extract these types of examples from large corpora semi-automatically.</citsent>
<aftsection>
<nextsent>in this work, by using syntactic information, we are collecting adjectives and adjectival nouns in the noun + no (of + noun)?
</nextsent>
<nextsent>structure that we supposed to have the same semantic functions.
</nextsent>
<nextsent>we examined how adjectives and adjectival nouns extracted from corpora are similar or different in the real data and how non-adjectival nouns unlike adjectival nouns are different from adjectives in order to verify the usefulness of self-organizing semantic maps for lexical semantics.
</nextsent>
<nextsent>in section 2, we explain our methodology, based on linguistic information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2262">
<title id=" W02-1107.xml">classification of adjectival and nonadjectival nouns based on their semantic behavior by using a self organizing semantic map </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>belong to different parts of speech (adjective and noun phrase), they must be classified as the same semantic category, since both carry the same type of meaning.
</prevsent>
<prevsent>as for data, necessary expressions are extracted from large corpora: 10 years worth of japanese newspapers ? the mainichi shinbun from 1991 to 2000, 100 novels ? shincho-bunko, and 100 kinds of essays.
</prevsent>
</prevsection>
<citsent citstr=" W00-0110 ">
we extracted 134 abstract nouns used as this kind of head noun semi-automatically by using syntactic patterns that isahara and kanzaki(1999) <papid> P99-1063 </papid>and kanzaki et al (2000) <papid> W00-0110 </papid>used in their paper.</citsent>
<aftsection>
<nextsent>the total number of adnominal constituents appearing with these head nouns in the corpora was 47,248, and the number of different adnominal constituents was 28,063.
</nextsent>
<nextsent>we got the list of pairs of head (abstract) noun and its adnominal constituents (table 1).
</nextsent>
<nextsent>these adnominal constituents are classified into three types, i.e. adjectives, adjectival nouns and non-adjectival nouns.
</nextsent>
<nextsent>table 1: example of gathered data noun adnominal constituents kimochi (feeling) shiawasena (happy), hokorashii (proud), kanashii (sad), ? joutai (status) aimaina (vague), ansei no (repose + no), ? kanten (viewpoint) gakumontekina (academic), anzensei no (safety + no), ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2263">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we focus on resolving the zero pronoun, which is shortened for simplicity to zero.?
</prevsent>
<prevsent>most studies on japanese zero pronoun resolution have not tried to resolve zeros in full-text newspaper articles.
</prevsent>
</prevsection>
<citsent citstr=" P86-1031 ">
they have discussed simple sentenses(kameyama, 1986; <papid> P86-1031 </papid>walker et al, 1994; <papid> J94-2003 </papid>yamura takei et al, 2002), dialogues (yamamoto et al,1997), stereotypical lead sentences of newspaper articles (nakaiwa and ikehara, 1993), intra sentential resolution (nakaiwa and ikehara, 1996; ehara andkim, 1996) or organization names in newspaper articles (aone and bennett, 1995).</citsent>
<aftsection>
<nextsent>there are two approaches to the problem: the heuristic approach and the machine learning ap 1http://trec.nist.gov/data/qa.html proach.
</nextsent>
<nextsent>the centering theory (grosz et al, 1995) <papid> J95-2003 </papid>is important in the heuristic approach.</nextsent>
<nextsent>walker et al (1994) <papid> J94-2003 </papid>proposed forward center ranking forjapanese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2264">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we focus on resolving the zero pronoun, which is shortened for simplicity to zero.?
</prevsent>
<prevsent>most studies on japanese zero pronoun resolution have not tried to resolve zeros in full-text newspaper articles.
</prevsent>
</prevsection>
<citsent citstr=" J94-2003 ">
they have discussed simple sentenses(kameyama, 1986; <papid> P86-1031 </papid>walker et al, 1994; <papid> J94-2003 </papid>yamura takei et al, 2002), dialogues (yamamoto et al,1997), stereotypical lead sentences of newspaper articles (nakaiwa and ikehara, 1993), intra sentential resolution (nakaiwa and ikehara, 1996; ehara andkim, 1996) or organization names in newspaper articles (aone and bennett, 1995).</citsent>
<aftsection>
<nextsent>there are two approaches to the problem: the heuristic approach and the machine learning ap 1http://trec.nist.gov/data/qa.html proach.
</nextsent>
<nextsent>the centering theory (grosz et al, 1995) <papid> J95-2003 </papid>is important in the heuristic approach.</nextsent>
<nextsent>walker et al (1994) <papid> J94-2003 </papid>proposed forward center ranking forjapanese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2265">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they have discussed simple sentenses(kameyama, 1986; <papid> P86-1031 </papid>walker et al, 1994; <papid> J94-2003 </papid>yamura takei et al, 2002), dialogues (yamamoto et al,1997), stereotypical lead sentences of newspaper articles (nakaiwa and ikehara, 1993), intra sentential resolution (nakaiwa and ikehara, 1996; ehara andkim, 1996) or organization names in newspaper articles (aone and bennett, 1995).</prevsent>
<prevsent>there are two approaches to the problem: the heuristic approach and the machine learning ap 1http://trec.nist.gov/data/qa.html proach.</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
the centering theory (grosz et al, 1995) <papid> J95-2003 </papid>is important in the heuristic approach.</citsent>
<aftsection>
<nextsent>walker et al (1994) <papid> J94-2003 </papid>proposed forward center ranking forjapanese.</nextsent>
<nextsent>kameyama (1986) <papid> P86-1031 </papid>emphasized the importance of property-sharing constraint.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2268">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>walker et al (1994) <papid> J94-2003 </papid>proposed forward center ranking forjapanese.</prevsent>
<prevsent>kameyama (1986) <papid> P86-1031 </papid>emphasized the importance of property-sharing constraint.</prevsent>
</prevsection>
<citsent citstr=" C96-2147 ">
okumura and tamura (1996) <papid> C96-2147 </papid>experimented on the roles of conjunctive post positions in complex sentences.</citsent>
<aftsection>
<nextsent>however, these improvements are not sufficient for resolving zeros accurately.
</nextsent>
<nextsent>murata and na gao (1997) proposed complicated heuristic rules that take various features of antecedents and anaphors into account.
</nextsent>
<nextsent>we have to take even more factors into account, but it is difficult to maintain such heuristic rules.
</nextsent>
<nextsent>therefore, recent studies employ machine learning approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2269">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance,  ff fi fl  flffi   ff !
</prevsent>
<prevsent> # indicates that there are four bunsetsus in this sentence and that the first bunsetsu modifies the fourth bunsetsu and so on.the last bunsetsu modifies no bunsetsu, which is indicated by !  .it takes long time to construct high-quality annotated data, and we want to compare our results with conventional methods.
</prevsent>
</prevsection>
<citsent citstr=" C02-1078 ">
therefore, we obtained sekis data (seki et al, 2002<papid> C02-1078 </papid>a; seki et al, 2002<papid> C02-1078 </papid>b), which are based on the kyoto university corpus 2 2.0.</citsent>
<aftsection>
<nextsent>these data are divided into two groups: gen-.
</nextsent>
<nextsent>eral and editorial.
</nextsent>
<nextsent>general contains 30 general news articles, and editorial contains 30 editorial articles.
</nextsent>
<nextsent>according to his experiments, editorial is harder than general.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2285">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>if % is dou-sha (thecompany), it is replaced by the latest organization name.
</prevsent>
<prevsent>if % is dou+suffix, it is replaced by the latest candidate that has the same suffix.
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
for this task, we use named entity recognizer (isozaki and kazawa, 2002).<papid> C02-1054 </papid></citsent>
<aftsection>
<nextsent>the first step extracts content word sequence from bunsetsu.
</nextsent>
<nextsent>the second step excludes verb phrases, adjective phrases, and clauses.
</nextsent>
<nextsent>as result, we obtain only noun phrases.
</nextsent>
<nextsent>the third step excludes adverbial expressions like kotoshi (this year).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2289">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> semantic constraints (yamura-takei et al,.  </section>
<citcontext>
<prevsection>
<prevsent>although we can consider various other features for zero pronoun resolution, it is difficult to combine these features consistently.
</prevsent>
<prevsent>therefore, we use machine learning.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
support vector machines (svms) have shown good performance in various tasks in natural language processing (kudo and matsumoto, 2001; <papid> N01-1025 </papid>isozaki and kazawa, 2002; <papid> C02-1054 </papid>hi rao et al, 2002).<papid> C02-1053 </papid></citsent>
<aftsection>
<nextsent>yoshino (2001) and iida et al(2003b) also applied svm to japanese zero pronoun resolution, but the usefulness of each feature was not clear.
</nextsent>
<nextsent>here, weadd features for complex sentences and analyze useful features by examining the weights of features.
</nextsent>
<nextsent>we use the following features of % as well as cp.
</nextsent>
<nextsent>csem % semantic categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2291">
<title id=" W03-1024.xml">japanese zero pronoun resolution based on ranking rules and machine learning </title>
<section> semantic constraints (yamura-takei et al,.  </section>
<citcontext>
<prevsection>
<prevsent>although we can consider various other features for zero pronoun resolution, it is difficult to combine these features consistently.
</prevsent>
<prevsent>therefore, we use machine learning.
</prevsent>
</prevsection>
<citsent citstr=" C02-1053 ">
support vector machines (svms) have shown good performance in various tasks in natural language processing (kudo and matsumoto, 2001; <papid> N01-1025 </papid>isozaki and kazawa, 2002; <papid> C02-1054 </papid>hi rao et al, 2002).<papid> C02-1053 </papid></citsent>
<aftsection>
<nextsent>yoshino (2001) and iida et al(2003b) also applied svm to japanese zero pronoun resolution, but the usefulness of each feature was not clear.
</nextsent>
<nextsent>here, weadd features for complex sentences and analyze useful features by examining the weights of features.
</nextsent>
<nextsent>we use the following features of % as well as cp.
</nextsent>
<nextsent>csem % semantic categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2329">
<title id=" W03-0605.xml">an architecture for word learning using bidirectional multimodal structural alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the path and place functions described in section 4 are found by examining the output of the visual routines and are added to the lcs frame.figure 9 shows the lcs frame constructed by the system based on the example shown in figure 7.
</prevsent>
<prevsent>the frame can now be used by the remainder of our system in the structural alignment phase.
</prevsent>
</prevsection>
<citsent citstr=" P90-1019 ">
this work has parallels to maimra, system for word learning from non-linguistic input (siskind, 1990).<papid> P90-1019 </papid></citsent>
<aftsection>
<nextsent>maimras semantic structure is also jackendoff lcs, and its architecture consists of three modules: parser(which produces syntactic parse trees from linguistic input strings), an inference component (which produces semantic structures from non-linguistic input), and linker (which establishes correspondence between the syntactic and semantic structures).
</nextsent>
<nextsent>observing that the parser, inference, and linker components respectively fill the linguistic processing, semantic processing, and structural alignment requirements outlined in section 2, maimra can be viewed as an instance of the general architecture we have described.however, our system is also significantly different from maimra in two important respects.
</nextsent>
<nextsent>first, maimra is designed with the model-refinement aspect of word learning intertwined with the correspondence inference aspect.
</nextsent>
<nextsent>in contrast, our architecture seeks to systematically isolate these two problems, so that problems of model refinement and correspondence establishment may be pursued independently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2330">
<title id=" W03-0812.xml">sdl  a description language for building nlp systems </title>
<section> motivation &amp; idea.  </section>
<citcontext>
<prevsection>
<prevsent>in order to connect such (independently developed) nlcomponents, one must look at the application programmer interface (api) of each module, hoping that there are api methods which allow, e.g., to call module with specic input, to obtain the result value, etc. in the best case, api methods from different modules can be used directly without much programming overhead.
</prevsent>
<prevsent>in the worst case, however, there is no api available, meaning that we have to inspect the programming code of module and have to write additional code to realize interfaces between modules (e.g., data transformation).
</prevsent>
</prevsection>
<citsent citstr=" P02-1056 ">
even more demanding, recent hybrid nlp systems such as whiteboard(crysmann et al, 2002) <papid> P02-1056 </papid>implement more complex interactions and loops, instead of using simple pipeline of modules.we have overcome this inexible behavior by implementing the following idea.</citsent>
<aftsection>
<nextsent>since we use typed feature structures (carpenter, 1992) in sprout as the sole data interchange format between processing modules, the construction of new system can be reduced to the interpretation of regular expression of modules.
</nextsent>
<nextsent>because the ? sign for concatenation can not be found on keyboard,we have given the three characters +, |, and ? the following meaning: ? sequence or concatenation m1+m2 expresses the fact that (1) the input tom1+ m2 is the input given tom1, (2) the output of module m1 serves as the input to m2, and (3) that the nal output of m1 + m2 is equal to the output of m2.
</nextsent>
<nextsent>this is the usual ow of information in sequential cascaded shallow nl architecture.
</nextsent>
<nextsent>con currency or parallelism| denotes quasi-parallel computation of independent modules, where the nal output of each module serves as the input to subsequent module (perhaps grouped in structured object, as we do by de fault).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2331">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper addresses the problem of extracting synonymous english words (synonyms) from multiple resources: monolingual dictionary, parallel bilingual corpus, and monolingual corpus.
</prevsent>
<prevsent>the extracted synonyms can be used in number of nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" C02-1084 ">
in information retrieval and question answering, the synonymous words are employed to bridge the expressions gaps between the query space and the document space (mandala et al, 1999; radev et al, 2001; kiyota et al, 2002).<papid> C02-1084 </papid></citsent>
<aftsection>
<nextsent>in automatic text summarization, synonymous words are employed to identify repetitive information in order to avoid redundant contents in summary (barzilay and elhadad, 1997).<papid> W97-0703 </papid></nextsent>
<nextsent>in language generation, synonyms are employed to create more varied texts (langkilde and knight, 1998).<papid> P98-1116 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2332">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the extracted synonyms can be used in number of nlp applications.
</prevsent>
<prevsent>in information retrieval and question answering, the synonymous words are employed to bridge the expressions gaps between the query space and the document space (mandala et al, 1999; radev et al, 2001; kiyota et al, 2002).<papid> C02-1084 </papid></prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
in automatic text summarization, synonymous words are employed to identify repetitive information in order to avoid redundant contents in summary (barzilay and elhadad, 1997).<papid> W97-0703 </papid></citsent>
<aftsection>
<nextsent>in language generation, synonyms are employed to create more varied texts (langkilde and knight, 1998).<papid> P98-1116 </papid></nextsent>
<nextsent>up to our knowledge, there are few studies investigating the combination of different resources for synonym extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2333">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in information retrieval and question answering, the synonymous words are employed to bridge the expressions gaps between the query space and the document space (mandala et al, 1999; radev et al, 2001; kiyota et al, 2002).<papid> C02-1084 </papid></prevsent>
<prevsent>in automatic text summarization, synonymous words are employed to identify repetitive information in order to avoid redundant contents in summary (barzilay and elhadad, 1997).<papid> W97-0703 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
in language generation, synonyms are employed to create more varied texts (langkilde and knight, 1998).<papid> P98-1116 </papid></citsent>
<aftsection>
<nextsent>up to our knowledge, there are few studies investigating the combination of different resources for synonym extraction.
</nextsent>
<nextsent>however, many studies investigate synonym extraction from only one resource.
</nextsent>
<nextsent>the most frequently used resource for synonym extraction is large monolingual corpora (hindle, 1990; <papid> P90-1034 </papid>crouch and yang, 1992; grefen statte, 1994; park and choi, 1997; gasperin et al, 2001 and lin, 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>the methods used the contexts around the investigated words to discover synonyms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2334">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>up to our knowledge, there are few studies investigating the combination of different resources for synonym extraction.
</prevsent>
<prevsent>however, many studies investigate synonym extraction from only one resource.
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
the most frequently used resource for synonym extraction is large monolingual corpora (hindle, 1990; <papid> P90-1034 </papid>crouch and yang, 1992; grefen statte, 1994; park and choi, 1997; gasperin et al, 2001 and lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the methods used the contexts around the investigated words to discover synonyms.
</nextsent>
<nextsent>the problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat?
</nextsent>
<nextsent>and dog?, which are similar but not synonymous.
</nextsent>
<nextsent>other resources are also used for synonym extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2335">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>up to our knowledge, there are few studies investigating the combination of different resources for synonym extraction.
</prevsent>
<prevsent>however, many studies investigate synonym extraction from only one resource.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the most frequently used resource for synonym extraction is large monolingual corpora (hindle, 1990; <papid> P90-1034 </papid>crouch and yang, 1992; grefen statte, 1994; park and choi, 1997; gasperin et al, 2001 and lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the methods used the contexts around the investigated words to discover synonyms.
</nextsent>
<nextsent>the problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat?
</nextsent>
<nextsent>and dog?, which are similar but not synonymous.
</nextsent>
<nextsent>other resources are also used for synonym extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2336">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and dog?, which are similar but not synonymous.
</prevsent>
<prevsent>other resources are also used for synonym extraction.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
barzilay and mckeown (2001), <papid> P01-1008 </papid>and shimohata and sumita (2002) used bilingual corpora to extract synonyms.</citsent>
<aftsection>
<nextsent>however, these methods can only extract synonyms which occur in the bilingual corpus.
</nextsent>
<nextsent>thus, the extracted synonyms are limited.
</nextsent>
<nextsent>besides, blondel and sennelart (2002) used monolingual dictionaries to extract synonyms.
</nextsent>
<nextsent>although the precision of this method is high, the coverage is low because the result of this method heavily depends on the definitions of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2337">
<title id=" W03-1610.xml">optimizing synonym extraction using monolingual and bilingual resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides, blondel and sennelart (2002) used monolingual dictionaries to extract synonyms.
</prevsent>
<prevsent>although the precision of this method is high, the coverage is low because the result of this method heavily depends on the definitions of words.
</prevsent>
</prevsection>
<citsent citstr=" W02-1029 ">
in order to improve the performance of synonym extraction, curran (2002) <papid> W02-1029 </papid>used an ensemble method to combine the results of different methods using monolingual corpus.</citsent>
<aftsection>
<nextsent>although curran (2002) <papid> W02-1029 </papid>showed that the ensemble extractors outperformed the individual extractors, it still cannot overcome the deficiency of the methods using the monolingual corpus.</nextsent>
<nextsent>to overcome the deficiencies of the methods using only one resource, our approach combines both monolingual and bilingual resources to automatically extract synonymous words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2345">
<title id=" W02-1020.xml">user friendly text prediction for translators </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>letting u1 be the prefix of the word that ends in v1 (eg, in figure 1), w1 = u1v1, and = hu1: p(v1|h, s) = p(w1|h?, s)/ ? w:w=u1v p(w|h?, s), where the sum is over all words that start with u1.
</prevsent>
<prevsent>similarly: p(um|h?, m1 1 , s) = ? w:w=umv p(w|h?, wm11 , s).
</prevsent>
</prevsection>
<citsent citstr=" W00-0707 ">
(4) thus all factors in (3) can be calculated from probabilities of the form p(w|h, s) which give the likelihood that word will follow previous sequence of words in the translation of s.1 this is the family of distributions we have concentrated on modeling.our model for p(w|h, s) is log-linear combination of trigram language model for p(w|h) and amaximum-entropy translation model for p(w|s), described in (foster, 2000<papid> W00-0707 </papid>a; foster, 2000<papid> W00-0707 </papid>b).</citsent>
<aftsection>
<nextsent>the translation component is an analog of the ibm model 2(brown et al, 1993), <papid> J93-2003 </papid>with parameters that are optimized for use with the trigram.</nextsent>
<nextsent>the combined model is shown in (foster, 2000<papid> W00-0707 </papid>a) to have significantly lower test corpus perplexity than the linear combination of trigram and ibm 2 used in the trans type experiments (langlais et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2365">
<title id=" W02-1020.xml">user friendly text prediction for translators </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>similarly: p(um|h?, m1 1 , s) = ? w:w=umv p(w|h?, wm11 , s).
</prevsent>
<prevsent>(4) thus all factors in (3) can be calculated from probabilities of the form p(w|h, s) which give the likelihood that word will follow previous sequence of words in the translation of s.1 this is the family of distributions we have concentrated on modeling.our model for p(w|h, s) is log-linear combination of trigram language model for p(w|h) and amaximum-entropy translation model for p(w|s), described in (foster, 2000<papid> W00-0707 </papid>a; foster, 2000<papid> W00-0707 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the translation component is an analog of the ibm model 2(brown et al, 1993), <papid> J93-2003 </papid>with parameters that are optimized for use with the trigram.</citsent>
<aftsection>
<nextsent>the combined model is shown in (foster, 2000<papid> W00-0707 </papid>a) to have significantly lower test corpus perplexity than the linear combination of trigram and ibm 2 used in the trans type experiments (langlais et al, 2002).</nextsent>
<nextsent>both models supporto(mjv 3) viterbi-style searches for the most likely sequence of words that follows h, where is the number of tokens in and is the size of the target-language vocabulary.compared to an equivalent noisy-channel combination of the form p(t)p(s|t), where is the target sentence, our model is faster but less accurate.it is faster because the search problem for noisy channel models is np-complete (knight, 1999), <papid> J99-4005 </papid>and even the fastest dynamic-programming heuristics used in statistical mt (niessen et al, 1998; tillmann and ney, 2000), <papid> C00-2123 </papid>are polynomial in jfor instance o(mj4v 3) in (tillmann and ney, 2000).<papid> C00-2123 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2376">
<title id=" W02-1020.xml">user friendly text prediction for translators </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>the translation component is an analog of the ibm model 2(brown et al, 1993), <papid> J93-2003 </papid>with parameters that are optimized for use with the trigram.</prevsent>
<prevsent>the combined model is shown in (foster, 2000<papid> W00-0707 </papid>a) to have significantly lower test corpus perplexity than the linear combination of trigram and ibm 2 used in the trans type experiments (langlais et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
both models supporto(mjv 3) viterbi-style searches for the most likely sequence of words that follows h, where is the number of tokens in and is the size of the target-language vocabulary.compared to an equivalent noisy-channel combination of the form p(t)p(s|t), where is the target sentence, our model is faster but less accurate.it is faster because the search problem for noisy channel models is np-complete (knight, 1999), <papid> J99-4005 </papid>and even the fastest dynamic-programming heuristics used in statistical mt (niessen et al, 1998; tillmann and ney, 2000), <papid> C00-2123 </papid>are polynomial in jfor instance o(mj4v 3) in (tillmann and ney, 2000).<papid> C00-2123 </papid></citsent>
<aftsection>
<nextsent>itis less accurate because it ignores the alignment relation between and h, which is captured by even the simplest noisy-channel models.
</nextsent>
<nextsent>our model is therefore suitable for making predictions in real time, but not for establishing complete translations unassisted by human.
</nextsent>
<nextsent>3.1 implementation.
</nextsent>
<nextsent>the most expensive part of the calculation in equation (3) is the sum in (4) over all words in the vocabulary, which according to (2) must be carried out for every character position in given prediction x. we reduce the cost of this by performing sums only at the end of each sequence of complete tokens in (eg, after revenir and revenir aux in the aboveexample).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2377">
<title id=" W02-1020.xml">user friendly text prediction for translators </title>
<section> translation model.  </section>
<citcontext>
<prevsection>
<prevsent>the translation component is an analog of the ibm model 2(brown et al, 1993), <papid> J93-2003 </papid>with parameters that are optimized for use with the trigram.</prevsent>
<prevsent>the combined model is shown in (foster, 2000<papid> W00-0707 </papid>a) to have significantly lower test corpus perplexity than the linear combination of trigram and ibm 2 used in the trans type experiments (langlais et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" C00-2123 ">
both models supporto(mjv 3) viterbi-style searches for the most likely sequence of words that follows h, where is the number of tokens in and is the size of the target-language vocabulary.compared to an equivalent noisy-channel combination of the form p(t)p(s|t), where is the target sentence, our model is faster but less accurate.it is faster because the search problem for noisy channel models is np-complete (knight, 1999), <papid> J99-4005 </papid>and even the fastest dynamic-programming heuristics used in statistical mt (niessen et al, 1998; tillmann and ney, 2000), <papid> C00-2123 </papid>are polynomial in jfor instance o(mj4v 3) in (tillmann and ney, 2000).<papid> C00-2123 </papid></citsent>
<aftsection>
<nextsent>itis less accurate because it ignores the alignment relation between and h, which is captured by even the simplest noisy-channel models.
</nextsent>
<nextsent>our model is therefore suitable for making predictions in real time, but not for establishing complete translations unassisted by human.
</nextsent>
<nextsent>3.1 implementation.
</nextsent>
<nextsent>the most expensive part of the calculation in equation (3) is the sum in (4) over all words in the vocabulary, which according to (2) must be carried out for every character position in given prediction x. we reduce the cost of this by performing sums only at the end of each sequence of complete tokens in (eg, after revenir and revenir aux in the aboveexample).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2399">
<title id=" W02-1020.xml">user friendly text prediction for translators </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the user model could also be made adaptive, and it could be enriched in many other ways, for instance so as to capture the propensity of translators to accept at the beginnings of words.we feel that the idea of creating explicit user models to guide the behaviour of interactive systems is likely to have applications in areas of nlp apart from translators?
</prevsent>
<prevsent>tools.
</prevsent>
</prevsection>
<citsent citstr=" W97-0504 ">
for one thing, most of the approach described here carries over more or less directly to monolingual text prediction, which is an important tool for the handicapped (carlberger et al,1997).<papid> W97-0504 </papid></citsent>
<aftsection>
<nextsent>other possibilities include virtually any application where human and machine communicate through language-rich interface.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2400">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is cross-platform implementation, written in c++.
</prevsent>
<prevsent>tex tract is populated?
</prevsent>
</prevsection>
<citsent citstr=" W02-0901 ">
by number of plugins, providing functional ities for: ? tokenization; ? document structure analysis, from tags and white space; ? lexicon interface, complete with efficient look up and full morphology; ? importation of lexical and vocabulary analyses from non-textract process via xml markup; ? analysis of out-of-vocabulary words (park, 2002); ? <papid> W02-0901 </papid>abbreviation finding and expansion (park and byrd, 2001); ? <papid> W01-0516 </papid>named entity identification and classification (person names, organizations, places, and so forth) (ravin and wacholder, 1997); ? technical term identification, in technical prose (justeson and katz, 1995); ? vocabulary determination and glossary extraction, in specialized domains (park et al, 2002); ? <papid> C02-1142 </papid>vocabulary aggregation, with reduction to canonical form, within and across documents; ? part-of-speech tagging (with different taggers) for determining syntactic categories in context; ? shallow syntactic parsing, for identifying phrasal and clausal constructs and semantic relations (boguraev, 2000); ? salience calculations, both of inter- and intra document salience; ? analysis of topic shifts within document (bogu raev and neff, 2000a); ? document clustering, cluster organization, and cluster labeling; ? single document summarization, configurable to deploy different algorithmic schemes (sentence extraction, topical highlights, lexical cohesion) (boguraev and neff, 2000a, 2000b); ? multi-document summarization, using iterative residual re scaling (ando et al, 2000); ? <papid> W00-0409 </papid>pattern matching, deploying finite state technology specially designed to operate over document content abstractions (as opposed to character stream alone).</citsent>
<aftsection>
<nextsent>the list above is not exhaustive, but indicative of the kinds of text mining tex tract is being utilized for; we anticipate new technologies being continually added to the inventory of plugins.
</nextsent>
<nextsent>as will become clear later in the paper, the architecture of this system openly caters for third-party plugin writers.
</nextsent>
<nextsent>figure 1: tex tract architecture specific tex tract configurations may deploy custom subsets of available plugin components, in order to effect certain processing; such configurations typically implement an application for specific content analysis / text mining task.
</nextsent>
<nextsent>from an application point of view, tex tract plugins deposit analysis results in the shared repository; the application itself reads?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2401">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is cross-platform implementation, written in c++.
</prevsent>
<prevsent>tex tract is populated?
</prevsent>
</prevsection>
<citsent citstr=" W01-0516 ">
by number of plugins, providing functional ities for: ? tokenization; ? document structure analysis, from tags and white space; ? lexicon interface, complete with efficient look up and full morphology; ? importation of lexical and vocabulary analyses from non-textract process via xml markup; ? analysis of out-of-vocabulary words (park, 2002); ? <papid> W02-0901 </papid>abbreviation finding and expansion (park and byrd, 2001); ? <papid> W01-0516 </papid>named entity identification and classification (person names, organizations, places, and so forth) (ravin and wacholder, 1997); ? technical term identification, in technical prose (justeson and katz, 1995); ? vocabulary determination and glossary extraction, in specialized domains (park et al, 2002); ? <papid> C02-1142 </papid>vocabulary aggregation, with reduction to canonical form, within and across documents; ? part-of-speech tagging (with different taggers) for determining syntactic categories in context; ? shallow syntactic parsing, for identifying phrasal and clausal constructs and semantic relations (boguraev, 2000); ? salience calculations, both of inter- and intra document salience; ? analysis of topic shifts within document (bogu raev and neff, 2000a); ? document clustering, cluster organization, and cluster labeling; ? single document summarization, configurable to deploy different algorithmic schemes (sentence extraction, topical highlights, lexical cohesion) (boguraev and neff, 2000a, 2000b); ? multi-document summarization, using iterative residual re scaling (ando et al, 2000); ? <papid> W00-0409 </papid>pattern matching, deploying finite state technology specially designed to operate over document content abstractions (as opposed to character stream alone).</citsent>
<aftsection>
<nextsent>the list above is not exhaustive, but indicative of the kinds of text mining tex tract is being utilized for; we anticipate new technologies being continually added to the inventory of plugins.
</nextsent>
<nextsent>as will become clear later in the paper, the architecture of this system openly caters for third-party plugin writers.
</nextsent>
<nextsent>figure 1: tex tract architecture specific tex tract configurations may deploy custom subsets of available plugin components, in order to effect certain processing; such configurations typically implement an application for specific content analysis / text mining task.
</nextsent>
<nextsent>from an application point of view, tex tract plugins deposit analysis results in the shared repository; the application itself reads?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2402">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is cross-platform implementation, written in c++.
</prevsent>
<prevsent>tex tract is populated?
</prevsent>
</prevsection>
<citsent citstr=" C02-1142 ">
by number of plugins, providing functional ities for: ? tokenization; ? document structure analysis, from tags and white space; ? lexicon interface, complete with efficient look up and full morphology; ? importation of lexical and vocabulary analyses from non-textract process via xml markup; ? analysis of out-of-vocabulary words (park, 2002); ? <papid> W02-0901 </papid>abbreviation finding and expansion (park and byrd, 2001); ? <papid> W01-0516 </papid>named entity identification and classification (person names, organizations, places, and so forth) (ravin and wacholder, 1997); ? technical term identification, in technical prose (justeson and katz, 1995); ? vocabulary determination and glossary extraction, in specialized domains (park et al, 2002); ? <papid> C02-1142 </papid>vocabulary aggregation, with reduction to canonical form, within and across documents; ? part-of-speech tagging (with different taggers) for determining syntactic categories in context; ? shallow syntactic parsing, for identifying phrasal and clausal constructs and semantic relations (boguraev, 2000); ? salience calculations, both of inter- and intra document salience; ? analysis of topic shifts within document (bogu raev and neff, 2000a); ? document clustering, cluster organization, and cluster labeling; ? single document summarization, configurable to deploy different algorithmic schemes (sentence extraction, topical highlights, lexical cohesion) (boguraev and neff, 2000a, 2000b); ? multi-document summarization, using iterative residual re scaling (ando et al, 2000); ? <papid> W00-0409 </papid>pattern matching, deploying finite state technology specially designed to operate over document content abstractions (as opposed to character stream alone).</citsent>
<aftsection>
<nextsent>the list above is not exhaustive, but indicative of the kinds of text mining tex tract is being utilized for; we anticipate new technologies being continually added to the inventory of plugins.
</nextsent>
<nextsent>as will become clear later in the paper, the architecture of this system openly caters for third-party plugin writers.
</nextsent>
<nextsent>figure 1: tex tract architecture specific tex tract configurations may deploy custom subsets of available plugin components, in order to effect certain processing; such configurations typically implement an application for specific content analysis / text mining task.
</nextsent>
<nextsent>from an application point of view, tex tract plugins deposit analysis results in the shared repository; the application itself reads?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2403">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is cross-platform implementation, written in c++.
</prevsent>
<prevsent>tex tract is populated?
</prevsent>
</prevsection>
<citsent citstr=" W00-0409 ">
by number of plugins, providing functional ities for: ? tokenization; ? document structure analysis, from tags and white space; ? lexicon interface, complete with efficient look up and full morphology; ? importation of lexical and vocabulary analyses from non-textract process via xml markup; ? analysis of out-of-vocabulary words (park, 2002); ? <papid> W02-0901 </papid>abbreviation finding and expansion (park and byrd, 2001); ? <papid> W01-0516 </papid>named entity identification and classification (person names, organizations, places, and so forth) (ravin and wacholder, 1997); ? technical term identification, in technical prose (justeson and katz, 1995); ? vocabulary determination and glossary extraction, in specialized domains (park et al, 2002); ? <papid> C02-1142 </papid>vocabulary aggregation, with reduction to canonical form, within and across documents; ? part-of-speech tagging (with different taggers) for determining syntactic categories in context; ? shallow syntactic parsing, for identifying phrasal and clausal constructs and semantic relations (boguraev, 2000); ? salience calculations, both of inter- and intra document salience; ? analysis of topic shifts within document (bogu raev and neff, 2000a); ? document clustering, cluster organization, and cluster labeling; ? single document summarization, configurable to deploy different algorithmic schemes (sentence extraction, topical highlights, lexical cohesion) (boguraev and neff, 2000a, 2000b); ? multi-document summarization, using iterative residual re scaling (ando et al, 2000); ? <papid> W00-0409 </papid>pattern matching, deploying finite state technology specially designed to operate over document content abstractions (as opposed to character stream alone).</citsent>
<aftsection>
<nextsent>the list above is not exhaustive, but indicative of the kinds of text mining tex tract is being utilized for; we anticipate new technologies being continually added to the inventory of plugins.
</nextsent>
<nextsent>as will become clear later in the paper, the architecture of this system openly caters for third-party plugin writers.
</nextsent>
<nextsent>figure 1: tex tract architecture specific tex tract configurations may deploy custom subsets of available plugin components, in order to effect certain processing; such configurations typically implement an application for specific content analysis / text mining task.
</nextsent>
<nextsent>from an application point of view, tex tract plugins deposit analysis results in the shared repository; the application itself reads?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2404">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>document application examples to date include document summarization, customer claims analysis system (nasukawa and nagano, 2001), and so forth.
</prevsent>
<prevsent>collection applications have document analysis component, which may also write to the shared repository.
</prevsent>
</prevsection>
<citsent citstr=" W99-0202 ">
these include named relation extraction (byrd and ravin, 1999), custom dictionary building (park, et al., 2001), indexing for question answering (prager et al., 2000), cross-document coreference (ravin and kazi, 1999), <papid> W99-0202 </papid>and statistical collection analysis for document summarization or lexical navigation (cooper and byrd, 1997).</citsent>
<aftsection>
<nextsent>figure 2: tex tracts gui for packaging in applications, tex tract has, in addition to native apis, c api layer for exporting the contents of the data store to external components in c++ or java.
</nextsent>
<nextsent>3 different operational environments.
</nextsent>
<nextsent>for the purposes of interactive (re-)configuration of tex tracts processing chain, rapid application prototyping, and incremental plugin functionality development, the systems underlying infrastructure capabilities are available to graphical interface.
</nextsent>
<nextsent>this allows cont trol over individual plugins; in particular, it exploits the configuration object to dynamically reconfigure specified plugins on demand.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2406">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the talent system, and tex tract in particular, belongs to family of language engineering systems which includes gate (university of sheffield), alembic (mitre corporation), atlas (university of pennsyl vania), among others.
</prevsent>
<prevsent>talent is perhaps closest in spirit to gate.
</prevsent>
</prevsection>
<citsent citstr=" A97-1035 ">
in cunningham, et al (1997), <papid> A97-1035 </papid>gate is described as software infrastructure on top of which heterogeneous nlp processing modules may be evaluated and refined individually or may be combined into larger application systems.?</citsent>
<aftsection>
<nextsent>thus, both talent and gate address the needs of researchers and developers, on the one hand, and of application builders, on the other.
</nextsent>
<nextsent>the gate system architecture comprises three components: the gate document manager (gdm), the collection of reusable objects for language engineering (creole), and the gate graphical interface (ggi).
</nextsent>
<nextsent>gdm, which corresponds to tex tracts driver, engine, and plugin manager, is responsible for managing the storage and transmission (via apis) of the annotations created and manipulated by the nlp processing modules in creole.
</nextsent>
<nextsent>in tex tracts terms, the gdm is responsible for the data model kept in the document and collection objects.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2408">
<title id=" W03-0801.xml">the talent system tex tract architecture and data model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, limitation of the current design is the fixed organization of annotations into families (see section 4).
</prevsent>
<prevsent>this makes it hard to accommodate new plugins which need to appeal to information which is either not naturally encodable in the family space tex tract pre-defines, or requires richer substrate of (possibly mutually dependent) feature sets.
</prevsent>
</prevsection>
<citsent citstr=" W03-0810 ">
in move towards fully declarative representation of linguistic information, where an annotation maximally shares an underlying set of linguistic properties, rational re-design of tex tract (ferrucci and lally, 2003) <papid> W03-0810 </papid>is adopting hierarchical system of feature-based annotation types; it has been demonstrated that even systems supporting strict single inheritance only are powerful enough for variety of linguistic processing applications (shieber, 1986), largely through their well understood mathematical properties (carpenter, 1992).</citsent>
<aftsection>
<nextsent>some of this migration is naturally supported by the initial tex tract data model design.
</nextsent>
<nextsent>other architectural components will require re-tooling; in particular, the fst subsystem will need further extensions for the definition of fs algebra over true typed feature structures (see, for instance, brawer, 1998; wunsch, 2003).
</nextsent>
<nextsent>we will return to this issue in following paper.
</nextsent>
<nextsent>8 acknowledgements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2409">
<title id=" W03-1703.xml">utterance segmentation using combined approach based on bidirectional ngram and maximum entropy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe that accurate segmentation can greatly improve the performance of language analysis modules.
</prevsent>
<prevsent>stevenson et al  have demonstrated the difficulties of text segmentation through an experiment in which six people, educated to at least the bachelors degree level, were required to segment into sentences broadcast transcripts from which all punctuation symbols had been removed.
</prevsent>
</prevsection>
<citsent citstr=" A00-1012 ">
the experimental results show that humans do not always agree on the insertion of punctuation symbols, and that their segmentation performance is not very good (stevenson and gaizauskas, 2000).<papid> A00-1012 </papid></citsent>
<aftsection>
<nextsent>thus it is great challenge for computers to perform the task output (text or speech) language analysis and generation speech recognition input speechautomatically.
</nextsent>
<nextsent>to solve this problem, many methods have been proposed, which can be roughly classified into two categories.
</nextsent>
<nextsent>one approach is based on simple acoustic criteria, such as non speech intervals (e.g. pauses), pitch and energy.
</nextsent>
<nextsent>we can call this approach acoustic segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2410">
<title id=" W03-1703.xml">utterance segmentation using combined approach based on bidirectional ngram and maximum entropy </title>
<section> related work and our motivations.  </section>
<citcontext>
<prevsection>
<prevsent>since this approach is intended to facilitate translation of chi nese-to-english slt systems, it rewrites long sentences as several simple units.
</prevsent>
<prevsent>once again, these results cannot be regarded as general-purpose utterance segmentation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1070 ">
furuse et al  (1998) <papid> P98-1070 </papid>similarly propose an input-splitting method for translating spoken language which includes many long or ill-formed expressions.</citsent>
<aftsection>
<nextsent>the method splits an input into well-balanced translation units, using semantic dictionary.
</nextsent>
<nextsent>ramaswamy et al  (1998) applied maximum entropy approach to the detection of command boundaries in conversational natural language user interface.
</nextsent>
<nextsent>they considered as their features words and their distances to potential boundaries.
</nextsent>
<nextsent>they posited 400 feature functions, and trained their weights using 3000 commands.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2411">
<title id=" W03-1703.xml">utterance segmentation using combined approach based on bidirectional ngram and maximum entropy </title>
<section> related work and our motivations.  </section>
<citcontext>
<prevsection>
<prevsent>the features they considered included the candidates prefix and suffix; the presence of particular characters in the prefix or suffix; whether the candidate was honorific (e.g. mr., dr.); and whether the candidate was corporate designator (e.g. corp.).
</prevsent>
<prevsent>the system was tested on the brown corpus, and achieved precision of 98.8%.
</prevsent>
</prevsection>
<citsent citstr=" P99-1026 ">
elsewhere, nakano et al  (1999) <papid> P99-1026 </papid>proposed method for incrementally understanding user utterances whose semantic boundaries were unknown.</citsent>
<aftsection>
<nextsent>the method operated by incrementally finding plausible sequences of utterances that play crucial roles in the task execution of dialogues, and by utilizing beam search to deal with the ambiguity of boundaries and with syntactic and semantic ambiguities.
</nextsent>
<nextsent>though the method does not require utterance segmentation before discourse processing, it employs special rule tables for discontinuation of significant utterance boundaries.
</nextsent>
<nextsent>such rule tables are not easy to maintain, and experimental results have demonstrated only that the method outperformed the method assuming pauses to be semantic boundaries.
</nextsent>
<nextsent>2.2 our motivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2412">
<title id=" W02-0904.xml">building a hyponymy lexicon with hierarchical structure </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the lexicon will thus, reflect partial hierarchical hyponymy structures that bring forward extended hypernym-hyponym relations.
</prevsent>
<prevsent>section 2 describes previous work in the area of automatic acquisition of semantic lexicons, section 3 elaborates on the principles for this work, and the remaining sections describe the implementation as well as the evaluation of the algorithm for building hierarchical hyponymy lexicon.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
one of the first studies on acquisition of hyponymy relations was made by hearst (1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>she found that certain lexico-syntactic constructions can be used as indicators of the hyponymy relation between words in text.
</nextsent>
<nextsent>example 1 shows relation of this kind and an example.
</nextsent>
<nextsent>the noun phrase ?
</nextsent>
<nextsent> ? is hypernym and ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2416">
<title id=" W02-0904.xml">building a hyponymy lexicon with hierarchical structure </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>find new useful syntactic patterns.
</prevsent>
<prevsent>hyponym examples.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
continue at 1.caraballo (1999) <papid> P99-1016 </papid>uses hierarchical clustering technique to build hyponymy hierarchy of nouns.</citsent>
<aftsection>
<nextsent>the internal nodes are labeled by the syntactic constructions from hearst (1992).<papid> C92-2082 </papid></nextsent>
<nextsent>each internal node in the hierarchy can be represented by up to three nouns.work by riloff &amp; shepherd (1997) <papid> W97-0313 </papid>and charniak &amp; roark (1998) aims to build semantic lexicons where the words included in each category or entry are related to, or are member of the category.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2422">
<title id=" W02-0904.xml">building a hyponymy lexicon with hierarchical structure </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>continue at 1.caraballo (1999) <papid> P99-1016 </papid>uses hierarchical clustering technique to build hyponymy hierarchy of nouns.</prevsent>
<prevsent>the internal nodes are labeled by the syntactic constructions from hearst (1992).<papid> C92-2082 </papid></prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
each internal node in the hierarchy can be represented by up to three nouns.work by riloff &amp; shepherd (1997) <papid> W97-0313 </papid>and charniak &amp; roark (1998) aims to build semantic lexicons where the words included in each category or entry are related to, or are member of the category.</citsent>
<aftsection>
<nextsent>sanderson &amp; croft (1999) build hierarchical structures of concepts on the basis of generality and specificity.
</nextsent>
<nextsent>they use material divided by different text categories and base the decision of subsumption on term co-occurrence in the different categories.
</nextsent>
<nextsent>a term is said to subsume if the documents in which occurs are subset of the documents in which occurs.
</nextsent>
<nextsent>the relations between concepts in their subsumption hierarchy are of different kinds(among other the hyponymy relation), and are unlabeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2424">
<title id=" W02-0904.xml">building a hyponymy lexicon with hierarchical structure </title>
<section> corpus and relevant terms.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus used for this research consists of293,692 articles from the swedish daily news paper dagens nyheter?.
</prevsent>
<prevsent>the corpus was tokenized,tagged and lemmatized.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the tagger we used, implemented by megyesi (2001) for swedish, is thetnt-tagger (brants, 2000), <papid> A00-1031 </papid>trained on the succor pus (ejerhed et al, 1992).</citsent>
<aftsection>
<nextsent>after preprocessing, the corpus was labeled for base noun phrases (basenp).a basenp includes optional determiners and/or premodifiers, followed by nominal heads.
</nextsent>
<nextsent>naturally, conceptually relevant terms, rather than noun phrases, should be placed in the lexicon and the hierarchies.
</nextsent>
<nextsent>for reasons of simplification, though, the choice was made as to treat nominal heads with pre modifying nouns in genitive (within the limits of the basenp described above) as the relevant termsto include in the hierarchies.
</nextsent>
<nextsent>however, premodifiers describing amounts, such as kilo?, are never included in the relevant terms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2433">
<title id=" W02-0904.xml">building a hyponymy lexicon with hierarchical structure </title>
<section> results &amp; evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the second, at-least-one, gives the percentage of d-pairs where at least one of the judges deemed the pair as correct.
</prevsent>
<prevsent>the majority is the percentage of d-pairs where at least two deemed the pair as correct, and the consensus option refers to the percentage of d-pairs where all judges agreed.the at-least-one option, the least strict of the measures, give us 82.2% correct, while the most strict (the consensus) gives us 41.6% correct.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the kappa value (carletta, 1996) <papid> J96-2004 </papid>was used to evaluate the agreement among the judges and to estimate how difficult the evaluation task was.</citsent>
<aftsection>
<nextsent>not average 62.5% at-least-one 82.2% majority 71.0% consensus 41.6% kappa = 0.51 table 5: statistics on results from evaluation of 1,000 d-pairs, by four judges.
</nextsent>
<nextsent>surprisingly, as evaluation of semantic information, in general, is hard to perform on purely objective grounds, the kappa value is rather low; that is, the value for four annotators on the 1,000 d-pairs is k=0.51.
</nextsent>
<nextsent>the low kappa value for the evaluation task reflects the great many problems of evaluations of semantic resources by humans.
</nextsent>
<nextsent>some of these problems are discussed below: while lemmatization or stemming is necessary for performing this kind of task, it may also cause problems in cases where morphology is important for correct classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2441">
<title id=" W02-1001.xml">discriminative training methods for hidden markov models theory and experiments with perceptron algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for maximum-entropy tagger (a11.9% relative reduction in error for pos tagging, 5.1% relative reduction in error for np chunking).
</prevsent>
<prevsent>although we concentrate on tagging problems in this paper, the theoretical framework and algorithm described in section 3 ofthis paper should be applicable to wide variety of models where viterbi-style algorithm scan be used for decoding: examples are probabilistic context-free grammars, or me models for parsing.
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
see (collins and duy 2001; collin sand duy 2002; collins 2002) <papid> P02-1062 </papid>for other applications of the voted perceptron to nlp problems.</citsent>
<aftsection>
<nextsent>1
</nextsent>
<nextsent>2.1 hmm taggers.
</nextsent>
<nextsent>in this section, as motivating example, we describe special case of the algorithm in thispaper: the algorithm applied to trigram tagger.
</nextsent>
<nextsent>in trigram hmm tagger, each trigram 1the theorems in section 3, and the proofs in section 5, apply directly to the work in these other papers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2442">
<title id=" W03-1102.xml">a practical text summarizer by paragraph extraction for thai </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, most of recent works in this research area are based on extraction (goldstein et al ,1999).
</prevsent>
<prevsent>although one may argue that extraction approach makes the text hard to read due to the lack of coherence, it also depends on the objective of summarization.
</prevsent>
</prevsection>
<citsent citstr=" E99-1011 ">
if we need to generate summaries that can be used to indicative what topics are addressed in the original document, and thus can be used toalert the uses as the source content, i.e., the indicative function (mani et al , 1999), <papid> E99-1011 </papid>extraction approach is capable of handling this kind of tasks.there have been many researches on text summarization problem.</citsent>
<aftsection>
<nextsent>however, in thai, we are inthe initial stage of developing mechanisms for automatically summarizing documents.
</nextsent>
<nextsent>it is challenge to summarize these documents, since they are extremely different from documents written in english.
</nextsent>
<nextsent>similar to chinese or japanese, for the thai writing system, there are no boundaries between adjoining words, and also there are no explicit sentences boundaries within the document.
</nextsent>
<nextsent>fortunately, there is the use of the paragraph structure in thethai writing system, which is indicated by indentations and blank lines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2443">
<title id=" W03-1102.xml">a practical text summarizer by paragraph extraction for thai </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>many research questions remain.
</prevsent>
<prevsent>since extraction performs at the paragraph level, the paragraph lengths may affect the summarization results.
</prevsent>
</prevsection>
<citsent citstr=" A00-2024 ">
the recent approach for editing extracted text spans (jing and mckeown,2000) <papid> A00-2024 </papid>may also produce improvement for our algorithm.</citsent>
<aftsection>
<nextsent>we believe that our algorithm is language independent, which can summarize documents written in many other languages.
</nextsent>
<nextsent>we plan to experimentally test our algorithm with available standard datasets in english.
</nextsent>
<nextsent>acknowledgments this research was supported by the grant of the national research council of thailand, 2002.
</nextsent>
<nextsent>many thanks to tan sinthurahat (thammasat university) for manual summarizing the datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2444">
<title id=" W03-1008.xml">identifying semantic roles using combinatory categorial grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2) the door opened.
</prevsent>
<prevsent>mary opened the door.recently, attention has turned to creating corpora annotated with argument structures.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the propbank (kingsbury and palmer, 2002) and the framenet (baker et al, 1998) <papid> P98-1013 </papid>projects both document the variation in syntactic realization of the arguments of predicates in general english text.</citsent>
<aftsection>
<nextsent>gildea and palmer (2002) <papid> P02-1031 </papid>developed system to predict semantic roles (as defined in propbank) from sentences and their parse trees as determined by the statistical parser of collins (1999).</nextsent>
<nextsent>in this paper, we examine how the syntactic representations used by different statistical parsers affect the performance of such system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2445">
<title id=" W03-1008.xml">identifying semantic roles using combinatory categorial grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mary opened the door.recently, attention has turned to creating corpora annotated with argument structures.
</prevsent>
<prevsent>the propbank (kingsbury and palmer, 2002) and the framenet (baker et al, 1998) <papid> P98-1013 </papid>projects both document the variation in syntactic realization of the arguments of predicates in general english text.</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
gildea and palmer (2002) <papid> P02-1031 </papid>developed system to predict semantic roles (as defined in propbank) from sentences and their parse trees as determined by the statistical parser of collins (1999).</citsent>
<aftsection>
<nextsent>in this paper, we examine how the syntactic representations used by different statistical parsers affect the performance of such system.
</nextsent>
<nextsent>we compare parser based oncombinatory categorial grammar (ccg) (hocken maier and steedman, 2002<papid> P02-1043 </papid>b) with the collins parser.as the ccg parser is trained and tested on corpus of ccg derivations that have been obtained by automatic conversion from the penn treebank, weare able to compare performance using both gold standard and automatic parses for both ccg and the traditional treebank representation.</nextsent>
<nextsent>the treebank parser returns skeletal phrase-structure trees with out the traces or functional tags in the original penn treebank, whereas the ccg parser returns word word dependencies that correspond to the underlying predicate-argument structure, including long range dependencies arising through control, raising, extraction and coordination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2447">
<title id=" W03-1008.xml">identifying semantic roles using combinatory categorial grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>gildea and palmer (2002) <papid> P02-1031 </papid>developed system to predict semantic roles (as defined in propbank) from sentences and their parse trees as determined by the statistical parser of collins (1999).</prevsent>
<prevsent>in this paper, we examine how the syntactic representations used by different statistical parsers affect the performance of such system.</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
we compare parser based oncombinatory categorial grammar (ccg) (hocken maier and steedman, 2002<papid> P02-1043 </papid>b) with the collins parser.as the ccg parser is trained and tested on corpus of ccg derivations that have been obtained by automatic conversion from the penn treebank, weare able to compare performance using both gold standard and automatic parses for both ccg and the traditional treebank representation.</citsent>
<aftsection>
<nextsent>the treebank parser returns skeletal phrase-structure trees with out the traces or functional tags in the original penn treebank, whereas the ccg parser returns word word dependencies that correspond to the underlying predicate-argument structure, including long range dependencies arising through control, raising, extraction and coordination.
</nextsent>
<nextsent>propbank the proposition bank (kingsbury and palmer, 2002) provides human-annotated corpus of semantic verb-argument relations.
</nextsent>
<nextsent>for each verb appearing in the corpus, set of semantic roles is defined.
</nextsent>
<nextsent>roles for each verb are simply numberedarg0, arg1, arg2, etc. as an example, the entry specific roles for the verb offer are given below: arg0 entity offering arg1 commodity arg2 price arg3 benefactive or entity offered to these roles are then annotated for every instance of the verb appearing in the corpus, including the following examples: (3) [arg0 the company] to offer [arg1 15% stake] to [arg2 the public].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2455">
<title id=" W03-1008.xml">identifying semantic roles using combinatory categorial grammar </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the interpolation is performed over the most specific distributions for which data are available, which can be thought of as choosing the topmost distributions available from backoff lattice, shown in figure 3.
</prevsent>
<prevsent>p(r | h) p(r | h, pt, p) p(r | pt, p) p(r | p) p(r | pt, path, p) p(r | h, p) p(r | pt, pos, v, p) p(r | pt, pos, v)figure 3: backoff lattice with more specific distributions towards the top.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the probabilities (r |f , p) are combined with the probabilities ({r 1..n}|p) for set of roles appearing in sentence given predicate, using the following formula: (r 1..n |f 1..n , p) ? ({r 1..n }|p) ? p (r |f , p) (r |p) this approach, described in more detail ingildea and jurafsky (2002), <papid> J02-3001 </papid>allows interaction between the role assignments for individual constituents while making certain independence assumptions necessary for efficient probability estimation.</citsent>
<aftsection>
<nextsent>in particular, we assume that sets of roles appear independent of their linear order, and that the features of constituents are independent of other constituents?
</nextsent>
<nextsent>features given the constituents role.
</nextsent>
<nextsent>5.2 the model for ccg derivations.
</nextsent>
<nextsent>in the ccg version, we replace the features above with corresponding features based on both the sentences ccg derivation tree (shown in figure 1) and the ccg predicate-argument relations extracted from it (shown in table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2457">
<title id=" W03-1008.xml">identifying semantic roles using combinatory categorial grammar </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we speculate that much of the performance improvement we show could be obtained with traditional (ie.
</prevsent>
<prevsent>non-ccg-based) parser sif they were designed to recover more of the information present in the penn treebank, in particular the trace co-indexation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
an interesting experiment would be the application of our role-labeling system to the output of the trace recovery system of johnson (2002).<papid> P02-1018 </papid></citsent>
<aftsection>
<nextsent>our results also have implications for parser evaluation, as the most frequently used constituent-based precision and recall measures do not evaluate how well long-range dependencies can be recovered from the output of parser.
</nextsent>
<nextsent>measures based on dependencies, such as those of lin (1995)and carroll et al (1998), are likely to be more relevant to real-world applications of parsing.acknowledgments this work was supported by the institute for research in cognitive science at the university of pennsylvania, the propbank project (dod grant mda904-00c 2136), an epsrc studentship and grant gr/m96889, and nsf itr grant 0205 456.
</nextsent>
<nextsent>we thank mark steedman, martha palmer and alexandra kinyon for their comments on this work.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2458">
<title id=" W02-1116.xml">a maximum entropy approach to hownetbased chinese word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a word usually has more than one meaning or sense, which are listed in the dictionary.
</prevsent>
<prevsent>the task of word sense disambiguation (wsd) is to make the choice between the senses for particular usage of the word in context.
</prevsent>
</prevsection>
<citsent citstr=" W00-1209 ">
there are, however, several difficulties to wsd (yang et al 2000): (<papid> W00-1209 </papid>i) the evaluation of word sense disambiguation system is not yet standardized.</citsent>
<aftsection>
<nextsent>(ii) the potential for wsd varies by task.
</nextsent>
<nextsent>(iii) sense-tagged corpora are crucial resources for wsd but they are difficult to obtain.
</nextsent>
<nextsent>efforts in building large chinese corpora started in the 90s, for example, the sinica corpus (ckip, 1995) and the chinese penn tree bank (xia et al, 2000).
</nextsent>
<nextsent>however, these two corpora concentrate on the tagging of parts-of-speech and syntactic structures, while little work has been done on semantic annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2459">
<title id=" W02-1116.xml">a maximum entropy approach to hownetbased chinese word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the release of hownet (dong, 1999; dong, 2000) in 1 http://www.cslp.com.nus.edu/sg/cslp/ 1999, gan and tham (1999) manually annotated chinese corpus of 30,000 words with the senses from hownet.
</prevsent>
<prevsent>the corpus is subset of the sinica balanced corpus, and consists of 103 narratives on news stories, in which the words have already been segmented and tagged with parts-of-speech.
</prevsent>
</prevsection>
<citsent citstr=" W00-1213 ">
gan and tham (1999) added sense tagging and subsequently gan and wong (2000) <papid> W00-1213 </papid>annotated the corpus with semantic dependency relations as defined in hownet.</citsent>
<aftsection>
<nextsent>the corpus was released to the public in january 2002 2 , providing essential resources for chinese word sense disambiguation.
</nextsent>
<nextsent>this paper is organized as follows: section 2 gives an introduction of hownet.
</nextsent>
<nextsent>section 3 describes the wsd task and the experiment results.
</nextsent>
<nextsent>section 4 describes the previous work, followed by conclusion in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2463">
<title id=" W02-1116.xml">a maximum entropy approach to hownetbased chinese word sense disambiguation </title>
<section> task description.  </section>
<citcontext>
<prevsection>
<prevsent>3.2.1.
</prevsent>
<prevsent>maximum entropy tagger the goal of this work is to investigate the possibility of applying standard pos taggers to identify word sense tags.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
for this work, an off-the-shelf maximum entropy tagger 10 (ratnaparkhi, 1996) <papid> W96-0213 </papid>was used.</citsent>
<aftsection>
<nextsent>each word is therefore tagged with sememe (categorical attribute), which is treated equivalently to pos tag by the tagger, whose goal it is to generate 9 sentences are delimited by the following punctuations 576 : ; ! ?
</nextsent>
<nextsent>10 ftp://ftp.cis.upenn.edu/pub/adwait/jmx/jmx.tar.gz sense tag dictionary from the training data.
</nextsent>
<nextsent>in the following subsections, we will first explain the semantic tags used in the current research, its limitations and suggestion for resolving the problem, and then illustrate how to build the tag dictionary for the maxent sense tagger.
</nextsent>
<nextsent>3.2.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2468">
<title id=" W03-1808.xml">verb particle constructions and lexical resources </title>
<section> vpcs in corpora.  </section>
<citcontext>
<prevsection>
<prevsent>the coverage of these resources is quite limited and possible ways of extending it are necessity for successful nlp systems.
</prevsent>
<prevsent>the use of corpora to extract verb-particle combinations can contribute to extending the coverage of dictionaries.
</prevsent>
</prevsection>
<citsent citstr=" W02-2001 ">
an investigation of the automatic extraction of vpcs from corpora is described in baldwin and villavicencio (2002).<papid> W02-2001 </papid></citsent>
<aftsection>
<nextsent>in this section we use vpcs extracted from the british national corpus (bnc), comparing these vpcs with those contained in the combined a+c+e-vpcs, and discussing how the former can be used to complement the coverage provided by the latter.the bnc is 100 million word corpus containing samples of written text from wide variety of sources, designed to represent as wide range of modern british english as possible.
</nextsent>
<nextsent>using the methods described in baldwin and villavicencio (2002), <papid> W02-2001 </papid>8,751 vpc entries were extracted from the bnc.</nextsent>
<nextsent>these entries are classified into in transitive and/ortransitive vpcs, depending on their subcategorisation frame, and they result in 7,078 distinct vpcs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2470">
<title id=" W03-1808.xml">verb particle constructions and lexical resources </title>
<section> vpc patterns in levins verb classes.  </section>
<citcontext>
<prevsection>
<prevsent>more investigation is needed to verify whether the un attested combinations, specially in the lower ranked classes are invalid or simply did not occur in the dictionaries or in the corpus,because the problem of data sparseness is especially accute for vpcs.
</prevsent>
<prevsent>moreover, it is also necessary to determine the precise semantics of thesevpcs, even though we expect that the more productive classes generate vpcs compositionally, combining the semantics of the verb and particle together.
</prevsent>
</prevsection>
<citsent citstr=" W03-1809 ">
possible alternatives for dealing with this issue are discussed by both bannard et al (2003) <papid> W03-1809 </papid>and mccarthy et al (2003).<papid> W03-1810 </papid></citsent>
<aftsection>
<nextsent>furthermore, although there are some cases where it appears reason able to treat vpcs as fully productive, there arealso cases of semi-productivity (e.g. verbs denoting cooking processes and aspect ual up: boil up and heat up, but not saute up), as discussed by villavicencio and copestake (2002), so it is important to determine which classes are fully productive and which are not.
</nextsent>
<nextsent>we investigated the identification of regular patterns among verb-particle constructions using dictionaries, corpora and levins classes.
</nextsent>
<nextsent>these results suggest that levins classes provide us with productive patterns of vpcs.
</nextsent>
<nextsent>candidate vpcs generated from these classes can help us improve the coverage of current lexical resources, as shown in this investigation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2471">
<title id=" W03-1808.xml">verb particle constructions and lexical resources </title>
<section> vpc patterns in levins verb classes.  </section>
<citcontext>
<prevsection>
<prevsent>more investigation is needed to verify whether the un attested combinations, specially in the lower ranked classes are invalid or simply did not occur in the dictionaries or in the corpus,because the problem of data sparseness is especially accute for vpcs.
</prevsent>
<prevsent>moreover, it is also necessary to determine the precise semantics of thesevpcs, even though we expect that the more productive classes generate vpcs compositionally, combining the semantics of the verb and particle together.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
possible alternatives for dealing with this issue are discussed by both bannard et al (2003) <papid> W03-1809 </papid>and mccarthy et al (2003).<papid> W03-1810 </papid></citsent>
<aftsection>
<nextsent>furthermore, although there are some cases where it appears reason able to treat vpcs as fully productive, there arealso cases of semi-productivity (e.g. verbs denoting cooking processes and aspect ual up: boil up and heat up, but not saute up), as discussed by villavicencio and copestake (2002), so it is important to determine which classes are fully productive and which are not.
</nextsent>
<nextsent>we investigated the identification of regular patterns among verb-particle constructions using dictionaries, corpora and levins classes.
</nextsent>
<nextsent>these results suggest that levins classes provide us with productive patterns of vpcs.
</nextsent>
<nextsent>candidate vpcs generated from these classes can help us improve the coverage of current lexical resources, as shown in this investigation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2472">
<title id=" W02-0807.xml">sense information for disambiguation confluence of supervised and unsupervised methods </title>
<section> dictionary preparation.  </section>
<citcontext>
<prevsection>
<prevsent>for each word, the sub dictionaries consisted of the main word and all entries identifiable from the phrase dictionary for that word.
</prevsent>
<prevsent>(for bar, in node, there were 13 entries where bar was the first word in an mwu and 50 entries where it was the head noun; for begin, there was only one entry.)
</prevsent>
</prevsection>
<citsent citstr=" W99-0505 ">
the node dictionaries were then mapped into the wordnet dictionaries (see litkowski, 1999), <papid> W99-0505 </papid>using overlap among words and semantic relations.</citsent>
<aftsection>
<nextsent>the 73 dictionaries for the lexical sample words gave rise to 1372 wordnet entries and 1722 node entries.
</nextsent>
<nextsent>only 491 entries (of which, 418 were mwus) were common (i.e., no mappings were available for the remaining 1231 node entries, all of which were mwus); 881 entries in wordnet were therefore inaccessible through node.
</nextsent>
<nextsent>for the entries in common, there was an average of 5.6 senses, of which only 64% were mappable into wordnet, thus creating our initial impression that use of node would not be feasible.
</nextsent>
<nextsent>3
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2473">
<title id=" W03-0601.xml">word sense disambiguation with pictures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>results on this data strongly suggest that images can help with word sense disambiguation.
</prevsent>
<prevsent>in this paper we investigate using words and pictures to disambiguate each other.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
word sense disambiguation has long been studied as an important problem in natural language processing (agirre and rigau, 1995; gale et al, 1992; <papid> H92-1045 </papid>manning and schtze, 1999; mihalcea and moldovan., 1998; <papid> W98-0703 </papid>traupman and wilensky, 2003; yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>it is illustrated in figure 1 with the arguably overused bank?
</nextsent>
<nextsent>example.
</nextsent>
<nextsent>a priori, the word bank?
</nextsent>
<nextsent>has number of meanings including financial institution and step or edge as in snow bank?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2474">
<title id=" W03-0601.xml">word sense disambiguation with pictures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>results on this data strongly suggest that images can help with word sense disambiguation.
</prevsent>
<prevsent>in this paper we investigate using words and pictures to disambiguate each other.
</prevsent>
</prevsection>
<citsent citstr=" W98-0703 ">
word sense disambiguation has long been studied as an important problem in natural language processing (agirre and rigau, 1995; gale et al, 1992; <papid> H92-1045 </papid>manning and schtze, 1999; mihalcea and moldovan., 1998; <papid> W98-0703 </papid>traupman and wilensky, 2003; yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>it is illustrated in figure 1 with the arguably overused bank?
</nextsent>
<nextsent>example.
</nextsent>
<nextsent>a priori, the word bank?
</nextsent>
<nextsent>has number of meanings including financial institution and step or edge as in snow bank?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2475">
<title id=" W03-0601.xml">word sense disambiguation with pictures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>results on this data strongly suggest that images can help with word sense disambiguation.
</prevsent>
<prevsent>in this paper we investigate using words and pictures to disambiguate each other.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
word sense disambiguation has long been studied as an important problem in natural language processing (agirre and rigau, 1995; gale et al, 1992; <papid> H92-1045 </papid>manning and schtze, 1999; mihalcea and moldovan., 1998; <papid> W98-0703 </papid>traupman and wilensky, 2003; yarowsky, 1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>it is illustrated in figure 1 with the arguably overused bank?
</nextsent>
<nextsent>example.
</nextsent>
<nextsent>a priori, the word bank?
</nextsent>
<nextsent>has number of meanings including financial institution and step or edge as in snow bank?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2477">
<title id=" W03-0417.xml">training a naive bayes classifier via the em algorithm with a class distribution constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental results from using 26 confusion sets and large amount of unlabeled data show that our proposed method for using unlabeled data considerably improves classification performance when the amount of labeled data is small.
</prevsent>
<prevsent>many of the tasks in natural language processing canbe addressed as classification problems.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
state-of-theart machine learning techniques including support vector machines (vapnik, 1995), ada boost (schapire and singer, 2000) and maximum entropy models (ratnaparkhi, 1998; berger et al, 1996) <papid> J96-1002 </papid>provide high performance classifiers if one has abundant correctly labeled examples.</citsent>
<aftsection>
<nextsent>however, annotating large set of examples generally requires huge amount of human labor and time.
</nextsent>
<nextsent>this annotation cost is one of the major obstacles to applying machine learning techniques to real-world nlp applica tions.recently, learning algorithms called minimally supervised learning or unsupervised learning that can make use of unlabeled data have received much attention.
</nextsent>
<nextsent>since collecting unlabeled data is generally much easier than annotating data, such techniques have potential for solving the problem of annotation cost.
</nextsent>
<nextsent>those approaches include naive bayes classifier combined with the em algorithm (dempster et al, 1977; nigam et al, 2000; pedersen and bruce, 1998), co-training (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>nigam and ghani, 2000), and transductive support vector machines (joachims, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2478">
<title id=" W03-0417.xml">training a naive bayes classifier via the em algorithm with a class distribution constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this annotation cost is one of the major obstacles to applying machine learning techniques to real-world nlp applica tions.recently, learning algorithms called minimally supervised learning or unsupervised learning that can make use of unlabeled data have received much attention.
</prevsent>
<prevsent>since collecting unlabeled data is generally much easier than annotating data, such techniques have potential for solving the problem of annotation cost.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
those approaches include naive bayes classifier combined with the em algorithm (dempster et al, 1977; nigam et al, 2000; pedersen and bruce, 1998), co-training (blum and mitchell, 1998; collins and singer, 1999; <papid> W99-0613 </papid>nigam and ghani, 2000), and transductive support vector machines (joachims, 1999).</citsent>
<aftsection>
<nextsent>these algorithms have been applied to some tasks including text classification and word sense disambiguation and their effectiveness has been demonstrated to some extent.combining naive bayes classifier with the em algorithm is one of the promising minimally supervised approaches because its computational cost is low (linear to the size of unlabeled data), and it does not require the features to be split into two independent sets unlike co training.
</nextsent>
<nextsent>however, the use of unlabeled data via the basic emalgorithm does not always improve classification performance.
</nextsent>
<nextsent>in fact, this often causes disastrous performance degradation resulting in poor classification performance on average.
</nextsent>
<nextsent>to alleviate this problem, we introduce class distribution constraint into the iteration process ofthe em algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2479">
<title id=" W03-0417.xml">training a naive bayes classifier via the em algorithm with a class distribution constraint </title>
<section> naive bayes classifier.  </section>
<citcontext>
<prevsection>
<prevsent>section 7 offers some concluding remarks.
</prevsent>
<prevsent>the naive bayes classifier is simple but effective classifier which has been used in numerous applications of information processing such as image recognition, natural language processing, information retrieval, etc.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
(escud ero et al, 2000; lewis, 1998; nigam and ghani, 2000; pedersen, 2000).<papid> A00-2009 </papid>in this section, we briefly review the naive bayes classifier and the em algorithm that is used for making use of unlabeled data.</citsent>
<aftsection>
<nextsent>2.1 naive bayes model.
</nextsent>
<nextsent>let
</nextsent>
<nextsent>x be vector we want to classify, and ck be possible class.
</nextsent>
<nextsent>what we want to know is the probability that the vector
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2480">
<title id=" W03-0417.xml">training a naive bayes classifier via the em algorithm with a class distribution constraint </title>
<section> transform q.  </section>
<citcontext>
<prevsection>
<prevsent>an automatic proofreading system would need to judge which is the correct use given the context surrounding the target.
</prevsent>
<prevsent>example confusion sets in clude: {principle, principal}, {then, than}, and {weather, whether}.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
until now, many methods have been proposed for this problem including winnow-based algorithms (golding and roth, 1999), differential grammars (powers, 1998), transformation based learning (mangu and brill, 1997), decision lists (yarowsky, 1994).<papid> P94-1013 </papid>confusion set disambiguation has very similar characteristics to word sense disambiguation problem inwhich the system has to identify the meaning of pol ysemous word given the surrounding context.</citsent>
<aftsection>
<nextsent>the merit of using confusion set disambiguation as test-bed for alearning algorithm is that since one does not need to annotate the examples to make labeled data, one can conduct experiments using an arbitrary amount of labeled data.
</nextsent>
<nextsent>4.1 features.
</nextsent>
<nextsent>as the input of the classifier, the context of the target must be represented in the form of vector.
</nextsent>
<nextsent>we use binary feature vector which contains only the values of 0 or 1 for each element.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2481">
<title id=" W03-0417.xml">training a naive bayes classifier via the em algorithm with a class distribution constraint </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pedersen et al(1998) employed the em algorithm and gibbs sampling for word sense disambiguation by usinga naive bayes classifier.
</prevsent>
<prevsent>although gibbs sampling results in small improvement over the em algorithm, the results for verbs and adjectives did not reach baseline performance on average.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the amount of unlabeled data used in their experiments was relatively small (from several hundreds to few thousands).yarowsky (1995) <papid> P95-1026 </papid>presented an approach that significantly reduces the amount of labeled data needed forword sense disambiguation.</citsent>
<aftsection>
<nextsent>yarowsky achieved accuracies of more than 90% for two-sense polysemous words.
</nextsent>
<nextsent>this success was likely due to the use of one sense per discourse?
</nextsent>
<nextsent>characteristic of polysemous words.
</nextsent>
<nextsent>yarowskys approach can be viewed in the context ofco-training (blum and mitchell, 1998) in which the features can be split into two independent sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2482">
<title id=" W03-0417.xml">training a naive bayes classifier via the em algorithm with a class distribution constraint </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>characteristic.
</prevsent>
<prevsent>confusion sets however do not have the latter characteristic.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
the effect of huge amount of unlabeled data for confusion set disambiguation is discussed in (banko and brill, 2001).<papid> P01-1005 </papid></citsent>
<aftsection>
<nextsent>bank and brill conducted experiments ofcommittee-based unsupervised learning for two confusion sets.
</nextsent>
<nextsent>their results showed that they gained slight improvement by using certain amount of unlabeleddata.
</nextsent>
<nextsent>however, test set accuracy began to decline as additional data were harvested.as for the performance of confusion set disambiguation, golding (1999) achieved over 96% by winnow based approach.
</nextsent>
<nextsent>although our results are not directly comparable with their results since the datasets are different, our results does not reach the state-of-the art performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2483">
<title id=" W02-1802.xml">some considerations on guidelines for bilingual alignment and terminology extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the discussion in the paper is based on issues arising from the extraction of bilingual legal terms from aligned chinese-english legal corpus in the implementation of bilingual text retrieval system for the judiciary of the hongkong special administrative region (hksar) government.
</prevsent>
<prevsent>much attention in computational terminology has been directed to the development of algorithms for extraction from parallel texts.
</prevsent>
</prevsection>
<citsent citstr=" C00-1015 ">
for example, chinese-english (wu and xia 1995), swedish-english-polish (borin 2000), <papid> C00-1015 </papid>and chinese-korean (huang and choi 2000).<papid> P00-1050 </papid></citsent>
<aftsection>
<nextsent>despite considerable progress, bilingual terminology so generated is often not ready for immediate and practical use.
</nextsent>
<nextsent>machine extraction is often the first step of terminology extraction and must be used in conjunction with rigorous and well-managed manual efforts which are critical for the production of consistent and useable multilingual terminology.
</nextsent>
<nextsent>however, there has been relatively little discussion on the significance of human intervention.
</nextsent>
<nextsent>the process is far from being straightforward because of the different purposes of alignment, the requirements of target users and the corpus type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2484">
<title id=" W02-1802.xml">some considerations on guidelines for bilingual alignment and terminology extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the discussion in the paper is based on issues arising from the extraction of bilingual legal terms from aligned chinese-english legal corpus in the implementation of bilingual text retrieval system for the judiciary of the hongkong special administrative region (hksar) government.
</prevsent>
<prevsent>much attention in computational terminology has been directed to the development of algorithms for extraction from parallel texts.
</prevsent>
</prevsection>
<citsent citstr=" P00-1050 ">
for example, chinese-english (wu and xia 1995), swedish-english-polish (borin 2000), <papid> C00-1015 </papid>and chinese-korean (huang and choi 2000).<papid> P00-1050 </papid></citsent>
<aftsection>
<nextsent>despite considerable progress, bilingual terminology so generated is often not ready for immediate and practical use.
</nextsent>
<nextsent>machine extraction is often the first step of terminology extraction and must be used in conjunction with rigorous and well-managed manual efforts which are critical for the production of consistent and useable multilingual terminology.
</nextsent>
<nextsent>however, there has been relatively little discussion on the significance of human intervention.
</nextsent>
<nextsent>the process is far from being straightforward because of the different purposes of alignment, the requirements of target users and the corpus type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2485">
<title id=" W03-1501.xml">learning formulation and transformation rules for multilingual named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>capturing named entities is fundamental task to understanding documents (muc, 1998).
</prevsent>
<prevsent>several approaches have been proposed to recognize these types of terms.
</prevsent>
</prevsection>
<citsent citstr=" C96-1039 ">
for example, corpus-based methods are employed to extract chinese personal names, and rule-based methods are used to extract chinese date/time expressions and monetary and percentage expressions (chen and lee, 1996; <papid> C96-1039 </papid>chen, ding and tsai, 1998).</citsent>
<aftsection>
<nextsent>in the past, named entity extraction mainly focuses on general domains and is employed to various applications such as information retrieval (chen, ding and tsai, 1998), question-answering (lin, et al, 2001), and so on.
</nextsent>
<nextsent>recently, several attempts have been extended to mine knowledge from biomedical documents (hirschman, et al, 2002).
</nextsent>
<nextsent>most of the previous approaches dealt with monolingual named entity extraction.
</nextsent>
<nextsent>chen et al (1998) <papid> P98-1036 </papid>extended it to cross-language information retrieval.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2486">
<title id=" W03-1501.xml">learning formulation and transformation rules for multilingual named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, several attempts have been extended to mine knowledge from biomedical documents (hirschman, et al, 2002).
</prevsent>
<prevsent>most of the previous approaches dealt with monolingual named entity extraction.
</prevsent>
</prevsection>
<citsent citstr=" P98-1036 ">
chen et al (1998) <papid> P98-1036 </papid>extended it to cross-language information retrieval.</citsent>
<aftsection>
<nextsent>a grapheme-based model was proposed to compute the similarity between chinese transliteration name and english name.
</nextsent>
<nextsent>lin and chen (2000) further classified the works into two directions ? say, forward transliteration (wan and verspoor, 1998) <papid> P98-2220 </papid>and backward transliteration (chen et al, 1998; <papid> P98-1036 </papid>knight and graehl, 1998), <papid> J98-4003 </papid>and proposed phoneme-based model.</nextsent>
<nextsent>lin and chen (2002) <papid> W02-2017 </papid>employed machine learning approach to determine phonetic similarity scores for machine transliteration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2487">
<title id=" W03-1501.xml">learning formulation and transformation rules for multilingual named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>chen et al (1998) <papid> P98-1036 </papid>extended it to cross-language information retrieval.</prevsent>
<prevsent>a grapheme-based model was proposed to compute the similarity between chinese transliteration name and english name.</prevsent>
</prevsection>
<citsent citstr=" P98-2220 ">
lin and chen (2000) further classified the works into two directions ? say, forward transliteration (wan and verspoor, 1998) <papid> P98-2220 </papid>and backward transliteration (chen et al, 1998; <papid> P98-1036 </papid>knight and graehl, 1998), <papid> J98-4003 </papid>and proposed phoneme-based model.</citsent>
<aftsection>
<nextsent>lin and chen (2002) <papid> W02-2017 </papid>employed machine learning approach to determine phonetic similarity scores for machine transliteration.</nextsent>
<nextsent>ai-onaizan and knight (2002) investigated the translation of arabic named entities to english using monolingual and bilingual resources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2489">
<title id=" W03-1501.xml">learning formulation and transformation rules for multilingual named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>chen et al (1998) <papid> P98-1036 </papid>extended it to cross-language information retrieval.</prevsent>
<prevsent>a grapheme-based model was proposed to compute the similarity between chinese transliteration name and english name.</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
lin and chen (2000) further classified the works into two directions ? say, forward transliteration (wan and verspoor, 1998) <papid> P98-2220 </papid>and backward transliteration (chen et al, 1998; <papid> P98-1036 </papid>knight and graehl, 1998), <papid> J98-4003 </papid>and proposed phoneme-based model.</citsent>
<aftsection>
<nextsent>lin and chen (2002) <papid> W02-2017 </papid>employed machine learning approach to determine phonetic similarity scores for machine transliteration.</nextsent>
<nextsent>ai-onaizan and knight (2002) investigated the translation of arabic named entities to english using monolingual and bilingual resources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2490">
<title id=" W03-1501.xml">learning formulation and transformation rules for multilingual named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a grapheme-based model was proposed to compute the similarity between chinese transliteration name and english name.
</prevsent>
<prevsent>lin and chen (2000) further classified the works into two directions ? say, forward transliteration (wan and verspoor, 1998) <papid> P98-2220 </papid>and backward transliteration (chen et al, 1998; <papid> P98-1036 </papid>knight and graehl, 1998), <papid> J98-4003 </papid>and proposed phoneme-based model.</prevsent>
</prevsection>
<citsent citstr=" W02-2017 ">
lin and chen (2002) <papid> W02-2017 </papid>employed machine learning approach to determine phonetic similarity scores for machine transliteration.</citsent>
<aftsection>
<nextsent>ai-onaizan and knight (2002) investigated the translation of arabic named entities to english using monolingual and bilingual resources.
</nextsent>
<nextsent>the past works on multilingual named entities emphasizes on the transliteration issues.
</nextsent>
<nextsent>however, the transformation between named entities in different languages is not transliteration only.
</nextsent>
<nextsent>the mapping may be combination of meaning translation and/or phoneme transliteration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2495">
<title id=" W03-1711.xml">a chinese efficient analyser integrating word segmentation partofspeech tagging partial parsing and full parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>5) in this way, full parsing is completed with fully parsed tree after several levels (3 in the example of figure 1) of cascaded partial parsing.
</prevsent>
<prevsent>3 hmm-based tagger.
</prevsent>
</prevsection>
<citsent citstr=" W00-0737 ">
the chinese efficient analyser is based on the hmm-based tagger described in zhou et al 2000<papid> W00-0737 </papid>a.</citsent>
<aftsection>
<nextsent>given token sequence , the goal of tagging is to find stochastic optimal tag sequence that maximizes n ggg l211 = n tttt l211 = )()( ),(log)(log)|(log 11 11 111 nn nn nnn gptp gtptpgtp ?+= by assuming mutual information independence: ? = = i i nn gtmigtmi 1 111 ),(),( or ? = ?=?
</nextsent>
<nextsent>n n n nn nn gptp gtp gptp gtp 1 1 1 11 11 )()( ),(log )()( ),(log we have: ? ?
</nextsent>
<nextsent>= = + ?= i i i nnn gtp tptpgtp 1 1 1 111 )|(log )(log)(log)|(log both the first and second items correspond to the language model component of the tagger.
</nextsent>
<nextsent>we will not discuss these two items further in this paper since they are well studied in ngram modeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2498">
<title id=" W03-1711.xml">a chinese efficient analyser integrating word segmentation partofspeech tagging partial parsing and full parsing </title>
<section> invalid invalid valid valid.  </section>
<citcontext>
<prevsection>
<prevsent>this makes the number of segmented words/pos tagged words in the system output higher than that in the correct answer.
</prevsent>
<prevsent>6.2 partial parsing and full parsing.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
table 3 shows the results of 1st-level partial parsing and full parsing, using the parseval evaluation methodology (black et al 1991) <papid> H91-1060 </papid>on the upenn chinese tree bank of 100k words developed by univ. of penn. here, 80% of the corpus is used as formal training data, another 10% as development data and remaining 10% as formal test data.</citsent>
<aftsection>
<nextsent>function r speed partial parsing 85.1 82.5 83.8 4500 wps full parsing 77.1 70.3 73.7 2100 wps table 3: performances of 1st-level partial parsing and full parsing (wps: words per second) table 3 shows that the performances of partial parsing and full parsing are quite low, compared to those of state-of-art partial parsing and full parsing for the english language (zhou et al 2000<papid> W00-0737 </papid>a; collins 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>the main reason behind is the small size of the training corpus used in our experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2502">
<title id=" W03-1711.xml">a chinese efficient analyser integrating word segmentation partofspeech tagging partial parsing and full parsing </title>
<section> invalid invalid valid valid.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 partial parsing and full parsing.
</prevsent>
<prevsent>table 3 shows the results of 1st-level partial parsing and full parsing, using the parseval evaluation methodology (black et al 1991) <papid> H91-1060 </papid>on the upenn chinese tree bank of 100k words developed by univ. of penn. here, 80% of the corpus is used as formal training data, another 10% as development data and remaining 10% as formal test data.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
function r speed partial parsing 85.1 82.5 83.8 4500 wps full parsing 77.1 70.3 73.7 2100 wps table 3: performances of 1st-level partial parsing and full parsing (wps: words per second) table 3 shows that the performances of partial parsing and full parsing are quite low, compared to those of state-of-art partial parsing and full parsing for the english language (zhou et al 2000<papid> W00-0737 </papid>a; collins 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>the main reason behind is the small size of the training corpus used in our experiments.
</nextsent>
<nextsent>however, the chinese penn tree bank is the largest corpus we can find for partial parsing and full parsing.
</nextsent>
<nextsent>therefore, developing much larger chinese tree bank (comparable to upenn english tree bank) becomes an urgent task for the chinese language processing community.
</nextsent>
<nextsent>actually, the best individual system (zhou et al 2000<papid> W00-0737 </papid>b) in conll2000 chunking shared task for the english language (tjong et al 2000) used the same hmm-based tagging engine.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2506">
<title id=" W03-1708.xml">chiners a chinese named entity recognition system for the sports domain </title>
<section> repairing the errors for word segmen-.  </section>
<citcontext>
<prevsection>
<prevsent>in order to ensure the overall quality of the system, we have to enhance basic quality.
</prevsent>
<prevsent>second, it is more effective to improve the quality for word segmentation and pos tagging on specific do main.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the transformation based error-driven machine learning approach (brill, 1995) <papid> J95-4004 </papid>is adopted to repair word segmentation and pos tagging errors, because it is suitable for fixing chinese word segmentation and pos tagging errors as well as producing effective repairing rules automatically.</citsent>
<aftsection>
<nextsent>following (hockenmaier and brew, 1998; palmer, 1997) <papid> P97-1041 </papid>we divide the error repairing operations of word segmentation into three types, that is, concat,split and slide.</nextsent>
<nextsent>in addition, we add context sensitive or context-free constraints in the rules to repair the errors of word segmentation and pos tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2507">
<title id=" W03-1708.xml">chiners a chinese named entity recognition system for the sports domain </title>
<section> repairing the errors for word segmen-.  </section>
<citcontext>
<prevsection>
<prevsent>second, it is more effective to improve the quality for word segmentation and pos tagging on specific do main.
</prevsent>
<prevsent>the transformation based error-driven machine learning approach (brill, 1995) <papid> J95-4004 </papid>is adopted to repair word segmentation and pos tagging errors, because it is suitable for fixing chinese word segmentation and pos tagging errors as well as producing effective repairing rules automatically.</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
following (hockenmaier and brew, 1998; palmer, 1997) <papid> P97-1041 </papid>we divide the error repairing operations of word segmentation into three types, that is, concat,split and slide.</citsent>
<aftsection>
<nextsent>in addition, we add context sensitive or context-free constraints in the rules to repair the errors of word segmentation and pos tagging.
</nextsent>
<nextsent>it is important that the context constraint scan help us distinguish different sentence environments.
</nextsent>
<nextsent>the error repairing rules for word segmentation and pos tagging are defined as follows: rectify_segmentation_error ( operator, old_word(s)_and_tag(s), repairing_mode,new_tag(s), preceding_context_constraint, fol lowing_context_constraint) rectify_tag_error (old_word_and_tag, new_tag,preceding_context_constraint, follow ing_context_constraint)using these rules, we can move the word segmentation position newly and replace an error tag with correct tag.
</nextsent>
<nextsent>e.g. |n|  |n|   |v|
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2508">
<title id=" W03-1003.xml">cross lingual lexical triggers in statistical language modeling </title>
<section> data sparseness in language modeling.  </section>
<citcontext>
<prevsection>
<prevsent>more recently, there has been an increasing interest in languages such as mandarin and arabic for asr and nlp, and data resources are being created for them at considerable cost.
</prevsent>
<prevsent>the data-resource bottleneck, however, is likely to remain for majority of the worlds languages in the foreseeable future.methods have been proposed to bootstrap acoustic models for asr in resource deficient languages by reusing acoustic models from resource-rich languages (schultz and waibel, 1998; byrne et al,2000).
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
morphological analyzers, noun-phrase chun kers, pos taggers, etc., have also been developed for resource deficient languages by exploiting translated or parallel text (yarowsky et al, 2001).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>khudanpur and kim (2002) recently proposed usingcross-lingual information retrieval (clir) and machine translation (mt) to improve statistical language model (lm) in resource-deficient language by exploiting copious amounts of text available in resource-rich languages.
</nextsent>
<nextsent>when transcribing news story in resource-deficient language, their core idea is to use the first pass output of rudimentary asr system as query for clir, identify contemporaneous english document on that news topic, followed by mt to provide rough translation which, even if not fluent, is adequate to update estimates ofword frequencies and the lm vocabulary.
</nextsent>
<nextsent>theyre port up to 28% reduction in perplexity on chinese text from the hongkong news corpus.in spite of their considerable success, some shortcomings remain in the method used by khudanpur and kim (2002).
</nextsent>
<nextsent>specifically, stochastic translation lexicons estimated using the ibm method (brown et al, 1993) <papid> J93-2003 </papid>from fairly large sentence-alignedchinese-english parallel corpus are used in their approach ? considerable demand for resource deficient language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2509">
<title id=" W03-1003.xml">cross lingual lexical triggers in statistical language modeling </title>
<section> data sparseness in language modeling.  </section>
<citcontext>
<prevsection>
<prevsent>when transcribing news story in resource-deficient language, their core idea is to use the first pass output of rudimentary asr system as query for clir, identify contemporaneous english document on that news topic, followed by mt to provide rough translation which, even if not fluent, is adequate to update estimates ofword frequencies and the lm vocabulary.
</prevsent>
<prevsent>theyre port up to 28% reduction in perplexity on chinese text from the hongkong news corpus.in spite of their considerable success, some shortcomings remain in the method used by khudanpur and kim (2002).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
specifically, stochastic translation lexicons estimated using the ibm method (brown et al, 1993) <papid> J93-2003 </papid>from fairly large sentence-alignedchinese-english parallel corpus are used in their approach ? considerable demand for resource deficient language.</citsent>
<aftsection>
<nextsent>it is suggested that an easier to-obtain document-aligned comparable corpus may suffice, but no results are reported.
</nextsent>
<nextsent>furthermore, foreach mandarin news story, the single best matching english article obtained via clir is translated and used for priming the chinese lm, no matter how good the clir similarity, nor are other well matching english articles considered.
</nextsent>
<nextsent>this issue clearly deserves further attention.
</nextsent>
<nextsent>finally, asr results are not reported in their work, though their proposed solution is clearly motivated by an asr task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2510">
<title id=" W03-1003.xml">cross lingual lexical triggers in statistical language modeling </title>
<section> cross-lingual story-specific lms.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 obtaining stochastic translation lexicons.
</prevsent>
<prevsent>the translation lexicons k ffwfi and  ff fi may be created out of an available electronic translation lexicon, with multiple translations of word being treated as equally likely.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
stemming and other morphological analyses may be applied to increase the vocabulary-coverage of the translation lexicons.alternately, they may also be obtained automatically from parallel corpus of translated andsentence-aligned chinese-english text using statistical machine translation techniques, such as the publicly available giza++ tools (och and ney, 2000),<papid> P00-1056 </papid>as done by khudanpur and kim (2002).</citsent>
<aftsection>
<nextsent>unlike standard mt systems, however, we apply the translation models to entire articles, one word at time, to get bag of translated words ? cf.
</nextsent>
<nextsent>(1) and (3).
</nextsent>
<nextsent>finally, for truly resource deficient languages, one may obtain translation lexicon via optical character recognition from printed bilingual dictionary (cf.
</nextsent>
<nextsent>doerman et al(2002)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2511">
<title id=" W03-1003.xml">cross lingual lexical triggers in statistical language modeling </title>
<section> cross-lingual lexical triggers.  </section>
<citcontext>
<prevsection>
<prevsent>in monolingual setting, the mutual information between lexical pairs co-occurring anywhere within long window?
</prevsent>
<prevsent>of each-other has been used to capture statistical dependencies not covered by
</prevsent>
</prevsection>
<citsent citstr=" W97-1014 ">
-gram lms (rosenfeld, 1996; tillmann and ney,1997).<papid> W97-1014 </papid></citsent>
<aftsection>
<nextsent>we use this inspiration to propose the following notion of cross-lingual lexical triggers.
</nextsent>
<nextsent>in monolingual setting, pair of words xyqzfi is considered trigger-pair if, given word-position ina sentence, the occurrence of in any of the preceding word-positions significantly alters the (con ditional) probability that the following word in the sentence is : is said to trigger . e.g. the occurrence of either significantly increases the probability of or subsequently in the sentence.
</nextsent>
<nextsent>the set of preceding word-positions is variably defined to include all words from the beginning of the sentence,paragraph or document, or is limited to fixed number of preceding words, limited of course by the beginning of the sentence, paragraph or document.
</nextsent>
<nextsent>in the cross-lingual setting, we consider pair of words  ffw fi , ffgffi{# and 1ffi{ , to be trigger-pairif, given an english-chinese pair of aligned documents, the occurrence of ff in the english document significantly alters the (conditional) probability that the word  appears in the chinese document: ff is said to trigger  . it is plausible that translation-pairs will be natural candidates for trigger-pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2512">
<title id=" W03-1306.xml">boosting precision and recall of dictionary based protein name recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this kind of problem has been studied in the field of natural language processing as named entity recognition tasks.
</prevsent>
<prevsent>ohtaet al (2002) provided the genia corpus, an annotated corpus of medline abstracts, which canbe used as gold-standard for evaluating and training named entity recognition algorithms.
</prevsent>
</prevsection>
<citsent citstr=" W02-2029 ">
there are some research efforts using machine learning techniques to recognize biological entities in texts (takeuchi and collier, 2002; <papid> W02-2029 </papid>kim and tsujii, 2002; kazama et al, 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>one drawback of these machine learning based approaches is that they do not provide identification information of recognized terms.
</nextsent>
<nextsent>for the purpose of information extraction of protein-protein interaction, the id information of recognized proteins, such as genbank 1 id or swiss prot 2 id, is indispensable to integrate the extracted information with the data in other information sources.
</nextsent>
<nextsent>dictionary-based approaches, on the other hand, intrinsically provide id information because they recognize term by searching the most similar (or identical) one in the dictionary to the targetterm.
</nextsent>
<nextsent>this advantage currently makes dictionary based approaches particularly useful as the first step for practical information extraction from biomedical documents (ono et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2513">
<title id=" W03-1306.xml">boosting precision and recall of dictionary based protein name recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this kind of problem has been studied in the field of natural language processing as named entity recognition tasks.
</prevsent>
<prevsent>ohtaet al (2002) provided the genia corpus, an annotated corpus of medline abstracts, which canbe used as gold-standard for evaluating and training named entity recognition algorithms.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
there are some research efforts using machine learning techniques to recognize biological entities in texts (takeuchi and collier, 2002; <papid> W02-2029 </papid>kim and tsujii, 2002; kazama et al, 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>one drawback of these machine learning based approaches is that they do not provide identification information of recognized terms.
</nextsent>
<nextsent>for the purpose of information extraction of protein-protein interaction, the id information of recognized proteins, such as genbank 1 id or swiss prot 2 id, is indispensable to integrate the extracted information with the data in other information sources.
</nextsent>
<nextsent>dictionary-based approaches, on the other hand, intrinsically provide id information because they recognize term by searching the most similar (or identical) one in the dictionary to the targetterm.
</nextsent>
<nextsent>this advantage currently makes dictionary based approaches particularly useful as the first step for practical information extraction from biomedical documents (ono et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2514">
<title id=" W03-1306.xml">boosting precision and recall of dictionary based protein name recognition </title>
<section> filtering candidates by naive bayes.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we use naive bayes classifier for this classification task.
</prevsent>
<prevsent>4.1 naive bayes classifier.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
the naive bayes classifier is simple but effective classifier which has been used in numerous applications of information processing such as image recognition, natural language processing and information retrieval (lewis, 1998; escudero et al, 2000; pedersen, 2000; <papid> A00-2009 </papid>nigam and ghani, 2000).</citsent>
<aftsection>
<nextsent>here we briefly review the naive bayes model.
</nextsent>
<nextsent>let ~x be vector we want to classify, and ck be apos sible class.
</nextsent>
<nextsent>what we want to know is the probability that the vector ~x belongs to the class ck.
</nextsent>
<nextsent>we first transform the probability (ck|~x) using bayes?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2516">
<title id=" W03-0509.xml">a survey for multi document summarization </title>
<section> axis.  </section>
<citcontext>
<prevsection>
<prevsent>means that all the articles are talking about single event, person or other entity, whereas multi?
</prevsent>
<prevsent>articles are talking about multiple entities that might participate in similar types of events.
</prevsent>
</prevsection>
<citsent citstr=" C96-1079 ">
we used 6 categories of entity types, which are the major categories defined in the muc (grishman and sundheim 1996) <papid> C96-1079 </papid>or ace project (ace homepage).</citsent>
<aftsection>
<nextsent>for example, if document set is talking about einsteins biography, it should be tagged as single-person?, and if set is talking about earthquakes in california last year, it should be tagged as multi-event?.
</nextsent>
<nextsent>in order to demonstrate the validity of the categories, we tried to categorize the training data of duc 2001s multi-document sets into our categories.
</nextsent>
<nextsent>two people assigned one or two categories to each set.
</nextsent>
<nextsent>we allow more than one axis to document set, as some document sets should be inherently categorized into more than one axis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2517">
<title id=" W03-0502.xml">sub event based multi document summarization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>information to improve query answering results, and they also apply this method to multiple-document summarization (carbonell and goldstein, 1997 and goldstein, 1999).
</prevsent>
<prevsent>success in the use of inter-judge agreement has led us to pursue the use of the current evaluation methods.
</prevsent>
</prevsection>
<citsent citstr=" W00-0403 ">
however, this experiment differs from prior work in that we use judges to determine the relevance of sentences to sub-events rather than to evaluate summaries (radev et al , 2000).<papid> W00-0403 </papid></citsent>
<aftsection>
<nextsent>finally, mckeown et al  (1999), hatzivassiloglou et al  (2001) and boros et al  (2001) have shown the challenges and potential payoffs of using sentence clustering in extractive summarization.
</nextsent>
<nextsent>our study involves two experiments carried out on one corpus of news articles.
</nextsent>
<nextsent>the article corpus was selected from cluster of eleven articles describing the 2000 crash of gulf air flight 072.
</nextsent>
<nextsent>from these articles we chose corpus of five articles, containing total of 159 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2521">
<title id=" W03-0909.xml">surfaces and depths in text understanding the case of newspaper commentary </title>
<section> rhetorical structure.  </section>
<citcontext>
<prevsection>
<prevsent>we will return to these issues in section 6, but first consider the chances for building up rhetorical trees automatically.
</prevsent>
<prevsent>5 prospects for rhetorical parsing.
</prevsent>
</prevsection>
<citsent citstr=" P97-1013 ">
major proponents of rhetorical parsing have been (sumita et al, 1992), (corston-oliver, 1998), (marcu, 1997), <papid> P97-1013 </papid>and (schilder, 2002).</citsent>
<aftsection>
<nextsent>all these approaches emphasise their membership in the shallow analysis?
</nextsent>
<nextsent>family; they are based solely on surface cues, none tries to work with semantic / domain / world knowledge.
</nextsent>
<nextsent>(corston-oliverand schilder use some genre-specific heuristics for preferential parsing, though.)
</nextsent>
<nextsent>in general, our sample text belongs to rather friendly?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2522">
<title id=" W03-0413.xml">confidence estimation for translation prediction </title>
<section> text prediction for translators.  </section>
<citcontext>
<prevsection>
<prevsent>the system observes translator in the process of typing target text and, after every character typed, has the opportunity to display suggestion about what will come next, based on the source sentence under translation and the prefix ofits translation that has already been typed.
</prevsent>
<prevsent>the translator may incorporate suggestions into the text if they are helpful, or simply ignore them and keep typing.
</prevsent>
</prevsection>
<citsent citstr=" W02-1020 ">
suggestions may range in length from 0 characters to the end of the target sentence; it is up to the system to decide how much text to predict in given context, balancing the greater potential benefit of longer predictions against greater likelihood of being wrong, and higher cost to the user (in terms of distraction and editing) if they are wrong or only partially right.our solution to the problem of how much text to predict is based on decision-theoretic framework in whichwe attempt to find the prediction that maximizes the expected benefit to the translator in the current context (fos ter et al, 2002<papid> W02-1020 </papid>b).</citsent>
<aftsection>
<nextsent>formally, we seek: x?
</nextsent>
<nextsent>= argmax b(x|h, s), (1) where is prediction about what will follow in the translation of source sentence s, and b(x|h, s) is the expected benefit in terms of typing time saved.
</nextsent>
<nextsent>as described in (foster et al, 2002<papid> W02-1020 </papid>b), b(x? |h, s) = ? k=0 p(k|x, h, s)b(x|h, s, k) depends on two main quantities: the probability p(k|x, h, s) that exactly characters from the beginning of are correct, and the benefit b(x|h, s, k) to the translator if this is the case.</nextsent>
<nextsent>b(x|h, s, k) is estimated from model of user behaviour based on data collected in user trials of the tool that captures the cost of reading prediction and performing any necessary editing, as well as the somewhat random nature of peoples decisions to accept.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2533">
<title id=" W03-0413.xml">confidence estimation for translation prediction </title>
<section> text prediction for translators.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 translation models.
</prevsent>
<prevsent>we experimented with three different translation models for p(w|h, s).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
all have the property of being fast enough to support real-time searches for predictions of up to 5 words.the first model, referred to as maxent1 below, is loglinear combination of trigram language model with amaximum entropy translation component that is an analog of the ibm translation model 2 (brown et al, 1993).<papid> J93-2003 </papid>this model is described in (foster, 2000).<papid> W00-0707 </papid></citsent>
<aftsection>
<nextsent>its major weakness is that it does not keep track of which words in the current source sentence have already been translated, and hence it is prone to repeating previous suggestions.
</nextsent>
<nextsent>the second model, called maxent2 below, is similar to max ent1 but with the addition of extra parameters to limit this behaviour (foster et al, 2002<papid> W02-1020 </papid>a).</nextsent>
<nextsent>the final model, called bayes below, is also described in (foster et al, 2002<papid> W02-1020 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2534">
<title id=" W03-0413.xml">confidence estimation for translation prediction </title>
<section> text prediction for translators.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 translation models.
</prevsent>
<prevsent>we experimented with three different translation models for p(w|h, s).
</prevsent>
</prevsection>
<citsent citstr=" W00-0707 ">
all have the property of being fast enough to support real-time searches for predictions of up to 5 words.the first model, referred to as maxent1 below, is loglinear combination of trigram language model with amaximum entropy translation component that is an analog of the ibm translation model 2 (brown et al, 1993).<papid> J93-2003 </papid>this model is described in (foster, 2000).<papid> W00-0707 </papid></citsent>
<aftsection>
<nextsent>its major weakness is that it does not keep track of which words in the current source sentence have already been translated, and hence it is prone to repeating previous suggestions.
</nextsent>
<nextsent>the second model, called maxent2 below, is similar to max ent1 but with the addition of extra parameters to limit this behaviour (foster et al, 2002<papid> W02-1020 </papid>a).</nextsent>
<nextsent>the final model, called bayes below, is also described in (foster et al, 2002<papid> W02-1020 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2550">
<title id=" W03-1603.xml">preferential presentation of japanese near synonyms using definition statements </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>itcould be caused by the low precision of classification into lexical restrictions and by the inadequacy in the measure of similarity described in section 4.2.
</prevsent>
<prevsent>to improve those problems, another measure such as semantical similarities without using structure of thesaurus is needed.
</prevsent>
</prevsection>
<citsent citstr=" W02-0909 ">
also, we would learn from amethod of lexical choice with knowledge about collocational behavior (inkpen and hirst, 2002).<papid> W02-0909 </papid></citsent>
<aftsection>
<nextsent>though we have not discussed the evaluation of the propriety of arrangements to an input sentence, it seems that the information of addition often occurs imprecisely, against that the information of deletion appears infrequently but almost correctly, because, in our method, all denot ations of target word are given as the information of addition when they do not match with any denot ation of near-synonym.
</nextsent>
<nextsent>therefore, we must define the importance of each addition information and to present selected ones.
</nextsent>
<nextsent>5 conclusion and future work.
</nextsent>
<nextsent>this paper proposed new method of preferential presentation of japanese near-synonyms in order to treat with semantic suitability against contexts, as afirst step of semantic paraphrase system for elaboration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2551">
<title id=" W02-1012.xml">extent ions to hmm based statistical word alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main task in statistical machine translation is to model the string translation probability
</prevsent>
<prevsent>    where the string   in one language is translated into another language as string   . we refer to.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
as the source language string and  as the target language string in accordance with the noisy channel terminology used in the ibm models of (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>word-level translation models assume pairwise mapping between the words of the source and target strings.
</nextsent>
<nextsent>this mapping is generated by alignment models.
</nextsent>
<nextsent>in this paper we present extensions to the hmm alignment model of (vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000<papid> P00-1056 </papid>b).</nextsent>
<nextsent>some of our extensions are applicable to other alignment models as well and are of general utility.1 for most language pairs huge amounts of parallel corpora are not readily available whereas monolingual resources such as taggers are more often available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2552">
<title id=" W02-1012.xml">extent ions to hmm based statistical word alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word-level translation models assume pairwise mapping between the words of the source and target strings.
</prevsent>
<prevsent>this mapping is generated by alignment models.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
in this paper we present extensions to the hmm alignment model of (vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000<papid> P00-1056 </papid>b).</citsent>
<aftsection>
<nextsent>some of our extensions are applicable to other alignment models as well and are of general utility.1 for most language pairs huge amounts of parallel corpora are not readily available whereas monolingual resources such as taggers are more often available.
</nextsent>
<nextsent>little research has gone into exploring the po 1this paper was supported in part by the national science foundation under grants iis-0085896 and iis-9982226.
</nextsent>
<nextsent>the authors would also like to thank the various reviewers for their helpful comments on earlier versions.
</nextsent>
<nextsent>tential of part of speech information to better model translation probabilities and permutation probabilities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2554">
<title id=" W02-1012.xml">extent ions to hmm based statistical word alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word-level translation models assume pairwise mapping between the words of the source and target strings.
</prevsent>
<prevsent>this mapping is generated by alignment models.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
in this paper we present extensions to the hmm alignment model of (vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000<papid> P00-1056 </papid>b).</citsent>
<aftsection>
<nextsent>some of our extensions are applicable to other alignment models as well and are of general utility.1 for most language pairs huge amounts of parallel corpora are not readily available whereas monolingual resources such as taggers are more often available.
</nextsent>
<nextsent>little research has gone into exploring the po 1this paper was supported in part by the national science foundation under grants iis-0085896 and iis-9982226.
</nextsent>
<nextsent>the authors would also like to thank the various reviewers for their helpful comments on earlier versions.
</nextsent>
<nextsent>tential of part of speech information to better model translation probabilities and permutation probabilities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2568">
<title id=" W02-1012.xml">extent ions to hmm based statistical word alignment models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the authors would also like to thank the various reviewers for their helpful comments on earlier versions.
</prevsent>
<prevsent>tential of part of speech information to better model translation probabilities and permutation probabilities.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
melamed (2000) <papid> J00-2004 </papid>uses very broad classification of words (content, function and several punctuation classes) to estimate class-specific parameters for translation models.</citsent>
<aftsection>
<nextsent>fung and wu (1995) adapt english tags for chinese language modeling using coerced markov models.
</nextsent>
<nextsent>they use english pos classes as states of the markov model to generate chinese language words.
</nextsent>
<nextsent>in this paper we use pos tag information to incorporate prior knowledge ofword translation and to model local word order variation.
</nextsent>
<nextsent>we show that using this information can help in the translation modeling task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2573">
<title id=" W02-1012.xml">extent ions to hmm based statistical word alignment models </title>
<section> baseline model.  </section>
<citcontext>
<prevsection>
<prevsent>this means that pairwise alignments stay close to the diagonal line of the
</prevsent>
<prevsent>ih(kjl plane.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
it has been shown (vogel et al, 1996; <papid> C96-2141 </papid>och et al, 1999; <papid> W99-0604 </papid>och and ney, 2000<papid> P00-1056 </papid>a) that hmm based alignment models are effective at capturing such lo calization.</citsent>
<aftsection>
<nextsent>we use as baseline the model presented by (och and ney, 2000<papid> P00-1056 </papid>a).</nextsent>
<nextsent>a basic bigram hmm-based model gives us fl</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2606">
<title id=" W02-1012.xml">extent ions to hmm based statistical word alignment models </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>n (pzqf,g*?
</prevsent>
<prevsent>n.?
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
we could model probabilities of trans positions and insertion of function words in the target language that have no corresponding words in the source language ( f.g is null) similarly to the channel operations of the (yamada and knight, 2001) <papid> P01-1067 </papid>syntax based statistical translation model.</citsent>
<aftsection>
<nextsent>since the syntactic knowledge provided by pos tags is quite limited,this is crude model of trans positions and null insertions at the pre terminal level.
</nextsent>
<nextsent>however we could still expect that it would help in modeling local word order variations.
</nextsent>
<nextsent>for example, in the sentence jaime la chute love the fall?
</nextsent>
<nextsent>the probability of aligning ?!
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2664">
<title id=" W03-1807.xml">extracting multiword expressions with a semantic tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment shows that it is efficient in identifying mwes, in particular mwes of low frequencies.
</prevsent>
<prevsent>in the following sections, we describe this approach to mwe extraction and its evaluation.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
related works generally speaking, approaches to mwe extraction proposed so far can be divided into three categories: a) statistical approaches based on frequency and co-occurrence affinity, b) knowledge based or symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (smadja 1993; <papid> J93-1007 </papid>dagan and church 1994; <papid> A94-1006 </papid>daille 1995; mcenery et al  1997; wu 1997; <papid> J97-3002 </papid>wermter et al  1997; michiels and dufour 1998; merkel and andersson 2000; piao and mcenery 2001; sag et al  2001a, 2001b; biber et al  2003).</citsent>
<aftsection>
<nextsent>in practice, most statistical approaches use linguistic filters to collect candidate mwes.
</nextsent>
<nextsent>such approaches include dagan and churchs (1994) <papid> A94-1006 </papid>ter might tool.</nextsent>
<nextsent>in this tool, they first collect candidate nominal terms with pos syntactic pattern filter, then use concordances to identify frequently co-occurring multiword units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2665">
<title id=" W03-1807.xml">extracting multiword expressions with a semantic tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment shows that it is efficient in identifying mwes, in particular mwes of low frequencies.
</prevsent>
<prevsent>in the following sections, we describe this approach to mwe extraction and its evaluation.
</prevsent>
</prevsection>
<citsent citstr=" A94-1006 ">
related works generally speaking, approaches to mwe extraction proposed so far can be divided into three categories: a) statistical approaches based on frequency and co-occurrence affinity, b) knowledge based or symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (smadja 1993; <papid> J93-1007 </papid>dagan and church 1994; <papid> A94-1006 </papid>daille 1995; mcenery et al  1997; wu 1997; <papid> J97-3002 </papid>wermter et al  1997; michiels and dufour 1998; merkel and andersson 2000; piao and mcenery 2001; sag et al  2001a, 2001b; biber et al  2003).</citsent>
<aftsection>
<nextsent>in practice, most statistical approaches use linguistic filters to collect candidate mwes.
</nextsent>
<nextsent>such approaches include dagan and churchs (1994) <papid> A94-1006 </papid>ter might tool.</nextsent>
<nextsent>in this tool, they first collect candidate nominal terms with pos syntactic pattern filter, then use concordances to identify frequently co-occurring multiword units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2666">
<title id=" W03-1807.xml">extracting multiword expressions with a semantic tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiment shows that it is efficient in identifying mwes, in particular mwes of low frequencies.
</prevsent>
<prevsent>in the following sections, we describe this approach to mwe extraction and its evaluation.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
related works generally speaking, approaches to mwe extraction proposed so far can be divided into three categories: a) statistical approaches based on frequency and co-occurrence affinity, b) knowledge based or symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (smadja 1993; <papid> J93-1007 </papid>dagan and church 1994; <papid> A94-1006 </papid>daille 1995; mcenery et al  1997; wu 1997; <papid> J97-3002 </papid>wermter et al  1997; michiels and dufour 1998; merkel and andersson 2000; piao and mcenery 2001; sag et al  2001a, 2001b; biber et al  2003).</citsent>
<aftsection>
<nextsent>in practice, most statistical approaches use linguistic filters to collect candidate mwes.
</nextsent>
<nextsent>such approaches include dagan and churchs (1994) <papid> A94-1006 </papid>ter might tool.</nextsent>
<nextsent>in this tool, they first collect candidate nominal terms with pos syntactic pattern filter, then use concordances to identify frequently co-occurring multiword units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2671">
<title id=" W03-1807.xml">extracting multiword expressions with a semantic tagger </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, wu (1997) <papid> J97-3002 </papid>used an english-chinese bilingual parser based on stochastic transduction grammars to identify terms, including multiword expressions.</prevsent>
<prevsent>in their defi project, michiels and dufour (1998) used dictionaries to identify english and french multiword expressions and their translations in the other language.</prevsent>
</prevsection>
<citsent citstr=" P98-2226 ">
wehrli (1998) <papid> P98-2226 </papid>employed generative grammar framework to identify compounds and idioms in their its-2 mt english-french system.</citsent>
<aftsection>
<nextsent>sag et al  (2001b) introduced head-driven phrase structure grammar for analyzing mwes.
</nextsent>
<nextsent>like pure statistical approaches, purely knowledge based symbolic approaches also face problems.
</nextsent>
<nextsent>they are language dependent and not flexible enough to cope with complex structures of mwes.
</nextsent>
<nextsent>as sag et al  (2001b) suggest, it is important to find the right balance between symbolic and statistical approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2672">
<title id=" W03-1807.xml">extracting multiword expressions with a semantic tagger </title>
<section> text-based disambiguation. it has.  </section>
<citcontext>
<prevsection>
<prevsent>a set of heuristics is applied to enable the most likely template to be treated as the preferred one for tag assignment.
</prevsent>
<prevsent>the current domain or topic of discourse is used to alter rank ordering of semantic tags in the lexicon and template list for particular domain.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
been claimed (by gale et al  1992) <papid> H92-1045 </papid>on the basis of corpus analysis that to very large extent word keeps the same meaning throughout text.</citsent>
<aftsection>
<nextsent>mechanism is also used in identifying regular contexts in which word is constrained to occur in particular sense.
</nextsent>
<nextsent>is generally supposed that the correct semantic tag forgiven word is substantially determined by the local surrounding context.
</nextsent>
<nextsent>after automatic tag assignment has been carried out, manual post-editing can take place, if desired, to ensure that each word and idiom carries the correct semantic classification.
</nextsent>
<nextsent>from these seven disambiguation methods, our main interest in this paper is the third technique of overlapping mwu resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2675">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>disambiguation: recent successes and future directions, philadelphia, proceedings of the siglex/senseval workshop on word sense from the target word.
</prevsent>
<prevsent>the system was configured to use only local, only topical, or both local and topical features for each word, depending on which configuration produced the best result on held-out portion of the training data.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
previous experiments (ng and lee, 1996) <papid> P96-1006 </papid>have explored the relative contribution of different knowledge sources to wsd and have concluded that collocational information is more important than syntactic information.</citsent>
<aftsection>
<nextsent>additionally, pedersen (pedersen, 2001; <papid> N01-1011 </papid>pedersen, 2000) <papid> A00-2009 </papid>has pursued the approach of using simple word bigrams and other linguistically impoverished feature sets for sense tagging, to establish upper bounds on the accuracy of feature sets that do not impose substantial pre-processing requirements.</nextsent>
<nextsent>in contrast, we wish to demonstrate that such pre-processing significantly improves accuracy for sense-tagging english verbs, because we believe that they allow us to extract set of features that more closely parallels the information humans use for sense disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2676">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the system was configured to use only local, only topical, or both local and topical features for each word, depending on which configuration produced the best result on held-out portion of the training data.
</prevsent>
<prevsent>previous experiments (ng and lee, 1996) <papid> P96-1006 </papid>have explored the relative contribution of different knowledge sources to wsd and have concluded that collocational information is more important than syntactic information.</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
additionally, pedersen (pedersen, 2001; <papid> N01-1011 </papid>pedersen, 2000) <papid> A00-2009 </papid>has pursued the approach of using simple word bigrams and other linguistically impoverished feature sets for sense tagging, to establish upper bounds on the accuracy of feature sets that do not impose substantial pre-processing requirements.</citsent>
<aftsection>
<nextsent>in contrast, we wish to demonstrate that such pre-processing significantly improves accuracy for sense-tagging english verbs, because we believe that they allow us to extract set of features that more closely parallels the information humans use for sense disambiguation.
</nextsent>
<nextsent>we developed an automatic wsd system that usesa maximum entropy framework to combine linguistic contextual features from corpus instances of each verb to be tagged.
</nextsent>
<nextsent>under the maximum entropy framework (berger et al, 1996), <papid> J96-1002 </papid>evidence from different features can be combined with no assumptions of feature independence.</nextsent>
<nextsent>the automatic tagger estimates the conditional probability that word has sense given that it occurs in context y, wherey is conjunction of features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2677">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the system was configured to use only local, only topical, or both local and topical features for each word, depending on which configuration produced the best result on held-out portion of the training data.
</prevsent>
<prevsent>previous experiments (ng and lee, 1996) <papid> P96-1006 </papid>have explored the relative contribution of different knowledge sources to wsd and have concluded that collocational information is more important than syntactic information.</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
additionally, pedersen (pedersen, 2001; <papid> N01-1011 </papid>pedersen, 2000) <papid> A00-2009 </papid>has pursued the approach of using simple word bigrams and other linguistically impoverished feature sets for sense tagging, to establish upper bounds on the accuracy of feature sets that do not impose substantial pre-processing requirements.</citsent>
<aftsection>
<nextsent>in contrast, we wish to demonstrate that such pre-processing significantly improves accuracy for sense-tagging english verbs, because we believe that they allow us to extract set of features that more closely parallels the information humans use for sense disambiguation.
</nextsent>
<nextsent>we developed an automatic wsd system that usesa maximum entropy framework to combine linguistic contextual features from corpus instances of each verb to be tagged.
</nextsent>
<nextsent>under the maximum entropy framework (berger et al, 1996), <papid> J96-1002 </papid>evidence from different features can be combined with no assumptions of feature independence.</nextsent>
<nextsent>the automatic tagger estimates the conditional probability that word has sense given that it occurs in context y, wherey is conjunction of features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2678">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, we wish to demonstrate that such pre-processing significantly improves accuracy for sense-tagging english verbs, because we believe that they allow us to extract set of features that more closely parallels the information humans use for sense disambiguation.
</prevsent>
<prevsent>we developed an automatic wsd system that usesa maximum entropy framework to combine linguistic contextual features from corpus instances of each verb to be tagged.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
under the maximum entropy framework (berger et al, 1996), <papid> J96-1002 </papid>evidence from different features can be combined with no assumptions of feature independence.</citsent>
<aftsection>
<nextsent>the automatic tagger estimates the conditional probability that word has sense given that it occurs in context y, wherey is conjunction of features.
</nextsent>
<nextsent>the estimated probability is derived from feature weights which are determined automatically from training data so as to produce probability distribution that has maximum entropy, under the constraint that it is consistent with observed evidence.in order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using maximum entropy tagger (ratnaparkhi, 1998) and parsed using the collins parser (collins, 1997).<papid> P97-1003 </papid></nextsent>
<nextsent>in addition, an automatic named entity tagger (bikel et al, 1997) <papid> A97-1029 </papid>was run on the sentences to map proper nouns to small set of semantic classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2679">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>under the maximum entropy framework (berger et al, 1996), <papid> J96-1002 </papid>evidence from different features can be combined with no assumptions of feature independence.</prevsent>
<prevsent>the automatic tagger estimates the conditional probability that word has sense given that it occurs in context y, wherey is conjunction of features.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
the estimated probability is derived from feature weights which are determined automatically from training data so as to produce probability distribution that has maximum entropy, under the constraint that it is consistent with observed evidence.in order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using maximum entropy tagger (ratnaparkhi, 1998) and parsed using the collins parser (collins, 1997).<papid> P97-1003 </papid></citsent>
<aftsection>
<nextsent>in addition, an automatic named entity tagger (bikel et al, 1997) <papid> A97-1029 </papid>was run on the sentences to map proper nouns to small set of semantic classes.</nextsent>
<nextsent>following work by chodorow, leacock and miller, we divided the possible model features into topical and local contextual features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2680">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the automatic tagger estimates the conditional probability that word has sense given that it occurs in context y, wherey is conjunction of features.
</prevsent>
<prevsent>the estimated probability is derived from feature weights which are determined automatically from training data so as to produce probability distribution that has maximum entropy, under the constraint that it is consistent with observed evidence.in order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using maximum entropy tagger (ratnaparkhi, 1998) and parsed using the collins parser (collins, 1997).<papid> P97-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
in addition, an automatic named entity tagger (bikel et al, 1997) <papid> A97-1029 </papid>was run on the sentences to map proper nouns to small set of semantic classes.</citsent>
<aftsection>
<nextsent>following work by chodorow, leacock and miller, we divided the possible model features into topical and local contextual features.
</nextsent>
<nextsent>topical features looked for the presence of keywords occurring anywhere in the sentence and any surrounding sentences provided as context (usually one or two sentences).
</nextsent>
<nextsent>the set of 200-300 keywords is specific to each lemma to be disambiguated, and is determined automatically from training data so as to minimize the entropy ofthe probability of the senses conditioned on the key word.the local features for verb in particular sentence tend to look only within the smallest clause containing w. they include collocational features requiring no linguistic preprocessing beyond part of-speech tagging (1), syntactic features that capture relations between the verb and its complements (24), and semantic features that incorporate information about noun classes for objects (5-6): 1.
</nextsent>
<nextsent>the word w, the part of speech of w, and words at positions -2, -1, +1, +2, relative to 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2681">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>these instances that were difficult for the automatic wsd system, were also difficult for human annotators to differentiate consistently.
</prevsent>
<prevsent>these different senses are clearly related, but the relation is not reflected in their hypernyms, which emphasize the differences in what is being highlighted by each sense, rather than the similarities.
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
methods of evaluation that automatically back off from synset to hypernyms (lin, 1997) <papid> P97-1009 </papid>would fail to credit the system for mistagging?</citsent>
<aftsection>
<nextsent>an instance with closely related sense.
</nextsent>
<nextsent>manually created sense groups, on the other hand, can capture broader, more underspecified senses which are not explicitly listed and which do not participate in any of the wordnet semantic relations.
</nextsent>
<nextsent>we have demonstrated that our approach to disambiguating verb senses using maximum entropy models to combine as many linguistic knowledge sources as possible, yields state-of-the-art performance for english.
</nextsent>
<nextsent>this may be language-dependent feature,as other experiments indicate that additional linguistic pre-processing does not necessarily improve tagging accuracy for languages like chinese (dang et al., 2002).<papid> C02-1143 </papid>in examining the instances that proved trouble some to both the human taggers and the automatic system, we found errors that were tied to subtle sense distinctions which were reconciled by backing off to the more coarse-grained sense groups.achieving higher inter-annotator agreement is necessary in order to provide consistent training data for supervised wsd systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2682">
<title id=" W02-0813.xml">combining contextual features for word sense disambiguation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>manually created sense groups, on the other hand, can capture broader, more underspecified senses which are not explicitly listed and which do not participate in any of the wordnet semantic relations.
</prevsent>
<prevsent>we have demonstrated that our approach to disambiguating verb senses using maximum entropy models to combine as many linguistic knowledge sources as possible, yields state-of-the-art performance for english.
</prevsent>
</prevsection>
<citsent citstr=" C02-1143 ">
this may be language-dependent feature,as other experiments indicate that additional linguistic pre-processing does not necessarily improve tagging accuracy for languages like chinese (dang et al., 2002).<papid> C02-1143 </papid>in examining the instances that proved trouble some to both the human taggers and the automatic system, we found errors that were tied to subtle sense distinctions which were reconciled by backing off to the more coarse-grained sense groups.achieving higher inter-annotator agreement is necessary in order to provide consistent training data for supervised wsd systems.</citsent>
<aftsection>
<nextsent>lexicographers have long recognized that many natural occurrences of polysemous words are embedded in underspecified contexts and could correspond to more than one specific sense.
</nextsent>
<nextsent>annotators need the option of selecting, as an alternative to an explicit sense, either group of specific senses or single, broader sense, where specific meaning nuances are subsumed.
</nextsent>
<nextsent>sense grouping, already present in limited way in wordnets verb component, can be guided and enhanced by the analysis of inter-annotator disagreements and the development of explicit sense distinction criteria that such an analysis provides.
</nextsent>
<nextsent>this work has been supported by national science foundation grants, nsf-9800658 and nsf 9910603, and darpa grant n66001-00-1-8915 at the university of pennsylvania.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2683">
<title id=" W03-1504.xml">lowcost named entity classification for catalan exploiting multilingual resources and unlabeled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>existing linguistic resources and/or limited funding possibilities.
</prevsent>
<prevsent>this is one of the main causes for the recent growing interest on developing language?
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
independent nerc systems, which may be trained from small training sets by taking advantage of un labelled examples (collins and singer, 1999; <papid> W99-0613 </papid>abney,2002), <papid> P02-1046 </papid>and which are easy to adapt to changing domains (being all these aspects closely related).this work focuses on exploring the construction of lowcost named entity classification (nec) module for catalan without making use of large/expensive resources of the language.</citsent>
<aftsection>
<nextsent>in doingso, the paper first explores the training of classification models by using only catalan resources andthen proposes training scheme, in which cata lan/spanish bilingual classifier is trained directly from training set including examples of the two languages.
</nextsent>
<nextsent>in both cases, the bootstrapping of the resulting classifiers is also explored by using large unannotated catalan corpus.
</nextsent>
<nextsent>the strategy used for training the bilingual ne classification models hasbeen also applied with good results to ne recognition in (carreras et al, 2003), <papid> E03-1038 </papid>work that can be considered complementary to this one.when considering the training of bilingual models, we take advantage of the facts that spanish and catalan are two romance languages with similar syntactic structure, and that since spanish and catalan social and cultural environments greatlyoverlap?</nextsent>
<nextsent>many named entities appear in both languages corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2685">
<title id=" W03-1504.xml">lowcost named entity classification for catalan exploiting multilingual resources and unlabeled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>existing linguistic resources and/or limited funding possibilities.
</prevsent>
<prevsent>this is one of the main causes for the recent growing interest on developing language?
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
independent nerc systems, which may be trained from small training sets by taking advantage of un labelled examples (collins and singer, 1999; <papid> W99-0613 </papid>abney,2002), <papid> P02-1046 </papid>and which are easy to adapt to changing domains (being all these aspects closely related).this work focuses on exploring the construction of lowcost named entity classification (nec) module for catalan without making use of large/expensive resources of the language.</citsent>
<aftsection>
<nextsent>in doingso, the paper first explores the training of classification models by using only catalan resources andthen proposes training scheme, in which cata lan/spanish bilingual classifier is trained directly from training set including examples of the two languages.
</nextsent>
<nextsent>in both cases, the bootstrapping of the resulting classifiers is also explored by using large unannotated catalan corpus.
</nextsent>
<nextsent>the strategy used for training the bilingual ne classification models hasbeen also applied with good results to ne recognition in (carreras et al, 2003), <papid> E03-1038 </papid>work that can be considered complementary to this one.when considering the training of bilingual models, we take advantage of the facts that spanish and catalan are two romance languages with similar syntactic structure, and that since spanish and catalan social and cultural environments greatlyoverlap?</nextsent>
<nextsent>many named entities appear in both languages corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2686">
<title id=" W03-1504.xml">lowcost named entity classification for catalan exploiting multilingual resources and unlabeled data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in doingso, the paper first explores the training of classification models by using only catalan resources andthen proposes training scheme, in which cata lan/spanish bilingual classifier is trained directly from training set including examples of the two languages.
</prevsent>
<prevsent>in both cases, the bootstrapping of the resulting classifiers is also explored by using large unannotated catalan corpus.
</prevsent>
</prevsection>
<citsent citstr=" E03-1038 ">
the strategy used for training the bilingual ne classification models hasbeen also applied with good results to ne recognition in (carreras et al, 2003), <papid> E03-1038 </papid>work that can be considered complementary to this one.when considering the training of bilingual models, we take advantage of the facts that spanish and catalan are two romance languages with similar syntactic structure, and that since spanish and catalan social and cultural environments greatlyoverlap?</citsent>
<aftsection>
<nextsent>many named entities appear in both languages corpora.
</nextsent>
<nextsent>relying on this structural and content similarity, we will build our catalan ne classifier on the following assumptions: (a) named entities appear in the same contexts in both languages,and (b) named entities are composed by similar patterns in both languages.
</nextsent>
<nextsent>the paper presents an extensive experimental evaluation, giving strong evidence about the advantage of using multilingual models for training on language with scarce resources.
</nextsent>
<nextsent>additionally, the catalan nec models resulting from the bilingual training are easier to improve by bootstrapping on un labelled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2687">
<title id=" W03-1504.xml">lowcost named entity classification for catalan exploiting multilingual resources and unlabeled data </title>
<section> setting.  </section>
<citcontext>
<prevsection>
<prevsent>for catalan, we find 33.0% of per, 17.1% of loc, 43.5% of org and 6.4% of mis out of the2,570 manually annotated nes, whereas for spanish, out of the 22,355 labelled nes, 22.6% are per, 26.8% are loc, 39.4% are org and the remaining 11.2% are mis.
</prevsent>
<prevsent>additionally, we used spanish 7,427 trigger word list typically accompanying persons, organizations, locations, etc., and an 11,951 entry gazetteer containing geographical and person names.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
these lists have been semi-automatically extracted from lexical resources and manually enriched afterwards.they have been used in some previous works allowing significant improvements for the spanish nerc task (carreras et al, 2002; <papid> W02-2004 </papid>carreras et al, 2003).<papid> E03-1038 </papid>trigger words are annotated with the corresponding spanish synsets in the euro wordnet lexical knowledge base.</citsent>
<aftsection>
<nextsent>since there are translation links among spanish and catalan (and other languages)for the majority of these words, an equivalent version of the trigger word list for catalan has been automatically derived.
</nextsent>
<nextsent>in this work, we consider the gazetteer as language independent resource and is in distinctly used for training catalan and spanish models.
</nextsent>
<nextsent>2.2 feature codification.
</nextsent>
<nextsent>the features that characterise the ne examples are defined in window  anchored at word  , representing its local context used by classifier to make decision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2710">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our best method achieves 60% reduction in the amount of training material without any loss inaccuracy.
</prevsent>
<prevsent>even with significant resources such as the penn tree bank, major bottleneck for improving statistical parsers has been the lack of sufficient annotated material from which to estimate their parameters.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
most statistical parsing research, such as collins (1997), <papid> P97-1003 </papid>has centered on training probabilistic context-free grammars using the penn treebank.</citsent>
<aftsection>
<nextsent>for richer linguistic frameworks, such as head-driven phrase structure grammar (hpsg), there is even less annotated material available for training stochastic parsing models.
</nextsent>
<nextsent>there is thus pressing need to create significant volumes of annotated material in logistically efficient manner.
</nextsent>
<nextsent>even if it were possible to bootstrap from the penn treebank, it is still unlikely that there would be sufficient quantities of high quality mate rial.there has been strong focus in recent years on using the active learning technique of selective sampling to reduce the amount of human-annotated training material needed to train models for various natural language processing tasks.
</nextsent>
<nextsent>the aim of selective sampling is to identify the most informative examples, according to some selection method, from large pool of un labelled material.such selected examples are then manually labelled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2711">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even if it were possible to bootstrap from the penn treebank, it is still unlikely that there would be sufficient quantities of high quality mate rial.there has been strong focus in recent years on using the active learning technique of selective sampling to reduce the amount of human-annotated training material needed to train models for various natural language processing tasks.
</prevsent>
<prevsent>the aim of selective sampling is to identify the most informative examples, according to some selection method, from large pool of un labelled material.such selected examples are then manually labelled.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
selective sampling has typically been applied to classification tasks, but has also been shown to reduce the number of examples needed for inducing lexicalized tree insertion grammars from the penn treebank (hwa, 2000).<papid> W00-1306 </papid>the suitability of active learning for hpsg-type grammars has as yet not been explored.</citsent>
<aftsection>
<nextsent>this paper addresses the problem of minimizing the human effort expended in creating annotated training material for hpsg parse selection by using selective sampling.
</nextsent>
<nextsent>we do so in the context of redwoods (oepen et al, 2002), <papid> C02-2025 </papid>treebank that contains hpsg analyses for sentences from the verbmo bil appointment scheduling and travel planning domains.we show that sample selection metrics based on tree entropy (hwa, 2000) <papid> W00-1306 </papid>and disagreement between two different parse selection models significantly reduce the number of annotated sentences necessary to match given level of performance according to random selection.</nextsent>
<nextsent>furthermore, by combining these two methods as an ensemble selection method, we require even fewer examples ? achieving 60% reduction in the amount of annotated training material needed to outperform model trained on randomly selected material.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2712">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>selective sampling has typically been applied to classification tasks, but has also been shown to reduce the number of examples needed for inducing lexicalized tree insertion grammars from the penn treebank (hwa, 2000).<papid> W00-1306 </papid>the suitability of active learning for hpsg-type grammars has as yet not been explored.</prevsent>
<prevsent>this paper addresses the problem of minimizing the human effort expended in creating annotated training material for hpsg parse selection by using selective sampling.</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
we do so in the context of redwoods (oepen et al, 2002), <papid> C02-2025 </papid>treebank that contains hpsg analyses for sentences from the verbmo bil appointment scheduling and travel planning domains.we show that sample selection metrics based on tree entropy (hwa, 2000) <papid> W00-1306 </papid>and disagreement between two different parse selection models significantly reduce the number of annotated sentences necessary to match given level of performance according to random selection.</citsent>
<aftsection>
<nextsent>furthermore, by combining these two methods as an ensemble selection method, we require even fewer examples ? achieving 60% reduction in the amount of annotated training material needed to outperform model trained on randomly selected material.
</nextsent>
<nextsent>these results suggest that significant reductions in human effort can be realized through selective sampling when creating annotated material for linguistically rich grammar formalisms.
</nextsent>
<nextsent>as the basis of our active learning approach, we create both log-linear and perceptron models, the latter of which has not previously been used for feature-based grammars.we show that the different biases of the two types of models is sufficient to create diverse members for committee, even when they use exactly the same features.
</nextsent>
<nextsent>with respect to the features used to train models, we demonstrate that very simple feature selection strategy that ignores the proper structure of trees is competitive with one that fully respects tree configurations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2715">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> active learning.  </section>
<citcontext>
<prevsection>
<prevsent>for certainty-based selection, the examples chosen for annotation are those for which single learner is least confident, as determined by some criterion.
</prevsent>
<prevsent>committee-based selection involves groups of learners that each maintain different hypotheses about the problem; examples on which the learners disagree insome respect are typically regarded as the most informative.
</prevsent>
</prevsection>
<citsent citstr=" P96-1042 ">
active learning has been successfully applied to number of natural language oriented tasks, including text categorization (lewis and gale, 1994) and part-of-speech tagging (engelson and dagan, 1996).<papid> P96-1042 </papid></citsent>
<aftsection>
<nextsent>hwa (2000) <papid> W00-1306 </papid>shows that certainty-based selective sampling can reduce the amount of training material needed for inducing probabilistic lexicalized tree insertion grammars by 36% without degrading the quality of the grammars.</nextsent>
<nextsent>like hwa, we investigate active learning for parsing and thus seek informative sentences; however, rather than inducing grammars, our task is to select the best parse from the output of an existing hand-crafted grammar by using the redwoods treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2718">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 features.
</prevsent>
<prevsent>our two feature sets are created by using only the derivation trees made available in redwoods.
</prevsent>
</prevsection>
<citsent citstr=" W02-2030 ">
the configura tional set is loosely based on the derivation tree features given by toutanova and manning (2002), <papid> W02-2030 </papid>and thus encodes standard relations such as grandparent-of and left sibling for the nodes in the tree.</citsent>
<aftsection>
<nextsent>the ngram set is created by flattening derivation trees and treating them as strings of rule names over which ngrams are extracted, taking up to four rule names at time and including the number of intervening parentheses between them.
</nextsent>
<nextsent>we ignore orthographic values for both feature sets.
</nextsent>
<nextsent>as examples of typical ngram features, the derivation tree given in figure 1 generates features such as those depicted in figure 2.
</nextsent>
<nextsent>such features provide reasonable approximation of trees that implicitly encodes many of the interesting relationships that are typically gathered from them, such as grandparent and sibling relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2720">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>when preparing the training material, we record observations about the distribution of analyses with binary distinction that simply identifies the preferred parse, rather than using full regression approach that recognizes similarities between the preferred parse and some of the dis preferred ones.
</prevsent>
<prevsent>log-linear models have previously been used for stochastic unification-based grammars by johnson et al.
</prevsent>
</prevsection>
<citsent citstr=" C00-1085 ">
(1999) and osborne (2000).<papid> C00-1085 </papid></citsent>
<aftsection>
<nextsent>using redwoods-1,toutanova and manning (2002) <papid> W02-2030 </papid>have shown that loglinear models for parse selection considerably outperform pcfg models trained on the same features.</nextsent>
<nextsent>byusing features based on both derivation trees and semantic dependency trees, they achieved 83.32% exact match whole-sentence parse selection with an an ensemble oflog-linear models that used different subsets of the feature space.as standard for parse selection using log-linear modelling, we model the probability of an analysis ffi  given sentence with set of analyses !# $ffi   ffi&amp;% fl as follows:   (ffi  ) *</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2722">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>returns the number of times feature 4 occurs in analysis ffi and 3  *
</prevsent>
<prevsent>is normalization factor for the sentence.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
the parse with the highest probability is takenas the preferred parse for the model.2 we use the limited memory variable metric algorithm (malouf, 2002) <papid> W02-2018 </papid>to determine the weights.</citsent>
<aftsection>
<nextsent>perceptrons have been used by collins and duffy(2002) <papid> P02-1034 </papid>to re-rank the output of pcfg, but have not previously been applied to feature-based grammars.</nextsent>
<nextsent>standard perceptrons assign score rather than probability to each analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2723">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>is normalization factor for the sentence.
</prevsent>
<prevsent>the parse with the highest probability is takenas the preferred parse for the model.2 we use the limited memory variable metric algorithm (malouf, 2002) <papid> W02-2018 </papid>to determine the weights.</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
perceptrons have been used by collins and duffy(2002) <papid> P02-1034 </papid>to re-rank the output of pcfg, but have not previously been applied to feature-based grammars.</citsent>
<aftsection>
<nextsent>standard perceptrons assign score rather than probability to each analysis.
</nextsent>
<nextsent>scores are computed by taking the inner product of the analysis?
</nextsent>
<nextsent>feature vector with the parameter vector: *.576fi8 , ffi
</nextsent>
<nextsent>9   : 1 2  ff 1 (ffi
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2729">
<title id=" W03-0403.xml">active learning for hpsg parse selection </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>however, it requires the learner to be probabilistic, and thus cannot be straightforwardly used with machine learning algorithms such as standard perceptrons and support vector machines.
</prevsent>
<prevsent>a more important difference between tree entropy and disagreement is that the latter leads naturally to acombined approach using both active learning and co training.
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
rather than comparing the two learners on whether they categorically select the same preferred parse on number of examples, we can view active learning as the inverse of agreement-based co-training (abney, 2002).<papid> P02-1046 </papid></citsent>
<aftsection>
<nextsent>we can then explore thresholds for which we can determine that certain examples need to be human annotated and others can be confidently machine labelled.in future work, we will explore the effect of using further models that utilize the semantic information in redwoods for sample selection, and we will apply active learning to both expand redwoods and add discourse level annotations.
</nextsent>
<nextsent>acknowledgements.
</nextsent>
<nextsent>we would like to thank markus becker, chris callison-burch, dan flickinger, alex lascarides, chris manning, stephan oepen, kristina toutanova, and the anonymous reviewers.
</nextsent>
<nextsent>this work was supported by edinburgh-stanford link r36763, rosie project.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2730">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> how to ensure local cohesion.  </section>
<citcontext>
<prevsection>
<prevsent>several criteria are used to evaluate these algorithms on scientific articles in section 5.
</prevsent>
<prevsent>we finish with concluding remarks, which also indicate possible future research avenues.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
in the previous section we already mentioned that we are trying to improve the automatic summaries by using the continuity principle defined in centering theory (ct) (grosz et al, 1995).<papid> J95-2003 </papid></citsent>
<aftsection>
<nextsent>this principle, requires that two consecutive utterances have at least one entity in common.
</nextsent>
<nextsent>even though it sounds very simple, this principle is important for the rest of the principles defined in the ct because if it does not hold, none of the other principles can be satisfied.
</nextsent>
<nextsent>given that only the continuity principle will be used in this paper and due to space limits, the rest of these principles are not discussed here.
</nextsent>
<nextsent>their description can be found in (kibble and power, 2000).<papid> W00-1411 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2731">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> how to ensure local cohesion.  </section>
<citcontext>
<prevsection>
<prevsent>even though it sounds very simple, this principle is important for the rest of the principles defined in the ct because if it does not hold, none of the other principles can be satisfied.
</prevsent>
<prevsent>given that only the continuity principle will be used in this paper and due to space limits, the rest of these principles are not discussed here.
</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
their description can be found in (kibble and power, 2000).<papid> W00-1411 </papid></citsent>
<aftsection>
<nextsent>for the same reason we will not go into details about the ct. in this paper, we take an approach similar to (karamanis and manurung, 2002) and try to produce summaries which do not violate the continuity principle.
</nextsent>
<nextsent>in this way, we hope to produce summaries which contain sequences of sentences that refer the same entity, and therefore will be more coherent.
</nextsent>
<nextsent>before we can test if the principle is satisfied, it is necessary to define certain parameters on which the principle relies.
</nextsent>
<nextsent>as aforementioned, the principle is tested on pairs of consecutive utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2732">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> how to ensure local cohesion.  </section>
<citcontext>
<prevsection>
<prevsent>an advantage of using sentences is that most summarisation methods extract sentences, which makes it easier to integrate them with our method.
</prevsent>
<prevsent>in this paper, we consider that two utterances have an entity in common if the same head noun phrase appears in both utterances.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
in order to determine the head of noun phrases we use the fdg tagger (tapanainen and jarvinen, 1997) <papid> A97-1011 </papid>which also provides partial dependency relations between the constituents of sentence.</citsent>
<aftsection>
<nextsent>at this stage we do not employ any other method to determine whether two noun phrases are semantically related.
</nextsent>
<nextsent>before we implemented our method, we wanted to learn if the continuity principle holds in human produced summaries.
</nextsent>
<nextsent>in order to perform this analysis we investigated corpus of 146 human produced abstracts from the journal of artificial intelligence research (jair).
</nextsent>
<nextsent>1 most of the processing was done automatically using simple script which tests if the principle is satisfied by pairs of consecutive utterances (i.e. if the pair has at least one head noun phrase in common).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2733">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> the method.  </section>
<citcontext>
<prevsection>
<prevsent>the heuristics employed to compute the score are: keyword method: uses the tf-idf scores of words to compute the importance of sentences.
</prevsent>
<prevsent>the score of sentence is the sum of words?
</prevsent>
</prevsection>
<citsent citstr=" C96-2166 ">
scores from that sentence (zechner, 1996) <papid> C96-2166 </papid>indicator phrase method: paice (1981) noticed that in scientific papers it is possible to identify phrases such as in this paper, we present, in conclusion, which are usually meta-discourse markers.</citsent>
<aftsection>
<nextsent>a list of such phrases has been built and all the sentences which contain an indicating phrase have their scores boosted or penalised depending on the phrase.
</nextsent>
<nextsent>location method: in scientific papers important sentences tend to appear at the beginning and end of the document.
</nextsent>
<nextsent>for this reason sentences in the first and the last 13 paragraphs have their scores boosted.
</nextsent>
<nextsent>this value was determined through experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2734">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> evaluation and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>throughout the paper we have mentioned the term quality of summary several times without defining it.
</prevsent>
<prevsent>in this paper the quality of summary is measured in terms of coherence, cohesion and informativeness.
</prevsent>
</prevsection>
<citsent citstr=" W97-0705 ">
the coherence and cohesion were quantified through direct evaluation using methodology similar to the one proposed in (minel et al, 1997).<papid> W97-0705 </papid></citsent>
<aftsection>
<nextsent>the cohesion of summary is indicated by the number of dangling anaphoric expressions,3 whereas the coherence by the number of ruptures in the discourse.
</nextsent>
<nextsent>for informative ness we computed the similarity between the automatic summary and the document as proposed in (donaway et al, 2000).<papid> W00-0408 </papid></nextsent>
<nextsent>given that the methods discussed in this paper try to enforce local coherence they directly influence only the number of discourse ruptures, the changes of the other two measures are secondary effect.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2735">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> evaluation and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the coherence and cohesion were quantified through direct evaluation using methodology similar to the one proposed in (minel et al, 1997).<papid> W97-0705 </papid></prevsent>
<prevsent>the cohesion of summary is indicated by the number of dangling anaphoric expressions,3 whereas the coherence by the number of ruptures in the discourse.</prevsent>
</prevsection>
<citsent citstr=" W00-0408 ">
for informative ness we computed the similarity between the automatic summary and the document as proposed in (donaway et al, 2000).<papid> W00-0408 </papid></citsent>
<aftsection>
<nextsent>given that the methods discussed in this paper try to enforce local coherence they directly influence only the number of discourse ruptures, the changes of the other two measures are secondary effect.
</nextsent>
<nextsent>in our evaluation, we compared the two new algorithms with baseline method and the content based method.
</nextsent>
<nextsent>the baseline, referred to as tfidf, extracts the sentences with the highest tf idf scores.
</nextsent>
<nextsent>the comparison with the baseline does not tell us if by adding the context information described in section 4.2 the quality of summary improves.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2742">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, the greedy method seems to exclude useful information, for several texts, performing worse than the basic method and the baseline.
</prevsent>
<prevsent>in text summarisation several researchers have addressed the problem of producing coherent summaries.
</prevsent>
</prevsection>
<citsent citstr=" P99-1072 ">
in general, rules are applied to revise summaries produced by summarisation system (mani et al, 1999; <papid> P99-1072 </papid>otterbacher et al, 2002).<papid> W02-0404 </papid></citsent>
<aftsection>
<nextsent>these rules are produced by humans who read the automatic summaries and identify coherence problems.
</nextsent>
<nextsent>marcu (2000) produced coherent summaries using rhetorical structure theory (rst).
</nextsent>
<nextsent>a combination of rst and lexical chains is employed in (alonso alemany and fuentes fort, 2003) for the same purpose.
</nextsent>
<nextsent>comparison to the work by marcu and alonso alemany is difficult to make because they worked with different types of texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2743">
<title id=" W03-1205.xml">an evolutionary approach for improving the quality of automatic summaries </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, the greedy method seems to exclude useful information, for several texts, performing worse than the basic method and the baseline.
</prevsent>
<prevsent>in text summarisation several researchers have addressed the problem of producing coherent summaries.
</prevsent>
</prevsection>
<citsent citstr=" W02-0404 ">
in general, rules are applied to revise summaries produced by summarisation system (mani et al, 1999; <papid> P99-1072 </papid>otterbacher et al, 2002).<papid> W02-0404 </papid></citsent>
<aftsection>
<nextsent>these rules are produced by humans who read the automatic summaries and identify coherence problems.
</nextsent>
<nextsent>marcu (2000) produced coherent summaries using rhetorical structure theory (rst).
</nextsent>
<nextsent>a combination of rst and lexical chains is employed in (alonso alemany and fuentes fort, 2003) for the same purpose.
</nextsent>
<nextsent>comparison to the work by marcu and alonso alemany is difficult to make because they worked with different types of texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2748">
<title id=" W03-0431.xml">meta learning orthographic and contextual models for language independent named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the features that best classify words according to the two tasks are somewhat disparate, the two are often separated.
</prevsent>
<prevsent>attribute sets may be further divided into subsets through sub-grouping of attributes,sub-grouping of instances and/or the use of multiple classifying processes.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
while the use of multiple subsets can increase overall accuracy, the recombination of models has been shown to propagate errors (carreras et al, 2002;<papid> W02-2004 </papid>patrick et al, 2002).<papid> W02-2022 </papid></citsent>
<aftsection>
<nextsent>more importantly, the decision regarding the separation of attributes into various subsets is often manual task.
</nextsent>
<nextsent>as it is reasonable to assume that thesame attributes will have different relative levels of significance in different languages, using the same division of attributes across languages will be less than optimal, while manual redistribution across different languages is limited by the users knowledge of those languages.
</nextsent>
<nextsent>in this paper, the division and subsequent recombination of subgroups is treated as meta-learning task.
</nextsent>
<nextsent>it has been our intention to create linguistically driven model of named entity composition, and to search forthe attribute representations of these linguistic phenomena that best suit inference by machine learning algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2749">
<title id=" W03-0431.xml">meta learning orthographic and contextual models for language independent named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the features that best classify words according to the two tasks are somewhat disparate, the two are often separated.
</prevsent>
<prevsent>attribute sets may be further divided into subsets through sub-grouping of attributes,sub-grouping of instances and/or the use of multiple classifying processes.
</prevsent>
</prevsection>
<citsent citstr=" W02-2022 ">
while the use of multiple subsets can increase overall accuracy, the recombination of models has been shown to propagate errors (carreras et al, 2002;<papid> W02-2004 </papid>patrick et al, 2002).<papid> W02-2022 </papid></citsent>
<aftsection>
<nextsent>more importantly, the decision regarding the separation of attributes into various subsets is often manual task.
</nextsent>
<nextsent>as it is reasonable to assume that thesame attributes will have different relative levels of significance in different languages, using the same division of attributes across languages will be less than optimal, while manual redistribution across different languages is limited by the users knowledge of those languages.
</nextsent>
<nextsent>in this paper, the division and subsequent recombination of subgroups is treated as meta-learning task.
</nextsent>
<nextsent>it has been our intention to create linguistically driven model of named entity composition, and to search forthe attribute representations of these linguistic phenomena that best suit inference by machine learning algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2750">
<title id=" W03-0431.xml">meta learning orthographic and contextual models for language independent named entity recognition </title>
<section> feature representation.  </section>
<citcontext>
<prevsection>
<prevsent>individual grams, or aggregations of them, may be used as attributes in part of larger dataset for machine learning.
</prevsent>
<prevsent>modeling at the orthographic level has been shownto be successful method of named entity recognition.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
orthographic tries (cucerzan and yarowsky, 1999; <papid> W99-0612 </papid>whitelaw and patrick, 2003; <papid> W03-0432 </papid>whitelaw and patrick, 2002) and character n-gram modelling (patrick et al, 2002) <papid> W02-2022 </papid>are two methods for capturing orthographic features.</citsent>
<aftsection>
<nextsent>while tries give rich representation of word, they are fixed to one boundary of word and cannot extend beyond unseen character sequences.
</nextsent>
<nextsent>as they are also classifying tool in themselves, their integration with machine learning algorithm is problematic, as evidenced by reduction of overall accuracy when processing trie output through machine learner in patrick et al (2002).<papid> W02-2022 </papid></nextsent>
<nextsent>as such, tries have not been used here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2751">
<title id=" W03-0431.xml">meta learning orthographic and contextual models for language independent named entity recognition </title>
<section> feature representation.  </section>
<citcontext>
<prevsection>
<prevsent>individual grams, or aggregations of them, may be used as attributes in part of larger dataset for machine learning.
</prevsent>
<prevsent>modeling at the orthographic level has been shownto be successful method of named entity recognition.
</prevsent>
</prevsection>
<citsent citstr=" W03-0432 ">
orthographic tries (cucerzan and yarowsky, 1999; <papid> W99-0612 </papid>whitelaw and patrick, 2003; <papid> W03-0432 </papid>whitelaw and patrick, 2002) and character n-gram modelling (patrick et al, 2002) <papid> W02-2022 </papid>are two methods for capturing orthographic features.</citsent>
<aftsection>
<nextsent>while tries give rich representation of word, they are fixed to one boundary of word and cannot extend beyond unseen character sequences.
</nextsent>
<nextsent>as they are also classifying tool in themselves, their integration with machine learning algorithm is problematic, as evidenced by reduction of overall accuracy when processing trie output through machine learner in patrick et al (2002).<papid> W02-2022 </papid></nextsent>
<nextsent>as such, tries have not been used here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2754">
<title id=" W03-0431.xml">meta learning orthographic and contextual models for language independent named entity recognition </title>
<section> feature representation.  </section>
<citcontext>
<prevsection>
<prevsent>as they are also classifying tool in themselves, their integration with machine learning algorithm is problematic, as evidenced by reduction of overall accuracy when processing trie output through machine learner in patrick et al (2002).<papid> W02-2022 </papid></prevsent>
<prevsent>as such, tries have not been used here.</prevsent>
</prevsection>
<citsent citstr=" W02-2003 ">
although n-gram modelling hasnot always been successful as lone method of classification (burger et al, 2002), <papid> W02-2003 </papid>for the reasons outlined above it is more flexible modelling technique than tries.to capture affixal information, we used n-grams modelling to extract features for the suffixes and prefixes of all words for all categories.for general orthographic information we used the average probability of all bi-grams occurring in word for each category, and the value of the maximum and minimum probability of all bi-grams in word for eachcategory.</citsent>
<aftsection>
<nextsent>to capture contextual information, these bigram attributes was also extracted across word boundaries, both pre/post and exclusive/inclusive of the current word, for different context windows.all n-grams were extracted for the four entity types, location, person, organisation and miscellaneous, with theword level n-grams also extracted for ne recognition attributes using ioe2 model.the aggregate n-gram attributes (for example, the average probability of all the n-grams in word belonging to category), act as memory based attribute, clustering forms with less then random variance.
</nextsent>
<nextsent>these most benefit agglutinative structures, such as the compound words common to german, as well as morphologically disparate forms, for example, australia?
</nextsent>
<nextsent>and australian?.
</nextsent>
<nextsent>here, ofall the n-grams, only the final one differs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2756">
<title id=" W03-0431.xml">meta learning orthographic and contextual models for language independent named entity recognition </title>
<section> normalising case information.  </section>
<citcontext>
<prevsection>
<prevsent>this amounted to approximately 10,000,000 words.
</prevsent>
<prevsent>from these, we extracted the observed probability of word occurring as lowercase, all capitals, initial capital, or internal capital; the bi-gram distribution across these four categories; and the part-of-speech and chunking tags of the word.
</prevsent>
</prevsection>
<citsent citstr=" W01-0721 ">
using decision graph (patrick and goyal, 2001), <papid> W01-0721 </papid>all words from the test and training sets were the neither recapitalised or decapitalised according to the out put.</citsent>
<aftsection>
<nextsent>the results were 97.8% accurate, as indicated by the number of elements in the training set that were correctly re-assigned their original case.the benefit of case-restoration for the english development set was f?=1 1.56.
</nextsent>
<nextsent>case-restoration was not undertaken on the english test set or german sets.
</nextsent>
<nextsent>for consistency, the english development results reported in table 1 are for processing without case restoration.
</nextsent>
<nextsent>we leave more thorough investigation of case restoration as future work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2758">
<title id=" W03-1717.xml">learning verb noun relations to improve parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the question is how to acquire such knowledge automatically.
</prevsent>
<prevsent>in the rest of this paper, we will present learning procedure that learns those relations by processing large corpus with chart-filter, tree filter and an llr filter.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
the approach is in the spirit of smadja (1993) <papid> J93-1007 </papid>on retrieving collocations from text corpora, but is more integrated with pars ing.</citsent>
<aftsection>
<nextsent>we will show in the evaluation section how much the learned knowledge can help improve sentence analysis.
</nextsent>
<nextsent>the syntactic ambiguity associated with the verb noun sequence can be either local or global.
</nextsent>
<nextsent>the kind of ambiguity we have observed in (1) and (2) is global in nature, which exists even if this noun phrase is plugged into larger structure or complete sentence.
</nextsent>
<nextsent>there are also local ambiguities where the ambiguity disappears once the verb noun sequence is put into broader context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2759">
<title id=" W03-1717.xml">learning verb noun relations to improve parsing </title>
<section> the learning procedure.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, the objects are not typical?.
</prevsent>
<prevsent>secondly, those verbs tend not to occur in the modifier-head relation with following noun and we gain very little in terms of disambiguation by storing those pairs in the knowledge base.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
to prune away those pairs, we used the log-likelihood-ratio algorithm (dunning, 1993) <papid> J93-1003 </papid>to compute the degree of association between the verb and the noun in each pair.</citsent>
<aftsection>
<nextsent>pairs where there is high mutual information?
</nextsent>
<nextsent>between the verb and noun would receive higher scores while pairs where the verb can co-occur with many different nouns would receive lower scores.
</nextsent>
<nextsent>pairs with association scores below certain threshold were then thrown out.
</nextsent>
<nextsent>this not only makes the remaining pairs more typical?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2760">
<title id=" W03-1717.xml">learning verb noun relations to improve parsing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the first pass is the learning phase where we acquire additional knowledge by parsing the corpus.
</prevsent>
<prevsent>the knowledge acquired is used in the second pass to get better parses.
</prevsent>
</prevsection>
<citsent citstr=" C02-2002 ">
this is one example of the general approach of improving parsing by parsing?, as described in (wu et al  2002).<papid> C02-2002 </papid></citsent>
<aftsection>
<nextsent>to find out how much the learned knowledge contributes to the improvement of parsing, we performed human evaluation.
</nextsent>
<nextsent>in the evaluation, we used our existing sentence analyzer (heidorn 2000, jensen et al 1993, wu and jiang 1998) to process corpus of 271,690 sentences to learn the verb-noun relations.
</nextsent>
<nextsent>we then parsed the same sentences first without the additional knowledge and then with the acquired knowledge.
</nextsent>
<nextsent>comparing the outputs, we found that 16,445 (6%) of the sentences had different analyses in the two passes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2761">
<title id=" W03-1308.xml">biomedical entity extraction using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this task is an extension of the named entity task defined by the darpa-sponsored message understanding conferences (mucs) (muc, 1995) and is aimed at acquiring the shallow semantic building blocks that contribute to high level understanding of the text.
</prevsent>
<prevsent>although our study here looks at shallow semantics that can be captured using ie our basic goal is to join this with deep semantic representations so that computers can obtain full understanding of the facts in text using logical inference and reasoning.
</prevsent>
</prevsection>
<citsent citstr=" W98-1120 ">
the scenario is that human experts will create taxonomies and axioms (ontologies) and by providing small set of annotated examples, machine learning can take over the role of instance capturing though information extraction technology.recent studies into the use of supervised learning based models for the named entity task have shown that models based on hidden markov models (hmms) (bikel et al, 1997), and decision trees(sekine et al, 1998), <papid> W98-1120 </papid>and maximum entropy (borth wicket al, 1998) <papid> W98-1118 </papid>are much more generali sable and adaptable to new classes of words than systems based on hand-built patterns (including wrappers) and domain specific heuristic rules such as (herzig and johns, 1997).the method we use is based on support vector machines (svms)(vapnik, 1995), state of theart model that has achieved new levels of performance in many classification tasks.</citsent>
<aftsection>
<nextsent>in previous work we have shown svms to be superior to several other commonly used machine learning methods for named entity in previous experiments suchas hmms and c4.5 (citations omitted).
</nextsent>
<nextsent>this paper explores the underlying svm model and shows through detailed empirical analysis the key features and parameter settings.to show the application of svms to term extraction in unstructured texts related to the medical sciences we are using collection of abstracts from pubmeds medline (medline, 1999).
</nextsent>
<nextsent>themed line database is an online collection of abstracts for published journal articles in biology and medicine and contains more than nine million articles.
</nextsent>
<nextsent>the collection we use in our tests is controlled subset of medline obtained using three search keywords in the domain of molecular biology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2762">
<title id=" W03-1308.xml">biomedical entity extraction using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this task is an extension of the named entity task defined by the darpa-sponsored message understanding conferences (mucs) (muc, 1995) and is aimed at acquiring the shallow semantic building blocks that contribute to high level understanding of the text.
</prevsent>
<prevsent>although our study here looks at shallow semantics that can be captured using ie our basic goal is to join this with deep semantic representations so that computers can obtain full understanding of the facts in text using logical inference and reasoning.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
the scenario is that human experts will create taxonomies and axioms (ontologies) and by providing small set of annotated examples, machine learning can take over the role of instance capturing though information extraction technology.recent studies into the use of supervised learning based models for the named entity task have shown that models based on hidden markov models (hmms) (bikel et al, 1997), and decision trees(sekine et al, 1998), <papid> W98-1120 </papid>and maximum entropy (borth wicket al, 1998) <papid> W98-1118 </papid>are much more generali sable and adaptable to new classes of words than systems based on hand-built patterns (including wrappers) and domain specific heuristic rules such as (herzig and johns, 1997).the method we use is based on support vector machines (svms)(vapnik, 1995), state of theart model that has achieved new levels of performance in many classification tasks.</citsent>
<aftsection>
<nextsent>in previous work we have shown svms to be superior to several other commonly used machine learning methods for named entity in previous experiments suchas hmms and c4.5 (citations omitted).
</nextsent>
<nextsent>this paper explores the underlying svm model and shows through detailed empirical analysis the key features and parameter settings.to show the application of svms to term extraction in unstructured texts related to the medical sciences we are using collection of abstracts from pubmeds medline (medline, 1999).
</nextsent>
<nextsent>themed line database is an online collection of abstracts for published journal articles in biology and medicine and contains more than nine million articles.
</nextsent>
<nextsent>the collection we use in our tests is controlled subset of medline obtained using three search keywords in the domain of molecular biology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2763">
<title id=" W03-1308.xml">biomedical entity extraction using support vector machines </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the number of parameters to be estimated in ? therefore never exceeds the number of examples.
</prevsent>
<prevsent>the influence of basically means that training examples with   0 define the decision function (the support vectors) and those examples with = 0 have no influence, making the final model very compact and testing (but not training) very fast.
</prevsent>
</prevsection>
<citsent citstr=" W02-2029 ">
the point is classified as positive (or negative) if f(x)   0 (or f(x)   0).the kernel function we explored in our experiments was the polynomial function k(xi, xj) = (xi ? xj + 1)d for = 2 which was found to be the best by (takeuchi and collier, 2002).<papid> W02-2029 </papid></citsent>
<aftsection>
<nextsent>once input vectors have been mapped to the feature space the linear discrimination function which is found is the one which gives the maximum the geometric margin between the two classes in the feature space.
</nextsent>
<nextsent>besides efficiency of representation, svms are known to maximize their generalizability, making them an ideal model for the ne+ task.
</nextsent>
<nextsent>generalizability in svms is based on statistical learning theory and the observation that it is useful sometimes to mis classify some of the training data so that the margin between other training points is maximized.
</nextsent>
<nextsent>this is particularly useful for real world datasets that often contain inseparable data points.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2764">
<title id=" W03-1308.xml">biomedical entity extraction using support vector machines </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the multiclass model is built up from combining binary classifiers and then applying majority voting.
</prevsent>
<prevsent>3.2 generalising with features.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
in order for the model to be successful it must recognize regularities in the training data that relate pre classified examples of terms with unseen terms that will be encountered in testing.following on from previous studies in named entity we chose set of linguistically motivated word level features that include surface word forms, part of speech tags using the brill tagger (brill, 1992) <papid> A92-1021 </papid>and orthographic features.</citsent>
<aftsection>
<nextsent>additionally we usedhead-noun features that were obtained from pre analysis of the training dataset using the fdg shallow parser from conexor (tapanainen and jarvinen, 1997).<papid> A97-1011 </papid></nextsent>
<nextsent>a significant proportion of the terms inour corpus undergo local syntactic transformations such as coordination which introduces ambiguity that needs to be resolved by shallow parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2765">
<title id=" W03-1308.xml">biomedical entity extraction using support vector machines </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 generalising with features.
</prevsent>
<prevsent>in order for the model to be successful it must recognize regularities in the training data that relate pre classified examples of terms with unseen terms that will be encountered in testing.following on from previous studies in named entity we chose set of linguistically motivated word level features that include surface word forms, part of speech tags using the brill tagger (brill, 1992) <papid> A92-1021 </papid>and orthographic features.</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
additionally we usedhead-noun features that were obtained from pre analysis of the training dataset using the fdg shallow parser from conexor (tapanainen and jarvinen, 1997).<papid> A97-1011 </papid></citsent>
<aftsection>
<nextsent>a significant proportion of the terms inour corpus undergo local syntactic transformations such as coordination which introduces ambiguity that needs to be resolved by shallow parsing.
</nextsent>
<nextsent>for example the c- and v-rel (proto) oncogenes and nf-kappab and kappa protein families.
</nextsent>
<nextsent>in these cases the head noun features oncogene and family would be added to each word in the constituentphrase.
</nextsent>
<nextsent>head information is also needed when deciding the semantic category of long term such astumor necrosis factor-alpha which should be protein, whereas tumor necrosis factor (tnf) gene and tumor necrosis factor promoter region should both be types of dna.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2766">
<title id=" W02-1041.xml">information extraction from voicemail transcripts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>here we will discuss one way of addressing this problem, treating it exclusively as the task of extracting relevant information from voicemail transcripts.
</prevsent>
<prevsent>in practice, e.g. in the context of sophisticated voicemail front-end (hirschberg et al, 2001) that is tightly integrated with an organization-wide voicemail system and private branch exchange (pbx), additional sources of information may be available: the voicemail system or the pbx might provide information about the originating station of call, and speaker identification can be used to match callers voice against models of known callers (rosenberg et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" P01-1039 ">
restricting our attention to voicemail transcripts means that our focus and goals are similar to those of huang et al (2001), <papid> P01-1039 </papid>but the features and techniques we use are very different.</citsent>
<aftsection>
<nextsent>while the present task may seem broadly similar to named entity extraction from broadcast news (go toh and renals, 2000), it is quite distinct from the latter: first, we are only interested in small subset of the named entities; and second, the structure ofthe voicemail transcripts in our corpus is very different from broadcast news and certain aspects of this structure can be exploited for extracting caller names.
</nextsent>
<nextsent>huang et al (2001) <papid> P01-1039 </papid>discuss three approaches:hand-crafted rules; grammatical inference of subse quential transducers; and log-linear classifiers with bigram and trigram features used as taggers (ratna parkhi, 1996).<papid> W96-0213 </papid></nextsent>
<nextsent>while the latter are reported to yield the best overall performance, the hand-crafted rules resulted in higher recall.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2774">
<title id=" W02-1041.xml">information extraction from voicemail transcripts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>restricting our attention to voicemail transcripts means that our focus and goals are similar to those of huang et al (2001), <papid> P01-1039 </papid>but the features and techniques we use are very different.</prevsent>
<prevsent>while the present task may seem broadly similar to named entity extraction from broadcast news (go toh and renals, 2000), it is quite distinct from the latter: first, we are only interested in small subset of the named entities; and second, the structure ofthe voicemail transcripts in our corpus is very different from broadcast news and certain aspects of this structure can be exploited for extracting caller names.</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
huang et al (2001) <papid> P01-1039 </papid>discuss three approaches:hand-crafted rules; grammatical inference of subse quential transducers; and log-linear classifiers with bigram and trigram features used as taggers (ratna parkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>while the latter are reported to yield the best overall performance, the hand-crafted rules resulted in higher recall.
</nextsent>
<nextsent>our phone number extractor is based on two-phase procedure that employs small hand-crafted component to propose candidate phrases, followed by classifier that retains the desirable candidates.
</nextsent>
<nextsent>this allows for more or less inde association for computational linguistics.
</nextsent>
<nextsent>language processing (emnlp), philadelphia, july 2002, pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2831">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the data contains enti 1 the data les are available from http://lcg-www.
</prevsent>
<prevsent>uia.ac.be/conll2002/ner/ties of four types: persons (per), organizations (org), locations (loc) and miscellaneous names (misc).
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
the tagging scheme is avariant of the iob scheme originally put forward by ramshaw and marcus (1995).<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>we assume that named entities are non-recursive andnon-overlapping.
</nextsent>
<nextsent>in case named entity is embedded in another named entity usually only the top level entity will be marked.
</nextsent>
<nextsent>the spanish data is collection of news wire articles made available by the spanish efe newsagency.
</nextsent>
<nextsent>the articles are from may 2000.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2832">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> data and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the dutch data consist of four editions of the belgian newspaper  de morgen  of 2000 (june 2, july 1, august 1 and september 1).
</prevsent>
<prevsent>the data was annotated as part of the atranos project 4at the university of antwerp in belgium, europe.
</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
the annotator has followed the mitre and saic guidelines for named entity recognition (chinchor et al, 1999) as well as possible.the data consists of words, entity tags and part of-speech tags which have been derived by dutch part-of-speech tagger (daelemans et al, 1996).<papid> W96-0102 </papid></citsent>
<aftsection>
<nextsent>additionally the article boundaries in the text have been marked explicitly with lines containing the tag -docstart-.
</nextsent>
<nextsent>the training, development and test data les contain 218737, 40656 and 74189 lines respectively.the performance in this task is measured with =1 rate which is equal to ( 2 +1)*precision*recall / ( 2 *precision+recall) with =1 (van rijsbergen, 1975).
</nextsent>
<nextsent>precision is the percentage of named entities found by the learning system that are correct.
</nextsent>
<nextsent>recall is the percentage of named entities present in the corpus that are found by the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2833">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>if phrase was part of more than one entity, the system would select the longest one.
</prevsent>
<prevsent>all systems that participated in the shared task have outperformed the baseline system.
</prevsent>
</prevsection>
<citsent citstr=" W02-2020 ">
mcnamee and may eld (2002) <papid> W02-2020 </papid>have applied support vector machines to the data of the shared task.</citsent>
<aftsection>
<nextsent>their system used many binary features for representing words (almost 9000).they have evaluated dierent parameter settings of the system and have selected cascaded approach in which rst entity boundaries were predicted and then entity classes (spanish test set: =1 =60.97; dutch test set: =1 =59.52).black and vasilakopoulos (2002) <papid> W02-2002 </papid>have evaluated two approaches to the shared task.</nextsent>
<nextsent>the rst was transformation-based method which generated in rules in single pass rather than in many passes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2834">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>all systems that participated in the shared task have outperformed the baseline system.
</prevsent>
<prevsent>mcnamee and may eld (2002) <papid> W02-2020 </papid>have applied support vector machines to the data of the shared task.</prevsent>
</prevsection>
<citsent citstr=" W02-2002 ">
their system used many binary features for representing words (almost 9000).they have evaluated dierent parameter settings of the system and have selected cascaded approach in which rst entity boundaries were predicted and then entity classes (spanish test set: =1 =60.97; dutch test set: =1 =59.52).black and vasilakopoulos (2002) <papid> W02-2002 </papid>have evaluated two approaches to the shared task.</citsent>
<aftsection>
<nextsent>the rst was transformation-based method which generated in rules in single pass rather than in many passes.
</nextsent>
<nextsent>the second method was decision tree method.
</nextsent>
<nextsent>they found that thetransformation-based method consistently outperformed the decision trees (spanish test set: =1 =67.49; dutch test set: =1 =56.43) tsukamoto, mitsuishi and sassano (2002) used stacked ada boost classier for ndingnamed entities.
</nextsent>
<nextsent>they found that cascading classi ers helped improved performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2835">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>they found that thetransformation-based method consistently outperformed the decision trees (spanish test set: =1 =67.49; dutch test set: =1 =56.43) tsukamoto, mitsuishi and sassano (2002) used stacked ada boost classier for ndingnamed entities.
</prevsent>
<prevsent>they found that cascading classi ers helped improved performance.
</prevsent>
</prevsection>
<citsent citstr=" W02-2019 ">
their nal system consisted of cascade of ve learners each of which performed 10,000 boosting rounds (spanish test set: =1 =71.49; dutch test set: =1 =60.93) malouf (2002) <papid> W02-2019 </papid>tested dierent models with the shared task data: statistical baseline model, hidden markov model and maximum entropy models with dierent features.</citsent>
<aftsection>
<nextsent>the latter proved to perform best.
</nextsent>
<nextsent>the maximum entropy models bene ted from extra feature which encoded capitalization information, positional information and information about the current word being part of person name earlier inthe text.
</nextsent>
<nextsent>however, incorporating list of person names in the training process did not help (spanish test set: =1 =73.66; dutch test set: =1 =68.08) jansche (2002) <papid> W02-2013 </papid>employed rst-order markov model as named entity recognizer.</nextsent>
<nextsent>his system used two separate passes, one for extracting entity boundaries and one for classifying entities.he evaluated dierent features in both subpro cesses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2836">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the latter proved to perform best.
</prevsent>
<prevsent>the maximum entropy models bene ted from extra feature which encoded capitalization information, positional information and information about the current word being part of person name earlier inthe text.
</prevsent>
</prevsection>
<citsent citstr=" W02-2013 ">
however, incorporating list of person names in the training process did not help (spanish test set: =1 =73.66; dutch test set: =1 =68.08) jansche (2002) <papid> W02-2013 </papid>employed rst-order markov model as named entity recognizer.</citsent>
<aftsection>
<nextsent>his system used two separate passes, one for extracting entity boundaries and one for classifying entities.he evaluated dierent features in both subpro cesses.
</nextsent>
<nextsent>the categorization process was trained separately from the extraction process but thatdid not seem to have harmed overall performance (spanish test set: =1 =73.89; dutch test set: =1 =69.68) patrick, whitelaw and munro (2002) presentslinerc, language-independent named entity recognizer.
</nextsent>
<nextsent>the system uses tries as well as character n-grams for encoding word-internaland contextual information.
</nextsent>
<nextsent>additionally, it relies on lists of entities which have been compiled from the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2837">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>after this several smoothed word classes derived from the available data were incorporated into the training process.
</prevsent>
<prevsent>the system performed better with the derived word lists than with the external named entity lists (spanish test set: =1 =75.78; dutch test set: =1 =72.57).
</prevsent>
</prevsection>
<citsent citstr=" W02-2007 ">
cucerzan and yarowsky (2002) <papid> W02-2007 </papid>approached the shared task by using word-internal and contextual information stored in character-basedtries.</citsent>
<aftsection>
<nextsent>their system obtained good results by using part-of-speech tag information and employing the one sense per discourse principle.
</nextsent>
<nextsent>the authors expect performance increase when the system has access to external entity lists but have not presented the results of this in detail (spanish test set: =1 =77.15; dutch test set: =1 =72.31).
</nextsent>
<nextsent>wu, ngai, carpuat, larsen and yang (2002) have applied adaboost.mh to the shared task data and compared the performance with that of maximum entropy-based named entity tagger.
</nextsent>
<nextsent>their system used lexical and part-of-speech information, contextual and word-internal clues, capitalization information,knowledge about entity classes of previous occurrences of words and small external listof named entity words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2838">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the boosting techniques operated on decision stumps, decision trees of depth one.
</prevsent>
<prevsent>they outperformed the maximum entropy-based named entity tagger (spanish test set: =1 =76.61; dutch test set: =1 =75.36).
</prevsent>
</prevsection>
<citsent citstr=" W02-2010 ">
florian (2002) <papid> W02-2010 </papid>employed three stacked learners for named entity recognition:transformation-based learning for obtaining base-level non-typed named entities, snow for improving the quality of these entities and the forward-backward algorithm for nd ing categories for the named entities.</citsent>
<aftsection>
<nextsent>the combination of the three algorithms showed substantially improved performance when compared with single algorithm and an algorithm pair (spanish test set: =1 =79.05; dutch test set: =1 =74.99).carreras, marquez and padro (2002) have approached the shared task by using adaboostapplied to xed-depth decision trees.
</nextsent>
<nextsent>their system used many dierent input features contextual information, word-internal clues, previous entity classes, part-of-speech tags (dutch only)and external word lists (spanish only).
</nextsent>
<nextsent>it processed the data in two stages: rst entity recognition and then classi cation.
</nextsent>
<nextsent>their system obtained the best results in this shared task for both the spanish and dutch test datasets (spanish test set: =1 =81.39; dutch test set: =1 =77.05).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2839">
<title id=" W02-2024.xml">introduction to the conll2002 shared task language independent named entity recognition </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>we have described the conll-2002 shared task: language-independent named entity recognition.
</prevsent>
<prevsent>twelve dierent systems have been applied to data covering two western europeanlanguages: spanish and dutch.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
a boosted decision tree method obtained the best performance on both datasets (carreras et al, 2002).<papid> W02-2004 </papid></citsent>
<aftsection>
<nextsent>acknowledgements tjong kim sang is supported by iwt stww as researcher in the atranos project.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2840">
<title id=" W03-0313.xml">translation spotting for translation memories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows some examples of ts, where the words in italics represent the sl query, and the words in bold are the sl and tl answers.
</prevsent>
<prevsent>as can be seen in these examples, the tokens in the query and answers rq(s) and rq(t ) may or may not be contiguous (examples 2 and 3), and the tl answer may possibly be empty (example 4) when there is no satisfying way of linking tl tokens to the query.
</prevsent>
</prevsection>
<citsent citstr=" C96-1030 ">
translation spotting finds different applications, for example in bilingual concordancers, such as the trans search system (macklovitch et al, 2000), and example-based machine translation (brown, 1996).<papid> C96-1030 </papid></citsent>
<aftsection>
<nextsent>inthis article, we focus on different application: sub sentential translation memory.
</nextsent>
<nextsent>we describe this application context in section 2, and discuss how ts fits in to this type of system.
</nextsent>
<nextsent>we then propose in section 3 series ofts methods, specifically adapted to this application context.
</nextsent>
<nextsent>in section 4, we present an empirical evaluation of the proposed methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2841">
<title id=" W03-0313.xml">translation spotting for translation memories </title>
<section> ts methods.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned earlier, ts can be seen as bi-product of word-level alignments.
</prevsent>
<prevsent>such alignments have been the focus of much attention in recent years, especially in the field of statistical translation modeling, where they play an important role in the learning process.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for the purpose of statistical translation modeling, brown et al (1993) <papid> J93-2003 </papid>define an alignment as vector = a1...am that connects each word of source-languagetext = s1...sm to target-language word in its translation = t1...tn, with the interpretation that word taj is the translation of word sj in (aj = 0 is used to denote words of that do not produce anything in ).</citsent>
<aftsection>
<nextsent>brown et al also define the viterbi alignment between source and target sentences and as the alignment a?
</nextsent>
<nextsent>whose probability is maximal under some translation model: a?
</nextsent>
<nextsent>= argmaxaaprm(a|s, ) where is the set of all possible alignments between sand , and prm(a|s, ) is the estimate of as probability under model m, which we denote pr(a|s, ) from hereon.
</nextsent>
<nextsent>in general, the size of grows exponentially with the sizes of and , and so there is no efficient way of computing a?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2842">
<title id=" W03-0313.xml">translation spotting for translation memories </title>
<section> ts methods.  </section>
<citcontext>
<prevsection>
<prevsent>figure 4: contiguous ts example 3.4 compositional ts.
</prevsent>
<prevsent>as pointed out in section 3.3, in ibm-style alignments,a single tl token can be connected to several sl tokens, which sometimes leads to aberrations.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
this contrasts with alternative alignment models such as those of melamed (1998) and wu (1997), <papid> J97-3002 </papid>which impose one-to-one?</citsent>
<aftsection>
<nextsent>constraint on alignments.
</nextsent>
<nextsent>such constraint evokes the notion of compositionality in translation: it suggests that each sl token operates independently in the sl sentence to produce single tl token in the tl sentence, which then depends on no other sl token.
</nextsent>
<nextsent>this view is, of course, extreme, and real-life translations are full of examples (idiomatic expressions, terminology, paraphrasing, etc.) that show how this compositionality principle breaks down as we approach the level of word correspondences.
</nextsent>
<nextsent>however, in tm application, ts usually needs not godown to the level of individual words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2843">
<title id=" W03-0313.xml">translation spotting for translation memories </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we call this the hansard tm.
</prevsent>
<prevsent>to identify sl queries, distinct document from the hansard was used, the transcript from session held in march 2002.
</prevsent>
</prevsection>
<citsent citstr=" W00-0731 ">
the english version of this document was segmented into syntactic chunks, using an implementation of osbornes chunker (osborne, 2000).<papid> W00-0731 </papid></citsent>
<aftsection>
<nextsent>all sequences of chunks from this text that contained three or more word tokens were then looked up in the hansard tm.
</nextsent>
<nextsent>among the sequences that did match sentences in the tm, 100 were selected at random.
</nextsent>
<nextsent>these made up the test sl queries.
</nextsent>
<nextsent>recur sion level sl segment tl segment direction (d) 1 [let us see] [where the government commitment is really at in terms of the farm community]??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2844">
<title id=" W03-0313.xml">translation spotting for translation memories </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>considering that precision is possibly more important than recall in tm application, the contiguous ts would probably be good choice.
</prevsent>
<prevsent>the zero-tolerance strategy, used as filter on viterbialignments, turns out to be particularily effective.
</prevsent>
</prevsection>
<citsent citstr=" P01-1050 ">
it is interesting to note that this method is equivalent to the one proposed by marcu (marcu, 2001) <papid> P01-1050 </papid>to automatically construct sub-sentential translation memory.</citsent>
<aftsection>
<nextsent>taking only non-null tss into consideration, it out classes all other methods, regardless of the metric.
</nextsent>
<nextsent>but this is at the cost of eliminating numerous potentially useful tl answers(more than 70%).
</nextsent>
<nextsent>this is particularily frustrating, considering that over 90% of all tl answers in the reference are indeed contiguous.
</nextsent>
<nextsent>to understand how this happens, one must go back to the definition of ibm-style alignments, which specifies that each sl token is linked to at most one tl token.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2846">
<title id=" W03-0313.xml">translation spotting for translation memories </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>computing word alignments with ibm model 2 is straightforward and efficient, which made it good choice forex perimenting; however, this model is certainly not the state of the art in statistical translation modeling.
</prevsent>
<prevsent>then again, the methods proposed here were all based on the idea of finding the most likely word-alignment under variousconstraints.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
this approach is not dependent on the underlying translation model, and similar methods could certainly be devised based on more elaborate models, such as ibm models 35, or the hmm-based models proposed by och et al (1999) <papid> W99-0604 </papid>for example.</citsent>
<aftsection>
<nextsent>alternatively, there are other ways to compensate for model 2s weaknesses.
</nextsent>
<nextsent>each ibm-style alignment between two segments of text denotes one particular explanation of how the tl words emerged from the sl words,but it doesnt tell the whole story.
</nextsent>
<nextsent>basing our ts methods on set of likely alignments rather than on the single most-likely alignment, as is normally done to estimate the parameters of higher-level models, could possibly lead to more accurate ts results.
</nextsent>
<nextsent>similarly, ts applications arenot bound to translation directionality as statistical translation systems are; this means that we could also make use of reverse?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2847">
<title id=" W02-1510.xml">a development environment for largescale multilingual parsing systems </title>
<section> process of grammar development.  </section>
<citcontext>
<prevsection>
<prevsent>one possibility, which is currently pursued in our group, is to develop metric that enables comparison with manually created golden standards, as they have become more widely available for various languages, such as the penn treebank for chinese and english, negra corpus for german, and kyoto corpus for japanese.
</prevsent>
<prevsent>ultimately, the parser output must be compared and evaluated at the level of an application that uses the result of linguistic analysis.
</prevsent>
</prevsection>
<citsent citstr=" W02-1504 ">
campbell et al (2002) <papid> W02-1504 </papid>is an attempt to use machine translation as test bed for multi-lingual parsing system.</citsent>
<aftsection>
<nextsent>parser development for development of truly broad-coverage parser, it is critical that grammar changes are constantly verified against very large set of sentences, and that the time for feedback is minimal.
</nextsent>
<nextsent>the efficiency of the parsing engine is thus inseparable from efficient grammar development.
</nextsent>
<nextsent>our parsing engine is already quite fast: for example, our english system currently parses section 21 of penn wall street journal (wsj) treebank (1,671 sentences) in 110 seconds (or about 15 sentences/sec) on standard machine (993mhz pentium iii with 512mb ram); this performance is comparable across languages.
</nextsent>
<nextsent>speed improvements are usually performed by non-linguistic developers following standard optimization techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2848">
<title id=" W02-1506.xml">adapting existing grammars the xle experience </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J93-4001 ">
we report on the xle parser and grammar development platform (maxwell and kaplan, 1993) <papid> J93-4001 </papid>and describe how basic lexical functional grammar for english has been adapted to two different corpora (newspaper text and copier repair tips).</citsent>
<aftsection>
<nextsent>large-scale grammar development platforms should be able to be used to develop grammars for wide variety of purposes.
</nextsent>
<nextsent>in this paper, we report on the the xle system (maxwell and kaplan, 1993), <papid> J93-4001 </papid>aparser and grammar development platform for lexical functional grammars.</nextsent>
<nextsent>we describe some of the strategies and notational devices that enable the basic english grammar developed for the pargram project (butt et al, 1999; butt et al, 2002) <papid> W02-1503 </papid>to be adapted to two corpora with different properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2850">
<title id=" W02-1506.xml">adapting existing grammars the xle experience </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>large-scale grammar development platforms should be able to be used to develop grammars for wide variety of purposes.
</prevsent>
<prevsent>in this paper, we report on the the xle system (maxwell and kaplan, 1993), <papid> J93-4001 </papid>aparser and grammar development platform for lexical functional grammars.</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
we describe some of the strategies and notational devices that enable the basic english grammar developed for the pargram project (butt et al, 1999; butt et al, 2002) <papid> W02-1503 </papid>to be adapted to two corpora with different properties.</citsent>
<aftsection>
<nextsent>1.1 the corpora.
</nextsent>
<nextsent>the standard pargram english grammar covers the core phenomena of english (e.g., main and subordinate clauses, noun phrases, adjectives and ad verbs, prepositional phrases, coordination; see (butt et al, 1999)).
</nextsent>
<nextsent>we have built two different specialized grammars on top of this: the eureka grammar and the wsj grammar.the eureka grammar parses the eureka corpus of copier repair tips, collection of documents offering suggestions for how to diagnose and fix particular copier malfunctions.
</nextsent>
<nextsent>these informal and unedited documents were contributed by copier repair technicians, and the corpus is characterized by significant amount of ungrammatical input (e.g., typos, incorrect punctuation, telegraphic sentences) and much technical terminology (1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2851">
<title id=" W02-1506.xml">adapting existing grammars the xle experience </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(solution 27240 80) 4.
</prevsent>
<prevsent>enter into the machine log, the changes that have been made.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
the wsj grammar covers the upenn wall street journal (wsj) treebank sentences (marcus et al,1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>this corpus is characterized by long sentences with many direct quotes and proper names,(2a).
</nextsent>
<nextsent>in addition, for evaluation and training purposes we also parsed version of this corpus marked up with labeled brackets and part-of-speech tags, asin (2b).
</nextsent>
<nextsent>riezler et al (2002) <papid> P02-1035 </papid>report on our wsj parsing experiments.</nextsent>
<nextsent>(2) a. but since 1981, kirk horse insurance inc. of lexington, ky. has grabbed 20% stake of the market.b. but since 1981, [np-sbj kirk horse insurance inc. of lexington, ky.] has/vbzgrabbed/vbn [np 20% stake of the mar ket].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2852">
<title id=" W02-1506.xml">adapting existing grammars the xle experience </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this corpus is characterized by long sentences with many direct quotes and proper names,(2a).
</prevsent>
<prevsent>in addition, for evaluation and training purposes we also parsed version of this corpus marked up with labeled brackets and part-of-speech tags, asin (2b).
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
riezler et al (2002) <papid> P02-1035 </papid>report on our wsj parsing experiments.</citsent>
<aftsection>
<nextsent>(2) a. but since 1981, kirk horse insurance inc. of lexington, ky. has grabbed 20% stake of the market.b. but since 1981, [np-sbj kirk horse insurance inc. of lexington, ky.] has/vbzgrabbed/vbn [np 20% stake of the mar ket].
</nextsent>
<nextsent>the xle system is designed so that the grammar writer can build specialized grammars by both extending and restricting another grammar (in our casethe base grammar is the standard pargram english grammar).
</nextsent>
<nextsent>an lfg grammar is presented to the xle system in priority-ordered sequence offiles containing phrase-structure rules, lexical entries, abbreviatory macros and templates, feature declarations, and finite-state transducers for tokenization and morphological analysis.
</nextsent>
<nextsent>xle is applied to single root file holding configuration that identifies all the other files containing relevant linguistic specifications, that indicates how those components are to be assembled into complete grammar, and that specifies certain parameters that control how that grammar is to be interpreted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2853">
<title id=" W02-1506.xml">adapting existing grammars the xle experience </title>
<section> tokenizing and morphological analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the tokenizing transducer must recognize this pattern and split the tagsoff as separate tokens.
</prevsent>
<prevsent>the tag-tokens must be available to filter the output of the morphological analyzer so that only verbal forms are compatible with the tags in this example and the adjectival reading of shaken is therefore blocked.
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
xle tokenizing transducers are compiled from specifications expressed in the sophisticated xerox finite state calculus (beesley and karttunen, 2002).the xerox calculus includes the composition, ignore, and substitution operator discussed by kaplan and kay (1994) <papid> J94-3001 </papid>and the priority-union operator of kaplan and newman (1997).</citsent>
<aftsection>
<nextsent>the specialized tok enizers are constructed by using these operators to combine the standard specification with expressions that extend or restrict the standard behavior.
</nextsent>
<nextsent>for example, the ignore operator is applied to allow the part-of-speech information to be passed through to the morphology without interrupting the standard patterns of english punctuation.xle also allows separately compiled transducers to be combined at run-time by the operations of priority-union, composition, and union.
</nextsent>
<nextsent>priority union was used to supplement the standard morphology with specialized guessing?
</nextsent>
<nextsent>transducers that apply only to tokens that would otherwise be unrecognized.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2854">
<title id=" W03-0432.xml">named entity recognition using a character based probabilistic approach </title>
<section> probabilistic classification using.  </section>
<citcontext>
<prevsection>
<prevsent>an in each word category.
</prevsent>
<prevsent>these frequencies can be used to calculate probability estimatesp (c | a1a2 . . .
</prevsent>
</prevsection>
<citsent citstr=" W02-2022 ">
an) for each category c. tries have previously been used in both supervised (patrick et al, 2002) <papid> W02-2022 </papid>and unsupervised (cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>named entity recognition.each node in an orthographic trie stores the cumulative frequency information for each category in which given string of characters occurs.</citsent>
<aftsection>
<nextsent>a heterogeneous node represents string that occurs in more than one category, while homogeneous node represents string that occurs in only one category.
</nextsent>
<nextsent>if string a1a2 . . .
</nextsent>
<nextsent>an occurs in only one category, all longer strings a1a2 . . .
</nextsent>
<nextsent>an . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2855">
<title id=" W03-0432.xml">named entity recognition using a character based probabilistic approach </title>
<section> probabilistic classification using.  </section>
<citcontext>
<prevsection>
<prevsent>an in each word category.
</prevsent>
<prevsent>these frequencies can be used to calculate probability estimatesp (c | a1a2 . . .
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
an) for each category c. tries have previously been used in both supervised (patrick et al, 2002) <papid> W02-2022 </papid>and unsupervised (cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>named entity recognition.each node in an orthographic trie stores the cumulative frequency information for each category in which given string of characters occurs.</citsent>
<aftsection>
<nextsent>a heterogeneous node represents string that occurs in more than one category, while homogeneous node represents string that occurs in only one category.
</nextsent>
<nextsent>if string a1a2 . . .
</nextsent>
<nextsent>an occurs in only one category, all longer strings a1a2 . . .
</nextsent>
<nextsent>an . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2856">
<title id=" W03-0432.xml">named entity recognition using a character based probabilistic approach </title>
<section> restoring case information.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, some sentences such as newspaper headlines are written in all capitals for emphasis.
</prevsent>
<prevsent>in these environments, the case information that has traditionally been so useful toner systems is lost.previous work inner has been aware of this problem of dealing with words without accurate case information, and various work arounds have been exploited.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
most commonly, feature-based classifiers use set of capitalisation features and sentence-initial feature (bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>chieu and ng used global information such as the occurrence of the same word with other capitalisation in the same document (chieu and ng, 2002<papid> P02-1061 </papid>a), and have also used mixed-case classifier to teach weaker?</nextsent>
<nextsent>classifier that did not use case information at all (chieu and ng, 2002<papid> P02-1061 </papid>b).we propose different solution to the problem of case less words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2857">
<title id=" W03-0432.xml">named entity recognition using a character based probabilistic approach </title>
<section> restoring case information.  </section>
<citcontext>
<prevsection>
<prevsent>in these environments, the case information that has traditionally been so useful toner systems is lost.previous work inner has been aware of this problem of dealing with words without accurate case information, and various work arounds have been exploited.
</prevsent>
<prevsent>most commonly, feature-based classifiers use set of capitalisation features and sentence-initial feature (bikel et al, 1997).<papid> A97-1029 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1061 ">
chieu and ng used global information such as the occurrence of the same word with other capitalisation in the same document (chieu and ng, 2002<papid> P02-1061 </papid>a), and have also used mixed-case classifier to teach weaker?</citsent>
<aftsection>
<nextsent>classifier that did not use case information at all (chieu and ng, 2002<papid> P02-1061 </papid>b).we propose different solution to the problem of case less words.</nextsent>
<nextsent>rather than noting their lack of case and treating them separately, we propose to restore the correct capitalisation as preprocessing step, allowing all words to be treated in the same manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2865">
<title id=" W03-1509.xml">chinese named entity recognition combining statistical model wih human knowledge </title>
<section> backgroud.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 is the evaluation and section 6 is the conclusion.
</prevsent>
<prevsent>the researches on english ner have made impressive achievement.
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
the best ner system [mikheev, et al 1999] <papid> E99-1001 </papid>in muc7 achieved 95% precision and 92% recall.</citsent>
<aftsection>
<nextsent>recent methods for english ner focus on machine-learning algorithms such as dl-cotrain, coboost [collins and singer 1999], <papid> W99-0613 </papid>hmm [daniel m. bikel 1997], maximum entropy model [borthwick, et al 1999] and so on.</nextsent>
<nextsent>however, chinese ner is still at its immature phase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2866">
<title id=" W03-1509.xml">chinese named entity recognition combining statistical model wih human knowledge </title>
<section> backgroud.  </section>
<citcontext>
<prevsection>
<prevsent>the researches on english ner have made impressive achievement.
</prevsent>
<prevsent>the best ner system [mikheev, et al 1999] <papid> E99-1001 </papid>in muc7 achieved 95% precision and 92% recall.</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
recent methods for english ner focus on machine-learning algorithms such as dl-cotrain, coboost [collins and singer 1999], <papid> W99-0613 </papid>hmm [daniel m. bikel 1997], maximum entropy model [borthwick, et al 1999] and so on.</citsent>
<aftsection>
<nextsent>however, chinese ner is still at its immature phase.
</nextsent>
<nextsent>typical chinese ner systems are as follows.
</nextsent>
<nextsent>ntu system [hsin-his chen, et al 1997] relied on statistical model when recognizing person names, but rules when recognizing location and organization names.
</nextsent>
<nextsent>in the formal run of met-2, the total f-measure is 79.61%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2867">
<title id=" W03-1509.xml">chinese named entity recognition combining statistical model wih human knowledge </title>
<section> backgroud.  </section>
<citcontext>
<prevsection>
<prevsent>in the formal run of met-2, the total f-measure is 79.61%.
</prevsent>
<prevsent>as result, they may miss the person names whose probability is lower than the threshold, the location and organization names may also be missed for those which dont accord with the rules.
</prevsent>
</prevsection>
<citsent citstr=" M98-1016 ">
[yu et al 1998] <papid> M98-1016 </papid>uses both contextual model and morphological model.</citsent>
<aftsection>
<nextsent>however, their system requires information of pos tags, semantic tags and ne lists.
</nextsent>
<nextsent>the system obtains 86.38% measure.
</nextsent>
<nextsent>[chua et al 2000] employs combination of template-based rules supplemented by the default exception trees and decision tree that obtains over 91% f-measure on met-2 test data.
</nextsent>
<nextsent>it also uses hownet [dong &amp; dong 2000] to cluster semantically related words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2868">
<title id=" W03-1021.xml">training connection ist models for the structured language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>statistical machine translation, language model is crucial component for searching in the often prohibitively large hypothesis space.
</prevsent>
<prevsent>most of thestate-of-the-art systems use n-gram language models, which are simple and effective most of thetime.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
many smoothing techniques that improve language model probability estimation have been proposed and studied in the n-gram literature (chen and goodman, 1998).recent efforts have studied various ways of using information from longer context span than that usually captured by normal n-gram language models, as well as ways of using syntactical information that is not available to the word-based n-gram models (chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001; uystel et al, 2001).</citsent>
<aftsection>
<nextsent>all these language models are based on stochastic parsing techniques that build up parse trees for the input word sequence and condition the generation of words on syntactical and lexical information available in the parse trees.since these language models capture useful hierarchical characteristics of language, they can improve the ppl significantly for various tasks.
</nextsent>
<nextsent>although more improvement can be achieved by enriching the syntactical dependencies in the structured language model (slm) (xu et al, 2002), <papid> P02-1025 </papid>severe data sparseness problem was observed in (xu et al, 2002) <papid> P02-1025 </papid>when the number of conditioning features was increased.there has been recent promising work in using distributional representation of words and neural networks for language modeling (bengio et al,2001) and parsing (henderson, 2003).<papid> E03-1002 </papid></nextsent>
<nextsent>one great advantage of this approach is its ability to fight data sparseness.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2869">
<title id=" W03-1021.xml">training connection ist models for the structured language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many smoothing techniques that improve language model probability estimation have been proposed and studied in the n-gram literature (chen and goodman, 1998).recent efforts have studied various ways of using information from longer context span than that usually captured by normal n-gram language models, as well as ways of using syntactical information that is not available to the word-based n-gram models (chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001; uystel et al, 2001).</prevsent>
<prevsent>all these language models are based on stochastic parsing techniques that build up parse trees for the input word sequence and condition the generation of words on syntactical and lexical information available in the parse trees.since these language models capture useful hierarchical characteristics of language, they can improve the ppl significantly for various tasks.</prevsent>
</prevsection>
<citsent citstr=" P02-1025 ">
although more improvement can be achieved by enriching the syntactical dependencies in the structured language model (slm) (xu et al, 2002), <papid> P02-1025 </papid>severe data sparseness problem was observed in (xu et al, 2002) <papid> P02-1025 </papid>when the number of conditioning features was increased.there has been recent promising work in using distributional representation of words and neural networks for language modeling (bengio et al,2001) and parsing (henderson, 2003).<papid> E03-1002 </papid></citsent>
<aftsection>
<nextsent>one great advantage of this approach is its ability to fight data sparseness.
</nextsent>
<nextsent>the model size grows only sub-linearly with the number of predicting features used.
</nextsent>
<nextsent>it has been shown that this method improves significantly on regular n-gram models in perplexity (bengio etal., 2001).
</nextsent>
<nextsent>the ability of the method to accommodate longer contexts is most appealing, since experiments have shown consistent improvements in ppl when the context of one of the components of the slm is increased in length (emami et al, 2003).moreover, because the slm provides an em training procedure for its components, the connection ist models can also be improved by the em training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2872">
<title id=" W03-1021.xml">training connection ist models for the structured language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many smoothing techniques that improve language model probability estimation have been proposed and studied in the n-gram literature (chen and goodman, 1998).recent efforts have studied various ways of using information from longer context span than that usually captured by normal n-gram language models, as well as ways of using syntactical information that is not available to the word-based n-gram models (chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>roark, 2001; uystel et al, 2001).</prevsent>
<prevsent>all these language models are based on stochastic parsing techniques that build up parse trees for the input word sequence and condition the generation of words on syntactical and lexical information available in the parse trees.since these language models capture useful hierarchical characteristics of language, they can improve the ppl significantly for various tasks.</prevsent>
</prevsection>
<citsent citstr=" E03-1002 ">
although more improvement can be achieved by enriching the syntactical dependencies in the structured language model (slm) (xu et al, 2002), <papid> P02-1025 </papid>severe data sparseness problem was observed in (xu et al, 2002) <papid> P02-1025 </papid>when the number of conditioning features was increased.there has been recent promising work in using distributional representation of words and neural networks for language modeling (bengio et al,2001) and parsing (henderson, 2003).<papid> E03-1002 </papid></citsent>
<aftsection>
<nextsent>one great advantage of this approach is its ability to fight data sparseness.
</nextsent>
<nextsent>the model size grows only sub-linearly with the number of predicting features used.
</nextsent>
<nextsent>it has been shown that this method improves significantly on regular n-gram models in perplexity (bengio etal., 2001).
</nextsent>
<nextsent>the ability of the method to accommodate longer contexts is most appealing, since experiments have shown consistent improvements in ppl when the context of one of the components of the slm is increased in length (emami et al, 2003).moreover, because the slm provides an em training procedure for its components, the connection ist models can also be improved by the em training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2873">
<title id=" W03-1021.xml">training connection ist models for the structured language model </title>
<section> a probabilistic neural network model </section>
<citcontext>
<prevsection>
<prevsent>the function we try to maximize is the log-likelihood of the training data given by equation 1.
</prevsent>
<prevsent>it is straightforward to compute the gradient of the likelihood function for the feature vectors and the neural network parameters, and hence compute their updates.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we should note from equation 4 that the neural network model is similar in functional form to the maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>except that the neural network learns the feature functions by itself from the training data.</citsent>
<aftsection>
<nextsent>however,unlike the g/iis algorithm for the maximum entropy model, the training algorithm (usually stochastic gradient descent) for the neural network models is not guaranteed to find even local maximum of the objective function.
</nextsent>
<nextsent>it is very important to mention that one of the great advantages of this model is that the number of inputs can be increased causing only sub-linearincrease in the number of model parameters, as opposed to exponential growth in n-gram models.
</nextsent>
<nextsent>this makes the parameter estimation more robust, especially when the input span is long.
</nextsent>
<nextsent>an extensive presentation of the slm can be found in (chelba and jelinek, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2877">
<title id=" W02-1407.xml">a simple but powerful automatic term extraction method </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to extract compound nouns which are promising term candidates and at the same time to exclude undesirable strings such as is a?
</prevsent>
<prevsent>or of the?, the frequently used method is to filter out the words that are members of stop-word-list.
</prevsent>
</prevsection>
<citsent citstr=" C96-1009 ">
more complex structures like noun phrases, collocations and so on, become focused on (frantzi and ananiadou 1996).<papid> C96-1009 </papid></citsent>
<aftsection>
<nextsent>all of these are good term candidates in corpus of specific domain because all of them have strong unithood (kageura&umino96;) which refers to the degree of strength or stability of syntagmatic combinations or collocations.
</nextsent>
<nextsent>we assume the following about compound nouns or collocations: assumption terms having complex structure e be made of xisting simple terms o the structure of complex terms is another important factor for automatic term candidates extraction.
</nextsent>
<nextsent>it is expressed syntactically or semantically.
</nextsent>
<nextsent>as syntactic structure, dependency structures that are the results of parsing are focused on in many works.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2883">
<title id=" W02-1613.xml">automatic information transfer between english and chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bayesian disambiguation from the above formal description we can see that the key to the stochastic word translation is to select proper context and context features vj.
</prevsent>
<prevsent>present methods often define word window of some size, i.e. to suppose only words within the window contributes to the translation choice of the ambiguous word.
</prevsent>
</prevsection>
<citsent citstr=" W97-0323 ">
for example, [huang 1997] <papid> W97-0323 </papid>uses word window of length 6 words for word sense disambiguation; [xun 1998] define moveable window of length 4 words; [ng 1997] <papid> W97-0323 </papid>uses word window with offset 2.</citsent>
<aftsection>
<nextsent>but two problems exist for this method: (1) some words that are informative to sense disambiguation may not be covered by the window; (2) some words that are covered by the word window really contribute nothing to the sense choice, but only bring noise information.
</nextsent>
<nextsent>after broad investigation for large-scale ambiguous words, we choose the context according to the correlation of the context words with the ambiguous word, but not only the distance from the word.
</nextsent>
<nextsent>from the above analysis, we choose the translation choice method based on syntactic analysis.
</nextsent>
<nextsent>place the module of translation choice between the parser and the generator; acquire context set for the ambiguous word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2887">
<title id=" W03-0104.xml">geoname a system for backtransliterating pinyin place names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is evidence that this system is gaining popularity in the u.s. as the default choice (library of congress 2000).
</prevsent>
<prevsent>this paper investigates methods of recovering chinese place name in gb-encoding (the character codes used for simplified chinese characters) when its english pinyin is given.
</prevsent>
</prevsection>
<citsent citstr=" W02-1809 ">
we have previously built system pyname (kwok and deng 2002) <papid> W02-1809 </papid>to back-transliterate chinese person names.</citsent>
<aftsection>
<nextsent>this paper extends it to provide similar functionality for place names.
</nextsent>
<nextsent>it is tool to help reduce ambiguity in cross language geographic entity reference, and would be useful for cross language information retrieval.
</nextsent>
<nextsent>the organization of this paper is as follows: section 2 discusses some properties of pinyin place names.
</nextsent>
<nextsent>section 3 discusses the use of frequencies to help back-transliteration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2888">
<title id=" W03-0104.xml">geoname a system for backtransliterating pinyin place names </title>
<section> mapping pinyin to chinese character.  </section>
<citcontext>
<prevsection>
<prevsent>this is very useful, like style one or two.
</prevsent>
<prevsent>unfortunately, none of these is mandatory.
</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
back-transliteration is difficult problem as exemplified in (knight and graehl 1997, <papid> P97-1017 </papid>chen, et.al. 1998).<papid> P98-1036 </papid></citsent>
<aftsection>
<nextsent>we limit ourselves to text input of place name.
</nextsent>
<nextsent>let = e1 e2 e3 ..
</nextsent>
<nextsent>en be given english place name with pinyin syllables ek, 1 =k =n. it may have originated from chinese character sequence = c1 c2 c3..
</nextsent>
<nextsent>cn with probability: p(c|e) = p(e|c)*p(c)/p(e).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2889">
<title id=" W03-0104.xml">geoname a system for backtransliterating pinyin place names </title>
<section> mapping pinyin to chinese character.  </section>
<citcontext>
<prevsection>
<prevsent>this is very useful, like style one or two.
</prevsent>
<prevsent>unfortunately, none of these is mandatory.
</prevsent>
</prevsection>
<citsent citstr=" P98-1036 ">
back-transliteration is difficult problem as exemplified in (knight and graehl 1997, <papid> P97-1017 </papid>chen, et.al. 1998).<papid> P98-1036 </papid></citsent>
<aftsection>
<nextsent>we limit ourselves to text input of place name.
</nextsent>
<nextsent>let = e1 e2 e3 ..
</nextsent>
<nextsent>en be given english place name with pinyin syllables ek, 1 =k =n. it may have originated from chinese character sequence = c1 c2 c3..
</nextsent>
<nextsent>cn with probability: p(c|e) = p(e|c)*p(c)/p(e).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2890">
<title id=" W03-1302.xml">unsupervised monolingual and bilingual word sense disambiguation of medical documents using umls </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even short ofthe task of full translation, wsd is crucial to applications such as cross-lingual information retrieval (clir), since search terms entered in the language used for querying must be appropriately rendered in the language used for retrieval.
</prevsent>
<prevsent>wsd has become awell-established sub field of natural language processing with its own evaluation standards and senseval competitions (kilgarriff and rosenzweig, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
methods for wsd can effectively be divided into those that require manually annotated training data(supervised methods) and those that do not (unsupervised methods) (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>in general, supervised methods are less scalable than unsupervised methods because they relyon training data which may be costly and unrealistic to produce, andeven then might be available for only few ambiguous terms.
</nextsent>
<nextsent>the goal of our work on disambiguation in the much more project is to enable the correct semantic annotation of entire document collections with all terms which are potentially relevant for organisation, retrieval and summarisation of information.
</nextsent>
<nextsent>therefore decision was taken early on in the project that we should focus on unsupervised methods, which have the potential to be scaled up enough to meet our needs.
</nextsent>
<nextsent>this paper is arranged as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2891">
<title id=" W03-1302.xml">unsupervised monolingual and bilingual word sense disambiguation of medical documents using umls </title>
<section> bilingual disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>for example, if in aparticular context the english word drugs is translated into french as drogues rather than medicaments, then the english word drug is being usedto mean narcotics rather than medicines.
</prevsent>
<prevsent>this observation has been used for some years on varyingscales.
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
brown et al (1991) <papid> P91-1034 </papid>pioneered the use of statistical wsd for translation, building translation model from one million sentences in english and french.</citsent>
<aftsection>
<nextsent>using this model to help with translation decisions (such as whether prendre should be translated as take or make), the number of acceptable translations produced by their system increased by 8%.
</nextsent>
<nextsent>gale et al (1992) use parallel translations to obtain training and testing data for word-sense disambiguation.
</nextsent>
<nextsent>ide (1999) <papid> W99-0508 </papid>investigates the information made available by translation of george orwells nineteen eighty-four into six languages, using thisto analyse the related senses of nine ambiguous english words into hierarchical clusters.</nextsent>
<nextsent>these applications have all been case studies of handful of particularly interesting words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2892">
<title id=" W03-1302.xml">unsupervised monolingual and bilingual word sense disambiguation of medical documents using umls </title>
<section> bilingual disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>using this model to help with translation decisions (such as whether prendre should be translated as take or make), the number of acceptable translations produced by their system increased by 8%.
</prevsent>
<prevsent>gale et al (1992) use parallel translations to obtain training and testing data for word-sense disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" W99-0508 ">
ide (1999) <papid> W99-0508 </papid>investigates the information made available by translation of george orwells nineteen eighty-four into six languages, using thisto analyse the related senses of nine ambiguous english words into hierarchical clusters.</citsent>
<aftsection>
<nextsent>these applications have all been case studies of handful of particularly interesting words.
</nextsent>
<nextsent>the large scale of the semantic annotation carried out by the much more project has made it possible to extend the bilingual disambiguation technique to entire dictionaries and corpora.
</nextsent>
<nextsent>to disambiguate an instance of an ambiguous term, we consulted the translation of the abstract in which it appeared.
</nextsent>
<nextsent>we regarded the translated abstract as disambiguating the ambiguous term if it met the following two criteria: ? only one of the cuis was assigned to any term in the translated abstract.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2893">
<title id=" W03-1302.xml">unsupervised monolingual and bilingual word sense disambiguation of medical documents using umls </title>
<section> collocational disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>(for the purposes of this paper we only consider contiguous multiword expressions which are listed in umls.)
</prevsent>
<prevsent>there is astrong and well-known tendency for words to express only one sense in given collocation.
</prevsent>
</prevsection>
<citsent citstr=" H93-1052 ">
this property of words was first described and quantified by yarowsky (1993), <papid> H93-1052 </papid>and has become known generally as the one sense per collocation?</citsent>
<aftsection>
<nextsent>property.
</nextsent>
<nextsent>yarowsky (1995) <papid> P95-1026 </papid>used the one sense per collocation property as an essential ingredient for an unsupervised word-sense disambiguation algorithm.</nextsent>
<nextsent>forex ample, the collocations plant life and manufacturing plant are used as seed-examples?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2894">
<title id=" W03-1302.xml">unsupervised monolingual and bilingual word sense disambiguation of medical documents using umls </title>
<section> collocational disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>this property of words was first described and quantified by yarowsky (1993), <papid> H93-1052 </papid>and has become known generally as the one sense per collocation?</prevsent>
<prevsent>property.</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
yarowsky (1995) <papid> P95-1026 </papid>used the one sense per collocation property as an essential ingredient for an unsupervised word-sense disambiguation algorithm.</citsent>
<aftsection>
<nextsent>forex ample, the collocations plant life and manufacturing plant are used as seed-examples?
</nextsent>
<nextsent>for the living thing and building senses of plant, and these examples canthen be used as high-precision training data to perform more general high-recall disambiguation.
</nextsent>
<nextsent>while yarowskys algorithm is unsupervised (thealgorithm does not need large collection of annotated training examples), it still needs direct human intervention to recognise which ambiguous terms are amenable to this technique, and to choose appropriate seed-collocations?
</nextsent>
<nextsent>for each sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2895">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that terminological databases are obvious resources that should be used to boost the performance of statistical engine.
</prevsent>
<prevsent>we propose and evaluate way of integrating terminology into smt engine which yields significant reduction in word error rate.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
smt mainly became known to the linguistic community as result of the seminal work ofbrown et al (1993<papid> J93-2003 </papid>b).</citsent>
<aftsection>
<nextsent>since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem.
</nextsent>
<nextsent>for instance, vogel et al (1996) <papid> C96-2141 </papid>succeeded in overcoming the independence assumption made by ibm models by introducing order-1 hidden markov alignment models.</nextsent>
<nextsent>och et al (1999) <papid> W99-0604 </papid>described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and nieen and ney (2001) did the same for morphological information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2897">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>smt mainly became known to the linguistic community as result of the seminal work ofbrown et al (1993<papid> J93-2003 </papid>b).</prevsent>
<prevsent>since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
for instance, vogel et al (1996) <papid> C96-2141 </papid>succeeded in overcoming the independence assumption made by ibm models by introducing order-1 hidden markov alignment models.</citsent>
<aftsection>
<nextsent>och et al (1999) <papid> W99-0604 </papid>described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and nieen and ney (2001) did the same for morphological information.</nextsent>
<nextsent>radically different statistical models have also been proposed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2898">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem.
</prevsent>
<prevsent>for instance, vogel et al (1996) <papid> C96-2141 </papid>succeeded in overcoming the independence assumption made by ibm models by introducing order-1 hidden markov alignment models.</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
och et al (1999) <papid> W99-0604 </papid>described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and nieen and ney (2001) did the same for morphological information.</citsent>
<aftsection>
<nextsent>radically different statistical models have also been proposed.
</nextsent>
<nextsent>(foster, 2000) <papid> P00-1006 </papid>investigated maximum entropy models as an alternative tothe so-called noisy-channel approach.</nextsent>
<nextsent>very recently, yamada and knight (2001) <papid> P01-1067 </papid>described model in which the noisy-channel takes as input parsed sentence rather than simple words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2899">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>och et al (1999) <papid> W99-0604 </papid>described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and nieen and ney (2001) did the same for morphological information.</prevsent>
<prevsent>radically different statistical models have also been proposed.</prevsent>
</prevsection>
<citsent citstr=" P00-1006 ">
(foster, 2000) <papid> P00-1006 </papid>investigated maximum entropy models as an alternative tothe so-called noisy-channel approach.</citsent>
<aftsection>
<nextsent>very recently, yamada and knight (2001) <papid> P01-1067 </papid>described model in which the noisy-channel takes as input parsed sentence rather than simple words.</nextsent>
<nextsent>while many of these studies include intensive evaluation sections, it is not always easy to determine exactly how well statistical translation can do on given task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2900">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>radically different statistical models have also been proposed.
</prevsent>
<prevsent>(foster, 2000) <papid> P00-1006 </papid>investigated maximum entropy models as an alternative tothe so-called noisy-channel approach.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
very recently, yamada and knight (2001) <papid> P01-1067 </papid>described model in which the noisy-channel takes as input parsed sentence rather than simple words.</citsent>
<aftsection>
<nextsent>while many of these studies include intensive evaluation sections, it is not always easy to determine exactly how well statistical translation can do on given task.
</nextsent>
<nextsent>we know that on specific task of spoken language translation, wang (1998) provided evidence that smt compared favorably to symbolic translation system; but as mentioned by the author, the comparison was not totally fair.
</nextsent>
<nextsent>we do not know of any studies that describe extensive experiments evaluating the adequacy of smt in real translation environment.
</nextsent>
<nextsent>we prefer not to commit ourselves to defining what real translation task is; instead, we adopt the conservative point of view that viable translation engine (statistical or not) is one that copes with texts that may be very different in nature from those used to train it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2906">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> our statistical engine.  </section>
<citcontext>
<prevsection>
<prevsent>an hypothesis is fully determined by four parameters: its source (j) and target(i) positions of the last word (e), and its coverage (c).
</prevsent>
<prevsent>therefore, the search space can be represented as 4-dimension table, each item of which contains backtracking information (f for the fertility of e, bj and bw for the source position and the target word we should look at to backtrack) and the hypothesis score (prob).
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
we know that better alignment models have been proposed and extensively compared (och and ney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>we must however point out that the performance we obtained on the hansard corpus (see section 3) is comparable to the rates published elsewhere on the same kind of corpus.
</nextsent>
<nextsent>in any case, our goal in this study is to compare the behavior of smt engine in both friendly and adverse situations.
</nextsent>
<nextsent>in our view, the present smt engine is suitable for such comparative study.
</nextsent>
<nextsent>2.3 tuning the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2911">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this suggests the need to implementing an adaptative strategy.
</prevsent>
<prevsent>among the possible scenarios, we have shown that opening the engine to terminological resources is natural and efficient way of softening the decoder.
</prevsent>
</prevsection>
<citsent citstr=" P01-1050 ">
in similar vein, marcu (2001) <papid> P01-1050 </papid>investigate dhow to combine example based machine translation (ebmt) and smt approaches.</citsent>
<aftsection>
<nextsent>the author automatically derived from the hansard corpus what he calls translation memory: actually collection of pairs of source and target word sequences that are in translation relation according to the viterbi alignment run with an ibm4 model that was also trained on the hansard corpus.
</nextsent>
<nextsent>this collection of phrases was then merged with greedy statistical decoder to improve the overall performance of the system.
</nextsent>
<nextsent>what this study suggests is that translation memories collected from given corpus can im prove the performance of statistical engine trained on the same corpus, which in itself is an interesting result.
</nextsent>
<nextsent>a very similar study but with weaker results is derscribed in (langlais et al., 2000), <papid> A00-1019 </papid>in the framework of the transtypeproject.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2912">
<title id=" W02-1405.xml">improving a general purpose statistical translation engine by terminological lexicons </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this collection of phrases was then merged with greedy statistical decoder to improve the overall performance of the system.
</prevsent>
<prevsent>what this study suggests is that translation memories collected from given corpus can im prove the performance of statistical engine trained on the same corpus, which in itself is an interesting result.
</prevsent>
</prevsection>
<citsent citstr=" A00-1019 ">
a very similar study but with weaker results is derscribed in (langlais et al., 2000), <papid> A00-1019 </papid>in the framework of the transtypeproject.</citsent>
<aftsection>
<nextsent>besides the different metrics the authors used, the discrepancy in performance inthese two studies may be explained by the nature of the test corpora used.
</nextsent>
<nextsent>the test corpus in the latter study was more representative of real translation task, while the test corpus thatmarcu used was set of around 500 french sentences of no more than 10 words.
</nextsent>
<nextsent>our present study is close in spirit to these last two, except that we do not attack the problem of automatically acquiring bilingual lexicons; instead, we consider it part of the translators task to provide such lexicons.
</nextsent>
<nextsent>actually, we feel this may be one of the only ways user has of retaining some control over the engines output, fact that professional translators seem to appreciate (langlais et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2914">
<title id=" W02-1713.xml">xtragen  a natural language generation system using xml and java technologies </title>
<section> generation grammars.  </section>
<citcontext>
<prevsection>
<prevsent>this means that from our standpoint real-world applications hardly ever require full and complete linguistic coverage which is striven for by linguistically motivated generationsystems.
</prevsent>
<prevsent>therefore our formalism is based on extended templates that allow the inclusion of predefined and dynamically retrieved text, constraint based inflection and context-free selection mechanism.
</prevsent>
</prevsection>
<citsent citstr=" W96-0411 ">
the development of this formalism was strongly influenced by the ideas found in the (lisp based) formalism of the tg/2 system (busemann,1996; <papid> W96-0411 </papid>wein, 1996) and the yag system (chan narukul, 1999).</citsent>
<aftsection>
<nextsent>a template has the overall form as depicted in the backus-naur form in figure 2.1.
</nextsent>
<nextsent>each part of the template will be elaborated below.
</nextsent>
<nextsent>2.2 conditions.
</nextsent>
<nextsent>conditions describe the exact circumstances under which certain template can be applied and its actions executed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2915">
<title id=" W02-1713.xml">xtragen  a natural language generation system using xml and java technologies </title>
<section> generation grammars.  </section>
<citcontext>
<prevsection>
<prevsent>the treatment of morphology is naturally one ofthe major issues in the context of complete natural language generation especially when working with morphologically rich languages such as german, russian or finnish.
</prevsent>
<prevsent>therefore we took great care to design and develop morphological subsystem that is powerful and flexible yet easy to understand and use.
</prevsent>
</prevsection>
<citsent citstr=" P89-1002 ">
the actual realization of the component is based on constraint-based inheritance algorithm that follows the example of patr-ii (shieber et al, 1989).<papid> P89-1002 </papid></citsent>
<aftsection>
<nextsent>in the (overly simplified) example in figure 6 one can get glimpse on how the morphology works:there are two selection-actions, the first one labelled x0, the second one labelled x1.
</nextsent>
<nextsent>the given constraint now tells that the attribute number of x0 is the same as the attribute number of x1 and setsit dynamically to the value retrieved by the getter action.
</nextsent>
<nextsent> template ...   actions   select category= determiner  label= x0 /   select category= noun  label= x1 /   /actions   constraint   place label= x0  attribute= number /   place label= x1  attribute= number /   get path= /categorynumber /   /constraint   /template  figure 6: example of using constraints 2.6 compilation.
</nextsent>
<nextsent>in order to be able to work with generation grammar the generation engine requires the grammar(and its templates) to exist in the form of java object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2916">
<title id=" W02-1809.xml">corpus based pinyin name resolution </title>
<section> mapping pinyin name to chinese.  </section>
<citcontext>
<prevsection>
<prevsent>existence of such characters in this surname database is the first step to decide that one may have possible name sequence.
</prevsent>
<prevsent>otherwise, we assume the pinyin is not name.
</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
knight and graehl (1997) <papid> P97-1017 </papid>have proposed to compose set of weighted finite state transducers to solve the much more complicated problem of back-transliteration from japanese katakana to english.</citsent>
<aftsection>
<nextsent>their concern includes all types of source katakana terms (not just names), corruptions due to ocr, approximations due to modeling of english, japanese pronunciations, and language model for english.
</nextsent>
<nextsent>proposing chinese characters for pinyin is like back transliteration and can also be viewed probabilistically.
</nextsent>
<nextsent>some unique considerations however lead to much simpler problem.
</nextsent>
<nextsent>given an english pinyin name e=eseg (surname es, given name eg), our concern is to find the best chinese name character sequence c=cscg that maximizes p(c|e), or equivalently p(e|c)*p(c).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2917">
<title id=" W02-1809.xml">corpus based pinyin name resolution </title>
<section> experimental studies.  </section>
<citcontext>
<prevsection>
<prevsent>is rarely used in names.
</prevsent>
<prevsent>it was pulled out by high occurrence frequency in the target collection.
</prevsent>
</prevsection>
<citsent citstr=" W97-0315 ">
thompson &amp; dozier (1997) <papid> W97-0315 </papid>have also shown that correctly indexing names in monolingual english retrieval leads to better retrieval.</citsent>
<aftsection>
<nextsent>4.2 resolving pinyin names in text.
</nextsent>
<nextsent>in another experiment we intended to test our pinyin procedure with parallel collections that contain many paired names, but failed to locate one.
</nextsent>
<nextsent>we intend to evaluate how well our extraction procedure works, and whether candidate suggestion can recover correct chinese names.
</nextsent>
<nextsent>a pair of collections was downloaded from the peoples?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2918">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of systems participating in the past document understanding conference (duc, 2002) (a large scale summarization evaluation effort sponsored by the united states government), and the text summarization challenge (fukusima and okumura, 2001) (sponsored by japanese government) are extraction based.
</prevsent>
<prevsent>extraction-based automatic text summarization systems extract parts of original documents and output the results as summaries (chen et al, 2003; edmundson, 1969; goldstein et al, 1999; hovy and lin, 1999; kupiec et al, 1995; luhn, 1969).
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
other systems based on information extraction (mckeown et al, 2002; radev and mckeown, 1998; <papid> J98-3005 </papid>white et al, 2001) <papid> H01-1054 </papid>and discourse analysis (marcu, 1999; strzalkowski et al, 1999) also exist but they are not yet usable for general-domain summarization.</citsent>
<aftsection>
<nextsent>our study focuses on the effectiveness of applying sentence compression techniques to improve the performance of extraction-based automatic text summarization systems.
</nextsent>
<nextsent>sentence compression aims to retain the most salient information of sentence, rewritten in short form (knight and marcu, 2000).
</nextsent>
<nextsent>it can be used to deliver compressed content to portable devices (buyukkokten et al, 2001; corston-oliver, 2001) or as reading aid for aphasic readers (carroll et al., 1998) or the blind (grefenstette, 1998).
</nextsent>
<nextsent>earlier research in sentence compression focused on compressing single sentences, and were evaluated on sentence by sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2919">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of systems participating in the past document understanding conference (duc, 2002) (a large scale summarization evaluation effort sponsored by the united states government), and the text summarization challenge (fukusima and okumura, 2001) (sponsored by japanese government) are extraction based.
</prevsent>
<prevsent>extraction-based automatic text summarization systems extract parts of original documents and output the results as summaries (chen et al, 2003; edmundson, 1969; goldstein et al, 1999; hovy and lin, 1999; kupiec et al, 1995; luhn, 1969).
</prevsent>
</prevsection>
<citsent citstr=" H01-1054 ">
other systems based on information extraction (mckeown et al, 2002; radev and mckeown, 1998; <papid> J98-3005 </papid>white et al, 2001) <papid> H01-1054 </papid>and discourse analysis (marcu, 1999; strzalkowski et al, 1999) also exist but they are not yet usable for general-domain summarization.</citsent>
<aftsection>
<nextsent>our study focuses on the effectiveness of applying sentence compression techniques to improve the performance of extraction-based automatic text summarization systems.
</nextsent>
<nextsent>sentence compression aims to retain the most salient information of sentence, rewritten in short form (knight and marcu, 2000).
</nextsent>
<nextsent>it can be used to deliver compressed content to portable devices (buyukkokten et al, 2001; corston-oliver, 2001) or as reading aid for aphasic readers (carroll et al., 1998) or the blind (grefenstette, 1998).
</nextsent>
<nextsent>earlier research in sentence compression focused on compressing single sentences, and were evaluated on sentence by sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2920">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it can be used to deliver compressed content to portable devices (buyukkokten et al, 2001; corston-oliver, 2001) or as reading aid for aphasic readers (carroll et al., 1998) or the blind (grefenstette, 1998).
</prevsent>
<prevsent>earlier research in sentence compression focused on compressing single sentences, and were evaluated on sentence by sentence basis.
</prevsent>
</prevsection>
<citsent citstr=" A00-1043 ">
for example, jing (2000) <papid> A00-1043 </papid>trained her system on set of 500 sentences from the benton foundation (http://www.benton.org) and their reduced forms written by humans.</citsent>
<aftsection>
<nextsent>the results were evaluated at the parse tree level against the reduced trees; while knight and marcu (2000) trained their system on set of 1,067 sentences from ziff-davis magazine articles and evaluated their results on grammatical ity and importance rated by humans.
</nextsent>
<nextsent>both reported success in their evaluation criteria.
</nextsent>
<nextsent>however, neither of them reported their techniques?
</nextsent>
<nextsent>effectiveness in improving the overall performance of automatic text summarization systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2921">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ranked according to their length adjusted log-probability.
</prevsent>
<prevsent>3 neats ? multi-document summarization.
</prevsent>
</prevsection>
<citsent citstr=" W02-0406 ">
system neats (lin and hovy, 2002) <papid> W02-0406 </papid>is an extraction based multi-document summarization system.</citsent>
<aftsection>
<nextsent>it is among the top two performers in duc 2001 and 2002 (over and liggett, 2002).
</nextsent>
<nextsent>it consists of three main components: ? content selection ? the goal of content selection is to identify important concepts mentioned in document collection.
</nextsent>
<nextsent>neats computes the likelihood ratio ?
</nextsent>
<nextsent>(dunning, 1993) <papid> J93-1003 </papid>to identify key concepts in unigrams, bigrams, and trigrams, and clusters these concepts in order to identify major sub topics within the main topic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2923">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it consists of three main components: ? content selection ? the goal of content selection is to identify important concepts mentioned in document collection.
</prevsent>
<prevsent>neats computes the likelihood ratio ?
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
(dunning, 1993) <papid> J93-1003 </papid>to identify key concepts in unigrams, bigrams, and trigrams, and clusters these concepts in order to identify major sub topics within the main topic.</citsent>
<aftsection>
<nextsent>each sentence in the document set is then ranked, using the key concept structures.
</nextsent>
<nextsent>these n-gram key concepts are called topic signatures (lin and hovy 2000).<papid> C00-1072 </papid></nextsent>
<nextsent>we used key n-grams to rerank com pres sions in our experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2924">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(dunning, 1993) <papid> J93-1003 </papid>to identify key concepts in unigrams, bigrams, and trigrams, and clusters these concepts in order to identify major sub topics within the main topic.</prevsent>
<prevsent>each sentence in the document set is then ranked, using the key concept structures.</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
these n-gram key concepts are called topic signatures (lin and hovy 2000).<papid> C00-1072 </papid></citsent>
<aftsection>
<nextsent>we used key n-grams to rerank com pres sions in our experiments.
</nextsent>
<nextsent>content filtering ? neats uses three different filters: sentence position, stigma words, and maximum marginal relevancy.
</nextsent>
<nextsent>sentence position has been used as good content filter since the late 60s (edmundson, 1969).
</nextsent>
<nextsent>we apply simple sentence filter that only retains the 10 lead sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2925">
<title id=" W03-1101.xml">improving summarization performance by sentence compression  a pilot study </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe the automatic evaluation metric used in our experiments in the next section.
</prevsent>
<prevsent>4 unigram co-occurrence metric.
</prevsent>
</prevsection>
<citsent citstr=" W03-0510 ">
in recent study (lin and hovy, 2003<papid> W03-0510 </papid>a), we showed that the recall-based unigram cooccurrence automatic scoring metric correlates highly with human evaluation and has high recall and precision in predicting the statistical significance of results comparing with its human counter part.</citsent>
<aftsection>
<nextsent>the idea is to measure the content similarity between system extract and manual summary using simple n-gram overlap.
</nextsent>
<nextsent>a similar idea called ibm bleu score has proved successful in automatic machine translation evaluation (nist, 2002; papineni et al, 2001).
</nextsent>
<nextsent>for summarization, we can express the degree of content overlap in terms of gram matches as the following equation: )1( )( )( }{ }{ ? ?
</nextsent>
<nextsent>= unitsmodelc cgramn unitsmodelc cgramn match gramncount gramncount model units are segments of manual summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2931">
<title id=" W02-1113.xml">generating extraction patterns from a large semantic network and an untagged corpus </title>
<section> the semantic net.  </section>
<citcontext>
<prevsection>
<prevsent>1 this means that for target english text, one can assume that 92% of the tokens will be in the semantic net.
</prevsent>
<prevsent>figure 1: table of linguistic constraints we will not detail here the different measures that have been implemented to calculate similarities between words.
</prevsent>
</prevsection>
<citsent citstr=" C02-1062 ">
please refer to (dutoit and poibeau, 2002) <papid> C02-1062 </papid>for more details.</citsent>
<aftsection>
<nextsent>equivalent predicative structures for ie applications, defining an appropriate set of extraction pattern is crucial.
</nextsent>
<nextsent>that is why we want to validate the proposed measures to extend an initial set of extraction patterns.
</nextsent>
<nextsent>4.1 the acquisition process.
</nextsent>
<nextsent>the process begins when the end-user provides predicative linguistic structure to the system along with representative corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2932">
<title id=" W03-0304.xml">statistical translation alignment with compositionality constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this article presents method for aligning words between translations, that imposes acompositionality constraint on alignments produced with statistical translation models.
</prevsent>
<prevsent>experiments conducted within the wpt-03 shared task on word alignment demonstrate the effectiveness of the proposed approach.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
since the pioneering work of the ibm machine translation team almost 15 years ago (brown et al, 1990), <papid> J90-2002 </papid>statistical methods have proven to be valuable tools in approaching the automation of translation.</citsent>
<aftsection>
<nextsent>word alignments (wa) play central role in the statistical modeling process, and reliable wa techniques are crucial in acquiring the parameters of the models (och and ney, 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>yet, the very nature of these alignments, as defined in the ibm modeling approach (brown et al, 1993), <papid> J93-2003 </papid>leadto descriptions of the correspondences between source language (sl) and target-language (tl) words of translation that are often unsatisfactory, at least from human perspective.one notion that is typically evacuated in the statistical modeling process is that of compositionality: fundamental assumption in statistical machine translation isthat, ultimately, all the words of sl segment contribute to produce all the words of its tl translation , at least to some degree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2933">
<title id=" W03-0304.xml">statistical translation alignment with compositionality constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments conducted within the wpt-03 shared task on word alignment demonstrate the effectiveness of the proposed approach.
</prevsent>
<prevsent>since the pioneering work of the ibm machine translation team almost 15 years ago (brown et al, 1990), <papid> J90-2002 </papid>statistical methods have proven to be valuable tools in approaching the automation of translation.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
word alignments (wa) play central role in the statistical modeling process, and reliable wa techniques are crucial in acquiring the parameters of the models (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>yet, the very nature of these alignments, as defined in the ibm modeling approach (brown et al, 1993), <papid> J93-2003 </papid>leadto descriptions of the correspondences between source language (sl) and target-language (tl) words of translation that are often unsatisfactory, at least from human perspective.one notion that is typically evacuated in the statistical modeling process is that of compositionality: fundamental assumption in statistical machine translation isthat, ultimately, all the words of sl segment contribute to produce all the words of its tl translation , at least to some degree.</nextsent>
<nextsent>while this makes perfect sense from stochastic point of view, it contrasts with the hypothesis at the basis of most (if not all) other mt approaches, as well as with our natural intuitions about translation: that individual portions of the sl text produce individual tl portions autonomously, and that the final translation is obtained by somehow piecing together these tl portions.in what follows, we show how re-integrating compo sitionality into the statistical translation word alignment process leads to better alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2935">
<title id=" W03-0304.xml">statistical translation alignment with compositionality constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the pioneering work of the ibm machine translation team almost 15 years ago (brown et al, 1990), <papid> J90-2002 </papid>statistical methods have proven to be valuable tools in approaching the automation of translation.</prevsent>
<prevsent>word alignments (wa) play central role in the statistical modeling process, and reliable wa techniques are crucial in acquiring the parameters of the models (och and ney, 2000).<papid> P00-1056 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
yet, the very nature of these alignments, as defined in the ibm modeling approach (brown et al, 1993), <papid> J93-2003 </papid>leadto descriptions of the correspondences between source language (sl) and target-language (tl) words of translation that are often unsatisfactory, at least from human perspective.one notion that is typically evacuated in the statistical modeling process is that of compositionality: fundamental assumption in statistical machine translation isthat, ultimately, all the words of sl segment contribute to produce all the words of its tl translation , at least to some degree.</citsent>
<aftsection>
<nextsent>while this makes perfect sense from stochastic point of view, it contrasts with the hypothesis at the basis of most (if not all) other mt approaches, as well as with our natural intuitions about translation: that individual portions of the sl text produce individual tl portions autonomously, and that the final translation is obtained by somehow piecing together these tl portions.in what follows, we show how re-integrating compo sitionality into the statistical translation word alignment process leads to better alignments.
</nextsent>
<nextsent>we first take closer look at the standard?
</nextsent>
<nextsent>statistical wa techniques in section2, and then propose way of imposing compositional ity constraint on these techniques in section 3.
</nextsent>
<nextsent>in section 4, we discuss various implementation issues, and finally present the experimental results of this approach on the wpt-03 shared task on wa in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2937">
<title id=" W03-0304.xml">statistical translation alignment with compositionality constraints </title>
<section> compositionality.  </section>
<citcontext>
<prevsection>
<prevsent>in ibm-style alignments, each sl token is connected to single (possibly null) tl token, typically the tl token with which it has the most lexical affinities?, regard less of other existing connections in the alignment and, more importantly, of the relationships it holds with other sl tokens in its vicinity.
</prevsent>
<prevsent>in practice, this means that some tl tokens can end up being connected to several sl tokens, while other tl tokens are left unconnected.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
this contrasts with alternative alignment models such as those of melamed (1998) and wu (1997), <papid> J97-3002 </papid>which impose one-to-one?</citsent>
<aftsection>
<nextsent>constraint on alignments.
</nextsent>
<nextsent>such constraint evokes the notion of compositionality in translation: it suggests that each sl token operates independently in thesl sentence to produce single tl token in the tl sentence, which then depends on no other sl token.this view is, of course, extreme, and real-life translations are full of examples that show how this composi tionality principle breaks down as we approach the level of word correspondences.
</nextsent>
<nextsent>yet, if we can find way of imposing compositionality constraints on was, at least to the level where it applies, then we should obtain more sensible results than with viterbi alignments.
</nextsent>
<nextsent>for instance, consider procedure that splits both the sl and tl sentences and into two independent parts, in such way as to maximise the probability of the two resulting viterbi alignments: argmaxi,j,d? ? ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2940">
<title id=" W03-0304.xml">statistical translation alignment with compositionality constraints </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>but early experiments with this approach are unconvincing, and more elaborate filtering mechanisms will probably be necessary.
</prevsent>
<prevsent>finally, ibm model 2 is certainly not the state of the art in statistical translation modeling.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
then again, the methods proposed here are not dependent on the underlying translation model, and similar wa methods could be based on more elaborate models, such as models 35, or the hmm-based models proposed by och et al (1999)<papid> W99-0604 </papid>for example.</citsent>
<aftsection>
<nextsent>on the other hand, our compositional alignment method could be used during the training process of higher-level models.
</nextsent>
<nextsent>whether this would lead to better estimates of the models?
</nextsent>
<nextsent>parameters remains to be seen, but it is certainly direction worth exploring.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2941">
<title id=" W03-1723.xml">a two stage statistical word segmentation system for chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also give results and discussions on this evaluation.
</prevsent>
<prevsent>word segmentation is very important for chinese language processing, which aims to recognize the implicit word boundaries in chinese text.
</prevsent>
</prevsection>
<citsent citstr=" W02-1817 ">
during the past decades, great success has been achieved in chinese word segmentation (nie, et al 1995; yao, 1997; fu and wang, 1999; wang et al 2000; zhang, et al 2002).<papid> W02-1817 </papid></citsent>
<aftsection>
<nextsent>however, there still remain two difficult problems, i.e. ambiguity resolution and unknown word (so-called oov word) identification, while developing practical segmentation system for large open applications.
</nextsent>
<nextsent>in this paper, we present two-stage statistical word segmentation system for chinese.
</nextsent>
<nextsent>in the first stage, we employ word bigram model to segment known words (viz.
</nextsent>
<nextsent>the words included in the system dictionary) in input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2942">
<title id=" W02-1819.xml">learning rules for chinese prosodic phrase prediction </title>
<section> rule learning algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>research on machine learning has concentrated in the main on inducing rules from unordered set of examples.
</prevsent>
<prevsent>and knowledge represented in collection of rules is understandable and effective way to realize some kind of intelligence.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
c4.5 (quinlan, 1986) and transformation-based learning (brill, 1995) <papid> J95-4004 </papid>are typical rule-learning algorithms that have been applied to various nlp tasks such as part-of-speech tagging and named entity extraction etc. both algorithms are supervised learning and can be used to induce rules from examples.</citsent>
<aftsection>
<nextsent>but they also have difference from each other.
</nextsent>
<nextsent>firstly the c4.5 rule induction is completely automatic process.
</nextsent>
<nextsent>what we need to do is to extract appropriate features for our problem.
</nextsent>
<nextsent>as to transformation-based learning (henceforth tbl), transformation rule templates, which determine the effectiveness of the acquired rules, have to be designed manually before learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2943">
<title id=" W02-0717.xml">a multi perspective evaluation of the nespole speechtospeech translation system </title>
<section> the nespole! system.  </section>
<citcontext>
<prevsection>
<prevsent>system architectureipated network trac, can be taken into account at any time.
</prevsent>
<prevsent>a well-de ned api allows the hlt servers to communicate with each other and with the mediator, while the hlt modules within the servers for the dierent languages are implemented using very dierent software packages.
</prevsent>
</prevsection>
<citsent citstr=" H01-1007 ">
further details of the design principles of the system are described in (lavie et al, 2001).<papid> H01-1007 </papid></citsent>
<aftsection>
<nextsent>the computationally intensive part of speech recognition and translation is done on dedicated server machines, whose nature and location is of no concern to the user.
</nextsent>
<nextsent>a wide range ofclient-machines, even portable devices or public information kiosks, are therefore able to run the client software, so that the service can be made available nearly everywhere.
</nextsent>
<nextsent>the system architecture shown in figure 1contains two dierent types of internet connections with dierent characteristics.
</nextsent>
<nextsent>the connection between client/agent pcs and the mediator is standard video-conferencing connection that uses h323 and udp protocols.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2944">
<title id=" W02-0717.xml">a multi perspective evaluation of the nespole speechtospeech translation system </title>
<section> multi-perspective evaluations.  </section>
<citcontext>
<prevsection>
<prevsent>translations were graded by multiple human graders at the level of semantic dialogue units (sdus).
</prevsent>
<prevsent>foreach dataset, one grader rst manually segmented each utterance into sdus.
</prevsent>
</prevsection>
<citsent citstr=" W00-0203 ">
all graders then used this segmentation in order to assign scores for each sdu present in the utterance.we followed the three-point grading scheme previously developed for the c-star consortium, as described in (levin et al, 2000).<papid> W00-0203 </papid></citsent>
<aftsection>
<nextsent>each sdu is graded as either \perfect  (meaning translated correctly and output is fluent), \ok  (meaning is translated reasonably correct but output may be disfluent), or \bad  (meaning not properly translated).
</nextsent>
<nextsent>we calculate the percent of sdus that are graded with each of the above categories.
</nextsent>
<nextsent>\perfect  and \ok  percentages are also summed together into category of \acceptable  translations.
</nextsent>
<nextsent>average percentages are calculated for each dialogue, each grader, and separately for client and agent utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2945">
<title id=" W03-0305.xml">reducing parameter space for word alignment </title>
<section> word alignment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>for that purpose, we preprocessed the training corpus using word lemmatizer and bilingual lexicon extraction algorithm.
</prevsent>
<prevsent>section 2 briefly describes the base alignment algorithm, section 3 describes our additional components, and section 4 shows our experimental results, followed by discussion and conclusion in section 5 and 6, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use ibm model 4 (brown et al, 1993) <papid> J93-2003 </papid>as basis for our word alignment system.</citsent>
<aftsection>
<nextsent>the model was implemented in public software package giza++ (och and ney, 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>we use default parameters provided with the package, namely, it was boot strapped from model 1 (five iterations), hmm model (five iterations) model 3 (two iterations) and model 4 (four iterations).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2946">
<title id=" W03-0305.xml">reducing parameter space for word alignment </title>
<section> word alignment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>section 2 briefly describes the base alignment algorithm, section 3 describes our additional components, and section 4 shows our experimental results, followed by discussion and conclusion in section 5 and 6, respectively.
</prevsent>
<prevsent>we use ibm model 4 (brown et al, 1993) <papid> J93-2003 </papid>as basis for our word alignment system.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
the model was implemented in public software package giza++ (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>we use default parameters provided with the package, namely, it was boot strapped from model 1 (five iterations), hmm model (five iterations) model 3 (two iterations) and model 4 (four iterations).
</nextsent>
<nextsent>ibm model 4 is conditional generative model, which generates an english sentence (and word alignment)given foreign sentence (french or romanian, in our experiments here).
</nextsent>
<nextsent>in the generative process, each english word  is duplicated  times according to the probabilities given by the fertility table    . each duplicated english word  is then translated to french (or roma nian) word according to the probabilities given by the translation table    . the position of in the french sentence is then moved from the position of  in the english sentence by an offset  . the probability of  is given by the distortion table   fffi fl ffi , which is conditioned on the word classes  and fi fl . in giza++, the word classes are automatically detected by bilingual clustering algorithm.
</nextsent>
<nextsent>the translation table    dominates the parameter space when the vocabulary size grows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2947">
<title id=" W03-0808.xml">infoxtract a customizable intermediate level information extraction engine </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the us, muc [chinchor &amp; marsh 1998] has been the driving force for developing this technology.
</prevsent>
<prevsent>the most successful ie task thus far has been named entity (ne) tagging.
</prevsent>
</prevsection>
<citsent citstr=" M98-1015 ">
the state-of-the-art exemplified by systems such as netowl [krupka &amp; hausman 1998], <papid> M98-1015 </papid>identifinder [miller et al 1998] <papid> M98-1009 </papid>and infoxtract [srihari et al 2000] <papid> A00-1034 </papid>has reached near human performance, with 90% or above f-measure.</citsent>
<aftsection>
<nextsent>on the other hand, the deep level muc ie task scenario template (st) is designed to extract detailed information for predefined event scenarios of interest.
</nextsent>
<nextsent>it involves filling the slots of complicated templates.
</nextsent>
<nextsent>it is generally felt that this task is too ambitious for commercial application at present.
</nextsent>
<nextsent>information discovery (id) is term which has traditionally been used to describe efforts in data mining [han 1999].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2948">
<title id=" W03-0808.xml">infoxtract a customizable intermediate level information extraction engine </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the us, muc [chinchor &amp; marsh 1998] has been the driving force for developing this technology.
</prevsent>
<prevsent>the most successful ie task thus far has been named entity (ne) tagging.
</prevsent>
</prevsection>
<citsent citstr=" M98-1009 ">
the state-of-the-art exemplified by systems such as netowl [krupka &amp; hausman 1998], <papid> M98-1015 </papid>identifinder [miller et al 1998] <papid> M98-1009 </papid>and infoxtract [srihari et al 2000] <papid> A00-1034 </papid>has reached near human performance, with 90% or above f-measure.</citsent>
<aftsection>
<nextsent>on the other hand, the deep level muc ie task scenario template (st) is designed to extract detailed information for predefined event scenarios of interest.
</nextsent>
<nextsent>it involves filling the slots of complicated templates.
</nextsent>
<nextsent>it is generally felt that this task is too ambitious for commercial application at present.
</nextsent>
<nextsent>information discovery (id) is term which has traditionally been used to describe efforts in data mining [han 1999].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2949">
<title id=" W03-0808.xml">infoxtract a customizable intermediate level information extraction engine </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the us, muc [chinchor &amp; marsh 1998] has been the driving force for developing this technology.
</prevsent>
<prevsent>the most successful ie task thus far has been named entity (ne) tagging.
</prevsent>
</prevsection>
<citsent citstr=" A00-1034 ">
the state-of-the-art exemplified by systems such as netowl [krupka &amp; hausman 1998], <papid> M98-1015 </papid>identifinder [miller et al 1998] <papid> M98-1009 </papid>and infoxtract [srihari et al 2000] <papid> A00-1034 </papid>has reached near human performance, with 90% or above f-measure.</citsent>
<aftsection>
<nextsent>on the other hand, the deep level muc ie task scenario template (st) is designed to extract detailed information for predefined event scenarios of interest.
</nextsent>
<nextsent>it involves filling the slots of complicated templates.
</nextsent>
<nextsent>it is generally felt that this task is too ambitious for commercial application at present.
</nextsent>
<nextsent>information discovery (id) is term which has traditionally been used to describe efforts in data mining [han 1999].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2955">
<title id=" W03-0808.xml">infoxtract a customizable intermediate level information extraction engine </title>
<section> hybrid technology.  </section>
<citcontext>
<prevsection>
<prevsent>expert lexicons are used in customization of lexicons, named entity glossaries, and alias lists, as well as concept tagging.
</prevsent>
<prevsent>both supervised machine learning and unsuper-vised learning are used in infoxtract.
</prevsent>
</prevsection>
<citsent citstr=" C02-1127 ">
supervised learning is used in hybrid modules such as ne [srihari et al 2000], <papid> A00-1034 </papid>ne normalization [li et al 2002] <papid> C02-1127 </papid>and co-reference.</citsent>
<aftsection>
<nextsent>it is also used in the preprocessing module for orthographic case restoration of case insensitive input [niu et al 2003].
</nextsent>
<nextsent>unsupervised learning involves acquisition of lexical knowledge and rules from raw corpus.
</nextsent>
<nextsent>the former includes word clustering, automatic name glossary acquisition and thesaurus construction.
</nextsent>
<nextsent>the latter involves boot strapped learning of ne and ce rules, similar to the techniques used in [riloff 1996].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2956">
<title id=" W03-1707.xml">annotating the propositions in the penn chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the information encoded in the corpora to large extent determines what can be learned by supervised machine learning systems.
</prevsent>
<prevsent>therefore, it is crucial to encode the desired level of information for its automatic acquisition.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the creation of the penn english treebank (marcus et al, 1993), <papid> J93-2004 </papid>syntactically interpreted corpus, played acrucial role in the advances in natural language parsing technology (collins, 1997; <papid> P97-1003 </papid>collins, 2000; charniak, 2000) <papid> A00-2018 </papid>for english.</citsent>
<aftsection>
<nextsent>the creation of the penn chinese treebank (xia et al, 2000) is also beginning to help advance technologies in chinese syntactic analysis (chiang, 2000; <papid> P00-1058 </papid>bikel and chiang,2000).<papid> W00-1201 </papid></nextsent>
<nextsent>since the treebanks are generally syntactically oriented (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2957">
<title id=" W03-1707.xml">annotating the propositions in the penn chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the information encoded in the corpora to large extent determines what can be learned by supervised machine learning systems.
</prevsent>
<prevsent>therefore, it is crucial to encode the desired level of information for its automatic acquisition.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
the creation of the penn english treebank (marcus et al, 1993), <papid> J93-2004 </papid>syntactically interpreted corpus, played acrucial role in the advances in natural language parsing technology (collins, 1997; <papid> P97-1003 </papid>collins, 2000; charniak, 2000) <papid> A00-2018 </papid>for english.</citsent>
<aftsection>
<nextsent>the creation of the penn chinese treebank (xia et al, 2000) is also beginning to help advance technologies in chinese syntactic analysis (chiang, 2000; <papid> P00-1058 </papid>bikel and chiang,2000).<papid> W00-1201 </papid></nextsent>
<nextsent>since the treebanks are generally syntactically oriented (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2958">
<title id=" W03-1707.xml">annotating the propositions in the penn chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the information encoded in the corpora to large extent determines what can be learned by supervised machine learning systems.
</prevsent>
<prevsent>therefore, it is crucial to encode the desired level of information for its automatic acquisition.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the creation of the penn english treebank (marcus et al, 1993), <papid> J93-2004 </papid>syntactically interpreted corpus, played acrucial role in the advances in natural language parsing technology (collins, 1997; <papid> P97-1003 </papid>collins, 2000; charniak, 2000) <papid> A00-2018 </papid>for english.</citsent>
<aftsection>
<nextsent>the creation of the penn chinese treebank (xia et al, 2000) is also beginning to help advance technologies in chinese syntactic analysis (chiang, 2000; <papid> P00-1058 </papid>bikel and chiang,2000).<papid> W00-1201 </papid></nextsent>
<nextsent>since the treebanks are generally syntactically oriented (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2959">
<title id=" W03-1707.xml">annotating the propositions in the penn chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, it is crucial to encode the desired level of information for its automatic acquisition.
</prevsent>
<prevsent>the creation of the penn english treebank (marcus et al, 1993), <papid> J93-2004 </papid>syntactically interpreted corpus, played acrucial role in the advances in natural language parsing technology (collins, 1997; <papid> P97-1003 </papid>collins, 2000; charniak, 2000) <papid> A00-2018 </papid>for english.</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
the creation of the penn chinese treebank (xia et al, 2000) is also beginning to help advance technologies in chinese syntactic analysis (chiang, 2000; <papid> P00-1058 </papid>bikel and chiang,2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>since the treebanks are generally syntactically oriented (cf.
</nextsent>
<nextsent>sinica treebank (chen et al,to appear)), the information encoded there is shallow?.
</nextsent>
<nextsent>important information useful for natural language applications is missing.
</nextsent>
<nextsent>most notably, significant regularities in the predicate-argument structure of lexical items are not captured.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2960">
<title id=" W03-1707.xml">annotating the propositions in the penn chinese treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, it is crucial to encode the desired level of information for its automatic acquisition.
</prevsent>
<prevsent>the creation of the penn english treebank (marcus et al, 1993), <papid> J93-2004 </papid>syntactically interpreted corpus, played acrucial role in the advances in natural language parsing technology (collins, 1997; <papid> P97-1003 </papid>collins, 2000; charniak, 2000) <papid> A00-2018 </papid>for english.</prevsent>
</prevsection>
<citsent citstr=" W00-1201 ">
the creation of the penn chinese treebank (xia et al, 2000) is also beginning to help advance technologies in chinese syntactic analysis (chiang, 2000; <papid> P00-1058 </papid>bikel and chiang,2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>since the treebanks are generally syntactically oriented (cf.
</nextsent>
<nextsent>sinica treebank (chen et al,to appear)), the information encoded there is shallow?.
</nextsent>
<nextsent>important information useful for natural language applications is missing.
</nextsent>
<nextsent>most notably, significant regularities in the predicate-argument structure of lexical items are not captured.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2962">
<title id=" W03-0901.xml">a knowledge driven approach to text meaning processing </title>
<section> text interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample, in this case the fragments extracted from text best match the launch satellite v1 scenario; as result, launch?
</prevsent>
<prevsent>in the text will be taken to mean the launch satellite v1 concept (  word sense), as opposed to launching product, launching ship, etc.one piece of information we are not currently exploiting in this matching process are the statistical probabilities that particular syntactic roles (grammatical functions)such as subject, direct object, etc., will correspond to particular semantic roles such as agent n1, vehicle n1, etc. these would help the matcher deal with ambiguous cases, where the current approach is not sufficient to determine the appropriate match.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
automated methods for obtaining such statistics, such as (gildea and jurafsky, 2002), <papid> J02-3001 </papid>could be exploited for this task.</citsent>
<aftsection>
<nextsent>3.3 question answering.
</nextsent>
<nextsent>having identified and instantiated the appropriate scenario representation in the knowledge base, that representation is now available for use in question-answering.
</nextsent>
<nextsent>this allows questions to be answered which go beyond facts explicitly mentioned in the text, but which are part of the scenario representation (e.g., question about therocket), and those requiring inference (using kms inference engine, applied to the scenario and other knowledge in the knowledge base).
</nextsent>
<nextsent>the inference engine currently requires questions to be posed in the native representation language (km), rather than having natural language front end.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2963">
<title id=" W02-2016.xml">japanese dependency analysis using cascaded chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency analysis has been recognized as basic process in japanese sentence analysis, and number of studies have been proposed.
</prevsent>
<prevsent>japanese dependency structure is usually defined in terms of the relationship between phrasal units called bunsetsu segments (hereafter segments?).
</prevsent>
</prevsection>
<citsent citstr=" E99-1026 ">
most of the previous statistical approaches for japanese dependency analysis (fujio and matsumoto, 1998; haruno et al , 1999; uchimoto et al ., 1999; <papid> E99-1026 </papid>kanayama et al , 2000; <papid> C00-1060 </papid>uchimoto et al , 2000; kudo and matsumoto, 2000) <papid> W00-1303 </papid>are based on probabilistic model consisting of the following two steps.</citsent>
<aftsection>
<nextsent>first, they estimate modification probabilities, in other words, how probable one segment tends to modify another.
</nextsent>
<nextsent>second the optimal combination of dependencies is searched from the all candidates dependencies.
</nextsent>
<nextsent>such probabilistic model is not always efficient since it needs to calculate the probabilities for all possible dependencies and creates n(n1)/2 (where is the number of segments in sentence) training examples per sentence.
</nextsent>
<nextsent>in addition, the probabilistic model assumes that each pairs of dependency structure is independent.in this paper, we propose new japanese dependency parser which is more efficient and simpler than the probabilistic model, yet performs better in training and testing on the kyoto university corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2964">
<title id=" W02-2016.xml">japanese dependency analysis using cascaded chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency analysis has been recognized as basic process in japanese sentence analysis, and number of studies have been proposed.
</prevsent>
<prevsent>japanese dependency structure is usually defined in terms of the relationship between phrasal units called bunsetsu segments (hereafter segments?).
</prevsent>
</prevsection>
<citsent citstr=" C00-1060 ">
most of the previous statistical approaches for japanese dependency analysis (fujio and matsumoto, 1998; haruno et al , 1999; uchimoto et al ., 1999; <papid> E99-1026 </papid>kanayama et al , 2000; <papid> C00-1060 </papid>uchimoto et al , 2000; kudo and matsumoto, 2000) <papid> W00-1303 </papid>are based on probabilistic model consisting of the following two steps.</citsent>
<aftsection>
<nextsent>first, they estimate modification probabilities, in other words, how probable one segment tends to modify another.
</nextsent>
<nextsent>second the optimal combination of dependencies is searched from the all candidates dependencies.
</nextsent>
<nextsent>such probabilistic model is not always efficient since it needs to calculate the probabilities for all possible dependencies and creates n(n1)/2 (where is the number of segments in sentence) training examples per sentence.
</nextsent>
<nextsent>in addition, the probabilistic model assumes that each pairs of dependency structure is independent.in this paper, we propose new japanese dependency parser which is more efficient and simpler than the probabilistic model, yet performs better in training and testing on the kyoto university corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2965">
<title id=" W02-2016.xml">japanese dependency analysis using cascaded chunking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency analysis has been recognized as basic process in japanese sentence analysis, and number of studies have been proposed.
</prevsent>
<prevsent>japanese dependency structure is usually defined in terms of the relationship between phrasal units called bunsetsu segments (hereafter segments?).
</prevsent>
</prevsection>
<citsent citstr=" W00-1303 ">
most of the previous statistical approaches for japanese dependency analysis (fujio and matsumoto, 1998; haruno et al , 1999; uchimoto et al ., 1999; <papid> E99-1026 </papid>kanayama et al , 2000; <papid> C00-1060 </papid>uchimoto et al , 2000; kudo and matsumoto, 2000) <papid> W00-1303 </papid>are based on probabilistic model consisting of the following two steps.</citsent>
<aftsection>
<nextsent>first, they estimate modification probabilities, in other words, how probable one segment tends to modify another.
</nextsent>
<nextsent>second the optimal combination of dependencies is searched from the all candidates dependencies.
</nextsent>
<nextsent>such probabilistic model is not always efficient since it needs to calculate the probabilities for all possible dependencies and creates n(n1)/2 (where is the number of segments in sentence) training examples per sentence.
</nextsent>
<nextsent>in addition, the probabilistic model assumes that each pairs of dependency structure is independent.in this paper, we propose new japanese dependency parser which is more efficient and simpler than the probabilistic model, yet performs better in training and testing on the kyoto university corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2983">
<title id=" W02-0812.xml">evaluating the effectiveness of ensembles of decision trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper concludes with review of the origins of ourapproach.
</prevsent>
<prevsent>since the focus here is on analysis, implementation level details are not extensively discussed.
</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
such descriptions can be found in (pedersen, 2001<papid> N01-1011 </papid>b) or (pedersen, 2002).</citsent>
<aftsection>
<nextsent>july 2002, pp.
</nextsent>
<nextsent>81-87.
</nextsent>
<nextsent>association for computational linguistics.
</nextsent>
<nextsent>disambiguation: recent successes and future directions, philadelphia, proceedings of the siglex/senseval workshop on word sense
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2985">
<title id=" W02-0812.xml">evaluating the effectiveness of ensembles of decision trees </title>
<section> decomposition of ensembles.  </section>
<citcontext>
<prevsection>
<prevsent>the decision tree learner must search through very large feature space, and under such circumstances may fall victim to fragmentation.despite these results, we are not prepared to dismiss the use of ensembles or unigram decision trees.an ensemble of unigram and cooccurrence decision trees (uc) results in greater accuracy than any other lexical decision tree for the english senseval-1 lexical sample, and is essentially tied with the most accurate of these approaches (ubc) inthe english senseval-2 lexical sample.
</prevsent>
<prevsent>in principle unigrams and cooccurrence features are complementary, since unigrams represent topical context, and cooccurrences represent local context.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
this follows the line of reasoning developed by (leacock et al, 1998) <papid> J98-1006 </papid>in formulating their ensemble of naive bayesian classifiers for word sense disam biguation.adding the bigram decision tree (b) to the ensemble of the unigram and cooccurrence decision trees (uc) to create ubc does not result insignificant improvements inaccuracy for the any of the lexical samples.</citsent>
<aftsection>
<nextsent>this reflects the fact that the bigram and cooccurrence feature sets can be redundant.
</nextsent>
<nextsent>bi grams are two word sequences that occur anywhere within the context of the ambiguous word, while cooccurrences are bigrams that include the target word and word one or two positions away.
</nextsent>
<nextsent>thus, any consecutive two word sequence that includes the word to be disambiguated and has loglikelihoodratio greater than the specified threshold will be considered both bigram and cooccurrence.
</nextsent>
<nextsent>despite the partial overlap between bigrams and cooccurrences, we believe that retaining them as separate feature sets is reasonable idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2986">
<title id=" W02-0812.xml">evaluating the effectiveness of ensembles of decision trees </title>
<section> duluth38 background.  </section>
<citcontext>
<prevsection>
<prevsent>of course, how to achieve such an optimal combination is an open question.
</prevsent>
<prevsent>this is still an interesting point, since it suggests that there is relatively large number of test instances that require fairly minimal information to disambiguate successfully.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
the origins of duluth38 can be found in an ensemble approach based on multiple naive bayesian classifiers that perform disambiguation via majority vote (pedersen, 2000).<papid> A00-2009 </papid></citsent>
<aftsection>
<nextsent>each member of the ensemble is based on unigram features that occur in varying sized windows of context to the left and right of the ambiguous word.
</nextsent>
<nextsent>the sizes of these windows are 0, 1, 2, 3, 4, 5, 10, 25, and 50 words to the left and to the right, essentially forming bags of words to theleft and right.
</nextsent>
<nextsent>the accuracy of this ensemble disam biguating the nouns interest (89%) and line (88%) isas high as any previously published results.
</nextsent>
<nextsent>how ever, each ensemble consists of 81 naive bayesian classifiers, making it difficult to determine which features and classifiers were contributing most significantly to disambiguation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2989">
<title id=" W02-0812.xml">evaluating the effectiveness of ensembles of decision trees </title>
<section> duluth38 background.  </section>
<citcontext>
<prevsection>
<prevsent>when the impact of mixed feature setson disambiguation is analyzed, cooccurrences usually prove to contribute significantly to overall accuracy.
</prevsent>
<prevsent>this is certainly our experience, where the cooccurrence decision tree (c) is the most accurate of the individual lexical decision trees.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
likewise, (ng and lee, 1996) <papid> P96-1006 </papid>report overall accuracy for the noun interest of 87%, and find that that when their feature set only consists of cooccurrence features the accuracy only drops to 80%.</citsent>
<aftsection>
<nextsent>our interest in bigrams was indirectly motivated by (leacock et al, 1998), <papid> J98-1006 </papid>who describe an ensemble approach made up of local context and topical context.</nextsent>
<nextsent>they suggest that topical context can be represented by words that occur anywhere in window of context, while local contextual features are words that occur within close proximity to the targetword.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2991">
<title id=" W03-0804.xml">international standard for a linguistic annotation framework </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the data model that will define the pivot format mustbe capable of representing all of the information contained in diverse annotation types.
</prevsent>
<prevsent>the model we assume is feature structure graph for annotation information, capable of referencing n-dimensional regions of primary data as well as other annotations.
</prevsent>
</prevsection>
<citsent citstr=" P01-1040 ">
the choice of this model is indicated by its almost universal use in defininggeneral-purpose annotation formats, including the generic modeling tool (gmt) (ide &amp; romary, 2001<papid> P01-1040 </papid>2002) and annotation graphs (bird &amp; liberman, 2001).</citsent>
<aftsection>
<nextsent>thexml-based gmt could serve as starting point for defining the pivot format; its applicability to diverse annotation types, including terminology, dictionaries and other lexical data (ide, et al, 2000), morphological annotation (ide &amp; romary, 2001<papid> P01-1040 </papid>a; 2003) and syntactic annotation (ide &amp; romary, 2001<papid> P01-1040 </papid>b) demonstrates its generality.</nextsent>
<nextsent>as specified by the laf architecture, the gmt implements feature structure graph, and exploits the hierarchical structure of xml elements and xmls powerful inter and intra-document pointing and linkage mechanisms for referencing both raw?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2998">
<title id=" W02-2018.xml">a comparison of algorithms for maximum entropy parameter estimation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, the standardly used iterative scaling algorithms perform quite poorly in comparison to the others, and for all of the test problems, limited memory variable metric algorithm outperformed the other choices.
</prevsent>
<prevsent>maximum entropy (me) models, variously known as log-linear, gibbs, exponential, and multinomial logit models, provide general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computervision and econometrics.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
in natural language processing, recent years have seen me techniques used for sentence boundary detection,part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just few applications (abney, 1997; <papid> J97-4005 </papid>berger et al, 1996; <papid> J96-1002 </papid>ratnaparkhi, 1998; johnson et al., 1999).<papid> P99-1069 </papid>a leading advantage of me models is their flex ibility: they allow stochastic rule systems to be augmented with additional syntactic, semantic, and pragmatic features.</citsent>
<aftsection>
<nextsent>however, the richness of the representations is not without cost.
</nextsent>
<nextsent>even modest me models can require considerable computational resources and very large quantities of annotated training data in order to accurately estimate the models parameters.
</nextsent>
<nextsent>while parameter estimation for me models is conceptually straightforward, in practice me models for typical natural language tasks are usually quite large, and frequently contain hundreds of thousands of free parameters.
</nextsent>
<nextsent>estimation of such large models is not only expensive, but also, due to sparsely distributed features, sensitive to round-off errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z2999">
<title id=" W02-2018.xml">a comparison of algorithms for maximum entropy parameter estimation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, the standardly used iterative scaling algorithms perform quite poorly in comparison to the others, and for all of the test problems, limited memory variable metric algorithm outperformed the other choices.
</prevsent>
<prevsent>maximum entropy (me) models, variously known as log-linear, gibbs, exponential, and multinomial logit models, provide general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computervision and econometrics.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in natural language processing, recent years have seen me techniques used for sentence boundary detection,part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just few applications (abney, 1997; <papid> J97-4005 </papid>berger et al, 1996; <papid> J96-1002 </papid>ratnaparkhi, 1998; johnson et al., 1999).<papid> P99-1069 </papid>a leading advantage of me models is their flex ibility: they allow stochastic rule systems to be augmented with additional syntactic, semantic, and pragmatic features.</citsent>
<aftsection>
<nextsent>however, the richness of the representations is not without cost.
</nextsent>
<nextsent>even modest me models can require considerable computational resources and very large quantities of annotated training data in order to accurately estimate the models parameters.
</nextsent>
<nextsent>while parameter estimation for me models is conceptually straightforward, in practice me models for typical natural language tasks are usually quite large, and frequently contain hundreds of thousands of free parameters.
</nextsent>
<nextsent>estimation of such large models is not only expensive, but also, due to sparsely distributed features, sensitive to round-off errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3001">
<title id=" W02-2018.xml">a comparison of algorithms for maximum entropy parameter estimation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, the standardly used iterative scaling algorithms perform quite poorly in comparison to the others, and for all of the test problems, limited memory variable metric algorithm outperformed the other choices.
</prevsent>
<prevsent>maximum entropy (me) models, variously known as log-linear, gibbs, exponential, and multinomial logit models, provide general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computervision and econometrics.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
in natural language processing, recent years have seen me techniques used for sentence boundary detection,part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just few applications (abney, 1997; <papid> J97-4005 </papid>berger et al, 1996; <papid> J96-1002 </papid>ratnaparkhi, 1998; johnson et al., 1999).<papid> P99-1069 </papid>a leading advantage of me models is their flex ibility: they allow stochastic rule systems to be augmented with additional syntactic, semantic, and pragmatic features.</citsent>
<aftsection>
<nextsent>however, the richness of the representations is not without cost.
</nextsent>
<nextsent>even modest me models can require considerable computational resources and very large quantities of annotated training data in order to accurately estimate the models parameters.
</nextsent>
<nextsent>while parameter estimation for me models is conceptually straightforward, in practice me models for typical natural language tasks are usually quite large, and frequently contain hundreds of thousands of free parameters.
</nextsent>
<nextsent>estimation of such large models is not only expensive, but also, due to sparsely distributed features, sensitive to round-off errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3005">
<title id=" W02-2018.xml">a comparison of algorithms for maximum entropy parameter estimation </title>
<section> comparing estimation techniques.  </section>
<citcontext>
<prevsection>
<prevsent>the summary?
</prevsent>
<prevsent>dataset is part of sentence extraction task (osborne, to appear), and the shallow?
</prevsent>
</prevsection>
<citsent citstr=" W02-0401 ">
dataset is drawn from text chunking application (osborne, 2002).<papid> W02-0401 </papid></citsent>
<aftsection>
<nextsent>these datasets vary widely in their size and composition, and are representative of the kinds of datasets typically encountered in applying me models to nlp classification tasks.the results of applying each of the parameter estimation algorithms to each of the datasets is summarized in table 2.
</nextsent>
<nextsent>for each run, we report the kldivergence between the fitted model and the training data at convergence, the prediction accuracy of fitted model on held-out test set (the fraction of contexts for which the event with the highest probability under the model also had the highest probability under the reference distribution), the number of iterations required, the number of log-likelihood and gradient evaluations required (algorithms which use line search may require several function evaluations per iteration), and the total elapsed time (in seconds).2 there are few things to observe about these results.
</nextsent>
<nextsent>first, while iis converges in fewer steps the gis, it takes substantially more time.
</nextsent>
<nextsent>at least for this implementation, the additional bookkeeping overhead required by iis more than cancels any improvements in speed offered by accelerated convergence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3006">
<title id=" W02-0902.xml">learning a translation lexicon from monolingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>noun translation accuracy of39% scored against parallel test corpus could be achieved.
</prevsent>
<prevsent>recently, there has been surge in research in machine translation that is based on empirical methods.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
the seminal work by brown et al [1990] <papid> J90-2002 </papid>at ibm on the candide system laid the foundation for much of the current work in statistical machine translation (smt).</citsent>
<aftsection>
<nextsent>some of this work has been re-implementedand is freely available for research purposes [al onaizan et al, 1999].
</nextsent>
<nextsent>roughly speaking, smt divides the task of translation into two steps: word-level translation model and model for word reordering during the translation process.
</nextsent>
<nextsent>the statistical models are trained on parallel corpora: large amounts of text in one language along with their translation in another.
</nextsent>
<nextsent>various parallel texts have recently become available, mostly from government sources such as parliament proceedings (the canadian hansard, the minutes of the european parliament1) or law texts (from hong kong).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3007">
<title id=" W02-0902.xml">learning a translation lexicon from monolingual corpora </title>
<section> clues.  </section>
<citcontext>
<prevsection>
<prevsent>this measurement can be formalized as the number of letters common in sequence between the two words, divided by the length of the longer word.
</prevsent>
<prevsent>the example word pair friend and freund shares 5 letters (fr-e-nd), and both words have length 6, hence there spelling similarity is 5/6, or0.83.
</prevsent>
</prevsection>
<citsent citstr=" W95-0115 ">
this measurement is called longest common sub sequence ratio [melamed, 1995].<papid> W95-0115 </papid></citsent>
<aftsection>
<nextsent>in related work, string edit distance (or, lev enshtein distance) has been used [mann and yarowski, 2001].<papid> N01-1020 </papid></nextsent>
<nextsent>with this computational means at hand, we can now measure the spelling similarity between every german and english word, and sort possible word pairs accordingly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3008">
<title id=" W02-0902.xml">learning a translation lexicon from monolingual corpora </title>
<section> clues.  </section>
<citcontext>
<prevsection>
<prevsent>the example word pair friend and freund shares 5 letters (fr-e-nd), and both words have length 6, hence there spelling similarity is 5/6, or0.83.
</prevsent>
<prevsent>this measurement is called longest common sub sequence ratio [melamed, 1995].<papid> W95-0115 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
in related work, string edit distance (or, lev enshtein distance) has been used [mann and yarowski, 2001].<papid> N01-1020 </papid></citsent>
<aftsection>
<nextsent>with this computational means at hand, we can now measure the spelling similarity between every german and english word, and sort possible word pairs accordingly.
</nextsent>
<nextsent>by going through this list starting at the top we can collect new word pairs.
</nextsent>
<nextsent>we do this is in greedy fashion ? once word is assigned to word pair, we do not look for another match.
</nextsent>
<nextsent>table 2 gives the top 24 generated word pairs by this algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3009">
<title id=" W02-0902.xml">learning a translation lexicon from monolingual corpora </title>
<section> clues.  </section>
<citcontext>
<prevsection>
<prevsent>context, as we understand it here, is defined by the frequencies of context words in surrounding positions.
</prevsent>
<prevsent>this local context has to be translated into the other language, and we can search the word with the most similar context.this idea has already been investigated in earlier work.
</prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
rapp [1995, <papid> P95-1050 </papid>1999] proposes to collect counts over words occurring in four word window around the target word.</citsent>
<aftsection>
<nextsent>for each occurrence of target word, counts are collected over how often certain context words occur in the two positions directly ahead of the target word andthe two following positions.
</nextsent>
<nextsent>the counts are collected separately for each position and then entered into in context vector with an dimension for each context word in each position.
</nextsent>
<nextsent>finally, the raw counts are normalized, so that for each of the four word positions the vector values add up to one.
</nextsent>
<nextsent>vector comparison is done by adding all absolute differences of all components.fung and yee [1998] <papid> P98-1069 </papid>propose similar approach: they count how often another word occurs in the same sentence as the target word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3010">
<title id=" W02-0902.xml">learning a translation lexicon from monolingual corpora </title>
<section> clues.  </section>
<citcontext>
<prevsection>
<prevsent>the counts are collected separately for each position and then entered into in context vector with an dimension for each context word in each position.
</prevsent>
<prevsent>finally, the raw counts are normalized, so that for each of the four word positions the vector values add up to one.
</prevsent>
</prevsection>
<citsent citstr=" P98-1069 ">
vector comparison is done by adding all absolute differences of all components.fung and yee [1998] <papid> P98-1069 </papid>propose similar approach: they count how often another word occurs in the same sentence as the target word.</citsent>
<aftsection>
<nextsent>the counts are then normalized by using the tf/idf method which is often used in information retrieval [jones, 1979].
</nextsent>
<nextsent>the need for translating the context poses chicken-and-egg problem: if we already have translation lexicon we can translate the context vectors.
</nextsent>
<nextsent>but we can only construct translation lexicon with this approach if we are already able to translate the context vectors.theoretically, it is possible to use these methods to build translation lexicon from scratch [rapp, 1995].<papid> P95-1050 </papid></nextsent>
<nextsent>the number of possible mappings has complexity o(n!), and the computing cost of each mapping has quadratic complexity o(n2).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3012">
<title id=" W02-0902.xml">learning a translation lexicon from monolingual corpora </title>
<section> clues.  </section>
<citcontext>
<prevsection>
<prevsent>we collect then the best word matches in greedy fashion.
</prevsent>
<prevsent>table 3 displays the top 15 generated word pairs by this algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
the context vectors are constructed in the way proposed by rapp [1999], <papid> P99-1067 </papid>with the difference that we collect counts over four noun window, not four word window, by dropping all intermediate words.</citsent>
<aftsection>
<nextsent>german english score jahr mr 5.03024 wrong regie rung government 5.54937 correct prozent percent 5.57756 correct angabe us 5.73654 wrong mittwoch company 5.83199 wrong donner stag time 5.90623 wrong prasident president 5.93884 correct dien stag year 5.94611 wrong staat state 5.96725 correct zeit people 6.05552 wrong freitag officials 6.11668 wrong montag week 6.13604 wrong krieg war 6.13604 correct woche yesterday 6.15378 wrong krankheit disease 6.20817 correct kirche church 6.21477 correct unternehmen companies 6.22896 correct ende money 6.28154 wrong streik strike 6.28690 correct energie energy 6.29883 correct ol oil 6.30794 correct markt market 6.31116 correct wirtschaft economy 6.34883 correct sonntag group 6.34917 wrong table 3: first 24 word pairs collected by finding words with most similar context vectors in greedy fashion.
</nextsent>
<nextsent>2.4 preserving word similarity.
</nextsent>
<nextsent>intuitively it is obvious that pairs of words thatare similar in one language should have translations that are similar in the other language.
</nextsent>
<nextsent>for instance, wednesday is similar to thursday as mittwoch is similar to donnerstag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3013">
<title id=" W03-0604.xml">towards a framework for learning structured shape models from text annotated images </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>however, this assumption is very restrictive from the computer vision standpoint, and fails to account for two important properties of image segmentation: 1) objects often consist of multiple parts, each captured by an individual region; and 2) individual regions are often over-segmented into multiple subregions.
</prevsent>
<prevsent>moreover, this assumption also fails to capture the structural relations among words, e.g., part/whole relations.we outline general framework that accommodates many-to-many mapping between image regions and words, allowing for structured descriptions on both sides.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
in this paper,we describe our extensions to the probabilistic translation model of brown et al (1993) (<papid> J93-2003 </papid>asin duygulu et al (2002)) that enable the creation of structured models of image objects.</citsent>
<aftsection>
<nextsent>we demonstrate our work in progress, in which set of annotated images is used to derive setof labeled, structured descriptions in the presence of oversegmentation.
</nextsent>
<nextsent>researchers in computervision and computational linguistics have similar goals in their desire to automatically associate semantic information with the visual or linguistic representations they extract from an image or text.
</nextsent>
<nextsent>given paired image and text data, one approach0wachsmuth is supported by the german research foundation (dfg).
</nextsent>
<nextsent>stevenson and dickinson gratefully acknowledge the support of nserc of canada.is to use the visual and linguistic representations as implicit semantics for each other that is, using the wordsas names for the visual features, and using the image objects as referents for the words in the text (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3019">
<title id=" W03-0604.xml">towards a framework for learning structured shape models from text annotated images </title>
<section> 3001 </section>
<citcontext>
<prevsection>
<prevsent>terion does not apply because the silhouette of the merged structure does not appear in the rest of the dataset.
</prevsent>
<prevsent>since the current translation model has no information about the whole object, merging the component regions cannot increase the quality of the translation model.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
instead, we develop new scoring criterion, based on melamed (1997).<papid> W97-0311 </papid></citsent>
<aftsection>
<nextsent>first, the current translation model is used to induce translation links between words and regions, and the mutual information of words and regions is calculated, using the link counts for the joint distribution.
</nextsent>
<nextsent>next, the increas ein mutual information is estimated for hypothetical dataset # in which the regions of potential compounds are merged.
</nextsent>
<nextsent>if compound contributes to an increase in mutual information in # , then the merge is added to our dataset.
</nextsent>
<nextsent>5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3021">
<title id=" W03-0809.xml">automatic creation of interface specifications from ontologies </title>
<section> application in dialogue system.  </section>
<citcontext>
<prevsection>
<prevsent>smartkom supports speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states.
</prevsent>
<prevsent>on the output side, the system features gesturing and speaking life-like character together with displayed generated text and multimedia graphical output.
</prevsent>
</prevsection>
<citsent citstr=" W03-0811 ">
the system currently comprises nearly 50 modules running on parallel virtual machine-based integration software called multi platform (herzog et al, 2003).<papid> W03-0811 </papid></citsent>
<aftsection>
<nextsent>the modules exchange messages whose content is encoded in xml.
</nextsent>
<nextsent>the interfaces are defined by set of xml schemata.
</nextsent>
<nextsent>the part of them containing the systems knowledge about application domains was obtained viathe automatic transformation of an oil-rdfs ontology (gurevych et al, 2003<papid> W03-0903 </papid>b).</nextsent>
<nextsent>thusly, all components of the system operate on common knowledge store xml schemata resulting from the ontology transformation, e. g., the parser (engel, 2002), the dialogue manager (lockelt et al, 2002).in this trial, our initial hypothesis that employing onto logical knowledge for interface specifications will make them more consistent, better-structured and more read able as compared to manually defined interfaces was fullysatisfied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3022">
<title id=" W03-0809.xml">automatic creation of interface specifications from ontologies </title>
<section> application in dialogue system.  </section>
<citcontext>
<prevsection>
<prevsent>the modules exchange messages whose content is encoded in xml.
</prevsent>
<prevsent>the interfaces are defined by set of xml schemata.
</prevsent>
</prevsection>
<citsent citstr=" W03-0903 ">
the part of them containing the systems knowledge about application domains was obtained viathe automatic transformation of an oil-rdfs ontology (gurevych et al, 2003<papid> W03-0903 </papid>b).</citsent>
<aftsection>
<nextsent>thusly, all components of the system operate on common knowledge store xml schemata resulting from the ontology transformation, e. g., the parser (engel, 2002), the dialogue manager (lockelt et al, 2002).in this trial, our initial hypothesis that employing onto logical knowledge for interface specifications will make them more consistent, better-structured and more read able as compared to manually defined interfaces was fullysatisfied.
</nextsent>
<nextsent>some additional advantages that were not anticipated originally also resulted from this approach.
</nextsent>
<nextsent>enhancing the oil-rdfs data typing capabilities: as previously stated, ontologies are suitable means for specifying high-level domain knowledge.
</nextsent>
<nextsent>however, if knowledge represented in the ontology is to become partof the common xml schema based representation exchanged between the modules, it is important to have amechanism for referencing structures, i. e., data types defined elsewhere in larger xml context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3030">
<title id=" W02-1703.xml">a brief introduction to the gem annotation schema for complex document layout </title>
<section> annotation content.  </section>
<citcontext>
<prevsection>
<prevsent>although it is (a) widely accepted that data for designing and improving natural language processing can best be made available in theform of structured, standardized annotated corpora and (b) increasingly accepted that such data should stretch to include more than the traditional concerns of linguisticsi.e., speech and plain text dataand take in more visually challenging presentations, movements in this direction have to date been very limited.the gem annotation scheme is being developed in order to support analyses of the broader range of layout-text-graphical interactions thatis commonplace in professionally designed documents.
</prevsent>
<prevsent>we are currently annotating an exploratory corpus in order to bring out the complex interrelationships that can be observed within page-based information delivery.
</prevsent>
</prevsection>
<citsent citstr=" J01-3004 ">
the starting basis for our annotation drawson some detailed non-computational accounts of the organization of multimodal pages/documentsmost specifically, the seminal account of constraints on document design by waller (1987)and exploratory computational accounts such as the layout structures introduced by bateman et al (2001).<papid> J01-3004 </papid></citsent>
<aftsection>
<nextsent>this organization reflects both artefact-internal considerations such as the layout, text and graphics, as well as artefact-external considerations such as design decisions, production constraints (e.g., cost), and artefact constraints (i.e., the limited size of piece of paper contrasted with the theoretically unbounded scroll able window on computer screen).
</nextsent>
<nextsent>these external considerations are often connected.
</nextsent>
<nextsent>the ideal?
</nextsent>
<nextsent>layout of information on page might as consequence never occur: it must be folded in?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3031">
<title id=" W03-0302.xml">pro align shared task system description </title>
<section> alignment algorithm at glance.  </section>
<citcontext>
<prevsection>
<prevsent>it received 5.71% aer onthe english-french task and 29.36% on the romanian english task.
</prevsent>
<prevsent>these results are with the no-null data; our output was not formatted to work with explicit nulls.proalign works by iteratively improving an alignment.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
the algorithm creates an initial alignment using search, constraints, and summed 2 correlation-based scores (gale and church, 1991).<papid> H91-1026 </papid></citsent>
<aftsection>
<nextsent>this is similar to the competitive linking process (melamed, 2000).<papid> J00-2004 </papid></nextsent>
<nextsent>it then learns probability model from the current alignment,and conducts constrained search again, this time scoring alignments according to the probability model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3032">
<title id=" W03-0302.xml">pro align shared task system description </title>
<section> alignment algorithm at glance.  </section>
<citcontext>
<prevsection>
<prevsent>these results are with the no-null data; our output was not formatted to work with explicit nulls.proalign works by iteratively improving an alignment.
</prevsent>
<prevsent>the algorithm creates an initial alignment using search, constraints, and summed 2 correlation-based scores (gale and church, 1991).<papid> H91-1026 </papid></prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
this is similar to the competitive linking process (melamed, 2000).<papid> J00-2004 </papid></citsent>
<aftsection>
<nextsent>it then learns probability model from the current alignment,and conducts constrained search again, this time scoring alignments according to the probability model.
</nextsent>
<nextsent>the process continues until results on validation set begin to indicate over-fitting.for the purposes of our algorithm, we view an alignment as set of links between the words in sentence pair.
</nextsent>
<nextsent>before describing the algorithm, we will define the following notation.
</nextsent>
<nextsent>let be an english sentence e1, e2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3035">
<title id=" W03-0302.xml">pro align shared task system description </title>
<section> constraints.  </section>
<citcontext>
<prevsection>
<prevsent>the model used for scoring alignments has no mechanism to prevent certain types of undesirable alignments,such as having all french words align to the same english word.
</prevsent>
<prevsent>to guide the search to correct alignments, we employ two constraints to limit our search for the most probable alignment.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
the first constraint is the one-to-one constraint (melamed, 2000): <papid> J00-2004 </papid>every word (except the null words e0 and f0) participates in exactly one link.the second constraint, known as the cohesion constraint (fox, 2002), <papid> W02-1039 </papid>uses the dependency tree (melcuk, 1987) of the english sentence to restrict possible linkcombinations.</citsent>
<aftsection>
<nextsent>given the dependency tree te and (par tial) alignment a, the cohesion constraint requires that phrasal cohesion is maintained in the french sentence.
</nextsent>
<nextsent>iftwo phrases are disjoint in the english sentence, the alignment must not map them to overlapping intervals in the french sentence.
</nextsent>
<nextsent>this notion of phrasal constraints on alignments need not be restricted to phrases determined from dependency structure.
</nextsent>
<nextsent>however, the experiments conducted in (fox, 2002) <papid> W02-1039 </papid>indicate that dependency trees demonstrate higher degree of phrasal cohesion during translation than other structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3041">
<title id=" W03-0302.xml">pro align shared task system description </title>
<section> constraints.  </section>
<citcontext>
<prevsection>
<prevsent>since both rebootand discover modify causes, this creates modifier modifier overlap.
</prevsent>
<prevsent>one can check for constraint violations inexpensively by incrementally updating the various spans as new links are added to the partial alignment, and checking for overlap after each modification.
</prevsent>
</prevsection>
<citsent citstr=" N03-2017 ">
more details on the cohesion constraint can be found in (lin and cherry, 2003).<papid> N03-2017 </papid></citsent>
<aftsection>
<nextsent>we define the word alignment problem as finding the alignment that maximizes (a|e,f ).
</nextsent>
<nextsent>pro align models (a|e,f ) directly, using different decomposition of terms than the model used by ibm (brown et al,1993).<papid> J93-2003 </papid></nextsent>
<nextsent>in the ibm models of translation, alignments exist as artifacts of stochastic process, where the words in the english sentence generate the words in the french sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3042">
<title id=" W03-0302.xml">pro align shared task system description </title>
<section> probability model.  </section>
<citcontext>
<prevsection>
<prevsent>more details on the cohesion constraint can be found in (lin and cherry, 2003).<papid> N03-2017 </papid></prevsent>
<prevsent>we define the word alignment problem as finding the alignment that maximizes (a|e,f ).</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
pro align models (a|e,f ) directly, using different decomposition of terms than the model used by ibm (brown et al,1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in the ibm models of translation, alignments exist as artifacts of stochastic process, where the words in the english sentence generate the words in the french sentence.
</nextsent>
<nextsent>our model does not assume that one sentence generates the other.
</nextsent>
<nextsent>instead it takes both sentences as given, and uses the sentences to determine an alignment.
</nextsent>
<nextsent>an alignment consists of links {l1, l2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3045">
<title id=" W03-0302.xml">pro align shared task system description </title>
<section> probability model.  </section>
<citcontext>
<prevsection>
<prevsent>k=1 ? (lk|eik , fjk)?
</prevsent>
<prevsent>ftftk (ft |lk) (ft |eik , fjk) ? ?
</prevsent>
</prevsection>
<citsent citstr=" P03-1012 ">
more details on the probability model used by pro align are available in (cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>3.1 features used in the shared task.
</nextsent>
<nextsent>for the purposes of the shared task, we use two feature types.
</nextsent>
<nextsent>each type could have any number of instantiations for any number of contexts.
</nextsent>
<nextsent>note that each feature type is described in terms of the context surrounding word pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3047">
<title id=" W03-0210.xml">a hybrid text classification approach for analysis of student essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a computer tutor then engages the student ina natural language dialogue to provide feedback, correct misconceptions, and to elicit more complete explanations.
</prevsent>
<prevsent>the first version of why2-atlas was deployed and evaluated with undergraduate students in the spring of 2002; the system is continuing to be actively developed (graesser et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P98-1032 ">
in contrast to many previous approaches to automated essay grading (burstein et al, 1998; <papid> P98-1032 </papid>foltz et al, 1998; larkey, 1998), our goal is not to assign letter grade to student essays.</citsent>
<aftsection>
<nextsent>instead, our purpose is totally which set of correct answer aspects?
</nextsent>
<nextsent>are present in student essays.
</nextsent>
<nextsent>for example, we expect satisfactory answers to the example question above to include detailed explanation of how newtons first law applies to this scenario.
</nextsent>
<nextsent>from newtons first law, the student should infer that the pumpkin and the man will continue at the same constant horizontal velocity that they both had before the release.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3048">
<title id=" W03-0210.xml">a hybrid text classification approach for analysis of student essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, after the pumpkin rises and falls, it will land back in the mans hands.
</prevsent>
<prevsent>our goal is to coach students through the process of constructing good physics explanations.
</prevsent>
</prevsection>
<citsent citstr=" P01-1014 ">
thus, our focus is on the physics content and not the quality of the students writing, in contrast to (burstein et al, 2001).<papid> P01-1014 </papid></citsent>
<aftsection>
<nextsent>we cast the student essay analysis problem as text classification problem where we classify each sentence inthe students essay as an expression one of set of correct answer aspects?, or nothing?
</nextsent>
<nextsent>in the case where no correct answer aspect?
</nextsent>
<nextsent>was expressed.after student attempts an initial answer to the question, the system analyzes the students essay to assess which key points are missing from the students argument.
</nextsent>
<nextsent>the system then uses its analysis of the students essay to determine which help to offer that student.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3049">
<title id=" W03-0210.xml">a hybrid text classification approach for analysis of student essays </title>
<section> carmeltc.  </section>
<citcontext>
<prevsection>
<prevsent>using the individual features extracted from the deep syntactic analysis of the input as well asthe bag of words?
</prevsent>
<prevsent>naive bayes classification of the in put sentence, carmeltc builds vector representation of each input sentence, with each vector position corresponding to one of these features.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
we then use the id3decision tree learning algorithm (mitchell, 1997; quin lin, 1993) to induce rules for identifying sentence classes based on these feature vectors.the symbolic features used for the carmeltc approach are extracted from deep syntactic functional analysis constructed using the carmel broad coverage english syntactic parsing grammar (rose?, 2000) and the large scale comlex lexicon (grishman et al, 1994), <papid> C94-1042 </papid>containing 40,000 lexical items.</citsent>
<aftsection>
<nextsent>for parsing we use an incremental version of the lcflex robust parser (rose?
</nextsent>
<nextsent>et al, 2002b; rose?
</nextsent>
<nextsent>and lavie, 2001), which was designed for efficient, robust interpretation.
</nextsent>
<nextsent>while computing adeep syntactic analysis is more computationally expensive than computing shallow syntactic analysis, we can do so very efficiently using the incremental ized version of lcflex because it takes advantage of student typing time to reduce the time delay between when students submit their essays and when the system is prepared to respond.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3050">
<title id=" W03-0315.xml">efficient optimization for bilingual sentence alignment based on linear regression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when faced with different, unseen text genre, however, translation performance usually drops noticeably.
</prevsent>
<prevsent>one way to remedy this situation is to adapt and retrain the system parameters based on bilingual data from the same source or at least closely related source.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
a bilingual sentence alignment program (gale and church, 1991, <papid> P91-1023 </papid>and brown et al, 1991) <papid> P91-1022 </papid>is the crucial part in this adaptation procedure, in that it collects bilingual document pairs from the internet, and identifies sentence pairs, which should have high likelihood of being correct translations of each other.</citsent>
<aftsection>
<nextsent>the set of identified bilingual parallel sentence pairs is then added to the training set for parameter reestimation.
</nextsent>
<nextsent>as is well known, text mined from the internet is very noisy.
</nextsent>
<nextsent>even after careful html parsing and filtering for text size and language, the text from comparable html-page pairs still contains mismatches of content or non-parallel junk text, and the sentence order can be too different to be aligned.
</nextsent>
<nextsent>together with large mismatch of vocabulary, the aligned sentence pairs, which are extracted from these collected comparable html-page pairs, contain number of low translation quality alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3051">
<title id=" W03-0315.xml">efficient optimization for bilingual sentence alignment based on linear regression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when faced with different, unseen text genre, however, translation performance usually drops noticeably.
</prevsent>
<prevsent>one way to remedy this situation is to adapt and retrain the system parameters based on bilingual data from the same source or at least closely related source.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
a bilingual sentence alignment program (gale and church, 1991, <papid> P91-1023 </papid>and brown et al, 1991) <papid> P91-1022 </papid>is the crucial part in this adaptation procedure, in that it collects bilingual document pairs from the internet, and identifies sentence pairs, which should have high likelihood of being correct translations of each other.</citsent>
<aftsection>
<nextsent>the set of identified bilingual parallel sentence pairs is then added to the training set for parameter reestimation.
</nextsent>
<nextsent>as is well known, text mined from the internet is very noisy.
</nextsent>
<nextsent>even after careful html parsing and filtering for text size and language, the text from comparable html-page pairs still contains mismatches of content or non-parallel junk text, and the sentence order can be too different to be aligned.
</nextsent>
<nextsent>together with large mismatch of vocabulary, the aligned sentence pairs, which are extracted from these collected comparable html-page pairs, contain number of low translation quality alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3052">
<title id=" W03-0315.xml">efficient optimization for bilingual sentence alignment based on linear regression </title>
<section> system of mining parallel text.  </section>
<citcontext>
<prevsection>
<prevsent>one crucial component of statistical machine translation (smt) system is the parallel text mining from internet.
</prevsent>
<prevsent>several processing modules are applied to collect, extract, convert, and clean the text from internet.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
the components in our system include: ? web crawler, which collects potential parallel html documents based on link information following (philip resnik 1999); ? <papid> P99-1068 </papid>bilingual html parser (based on flex for effi ciency), which is designed for both chinese and english html documents.</citsent>
<aftsection>
<nextsent>the paragraphs?
</nextsent>
<nextsent>boundaries within the html structure are kept.
</nextsent>
<nextsent>a character encoding detector, which judges if the chinese html document is gb2312 encoding or big5 encoding.
</nextsent>
<nextsent>an encoding converter, which converts the big5 documents to gb2312 encoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3053">
<title id=" W03-0315.xml">efficient optimization for bilingual sentence alignment based on linear regression </title>
<section> system of mining parallel text.  </section>
<citcontext>
<prevsection>
<prevsent>a more reliable re-scoring of the data is desirable to estimate the alignment quality as postprocessing step to filter out the errors and noise from the aligned data.
</prevsent>
<prevsent>2.2 statistical translation lexicon.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use statistical translation lexicon known as ibm model-1 in (brown et al, 1993) <papid> J93-2003 </papid>for both efficiency and simplicity.</citsent>
<aftsection>
<nextsent>in our approach, model-1 is the conditional probability that word in the source language is translated given word in the target language, t(f|e).
</nextsent>
<nextsent>this probability can be reliably estimated using the expectation maximization (em) algorithm (cavnar, w. b. and j. m. trenkle, 1994).
</nextsent>
<nextsent>given training data consisting of parallel sen tences: }..1),,{( )()( sief ii = , our model-1 training for t(f|e) is as follows: ? = ? = s ss efefceft 1 )()(1 ),;|()|( ? where 1?
</nextsent>
<nextsent>e? is normalization factor such that 0.1)|( = ? j eft ),;|( )()( ss efefc denotes the expected number of times that word connects to word f. ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3058">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in an experiment with domain specific korean to english translation, the approach yielded substantial improvements over three base line systems.
</prevsent>
<prevsent>in this paper, we describe the design of an mt system that employs transfer rules induced from parsed bitexts and present evaluation results for korean to english translation.
</prevsent>
</prevsection>
<citsent citstr=" C90-3044 ">
our approach is based on lexico-structural transfer (nasr et. al., 1997), and extends recent work reported in (han et al, 2000) about korean to english transfer in particular.whereas han et al focus on high quality domain specific translation using handcrafted transfer rules,in this work we instead focus on automating the acquisition of such rules.the proposed approach is inspired by example based machine translation (ebmt; nagao, 1984; sato and nagao, 1990; <papid> C90-3044 </papid>maruyama and watanabe,1992) and is similar to the recent works of (mey ers et al, 1998) <papid> P98-2139 </papid>and (richardson et al, 2001) <papid> W01-1402 </papid>where transfer rules are also derived after aligning the source and target nodes of corresponding parses.however, while (meyers et al, 1998) <papid> P98-2139 </papid>and (richard sonet al, 2001) <papid> W01-1402 </papid>only consider parses and rules with lexical labels and syntactic roles, our approach uses parses containing any syntactic information provided by parsers (lexical labels, syntactic roles,tense, number, person, etc.), and derives rules consisting of any source and target tree sub-patternsmatching subset of the parse features.</citsent>
<aftsection>
<nextsent>a more detailed description of the differences can be found in (lavoie et. al., 2001).<papid> W01-1403 </papid></nextsent>
<nextsent>our korean to english mt runtime system relies on the following off-the-shelf software components:korean parser for parsing, we used the wide coverage syntactic dependency parser for korean developed by (yoon et al, 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3059">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in an experiment with domain specific korean to english translation, the approach yielded substantial improvements over three base line systems.
</prevsent>
<prevsent>in this paper, we describe the design of an mt system that employs transfer rules induced from parsed bitexts and present evaluation results for korean to english translation.
</prevsent>
</prevsection>
<citsent citstr=" P98-2139 ">
our approach is based on lexico-structural transfer (nasr et. al., 1997), and extends recent work reported in (han et al, 2000) about korean to english transfer in particular.whereas han et al focus on high quality domain specific translation using handcrafted transfer rules,in this work we instead focus on automating the acquisition of such rules.the proposed approach is inspired by example based machine translation (ebmt; nagao, 1984; sato and nagao, 1990; <papid> C90-3044 </papid>maruyama and watanabe,1992) and is similar to the recent works of (mey ers et al, 1998) <papid> P98-2139 </papid>and (richardson et al, 2001) <papid> W01-1402 </papid>where transfer rules are also derived after aligning the source and target nodes of corresponding parses.however, while (meyers et al, 1998) <papid> P98-2139 </papid>and (richard sonet al, 2001) <papid> W01-1402 </papid>only consider parses and rules with lexical labels and syntactic roles, our approach uses parses containing any syntactic information provided by parsers (lexical labels, syntactic roles,tense, number, person, etc.), and derives rules consisting of any source and target tree sub-patternsmatching subset of the parse features.</citsent>
<aftsection>
<nextsent>a more detailed description of the differences can be found in (lavoie et. al., 2001).<papid> W01-1403 </papid></nextsent>
<nextsent>our korean to english mt runtime system relies on the following off-the-shelf software components:korean parser for parsing, we used the wide coverage syntactic dependency parser for korean developed by (yoon et al, 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3060">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in an experiment with domain specific korean to english translation, the approach yielded substantial improvements over three base line systems.
</prevsent>
<prevsent>in this paper, we describe the design of an mt system that employs transfer rules induced from parsed bitexts and present evaluation results for korean to english translation.
</prevsent>
</prevsection>
<citsent citstr=" W01-1402 ">
our approach is based on lexico-structural transfer (nasr et. al., 1997), and extends recent work reported in (han et al, 2000) about korean to english transfer in particular.whereas han et al focus on high quality domain specific translation using handcrafted transfer rules,in this work we instead focus on automating the acquisition of such rules.the proposed approach is inspired by example based machine translation (ebmt; nagao, 1984; sato and nagao, 1990; <papid> C90-3044 </papid>maruyama and watanabe,1992) and is similar to the recent works of (mey ers et al, 1998) <papid> P98-2139 </papid>and (richardson et al, 2001) <papid> W01-1402 </papid>where transfer rules are also derived after aligning the source and target nodes of corresponding parses.however, while (meyers et al, 1998) <papid> P98-2139 </papid>and (richard sonet al, 2001) <papid> W01-1402 </papid>only consider parses and rules with lexical labels and syntactic roles, our approach uses parses containing any syntactic information provided by parsers (lexical labels, syntactic roles,tense, number, person, etc.), and derives rules consisting of any source and target tree sub-patternsmatching subset of the parse features.</citsent>
<aftsection>
<nextsent>a more detailed description of the differences can be found in (lavoie et. al., 2001).<papid> W01-1403 </papid></nextsent>
<nextsent>our korean to english mt runtime system relies on the following off-the-shelf software components:korean parser for parsing, we used the wide coverage syntactic dependency parser for korean developed by (yoon et al, 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3063">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe the design of an mt system that employs transfer rules induced from parsed bitexts and present evaluation results for korean to english translation.
</prevsent>
<prevsent>our approach is based on lexico-structural transfer (nasr et. al., 1997), and extends recent work reported in (han et al, 2000) about korean to english transfer in particular.whereas han et al focus on high quality domain specific translation using handcrafted transfer rules,in this work we instead focus on automating the acquisition of such rules.the proposed approach is inspired by example based machine translation (ebmt; nagao, 1984; sato and nagao, 1990; <papid> C90-3044 </papid>maruyama and watanabe,1992) and is similar to the recent works of (mey ers et al, 1998) <papid> P98-2139 </papid>and (richardson et al, 2001) <papid> W01-1402 </papid>where transfer rules are also derived after aligning the source and target nodes of corresponding parses.however, while (meyers et al, 1998) <papid> P98-2139 </papid>and (richard sonet al, 2001) <papid> W01-1402 </papid>only consider parses and rules with lexical labels and syntactic roles, our approach uses parses containing any syntactic information provided by parsers (lexical labels, syntactic roles,tense, number, person, etc.), and derives rules consisting of any source and target tree sub-patternsmatching subset of the parse features.</prevsent>
</prevsection>
<citsent citstr=" W01-1403 ">
a more detailed description of the differences can be found in (lavoie et. al., 2001).<papid> W01-1403 </papid></citsent>
<aftsection>
<nextsent>our korean to english mt runtime system relies on the following off-the-shelf software components:korean parser for parsing, we used the wide coverage syntactic dependency parser for korean developed by (yoon et al, 1997).
</nextsent>
<nextsent>the parser was not trained on our corpus.
</nextsent>
<nextsent>transfer component for transfer of the korean parses to english structures, we used the same lexico-structural transfer framework as (lavoie et al, 2000).<papid> A00-1009 </papid></nextsent>
<nextsent>realizer for surface realization of the transferred english syntactic structures, we used there alpro english realizer (lavoie and rambow, 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3064">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> overall runtime system design.  </section>
<citcontext>
<prevsection>
<prevsent>our korean to english mt runtime system relies on the following off-the-shelf software components:korean parser for parsing, we used the wide coverage syntactic dependency parser for korean developed by (yoon et al, 1997).
</prevsent>
<prevsent>the parser was not trained on our corpus.
</prevsent>
</prevsection>
<citsent citstr=" A00-1009 ">
transfer component for transfer of the korean parses to english structures, we used the same lexico-structural transfer framework as (lavoie et al, 2000).<papid> A00-1009 </papid></citsent>
<aftsection>
<nextsent>realizer for surface realization of the transferred english syntactic structures, we used there alpro english realizer (lavoie and rambow, 1997).
</nextsent>
<nextsent>the training of the system is described in the next two sections.
</nextsent>
<nextsent>3.1 parses for the bitexts.
</nextsent>
<nextsent>in our experiments, we used parallel corpus derived from bilingual training manuals provided by the u.s. defense language institute.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3065">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> data preparation.  </section>
<citcontext>
<prevsection>
<prevsent>sentence size 9.08 13.26 avg.
</prevsent>
<prevsent>parse size 8.96 10.77 table 1: average sizes for sentences and parses in corpus tions were derived from an english tree bank developed in (han et al, 2000).
</prevsent>
</prevsection>
<citsent citstr=" H01-1014 ">
to enable the surface realization of the english parses via realpro, we automatically converted the phrase structures of the english tree bank into deep-syntactic dependency structures (dsyntss) of the meaning-texttheory (mtt) (melcuk, 1988) using xias converter (xia and palmer, 2001) <papid> H01-1014 </papid>and our own conversion grammars.</citsent>
<aftsection>
<nextsent>the realization results of there sulting dsyntss for our training corpus yielded aunigram and bigram accuracy (f-score) of approximately 95% and 90%, respectively.
</nextsent>
<nextsent>a dsynts is an unordered tree where all nodes are meaning-bearing and lexicalized.
</nextsent>
<nextsent>since the out put of the yoon parser is quite similar, we have usedits output as is. the syntactic dependency representations for two corresponding korean1 and english sentences are shown in figure 1.
</nextsent>
<nextsent>3.2 training and test sets of parse pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3067">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> transfer rule induction.  </section>
<citcontext>
<prevsection>
<prevsent>candidate transfer rules are generated by extracting source and target tree sub-patterns from the aligned parse pairs using the two set of constraints described below.
</prevsent>
<prevsent>4.2.1 alignment constraints figure 4 shows an example alignment constraint.this constraint, which matches the structural patterns of the transfer rule illustrated in figure 2, usesthe aid alignment attribute to indicate that in korean and english parse pair, any source and target sub-trees matching this alignment constraint (where$x1 and $y1 are aligned, i.e. have the same aid attribute values, and where $x2 and $y3 are aligned)can be used as point of departure for generating transfer rule candidates.
</prevsent>
</prevsection>
<citsent citstr=" J94-4004 ">
we suggest that alignment constraints such as this one can be used to define most of the possible syntactic divergences between languages (dorr, 1994), <papid> J94-4004 </papid>and that only handful of them are necessary for two given languages (we have identified 11 general alignment constraints @korean: $x1 [aid=$1] ( $r1 $x2 [aid=$2] ) @english: $y1 [aid=$1] ( $r2 $y2 ( $r3 $y3 [aid=$2] ) ) figure 4: alignment constraint each node of candidate transfer rule must have its relation attribute (relationship with its governor) specified if it is an internal node, otherwise this relation must not be specified: e.g.</citsent>
<aftsection>
<nextsent>$x1 ( $r $x2 ) figure 5: independent attribute constraint necessary for korean to english transfer so far).
</nextsent>
<nextsent>4.2.2 attribute constraints attribute constraints are used to limit the space of possible transfer rule candidates that can be generated from the sub-trees satisfying the alignment constraints.
</nextsent>
<nextsent>candidate transfer rules must satisfy all of the attribute constraints.
</nextsent>
<nextsent>attribute constraints can be divided into two types:
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3068">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>babel fish as first baseline, we used babel fish from systran, commercial large coverage mtsystem supporting korean to english translation.
</prevsent>
<prevsent>this system was not trained on our corpus.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
giza++/rw as second baseline, we used an off-the-shelf statistical mt system, consisting of the isi rewrite decoder (germann et al,2001) <papid> P01-1030 </papid>together with translation model produced by giza++ (och and ney, 2000) <papid> P00-1056 </papid>anda language model produced by the cmu statistical language modeling toolkit (clarkson and rosenfeld, 1997).</citsent>
<aftsection>
<nextsent>this system was trained on our corpus only.
</nextsent>
<nextsent>lex only as third baseline, we used our system with the baseline transfer dictionary as the sole transfer resource.lex+induced we compared the three baseline systems against our complete system, using the baseline transfer dictionary augmented with the induced transfer rules.
</nextsent>
<nextsent>we ran each of the four systems on the test set of 50 korean sentences described in section 3.2 and compared the resulting translations using the automatic evaluation and the human evaluation described below.
</nextsent>
<nextsent>5.2 automatic evaluation results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3069">
<title id=" W02-1610.xml">learning domain specific transfer rules an experiment with korean to english translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>babel fish as first baseline, we used babel fish from systran, commercial large coverage mtsystem supporting korean to english translation.
</prevsent>
<prevsent>this system was not trained on our corpus.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
giza++/rw as second baseline, we used an off-the-shelf statistical mt system, consisting of the isi rewrite decoder (germann et al,2001) <papid> P01-1030 </papid>together with translation model produced by giza++ (och and ney, 2000) <papid> P00-1056 </papid>anda language model produced by the cmu statistical language modeling toolkit (clarkson and rosenfeld, 1997).</citsent>
<aftsection>
<nextsent>this system was trained on our corpus only.
</nextsent>
<nextsent>lex only as third baseline, we used our system with the baseline transfer dictionary as the sole transfer resource.lex+induced we compared the three baseline systems against our complete system, using the baseline transfer dictionary augmented with the induced transfer rules.
</nextsent>
<nextsent>we ran each of the four systems on the test set of 50 korean sentences described in section 3.2 and compared the resulting translations using the automatic evaluation and the human evaluation described below.
</nextsent>
<nextsent>5.2 automatic evaluation results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3070">
<title id=" W02-0806.xml">assessing system agreement and instance difficulty in the lexical </title>
<section> pairwise system agreement.  </section>
<citcontext>
<prevsection>
<prevsent>(krippendorf,1980) points out that it is difficult to specify particular value of kappa as being generally indicative of agreement.
</prevsent>
<prevsent>as such we simply use kappa as tool for comparison and relative ranking.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
a detailed discussion on the use of kappa in natural language processing is presented in (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>july 2002, pp.
</nextsent>
<nextsent>40-46.
</nextsent>
<nextsent>association for computational linguistics.
</nextsent>
<nextsent>disambiguation: recent successes and future directions, philadelphia, proceedings of the siglex/senseval workshop on word sense table 1: lexical sample systems system correct instances name noun verb adj total (%) english 1754 1806 768 4328 (1.00) jhu final 1196 1022 562 2780 (0.64) smuls 1219 1016 528 2763 (0.64) kunlp 1171 1040 513 2724 (0.63) cs224n 1198 945 527 2670 (0.62) lia 1177 966 510 2653 (0.61) talp 1149 927 495 2571 (0.59) duluth3 1137 840 497 2473 (0.57) umcp 1081 891 487 2459 (0.57) ehu all 1069 891 480 2440 (0.56) duluth4 1065 806 476 2346 (0.54) duluth2 1056 795 483 2334 (0.54) lesk corp 960 804 454 2218 (0.51) duluthb 1004 729 467 2200 (0.51) uned ls 987 699 469 2155 (0.50) common 880 728 453 2061 (0.48) alicante 427 866 486 1779 (0.41) uned ls 781 519 437 1736 (0.40) clr ls 602 393 272 1267 (0.29) iit2 541 348 166 1054 (0.24) iit1 516 337 182 1034 (0.24) lesk 467 328 182 977 (0.23) lesk def 438 159 108 704 (0.16) random 303 153 155 611 (0.14) spanish 799 745 681 2225 (1.00) jhu 560 478 546 1584 (0.71) cs224 520 443 526 1489 (0.67) umcp 482 435 479 1396 (0.63) duluth8 494 382 494 1369 (0.62) duluth7 470 374 480 1324 (0.60) duluth9 445 359 446 1250 (0.56) duluthy 411 325 434 1170 (0.53) alicante 269 381 468 1118 (0.50)to study agreement we have made series of pairwise comparisons among the systems included in the english and spanish lexical sample tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3071">
<title id=" W03-1314.xml">exploring adjectival modification in biomedical discourse across two genres </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the predominance of adjectives in one corpus is analyzed.
</prevsent>
<prevsent>discussion: potential applications of this approach are discussed, namely terminology acquisition, information retrieval, and genre characterization.
</prevsent>
</prevsection>
<citsent citstr=" W02-0308 ">
in previous studies, we demonstrated the feasibility of using nlp techniques such as shallow parsing of adjectival modification for identifying hierarchical relations among biomedical terms (bodenreider et al, 2001) and for extending an existing biomedical terminology (bodenreider et al., 2002).<papid> W02-0308 </papid></citsent>
<aftsection>
<nextsent>in these studies, the corpus was biomedical terminology or phrases extracted from the biomedical literature.
</nextsent>
<nextsent>other authors have explored adjectival modification in clinical corpus.
</nextsent>
<nextsent>chute and elkin (1997) note, based on empirical observation of clinical data, that many clinical terms are accompanied by modifiers, including adjectives.
</nextsent>
<nextsent>the authors make distinction between clinical modifiers (such as chronic, severe, and acute) and operational or administrative qualifiers (such as no evidence of, history of, and status post).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3072">
<title id=" W03-1314.xml">exploring adjectival modification in biomedical discourse across two genres </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>(p.27) (i.e., big child) while relational adjectives are usually derived from and are somehow associated with noun (i.e., musical child).
</prevsent>
<prevsent>another prominent distinction has to do with whether an adjective can express continuous (scalar) or discrete (non-scalar) values.
</prevsent>
</prevsection>
<citsent citstr=" C96-2142 ">
raskin and niernburg (1996) <papid> C96-2142 </papid>point out that for text meaning representa 1 www.cogsci.princeton.edu/~wn/ tion for computational semantics, the most important distinction to make is between scalar and nonscalar.</citsent>
<aftsection>
<nextsent>they also present method for incorporating the semantics of the modifier adjective into the semantics of the modified noun by representing nouns as frames with elements such as attribute_size than can be filled in by the semantic content of the modifying adjectives.
</nextsent>
<nextsent>the major contribution of this study is to explore adjectival modification across two genres in the biomedical domain.
</nextsent>
<nextsent>our approach is essentially practical and oriented towards applied perspectives.
</nextsent>
<nextsent>the two genres compared in this study are the biomedical literature and patient records.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3073">
<title id=" W03-1314.xml">exploring adjectival modification in biomedical discourse across two genres </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>3 umlsinfo.nlm.nih.gov 4 also referred to as nested terms?
</prevsent>
<prevsent>in the literature step 1.
</prevsent>
</prevsection>
<citsent citstr=" A00-1026 ">
syntactic analysis the phrases in our bibliographic and clinical samples were then submitted to an underspecified syntactic analysis described by rindflesch et al (2000) <papid> A00-1026 </papid>that draws on stochastic tagger (see (cutting et al, 1992) <papid> A92-1018 </papid>for details) as well as the specialist lexicon5, large syntactic lexicon of both general and medical english that is distributed with the umls.</citsent>
<aftsection>
<nextsent>although not perfect, this combination of resources effectively addresses the phenomenon of part-of-speech ambiguity in english.
</nextsent>
<nextsent>the resulting syntactic structure identifies the head and modifiers for the noun phrase analyzed.
</nextsent>
<nextsent>each modifier is also labeled as being adjectival, adverbial, or nominal.
</nextsent>
<nextsent>although all types of modification in the simple english noun phrase were labeled, only adjectives and nouns were selected for further analysis in this study.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3074">
<title id=" W03-1314.xml">exploring adjectival modification in biomedical discourse across two genres </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>3 umlsinfo.nlm.nih.gov 4 also referred to as nested terms?
</prevsent>
<prevsent>in the literature step 1.
</prevsent>
</prevsection>
<citsent citstr=" A92-1018 ">
syntactic analysis the phrases in our bibliographic and clinical samples were then submitted to an underspecified syntactic analysis described by rindflesch et al (2000) <papid> A00-1026 </papid>that draws on stochastic tagger (see (cutting et al, 1992) <papid> A92-1018 </papid>for details) as well as the specialist lexicon5, large syntactic lexicon of both general and medical english that is distributed with the umls.</citsent>
<aftsection>
<nextsent>although not perfect, this combination of resources effectively addresses the phenomenon of part-of-speech ambiguity in english.
</nextsent>
<nextsent>the resulting syntactic structure identifies the head and modifiers for the noun phrase analyzed.
</nextsent>
<nextsent>each modifier is also labeled as being adjectival, adverbial, or nominal.
</nextsent>
<nextsent>although all types of modification in the simple english noun phrase were labeled, only adjectives and nouns were selected for further analysis in this study.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3076">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> background and other approaches.  </section>
<citcontext>
<prevsection>
<prevsent>second, we will show that it improves accuracy to flatten the parse trees and use flat, dependency-style rules like p(np put np pp | sput); this avoids overly strong independence assumptions, but it increases the number of unseen rules and so makes treebank grammars less tenable.
</prevsent>
<prevsent>third, backing off from the word is crude technique that does not distinguish among words.2 fourth, one would eventually like to reduce or eliminate supervision, and then generalization is important to constrain the search to reasonable grammars.to smooth the distribution p(rhs | lhs), one can define it in terms of set of parameters and then estimate those parameters.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
most researchers have used an n-gram model (eisner, 1996; <papid> C96-1058 </papid>charniak, 2000) <papid> A00-2018 </papid>or more general markov model (alshawi, 1996) to model the sequence of nonterminals in the rhs.</citsent>
<aftsection>
<nextsent>the sequence vput np pp in our example is then assumed to be emitted by some markov model of vpput rules (again with backoff from put).
</nextsent>
<nextsent>collins (1997, <papid> P97-1003 </papid>model 2) uses more sophisticated model in which all arguments in this sequence are generated jointly, as in treebank grammar, and then markov process is used to insert adjuncts among the arguments.</nextsent>
<nextsent>while treebank models overfit the training data, markov models underfit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3077">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> background and other approaches.  </section>
<citcontext>
<prevsection>
<prevsent>second, we will show that it improves accuracy to flatten the parse trees and use flat, dependency-style rules like p(np put np pp | sput); this avoids overly strong independence assumptions, but it increases the number of unseen rules and so makes treebank grammars less tenable.
</prevsent>
<prevsent>third, backing off from the word is crude technique that does not distinguish among words.2 fourth, one would eventually like to reduce or eliminate supervision, and then generalization is important to constrain the search to reasonable grammars.to smooth the distribution p(rhs | lhs), one can define it in terms of set of parameters and then estimate those parameters.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
most researchers have used an n-gram model (eisner, 1996; <papid> C96-1058 </papid>charniak, 2000) <papid> A00-2018 </papid>or more general markov model (alshawi, 1996) to model the sequence of nonterminals in the rhs.</citsent>
<aftsection>
<nextsent>the sequence vput np pp in our example is then assumed to be emitted by some markov model of vpput rules (again with backoff from put).
</nextsent>
<nextsent>collins (1997, <papid> P97-1003 </papid>model 2) uses more sophisticated model in which all arguments in this sequence are generated jointly, as in treebank grammar, and then markov process is used to insert adjuncts among the arguments.</nextsent>
<nextsent>while treebank models overfit the training data, markov models underfit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3078">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> background and other approaches.  </section>
<citcontext>
<prevsection>
<prevsent>most researchers have used an n-gram model (eisner, 1996; <papid> C96-1058 </papid>charniak, 2000) <papid> A00-2018 </papid>or more general markov model (alshawi, 1996) to model the sequence of nonterminals in the rhs.</prevsent>
<prevsent>the sequence vput np pp in our example is then assumed to be emitted by some markov model of vpput rules (again with backoff from put).</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
collins (1997, <papid> P97-1003 </papid>model 2) uses more sophisticated model in which all arguments in this sequence are generated jointly, as in treebank grammar, and then markov process is used to insert adjuncts among the arguments.</citsent>
<aftsection>
<nextsent>while treebank models overfit the training data, markov models underfit.
</nextsent>
<nextsent>a simple compromise (novel to this paper) is hybrid treebank/markov model, which backs off from treebank model to markov.
</nextsent>
<nextsent>like this papers main proposal, it can learn well-observed idiosyncratic rules but generalizes when data are sparse.3 1nonstandardly, this allows infinitely many rules with 0.
</nextsent>
<nextsent>2one might do better by backing off to word clusters, which charniak (1997) did find provided small benefit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3080">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> the abstract problem: designing priors.  </section>
<citcontext>
<prevsection>
<prevsent>we do train this case on the true internal bracketing, but it loses even with this unfair advantage.6this approach is called semi-bayesian or maximum pos priors can help both unsupervised and supervisedlearning.
</prevsent>
<prevsent>(in the semi-supervised experiments here, training data is not raw text but sparse sample of flat rules.)
</prevsent>
</prevsection>
<citsent citstr=" W97-1010 ">
indeed good deal of syntax induction work has been carried out in just this framework (stolcke and omohun dro, 1994; chen, 1996; de marcken, 1996; grunwald, 1996; osborne and briscoe, 1997).<papid> W97-1010 </papid></citsent>
<aftsection>
<nextsent>however, all such work to date has adopted rather simple prior distributions.
</nextsent>
<nextsent>typically, it has defined p(?)
</nextsent>
<nextsent>to favor pcfgs whose rules are few, short, nearly equi probable, and defined over asmall set of nonterminals.
</nextsent>
<nextsent>such definitions are convenient, especially when specifying an encoding for mdl, but since they treat all rules alike, they may not be good descriptions of linguistic plausibility.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3081">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> a transformation model </section>
<citcontext>
<prevsection>
<prevsent>the form of our new model is shown in figure 1.
</prevsent>
<prevsent>the vertices are flat context-free rules, and the arcs between them represent edit transformations.
</prevsent>
</prevsection>
<citsent citstr=" J91-3003 ">
the set of arcs leav 8carpenter (1991) <papid> J91-3003 </papid>writes that whenever linguists run into the problem of systematic redundancy in the syntactic lexicon, they design scheme in which lexical entries can be derived from one another by just these operations.</citsent>
<aftsection>
<nextsent>we are doing the same thing.
</nextsent>
<nextsent>the only twist that the lexical entries (in our case, flat pcfg rules) have probabilities that must also be derived, so we will assume that the speaker applies these operations (randomly from the hearers viewpoint) at various rates to be learned.
</nextsent>
<nextsent>exp 1 z1 exp 2+8 z1to fund np exp 3+5+8 z2 exp 0 z4 exp 0 z8 exp 3+5+9 z6 exp 2+9 z5 exp 1 z5 0.0002 start halt start(merge) to merge np to merge pp np to merge np pp halt to fund np pp to fund pp np halt halt start(fund) exp 7+8 z3exp 0 z3 0.0011 exp 0 z7 exp 7+9 z7 exp 3+4 z2 exp 0 z2 exp 0 z6 exp 3+4 z6 exp 6 z3 exp 6 z7 0 halts 3 inserts pp 6 deletes pp 8 yields to fund np pp 1 chooses to np 4 inserts pp before np 7 moves np right past pp 9 yields to merge np pp 2 chooses to np pp 5 inserts pp before right edge figure 1: fragment of transformation model.
</nextsent>
<nextsent>vertices are possible context-free rules (their left-hand sides, sfund ? and smerge ? , are omitted to avoid visual clutter).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3082">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> evaluation12.  </section>
<citcontext>
<prevsection>
<prevsent>was defined in section 4.
</prevsent>
<prevsent>to evaluate the quality of generalization, we used pre parsed training data and testing data (table 3).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
each dataset consisted of collection of flat rules such assput ? np put np pp extracted from the penn tree bank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>thus, p(d | ?,pi) andp(e | ?,pi) were each defined as product of rule probabilities of the form p?,pi(np put np pp | sput).
</nextsent>
<nextsent>the learner attempted to maximize p(?,pi) ? p(d | ?,pi) by gradient ascent.
</nextsent>
<nextsent>this amounts to learning the generalizations and exceptions that related the training rules d. the evaluation measure was then the perplexity on test data, ? log2 p(e | ?,pi)/|e| . to get good(low) perplexity score, the model had to assign reason able probabilities to the many novel rules in (table 3).
</nextsent>
<nextsent>for many of these rules, even the frame was novel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3083">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> evaluation12.  </section>
<citcontext>
<prevsection>
<prevsent>in the finite part of the transformation graph that was actually explored (including bad arcs that compete with good ones), about 70000 distinct features were encountered, though after training, only few hundred 12see (eisner, 2001) for full details of data preparation, model structure, parameter initialization, backoff levels for the comparison models, efficient techniques for computing the objective and its gradient, and more analysis of the results.
</prevsent>
<prevsent>treebank/markov basic katz one-counta flat non-flatb flat flat non-flat (a) treebank ? ?
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
1-gram 1774.9 86435.1 340.9 160.0 193.2 2-gram 135.2 199.3 127.2 116.2 174.7 3-gram 136.5 177.4 132.7 123.3 174.8 coll insc 363.0 494.5 197.9 transformation 108.6 averagedd 102.3 (b) 1-gram 1991.2 96318.8 455.1 194.3 233.1 2-gram 162.2 236.6 153.2 138.8 205.6 3-gram 161.9 211.0 156.8 145.7 208.1 collins 414.5 589.4 242.0 transformation 124.8 averaged 118.0 aback off from treebank grammar with katz vs. one-countbackoff (chen and goodman, 1996) (<papid> P96-1041 </papid>note: one-count was always used for backoff within the n-gram and collins models.)</citsent>
<aftsection>
<nextsent>bsee section 2 for discussion ccollins (1997, <papid> P97-1003 </papid>model 2) dave rage of transformation model with best other model table 4: perplexity of the test set under various models.</nextsent>
<nextsent>(a) full training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3086">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> evaluation12.  </section>
<citcontext>
<prevsection>
<prevsent>the competing models from the literature are best used to predict flat rules directly, rather than by summing over their possible non-flat internal structures, as has been done in the past.
</prevsent>
<prevsent>this result is significant in itself.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
extending johnson (1998), <papid> J98-4004 </papid>it shows the inappropriateness of the traditional independence assumptions that build up frame by several rule expansions (section 2).</citsent>
<aftsection>
<nextsent>figure 2 shows that averaging the transformation model with the treebank/bigram model improves the latter not merely on balance, but across the board.
</nextsent>
<nextsent>in other words, there is no evident class of phenomena for which incorporating transformations would be bad idea.
</nextsent>
<nextsent>transformations particularly helped raise the estimates of the low-probability novel rules in test data, as hoped.
</nextsent>
<nextsent>transformations also helped on test rules that had been observed once in training with relatively infrequent words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3087">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the vertices represent lexical entries and the arcs represent probabilistic lexical redundancy rules or meta rules (see footnote 8).
</prevsent>
<prevsent>the transformation model approach is therefore full stochastic treatment of lexicalized syntax?
</prevsent>
</prevsection>
<citsent citstr=" J99-4002 ">
apparently the first to treat lexical redundancy rules, although (briscoe and copestake, 1999) <papid> J99-4002 </papid>give an ad hoc approach.</citsent>
<aftsection>
<nextsent>see (eisner, 2001; eisner, 2002<papid> P02-1001 </papid>a) for more discussion.</nextsent>
<nextsent>it is worthwhile to compare the statistical approach here with some other approaches:?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3088">
<title id=" W02-1009.xml">transformational priors over grammars </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the transformation model approach is therefore full stochastic treatment of lexicalized syntax?
</prevsent>
<prevsent>apparently the first to treat lexical redundancy rules, although (briscoe and copestake, 1999) <papid> J99-4002 </papid>give an ad hoc approach.</prevsent>
</prevsection>
<citsent citstr=" P02-1001 ">
see (eisner, 2001; eisner, 2002<papid> P02-1001 </papid>a) for more discussion.</citsent>
<aftsection>
<nextsent>it is worthwhile to compare the statistical approach here with some other approaches:?
</nextsent>
<nextsent>transformation models are similar to graphical models: they allow similar patterns of deductive and abductive inference from observations.
</nextsent>
<nextsent>however, the vertices of transformation graph do not represent different random variables, but rather mutually exclusive values of the same random variable, whose probabilities sum to 1.?
</nextsent>
<nextsent>transformation models incorporate conditional loglinear (maximum entropy) models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3097">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we incorporate context into the search for an optimal alignment in two complementary ways: learning rules for matching paragraphs using topic structure and further refining the matching through local alignment to find good sentence pairs.
</prevsent>
<prevsent>evaluation shows that our alignment method outperforms state-of-the-art systems developed for the same task.
</prevsent>
</prevsection>
<citsent citstr=" A00-2024 ">
text-to-text generation is an emerging area of research in nlp (chandrasekar and bangalore, 1997; caroll et al, 1999; knight and marcu, 2000; jingand mckeown, 2000).<papid> A00-2024 </papid></citsent>
<aftsection>
<nextsent>unlike in traditional conceptto-text generation, text-to-text generation applications take text as input and transform it into new text satisfying specific constraints, such as length in summarization or style in text simplification.
</nextsent>
<nextsent>one exciting new research direction is the automatic induction of such transformation rules.
</nextsent>
<nextsent>this is particularly promising direction given that there are naturally occurring examples of comparable texts that convey the same information yet are written in different styles.
</nextsent>
<nextsent>presented with two such texts, one can pair sentences that convey the same information, thereby building training set of rewriting examples for the domain to which the texts belong.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3098">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even simple lexical function (e.g., one that counts word overlap) could produce an accurate alignment.
</prevsent>
<prevsent>1sentence alignment for comparable multilingual corpor awas not addressed in previous research.
</prevsent>
</prevsection>
<citsent citstr=" P98-1069 ">
comparable corpora have primarily been used to build bilingual lexical resources (fung and yee, 1998).<papid> P98-1069 </papid></citsent>
<aftsection>
<nextsent>after all, two sentences which share most of their words are likely to paraphrase each other.
</nextsent>
<nextsent>the problem is that there are many sentences that convey the same information but have little surface resemblance.
</nextsent>
<nextsent>as result, simple word counts cannot distinguish the matching pair (a) in figure 1 from the unrelated pair (b).
</nextsent>
<nextsent>an accurate local similarity measure would have to account for many complex paraphrasing phenomena.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3099">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: sentence pairs from our corpus sharing two content words.
</prevsent>
<prevsent>(a) is matching pair, (b) is not.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
in mt, weak similarity function is compensated for by searching for globally optimal alignment, using dynamic programming or taking advantage of the geometric/positional or contextual properties of the text pair (gale and church, 1991; <papid> P91-1023 </papid>shemtov,1993; <papid> E93-1054 </papid>melamed, 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>but these techniques operate on the assumptions that there are limited insertions and deletions between the texts and that the order of the information is roughly preserved from one text to another.
</nextsent>
<nextsent>texts from comparable corpora, as opposed to parallel corpora, contain great deal of noise.?
</nextsent>
<nextsent>in figure 2 which plots the manually identified alignment for text pair in our corpus, only small fraction of the sentences got aligned (35 out of 31 ? 270 sentence pairs), which illustrates that there is no complete information overlap.
</nextsent>
<nextsent>consider two texts written by different press agencies: while both report on the same events, one may contain additional interviews and the other, background information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3100">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: sentence pairs from our corpus sharing two content words.
</prevsent>
<prevsent>(a) is matching pair, (b) is not.
</prevsent>
</prevsection>
<citsent citstr=" E93-1054 ">
in mt, weak similarity function is compensated for by searching for globally optimal alignment, using dynamic programming or taking advantage of the geometric/positional or contextual properties of the text pair (gale and church, 1991; <papid> P91-1023 </papid>shemtov,1993; <papid> E93-1054 </papid>melamed, 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>but these techniques operate on the assumptions that there are limited insertions and deletions between the texts and that the order of the information is roughly preserved from one text to another.
</nextsent>
<nextsent>texts from comparable corpora, as opposed to parallel corpora, contain great deal of noise.?
</nextsent>
<nextsent>in figure 2 which plots the manually identified alignment for text pair in our corpus, only small fraction of the sentences got aligned (35 out of 31 ? 270 sentence pairs), which illustrates that there is no complete information overlap.
</nextsent>
<nextsent>consider two texts written by different press agencies: while both report on the same events, one may contain additional interviews and the other, background information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3101">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: sentence pairs from our corpus sharing two content words.
</prevsent>
<prevsent>(a) is matching pair, (b) is not.
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
in mt, weak similarity function is compensated for by searching for globally optimal alignment, using dynamic programming or taking advantage of the geometric/positional or contextual properties of the text pair (gale and church, 1991; <papid> P91-1023 </papid>shemtov,1993; <papid> E93-1054 </papid>melamed, 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>but these techniques operate on the assumptions that there are limited insertions and deletions between the texts and that the order of the information is roughly preserved from one text to another.
</nextsent>
<nextsent>texts from comparable corpora, as opposed to parallel corpora, contain great deal of noise.?
</nextsent>
<nextsent>in figure 2 which plots the manually identified alignment for text pair in our corpus, only small fraction of the sentences got aligned (35 out of 31 ? 270 sentence pairs), which illustrates that there is no complete information overlap.
</nextsent>
<nextsent>consider two texts written by different press agencies: while both report on the same events, one may contain additional interviews and the other, background information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3102">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in single document summarization, alignment between full documents and summaries written by humans is used tolearn rules for text compression.
</prevsent>
<prevsent>marcu (1999) computes sentence similarity using cosine-based metric.
</prevsent>
</prevsection>
<citsent citstr=" J02-4006 ">
jing (2002) <papid> J02-4006 </papid>identifies phrases that were cut and pasted together using hidden markov model with features incorporating word identity and positioning within sentences, thereby providing an alignment of the document and its summary.</citsent>
<aftsection>
<nextsent>however, both of these methods construct an alignment by looking at sentences one at time, independently of the decisions made about other sentences.
</nextsent>
<nextsent>because summaries often reuse original document text to large extent, these methods achieve good results.
</nextsent>
<nextsent>in the context of multi document summarization, sim finder (hatzivassiloglou et al, 1999) <papid> W99-0625 </papid>identifies sentences that convey similar information across in put documents to select the summary content.</nextsent>
<nextsent>even though the input documents are about the same subject, they exhibit great deal of lexical variability.to address this issue, sim finder employs complex similarity function, combining features that extend beyond simple word count and include noun phrase, proper noun, and wordnet sense overlap.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3104">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, both of these methods construct an alignment by looking at sentences one at time, independently of the decisions made about other sentences.
</prevsent>
<prevsent>because summaries often reuse original document text to large extent, these methods achieve good results.
</prevsent>
</prevsection>
<citsent citstr=" W99-0625 ">
in the context of multi document summarization, sim finder (hatzivassiloglou et al, 1999) <papid> W99-0625 </papid>identifies sentences that convey similar information across in put documents to select the summary content.</citsent>
<aftsection>
<nextsent>even though the input documents are about the same subject, they exhibit great deal of lexical variability.to address this issue, sim finder employs complex similarity function, combining features that extend beyond simple word count and include noun phrase, proper noun, and wordnet sense overlap.
</nextsent>
<nextsent>since many documents are processed in parallel, clustering is used to combine pairwise alignments.
</nextsent>
<nextsent>in contrast to our approach, sim finder does not take the context around sentences into account.
</nextsent>
<nextsent>given comparable corpus consisting of two collections and training set of manually aligned text pairs from the corpus, the algorithm follows four main steps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3106">
<title id=" W03-1004.xml">sentence alignment for monolingual comparable corpora </title>
<section> algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>or treat ment.3 if the task is to align disease description written for physicians and text describing the same disease for lay people, it is most likely that sentences within the topic symptoms?
</prevsent>
<prevsent>in the expert version will map to sentences describing the symptoms inthe lay version rather than those describing treatment options.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
if we can automatically identify the topic each paragraph conveys, we can decide more accurately whether two paragraphs are related and should be mapped for further processing.2texts without adequate paragraph marking could be segmented using tools such as text tiling (hearst, 1994).<papid> P94-1002 </papid></citsent>
<aftsection>
<nextsent>3we use the term topic differently than it is commonly used in the topic detection task?
</nextsent>
<nextsent>there, topic?
</nextsent>
<nextsent>would designate which disease is described.
</nextsent>
<nextsent>in the field of text generation, methods for representing the semantic structure of texts have been investigated through text schemata (mckeown, 1985) or rhetorical structures (mann and thompson, 1987).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3112">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(sequence-to-sequence) translation correspondences from parallel corpora.
</prevsent>
<prevsent>it is well-known that translation does not always proceed by word-for-word.
</prevsent>
</prevsection>
<citsent citstr=" P93-1003 ">
this highlights the need for finding multi-word translation cor respondences.previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (kupiec, 1993), <papid> P93-1003 </papid>fixed/flexiblecollocations (smadja et al, 1996), <papid> J96-1001 </papid>n-gram word sequences of arbitrary length (kitamura and matsumoto, 1996), <papid> W96-0107 </papid>non-compositional compounds (melamed, 2001), captoids (moore, 2001), <papid> W01-1411 </papid>and named entities 1.</citsent>
<aftsection>
<nextsent>in all of these approaches, common problem seems to be an identification of meaningful multi-word translationunits.
</nextsent>
<nextsent>there are number of factors which make handling of multi-word units more complicated than it appears.
</nextsent>
<nextsent>first, it is many-to-many mapping which potentially leads to combinatorial explosion.
</nextsent>
<nextsent>second, multiword translation units are not necessarily contiguous, soan algorithm should not be hampered by the word adjacency constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3113">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(sequence-to-sequence) translation correspondences from parallel corpora.
</prevsent>
<prevsent>it is well-known that translation does not always proceed by word-for-word.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
this highlights the need for finding multi-word translation cor respondences.previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (kupiec, 1993), <papid> P93-1003 </papid>fixed/flexiblecollocations (smadja et al, 1996), <papid> J96-1001 </papid>n-gram word sequences of arbitrary length (kitamura and matsumoto, 1996), <papid> W96-0107 </papid>non-compositional compounds (melamed, 2001), captoids (moore, 2001), <papid> W01-1411 </papid>and named entities 1.</citsent>
<aftsection>
<nextsent>in all of these approaches, common problem seems to be an identification of meaningful multi-word translationunits.
</nextsent>
<nextsent>there are number of factors which make handling of multi-word units more complicated than it appears.
</nextsent>
<nextsent>first, it is many-to-many mapping which potentially leads to combinatorial explosion.
</nextsent>
<nextsent>second, multiword translation units are not necessarily contiguous, soan algorithm should not be hampered by the word adjacency constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3114">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(sequence-to-sequence) translation correspondences from parallel corpora.
</prevsent>
<prevsent>it is well-known that translation does not always proceed by word-for-word.
</prevsent>
</prevsection>
<citsent citstr=" W96-0107 ">
this highlights the need for finding multi-word translation cor respondences.previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (kupiec, 1993), <papid> P93-1003 </papid>fixed/flexiblecollocations (smadja et al, 1996), <papid> J96-1001 </papid>n-gram word sequences of arbitrary length (kitamura and matsumoto, 1996), <papid> W96-0107 </papid>non-compositional compounds (melamed, 2001), captoids (moore, 2001), <papid> W01-1411 </papid>and named entities 1.</citsent>
<aftsection>
<nextsent>in all of these approaches, common problem seems to be an identification of meaningful multi-word translationunits.
</nextsent>
<nextsent>there are number of factors which make handling of multi-word units more complicated than it appears.
</nextsent>
<nextsent>first, it is many-to-many mapping which potentially leads to combinatorial explosion.
</nextsent>
<nextsent>second, multiword translation units are not necessarily contiguous, soan algorithm should not be hampered by the word adjacency constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3115">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(sequence-to-sequence) translation correspondences from parallel corpora.
</prevsent>
<prevsent>it is well-known that translation does not always proceed by word-for-word.
</prevsent>
</prevsection>
<citsent citstr=" W01-1411 ">
this highlights the need for finding multi-word translation cor respondences.previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences (kupiec, 1993), <papid> P93-1003 </papid>fixed/flexiblecollocations (smadja et al, 1996), <papid> J96-1001 </papid>n-gram word sequences of arbitrary length (kitamura and matsumoto, 1996), <papid> W96-0107 </papid>non-compositional compounds (melamed, 2001), captoids (moore, 2001), <papid> W01-1411 </papid>and named entities 1.</citsent>
<aftsection>
<nextsent>in all of these approaches, common problem seems to be an identification of meaningful multi-word translationunits.
</nextsent>
<nextsent>there are number of factors which make handling of multi-word units more complicated than it appears.
</nextsent>
<nextsent>first, it is many-to-many mapping which potentially leads to combinatorial explosion.
</nextsent>
<nextsent>second, multiword translation units are not necessarily contiguous, soan algorithm should not be hampered by the word adjacency constraint.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3117">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> our basic idea.  </section>
<citcontext>
<prevsection>
<prevsent>frequencies of bilingual pattern eijj , an english pattern ei, and japanese pattern jj correspond to a, + b, and + respectively.
</prevsent>
<prevsent>since we know the total number of bilingual sequences = + + + d, values of b, and can be calculated immediately.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
table 1: contingency table jj ? jj ei b + ? ei d + nthe contingency table is used for calculating similarity (or association) score between ei and jj . for this present work, we use dunnings log-likelihood ratio statistics (dunning, 1993) <papid> J93-1003 </papid>defined as follows: sim = log a+ log b+ log c+ log ?(a+ b) log (a+ b)?</citsent>
<aftsection>
<nextsent>(a+ c) log (a+ c) ?(b+ d) log (b+ d)?
</nextsent>
<nextsent>(c+ d) log (c+ d) +(a+ b+ c+ d) log (a+ b+ c+ d) for each bilingual pattern eijj , we compute its similarity score and qualify it as bilingual sequence-to-sequencecorrespondence if no equally strong or stronger association for monolingual constituent is found.
</nextsent>
<nextsent>this step is conservative and the same as step 5 in moore (2001) <papid> W01-1411 </papid>orstep 6(b) in kitamura and matsumoto (1996).<papid> W96-0107 </papid></nextsent>
<nextsent>our implementation uses digital trie structure called double array for efficient storage and retrieval of sequential patterns (aoe, 1989).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3122">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>we use the english-japanese parallel corpora that are automatically aligned from comparable corpora of the news wires (utiyama and isahara, 2002).
</prevsent>
<prevsent>there are 150,000 parallel sentences which satisfy their proposed sentence similarity.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we use tnt (brants, 2000) <papid> A00-1031 </papid>for english pos tagging and chasen (matsumoto et al, 2000)for japanese morphological analysis, and label each token to either content or functional depending on its part of-speech.</citsent>
<aftsection>
<nextsent>table 2: statistics of 150,000 parallel sentences japanese english content (token) 2,039,656 2,257,806 content (type) 47,316 57,666 functional (token) 2,660,855 1,704,189 functional (type) 1,811 386 3.2 evaluation criteria.
</nextsent>
<nextsent>we evaluate our sequence-to-sequence correspondence by accuracy and coverage, which we believe, similar criteria to (moore, 2001) <papid> W01-1411 </papid>and (melamed, 2001) 2.</nextsent>
<nextsent>let cseq be the set of correct bilingual sequences by human judge, sseq be the set of bilingual sequences identified by our system, ctoken be the multi set of items covered by cseq , ttoken be the multi set of items in the bilingual sequence database, ctype be the set of items covered bycseq , and ttype be the set of items in the bilingual sequence database.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3134">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>it can take mutually exclusive constraints into account more easily which will improve the overall performance.
</prevsent>
<prevsent>another interesting extension is to incorporate more linguistically motivated constraints in generation of sequences.
</prevsent>
</prevsection>
<citsent citstr=" W01-1412 ">
yamamoto et al (2001) <papid> W01-1412 </papid>reports that n-gram translation candidates that do not go beyond the chunk boundary boosts performance.</citsent>
<aftsection>
<nextsent>had we performed language dependent chunking in preparation of bilingual sequences, such chunk boundary constraint could be simply represented in the project able predicate.
</nextsent>
<nextsent>the issues are left for future research.
</nextsent>
<nextsent>3.3.2 gapped sequences one of advantages in our method is uniform generation of both rigid and gapped sequences simultaneously.
</nextsent>
<nextsent>gapped sequences are generated and extracted without recording offset and without distinguisting compositional compounds from non-compositional compounds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3144">
<title id=" W03-0314.xml">learning sequencetosequence correspondences from parallel corpora via sequential pattern mining </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many of works mentioned in the last paragraph as well as ours extract non-probabilistic translation lexicons.
</prevsent>
<prevsent>however, there are research works which go beyond word-level translations in statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
one notable work is that of marcu and wong (2002), <papid> W02-1018 </papid>which is based on joint probability model for statistical machine translation where word equivalents and phrase (rigid sequence) equivalents are automatically learned form bilingual corpora.</citsent>
<aftsection>
<nextsent>our method does not iterate an extraction process asshown in figure 1.
</nextsent>
<nextsent>this could be cause of poor performance in single-word translation pairs, since there is no mechanism for imposing mutually exclusion constrains.
</nextsent>
<nextsent>an interesting question then is what kind of iteration should be performed to improve performance.
</nextsent>
<nextsent>probabilistic translation lexicon acquisition often uses em training on viterbi alignments, e.g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3147">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, although the data sparseness is common problem, it is especially severe for wsd.
</prevsent>
<prevsent>the problems were attacked in various ways.
</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
yarowsky (1992) <papid> C92-2070 </papid>showed class-based approach under which very large untagged corpus and thesaurus can be used effectively for unsupervised training for noun homo graph disambiguation.</citsent>
<aftsection>
<nextsent>however, the method does not offer method that explicitly produces sense tagged data for any given sense inventory.
</nextsent>
<nextsent>li and huang (1999) described similar unsupervised approach for chinese text based on chinese thesaurus.
</nextsent>
<nextsent>as noted in merialdo (1994), <papid> J94-2001 </papid>even minimal hand tagging improved on the results of unsupervised methods.</nextsent>
<nextsent>yarowsky (1995) <papid> P95-1026 </papid>showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3149">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the method does not offer method that explicitly produces sense tagged data for any given sense inventory.
</prevsent>
<prevsent>li and huang (1999) described similar unsupervised approach for chinese text based on chinese thesaurus.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
as noted in merialdo (1994), <papid> J94-2001 </papid>even minimal hand tagging improved on the results of unsupervised methods.</citsent>
<aftsection>
<nextsent>yarowsky (1995) <papid> P95-1026 </papid>showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods.</nextsent>
<nextsent>li and li (2002) <papid> P02-1044 </papid>extended the approach by using corpora in two languages to bootstrap the learning process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3150">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>li and huang (1999) described similar unsupervised approach for chinese text based on chinese thesaurus.
</prevsent>
<prevsent>as noted in merialdo (1994), <papid> J94-2001 </papid>even minimal hand tagging improved on the results of unsupervised methods.</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
yarowsky (1995) <papid> P95-1026 </papid>showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods.</citsent>
<aftsection>
<nextsent>li and li (2002) <papid> P02-1044 </papid>extended the approach by using corpora in two languages to bootstrap the learning process.</nextsent>
<nextsent>they showed bilingual bootstrapping is even more effective.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3151">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as noted in merialdo (1994), <papid> J94-2001 </papid>even minimal hand tagging improved on the results of unsupervised methods.</prevsent>
<prevsent>yarowsky (1995) <papid> P95-1026 </papid>showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods.</prevsent>
</prevsection>
<citsent citstr=" P02-1044 ">
li and li (2002) <papid> P02-1044 </papid>extended the approach by using corpora in two languages to bootstrap the learning process.</citsent>
<aftsection>
<nextsent>they showed bilingual bootstrapping is even more effective.
</nextsent>
<nextsent>the bootstrapping approach is limited by lack of systematic procedure of preparing seed data for any word in given sense inventory.
</nextsent>
<nextsent>the approach also suffers from errors propagating from one iteration into the next.
</nextsent>
<nextsent>li and huang another alternative involves using parallel corpus as surrogate for tagged data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3154">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they reported high precision rates of wsd system for two-way disambiguation of six english nouns based on their translations in an english-french parallel corpus.
</prevsent>
<prevsent>however, when working with particular sense inventory, there is no obvious way to know whether the one sense per translation constraint holds or how to determine the relevant translations automatically.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
diab and resnik (2002) <papid> P02-1033 </papid>extended the translation-based learning strategy with weakened constraint that many instances of word in parallel corpus often correspond to lexically varied but semantically consistent translations.</citsent>
<aftsection>
<nextsent>they proposed to group those translations into target set, which can be automatically tagged with correct senses based on the hypernym hierarchy of wordnet.
</nextsent>
<nextsent>diab and resniks work represents departure from previous unsupervised approaches in that no seed data is needed and explicit tagged data are produced forgiven sense inventory (wordnet in their case).
</nextsent>
<nextsent>the system trained on the tagged data was shown to be on par with the best supervised training?
</nextsent>
<nextsent>systems in senseval-2 competition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3155">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> output c* as the translation;.  </section>
<citcontext>
<prevsection>
<prevsent>words in c: ,)|(maxmaxarg* ),( ??
</prevsent>
<prevsent>= lcpl cwlinkl ( )*)|(maxarg* lcpc = , where link(x, y) means and are two word aligned based on competitive linking alignment
</prevsent>
</prevsection>
<citsent citstr=" P97-1063 ">
to make sense tagging more precise, it is advisable to place constraint on the translation counterpart of w. swat considers only those translations that has been linked with based the competitive linking algorithm (melamed 1997) <papid> P97-1063 </papid>and logarithmic likelihood ratio (dunning 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>table 4.
</nextsent>
<nextsent>the experimental results of assigning ldoce senses to classes of lloce.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>experiments and evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3156">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> output c* as the translation;.  </section>
<citcontext>
<prevsection>
<prevsent>words in c: ,)|(maxmaxarg* ),( ??
</prevsent>
<prevsent>= lcpl cwlinkl ( )*)|(maxarg* lcpc = , where link(x, y) means and are two word aligned based on competitive linking alignment
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
to make sense tagging more precise, it is advisable to place constraint on the translation counterpart of w. swat considers only those translations that has been linked with based the competitive linking algorithm (melamed 1997) <papid> P97-1063 </papid>and logarithmic likelihood ratio (dunning 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>table 4.
</nextsent>
<nextsent>the experimental results of assigning ldoce senses to classes of lloce.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>experiments and evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3157">
<title id=" W03-1702.xml">class based sense definition model for word sense tagging and disambiguation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is possible to work with any number of sense inventories.
</prevsent>
<prevsent>iii.
</prevsent>
</prevsection>
<citsent citstr=" J98-1005 ">
the method is applicable not only to nouns but also to adjectives and verbs, since it does not relyon topical context, which is effective only for nouns as pointed out by towell and voorhees (1998).<papid> J98-1005 </papid></citsent>
<aftsection>
<nextsent>the approach is very general and modular and can work in conjunction with number of learning strategies for word sense disambiguation (yarowsky, 1995; <papid> P95-1026 </papid>li and li, 2002).</nextsent>
<nextsent>in this paper, we present the mutual assured resolution of sense (mars) algorithm for assigning relevant senses to word classes in given sense inventory (i.e. ldoce or wordnet).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3159">
<title id=" W02-1033.xml">an analysis of the askmsr question answering system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most question answering systems use variety of linguistic resources to help in understanding the users query and matching sections in documents.
</prevsent>
<prevsent>the most common linguistic resources include: part-of-speech tagging, parsing, named entity extraction, semantic relations, dictionaries, wordnet, etc.
</prevsent>
</prevsection>
<citsent citstr=" A00-1041 ">
(e.g., abney et al, 2000; <papid> A00-1041 </papid>chen et al 2000; harabagiu et al, 2000; hovy et al, 2000; pasca et al, 2001; prager et al, 2000).</citsent>
<aftsection>
<nextsent>we chose instead to focus on the web as gigantic data repository with tremendous redundancy that can be exploited for question answering.
</nextsent>
<nextsent>we view our approach as complimentary to more linguistic approaches, but have chosen to see how far we can get initially by focusing on data perse as key resource available to drive our system design.
</nextsent>
<nextsent>recently, other researchers have also looked to the web as resource for question answering (buch holtz, 2001; clarke et al, 2001; kwok et al, 2001).
</nextsent>
<nextsent>these systems typically perform complex parsing and entity extraction for both queries and best matching web pages, and maintain local caches of pages or term weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3160">
<title id=" W03-0318.xml">input sentence splitting and translating </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to achieve translation technology that is adequate for speech translation, the possibilities of several corpus based approaches are being investigated.
</prevsent>
<prevsent>among these methods, dp-match driven transducer (d3) has been proposed as an example-based machine translation (ebmt).
</prevsent>
</prevsection>
<citsent citstr=" W01-1401 ">
when d3 is adapted to japanese-to-english translation in travel conversation domain, the method can achieve high translation quality (sumita, 2001 <papid> W01-1401 </papid>and 2002).</citsent>
<aftsection>
<nextsent>on the other hand, the translation method is sensitive to the long sentence problem, where longer input sentences make it more difficult for machine translation (mt) system to perform good translation.
</nextsent>
<nextsent>to over come this problem, the technique of splitting an input sentence 1 and translating the split sentences appears promising.
</nextsent>
<nextsent>the methods of previous studies related to this approach can be roughly classified into two types: one splits sentences before translation and the other splits them in the parsing phase of translation.
</nextsent>
<nextsent>well call the former pre-process-splitting, the latter parse-time 1 strictly speaking, this isn necessarily sentence but an.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3162">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>ensemble methods are state of the art for many nlp tasks.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
recent work by banko and brill (2001) <papid> P01-1005 </papid>suggests that this would not necessarily be true if very large training corpora were available.</citsent>
<aftsection>
<nextsent>however,their results are limited by the simplicity of their evaluation task and individual classifiers.
</nextsent>
<nextsent>our work explores ensemble efficacy forthe more complex task of automatic thesaurus extraction on up to 300 million words.
</nextsent>
<nextsent>we examine our conflicting resultsin terms of the constraints on, and complexity of, different contextual representations, which contribute to the sparseness and noise-induced bias behaviour of nlp systems on very large corpora.
</nextsent>
<nextsent>ensemble learning is machine learning technique that combines the output of several different classifiers with the goal of improving classification performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3165">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ensemble learning is machine learning technique that combines the output of several different classifiers with the goal of improving classification performance.
</prevsent>
<prevsent>the classifiers within the ensemble may differ in several ways, such as the learning algorithm or knowledge representation used, or data they were trained on.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
ensemble learning has been successfully applied to numerous nlp tasks, including pos tagging (brill and wu, 1998; van halteren et al, 1998),chunking (tjong kim sang, 2000), word sense disambiguation (pederson, 2000) and statistical parsing (henderson and brill, 1999).<papid> W99-0623 </papid></citsent>
<aftsection>
<nextsent>dietterich (2000) presents good introduction to ensemble methods.
</nextsent>
<nextsent>ensemble methods ameliorate learner bias by amortising individual classifier bias of over different systems.
</nextsent>
<nextsent>for an ensemble to be more effective than its constituents, the individual classifiers must have better than 50% accuracy and must produce diverse erroneous classifications (dietterich, 2000).
</nextsent>
<nextsent>brill and wu (1998) <papid> P98-1029 </papid>call this complementary disagreement complementarity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3166">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ensemble methods ameliorate learner bias by amortising individual classifier bias of over different systems.
</prevsent>
<prevsent>for an ensemble to be more effective than its constituents, the individual classifiers must have better than 50% accuracy and must produce diverse erroneous classifications (dietterich, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
brill and wu (1998) <papid> P98-1029 </papid>call this complementary disagreement complementarity.</citsent>
<aftsection>
<nextsent>although ensembles are often effective on problems with small training sets, recent work suggests this may not be true as dataset size increases.
</nextsent>
<nextsent>banko and brill (2001) <papid> P01-1005 </papid>found that for confusion set disambiguation with corpora larger than 100 million words, the best individual classifiers outperformed ensemble methods.</nextsent>
<nextsent>one limitation of their results is the simplicity of the task and methods used to examine the efficacy of ensemble methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3172">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>222-229.
</prevsent>
<prevsent>proceedings of the conference on empirical methods in natural
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
the development of large thesauri and semantic resources, such as wordnet (fellbaum, 1998), has allowed lexical semantic information to be leveraged to solve nlp tasks, including collocation discovery (pearce, 2001), model estimation (brown et al, 1992; <papid> J92-4003 </papid>clark and weir, 2001) <papid> N01-1013 </papid>and text classification (baker and mccallum, 1998).unfortunately, thesauri are expensive and time consuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.</citsent>
<aftsection>
<nextsent>in addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many sub domains that nlp techniques are being applied to.there is clear need for automatic thesaurus extraction methods.much of the existing work on thesaurus extraction and word clustering is based on the observations that related terms will appear in similar contexts.
</nextsent>
<nextsent>these systems differ primarily in their definition of context?
</nextsent>
<nextsent>and the way they calculate similarity from the contexts each term appears in.
</nextsent>
<nextsent>many systems extract co-occurrence and syntactic information from the words surrounding the target term,which is then converted into vector-space representation of the contexts that each target term appears in (pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin,1998b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3173">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>222-229.
</prevsent>
<prevsent>proceedings of the conference on empirical methods in natural
</prevsent>
</prevsection>
<citsent citstr=" N01-1013 ">
the development of large thesauri and semantic resources, such as wordnet (fellbaum, 1998), has allowed lexical semantic information to be leveraged to solve nlp tasks, including collocation discovery (pearce, 2001), model estimation (brown et al, 1992; <papid> J92-4003 </papid>clark and weir, 2001) <papid> N01-1013 </papid>and text classification (baker and mccallum, 1998).unfortunately, thesauri are expensive and time consuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.</citsent>
<aftsection>
<nextsent>in addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many sub domains that nlp techniques are being applied to.there is clear need for automatic thesaurus extraction methods.much of the existing work on thesaurus extraction and word clustering is based on the observations that related terms will appear in similar contexts.
</nextsent>
<nextsent>these systems differ primarily in their definition of context?
</nextsent>
<nextsent>and the way they calculate similarity from the contexts each term appears in.
</nextsent>
<nextsent>many systems extract co-occurrence and syntactic information from the words surrounding the target term,which is then converted into vector-space representation of the contexts that each target term appears in (pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin,1998b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3174">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>these systems differ primarily in their definition of context?
</prevsent>
<prevsent>and the way they calculate similarity from the contexts each term appears in.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
many systems extract co-occurrence and syntactic information from the words surrounding the target term,which is then converted into vector-space representation of the contexts that each target term appears in (pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin,1998b).</citsent>
<aftsection>
<nextsent>curran and moens (2002<papid> W02-0908 </papid>b) evaluate thesaurus extractors based on several different models of context on large corpora.</nextsent>
<nextsent>the context models used in our experiments are described in section 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3175">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> automatic thesaurus extraction.  </section>
<citcontext>
<prevsection>
<prevsent>and the way they calculate similarity from the contexts each term appears in.
</prevsent>
<prevsent>many systems extract co-occurrence and syntactic information from the words surrounding the target term,which is then converted into vector-space representation of the contexts that each target term appears in (pereira et al, 1993; <papid> P93-1024 </papid>ruge, 1997; lin,1998b).</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
curran and moens (2002<papid> W02-0908 </papid>b) evaluate thesaurus extractors based on several different models of context on large corpora.</citsent>
<aftsection>
<nextsent>the context models used in our experiments are described in section 3.
</nextsent>
<nextsent>we define context relation instance as tuple (w, r,w?) where is thesaurus term, occurring in arelation of type r, with another word w?
</nextsent>
<nextsent>in the sentence.
</nextsent>
<nextsent>we refer to the tuple (r,w?) as an attribute of w. the relation type may be grammatical or it may label the position of w?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3187">
<title id=" W02-1029.xml">ensemble methods for automatic thesaurus extraction </title>
<section> individual methods.  </section>
<citcontext>
<prevsection>
<prevsent>term is the (direct/indirect) object of verb 3.
</prevsent>
<prevsent>term is modified by noun or adjective 4.
</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
term is modified by prepositional phrase the relation tuple is then converted to root form using the sussex morphological analyser (minnen etal., 2000) <papid> W00-1427 </papid>and the pos tags are stripped.</citsent>
<aftsection>
<nextsent>the relations for each term are collected together producing context vector of attributes and their frequencies in the corpus.
</nextsent>
<nextsent>figure 1 shows the most strongly weighted attributes and their frequencies for idea.
</nextsent>
<nextsent>our experiments use large quantity of text which we have grouped into range of corpus sizes.
</nextsent>
<nextsent>the approximately 300 million word corpus is random conflation of the bnc and the reuters corpus (re spec tive sizes in table 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3201">
<title id=" W03-1107.xml">feature selection in categorizing procedural expressions </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>in this perspective, that means that the requirements for categorization in such applications are different from those in previous categorizations.
</prevsent>
<prevsent>many studies have been made that are related to qa.fujii et al(2001) studied qa and knowledge acquisition for definition type questions.
</prevsent>
</prevsection>
<citsent citstr=" W02-1904 ">
approaches by seeking any answer text in the pages of faqs or news groups appeared in some studies(hamada et al, 2002; lai et al, 2002).<papid> W02-1904 </papid></citsent>
<aftsection>
<nextsent>automatic qa systems in support center of organizations was addressed in study by kurohashi et al(2000).
</nextsent>
<nextsent>however, most of the previous studies targeting qa address fact type or definition type questions,such as when was mozart born??
</nextsent>
<nextsent>or what is plat inum??.
</nextsent>
<nextsent>previous research addressing the type ofqa relevant to procedures in japanese is inconclu table 1: result from search engine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3202">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>2antecedents are also available structurally in constructions other than?, e.g., few clients other than the state?.
</prevsent>
<prevsent>for computational treatment of other?
</prevsent>
</prevsection>
<citsent citstr=" P01-1009 ">
with structural antecedents see (bierner, 2001).<papid> P01-1009 </papid></citsent>
<aftsection>
<nextsent>the algorithms performance with this feature set is encouraging.
</nextsent>
<nextsent>however, the semantic knowledge the algorithm relies on is not sufficient for many cases of other-anaphors (section 4.2).
</nextsent>
<nextsent>many expressions, word senses and lexical relations are missing from wordnet.
</nextsent>
<nextsent>whereas it includes moscow as hyponym of city, so that the relation between anaphor and antecedent in (1) can be retrieved, it does not include the sense of school as university, nor does it allow to infer that age is risk factor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3203">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many expressions, word senses and lexical relations are missing from wordnet.
</prevsent>
<prevsent>whereas it includes moscow as hyponym of city, so that the relation between anaphor and antecedent in (1) can be retrieved, it does not include the sense of school as university, nor does it allow to infer that age is risk factor.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
there have been efforts to extract missing lexical relations from corpora in order to build new knowledge sources and enrich existing ones (hearst, 1992; <papid> C92-2082 </papid>berland and charniak, 1999; <papid> P99-1008 </papid>poesio et al , 2002).3 however, the size of the used corpora still leads to data sparseness (berland and charniak, 1999) <papid> P99-1008 </papid>and the extraction procedure can therefore require extensive smoothing.</citsent>
<aftsection>
<nextsent>moreover, some relations should probably not be encoded in fixed context independent ontologies at all.
</nextsent>
<nextsent>should, e.g., underspecified and point-of-view dependent hyponymy relations (hearst, 1992) <papid> C92-2082 </papid>be included?</nextsent>
<nextsent>should age,for example, be classified as hyponym of risk factor independent of context?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3205">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many expressions, word senses and lexical relations are missing from wordnet.
</prevsent>
<prevsent>whereas it includes moscow as hyponym of city, so that the relation between anaphor and antecedent in (1) can be retrieved, it does not include the sense of school as university, nor does it allow to infer that age is risk factor.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
there have been efforts to extract missing lexical relations from corpora in order to build new knowledge sources and enrich existing ones (hearst, 1992; <papid> C92-2082 </papid>berland and charniak, 1999; <papid> P99-1008 </papid>poesio et al , 2002).3 however, the size of the used corpora still leads to data sparseness (berland and charniak, 1999) <papid> P99-1008 </papid>and the extraction procedure can therefore require extensive smoothing.</citsent>
<aftsection>
<nextsent>moreover, some relations should probably not be encoded in fixed context independent ontologies at all.
</nextsent>
<nextsent>should, e.g., underspecified and point-of-view dependent hyponymy relations (hearst, 1992) <papid> C92-2082 </papid>be included?</nextsent>
<nextsent>should age,for example, be classified as hyponym of risk factor independent of context?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3208">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> data collection and preparation.  </section>
<citcontext>
<prevsection>
<prevsent>we collected 500 other-anaphors with np antecedents from the wall street journal corpus (penn treebank, release 2).
</prevsent>
<prevsent>this data sample excludes several types of expressions containing other?: (a)list-contexts (ex.
</prevsent>
</prevsection>
<citsent citstr=" W99-0501 ">
4) and other-than contexts (footnote 2), in which the antecedents are available structurally and thus relatively unsophisticated procedure would suffice to find them; (b) idiomatic and discourse connective other?, e.g., on the other 3in parallel, efforts have been made to enrich wordnet by adding information in glosses (harabagiu et al , 1999).<papid> W99-0501 </papid></citsent>
<aftsection>
<nextsent>hand?, which are not anaphoric; and (c) reciprocal each other?
</nextsent>
<nextsent>and one another?, elliptic phrases e.g. one . . .
</nextsent>
<nextsent>the other(s)?
</nextsent>
<nextsent>and one-anaphora, e.g., the other/another one?, which behave like pronouns and thus would require different search method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3209">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> the algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>nps containing possessive np modifier, e.g., spains economy?, were split into possessor phrase, spain?, and possessed entity, economy?.
</prevsent>
<prevsent>we then filtered out null elements and lemmatised all antecedents and anaphors.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
we use naive bayes classifier, specifically the implementation in the weka ml library.4 the training data was generated following the procedure employed by soon et al  (2001) <papid> J01-4004 </papid>for coreference resolution.</citsent>
<aftsection>
<nextsent>every pair of an anaphora nd its closest preceding antecedent created positive training instance.
</nextsent>
<nextsent>to generate negative training instances, we paired anaphors with each of thenps that intervene between the anaphor and its antecedent.
</nextsent>
<nextsent>this procedure produced set of 3,084 antecedent-anaphor pairs, of which 500 (16%) were positive training instances.
</nextsent>
<nextsent>the classifier was trained and tested using 10-fold cross-validation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3211">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> naive bayes without the web.  </section>
<citcontext>
<prevsection>
<prevsent>to exactly one antecedent per anaphor.
</prevsent>
<prevsent>its p, and -measure are 27.8%.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
first, we trained and tested the nb classifier with set of 9 features motivated by our own work on other-anaphora (modjeska, 2002) and previous mlresearch on coreference resolution (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al ., 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>strube et al , 2002).<papid> W02-1040 </papid></citsent>
<aftsection>
<nextsent>4.1 features.
</nextsent>
<nextsent>a set of 9 features, f1, was automatically acquired from the corpus and from additional external resources (see summary in table 1).
</nextsent>
<nextsent>non-semantic features.
</nextsent>
<nextsent>np form is based on the pos tags in the wall street journal corpus and heuristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3212">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> naive bayes without the web.  </section>
<citcontext>
<prevsection>
<prevsent>to exactly one antecedent per anaphor.
</prevsent>
<prevsent>its p, and -measure are 27.8%.
</prevsent>
</prevsection>
<citsent citstr=" W02-1040 ">
first, we trained and tested the nb classifier with set of 9 features motivated by our own work on other-anaphora (modjeska, 2002) and previous mlresearch on coreference resolution (aone and bennett, 1995; mccarthy and lehnert, 1995; soon et al ., 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>strube et al , 2002).<papid> W02-1040 </papid></citsent>
<aftsection>
<nextsent>4.1 features.
</nextsent>
<nextsent>a set of 9 features, f1, was automatically acquired from the corpus and from additional external resources (see summary in table 1).
</nextsent>
<nextsent>non-semantic features.
</nextsent>
<nextsent>np form is based on the pos tags in the wall street journal corpus and heuristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3214">
<title id=" W03-1023.xml">using the web in machine learning for other anaphora resolution </title>
<section> related work and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>our approach is the first ml approach to any kind of anaphora that integrates the web.
</prevsent>
<prevsent>using the web as knowledge source has considerable advantages.first, the size of the web almost eliminates the problem of data sparseness for our task.
</prevsent>
</prevsection>
<citsent citstr=" W02-1030 ">
for this reason, using the web has proved successful in several other fields of nlp, e.g., machine translation(grefenstette, 1999) and bigram frequency estimation (keller et al , 2002).<papid> W02-1030 </papid></citsent>
<aftsection>
<nextsent>in particular, (keller et al , 2002) <papid> W02-1030 </papid>have shown that using the web handles data sparseness better than smoothing.</nextsent>
<nextsent>second, we donot process the returned web pages in any way (tagging, parsing, e.g.), unlike e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3218">
<title id=" W03-1316.xml">selecting text features for gene name classification from documents to terms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>classification methods typically relyon supervised machine learning techniques that examine the wider context in which terms are used.
</prevsent>
<prevsent>for example, ray chaudhuri et al (2002) used document-based word counts and naive bayesian classification, maximum entropy modelling and nearest-neighbour classification to assign the go ontology codes to set of genes.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
recently, sup port-vector machines (svms, (vapnik, 1995)) have been widely used as fast, effective and reliable means for text-based classification, both for document classification (joachims, 1998) and classification of specific named entities (stapley et al, 2002; kazama et al, 2002).<papid> W02-0301 </papid></citsent>
<aftsection>
<nextsent>regardless of the learning approach and target entities (documents or terms), different types of text features have been employed for the classification task.
</nextsent>
<nextsent>for example, bag-of-words approach was used by stapley et al (2002) to classify proteins, while collier et al (2001) used orthographic features to classify different biological entities.
</nextsent>
<nextsent>on the other hand, hatzivassiloglou et al (2001) experimented with morphological, distributional and shallow-syntactic information to discriminate between proteins, genes and rnas.
</nextsent>
<nextsent>in this paper we analyse the impact of different types of features on the performance of an svm based classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3220">
<title id=" W02-1117.xml">a character net based chinese text segmentation method </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for examples:
</prevsent>
<prevsent>      these words should be obtained:
</prevsent>
</prevsection>
<citsent citstr=" J97-4004 ">
ff the ambiguous string is  fi fl .there are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [guo 1997; <papid> J97-4004 </papid>sproat et al 1996; <papid> J96-3004 </papid>gu and mao 1994; li et al 1991; wang et al 1991b; wang et al 1990].</citsent>
<aftsection>
<nextsent>the second is the words finding automaton based on the aho-corasick algorithm [hong-i and lua].
</nextsent>
<nextsent>the former requires three scans of the input character string.
</nextsent>
<nextsent>in addition, during each scan, backtracking has to be performed in cases where dictionary search fails.
</nextsent>
<nextsent>after that, the word recognition is built based on the candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3221">
<title id=" W02-1117.xml">a character net based chinese text segmentation method </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for examples:
</prevsent>
<prevsent>      these words should be obtained:
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
ff the ambiguous string is  fi fl .there are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [guo 1997; <papid> J97-4004 </papid>sproat et al 1996; <papid> J96-3004 </papid>gu and mao 1994; li et al 1991; wang et al 1991b; wang et al 1990].</citsent>
<aftsection>
<nextsent>the second is the words finding automaton based on the aho-corasick algorithm [hong-i and lua].
</nextsent>
<nextsent>the former requires three scans of the input character string.
</nextsent>
<nextsent>in addition, during each scan, backtracking has to be performed in cases where dictionary search fails.
</nextsent>
<nextsent>after that, the word recognition is built based on the candidates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3222">
<title id=" W03-0405.xml">unsupervised personal name disambiguation </title>
<section> jim clark - clock maker from colorado.  </section>
<citcontext>
<prevsection>
<prevsent>jim clark - gun dealer in louisiana.
</prevsent>
<prevsent>in this paper, we present method for distinguishing the real world referent of given name in context.
</prevsent>
</prevsection>
<citsent citstr=" A97-1030 ">
approaches to this problem include wacholder et al (1997), <papid> A97-1030 </papid>focusing on the variation of surface name forgiven referent, and smith and crane (2002), resolving geographic name ambiguity.</citsent>
<aftsection>
<nextsent>we present preliminary evaluation on pseudonames: conflations of multiple personal names, constructed in the same way pseudo words are used for word sense disambiguation (gale et al, 1992).
</nextsent>
<nextsent>we then present corroborating evidence from real personal name polysemy to show that this technique works in practice.
</nextsent>
<nextsent>miles davis birthday may 26(5), may 25(5) birth year 1926(82), 1967(18), 1969(9)... occupation trumpeter(38), artist(10), player(5)... birthplace alton(7), illinois(6) joerg haider birth year 1950(6) occupation leader(198) politician(93) chairman(6)... birthplace austria(1) table 1: extracted biographical information from 1000 web pages.
</nextsent>
<nextsent>another topic of recent interest is in producing biographical summaries from corpora (schiffman et al., 2001).<papid> P01-1059 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3223">
<title id=" W03-0405.xml">unsupervised personal name disambiguation </title>
<section> jim clark - clock maker from colorado.  </section>
<citcontext>
<prevsection>
<prevsent>we then present corroborating evidence from real personal name polysemy to show that this technique works in practice.
</prevsent>
<prevsent>miles davis birthday may 26(5), may 25(5) birth year 1926(82), 1967(18), 1969(9)... occupation trumpeter(38), artist(10), player(5)... birthplace alton(7), illinois(6) joerg haider birth year 1950(6) occupation leader(198) politician(93) chairman(6)... birthplace austria(1) table 1: extracted biographical information from 1000 web pages.
</prevsent>
</prevsection>
<citsent citstr=" P01-1059 ">
another topic of recent interest is in producing biographical summaries from corpora (schiffman et al., 2001).<papid> P01-1059 </papid></citsent>
<aftsection>
<nextsent>along with disambiguation, our system simultaneously collects biographic information (table 1).
</nextsent>
<nextsent>the relevant biographical attributes are depicted along with clustering which shows the distinct referents (section 4.1).
</nextsent>
<nextsent>2 robust extraction of categorical.
</nextsent>
<nextsent>biographic data past work on this task (e.g. bagga and baldwin,1998) <papid> P98-1012 </papid>has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the clark case.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3224">
<title id=" W03-0405.xml">unsupervised personal name disambiguation </title>
<section> jim clark - clock maker from colorado.  </section>
<citcontext>
<prevsection>
<prevsent>the relevant biographical attributes are depicted along with clustering which shows the distinct referents (section 4.1).
</prevsent>
<prevsent>2 robust extraction of categorical.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
biographic data past work on this task (e.g. bagga and baldwin,1998) <papid> P98-1012 </papid>has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the clark case.</citsent>
<aftsection>
<nextsent>how ever, in the specialized case of personal names, there is more precise information available.
</nextsent>
<nextsent>in particular, information extraction techniques can add high precision, categorical information such as approximate age/date-of-birth, nationality and occupation.
</nextsent>
<nextsent>this categorical data can support or exclude candidate name referent matches with higher confidence and greater pinpoint accuracy than via simple context vector-style features alone.another major source of disambiguation information for proper nouns is the space of associatednames.
</nextsent>
<nextsent>while these names could be used in undifferentiated vector-based bag-of-words model, further accuracy can be gained by extracting specific types of association, such as familial relationships (e.g. son, wife), employment relationships (e.g.manager of), and nationality as distinct from simple term co-occurrence in window.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3225">
<title id=" W03-0405.xml">unsupervised personal name disambiguation </title>
<section> jim clark - clock maker from colorado.  </section>
<citcontext>
<prevsection>
<prevsent>this has the advantage of being more flexible, portable and scalable, and potentially having higher precision and recall.
</prevsent>
<prevsent>it also has the advantage of being applicable to new languages for which no developer with sufficient knowledge of the language is available.
</prevsent>
</prevsection>
<citsent citstr=" A00-1039 ">
string patterns with  person  and  birth year  extractions where  birth year  is year extraction graded by #correct extractions/#total extractions  person  (  birth year  ? \d\d\d\d)  person   birth year ?\d\d\d\d  person  was born in  birth year   person  ( b. birth year  extractions of  person  with potential  birth years  web pages w/ person  and  birth year  sentences with  person  and  birth year  sub strings with  person  and  birth year  web pages with  person  sentences with  person  1642 1685 1869 1770 1899 ludwig van beethoven humphrey bogart mohan das gandhi john sebastian bach isaac newton  person   birth year  figure 1: learning extraction patterns from filled templates and web pages in the late 90s, there was substantial body of research on learning information extraction patterns from templates (huffman, 1995; brin, 1998; califf and mooney, 1998; freitag and mccallum, 1999; yangarber et al, 2000; <papid> A00-1039 </papid>ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>these techniques provide way to bootstrap information extraction patterns from set of example extractions or seed facts, where tuple with the filled roles for the desired pattern are given.
</nextsent>
<nextsent>for the task of extracting biographical information, each example would include the personal name and the biographic feature.
</nextsent>
<nextsent>for example, training data for the pattern born in might be (wolfgang amadeus mozart?,1756).
</nextsent>
<nextsent>given this set of examples, each method generates patterns differently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3226">
<title id=" W03-0405.xml">unsupervised personal name disambiguation </title>
<section> jim clark - clock maker from colorado.  </section>
<citcontext>
<prevsection>
<prevsent>this has the advantage of being more flexible, portable and scalable, and potentially having higher precision and recall.
</prevsent>
<prevsent>it also has the advantage of being applicable to new languages for which no developer with sufficient knowledge of the language is available.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
string patterns with  person  and  birth year  extractions where  birth year  is year extraction graded by #correct extractions/#total extractions  person  (  birth year  ? \d\d\d\d)  person   birth year ?\d\d\d\d  person  was born in  birth year   person  ( b. birth year  extractions of  person  with potential  birth years  web pages w/ person  and  birth year  sentences with  person  and  birth year  sub strings with  person  and  birth year  web pages with  person  sentences with  person  1642 1685 1869 1770 1899 ludwig van beethoven humphrey bogart mohan das gandhi john sebastian bach isaac newton  person   birth year  figure 1: learning extraction patterns from filled templates and web pages in the late 90s, there was substantial body of research on learning information extraction patterns from templates (huffman, 1995; brin, 1998; califf and mooney, 1998; freitag and mccallum, 1999; yangarber et al, 2000; <papid> A00-1039 </papid>ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>these techniques provide way to bootstrap information extraction patterns from set of example extractions or seed facts, where tuple with the filled roles for the desired pattern are given.
</nextsent>
<nextsent>for the task of extracting biographical information, each example would include the personal name and the biographic feature.
</nextsent>
<nextsent>for example, training data for the pattern born in might be (wolfgang amadeus mozart?,1756).
</nextsent>
<nextsent>given this set of examples, each method generates patterns differently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3231">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they occur in wide variety of syntactic configurations in different languages (e.g. in the case of english, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.).
</prevsent>
<prevsent>decomposability is description of the degree to which the semantics of an mwe can be ascribed to those of its parts (riehemann, 2001; sag et al , 2002).
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
analysis of the semantic correlation between the constituent parts and whole of an mwe is perhaps more commonly discussed under the banner of compositionality (nunberg et al , 1994; lin, 1999).<papid> P99-1041 </papid></citsent>
<aftsection>
<nextsent>our claim here is that the semantics of the mwe are deconstructed and the parts coerced into often idiosyncratic interpretations to attain semantic alignment, rather than the other way around.
</nextsent>
<nextsent>one idiom which illustrates this process is spill the beans,where the semantics of reveal?(secret?)
</nextsent>
<nextsent>are decomposed such that spill is coerced into the idiosyncratic interpretation of reveal?
</nextsent>
<nextsent>and beans into the idiosyncratic interpretation of secret?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3232">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> past research.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 provides basic outline of the resources used in this research, lsa, the mwe extraction methods, and measures used to evaluate our method.
</prevsent>
<prevsent>section 4 then provides evaluation of the proposed method, and the paper is concluded with brief discussion in section 5.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
although there has been some useful work on com positionality in statistical machine translation (e.g.melamed (1997)), <papid> W97-0311 </papid>there has been little work on detecting non-compositional?</citsent>
<aftsection>
<nextsent>(i.e. non-decomposableand idiosyncratic ally decomposable) items of variable syntactic type in monolingual corpora.
</nextsent>
<nextsent>one interesting exception is lin (1999), <papid> P99-1041 </papid>whose approach is explained as follows: the intuitive idea behind the method isthat the metaphorical usage of non compositional expression causes it tohave different distributional characteristic than expressions that are similar to its literal meaning.the expressions he uses are taken from collocation database (lin, 1998<papid> P98-2127 </papid>b).</nextsent>
<nextsent>these expressions that are similar to [their] literal meaning?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3234">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> past research.  </section>
<citcontext>
<prevsection>
<prevsent>although there has been some useful work on com positionality in statistical machine translation (e.g.melamed (1997)), <papid> W97-0311 </papid>there has been little work on detecting non-compositional?</prevsent>
<prevsent>(i.e. non-decomposableand idiosyncratic ally decomposable) items of variable syntactic type in monolingual corpora.</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
one interesting exception is lin (1999), <papid> P99-1041 </papid>whose approach is explained as follows: the intuitive idea behind the method isthat the metaphorical usage of non compositional expression causes it tohave different distributional characteristic than expressions that are similar to its literal meaning.the expressions he uses are taken from collocation database (lin, 1998<papid> P98-2127 </papid>b).</citsent>
<aftsection>
<nextsent>these expressions that are similar to [their] literal meaning?
</nextsent>
<nextsent>are found by substituting each of the words in the expression withthe 10 most similar words according to corpus derived thesaurus (lin, 1998<papid> P98-2127 </papid>a).</nextsent>
<nextsent>lin models the distributional difference as significant difference in mutual information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3238">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> past research.  </section>
<citcontext>
<prevsection>
<prevsent>the semantic similarity between multiword expression and its head was used as an indicator of decomposability.
</prevsent>
<prevsent>the assumption was that if verb-particle was sufficiently similar to its he adverb, then the verb contributed its simplex meaning.
</prevsent>
</prevsection>
<citsent citstr=" W03-1809 ">
it gave empirical backing to this assumption by showing that annotator judgements for verb particle decomposability correlate significantly withnon-expert human judgements on the similarity between verb-particle construction and its head verb.bannard et al  (2003) <papid> W03-1809 </papid>extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not.</citsent>
<aftsection>
<nextsent>they successfully combined statistical and distributional techniques (including lsa) with substitution test in analysingcompositionality.
</nextsent>
<nextsent>mccarthy et al  (2003) <papid> W03-1810 </papid>also targeted verb-particles for study on compositionality, and judged compositionality according to the degree of overlap in the most similar words to the verb particle and head verb, e.g., to determine composi tionality.</nextsent>
<nextsent>we are not the first to consider applying lsa to mwes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3239">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> past research.  </section>
<citcontext>
<prevsection>
<prevsent>it gave empirical backing to this assumption by showing that annotator judgements for verb particle decomposability correlate significantly withnon-expert human judgements on the similarity between verb-particle construction and its head verb.bannard et al  (2003) <papid> W03-1809 </papid>extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not.</prevsent>
<prevsent>they successfully combined statistical and distributional techniques (including lsa) with substitution test in analysingcompositionality.</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
mccarthy et al  (2003) <papid> W03-1810 </papid>also targeted verb-particles for study on compositionality, and judged compositionality according to the degree of overlap in the most similar words to the verb particle and head verb, e.g., to determine composi tionality.</citsent>
<aftsection>
<nextsent>we are not the first to consider applying lsa to mwes.
</nextsent>
<nextsent>schone and jurafsky (2001) <papid> W01-0513 </papid>applied lsa tothe analysis of mwes in the task of mwe discovery, by way of rescoring mwes extracted from acorpus.</nextsent>
<nextsent>the major point of divergence from this research is that schone and jurafsky focused specifically on mwe extraction, whereas we are interested in the downstream task of semantically classifying attested mwes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3240">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> past research.  </section>
<citcontext>
<prevsection>
<prevsent>mccarthy et al  (2003) <papid> W03-1810 </papid>also targeted verb-particles for study on compositionality, and judged compositionality according to the degree of overlap in the most similar words to the verb particle and head verb, e.g., to determine composi tionality.</prevsent>
<prevsent>we are not the first to consider applying lsa to mwes.</prevsent>
</prevsection>
<citsent citstr=" W01-0513 ">
schone and jurafsky (2001) <papid> W01-0513 </papid>applied lsa tothe analysis of mwes in the task of mwe discovery, by way of rescoring mwes extracted from acorpus.</citsent>
<aftsection>
<nextsent>the major point of divergence from this research is that schone and jurafsky focused specifically on mwe extraction, whereas we are interested in the downstream task of semantically classifying attested mwes.
</nextsent>
<nextsent>in this section, we outline the resources used in evaluation, give an informal introduction to the lsa model, sketch how we extracted the mwes from corpus data, and describe number of methods for modelling decomposability within hierarchical lexicon.
</nextsent>
<nextsent>3.1 resources and target mwes.
</nextsent>
<nextsent>the particular reference lexicon we use to evaluate our technique is wordnet 1.7 (miller etal., 1990), due to its public availability, hierarchical structure and wide coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3244">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> resources and techniques.  </section>
<citcontext>
<prevsection>
<prevsent>similarity between two vectors (points) was measured using the cosine of the angle between them, in the same way as the similarity between query and document is often measured in information retrieval (baeza-yates and ribiero-neto, 1999, p28).
</prevsent>
<prevsent>effectively, we could use lsa to measure the extent to which two words or mwes and usually occur in similar contexts.since the corpora had been tagged with parts-of speech, we could build syntactic distinctions into the lsa models ? instead of just giving vector forthe string test we were able to build separate vectors for the nouns, verbs and adjectives test.
</prevsent>
</prevsection>
<citsent citstr=" N03-1036 ">
this combination of technologies was also used to good effect by widdows (2003): <papid> N03-1036 </papid>an example of the contribution of part-of-speech information to extracting semantic neighbours of the word fire is shown in table 1.</citsent>
<aftsection>
<nextsent>as can be seen, the noun fire (as in the substance/element) and the verb fire (mainly used to mean firing some sort of weapon) are related to quite different areas of meaning.
</nextsent>
<nextsent>building single vector for the string fire confuses this distinction ? the neighbours of fire treated just as string include words related to both the meaning of fire as noun(more frequent in the bnc) and as verb.
</nextsent>
<nextsent>the appropriate granularity of syntactic classifications is an open question for this kind of research: treating allthe possible verbs categories as different (e.g. distinguishing infinitive from finite from gerund forms) led to data sparseness, and instead we considered verb?
</nextsent>
<nextsent>as single part-of-speech type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3245">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> resources and techniques.  </section>
<citcontext>
<prevsection>
<prevsent>as single part-of-speech type.
</prevsent>
<prevsent>3.3 mwe extraction methods.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
nn compounds were extracted from the wsj byfirst tagging the data with fntbl 1.0 (ngai and florian, 2001) <papid> N01-1006 </papid>and then simply taking noun bigrams (adjoined on both sides by non-nouns to assure the bigram is not part of larger compound nominal).</citsent>
<aftsection>
<nextsent>out of these, we selected those compounds that are listed in wordnet, resulting in 5,405 nn compound types (208,000 tokens).extraction of the verb-particles was considerably more involved, and drew on the method of baldwin and villavicencio (2002).<papid> W02-2001 </papid></nextsent>
<nextsent>essentially, we used pos tagger and chunker (both built using fntbl 1.0 (ngai and florian, 2001)) <papid> N01-1006 </papid>to first (re)tagthe bnc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3246">
<title id=" W03-1812.xml">an empirical model of multiword expression decomposability </title>
<section> resources and techniques.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 mwe extraction methods.
</prevsent>
<prevsent>nn compounds were extracted from the wsj byfirst tagging the data with fntbl 1.0 (ngai and florian, 2001) <papid> N01-1006 </papid>and then simply taking noun bigrams (adjoined on both sides by non-nouns to assure the bigram is not part of larger compound nominal).</prevsent>
</prevsection>
<citsent citstr=" W02-2001 ">
out of these, we selected those compounds that are listed in wordnet, resulting in 5,405 nn compound types (208,000 tokens).extraction of the verb-particles was considerably more involved, and drew on the method of baldwin and villavicencio (2002).<papid> W02-2001 </papid></citsent>
<aftsection>
<nextsent>essentially, we used pos tagger and chunker (both built using fntbl 1.0 (ngai and florian, 2001)) <papid> N01-1006 </papid>to first (re)tagthe bnc.</nextsent>
<nextsent>this allowed us to extract verb-particle tokens through use of the particle pos and chunk tags returned by the two systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3249">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper presents new word-sense disambiguation and pos tagging experiments, and integrates apparently conflicting reports from other recent work.
</prevsent>
<prevsent>the success and widespread adoption of probabilistic models in nlp has led to numerous variant methods for any given task, and it can be difficult to tell what aspects of system have led to its relative successes or failures.
</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
as an example, maximum entropy taggers have achieved very good performance (ratnaparkhi, 1998; toutanova and manning, 2000;<papid> W00-1308 </papid>lafferty et al, 2001), but almost identical performance has also come from finely tuned hmm models (brants, 2000; <papid> A00-1031 </papid>thede and harper, 1999).<papid> P99-1023 </papid></citsent>
<aftsection>
<nextsent>are any performance gains due to the sequence model used,the maximum entropy approach to parameter estimation, or the features employed by the system recent experiments have given conflicting recommendations.
</nextsent>
<nextsent>johnson (2001) <papid> P01-1042 </papid>finds that conditionally trained pcfg marginally outperforms standard jointly trained pcfg, but that conditional shift reduce model performs worse than joint formu lation.</nextsent>
<nextsent>lafferty et al (2001) suggest on abstract grounds that conditional models will suffer from phenomenon called label bias (bottou, 1991) ? see section 3 ? but is this significant effect for real nlp problems?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3250">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper presents new word-sense disambiguation and pos tagging experiments, and integrates apparently conflicting reports from other recent work.
</prevsent>
<prevsent>the success and widespread adoption of probabilistic models in nlp has led to numerous variant methods for any given task, and it can be difficult to tell what aspects of system have led to its relative successes or failures.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
as an example, maximum entropy taggers have achieved very good performance (ratnaparkhi, 1998; toutanova and manning, 2000;<papid> W00-1308 </papid>lafferty et al, 2001), but almost identical performance has also come from finely tuned hmm models (brants, 2000; <papid> A00-1031 </papid>thede and harper, 1999).<papid> P99-1023 </papid></citsent>
<aftsection>
<nextsent>are any performance gains due to the sequence model used,the maximum entropy approach to parameter estimation, or the features employed by the system recent experiments have given conflicting recommendations.
</nextsent>
<nextsent>johnson (2001) <papid> P01-1042 </papid>finds that conditionally trained pcfg marginally outperforms standard jointly trained pcfg, but that conditional shift reduce model performs worse than joint formu lation.</nextsent>
<nextsent>lafferty et al (2001) suggest on abstract grounds that conditional models will suffer from phenomenon called label bias (bottou, 1991) ? see section 3 ? but is this significant effect for real nlp problems?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3251">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper presents new word-sense disambiguation and pos tagging experiments, and integrates apparently conflicting reports from other recent work.
</prevsent>
<prevsent>the success and widespread adoption of probabilistic models in nlp has led to numerous variant methods for any given task, and it can be difficult to tell what aspects of system have led to its relative successes or failures.
</prevsent>
</prevsection>
<citsent citstr=" P99-1023 ">
as an example, maximum entropy taggers have achieved very good performance (ratnaparkhi, 1998; toutanova and manning, 2000;<papid> W00-1308 </papid>lafferty et al, 2001), but almost identical performance has also come from finely tuned hmm models (brants, 2000; <papid> A00-1031 </papid>thede and harper, 1999).<papid> P99-1023 </papid></citsent>
<aftsection>
<nextsent>are any performance gains due to the sequence model used,the maximum entropy approach to parameter estimation, or the features employed by the system recent experiments have given conflicting recommendations.
</nextsent>
<nextsent>johnson (2001) <papid> P01-1042 </papid>finds that conditionally trained pcfg marginally outperforms standard jointly trained pcfg, but that conditional shift reduce model performs worse than joint formu lation.</nextsent>
<nextsent>lafferty et al (2001) suggest on abstract grounds that conditional models will suffer from phenomenon called label bias (bottou, 1991) ? see section 3 ? but is this significant effect for real nlp problems?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3252">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as an example, maximum entropy taggers have achieved very good performance (ratnaparkhi, 1998; toutanova and manning, 2000;<papid> W00-1308 </papid>lafferty et al, 2001), but almost identical performance has also come from finely tuned hmm models (brants, 2000; <papid> A00-1031 </papid>thede and harper, 1999).<papid> P99-1023 </papid></prevsent>
<prevsent>are any performance gains due to the sequence model used,the maximum entropy approach to parameter estimation, or the features employed by the system recent experiments have given conflicting recommendations.</prevsent>
</prevsection>
<citsent citstr=" P01-1042 ">
johnson (2001) <papid> P01-1042 </papid>finds that conditionally trained pcfg marginally outperforms standard jointly trained pcfg, but that conditional shift reduce model performs worse than joint formu lation.</citsent>
<aftsection>
<nextsent>lafferty et al (2001) suggest on abstract grounds that conditional models will suffer from phenomenon called label bias (bottou, 1991) ? see section 3 ? but is this significant effect for real nlp problems?
</nextsent>
<nextsent>we suggest that the results in the literature, along with the new results we present in this work, can be explained by the following generalizations:?
</nextsent>
<nextsent>the ability to include better features in well founded fashion leads to better performance.
</nextsent>
<nextsent>for fixed features, assumptions implicit in the model structure have large impact on errors.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3254">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> objective functions: naive-bayes.  </section>
<citcontext>
<prevsection>
<prevsent>we took as data the collection of senseval-2 english lexical sample wsd corpora.2 we set the nb model parameters in several ways.
</prevsent>
<prevsent>we optimized jl (using the rfes).3 we also optimized scl and (the log of) cl, using conjugate gradient (cg) method (press et al, 1988).4 for cl and scl, we optimized each objective both over the space of all distributions and over the sub space of non-deficient models (giving cl? and scl?).
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
acc was not directly optimized.unconstrained cl corresponds exactly to conditional maximum entropy model (berger et al, 1996; <papid> J96-1002 </papid>lafferty et al, 2001).</citsent>
<aftsection>
<nextsent>this particular case, where there are multiple explanatory variables and single categorical response variable, is also precisely the well-studied statistical model of (multinomial) logistic regression (agresti, 1990).
</nextsent>
<nextsent>its optimization problem is concave (over log parameters) and therefore has unique global maximum.
</nextsent>
<nextsent>for cl?, scl, and scl?, we are only guaranteed local optima, but in practice we detected no maxima which were not 2http://www.sle.sharp.co.uk/senseval2/ 3smoothing is an important factor for this task.
</nextsent>
<nextsent>so that the various estimates would be smoothed as similarly as possible, we smoothed implicitly, by adding smoothing data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3255">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> objective functions: naive-bayes.  </section>
<citcontext>
<prevsection>
<prevsent>their claim seems too strong here; even smaller datasets often show benefit to accuracy from cl estimation, although all would qualify as small on their scale.
</prevsent>
<prevsent>since the number of senses and skew towards common senses is so varied between senseval-2words, we turned to larger datasets to test the effective break-even?
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
size for wsd data, using thehard and line data from leacock et al (1998).<papid> J98-1006 </papid></citsent>
<aftsection>
<nextsent>figure 4 shows the accuracy of nb-cl and nb-jl as the amount of training data increases.
</nextsent>
<nextsent>conditional beats 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0 1000 2000 3000 4000 748 9 : ; : ;   =2  ? =2: @   c u ra y a)b d f b g i4j b c i4j 0.79 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0 1000 2000 3000 4000 m o o q&r; t r2o s c u ra y v-w x t w n z4[ \ o t z)[ (a) (b) figure 4: conditional nb is better than joint nb for wsd given all but possibly the smallest training sets, and the advantage increases with training set size.
</nextsent>
<nextsent>(a) line?
</nextsent>
<nextsent>(b) hard joint for all but the smallest training sizes, and the improvement is greater with larger training sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3258">
<title id=" W02-1002.xml">conditional structure versus conditional estimation in nlp models </title>
<section> related results.  </section>
<citcontext>
<prevsection>
<prevsent>we take these two results not as contradictory, but as confirmation that conditional estimation, though often slow, generally improves accuracy, while conditional model structures must be used with caution.the conditional shift-reduce parsing model he describes can be expected to exhibit the same type ofcompeting-variable explaining-away issues that occur in memm tagging.
</prevsent>
<prevsent>as an extreme example, if all words have been shifted, the rest of the parser actions will be reductions with probability one.
</prevsent>
</prevsection>
<citsent citstr=" P96-1024 ">
goodman (1996) <papid> P96-1024 </papid>describes algorithms for parse selection where the criterion being maximized inparse selection is the bracket-based accuracy measure that parses are scored by.</citsent>
<aftsection>
<nextsent>he shows test-set accuracy benefit from optimizing accuracy directly.
</nextsent>
<nextsent>finally, model structure and parameter estimation are not the entirety of factors which determine the behavior of model.
</nextsent>
<nextsent>model features are crucial, and the ability to incorporate richer features in relatively sensible way also leads to improved models.
</nextsent>
<nextsent>this is the main basis of the real world benefit which has been derived from maxent models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3259">
<title id=" W03-0402.xml">an svm based voting algorithm with application to parse reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>intuitively, it is the local normalization that results in the label bias problem.one way of using discriminative machine learning algorithms in sequential models is to rerank the n-best outputs of generative system.
</prevsent>
<prevsent>reranking uses global features as well as local features, and does not make local normalization.
</prevsent>
</prevsection>
<citsent citstr=" P93-1005 ">
if the output set is large enough, the reranking approach may help to alleviate the impact of the label bias problem, because the victim parses (i.e. those parses which get penalized due to the label biasproblem) will have chance to take part in the rerank ing.in recent years, reranking techniques have been successfully applied to the so-called history-based models (black et al, 1993), <papid> P93-1005 </papid>especially to parsing (collins, 2000; collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>in history-based model, the current decision depends on the decisions made previously.
</nextsent>
<nextsent>therefore, we may regard parsing as special form of sequential model without losing generality.
</nextsent>
<nextsent>collins (2000) has proposed two reranking algorithms to rerank the output of an existing parser (collins, 1999, model 2).
</nextsent>
<nextsent>one is based on markov random fields, and the other is based on boosting approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3260">
<title id=" W03-0402.xml">an svm based voting algorithm with application to parse reranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>intuitively, it is the local normalization that results in the label bias problem.one way of using discriminative machine learning algorithms in sequential models is to rerank the n-best outputs of generative system.
</prevsent>
<prevsent>reranking uses global features as well as local features, and does not make local normalization.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
if the output set is large enough, the reranking approach may help to alleviate the impact of the label bias problem, because the victim parses (i.e. those parses which get penalized due to the label biasproblem) will have chance to take part in the rerank ing.in recent years, reranking techniques have been successfully applied to the so-called history-based models (black et al, 1993), <papid> P93-1005 </papid>especially to parsing (collins, 2000; collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>in history-based model, the current decision depends on the decisions made previously.
</nextsent>
<nextsent>therefore, we may regard parsing as special form of sequential model without losing generality.
</nextsent>
<nextsent>collins (2000) has proposed two reranking algorithms to rerank the output of an existing parser (collins, 1999, model 2).
</nextsent>
<nextsent>one is based on markov random fields, and the other is based on boosting approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3278">
<title id=" W03-0402.xml">an svm based voting algorithm with application to parse reranking </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in ordinal regression, the marg inis min |f(ri) ? f(ri1)|, where is the regression function for ordinal values.
</prevsent>
<prevsent>in our algorithm, the margin is min |score(xi1)?
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
score(xij)|.in (kudo and matsumoto, 2001), <papid> N01-1025 </papid>svms have been employed in the np chunking task, typical labeling prob lem.</citsent>
<aftsection>
<nextsent>however, they have used deterministic algorithm for decoding.in (collins, 2000), two reranking algorithms were proposed.
</nextsent>
<nextsent>in both of these two models, the loss functions are computed directly on the feature space.
</nextsent>
<nextsent>all the features are manually defined.in (collins and duffy, 2002), <papid> P02-1034 </papid>the voted perceptron algorithm was used to in parse reranking.</nextsent>
<nextsent>it was shown in (freund and schapire, 1999; graepel et al, 2001) that error bound of (voted) perceptron is related to margins existing in the training data, but these algorithm are not supposed to maximize margins.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3287">
<title id=" W03-0402.xml">an svm based voting algorithm with application to parse reranking </title>
<section> experiments and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>0 cbs, 2 cbs are the percentage of sentences with 0 or ? 2 crossing brackets respectively.
</prevsent>
<prevsent>co99 = model 2 of (collins, 1999).
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
ch00 = (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>co00 = (collins, 2000).
</nextsent>
<nextsent>40 words (2245 sentences) model lr lp cbs 0 cbs 2 cbs co99 88.5% 88.7% 0.92 66.7% 87.1% ch00 90.1% 90.1% 0.74 70.1% 89.6% co00 90.1% 90.4% 0.73 70.7% 89.6% svm 89.9% 90.3% 0.75 71.7% 89.4% 100 words (2416 sentences) model lr lp cbs 0 cbs 2 cbs co99 88.1% 88.3% 1.06 64.0% 85.1% ch00 89.6% 89.5% 0.88 67.6% 87.7% co00 89.6% 89.9% 0.87 68.3% 87.7% svm 89.4% 89.8% 0.89 69.2% 87.6% where fi is the result of the ith svm.
</nextsent>
<nextsent>the parse with maximal value of pi(y = 1|fi) is chosen as the top most parse.
</nextsent>
<nextsent>experiments on the development data shows that the result is better if aefib is much larger than 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3298">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> research issues and our approach.  </section>
<citcontext>
<prevsection>
<prevsent>(robin and mckeown, 1996),  derivation of paraphrases through existing lexical resources, e.g.
</prevsent>
<prevsent>(kurohashi et al, 1999),  corpus-based statistical methods inspired by the work on information extraction, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P99-1044 ">
(jacquemin, 1999; <papid> P99-1044 </papid>lin and pantel, 2001), and  alignment-based acquisition of paraphrases from comparable corpora, e.g.</citsent>
<aftsection>
<nextsent>(barzilay and mckeown, 2001; <papid> P01-1008 </papid>shinyama et al, 2002; barzilay and lee, 2003).<papid> N03-1003 </papid>one remaining issue is how effectively these methods contribute to the generation of paraphrases in our application-oriented context.</nextsent>
<nextsent>2.3 paraphrase representation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3299">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> research issues and our approach.  </section>
<citcontext>
<prevsection>
<prevsent>(kurohashi et al, 1999),  corpus-based statistical methods inspired by the work on information extraction, e.g.
</prevsent>
<prevsent>(jacquemin, 1999; <papid> P99-1044 </papid>lin and pantel, 2001), and  alignment-based acquisition of paraphrases from comparable corpora, e.g.</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
(barzilay and mckeown, 2001; <papid> P01-1008 </papid>shinyama et al, 2002; barzilay and lee, 2003).<papid> N03-1003 </papid>one remaining issue is how effectively these methods contribute to the generation of paraphrases in our application-oriented context.</citsent>
<aftsection>
<nextsent>2.3 paraphrase representation.
</nextsent>
<nextsent>one of the findings obtained in the previous studies for paraphrase acquisition is that the automatic acquisition of candidates of paraphrases is quite realizable for various types of source data but acquired collections tend to be rather noisy and need manual cleaning as reported in, for example, (lin and pan tel, 2001).
</nextsent>
<nextsent>given that, it turns out to be important to devise an effective way of facilitating manual correction and standardized scheme for representing and storing paraphrase patterns as shared resources.our approach is (a) to define first fully express ible formalism for representing paraphrases at the level of tree-to-tree transformation and (b) devise an additional layer of representation on its top that is designed to facilitate hand coding transformation rules.
</nextsent>
<nextsent>2.4 post-transfer text revision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3300">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> research issues and our approach.  </section>
<citcontext>
<prevsection>
<prevsent>(kurohashi et al, 1999),  corpus-based statistical methods inspired by the work on information extraction, e.g.
</prevsent>
<prevsent>(jacquemin, 1999; <papid> P99-1044 </papid>lin and pantel, 2001), and  alignment-based acquisition of paraphrases from comparable corpora, e.g.</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
(barzilay and mckeown, 2001; <papid> P01-1008 </papid>shinyama et al, 2002; barzilay and lee, 2003).<papid> N03-1003 </papid>one remaining issue is how effectively these methods contribute to the generation of paraphrases in our application-oriented context.</citsent>
<aftsection>
<nextsent>2.3 paraphrase representation.
</nextsent>
<nextsent>one of the findings obtained in the previous studies for paraphrase acquisition is that the automatic acquisition of candidates of paraphrases is quite realizable for various types of source data but acquired collections tend to be rather noisy and need manual cleaning as reported in, for example, (lin and pan tel, 2001).
</nextsent>
<nextsent>given that, it turns out to be important to devise an effective way of facilitating manual correction and standardized scheme for representing and storing paraphrase patterns as shared resources.our approach is (a) to define first fully express ible formalism for representing paraphrases at the level of tree-to-tree transformation and (b) devise an additional layer of representation on its top that is designed to facilitate hand coding transformation rules.
</nextsent>
<nextsent>2.4 post-transfer text revision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3301">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> research issues and our approach.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 post-transfer text revision.
</prevsent>
<prevsent>in paraphrasing, the morpho-syntactic information of source sentence should be accessible throughout the transfer process since morphosyntactic transformation in itself can often be motivation or goal of paraphrasing.
</prevsent>
</prevsection>
<citsent citstr=" P98-1056 ">
therefore, suchan approach as semantic transfer, where morphosyntactic information is highly abstracted away as in (dorna et al, 1998; <papid> P98-1056 </papid>richardson et al, 2001),<papid> W01-1402 </papid>does not suit this task.</citsent>
<aftsection>
<nextsent>provided that the morphosyntactic stratum be an optimal level of abstraction for representing paraphrasing/transfer patterns, one must recall that semantic-transfer approaches such as those cited above were motivated mainly by the need for reducing the complexity of transfer knowledge, which could be unmanageable in morpho-syntactic transfer.our approach to this problem is to (a) leave the description of each transfer pattern underspecified and(b) implement the knowledge about linguistic constraints that are independent of particular transfer pattern separately from the transfer knowledge.
</nextsent>
<nextsent>there are wide range of such transfer-independent linguistic constraints.
</nextsent>
<nextsent>constraints on morpheme connectivity, verb conjugation, word collocation,and tense and aspect forms in relative clauses are typical examples of such constraints.
</nextsent>
<nextsent>these four issues can be considered as different aspects of the overall question how one can makethe development and maintenance of gigantic resource for paraphrasing tractable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3302">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> research issues and our approach.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 post-transfer text revision.
</prevsent>
<prevsent>in paraphrasing, the morpho-syntactic information of source sentence should be accessible throughout the transfer process since morphosyntactic transformation in itself can often be motivation or goal of paraphrasing.
</prevsent>
</prevsection>
<citsent citstr=" W01-1402 ">
therefore, suchan approach as semantic transfer, where morphosyntactic information is highly abstracted away as in (dorna et al, 1998; <papid> P98-1056 </papid>richardson et al, 2001),<papid> W01-1402 </papid>does not suit this task.</citsent>
<aftsection>
<nextsent>provided that the morphosyntactic stratum be an optimal level of abstraction for representing paraphrasing/transfer patterns, one must recall that semantic-transfer approaches such as those cited above were motivated mainly by the need for reducing the complexity of transfer knowledge, which could be unmanageable in morpho-syntactic transfer.our approach to this problem is to (a) leave the description of each transfer pattern underspecified and(b) implement the knowledge about linguistic constraints that are independent of particular transfer pattern separately from the transfer knowledge.
</nextsent>
<nextsent>there are wide range of such transfer-independent linguistic constraints.
</nextsent>
<nextsent>constraints on morpheme connectivity, verb conjugation, word collocation,and tense and aspect forms in relative clauses are typical examples of such constraints.
</nextsent>
<nextsent>these four issues can be considered as different aspects of the overall question how one can makethe development and maintenance of gigantic resource for paraphrasing tractable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3303">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> readability assessment.  </section>
<citcontext>
<prevsection>
<prevsent>while many researchers have addressed the issue of paraphrase acquisition reporting promising results as cited above, the other three issues have been left relatively unexplored inspite of their significance in the above sense.
</prevsent>
<prevsent>motivated by this context, in the rest of this paper, we address these remaining three.
</prevsent>
</prevsection>
<citsent citstr=" P01-1051 ">
to the best of our knowledge, there have never been no reports on research to build computational model of the language proficiency of deaf people, except for the remarkable reports by michaud and mccoy (2001).<papid> P01-1051 </papid></citsent>
<aftsection>
<nextsent>as subpart of their research aimed at developing the icicle system (mccoy and master man, 1997), <papid> W97-0508 </papid>language-tutoring application for deaf learners of written english, michaud and mccoy developed an architecture for modeling the writing proficiency of user called slalom.</nextsent>
<nextsent>slalom is designed to capture the stereotypic linear order of acquisition within certain categories of morphological and/or syntactic features of language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3304">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> readability assessment.  </section>
<citcontext>
<prevsection>
<prevsent>motivated by this context, in the rest of this paper, we address these remaining three.
</prevsent>
<prevsent>to the best of our knowledge, there have never been no reports on research to build computational model of the language proficiency of deaf people, except for the remarkable reports by michaud and mccoy (2001).<papid> P01-1051 </papid></prevsent>
</prevsection>
<citsent citstr=" W97-0508 ">
as subpart of their research aimed at developing the icicle system (mccoy and master man, 1997), <papid> W97-0508 </papid>language-tutoring application for deaf learners of written english, michaud and mccoy developed an architecture for modeling the writing proficiency of user called slalom.</citsent>
<aftsection>
<nextsent>slalom is designed to capture the stereotypic linear order of acquisition within certain categories of morphological and/or syntactic features of language.
</nextsent>
<nextsent>unfortunately, the modeling method used in slalom cannot be directly applied to our domain for three reasons. unlike writing tutoring, in reading assistance, target sentences are in principle unlimited.
</nextsent>
<nextsent>we therefore need to take wider range of morphosyntactic features into account.
</nextsent>
<nextsent> slalom is not designed to capture the difficulty of any combination of morpho-syntactic features, which it is essential to take into account in reading assistance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3305">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> paraphrase representation.  </section>
<citcontext>
<prevsection>
<prevsent>this types of paraphrasing requires the computation of reference to objects outside discourse and thus should be excluded from our scope for the present purpose.
</prevsent>
<prevsent>4.2 dependency trees (mdss).
</prevsent>
</prevsection>
<citsent citstr=" C96-1078 ">
previous work on transfer-based machine translation (mt) suggests that the dependency-based representation has the advantage of facilitating syntactic transforming operations (meyers et al, 1996; <papid> C96-1078 </papid>lavoie et al, 2000).<papid> A00-1009 </papid></citsent>
<aftsection>
<nextsent>following this, we adopt dependency trees as the internal representations of target texts.
</nextsent>
<nextsent>we suppose that dependency tree consists of set of nodes each of which corresponds to lexeme or compound and set of edges each of which represents the dependency relation between its ends.
</nextsent>
<nextsent>wecall such dependency tree morpheme-based dependency structure (mds).
</nextsent>
<nextsent>each node in an mds is supposed to be annotated with an open set of typed features that indicate morpho-syntactic and semanticinformation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3307">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> paraphrase representation.  </section>
<citcontext>
<prevsection>
<prevsent>this types of paraphrasing requires the computation of reference to objects outside discourse and thus should be excluded from our scope for the present purpose.
</prevsent>
<prevsent>4.2 dependency trees (mdss).
</prevsent>
</prevsection>
<citsent citstr=" A00-1009 ">
previous work on transfer-based machine translation (mt) suggests that the dependency-based representation has the advantage of facilitating syntactic transforming operations (meyers et al, 1996; <papid> C96-1078 </papid>lavoie et al, 2000).<papid> A00-1009 </papid></citsent>
<aftsection>
<nextsent>following this, we adopt dependency trees as the internal representations of target texts.
</nextsent>
<nextsent>we suppose that dependency tree consists of set of nodes each of which corresponds to lexeme or compound and set of edges each of which represents the dependency relation between its ends.
</nextsent>
<nextsent>wecall such dependency tree morpheme-based dependency structure (mds).
</nextsent>
<nextsent>each node in an mds is supposed to be annotated with an open set of typed features that indicate morpho-syntactic and semanticinformation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3313">
<title id=" W03-1602.xml">text simplification for reading assistance a project note </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>our next steps includes the investigation of the drawbacks of the present bag-of-features modeling approach.
</prevsent>
<prevsent>we also need to consider method to introduce the notion of user classes (e.g. beginner, intermediate and ad vanced).
</prevsent>
</prevsection>
<citsent citstr=" W01-0814 ">
textual aspects of readability will also need to be considered, as discussed in (inui and nogami, 2001; <papid> W01-0814 </papid>siddahrthan, 2003).regarding paraphrase representation, we presented our revision-based lexico-structural paraphrasing engine.</citsent>
<aftsection>
<nextsent>it provides fully expressiblescheme for represent ating paraphrases, while preserving the easiness of hand craft paraphrasing rules by providing an extended natural language as means of pattern editting.
</nextsent>
<nextsent>we have handcrafted over thousand transfer rules that implement broad range of lexical and structural paraphrasing.
</nextsent>
<nextsent>the problem of error detection is also critical.
</nextsent>
<nextsent>when we find effective solution to it, we will beready to integrate the technologies into an application system of text simplification and conduct user and task-oriented evaluations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3314">
<title id=" W03-0105.xml">grounding spatial named entities for information extraction and question answering </title>
<section> spatial grounding.  </section>
<citcontext>
<prevsection>
<prevsent>un-locode is the official gazetteer by the united nations; it is also freely available from the unece web site1 and contains more than 36 000 locations in 234 countries (unece, 1998).
</prevsent>
<prevsent>the alexandria gazetteer (smith et al, 1996; frew et al, 1998) is another database of geographical entities, including both their coordinates and relationships such as: in-state-of, in-province-of, in-county-of, in-country-of, in-region-of, part-of and formerly-known-as.
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
to date, named entity recognition (ner) has only used gazette ers as evidence that text span could be some kind of place name (location), even though their finite nature makes lists of names of limited use for classification (mikheev et al, 1999).<papid> E99-1001 </papid></citsent>
<aftsection>
<nextsent>here we use them for spatial grounding ? relating linguistic entities of subtype location (grishman and sundheim, 1998) to their real-world counterparts.
</nextsent>
<nextsent>world atlases?
</nextsent>
<nextsent>and the gazette ers that index them are not the only resources than can be used for grounding spatial terms.
</nextsent>
<nextsent>in biomedicine, there are are several brain atlases of different species, using various different techniques, and focussing on both normal and disease state; as well as digital atlas of the human body 1 http://www.unece.org/cefact/locode/service/main.htm figure 1: grounding an xml ontology in voxels: the mouse atlas (baldock et al, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3315">
<title id=" W03-0105.xml">grounding spatial named entities for information extraction and question answering </title>
<section> place-name resolution for information.  </section>
<citcontext>
<prevsection>
<prevsent>secondly, linguistic context can provide clues: an accident report on the road between perth and dundee promotes an interpretation of perth in scotland, while an accident on the road between perth and free mantle promotes an interpretation of perthin western australia.
</prevsent>
<prevsent>computers, which are bound to select referents algorithmically, can exploit linguistic context more easily than extra-linguistic context, but even the use of linguistic context requires (as always) some subtle heuristic reasoning.grounding place names mentioned in text can support effective visualization ? for instance, in multimedia document surrogate that contains textual, video and map elements (e.g. in question answering scenario), where we want to ensure that the video shows the region and the map is centered around the places mentioned.to make use of linguistic context in resolving ambiguous place names, we apply two different minimal ity heuristics (gardent and webber, 2001).
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
the first we borrow (slightly modified) from work in automatic word sense disambiguation (gale et al, 1992), <papid> H92-1045 </papid>calling it one referent per discourse?.</citsent>
<aftsection>
<nextsent>it assumes that place name mentioned in discourse refers to the same location throughout the discourse, just as word is assumed to be used in the same one sense throughout the discourse.
</nextsent>
<nextsent>neither is logically necessary, and hence both are simply interpretational biases.
</nextsent>
<nextsent>the second minimality heuristic assumes that, in cases where there is more than one place name mentioned in some span of text, the smallest region that is able to ground the whole set is the one that gives them their interpretation.5 this can be used to resolve referential ambiguity by proximity: i.e., not only is the place name berlin taken to denote the same berlin throughout discourse unless mentioned otherwise,6 but so does potsdam men 5 probably the smaller the span, the more often valid will this.
</nextsent>
<nextsent>heuristic be.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3316">
<title id=" W03-0105.xml">grounding spatial named entities for information extraction and question answering </title>
<section> visualization of geo-spatial aspects in.  </section>
<citcontext>
<prevsection>
<prevsent>-75?
</prevsent>
<prevsent>figure 9: story c: the final paragraph places the event in context (global view; complete story).
</prevsent>
</prevsection>
<citsent citstr=" P79-1017 ">
(shanon, 1979) <papid> P79-1017 </papid>discusses how the granularity of the answers to where-questions depends on the reference points of speaker and listener (where is the empire state building?</citsent>
<aftsection>
<nextsent>(a) in new york, (b) in the u.s.a, (c) on 34th street and 3rd avenue); the map generation task depends on such levels of granularity in the sense that to create auseful map, entities that belong to the same level of gran ularity or scale should be marked (e.g. city city rather than villagecontinent).
</nextsent>
<nextsent>using grounding knowledge in gazette ers also enables us to answer questions in natural language more effectively: 1.
</nextsent>
<nextsent>what is x?.
</nextsent>
<nextsent>q: what is kangiqsualujjuaqa: kangiqsualujjuaq is place approximately 1500 kilometers north of montreal, canada.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3317">
<title id=" W03-1009.xml">variation of entropy and parse trees of sentences as a function of the sentence number </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the later sentences in the discourse contain references to the entities in the preceding sentences, and this fact isoften useful, e.g., in caching for language modeling (goodman, 2001).
</prevsent>
<prevsent>the indirect influence of the context, however, can be observed even when sentence is taken as stand-alone unit, i.e., without its context.
</prevsent>
</prevsection>
<citsent citstr=" P02-1026 ">
it is possible to distinguish between setof earlier sentences and set of later sentences without any direct comparison by computing certain local statistics of individual sentences, such as their entropy (genzel and charniak, 2002).<papid> P02-1026 </papid></citsent>
<aftsection>
<nextsent>in this work we provide additional evidence for this hypothesis and investigate other sentence statistics.
</nextsent>
<nextsent>1.1 entropy rate constancy.
</nextsent>
<nextsent>entropy, as measure of information, is often used in the communication theory.
</nextsent>
<nextsent>if humans have evolved to communicate in the most efficient way (some evidence for that is provided by plotkin and nowak (2000)), then they would communicate in such way that the entropy rate would be constant, namely, equal to the channel capacity (shannon, 1948).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3324">
<title id=" W03-1009.xml">variation of entropy and parse trees of sentences as a function of the sentence number </title>
<section> investigating non-lexical causes.  </section>
<citcontext>
<prevsection>
<prevsent>0.001 table 1: correlation coefficient for different genres trees and investigate if any statistics show significant change with the sentence number.
</prevsent>
<prevsent>4.1 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we use the whole penn treebank corpus (marcus et al., 1993) <papid> J93-2004 </papid>as our data set.</citsent>
<aftsection>
<nextsent>this corpus contains about 50000 parsed sentences.
</nextsent>
<nextsent>many of the statistics we wish to compute are very sensitive to the length of the sentence.
</nextsent>
<nextsent>for example, the depth of the tree is almost linearly related to the sentence length.
</nextsent>
<nextsent>this is important because the average length of the sentence varies with the sentence number.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3325">
<title id=" W03-1728.xml">chinese word segmentation as lmr tagging </title>
<section> segmentation as tagging.  </section>
<citcontext>
<prevsection>
<prevsent>unlike english text in which sentences are sequences of words delimited by white spaces, in chinese text, sentences are represented as strings of chinese characters or hanzi without similar naturaldelimiters.
</prevsent>
<prevsent>therefore, the first step in chinese language processing task is to identify the sequence ofwords in sentence and mark boundaries in appropriate places.
</prevsent>
</prevsection>
<citsent citstr=" J96-4004 ">
this may sound simple enough but in reality identifying words in chinese is non-trivial problem that has drawn large body of research in the chinese language processing community (fan and tsai, 1988; gan et al , 1996; <papid> J96-4004 </papid>sproat et al , 1996; <papid> J96-3004 </papid>wu, 2003; xue, 2003).</citsent>
<aftsection>
<nextsent>the key to accurate automatic word identification in chinese lies in the successful resolution of ambiguities and proper way to handle out-of-vocabularywords.
</nextsent>
<nextsent>the ambiguities in chinese word segmentation is due to the fact that hanzi can occur in different word-internal positions (xue, 2003).
</nextsent>
<nextsent>given the proper context, generally provided by the sentence in which it occurs, the position of hanzi can be determined.
</nextsent>
<nextsent>in this paper, we model the chinese word segmentation as hanzi tagging problem and use amachine-learning algorithm to determine the appropriate position for hanzi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3326">
<title id=" W03-1728.xml">chinese word segmentation as lmr tagging </title>
<section> segmentation as tagging.  </section>
<citcontext>
<prevsection>
<prevsent>unlike english text in which sentences are sequences of words delimited by white spaces, in chinese text, sentences are represented as strings of chinese characters or hanzi without similar naturaldelimiters.
</prevsent>
<prevsent>therefore, the first step in chinese language processing task is to identify the sequence ofwords in sentence and mark boundaries in appropriate places.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
this may sound simple enough but in reality identifying words in chinese is non-trivial problem that has drawn large body of research in the chinese language processing community (fan and tsai, 1988; gan et al , 1996; <papid> J96-4004 </papid>sproat et al , 1996; <papid> J96-3004 </papid>wu, 2003; xue, 2003).</citsent>
<aftsection>
<nextsent>the key to accurate automatic word identification in chinese lies in the successful resolution of ambiguities and proper way to handle out-of-vocabularywords.
</nextsent>
<nextsent>the ambiguities in chinese word segmentation is due to the fact that hanzi can occur in different word-internal positions (xue, 2003).
</nextsent>
<nextsent>given the proper context, generally provided by the sentence in which it occurs, the position of hanzi can be determined.
</nextsent>
<nextsent>in this paper, we model the chinese word segmentation as hanzi tagging problem and use amachine-learning algorithm to determine the appropriate position for hanzi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3327">
<title id=" W03-1728.xml">chinese word segmentation as lmr tagging </title>
<section> tagging algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>memm models are capable of utilizing large set of features that generative models cannot use.
</prevsent>
<prevsent>on the other hand, memm approaches scan the input incrementally as generative models do.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the maximum entropy markov model used in pos-tagging is described in detail in (ratnaparkhi,1996) <papid> W96-0213 </papid>and the lmr tagger here uses the same probability model.</citsent>
<aftsection>
<nextsent>the probability model is defined over   , where is the set of possible contexts or histories?
</nextsent>
<nextsent>and  is the set of possible tags.
</nextsent>
<nextsent>the models joint probability of history  and tag  is defined as  ffflfiffi !  $#&amp;%(  )+*,.- /10 2   (1) where fi is normalization constant, 34ffi5   %  11    6 are the model parameters and 387 %  11 97 (6 are knownas features, where 7    :;=  3@?
</nextsent>
<nextsent>  6 . each feature 7   has corresponding parameter    , that effectively serves as weight?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3328">
<title id=" W03-1728.xml">chinese word segmentation as lmr tagging </title>
<section> tagging algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>a partial solution to the lbp is to compute the probability of transitions in both directions.
</prevsent>
<prevsent>this way we can use two memm taggers, one of which scans the input from left to right and the other scans the input from right to left.
</prevsent>
</prevsection>
<citsent citstr=" P03-1064 ">
this strategy has been successfully used in (shen and joshi, 2003).<papid> P03-1064 </papid></citsent>
<aftsection>
<nextsent>in that paper, pairwise voting (van halteren et al , 1998) has been used to combine the results of two super taggers that scan the input in the opposite directions.the pairwise voting is not suitable in this application because we must make sure that the lmr tags assigned to consecutive words are compatible.
</nextsent>
<nextsent>for example, an lm tag cannot immediately follow an mm.
</nextsent>
<nextsent>pairwise voting does not use any contextual information, so it cannot prevent incompatible tags from occurring.
</nextsent>
<nextsent>therefore, in our experiments described here, we use the transformation-based learning (brill, 1995) <papid> J95-4004 </papid>to combine the results of twomemm taggers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3329">
<title id=" W03-1728.xml">chinese word segmentation as lmr tagging </title>
<section> tagging algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>for example, an lm tag cannot immediately follow an mm.
</prevsent>
<prevsent>pairwise voting does not use any contextual information, so it cannot prevent incompatible tags from occurring.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
therefore, in our experiments described here, we use the transformation-based learning (brill, 1995) <papid> J95-4004 </papid>to combine the results of twomemm taggers.</citsent>
<aftsection>
<nextsent>the feature set used in the tbl algorithm is similar to those used in the np chunking task in (ngai and florian, 2001).<papid> N01-1006 </papid></nextsent>
<nextsent>we conducted closed track experiments on three data sources: the academia sinica (as) corpus, the beijing university (pku) corpus and the hongkong city university (cityu) corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3330">
<title id=" W03-1728.xml">chinese word segmentation as lmr tagging </title>
<section> tagging algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>pairwise voting does not use any contextual information, so it cannot prevent incompatible tags from occurring.
</prevsent>
<prevsent>therefore, in our experiments described here, we use the transformation-based learning (brill, 1995) <papid> J95-4004 </papid>to combine the results of twomemm taggers.</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
the feature set used in the tbl algorithm is similar to those used in the np chunking task in (ngai and florian, 2001).<papid> N01-1006 </papid></citsent>
<aftsection>
<nextsent>we conducted closed track experiments on three data sources: the academia sinica (as) corpus, the beijing university (pku) corpus and the hongkong city university (cityu) corpus.
</nextsent>
<nextsent>we first split the training data from each of the three sources into two portions.
</nextsent>
<nextsent> w ? of the official training data is used to train the memm taggers, and the other @w is held out as the development test data (the development set).
</nextsent>
<nextsent>the development set is used to estimate the optimal number of iterations in the memm training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3334">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since parsing results given by the lexicalized grammar cannot be decomposed into independent sub-events,we apply maximum entropy model for feature forests, which allows probabilistic modeling without the independence assumption.
</prevsent>
<prevsent>our approach provides general method of producing consistent probabilistic model of parsing results given by lexicalized grammars.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
recent studies on the automatic extraction of lexicalized grammars (xia, 1999; chen and vijay-shanker, 2000; hockenmaier and steedman, 2002<papid> P02-1043 </papid>a) allow the modeling of syntactic disambiguation based on linguistically motivated grammar theories including ltag (chiang, 2000)<papid> P00-1058 </papid>and ccg (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002<papid> P02-1043 </papid>b).</citsent>
<aftsection>
<nextsent>however, existing models of disambiguation with lexicalized grammars are mere extension of lexicalized probabilistic context-free grammars (lpcfg) (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>charniak, 1997), which are based on the decomposition of parsing results into thesyntactic/semantic dependencies of two words in sentence under the assumption of independence of the de pendencies.</nextsent>
<nextsent>while lpcfg models have proved that the incorporation of lexical associations (i.e., dependencies of words) significantly improves the accuracy of parsing, this idea has been naively inherited in the recent studies on disambiguation models of lexicalized grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3336">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since parsing results given by the lexicalized grammar cannot be decomposed into independent sub-events,we apply maximum entropy model for feature forests, which allows probabilistic modeling without the independence assumption.
</prevsent>
<prevsent>our approach provides general method of producing consistent probabilistic model of parsing results given by lexicalized grammars.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
recent studies on the automatic extraction of lexicalized grammars (xia, 1999; chen and vijay-shanker, 2000; hockenmaier and steedman, 2002<papid> P02-1043 </papid>a) allow the modeling of syntactic disambiguation based on linguistically motivated grammar theories including ltag (chiang, 2000)<papid> P00-1058 </papid>and ccg (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002<papid> P02-1043 </papid>b).</citsent>
<aftsection>
<nextsent>however, existing models of disambiguation with lexicalized grammars are mere extension of lexicalized probabilistic context-free grammars (lpcfg) (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>charniak, 1997), which are based on the decomposition of parsing results into thesyntactic/semantic dependencies of two words in sentence under the assumption of independence of the de pendencies.</nextsent>
<nextsent>while lpcfg models have proved that the incorporation of lexical associations (i.e., dependencies of words) significantly improves the accuracy of parsing, this idea has been naively inherited in the recent studies on disambiguation models of lexicalized grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3337">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since parsing results given by the lexicalized grammar cannot be decomposed into independent sub-events,we apply maximum entropy model for feature forests, which allows probabilistic modeling without the independence assumption.
</prevsent>
<prevsent>our approach provides general method of producing consistent probabilistic model of parsing results given by lexicalized grammars.
</prevsent>
</prevsection>
<citsent citstr=" P02-1042 ">
recent studies on the automatic extraction of lexicalized grammars (xia, 1999; chen and vijay-shanker, 2000; hockenmaier and steedman, 2002<papid> P02-1043 </papid>a) allow the modeling of syntactic disambiguation based on linguistically motivated grammar theories including ltag (chiang, 2000)<papid> P00-1058 </papid>and ccg (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002<papid> P02-1043 </papid>b).</citsent>
<aftsection>
<nextsent>however, existing models of disambiguation with lexicalized grammars are mere extension of lexicalized probabilistic context-free grammars (lpcfg) (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>charniak, 1997), which are based on the decomposition of parsing results into thesyntactic/semantic dependencies of two words in sentence under the assumption of independence of the de pendencies.</nextsent>
<nextsent>while lpcfg models have proved that the incorporation of lexical associations (i.e., dependencies of words) significantly improves the accuracy of parsing, this idea has been naively inherited in the recent studies on disambiguation models of lexicalized grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3340">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach provides general method of producing consistent probabilistic model of parsing results given by lexicalized grammars.
</prevsent>
<prevsent>recent studies on the automatic extraction of lexicalized grammars (xia, 1999; chen and vijay-shanker, 2000; hockenmaier and steedman, 2002<papid> P02-1043 </papid>a) allow the modeling of syntactic disambiguation based on linguistically motivated grammar theories including ltag (chiang, 2000)<papid> P00-1058 </papid>and ccg (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002<papid> P02-1043 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
however, existing models of disambiguation with lexicalized grammars are mere extension of lexicalized probabilistic context-free grammars (lpcfg) (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>charniak, 1997), which are based on the decomposition of parsing results into thesyntactic/semantic dependencies of two words in sentence under the assumption of independence of the de pendencies.</citsent>
<aftsection>
<nextsent>while lpcfg models have proved that the incorporation of lexical associations (i.e., dependencies of words) significantly improves the accuracy of parsing, this idea has been naively inherited in the recent studies on disambiguation models of lexicalized grammars.
</nextsent>
<nextsent>however, the disambiguation models of lexicalized grammars should be totally different from that of lpcfg, because the grammars define the relation of syntax and semantics, and can restrict the possible structure of parsing results.
</nextsent>
<nextsent>parsing results cannot simply be decomposed into primitive dependencies, because the complete structure is determined by solving the syntactic constraints of complete sentence.
</nextsent>
<nextsent>for example, when we applya unification-based grammar, lpcfg-like modeling results in an inconsistent probability model because the model assigns probabilities to parsing results not allowed by the grammar (abney, 1997).<papid> J97-4005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3342">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach provides general method of producing consistent probabilistic model of parsing results given by lexicalized grammars.
</prevsent>
<prevsent>recent studies on the automatic extraction of lexicalized grammars (xia, 1999; chen and vijay-shanker, 2000; hockenmaier and steedman, 2002<papid> P02-1043 </papid>a) allow the modeling of syntactic disambiguation based on linguistically motivated grammar theories including ltag (chiang, 2000)<papid> P00-1058 </papid>and ccg (clark et al, 2002; <papid> P02-1042 </papid>hockenmaier and steedman, 2002<papid> P02-1043 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
however, existing models of disambiguation with lexicalized grammars are mere extension of lexicalized probabilistic context-free grammars (lpcfg) (collins, 1996; <papid> P96-1025 </papid>collins, 1997; <papid> P97-1003 </papid>charniak, 1997), which are based on the decomposition of parsing results into thesyntactic/semantic dependencies of two words in sentence under the assumption of independence of the de pendencies.</citsent>
<aftsection>
<nextsent>while lpcfg models have proved that the incorporation of lexical associations (i.e., dependencies of words) significantly improves the accuracy of parsing, this idea has been naively inherited in the recent studies on disambiguation models of lexicalized grammars.
</nextsent>
<nextsent>however, the disambiguation models of lexicalized grammars should be totally different from that of lpcfg, because the grammars define the relation of syntax and semantics, and can restrict the possible structure of parsing results.
</nextsent>
<nextsent>parsing results cannot simply be decomposed into primitive dependencies, because the complete structure is determined by solving the syntactic constraints of complete sentence.
</nextsent>
<nextsent>for example, when we applya unification-based grammar, lpcfg-like modeling results in an inconsistent probability model because the model assigns probabilities to parsing results not allowed by the grammar (abney, 1997).<papid> J97-4005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3344">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the disambiguation models of lexicalized grammars should be totally different from that of lpcfg, because the grammars define the relation of syntax and semantics, and can restrict the possible structure of parsing results.
</prevsent>
<prevsent>parsing results cannot simply be decomposed into primitive dependencies, because the complete structure is determined by solving the syntactic constraints of complete sentence.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
for example, when we applya unification-based grammar, lpcfg-like modeling results in an inconsistent probability model because the model assigns probabilities to parsing results not allowed by the grammar (abney, 1997).<papid> J97-4005 </papid></citsent>
<aftsection>
<nextsent>we have only two ways of adhering to lpcfg models: preserve the consistency of probability models by abandoning improvements tothe lexicalized grammars using complex constraints (chi ang, 2000), <papid> P00-1058 </papid>or ignore the inconsistency in probability models (clark et al, 2002).<papid> P02-1042 </papid>this paper provides new model of syntactic disambiguation in which lexicalized grammars can restrict the possible structures of parsing results.</nextsent>
<nextsent>our modeling aimsat providing grounds for i) producing consistent probabilistic model of lexicalized grammars, as well as ii) evaluating the contributions of syntactic and semantic preferences to syntactic disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3350">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the syntax probability is responsible for determining the syntactic categories chosen by words in sentence, andthe semantics probability selects the most plausible dependencies of words from candidates allowed by the syntactic categories yielded by the syntax probability.
</prevsent>
<prevsent>since the sequence of syntactic categories restricts the possible structure of parsing results, the semantics probability is conditional probability without decomposition into the primitive dependencies of words.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
recently used machine learning methods including maximum entropy models (berger et al, 1996) <papid> J96-1002 </papid>and support vector machines(vapnik, 1995) provide grounds for this type of modeling, because it allows various dependent features to be incorporated into the model without the independence as sumption.</citsent>
<aftsection>
<nextsent>the above approach, however, has serious deficiency:a lexicalized grammar assigns exponentially many parsing results because of local ambiguities in sentence, which is problematic in estimating the parameters of probability model.
</nextsent>
<nextsent>to cope with this, we adopted an algorithm of maximum entropy estimation for feature forests (miyao and tsujii, 2002; geman and johnson,2002), <papid> P02-1036 </papid>which allows parameters to be efficiently esti mated.</nextsent>
<nextsent>the algorithm enables probabilistic modeling of complete structures, such as transition sequences in markov models and parse trees, without dividing the minto independent sub-events.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3351">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently used machine learning methods including maximum entropy models (berger et al, 1996) <papid> J96-1002 </papid>and support vector machines(vapnik, 1995) provide grounds for this type of modeling, because it allows various dependent features to be incorporated into the model without the independence as sumption.</prevsent>
<prevsent>the above approach, however, has serious deficiency:a lexicalized grammar assigns exponentially many parsing results because of local ambiguities in sentence, which is problematic in estimating the parameters of probability model.</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
to cope with this, we adopted an algorithm of maximum entropy estimation for feature forests (miyao and tsujii, 2002; geman and johnson,2002), <papid> P02-1036 </papid>which allows parameters to be efficiently esti mated.</citsent>
<aftsection>
<nextsent>the algorithm enables probabilistic modeling of complete structures, such as transition sequences in markov models and parse trees, without dividing the minto independent sub-events.
</nextsent>
<nextsent>the algorithm avoids exponential explosion by representing probabilistic event by packed representation of feature space.
</nextsent>
<nextsent>if complete structure is represented with feature forest of tractable size, the parameters can be efficiently estimated by dynamic programming.
</nextsent>
<nextsent>a series of studies on parsing with wide-coverage lfg (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al,2002) <papid> P02-1035 </papid>have had similar motivation to ours.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3352">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm avoids exponential explosion by representing probabilistic event by packed representation of feature space.
</prevsent>
<prevsent>if complete structure is represented with feature forest of tractable size, the parameters can be efficiently estimated by dynamic programming.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
a series of studies on parsing with wide-coverage lfg (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al,2002) <papid> P02-1035 </papid>have had similar motivation to ours.</citsent>
<aftsection>
<nextsent>their models have also been based on discriminative model to select parsing result from all candidates given by thegrammar.
</nextsent>
<nextsent>a significant difference is that we apply maximum entropy estimation for feature forests to avoid the inherent problem with estimation: the exponential explosion of parsing results given by the grammar.
</nextsent>
<nextsent>they assumed that parsing results would be suppressed to reasonable number through using heuristic rules, or by carefully implementing fully restrictive and wide-coverage grammar, which requires considerable amount of effort to develop.
</nextsent>
<nextsent>our contention is that this problem can be solved in more sophisticated way as is discussed in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3353">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm avoids exponential explosion by representing probabilistic event by packed representation of feature space.
</prevsent>
<prevsent>if complete structure is represented with feature forest of tractable size, the parameters can be efficiently estimated by dynamic programming.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
a series of studies on parsing with wide-coverage lfg (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al,2002) <papid> P02-1035 </papid>have had similar motivation to ours.</citsent>
<aftsection>
<nextsent>their models have also been based on discriminative model to select parsing result from all candidates given by thegrammar.
</nextsent>
<nextsent>a significant difference is that we apply maximum entropy estimation for feature forests to avoid the inherent problem with estimation: the exponential explosion of parsing results given by the grammar.
</nextsent>
<nextsent>they assumed that parsing results would be suppressed to reasonable number through using heuristic rules, or by carefully implementing fully restrictive and wide-coverage grammar, which requires considerable amount of effort to develop.
</nextsent>
<nextsent>our contention is that this problem can be solved in more sophisticated way as is discussed in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3354">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm avoids exponential explosion by representing probabilistic event by packed representation of feature space.
</prevsent>
<prevsent>if complete structure is represented with feature forest of tractable size, the parameters can be efficiently estimated by dynamic programming.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
a series of studies on parsing with wide-coverage lfg (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>riezler et al,2002) <papid> P02-1035 </papid>have had similar motivation to ours.</citsent>
<aftsection>
<nextsent>their models have also been based on discriminative model to select parsing result from all candidates given by thegrammar.
</nextsent>
<nextsent>a significant difference is that we apply maximum entropy estimation for feature forests to avoid the inherent problem with estimation: the exponential explosion of parsing results given by the grammar.
</nextsent>
<nextsent>they assumed that parsing results would be suppressed to reasonable number through using heuristic rules, or by carefully implementing fully restrictive and wide-coverage grammar, which requires considerable amount of effort to develop.
</nextsent>
<nextsent>our contention is that this problem can be solved in more sophisticated way as is discussed in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3355">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since the syntax and semantics probabilities are separate, we can improve them individually.
</prevsent>
<prevsent>for example, the syntax model can be improved by smoothing using the syntactic classes of words, while the semantics model should be able to be improved by using semantic classes.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
in addition, the model can be starting point that allows the theory of syntax and semantics to be evaluated through consulting an extensive corpus.we evaluated the validity of our model through experiments on disambiguation task of parsing the penn tree bank (marcus et al, 1994) <papid> H94-1020 </papid>with an automatically acquired ltag grammar.</citsent>
<aftsection>
<nextsent>to assess the contribution of the syntax and semantics probabilities to the accuracy of parsing andto evaluate the validity of applying maximum entropy estimation for feature forests, we compared three model strained with the same training set and the same set of features.
</nextsent>
<nextsent>following the experimental results, we concluded that i) parser with the syntax probability only achieved high accuracy with the lexicalized grammar, ii) the incorporation of preferences for lexical association through the semantics probability resulted insignificant improvements, and iii) our model recorded an accuracy that was quite close to the traditional model, which indicated the validity of applying maximum entropy estimation for feature forests.
</nextsent>
<nextsent>in what follows, we first describe the existing models for syntactic disambiguation, and discuss problems with them in section 2.
</nextsent>
<nextsent>we then define the general form for parsing results of lexicalized grammars, and introduce our model in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3362">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> traditional models for syntactic.  </section>
<citcontext>
<prevsection>
<prevsent>however, the models are based on the lexical dependencies of elementary trees, which is simple extension of the lpcfg.
</prevsent>
<prevsent>that is, the models are still based on decomposition into primitive lexical dependencies.
</prevsent>
</prevsection>
<citsent citstr=" C88-2121 ">
derivation trees, the structural description in ltag(schabes et al, 1988), <papid> C88-2121 </papid>represent the association of lexical items i.e., elementary trees.</citsent>
<aftsection>
<nextsent>in ltag, all syntactic constraints of words are described in an elementary tree,and the dependencies of elementary trees, i.e., derivation tree, describe the semantic relations of words more directly than lexicalized parse trees.
</nextsent>
<nextsent>for example, figure 3 has derivation tree corresponding to the parse tree in figure 12.
</nextsent>
<nextsent>the dotted lines represent substitution while the solid lines represent adjunction.
</nextsent>
<nextsent>we should note that the relations captured by ad-hoc augmentation 2the nodes in derivation tree are denoted with the names of the elementary trees, while we have omitted details.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3371">
<title id=" W03-0401.xml">a model of syntactic disambiguation based on lexicalized grammars </title>
<section> probability model based on lexicalized.  </section>
<citcontext>
<prevsection>
<prevsent>formally, p(a|w) = p(c|w)p(a|c).the first probability in the above formula is the probability of syntactic categories, i.e., the probability of selecting sequence of syntactic categories in sentence.since syntactic categories in lexicalized grammars determine the syntactic constraints of words, this expresses the syntactic preference of each word in sentence.
</prevsent>
<prevsent>note that our objective is not only to improve parsing accuracy butalso to investigate the relation between syntax and semantics.
</prevsent>
</prevsection>
<citsent citstr=" C94-1024 ">
we have not adopted the local contexts of words as in the super taggers in ltag (joshi and srinivas, 1994) <papid> C94-1024 </papid>because they partially include the semantic preferences of sentence.</citsent>
<aftsection>
<nextsent>the probability is purely unigram to select the probable syntactic category for each word.
</nextsent>
<nextsent>the probability is then given by the product of probabilities to select syntactic category for each word from set of candidate categories allowed by the lexicon.
</nextsent>
<nextsent>p(c|w) = ? p(c |w ) the second describes the probability of semantics, which expresses the semantic preferences of relating the words in sentence.
</nextsent>
<nextsent>note that the semantics probability is dependent on the syntactic categories determined by the syntax probability, because in lexicalized grammar formalism, series of syntactic categories determines the possible structures of parsing results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3388">
<title id=" W03-1211.xml">question answering on a case insensitive corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the orthographic case information for written text is an important information source.
</prevsent>
<prevsent>in particular, the basic information extraction (ie) support for qa, namely named entity (ne) tagging, relies heavily on the case information for recognizing proper names.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
almost all ne systems (e.g. [bikel et al 1997], [<papid> A97-1029 </papid>krupka &amp; hausman 1998]) <papid> M98-1015 </papid>utilize case-related features.</citsent>
<aftsection>
<nextsent>when this information is not available, if the system is notre trained or adapted, serious performance degradation will occur.
</nextsent>
<nextsent>in the case of the statistical ne tagger, without adaptation the system simply does not work.
</nextsent>
<nextsent>the degradation for proper name ne tagging is more than 70% based on our testing.
</nextsent>
<nextsent>the key issue here is how to minimize the performance degradation by adopting some strategy for the system adaptation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3389">
<title id=" W03-1211.xml">question answering on a case insensitive corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the orthographic case information for written text is an important information source.
</prevsent>
<prevsent>in particular, the basic information extraction (ie) support for qa, namely named entity (ne) tagging, relies heavily on the case information for recognizing proper names.
</prevsent>
</prevsection>
<citsent citstr=" M98-1015 ">
almost all ne systems (e.g. [bikel et al 1997], [<papid> A97-1029 </papid>krupka &amp; hausman 1998]) <papid> M98-1015 </papid>utilize case-related features.</citsent>
<aftsection>
<nextsent>when this information is not available, if the system is notre trained or adapted, serious performance degradation will occur.
</nextsent>
<nextsent>in the case of the statistical ne tagger, without adaptation the system simply does not work.
</nextsent>
<nextsent>the degradation for proper name ne tagging is more than 70% based on our testing.
</nextsent>
<nextsent>the key issue here is how to minimize the performance degradation by adopting some strategy for the system adaptation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3390">
<title id=" W03-1211.xml">question answering on a case insensitive corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, qa requires fine-grained text processing beyond keyword indexing since, instead of list of documents or urls, list of candidate answers at phrase level or sentence level is expected to be returned in response to query.
</prevsent>
<prevsent>typically qa is supported by natural language processing (nlp) and ie [chinchor &amp; marsh 1998] [hovy et al 2001] [srihari &amp; li 2000].
</prevsent>
</prevsection>
<citsent citstr=" W02-1905 ">
examples of using nlp and ie in question answering include shallow parsing [kupiec 1993] [srihari &amp; li 2000], deep parsing [li et al 2002] [<papid> W02-1905 </papid>litkowski 1999] [voorhees 1999], and ie [abney et al 2000] [<papid> A00-1041 </papid>srihari &amp; li 2000].</citsent>
<aftsection>
<nextsent>almost all state-of-the-art qa systems relyon ne in searching for candidate answers.
</nextsent>
<nextsent>for system based on language models, feature exclusion approach is used to re-train the models, excluding features related to the case information [kubala et al 1998] [miller et al 2000] [<papid> A00-1044 </papid>palmer et al 2000].</nextsent>
<nextsent>in particular, the darpa hub-4 program evaluates ne systems on speech recognizer output in snor (standard normalized orthographic representation) that is case insensitive and has no punctuations [chincor et al 1998].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3391">
<title id=" W03-1211.xml">question answering on a case insensitive corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, qa requires fine-grained text processing beyond keyword indexing since, instead of list of documents or urls, list of candidate answers at phrase level or sentence level is expected to be returned in response to query.
</prevsent>
<prevsent>typically qa is supported by natural language processing (nlp) and ie [chinchor &amp; marsh 1998] [hovy et al 2001] [srihari &amp; li 2000].
</prevsent>
</prevsection>
<citsent citstr=" A00-1041 ">
examples of using nlp and ie in question answering include shallow parsing [kupiec 1993] [srihari &amp; li 2000], deep parsing [li et al 2002] [<papid> W02-1905 </papid>litkowski 1999] [voorhees 1999], and ie [abney et al 2000] [<papid> A00-1041 </papid>srihari &amp; li 2000].</citsent>
<aftsection>
<nextsent>almost all state-of-the-art qa systems relyon ne in searching for candidate answers.
</nextsent>
<nextsent>for system based on language models, feature exclusion approach is used to re-train the models, excluding features related to the case information [kubala et al 1998] [miller et al 2000] [<papid> A00-1044 </papid>palmer et al 2000].</nextsent>
<nextsent>in particular, the darpa hub-4 program evaluates ne systems on speech recognizer output in snor (standard normalized orthographic representation) that is case insensitive and has no punctuations [chincor et al 1998].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3392">
<title id=" W03-1211.xml">question answering on a case insensitive corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples of using nlp and ie in question answering include shallow parsing [kupiec 1993] [srihari &amp; li 2000], deep parsing [li et al 2002] [<papid> W02-1905 </papid>litkowski 1999] [voorhees 1999], and ie [abney et al 2000] [<papid> A00-1041 </papid>srihari &amp; li 2000].</prevsent>
<prevsent>almost all state-of-the-art qa systems relyon ne in searching for candidate answers.</prevsent>
</prevsection>
<citsent citstr=" A00-1044 ">
for system based on language models, feature exclusion approach is used to re-train the models, excluding features related to the case information [kubala et al 1998] [miller et al 2000] [<papid> A00-1044 </papid>palmer et al 2000].</citsent>
<aftsection>
<nextsent>in particular, the darpa hub-4 program evaluates ne systems on speech recognizer output in snor (standard normalized orthographic representation) that is case insensitive and has no punctuations [chincor et al 1998].
</nextsent>
<nextsent>research on case insensitive text has so far been restricted to ne and the feature exclusion approach [chieu &amp; ng 2002] [kubala et al. 1998] [palmer et al 2000] [robinson et al 1999].
</nextsent>
<nextsent>when we examine system beyond the shallow processing of ne, the traditional feature exclusion approach may not be feasible.
</nextsent>
<nextsent>a sophisticated qa system usually involves several components with multiple modules, involving nlp/ie processing at various levels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3395">
<title id=" W03-1211.xml">question answering on a case insensitive corpus </title>
<section> question answering based on ie.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 is the conclusion.
</prevsent>
<prevsent>we use qa system supported by increasingly sophisticated levels of ie [srihari &amp; li 2000] [li et al. 2002].<papid> W02-1905 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0808 ">
figure 1 presents the underlying ie engine infoxtract [srihari et al 2003] <papid> W03-0808 </papid>that forms the basis for the qa system.</citsent>
<aftsection>
<nextsent>the major information objects extracted by infoxtract include nes,1 correlated entity (ce) relationships (e.g. affiliation, position etc.), subject-verb-object (svo) triples, entity profiles, and general or predefined events.
</nextsent>
<nextsent>these information objects capture the key content of the processed text, preparing foundation for answering factoid questions.
</nextsent>
<nextsent>document processor knowledge resources lexicon resources grammars process manager tok enlist legend output manager source document linguistic processor(s)tokenizer tok enlist lexicon lookup pragmatic filtering pos tagging named entity detection shallow parsing deep parsing relationship detection document pool ne ce ep svo time normalization alias/coreference linking profile/event linking profile/event merge abbreviations ne = named entity ce = correlated entity ep = entity profile svo=subject-verb-object ge = general event pe = predefined event grammar module procedure or statistical model hybrid module gestatisticalmodels location normalizationli ti pe ie index figure 1: system architecture of infoxtract figure 2 shows the architecture of the qa system.
</nextsent>
<nextsent>this system consists of three components: (i) question processing, (ii) text processing, and (iii) answer ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3398">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nlp is experiencing an explosion in the quantity of electronic text available.
</prevsent>
<prevsent>some of this new data will be manually annotated.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for example, 10 million words of the american national corpus (ide et al, 2002) will have manually corrected pos tags, tenfold increase over the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>currently used for training pos taggers.</citsent>
<aftsection>
<nextsent>this will require more efficient learning algorithms and implementations.
</nextsent>
<nextsent>however, the greatest increase is in the amount of rawtext available to be processed, e.g. the english gigaword corpus (linguistic data consortium, 2003).
</nextsent>
<nextsent>recent work (banko and brill, 2001; <papid> P01-1005 </papid>curran and moens, 2002) <papid> P02-1030 </papid>has suggested that some tasks will benefit fro musing significantly more data.</nextsent>
<nextsent>also, many potential applications of nlp will involve processing very large text databases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3399">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this will require more efficient learning algorithms and implementations.
</prevsent>
<prevsent>however, the greatest increase is in the amount of rawtext available to be processed, e.g. the english gigaword corpus (linguistic data consortium, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
recent work (banko and brill, 2001; <papid> P01-1005 </papid>curran and moens, 2002) <papid> P02-1030 </papid>has suggested that some tasks will benefit fro musing significantly more data.</citsent>
<aftsection>
<nextsent>also, many potential applications of nlp will involve processing very large text databases.
</nextsent>
<nextsent>for instance, biomedical text-mining involves extracting information from the vast body of biologic aland medical literature; and search engines may eventually apply nlp techniques to the whole web.
</nextsent>
<nextsent>other potential applications must process text online or in real time.
</nextsent>
<nextsent>for example, google currently answers 250 million queries per day, thus processing time must be minimised.clearly, efficient nlp components will need to be developed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3400">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this will require more efficient learning algorithms and implementations.
</prevsent>
<prevsent>however, the greatest increase is in the amount of rawtext available to be processed, e.g. the english gigaword corpus (linguistic data consortium, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P02-1030 ">
recent work (banko and brill, 2001; <papid> P01-1005 </papid>curran and moens, 2002) <papid> P02-1030 </papid>has suggested that some tasks will benefit fro musing significantly more data.</citsent>
<aftsection>
<nextsent>also, many potential applications of nlp will involve processing very large text databases.
</nextsent>
<nextsent>for instance, biomedical text-mining involves extracting information from the vast body of biologic aland medical literature; and search engines may eventually apply nlp techniques to the whole web.
</nextsent>
<nextsent>other potential applications must process text online or in real time.
</nextsent>
<nextsent>for example, google currently answers 250 million queries per day, thus processing time must be minimised.clearly, efficient nlp components will need to be developed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3401">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> existing systems.  </section>
<citcontext>
<prevsection>
<prevsent>1we use high performance to refer to both state of the art performance and high runtime efficiency.
</prevsent>
<prevsent>there are number of generalised nlp systems in the literature.
</prevsent>
</prevsection>
<citsent citstr=" A97-1051 ">
many provide graphical user interfaces (gui) for manual annotation (e.g. general architecture for text engineering (gate) (cunningham et al, 1997) and the alembic workbench (day et al, 1997)) <papid> A97-1051 </papid>as well as nlp tools and resources that can be manipulated from thegui.</citsent>
<aftsection>
<nextsent>for instance, gate currently provides pos tagger, named entity recogniser and gazetteer and ontology editors (cunningham et al, 2002).
</nextsent>
<nextsent>gate goes beyond earlier systems by using component-based infrastructure (cunningham, 2000) which the gui is built on top of.
</nextsent>
<nextsent>this allows components to be highly configurable and simplifies the addition of new components to the system.a number of stand-alone tools have also been developed.
</nextsent>
<nextsent>for example, the suite of lt tools (mikheev et al, 1999; grover et al, 2000) perform tokenization, tagging and chunking on xml marked-up text directly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3402">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> existing systems.  </section>
<citcontext>
<prevsection>
<prevsent>however, the source code for these tools is not freely available, so they cannot be extended.
</prevsent>
<prevsent>efficiency has not been focus for nlp research in general.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
however, it will be increasingly important as techniques become more complex and corpus sizes grow.an example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by ratnaparkhi (1998) that converge very slowly, to complex techniques from the optimisation literature that converge much more rapidly (malouf, 2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>other attempts to address efficiency include the fast transformation based learning (tbl) toolkit (ngai and florian,2001) <papid> N01-1006 </papid>which dramatically speeds uptraining tbl systems, and the translation of tbl rules into finite state machines for very fast tagging (roche and schabes, 1997).the tnt pos tagger (brants, 2000) <papid> A00-1031 </papid>has also been designed to train and run very quickly, tagging between 30,000 and 60,000 words per second.</nextsent>
<nextsent>the weka package (witten and frank, 1999) providesa common framework for several existing machine learning methods including decision trees and support vector machines.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3403">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> existing systems.  </section>
<citcontext>
<prevsection>
<prevsent>efficiency has not been focus for nlp research in general.
</prevsent>
<prevsent>however, it will be increasingly important as techniques become more complex and corpus sizes grow.an example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by ratnaparkhi (1998) that converge very slowly, to complex techniques from the optimisation literature that converge much more rapidly (malouf, 2002).<papid> W02-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
other attempts to address efficiency include the fast transformation based learning (tbl) toolkit (ngai and florian,2001) <papid> N01-1006 </papid>which dramatically speeds uptraining tbl systems, and the translation of tbl rules into finite state machines for very fast tagging (roche and schabes, 1997).the tnt pos tagger (brants, 2000) <papid> A00-1031 </papid>has also been designed to train and run very quickly, tagging between 30,000 and 60,000 words per second.</citsent>
<aftsection>
<nextsent>the weka package (witten and frank, 1999) providesa common framework for several existing machine learning methods including decision trees and support vector machines.
</nextsent>
<nextsent>this library has been very popular because it allows researchers to experiment with different methods without having to modify code or reformat data.
</nextsent>
<nextsent>finally, the natural language toolkit (nltk) is package of nlp components implemented in python (loper and bird, 2002).<papid> W02-0109 </papid></nextsent>
<nextsent>python scripting is extremely simple to learn, read and write, and so using the existing components and designing new components is simple.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3404">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> existing systems.  </section>
<citcontext>
<prevsection>
<prevsent>efficiency has not been focus for nlp research in general.
</prevsent>
<prevsent>however, it will be increasingly important as techniques become more complex and corpus sizes grow.an example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by ratnaparkhi (1998) that converge very slowly, to complex techniques from the optimisation literature that converge much more rapidly (malouf, 2002).<papid> W02-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
other attempts to address efficiency include the fast transformation based learning (tbl) toolkit (ngai and florian,2001) <papid> N01-1006 </papid>which dramatically speeds uptraining tbl systems, and the translation of tbl rules into finite state machines for very fast tagging (roche and schabes, 1997).the tnt pos tagger (brants, 2000) <papid> A00-1031 </papid>has also been designed to train and run very quickly, tagging between 30,000 and 60,000 words per second.</citsent>
<aftsection>
<nextsent>the weka package (witten and frank, 1999) providesa common framework for several existing machine learning methods including decision trees and support vector machines.
</nextsent>
<nextsent>this library has been very popular because it allows researchers to experiment with different methods without having to modify code or reformat data.
</nextsent>
<nextsent>finally, the natural language toolkit (nltk) is package of nlp components implemented in python (loper and bird, 2002).<papid> W02-0109 </papid></nextsent>
<nextsent>python scripting is extremely simple to learn, read and write, and so using the existing components and designing new components is simple.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3405">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> existing systems.  </section>
<citcontext>
<prevsection>
<prevsent>the weka package (witten and frank, 1999) providesa common framework for several existing machine learning methods including decision trees and support vector machines.
</prevsent>
<prevsent>this library has been very popular because it allows researchers to experiment with different methods without having to modify code or reformat data.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
finally, the natural language toolkit (nltk) is package of nlp components implemented in python (loper and bird, 2002).<papid> W02-0109 </papid></citsent>
<aftsection>
<nextsent>python scripting is extremely simple to learn, read and write, and so using the existing components and designing new components is simple.
</nextsent>
<nextsent>as discussed earlier, there are two main requirements of the system that are covered by high performance?: speed and state of the art accuracy.
</nextsent>
<nextsent>efficiency is required both in training and processing.
</nextsent>
<nextsent>efficient training is required because the amount of data available for training will increase significantly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3408">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>further, we can use techniques for making string matching and other text processing very fast such as making only one copy of each lexical item or annotation in memory.
</prevsent>
<prevsent>we can also load lexicon into memory that is shared between all of the components, reducing the memory use.
</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
the implementation has been inspired by experience in extracting information from very large corpora (cur ran and moens, 2002) <papid> P02-1030 </papid>and performing experiments on maximum entropy sequence tagging (curran and clark, 2003; <papid> E03-1071 </papid>clark et al, 2003).<papid> W03-0407 </papid></citsent>
<aftsection>
<nextsent>we have already implemented pos tagger, chunker, ccg super tagger and named entity recogniser using the infrastructure.
</nextsent>
<nextsent>these tools currently train in less than 10 minutes on the standard training materials and tag faster than tnt, the fastest existing postagger.
</nextsent>
<nextsent>these tools use highly optimised gis implementation and provide sophisticated gaussian smoothing(chen and rosenfeld, 1999).
</nextsent>
<nextsent>we expect even faster training times when we move to conjugate gradient methods.the next step of the process will be to add different statistical models and machine learning methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3410">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>further, we can use techniques for making string matching and other text processing very fast such as making only one copy of each lexical item or annotation in memory.
</prevsent>
<prevsent>we can also load lexicon into memory that is shared between all of the components, reducing the memory use.
</prevsent>
</prevsection>
<citsent citstr=" W03-0407 ">
the implementation has been inspired by experience in extracting information from very large corpora (cur ran and moens, 2002) <papid> P02-1030 </papid>and performing experiments on maximum entropy sequence tagging (curran and clark, 2003; <papid> E03-1071 </papid>clark et al, 2003).<papid> W03-0407 </papid></citsent>
<aftsection>
<nextsent>we have already implemented pos tagger, chunker, ccg super tagger and named entity recogniser using the infrastructure.
</nextsent>
<nextsent>these tools currently train in less than 10 minutes on the standard training materials and tag faster than tnt, the fastest existing postagger.
</nextsent>
<nextsent>these tools use highly optimised gis implementation and provide sophisticated gaussian smoothing(chen and rosenfeld, 1999).
</nextsent>
<nextsent>we expect even faster training times when we move to conjugate gradient methods.the next step of the process will be to add different statistical models and machine learning methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3418">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> web services.  </section>
<citcontext>
<prevsection>
<prevsent>systems can automatically discover and communicate with web services that provide the functionality they require by querying databases of standardised descriptions of services with wsdl and uddi.
</prevsent>
<prevsent>this standardisation of remote procedures is very exciting from software engineering viewpoint since it allows systems to be totally distributed.
</prevsent>
</prevsection>
<citsent citstr=" H01-1017 ">
there have already been several attempts to develop distributed nlp systems for dialogue systems (bayer et al, 2001) <papid> H01-1017 </papid>and speech recognition (hacioglu and pellom, 2003).</citsent>
<aftsection>
<nextsent>web services will allow components developed by different researchers in different locations to be composed to build larger systems.
</nextsent>
<nextsent>because web services are of great commercial interest they are already being supported strongly by many programming languages.
</nextsent>
<nextsent>for instance, web services can be accessed with very little code in java, python, perl, c, c++ and prolog.
</nextsent>
<nextsent>this allows us to provide nlp service sto many systems that we could not otherwise support using single interface definition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3419">
<title id=" W03-0806.xml">blueprint for a high performance nlp infrastructure </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we are currently in the process of implementing pos tagging web service using the gsoap library, which will translate our infrastructure binding into web service wrapper code and produce the necessary xml service description files.
</prevsent>
<prevsent>the generative programming approach to nlp infrastructure development will allow tools such as sentence boundary detectors, pos taggers, chunk ers and named entity recognisers to be rapidly composed from many elemental components.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
for instance, implementing an efficient version of the mxpost pos tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>will simply involve composing and configuring the appropriate text file reading component, with the sequential tagging component, the collection of feature extraction components and the maximum entropy model com ponent.</citsent>
<aftsection>
<nextsent>the individual components will provide state of the art accuracy and be highly optimised for both time and space efficiency.
</nextsent>
<nextsent>a key design feature of this infrastructure is that components share common representation for text and annotations so there is no time spent reading/writing formatted data (e.g. xml) between stages.
</nextsent>
<nextsent>to make the composition and configuration process easier we have implemented python scripting interface, which means that anyone can construct efficient new tools, without the need for much programming experience or compiler.
</nextsent>
<nextsent>the development of graphical user interface on top of the infrastructure will further ease the development cycle.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3420">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>abstraction permits structural neutralizations that facilitate learning of translation examples across languages with radically different surface structure characteristics, and allows mt development to proceed within largely language- independent nlp architecture.
</prevsent>
<prevsent>comparative evaluation indicates that after training in domain the english-japanese system is statistically indistinguishable from non-customized commercially available mt system in the same domain.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
in the wake of the pioneering work of nagao (1984), brown et al  (1990) <papid> J90-2002 </papid>and sato and nagao (1990), <papid> C90-3044 </papid>machine translation (mt) research has increasingly focused on the issue of how to acquire translation knowledge from aligned parallel texts.</citsent>
<aftsection>
<nextsent>while much of this research effort has focused on acquisition of correspondences between individual lexical items or between unstructured strings of words, closer attention has begun to be paid to the learning of structured phrasal units: yamamoto and matsumoto (2000), <papid> C00-2135 </papid>for example, describe method for automatically extracting correspondences between dependency relations in japanese and english.</nextsent>
<nextsent>similarly, imamura (2001a),  imamura (2001b) seeks to match corresponding japanese and english phrases containing information about hierarchical structures, including partially completed parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3421">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>abstraction permits structural neutralizations that facilitate learning of translation examples across languages with radically different surface structure characteristics, and allows mt development to proceed within largely language- independent nlp architecture.
</prevsent>
<prevsent>comparative evaluation indicates that after training in domain the english-japanese system is statistically indistinguishable from non-customized commercially available mt system in the same domain.
</prevsent>
</prevsection>
<citsent citstr=" C90-3044 ">
in the wake of the pioneering work of nagao (1984), brown et al  (1990) <papid> J90-2002 </papid>and sato and nagao (1990), <papid> C90-3044 </papid>machine translation (mt) research has increasingly focused on the issue of how to acquire translation knowledge from aligned parallel texts.</citsent>
<aftsection>
<nextsent>while much of this research effort has focused on acquisition of correspondences between individual lexical items or between unstructured strings of words, closer attention has begun to be paid to the learning of structured phrasal units: yamamoto and matsumoto (2000), <papid> C00-2135 </papid>for example, describe method for automatically extracting correspondences between dependency relations in japanese and english.</nextsent>
<nextsent>similarly, imamura (2001a),  imamura (2001b) seeks to match corresponding japanese and english phrases containing information about hierarchical structures, including partially completed parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3422">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>comparative evaluation indicates that after training in domain the english-japanese system is statistically indistinguishable from non-customized commercially available mt system in the same domain.
</prevsent>
<prevsent>in the wake of the pioneering work of nagao (1984), brown et al  (1990) <papid> J90-2002 </papid>and sato and nagao (1990), <papid> C90-3044 </papid>machine translation (mt) research has increasingly focused on the issue of how to acquire translation knowledge from aligned parallel texts.</prevsent>
</prevsection>
<citsent citstr=" C00-2135 ">
while much of this research effort has focused on acquisition of correspondences between individual lexical items or between unstructured strings of words, closer attention has begun to be paid to the learning of structured phrasal units: yamamoto and matsumoto (2000), <papid> C00-2135 </papid>for example, describe method for automatically extracting correspondences between dependency relations in japanese and english.</citsent>
<aftsection>
<nextsent>similarly, imamura (2001a),  imamura (2001b) seeks to match corresponding japanese and english phrases containing information about hierarchical structures, including partially completed parses.
</nextsent>
<nextsent>yamamoto and matsumoto (2000) <papid> C00-2135 </papid>explicitly assume that dependency relations between words will generally be preserved across languages.</nextsent>
<nextsent>however, when languages are as different as japanese and english with respect to their syntactic and informational structures, grammatical or dependency relations may not always be preserved: the english sentence the network failed?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3427">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the msr-mt english-japanese system is hybrid example-based machine translation system that employs handcrafted broad- coverage augmented phrase structure grammars for parsing, and statistical and heuristic techniques to capture translation knowlege and for transfer between languages.
</prevsent>
<prevsent>the parsers are general purpose: the english parser, for example, forms the core of the grammar checkers used in microsoft word (heidorn 2000).
</prevsent>
</prevsection>
<citsent citstr=" C00-2119 ">
the japanese grammar utilizes much of the same co debase, but contains language- specific grammar rules and additional features owing to the need for word-breaking in japanese (suzuki et al  2000; <papid> C00-2119 </papid>kacmarcik et al  2000).<papid> C00-1057 </papid></citsent>
<aftsection>
<nextsent>these parsers are robust in that if the analysis grammar fails to find an appropriate parse, it outputs best-guess fitted?
</nextsent>
<nextsent>parse.
</nextsent>
<nextsent>system development is not confined to english-japanese: msr-mt is part of broader natural language processing project involving three asian languages (japanese, chinese, and korean) and four european languages (english, french, german, and spanish).
</nextsent>
<nextsent>development of the msr-mt systems proceeds more or less simultaneously across these languages and in multiple directions, including japanese-english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3428">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the msr-mt english-japanese system is hybrid example-based machine translation system that employs handcrafted broad- coverage augmented phrase structure grammars for parsing, and statistical and heuristic techniques to capture translation knowlege and for transfer between languages.
</prevsent>
<prevsent>the parsers are general purpose: the english parser, for example, forms the core of the grammar checkers used in microsoft word (heidorn 2000).
</prevsent>
</prevsection>
<citsent citstr=" C00-1057 ">
the japanese grammar utilizes much of the same co debase, but contains language- specific grammar rules and additional features owing to the need for word-breaking in japanese (suzuki et al  2000; <papid> C00-2119 </papid>kacmarcik et al  2000).<papid> C00-1057 </papid></citsent>
<aftsection>
<nextsent>these parsers are robust in that if the analysis grammar fails to find an appropriate parse, it outputs best-guess fitted?
</nextsent>
<nextsent>parse.
</nextsent>
<nextsent>system development is not confined to english-japanese: msr-mt is part of broader natural language processing project involving three asian languages (japanese, chinese, and korean) and four european languages (english, french, german, and spanish).
</nextsent>
<nextsent>development of the msr-mt systems proceeds more or less simultaneously across these languages and in multiple directions, including japanese-english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3429">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>system development is not confined to english-japanese: msr-mt is part of broader natural language processing project involving three asian languages (japanese, chinese, and korean) and four european languages (english, french, german, and spanish).
</prevsent>
<prevsent>development of the msr-mt systems proceeds more or less simultaneously across these languages and in multiple directions, including japanese-english.
</prevsent>
</prevsection>
<citsent citstr=" W01-1402 ">
the spanish-english version of msr-mt has been described in richardson et al  2001<papid> W01-1402 </papid>a, richardson et al 2001<papid> W01-1402 </papid>b, and the reader is referred to these papers for more information concerning algorithms employed during phrase alignment.</citsent>
<aftsection>
<nextsent>a description of the french-spanish mt system is found in pinkham &amp; smets.
</nextsent>
<nextsent>2002.
</nextsent>
<nextsent>1.1 training data.
</nextsent>
<nextsent>msr-mt requires that large corpus of aligned sentences be available as examples for training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3431">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the next step, an lf alignment algorithm is used to match source language and target language lfs at the sub-sentence level.
</prevsent>
<prevsent>the lf alignment algorithm first establishes tentative lexical correspondences between nodes in the source and target lfs on the basis of lexical matching over dictionary information and approximately 31,000 word associations,?
</prevsent>
</prevsection>
<citsent citstr=" W01-1411 ">
that is, lexical mappings extracted from the training corpora using statistical techniques based on mutual information (moore 2001).<papid> W01-1411 </papid></citsent>
<aftsection>
<nextsent>from these possible lexical correspondences, the algorithm uses small grammar of (language-pair-independent) rules to align lf nodes on lexical and structural principles.
</nextsent>
<nextsent>the aligned lf pairs are then partitioned into smaller aligned lf segments, with individual node mappings captured in relationship we call sublinking.?
</nextsent>
<nextsent>finally, the aligned lf segments are filtered on the basis of frequency, and compiled into database known as mindnet.
</nextsent>
<nextsent>(see menezes &amp; richardson 2001 <papid> W01-1406 </papid>for detailed description of this process.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3432">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the aligned lf pairs are then partitioned into smaller aligned lf segments, with individual node mappings captured in relationship we call sublinking.?
</prevsent>
<prevsent>finally, the aligned lf segments are filtered on the basis of frequency, and compiled into database known as mindnet.
</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
(see menezes &amp; richardson 2001 <papid> W01-1406 </papid>for detailed description of this process.)</citsent>
<aftsection>
<nextsent>the mindnet is general-purpose database of semantic information (richardson et al  1998) <papid> P98-2180 </papid>that has been re purposed as the primary repository of translation information for mt applications.</nextsent>
<nextsent>the process of building the mindnet is entirely automated; there is no human vetting of candidate entries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3433">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, the aligned lf segments are filtered on the basis of frequency, and compiled into database known as mindnet.
</prevsent>
<prevsent>(see menezes &amp; richardson 2001 <papid> W01-1406 </papid>for detailed description of this process.)</prevsent>
</prevsection>
<citsent citstr=" P98-2180 ">
the mindnet is general-purpose database of semantic information (richardson et al  1998) <papid> P98-2180 </papid>that has been re purposed as the primary repository of translation information for mt applications.</citsent>
<aftsection>
<nextsent>the process of building the mindnet is entirely automated; there is no human vetting of candidate entries.
</nextsent>
<nextsent>at the end of typical training session, 1,816,520 transfer patterns identified in the training corpus may yield 98,248 final entries in the mindnet.
</nextsent>
<nextsent>only the output of successful parses is considered for inclusion, and each mapping of lf segments must have been encountered twice in the corpus before it is incorporated into the mindnet.
</nextsent>
<nextsent>in the mindnet, lf segments from the source language are represented as linked to the corresponding lf segment from the target languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3434">
<title id=" W02-1604.xml">english japanese example based machine translation using abstract linguistic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some structural differences, such as pro-drop phenomena in japanese.
</prevsent>
<prevsent>a series of core generation rules then applies to the lf tree, transforming it into japanese sentence string.
</prevsent>
</prevsection>
<citsent citstr=" W01-0808 ">
generation rules operate on single tree only, are application-independent and are developed in monolingual environment (see aikawa et al . 2001<papid> W01-0808 </papid>a, 2001b for further details.)</citsent>
<aftsection>
<nextsent>generation of inflectional morphology is also handled in this component.
</nextsent>
<nextsent>the generation component has no explicit knowledge of the source language.
</nextsent>
<nextsent>mappings the generalization provided by lf makes it possible for msr-mt to handle complex structural relations in cases where english and japanese are systematically divergent.
</nextsent>
<nextsent>this is 2 msr-mt resorts to lexical lookup only when a. term is not found in the mindnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3435">
<title id=" W02-1901.xml">scenario forms for web information seeking and summarizing in bone marrow transplantation </title>
<section> background and related.  </section>
<citcontext>
<prevsection>

<prevsent>approaches while graphical output of summaries was already addressed in the 80ies, interest in user interfaces of summarization systems is morerecent.
</prevsent>
</prevsection>
<citsent citstr=" W00-0409 ">
aone et al (1999) as well as strzalkowski et al (1999) and ando et al (2000) <papid> W00-0409 </papid>describe graphical user interfaces of their summarizers.</citsent>
<aftsection>
<nextsent>white, ruthven and joemon (2001) positively evaluate summarization function and interface added to alta vista and google.
</nextsent>
<nextsent>buyukkokten et al (w.d.) summarize for hand-helds.
</nextsent>
<nextsent>their small screens make them consider the user interface.
</nextsent>
<nextsent>kan, mckeown and klavans (2001) see summarization on top of an ir task, as we do.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3436">
<title id=" W03-1724.xml">integrating ngram model and case based learning for chinese word segmentation </title>
<section> case-based learning for disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>for the bakeoff, we have based our approach to ambiguity detection and disambiguation rule extraction on the assumption that only ambiguous strings cause mistakes: we detect the discrepancies of our probabilistic segmentation and the standard segmentation of the training corpus, and turn them into transformation rules.
</prevsent>
<prevsent>an advantage of this approach is that the rules so derived carry out not only disambiguation but also error correction.
</prevsent>
</prevsection>
<citsent citstr=" P97-1041 ">
this links our disambiguation strategy to the application of brills (1993) transformation-based error-driven learning to chinese word segmentation (palmer, 1997; <papid> P97-1041 </papid>hockenmaier and brew, 1998).</citsent>
<aftsection>
<nextsent>the overall architecture of our word segmentation system is presented in figure 1.
</nextsent>
<nextsent>figure 1: overall architecture of the system
</nextsent>
<nextsent>the performance of our system in the bakeoff is presented in table 1 in terms of precision (p), recall (r) and score in percentages, where c? denotes closed tests.
</nextsent>
<nextsent>its iv word identification performance is remarkable.however, its overall performance is not in balance with this, due to the lack of module for oov word discovery.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3437">
<title id=" W03-1704.xml">two character chinese word extraction based on hybrid of internal and contextual measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in general, there are two kinds of statistic-based measures for estimating the soundness of an extracted item being word/phrase: one is the internal measure, which estimates the soundness by the internal associative strength between constituents of the item.
</prevsent>
<prevsent>nine widely adopted internal measures are listed in (schone et al 2001), including frequency, mutual information, selectional association, symmetric conditional probability, dice formula, log-likelihood, chi-squared, z-score, students score.
</prevsent>
</prevsection>
<citsent citstr=" C00-2116 ">
the other kind is the contextual measure, which estimates the soundness by the dependency of the item on its context, such as the left/right entropy (sornlertlamvanich et al 2000), <papid> C00-2116 </papid>and the left/right context dependency (chien 1999).</citsent>
<aftsection>
<nextsent>this paper firstly analyzes nine internal measures mentioned above, tests and compares their word extraction performance on individual basis, then tries to improve the performance by properly combining these measures.
</nextsent>
<nextsent>furthermore, the contextual measure is integrated with internal measures to acquire more improvement.
</nextsent>
<nextsent>throughout the experiments, genetic algorithm is explored to adjust weights of combination and thresholds automatically.
</nextsent>
<nextsent>we only concern two character word extraction in this paper, because two-character words reflect the most popular word-formation of chinese and possess the largest proportion in chinese lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3438">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>location normalization is special application of word sense disambiguation (wsd).
</prevsent>
<prevsent>there is considerable research on wsd.
</prevsent>
</prevsection>
<citsent citstr=" J92-1001 ">
knowledge-based work, such as [hirst 1987; mcroy 1992; <papid> J92-1001 </papid>ng and lee 1996] <papid> P96-1006 </papid>used hand-coded rules or supervised machine learning based on an annotated corpus to perform wsd.</citsent>
<aftsection>
<nextsent>recent work emphasizes corpus-based unsupervised approach [dagon and itai 1994; yarowsky 1992; <papid> C92-2070 </papid>yarowsky 1995] <papid> P95-1026 </papid>that avoids the need for costly truthed training data.</nextsent>
<nextsent>location normalization is different from general wsd in that the selection restriction often used for wsd in many cases is not sufficient to distinguish the correct sense from the other candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3439">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>location normalization is special application of word sense disambiguation (wsd).
</prevsent>
<prevsent>there is considerable research on wsd.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
knowledge-based work, such as [hirst 1987; mcroy 1992; <papid> J92-1001 </papid>ng and lee 1996] <papid> P96-1006 </papid>used hand-coded rules or supervised machine learning based on an annotated corpus to perform wsd.</citsent>
<aftsection>
<nextsent>recent work emphasizes corpus-based unsupervised approach [dagon and itai 1994; yarowsky 1992; <papid> C92-2070 </papid>yarowsky 1995] <papid> P95-1026 </papid>that avoids the need for costly truthed training data.</nextsent>
<nextsent>location normalization is different from general wsd in that the selection restriction often used for wsd in many cases is not sufficient to distinguish the correct sense from the other candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3440">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is considerable research on wsd.
</prevsent>
<prevsent>knowledge-based work, such as [hirst 1987; mcroy 1992; <papid> J92-1001 </papid>ng and lee 1996] <papid> P96-1006 </papid>used hand-coded rules or supervised machine learning based on an annotated corpus to perform wsd.</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
recent work emphasizes corpus-based unsupervised approach [dagon and itai 1994; yarowsky 1992; <papid> C92-2070 </papid>yarowsky 1995] <papid> P95-1026 </papid>that avoids the need for costly truthed training data.</citsent>
<aftsection>
<nextsent>location normalization is different from general wsd in that the selection restriction often used for wsd in many cases is not sufficient to distinguish the correct sense from the other candidates.
</nextsent>
<nextsent>for example, in the sentence the white house is located in washington?, the selection restriction from the collocation located in?
</nextsent>
<nextsent>can only determine that washington?
</nextsent>
<nextsent>should be location name, but is not sufficient to decide the actual sense of this location.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3441">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is considerable research on wsd.
</prevsent>
<prevsent>knowledge-based work, such as [hirst 1987; mcroy 1992; <papid> J92-1001 </papid>ng and lee 1996] <papid> P96-1006 </papid>used hand-coded rules or supervised machine learning based on an annotated corpus to perform wsd.</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
recent work emphasizes corpus-based unsupervised approach [dagon and itai 1994; yarowsky 1992; <papid> C92-2070 </papid>yarowsky 1995] <papid> P95-1026 </papid>that avoids the need for costly truthed training data.</citsent>
<aftsection>
<nextsent>location normalization is different from general wsd in that the selection restriction often used for wsd in many cases is not sufficient to distinguish the correct sense from the other candidates.
</nextsent>
<nextsent>for example, in the sentence the white house is located in washington?, the selection restriction from the collocation located in?
</nextsent>
<nextsent>can only determine that washington?
</nextsent>
<nextsent>should be location name, but is not sufficient to decide the actual sense of this location.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3442">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a graph spanning algorithm can be used to select the best senses from the graph.
</prevsent>
<prevsent>last but not least, proper assignment of default senses is found to play significant role in the performance of location normalizer.
</prevsent>
</prevsection>
<citsent citstr=" C02-1127 ">
this involves two issues: (i) determining default senses using heuristics and/or other methods, such as statistical processing for semi-automatic default sense extraction from the web [li et al  2002]; <papid> C02-1127 </papid>and (ii) setting the conditions/thresholds and the proper levels when assigning default senses, to coordinate with local and discourse evidence for enhanced performance.</citsent>
<aftsection>
<nextsent>the second issue can be resolved through experimentation.
</nextsent>
<nextsent>in the light of the above overview, this paper presents an effective hybrid location normalization approach which consists of local pattern matching and discourse co-occurrence analysis as well as default senses.
</nextsent>
<nextsent>multiple knowledge sources are used in number of ways: (i) pattern matching driven by local context, (ii) maximum spanning tree search for discourse analysis, and (iii) applying heuristics-based default senses and web-extracted default senses in proper stages.
</nextsent>
<nextsent>in the remaining text, section 2 introduces the background for this research.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3443">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>this engine, in its current state, involves over 100 levels of processing and 12 major components.
</prevsent>
<prevsent>some components are based on hand-crafted pattern matching rules, some are statistical models or procedures, and others are hybrid (e.g. ne, co-reference, location normalization).
</prevsent>
</prevsection>
<citsent citstr=" M98-1015 ">
the basic information extraction task is ne tagging [krupka and hausman 1998; <papid> M98-1015 </papid>srihari et al  2000].<papid> A00-1034 </papid></citsent>
<aftsection>
<nextsent>the ne tagger identifies and classifies proper names of type person, organization, product, named-events, location (loc) as well as numerical expressions such as measurement (e.g. money, length, weight, etc) and time expressions (time, date, month, etc.).
</nextsent>
<nextsent>parallel to location normalization, infoxtract also involves time normalization and measurement normalization.
</nextsent>
<nextsent>document processor knowledge resources lexicon resources grammars process manager tok enlist legend output manager source document linguistic processor(s)tokenizer tok enlist lexicon lookup pos tagging ne tagging shallow parsing relationship extraction document pool ne ce ep svo time normalization profile/event consolidation event extraction abbreviations ne = named entity ce = correlated entity ep = entity profile svo = subject-verb-object ge = general event pe = predefined event rule-based pattern matching procedure or statistical model hybrid module ge statistical models pe ie repository deep parsing coreference location normalization measurement normalization figure 1: system architecture of infoxtract infoxtract combines the maximum entropy model (maxent) and hidden markov model for ne tagging [srihari et al  2000].<papid> A00-1034 </papid></nextsent>
<nextsent>maximum entropy models incorporate local contextual evidence to handle ambiguity of information from location gazetteer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3444">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>this engine, in its current state, involves over 100 levels of processing and 12 major components.
</prevsent>
<prevsent>some components are based on hand-crafted pattern matching rules, some are statistical models or procedures, and others are hybrid (e.g. ne, co-reference, location normalization).
</prevsent>
</prevsection>
<citsent citstr=" A00-1034 ">
the basic information extraction task is ne tagging [krupka and hausman 1998; <papid> M98-1015 </papid>srihari et al  2000].<papid> A00-1034 </papid></citsent>
<aftsection>
<nextsent>the ne tagger identifies and classifies proper names of type person, organization, product, named-events, location (loc) as well as numerical expressions such as measurement (e.g. money, length, weight, etc) and time expressions (time, date, month, etc.).
</nextsent>
<nextsent>parallel to location normalization, infoxtract also involves time normalization and measurement normalization.
</nextsent>
<nextsent>document processor knowledge resources lexicon resources grammars process manager tok enlist legend output manager source document linguistic processor(s)tokenizer tok enlist lexicon lookup pos tagging ne tagging shallow parsing relationship extraction document pool ne ce ep svo time normalization profile/event consolidation event extraction abbreviations ne = named entity ce = correlated entity ep = entity profile svo = subject-verb-object ge = general event pe = predefined event rule-based pattern matching procedure or statistical model hybrid module ge statistical models pe ie repository deep parsing coreference location normalization measurement normalization figure 1: system architecture of infoxtract infoxtract combines the maximum entropy model (maxent) and hidden markov model for ne tagging [srihari et al  2000].<papid> A00-1034 </papid></nextsent>
<nextsent>maximum entropy models incorporate local contextual evidence to handle ambiguity of information from location gazetteer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3451">
<title id=" W03-0106.xml">infoxtract location normalization a hybrid approach to geographic references in information extraction </title>
<section> previous work and issues.  </section>
<citcontext>
<prevsection>
<prevsent>to retain only one sense for the ne as early as possible; step 3.
</prevsent>
<prevsent>apply the one sense per discourse?
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
principle [gale et al 1992] <papid> H92-1045 </papid>for each disambiguated location name to propagate the selected sense to its other mentions within document; step 4.</citsent>
<aftsection>
<nextsent>call the discourse sub-module, which is graph search algorithm (kruskals algorithm), to resolve the remaining ambiguities; step 5.
</nextsent>
<nextsent>if the decision score for location name is lower than threshold, we choose default sense of that name as result.
</nextsent>
<nextsent>in this algorithm, step 2, step 4, and step 5 complement each other, and help produce better overall performance.
</nextsent>
<nextsent>step 2 uses local context that is the co-occurring words around location name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3454">
<title id=" W02-1403.xml">lexicallybased terminology structuring some inherent limits </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>internal methods look at the constituency of terms, and compare terms based on the words they contain.
</prevsent>
<prevsent>term matching can rely directly on raw word forms (bodenreider et al , 2001), on morphological variants (jacquemin and tzoukermann, 1999), on syntactic structure (bourigault, 1994;jacquemin and tzoukermann, 1999) or on semantic variants (synonyms, hyperonyms, etc.)
</prevsent>
</prevsection>
<citsent citstr=" P98-1082 ">
(hamon et al , 1998).<papid> P98-1082 </papid></citsent>
<aftsection>
<nextsent>external methods take advantage of the context in which terms occur: they examine the behavior of terms in corpora.
</nextsent>
<nextsent>distributional methods group terms that occur in similar contexts (grefenstette, 1994).
</nextsent>
<nextsent>the detection of appropriate syntactic patterns of cooccurrence is another method to uncover relations between terms in corpora (hearst, 1992; <papid> C92-2082 </papid>sgula and aussenac, 1999).</nextsent>
<nextsent>in previous work we applied lexical methods to identify relations between terms on the basis on their content words, taking morphological variants into account.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3455">
<title id=" W02-1403.xml">lexicallybased terminology structuring some inherent limits </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>external methods take advantage of the context in which terms occur: they examine the behavior of terms in corpora.
</prevsent>
<prevsent>distributional methods group terms that occur in similar contexts (grefenstette, 1994).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the detection of appropriate syntactic patterns of cooccurrence is another method to uncover relations between terms in corpora (hearst, 1992; <papid> C92-2082 </papid>sgula and aussenac, 1999).</citsent>
<aftsection>
<nextsent>in previous work we applied lexical methods to identify relations between terms on the basis on their content words, taking morphological variants into account.
</nextsent>
<nextsent>our goal was then to assess the feasibility of such structuring by studying it on an existing, hierarchically structured terminology.
</nextsent>
<nextsent>ignoring this existing structure and starting from the set of its terms, we attempt to discover hierarchical term-to term links and compare them with the preexisting relations.
</nextsent>
<nextsent>our goal in the present paper is to analyze new?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3456">
<title id=" W03-0428.xml">named entity recognition with character level models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the classic hmm view of these two tasks is one in which the observations are words and the hidden states encode classlabels.
</prevsent>
<prevsent>however, because of data sparsity, sophisticated unknown word models are generally required for good performance.
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
a common approach is to extract word-internal features from unknown words, for example suffix, capitalization, or punctuation features (mikheev, 1997, <papid> J97-3003 </papid>wacholder et al, 1997, <papid> A97-1030 </papid>bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>onethen treats the unknown word as collection of such features.
</nextsent>
<nextsent>having such unknown-word models as an add-on is perhaps misplaced focus: in these tasks, providing correct behavior on unknown words is typically the key challenge.here, we examine the utility of taking character sequences as primary representation.
</nextsent>
<nextsent>we present two models in which the basic units are characters and character  -grams, instead of words and word phrases.
</nextsent>
<nextsent>earlier papers have taken character-level approach to named entity recognition (ner), notably cucerzan and yarowsky (1999), <papid> W99-0612 </papid>which used prefix and suffix tries,though to our knowledge incorporating all character  grams is new.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3457">
<title id=" W03-0428.xml">named entity recognition with character level models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the classic hmm view of these two tasks is one in which the observations are words and the hidden states encode classlabels.
</prevsent>
<prevsent>however, because of data sparsity, sophisticated unknown word models are generally required for good performance.
</prevsent>
</prevsection>
<citsent citstr=" A97-1030 ">
a common approach is to extract word-internal features from unknown words, for example suffix, capitalization, or punctuation features (mikheev, 1997, <papid> J97-3003 </papid>wacholder et al, 1997, <papid> A97-1030 </papid>bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>onethen treats the unknown word as collection of such features.
</nextsent>
<nextsent>having such unknown-word models as an add-on is perhaps misplaced focus: in these tasks, providing correct behavior on unknown words is typically the key challenge.here, we examine the utility of taking character sequences as primary representation.
</nextsent>
<nextsent>we present two models in which the basic units are characters and character  -grams, instead of words and word phrases.
</nextsent>
<nextsent>earlier papers have taken character-level approach to named entity recognition (ner), notably cucerzan and yarowsky (1999), <papid> W99-0612 </papid>which used prefix and suffix tries,though to our knowledge incorporating all character  grams is new.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3458">
<title id=" W03-0428.xml">named entity recognition with character level models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the classic hmm view of these two tasks is one in which the observations are words and the hidden states encode classlabels.
</prevsent>
<prevsent>however, because of data sparsity, sophisticated unknown word models are generally required for good performance.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
a common approach is to extract word-internal features from unknown words, for example suffix, capitalization, or punctuation features (mikheev, 1997, <papid> J97-3003 </papid>wacholder et al, 1997, <papid> A97-1030 </papid>bikel et al, 1997).<papid> A97-1029 </papid></citsent>
<aftsection>
<nextsent>onethen treats the unknown word as collection of such features.
</nextsent>
<nextsent>having such unknown-word models as an add-on is perhaps misplaced focus: in these tasks, providing correct behavior on unknown words is typically the key challenge.here, we examine the utility of taking character sequences as primary representation.
</nextsent>
<nextsent>we present two models in which the basic units are characters and character  -grams, instead of words and word phrases.
</nextsent>
<nextsent>earlier papers have taken character-level approach to named entity recognition (ner), notably cucerzan and yarowsky (1999), <papid> W99-0612 </papid>which used prefix and suffix tries,though to our knowledge incorporating all character  grams is new.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3459">
<title id=" W03-0428.xml">named entity recognition with character level models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>having such unknown-word models as an add-on is perhaps misplaced focus: in these tasks, providing correct behavior on unknown words is typically the key challenge.here, we examine the utility of taking character sequences as primary representation.
</prevsent>
<prevsent>we present two models in which the basic units are characters and character  -grams, instead of words and word phrases.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
earlier papers have taken character-level approach to named entity recognition (ner), notably cucerzan and yarowsky (1999), <papid> W99-0612 </papid>which used prefix and suffix tries,though to our knowledge incorporating all character  grams is new.</citsent>
<aftsection>
<nextsent>in section 2, we discuss character-level hmm, while in section 3 we discuss sequence-free maximum-entropy (maxent) classifier which uses  -gram substring features.
</nextsent>
<nextsent>finally, in section 4 we add additional features to the maxent model, and chain these models into conditional markov model (cmm), as used for tagging (ratnaparkhi, 1996) <papid> W96-0213 </papid>or earlier ner work (borth wick, 1999).</nextsent>
<nextsent>figure 1 shows graphical model representation of our character-level hmm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3460">
<title id=" W03-0428.xml">named entity recognition with character level models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>earlier papers have taken character-level approach to named entity recognition (ner), notably cucerzan and yarowsky (1999), <papid> W99-0612 </papid>which used prefix and suffix tries,though to our knowledge incorporating all character  grams is new.</prevsent>
<prevsent>in section 2, we discuss character-level hmm, while in section 3 we discuss sequence-free maximum-entropy (maxent) classifier which uses  -gram substring features.</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
finally, in section 4 we add additional features to the maxent model, and chain these models into conditional markov model (cmm), as used for tagging (ratnaparkhi, 1996) <papid> W96-0213 </papid>or earlier ner work (borth wick, 1999).</citsent>
<aftsection>
<nextsent>figure 1 shows graphical model representation of our character-level hmm.
</nextsent>
<nextsent>characters are emitted one at time, and there is one state per character.
</nextsent>
<nextsent>each states identity depends only on the previous state.
</nextsent>
<nextsent>each characters identity depends on both the current state and on the previous   characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3461">
<title id=" W02-1501.xml">grammar and lexicon in the robust parsing of italian towards a nonnaefve interplay </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>results shed light on the contribution of types of lexical information to parsing.
</prevsent>
<prevsent>it is widely assumed that rich computational lexicons form fundamental component of reliable parsing architectures and that lexical information can only have beneficial effects on parsing.
</prevsent>
</prevsection>
<citsent citstr=" C88-2092 ">
since the beginning of work on broad coverage parsing (jensen 1988<papid> C88-2092 </papid>a, 1988b), the key issue has been how to make effective use of lexical information.</citsent>
<aftsection>
<nextsent>in this paper we put these assumptions to the test by addressing the following questions: to what extent should lexicon be trusted for parsing?
</nextsent>
<nextsent>what is the neat contribution of lexical information to overall parse success?
</nextsent>
<nextsent>we present here the results of preliminary evaluation of the interplay between lexical and grammatical information in parsing italian using robust parsing system based on an incremental approach to shallow syntactic analysis.
</nextsent>
<nextsent>the system can run in both non-lexicalised and lexicalised mode.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3462">
<title id=" W02-1501.xml">grammar and lexicon in the robust parsing of italian towards a nonnaefve interplay </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other types of syntactic information that are also found in syntactic lexicons are: argument optionality, verb control, auxiliary selection, order constraints, etc. on the other hand, collocation-based lexical information is only rarely provided by computational lexicons, gap often lamented in robust parsing system development.
</prevsent>
<prevsent>a number of syntactic computational lexicons are nowadays available to the nlp community.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
important examples are ldoce (procter 1987), comlex (grishman et al 1994), <papid> C94-1042 </papid>parole (ruimy et al 1998).</citsent>
<aftsection>
<nextsent>these lexicons are basically hand-crafted by expert lexico gra phers, and their natural purpose is to provide general purpose, domain-independent syntactic information, covering the most frequent entries and frames.
</nextsent>
<nextsent>on the other hand, parsing systems often complement general lexicons with corpus driven, automatically harvested syntactic information (federici et al 1998b, briscoe 2001, korhonen 2002).
</nextsent>
<nextsent>automatic acquisition of subcategorization frames allows systems to access highly context dependent constructions, to fill in possible lexical gaps and eventually relyon frequency information to tune the relative impact of specific frames (carroll et al 1998).<papid> W98-1114 </papid></nextsent>
<nextsent>lexicon coverage is usually regarded as the main parameter affecting use of lexical information for parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3463">
<title id=" W02-1501.xml">grammar and lexicon in the robust parsing of italian towards a nonnaefve interplay </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these lexicons are basically hand-crafted by expert lexico gra phers, and their natural purpose is to provide general purpose, domain-independent syntactic information, covering the most frequent entries and frames.
</prevsent>
<prevsent>on the other hand, parsing systems often complement general lexicons with corpus driven, automatically harvested syntactic information (federici et al 1998b, briscoe 2001, korhonen 2002).
</prevsent>
</prevsection>
<citsent citstr=" W98-1114 ">
automatic acquisition of subcategorization frames allows systems to access highly context dependent constructions, to fill in possible lexical gaps and eventually relyon frequency information to tune the relative impact of specific frames (carroll et al 1998).<papid> W98-1114 </papid></citsent>
<aftsection>
<nextsent>lexicon coverage is usually regarded as the main parameter affecting use of lexical information for parsing.
</nextsent>
<nextsent>however, the real comparative impact of the type (rather than the mere quantity) of lexical information has been seldom discussed.
</nextsent>
<nextsent>our results show that the contribution of various lexical information types to parse success is not uniform.
</nextsent>
<nextsent>the experiment focuses on particular subset of the information available in syntactic lexicons - the representation of pp complements in lexical frames - tested on the task of pp-attachment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3464">
<title id=" W03-1605.xml">interrogative reformulation patterns and acquisition of question paraphrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results obtained by using the patterns in paraphrase recognition were quite promising.
</prevsent>
<prevsent>the phenomenon of paraphrase in human languages is essentially the inverse of ambiguity ? given sentence could ambiguously have several meanings, while any given meaning could be formulated into several paraphrases using various words and syntactic constructions.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
for this reason, paraphrase posesa great challenge for many natural language processing (nlp) tasks, just as ambiguity does, notably in text summarization and nl generation (barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>the problem of paraphrase is important in question-answering systems as well, because the systems must return the same answer to questions which ask for the same thing but are expressed in different ways.
</nextsent>
<nextsent>recently there have been several work which utilized reformulations of questions as way to fill the chasm between words in question and those in potential answer sentence (hermjakob et al, 2002; murata and isahara, 2001; agichtei et al., 2001).
</nextsent>
<nextsent>in general, paraphrasing question, be it for recognition or generation, is more difficult than declarative sentence, because interrogative words carry meaning of their own, which is subject to reformulation, in addition to the rest (or the sentencepart) of the question.
</nextsent>
<nextsent>reformulations of the interrogative part of questions have some interesting characteristics which are distinct from reformulations of the sentence part or declarative sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3465">
<title id=" W03-1605.xml">interrogative reformulation patterns and acquisition of question paraphrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results obtained by using the patterns in paraphrase recognition were quite promising.
</prevsent>
<prevsent>the phenomenon of paraphrase in human languages is essentially the inverse of ambiguity ? given sentence could ambiguously have several meanings, while any given meaning could be formulated into several paraphrases using various words and syntactic constructions.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
for this reason, paraphrase posesa great challenge for many natural language processing (nlp) tasks, just as ambiguity does, notably in text summarization and nl generation (barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>the problem of paraphrase is important in question-answering systems as well, because the systems must return the same answer to questions which ask for the same thing but are expressed in different ways.
</nextsent>
<nextsent>recently there have been several work which utilized reformulations of questions as way to fill the chasm between words in question and those in potential answer sentence (hermjakob et al, 2002; murata and isahara, 2001; agichtei et al., 2001).
</nextsent>
<nextsent>in general, paraphrasing question, be it for recognition or generation, is more difficult than declarative sentence, because interrogative words carry meaning of their own, which is subject to reformulation, in addition to the rest (or the sentencepart) of the question.
</nextsent>
<nextsent>reformulations of the interrogative part of questions have some interesting characteristics which are distinct from reformulations of the sentence part or declarative sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3466">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>must recognize rants and emotional tirades, among otherthings.
</prevsent>
<prevsent>in general, nearly any system that seeks to identify information could benefit from being able to separate factual and subjective information.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
some existing resources contain lists of subjective words (e.g., levins desire verbs (1993)), and some empirical methods in nlp have automatically identified adjectives, verbs, and n-grams that are statistically associated with subjective language (e.g., (turney, 2002; <papid> P02-1053 </papid>hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>wiebe, 2000; wiebeet al, 2001)).</citsent>
<aftsection>
<nextsent>however, subjective language can be exhibited by staggering variety of words and phrases.
</nextsent>
<nextsent>in addition, many subjective terms occur infrequently, suchas strongly subjective adjectives (e.g., preposterous, un seemly) and metaphorical or idiomatic phrases (e.g., dealt blow, swept off ones feet).
</nextsent>
<nextsent>consequently, we believe that subjectivity learning systems must be trained on extremely large text collections before they will acquire asubjective vocabulary that is truly broad and comprehensive in scope.
</nextsent>
<nextsent>to address this issue, we have been exploring the use of bootstrapping methods to allow subjectivity classifier sto learn from collection of unannotated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3468">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>must recognize rants and emotional tirades, among otherthings.
</prevsent>
<prevsent>in general, nearly any system that seeks to identify information could benefit from being able to separate factual and subjective information.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
some existing resources contain lists of subjective words (e.g., levins desire verbs (1993)), and some empirical methods in nlp have automatically identified adjectives, verbs, and n-grams that are statistically associated with subjective language (e.g., (turney, 2002; <papid> P02-1053 </papid>hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>wiebe, 2000; wiebeet al, 2001)).</citsent>
<aftsection>
<nextsent>however, subjective language can be exhibited by staggering variety of words and phrases.
</nextsent>
<nextsent>in addition, many subjective terms occur infrequently, suchas strongly subjective adjectives (e.g., preposterous, un seemly) and metaphorical or idiomatic phrases (e.g., dealt blow, swept off ones feet).
</nextsent>
<nextsent>consequently, we believe that subjectivity learning systems must be trained on extremely large text collections before they will acquire asubjective vocabulary that is truly broad and comprehensive in scope.
</nextsent>
<nextsent>to address this issue, we have been exploring the use of bootstrapping methods to allow subjectivity classifier sto learn from collection of unannotated texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3471">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 subjectivity analysis.
</prevsent>
<prevsent>much previous work on subjectivity recognition has focused on document-level classification.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
for example,(spertus, 1997) developed system to identify inflammatory texts and (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002) <papid> W02-1011 </papid>developed methods for classifying reviews as positive or negative.</citsent>
<aftsection>
<nextsent>some research in genre classification has included the recognition of subjective genres such as editorials (e.g., (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al, 1997; <papid> P97-1005 </papid>wiebe et al, 2001)).in contrast, the goal of our work is to classify individual sentences as subjective or objective.</nextsent>
<nextsent>document-level classification can distinguish between subjective texts?, such as editorials and reviews, and objective texts,?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3473">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>much previous work on subjectivity recognition has focused on document-level classification.
</prevsent>
<prevsent>for example,(spertus, 1997) developed system to identify inflammatory texts and (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002) <papid> W02-1011 </papid>developed methods for classifying reviews as positive or negative.</prevsent>
</prevsection>
<citsent citstr=" C94-2174 ">
some research in genre classification has included the recognition of subjective genres such as editorials (e.g., (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al, 1997; <papid> P97-1005 </papid>wiebe et al, 2001)).in contrast, the goal of our work is to classify individual sentences as subjective or objective.</citsent>
<aftsection>
<nextsent>document-level classification can distinguish between subjective texts?, such as editorials and reviews, and objective texts,?
</nextsent>
<nextsent>such as newspaper articles.
</nextsent>
<nextsent>but in reality, most documents contain mix of both subjective and objective sentences.
</nextsent>
<nextsent>subjective texts often include some factual information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3474">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>much previous work on subjectivity recognition has focused on document-level classification.
</prevsent>
<prevsent>for example,(spertus, 1997) developed system to identify inflammatory texts and (turney, 2002; <papid> P02-1053 </papid>pang et al, 2002) <papid> W02-1011 </papid>developed methods for classifying reviews as positive or negative.</prevsent>
</prevsection>
<citsent citstr=" P97-1005 ">
some research in genre classification has included the recognition of subjective genres such as editorials (e.g., (karlgren and cutting, 1994; <papid> C94-2174 </papid>kessler et al, 1997; <papid> P97-1005 </papid>wiebe et al, 2001)).in contrast, the goal of our work is to classify individual sentences as subjective or objective.</citsent>
<aftsection>
<nextsent>document-level classification can distinguish between subjective texts?, such as editorials and reviews, and objective texts,?
</nextsent>
<nextsent>such as newspaper articles.
</nextsent>
<nextsent>but in reality, most documents contain mix of both subjective and objective sentences.
</nextsent>
<nextsent>subjective texts often include some factual information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3477">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for example, (pang et al, 2002) <papid> W02-1011 </papid>collected reviews from movie database and rated them as positive, negative, or neutral based on the rating (e.g., number of stars) given by the reviewer.</prevsent>
<prevsent>it is much harder to obtain collections of individual sentences that can be easily identified as subjective or objective.</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
previous work on sentence-level subjectivity classification (wiebe et al, 1999) <papid> P99-1032 </papid>used training corpora that had been manually annotated for subjectiv ity.</citsent>
<aftsection>
<nextsent>manually producing annotations is time consuming,so the amount of available annotated sentence data is relatively small.the goal of our research is to use high-precision subjectivity classifiers to automatically identify subjective and objective sentences in unannotated text corpora.
</nextsent>
<nextsent>the high-precision classifiers label sentence as subjective or objective when they are confident about the classification,and they leave sentence unlabeled otherwise.
</nextsent>
<nextsent>unannotated texts are easy to come by, so even if the classifier scan label only 30% of the sentences as subjective or objective, they will still produce large collection of labeledsentences.
</nextsent>
<nextsent>most importantly, the high-precision classifiers can generate much larger set of labeled sentences than are currently available in manually created datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3478">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample, you can say that comedian bombed last night, which is subjective statement, but you cant express this sentiment with the passive voice of bombed.
</prevsent>
<prevsent>in section 3.2, we will show examples of extraction patterns representing subjective expressions which do in fact exhibit both of these phenomena.a variety of algorithms have been developed to automatically learn extraction patterns.
</prevsent>
</prevsection>
<citsent citstr=" P98-1067 ">
most of these algorithms require special training resources, such astexts annotated with domain-specific tags (e.g., au toslog (riloff, 1993), crystal (soderland et al, 1995), rapier (califf, 1998), srv (freitag, 1998),<papid> P98-1067 </papid>whisk (soderland, 1999)) or manually defined keywords, frames, or object recognizers (e.g., palka (kim and moldovan, 1993) and liep (huffman, 1996)).</citsent>
<aftsection>
<nextsent>autoslog-ts (riloff, 1996) takes different approach, requiring only corpus of unannotated texts that have been separated into those that are related to the target domain (the relevant?
</nextsent>
<nextsent>texts) and those that are not (the irrelevant?
</nextsent>
<nextsent>texts).
</nextsent>
<nextsent>most recently, two bootstrapping algorithms have been used to learn extraction patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3479">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>most recently, two bootstrapping algorithms have been used to learn extraction patterns.
</prevsent>
<prevsent>meta bootstrapping (riloff and jones, 1999) learns both extraction patterns and semantic lexicon using unannotated texts and seed words as input.
</prevsent>
</prevsection>
<citsent citstr=" C00-2136 ">
exdisco (yangarber et al,2000) <papid> C00-2136 </papid>uses bootstrapping mechanism to find new extraction patterns using unannotated texts and some seed patterns as the initial input.</citsent>
<aftsection>
<nextsent>for our research, we adopted learning process very similar to that used by autoslog-ts, which requires only relevant texts and irrelevant texts as its input.
</nextsent>
<nextsent>we describe this learning process in more detail in the next section.
</nextsent>
<nextsent>patterns for subjectivity we have developed bootstrapping process for subjectivity classification that explores three ideas: (1) high precision classifiers can be used to automatically identify subjective and objective sentences from unannotated texts, (2) this data can be used as training set to automatically learn extraction patterns associated with subjectivity, and (3) the learned patterns can be used to growthe training set, allowing this entire process to be boot strapped.figure 1 shows the components and layout of the bootstrapping process.
</nextsent>
<nextsent>the process begins with large collection of unannotated text and two high precision subjectivity classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3480">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> learning and bootstrapping extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the high-precision classifiers (hp-subj and hp-obj) use lists of lexical items that have been shown in previous work to be good subjectivity clues.
</prevsent>
<prevsent>most of the items are single words, some are n-grams, but none involve syntactic generalizations as in the extraction patterns.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
any data used to develop this vocabulary does not overlap with the test sets or the unannotated data used in this paper.many of the subjective clues are from manually developed resources, including entries from (levin, 1993; ballmer and brennenstuhl, 1981), framenet lemmas with frame element experiencer (baker et al, 1998), <papid> P98-1013 </papid>adjectives manually annotated for polarity (hatzivassiloglou and mckeown, 1997), <papid> P97-1023 </papid>and subjectivity clues listed in(wiebe, 1990).</citsent>
<aftsection>
<nextsent>others were derived from corpora, including subjective nouns learned from unannotated data using bootstrapping (riloff et al, 2003).<papid> W03-0404 </papid></nextsent>
<nextsent>the subjectivity clues are divided into those that are strongly subjective and those that are weakly subjective,using combination of manual review and empirical results on small training set of manually annotated data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3482">
<title id=" W03-1014.xml">learning extraction patterns for subjective expressions </title>
<section> learning and bootstrapping extraction.  </section>
<citcontext>
<prevsection>
<prevsent>most of the items are single words, some are n-grams, but none involve syntactic generalizations as in the extraction patterns.
</prevsent>
<prevsent>any data used to develop this vocabulary does not overlap with the test sets or the unannotated data used in this paper.many of the subjective clues are from manually developed resources, including entries from (levin, 1993; ballmer and brennenstuhl, 1981), framenet lemmas with frame element experiencer (baker et al, 1998), <papid> P98-1013 </papid>adjectives manually annotated for polarity (hatzivassiloglou and mckeown, 1997), <papid> P97-1023 </papid>and subjectivity clues listed in(wiebe, 1990).</prevsent>
</prevsection>
<citsent citstr=" W03-0404 ">
others were derived from corpora, including subjective nouns learned from unannotated data using bootstrapping (riloff et al, 2003).<papid> W03-0404 </papid></citsent>
<aftsection>
<nextsent>the subjectivity clues are divided into those that are strongly subjective and those that are weakly subjective,using combination of manual review and empirical results on small training set of manually annotated data.
</nextsent>
<nextsent>as the terms are used here, strongly subjective clue is one that is seldom used without subjective meaning, whereas weakly subjective clue is one that commonly has both subjective and objective uses.the high-precision subjective classifier classifies sentence as subjective if it contains two or more of the strongly subjective clues.
</nextsent>
<nextsent>on manually annotated test set, this classifier achieves 91.5% precision and 31.9% recall (that is, 91.5% of the sentences that it selected are subjective, and it found 31.9% of the subjective sentences in the test set).
</nextsent>
<nextsent>this test set consists of 2197 sentences, 59% of which are subjective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3484">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the semi supervised approach (using seed set of sample verbs) overall outperforms not only the full set of features, but the hand-selected features as well.
</prevsent>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></citsent>
<aftsection>
<nextsent>unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</nextsent>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3485">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the semi supervised approach (using seed set of sample verbs) overall outperforms not only the full set of features, but the hand-selected features as well.
</prevsent>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
</prevsection>
<citsent citstr=" C96-1055 ">
learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></citsent>
<aftsection>
<nextsent>unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</nextsent>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3488">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the semi supervised approach (using seed set of sample verbs) overall outperforms not only the full set of features, but the hand-selected features as well.
</prevsent>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
</prevsection>
<citsent citstr=" W99-0632 ">
learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></citsent>
<aftsection>
<nextsent>unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</nextsent>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3489">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the semi supervised approach (using seed set of sample verbs) overall outperforms not only the full set of features, but the hand-selected features as well.
</prevsent>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></citsent>
<aftsection>
<nextsent>unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</nextsent>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3491">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the semi supervised approach (using seed set of sample verbs) overall outperforms not only the full set of features, but the hand-selected features as well.
</prevsent>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
</prevsection>
<citsent citstr=" E03-1040 ">
learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></citsent>
<aftsection>
<nextsent>unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</nextsent>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3492">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
<prevsent>learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" W98-1106 ">
unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</citsent>
<aftsection>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).
</nextsent>
<nextsent>as such, they serve as means for organizing complex knowledge about verbs in computational lexicon (kipper et al , 2000).
</nextsent>
<nextsent>however, creating verb classification is highly resource intensive, interms of both required time and linguistic expertise.
</nextsent>
<nextsent>development of minimally supervised methods is of particular importance if we are to automatically classify verbs for languages other than english, where substantial amounts of labelled data are not available for training classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3493">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>computational linguists face lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
</prevsent>
<prevsent>learning the argument structure properties of verbs the semantic roles they assign and their mapping to syntactic position sis both particularly important and difficult.a number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), <papid> J02-3001 </papid>selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; <papid> C96-1055 </papid>lapata and brew, 1999; <papid> W99-0632 </papid>merlo and stevenson, 2001; <papid> J01-3003 </papid>joanis and stevenson, 2003).<papid> E03-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" E99-1007 ">
unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (riloff and schmelzenbach, 1998), <papid> W98-1106 </papid>on the hand selection of features (stevenson and merlo, 1999), <papid> E99-1007 </papid>or on the use of an extensive grammar (schulte im walde and brew, 2002).we focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew,2002; stevenson and merlo, 1999), <papid> E99-1007 </papid>to the lexical semantic classification of verbs.</citsent>
<aftsection>
<nextsent>such classes group together verbs that share both common semantics (such as transfer of possession or change of state), and set of syntactic frames for expressing the arguments of the verb (levin, 1993; framenet, 2003).
</nextsent>
<nextsent>as such, they serve as means for organizing complex knowledge about verbs in computational lexicon (kipper et al , 2000).
</nextsent>
<nextsent>however, creating verb classification is highly resource intensive, interms of both required time and linguistic expertise.
</nextsent>
<nextsent>development of minimally supervised methods is of particular importance if we are to automatically classify verbs for languages other than english, where substantial amounts of labelled data are not available for training classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3502">
<title id=" W03-0410.xml">semi supervised verb class discovery using noisy features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to merlo and stevenson (2001), <papid> J01-3003 </papid>we confirmed that set of general features can be successfully used, without the needfor manually determining the relevant features for distinguishing particular classes (cf.</prevsent>
<prevsent>dorr and jones, 1996; <papid> C96-1055 </papid>schulte im walde and brew, 2002).</prevsent>
</prevsection>
<citsent citstr=" C02-1040 ">
on the other hand, in contrast to schulte im walde and brew (2002), we demonstrated that accurate subcategorization statistics are unnecessary (see also sarkar and tripasai, 2002).<papid> C02-1040 </papid>by avoiding the dependence on precise feature extraction, our approach should be more portable to new lan guages.</citsent>
<aftsection>
<nextsent>however, general feature space means that most features will be irrelevant to any given verb discrimination task.
</nextsent>
<nextsent>in an unsupervised (clustering) scenario of verb class discovery, can we maintain the benefit of only needing noisy features, without the generality of the feature space leading to the curse of dimensionality??
</nextsent>
<nextsent>in supervised experiments, the learner uses class labels during the training stage to determine which features are relevant to the task at hand.
</nextsent>
<nextsent>in the unsupervised setting, the large number of potentially irrelevant features becomes serious problem, since those features may mislead the learner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3525">
<title id=" W03-1809.xml">a statistical approach to the semantics of verb particles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such items cause considerable problems for any semantically-groundednlp application (including applications where semantic information is implicit, such as informationretrieval) because their meaning is often not simply function of the meaning of the constituent parts.
</prevsent>
<prevsent>however, corpus-based or empirical nlp has shown limited interest in the problem.
</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
while there has been some work on statistical approaches to the semantics of compositional compound nominals (e.g. lauer (1995), barker and szpakowicz (1998), <papid> P98-1015 </papid>rosario and hearst (2001)), the more idiosyncratic items have been largely ignored beyond attempts at identification (melamed, 1997; lin, 1999; schone and jurafsky, 2001).</citsent>
<aftsection>
<nextsent>and yet the identification of non compositional phrases, while valuable in itself, would by no means be the end of the matter.
</nextsent>
<nextsent>the unique challenge posed by mwes for empirical nlp is precisely that they do not fall cleanly into the binary classes of compositional and non-compositional expressions, but populate continuum between the two extremes.part of the reason for the lack of interest by computational linguists in the semantics of mwes is that there is no established gold standard data from which to constructor evaluate models.
</nextsent>
<nextsent>evaluation to date has tended to be fairly ad hoc.
</nextsent>
<nextsent>another key problem is the lack of any firm empirical foundations for the notion of compositionality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3526">
<title id=" W03-1809.xml">a statistical approach to the semantics of verb particles </title>
<section> building the resource.  </section>
<citcontext>
<prevsection>
<prevsent>entailment judgements, we decided upon an experimental setup where the subject is, for each vpc type, presented with fixed selection of sentential contexts for that vpc.
</prevsent>
<prevsent>so as to avoid introducing any bias into the experiment through artificially-generated sentences,we chose to extract the sentences from naturally occurring text, namely the written component of the british national corpus (bnc, burnard (2000)).
</prevsent>
</prevsection>
<citsent citstr=" W02-2001 ">
extraction of the vpcs was based on the method of baldwin and villavicencio (2002).<papid> W02-2001 </papid></citsent>
<aftsection>
<nextsent>first, we used pos tagger and chunker (both built using fntbl 1.0(ngai and florian, 2001)) to (re)tag the bnc.
</nextsent>
<nextsent>this allowed us to extract vpc tokens through use of: (a) the particle pos in the pos tagged output, for each instance of which we simply then look for the right most verb within fixed window to the left of the particle, and (b) the particle chunk tag in the chunker output, where we similarly locate the rightmost verb associated with each particle chunk occurrence.
</nextsent>
<nextsent>finally, we ran stochastic chunk-based grammar over the chunker output to extend extraction coverage to include mis tagged particles and also more reliably determine the valence of the vpc.
</nextsent>
<nextsent>the token output of these three methods was amalgamated by weighted voting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3527">
<title id=" W03-1809.xml">a statistical approach to the semantics of verb particles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly to this research, mccarthy et al in part used the similarity measure of lin (1998a) to model compositionality, e.g., in taking the top similar words to each vpc and looking at overlap with the top similar words to the head verb.
</prevsent>
<prevsent>they also examine the use of statistical tests such as mutual information in modelling com positionality, and find the similarity-based methods to correlate more highly with the human judgements.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
baldwin et al (2003) <papid> W03-1812 </papid>use lsa as technique for analysing the compositionality (or decomposabil ity) of given mwe.</citsent>
<aftsection>
<nextsent>lsa is suggested to be construction-inspecific test for compositionality, which is illustrated by testing its effectivity over both english noun-noun compounds and vpcs.
</nextsent>
<nextsent>baldwin et al used lsa to calculate the distributional similarity between an mwe and its head word, and demonstrate correlation between similarity and composi tionality (modelled in terms of endocentricity) by wayof items with higher similarity being more compositional.
</nextsent>
<nextsent>they do not go as far as to classify mwes as being compositional or non-compositional, however.
</nextsent>
<nextsent>having created our gold-standard data, we implemented some statistical techniques for automatic analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3528">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments show high accuracy, fine-grained tag resolution with minimal new human effort.
</prevsent>
<prevsent>previous work in minimally supervised language learning has defined minimal using several different criteria.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
some have assumed only partially tagged training corpora (merialdo, 1994), <papid> J94-2001 </papid>while others have begin with small tagged seed word lists (such as collins and singer (1999) <papid> W99-0613 </papid>and cucerzan and yarowsky (1999) <papid> W99-0612 </papid>for named-entity tagging).</citsent>
<aftsection>
<nextsent>others have exploited the automatic transfer of some already existing annotated resource in different medium or language (such as the trans lingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in yarowsky et al(2001), <papid> H01-1035 </papid>requiring no direct supervision in the foreign language).</nextsent>
<nextsent>ngai and yarowsky (2000) observed that an often more practical measure of the degree of supervision is not simply the quantity of annotated words, but the total weighted human labor and resource costs of different modes of supervision (allowing manual rule writing to be compared directly with active learning on common cost-performance learning curve).in this paper we observe that another useful measure of (minimal) supervision is the additional cost of obtaining desired functionality from existing commonly available knowledge sources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3529">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments show high accuracy, fine-grained tag resolution with minimal new human effort.
</prevsent>
<prevsent>previous work in minimally supervised language learning has defined minimal using several different criteria.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
some have assumed only partially tagged training corpora (merialdo, 1994), <papid> J94-2001 </papid>while others have begin with small tagged seed word lists (such as collins and singer (1999) <papid> W99-0613 </papid>and cucerzan and yarowsky (1999) <papid> W99-0612 </papid>for named-entity tagging).</citsent>
<aftsection>
<nextsent>others have exploited the automatic transfer of some already existing annotated resource in different medium or language (such as the trans lingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in yarowsky et al(2001), <papid> H01-1035 </papid>requiring no direct supervision in the foreign language).</nextsent>
<nextsent>ngai and yarowsky (2000) observed that an often more practical measure of the degree of supervision is not simply the quantity of annotated words, but the total weighted human labor and resource costs of different modes of supervision (allowing manual rule writing to be compared directly with active learning on common cost-performance learning curve).in this paper we observe that another useful measure of (minimal) supervision is the additional cost of obtaining desired functionality from existing commonly available knowledge sources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3530">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments show high accuracy, fine-grained tag resolution with minimal new human effort.
</prevsent>
<prevsent>previous work in minimally supervised language learning has defined minimal using several different criteria.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
some have assumed only partially tagged training corpora (merialdo, 1994), <papid> J94-2001 </papid>while others have begin with small tagged seed word lists (such as collins and singer (1999) <papid> W99-0613 </papid>and cucerzan and yarowsky (1999) <papid> W99-0612 </papid>for named-entity tagging).</citsent>
<aftsection>
<nextsent>others have exploited the automatic transfer of some already existing annotated resource in different medium or language (such as the trans lingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in yarowsky et al(2001), <papid> H01-1035 </papid>requiring no direct supervision in the foreign language).</nextsent>
<nextsent>ngai and yarowsky (2000) observed that an often more practical measure of the degree of supervision is not simply the quantity of annotated words, but the total weighted human labor and resource costs of different modes of supervision (allowing manual rule writing to be compared directly with active learning on common cost-performance learning curve).in this paper we observe that another useful measure of (minimal) supervision is the additional cost of obtaining desired functionality from existing commonly available knowledge sources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3531">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in minimally supervised language learning has defined minimal using several different criteria.
</prevsent>
<prevsent>some have assumed only partially tagged training corpora (merialdo, 1994), <papid> J94-2001 </papid>while others have begin with small tagged seed word lists (such as collins and singer (1999) <papid> W99-0613 </papid>and cucerzan and yarowsky (1999) <papid> W99-0612 </papid>for named-entity tagging).</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
others have exploited the automatic transfer of some already existing annotated resource in different medium or language (such as the trans lingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in yarowsky et al(2001), <papid> H01-1035 </papid>requiring no direct supervision in the foreign language).</citsent>
<aftsection>
<nextsent>ngai and yarowsky (2000) observed that an often more practical measure of the degree of supervision is not simply the quantity of annotated words, but the total weighted human labor and resource costs of different modes of supervision (allowing manual rule writing to be compared directly with active learning on common cost-performance learning curve).in this paper we observe that another useful measure of (minimal) supervision is the additional cost of obtaining desired functionality from existing commonly available knowledge sources.
</nextsent>
<nextsent>in particular, we note that for remarkably wide range of languages, academic libraries, many booksellers and web sites offer foundation of linguistic wisdom in reference grammars and dictionaries.
</nextsent>
<nextsent>thus starting from this baseline, what is the marginal cost of distilling from and augmenting this existing knowledge to achieve desired new task functionality?
</nextsent>
<nextsent>unlabeled bilingual dictionariesa substantial percentage of foreign language dictionaries that are available on line or in smaller paperback format are simple bilingual word or phrase translation lists which fail to specify part of speech.1 thus one component question of this work is howcan one extract preliminary part-of-speech distributions from untagged monolingual translation lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3532">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> inducing morphological analyses.  </section>
<citcontext>
<prevsection>
<prevsent>because all dictionary entries are equally weighted, errors on rare words such as mythological characters or kinship terms can substantially downgrade performance.
</prevsent>
<prevsent>but for the purposes of providing seed pos distributions tocontext-sensitive taggers, performance is quite adequate for this follow-on task.
</prevsent>
</prevsection>
<citsent citstr=" P01-1063 ">
there has been extensive previous work in the supervised and minimally supervised induction of both affix paradigms (e.g. goldsmith, 2000; snover and brent, 2001) <papid> P01-1063 </papid>and diverse models of regular and irregular concatenative and non-concatenative morphology (e.g. schone and jurafsky, 2000; <papid> W00-0712 </papid>van den bosch and daelemans, 1999; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while such approaches are important from the perspective of learning theory or broad coverage handling of irregular forms, another possible paradigm for minimal supervision is to begin with whatever knowledge can be efficiently manually entered from the grammar book in several hours work.
</nextsent>
<nextsent>we defined such grammar-based supervision?
</nextsent>
<nextsent>as entry of regular inflectional affix changes and their associated part of speech in standardized ordering of fine-grained attributes, as in table 2 for spanish and romanian.
</nextsent>
<nextsent>the full tables have approximately 200 lines each and required roughly 1.5-2 person-hours for entry.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3533">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> inducing morphological analyses.  </section>
<citcontext>
<prevsection>
<prevsent>because all dictionary entries are equally weighted, errors on rare words such as mythological characters or kinship terms can substantially downgrade performance.
</prevsent>
<prevsent>but for the purposes of providing seed pos distributions tocontext-sensitive taggers, performance is quite adequate for this follow-on task.
</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
there has been extensive previous work in the supervised and minimally supervised induction of both affix paradigms (e.g. goldsmith, 2000; snover and brent, 2001) <papid> P01-1063 </papid>and diverse models of regular and irregular concatenative and non-concatenative morphology (e.g. schone and jurafsky, 2000; <papid> W00-0712 </papid>van den bosch and daelemans, 1999; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while such approaches are important from the perspective of learning theory or broad coverage handling of irregular forms, another possible paradigm for minimal supervision is to begin with whatever knowledge can be efficiently manually entered from the grammar book in several hours work.
</nextsent>
<nextsent>we defined such grammar-based supervision?
</nextsent>
<nextsent>as entry of regular inflectional affix changes and their associated part of speech in standardized ordering of fine-grained attributes, as in table 2 for spanish and romanian.
</nextsent>
<nextsent>the full tables have approximately 200 lines each and required roughly 1.5-2 person-hours for entry.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3534">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> inducing morphological analyses.  </section>
<citcontext>
<prevsection>
<prevsent>because all dictionary entries are equally weighted, errors on rare words such as mythological characters or kinship terms can substantially downgrade performance.
</prevsent>
<prevsent>but for the purposes of providing seed pos distributions tocontext-sensitive taggers, performance is quite adequate for this follow-on task.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
there has been extensive previous work in the supervised and minimally supervised induction of both affix paradigms (e.g. goldsmith, 2000; snover and brent, 2001) <papid> P01-1063 </papid>and diverse models of regular and irregular concatenative and non-concatenative morphology (e.g. schone and jurafsky, 2000; <papid> W00-0712 </papid>van den bosch and daelemans, 1999; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while such approaches are important from the perspective of learning theory or broad coverage handling of irregular forms, another possible paradigm for minimal supervision is to begin with whatever knowledge can be efficiently manually entered from the grammar book in several hours work.
</nextsent>
<nextsent>we defined such grammar-based supervision?
</nextsent>
<nextsent>as entry of regular inflectional affix changes and their associated part of speech in standardized ordering of fine-grained attributes, as in table 2 for spanish and romanian.
</nextsent>
<nextsent>the full tables have approximately 200 lines each and required roughly 1.5-2 person-hours for entry.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3536">
<title id=" W02-2006.xml">bootstrapping a multilingual partofspeech tagger in one person day </title>
<section> pos model induction.  </section>
<citcontext>
<prevsection>
<prevsent> suffix-based part-of-speech probability model    suffix
</prevsent>
<prevsent>using hierarchically smoothed tries is trained on the raw initial tag distributions, yielding coverage to unseen words and smoothing of low-confidence initial tag assignments.
</prevsent>
</prevsection>
<citsent citstr=" P00-1035 ">
paradigmatic cross-context tag modeling is performed as in cucerzan and yarowsky (2000) <papid> P00-1035 </papid>when sufficiently large unannotated corpora are available.</citsent>
<aftsection>
<nextsent> sub-part-of-speech contextual agreement for features such as gender is performed as described in section 4.1.
</nextsent>
<nextsent> the part-of-speech tag sequence models
</nextsent>
<nextsent>utilize weighted backoff between fine-grained and coarse-grained tags.
</nextsent>
<nextsent> both the tag-sequence and lexical prior models are iteratively retrained using these additional evidence sources and first-pass probability dis tributions.the success of this model is based on the assumption that (a) words of the same part of speech tend to have similar tag sequence behavior, and (b)there are sufficient instances of each pos tag labeled by either the morphology models or closed class entries described in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3537">
<title id=" W03-0201.xml">utterance classification in auto tutor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by virtue of being embedded in auto tutor, the utterance classifier presented here has an unusual set of constraints, both practical and theoretical.
</prevsent>
<prevsent>on the practical side, auto tutor is web-based application that performs in real time; thus utterance classification must also proceed in real time.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
for that reason, the classifier uses minimum of resources, including part of speech tagging (brill 1995; <papid> J95-4004 </papid>sekine and grishman 1995) and cascaded finite state transducers defining the categories.</citsent>
<aftsection>
<nextsent>theoretically speaking, auto tutor must also recognize questions in meaningful way to both question answering and tutoring.
</nextsent>
<nextsent>the question taxonomy utilized, that of graesser et al (1992), is an extension of lehnert (1978) taxonomy for question answering and has been applied to human tutoring (graesser et al  1992; graesser and person 1994).
</nextsent>
<nextsent>this paper outlines the utterance classifier and quantifies its performance.
</nextsent>
<nextsent>in particular, section 2 presents autotutor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3538">
<title id=" W03-0201.xml">utterance classification in auto tutor </title>
<section> classifier algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>contributions in auto tutor, either as responses to questions or unprompted, are tracked to evaluate student performance via lsa, forming the basis for feedback.
</prevsent>
<prevsent>the present approach ignores the semantic and pragmatic context of the questions, and utilizes surface features to classify questions.
</prevsent>
</prevsection>
<citsent citstr=" A00-1023 ">
this shallow approach parallels work in question answering (srihari and li 2000; <papid> A00-1023 </papid>soubbotin and soubbotin 2002; moldovan et al  1999).</citsent>
<aftsection>
<nextsent>specifically, the classifier uses tagging provided by apple pie (sekine and grishman 1995) followed by cascaded finite state transducers defining the categories.
</nextsent>
<nextsent>the finite state transducers are roughly described in table 2.
</nextsent>
<nextsent>every transducer is given chance to match, and disambiguation routine is applied at the end to select single category.
</nextsent>
<nextsent>category example questions verification disjunctive concept completion feature specification quantification definition example comparison interpretation causal antecedent causal consequence goal orientation instrumental/procedural enable ment expectational judgmental does the pumpkin land in his hands?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3539">
<title id=" W03-0201.xml">utterance classification in auto tutor </title>
<section> training.  </section>
<citcontext>
<prevsection>
<prevsent>the skewed distribution of the question categories and their infrequency necessitates use of an extraction algorithm to locate them.
</prevsent>
<prevsent>simply looking for question marks is not enough: our estimates predict that raters would need to classify more than 5,000 questions extracted from the wall street journal this way to get mere 20 instances of the rarest types.
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
a bootstrapping approach using machine learning is possible alternative that will be explored in the future (abney 2002).<papid> P02-1046 </papid></citsent>
<aftsection>
<nextsent>regardless of these difficulties, the strongest evaluation results from using the classifier in real world task, with real world data.
</nextsent>
<nextsent>the classifier was used in auto tutor sessions through out the year of 2002.
</nextsent>
<nextsent>the log files from these sessions contained 9094 student utterances, each of which was classified by an expert.
</nextsent>
<nextsent>the expert ratings were compared to the classifier ratings, forming 2 2 contingency table for each category as in table 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3540">
<title id=" W03-0201.xml">utterance classification in auto tutor </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to expedite ratings, utterances extracted from the log files were split into two groups, contributions and non-contributions, according to their logged classification.
</prevsent>
<prevsent>expert judges were assigned to group and instructed to classify set of utterances to one of the 18 categories.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
though inter-rater reliability using the kappa statistic (carletta 1996) <papid> J96-2004 </papid>may be calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion.</citsent>
<aftsection>
<nextsent>skewed categories bias the kappa statistic to low values even when the proportion of rater agreement is very high (feinstein and cicchetti 1990a; feinstein and cicchetti 1990b).
</nextsent>
<nextsent>in the contribution group, judges can expect to see mostly one category, contribution, whereas judges in the non-contribution group can expect to see the other 17 categories.
</nextsent>
<nextsent>expected agreement by chance for the contribution group was 98%.
</nextsent>
<nextsent>correspondingly, inter-rater reliability using the kappa statistic was low for the contribution group, .5 despite 99% proportion agreement, and high for non-contribution group, .93.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="Z3541">
<title id=" W03-0201.xml">utterance classification in auto tutor </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>those categories that are not significant are starred; all other categories are significant,   .001.
</prevsent>
<prevsent>though not appropriate for hypothesis testing in this instance, likelihood ratios provide comparison of classifier performance across categories.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
likelihood ratios are particularly useful when comparing common and rare events (dunning 1993; <papid> J93-1003 </papid>plaunt and norgard 1998), making them natural here given the rare ness of most question categories and the frequency of contributions.</citsent>
<aftsection>
<nextsent>the likelihood ratios in the rightmost column of table 4 are on natural logarithmic scale, -2ln?, so procedural at . 5 20.23 = 24711 is more likely than goal orientation, at . 5 14.49 = 1401, with respect to the base rate, or null hypothesis.
</nextsent>
<nextsent>to judge overall performance on the auto tutor sessions, an average weighted f-measure may be calculated by summing the products of all category measures with their frequencies: ? +??= fntpmeasureffavg the average weighted f-measure reflects real world performance since accuracy on frequently occurring classes is weighted more.
</nextsent>
<nextsent>the average weighted measure for the evaluation data is .98, mostly due to the great frequency of contributions (.97 of all utterances) and the high associated f-measure.
</nextsent>
<nextsent>without weighting, the average f-measure for the significant cells is .54.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>