12	table 3: example compressions compression avglen rating baseline 9.70 1.93 bt-2-step 22.06 3.21 spade 19.09 3.10 humans 20.07 3.83 table 4: mean ratings for automatic compressionsnally, we added a simple baseline compression algorithm proposed by jing and mckeown which removed all prepositional phrases, clauses, toinfinitives, and gerunds. 
19	while earlier approaches for text compression were based on symbolic reduction rules , more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced . 
9	jing and mckeown proposed a system based on extraction and cut-and-paste generation.ù 
18	text-to-text generation is an emerging area of research in nlp . 
17	to contrast, concentrated on analyzing human-written summaries in order to determine how professionals construct summaries. 
4	additionally, some research has explored cutting and pasting segments of text from the full document to generate a summary . 
2	while this approach exploits only syntactic and lexical information, jing and mckeown also rely on cohesion information, derived from word distribution in a text: phrases that are linked to a local context are retained, while phrases that have no such links are dropped. 
8	5.3 related works and discussion our two-step model essentially belongs to the same category as the works of and . 
7	we found that the deletion of lead parts did not occur very often in our summary, unlike the case of jing and mckeown . 
14	jing and mckeown have proposed a rule-based algorithm for sentence combination, but no results have been reported. 
5	we analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences . 
3	because of this, it is generally accepted that some kind of postprocessing should be performed to improve the final result, by shortening, fusing, or otherwise revising the material . 
6	as previously observed in the literature , such components include a clause in the clause conjunction, relative clauses, and some elements within a clause . 
10	but in fact, the issue of editing in text summarization has usually been neglected, notable exceptions being the works by jing and mckeown and mani, gates, and bloedorn . 
20	in addition to reducing the original sentences, jing and mckeown use a number of manually compiled rules to aggregate reduced sentences; for example, reduced clauses might be conjoined with and. 
16	our work in sentence reformulation is different from cut-and-paste summarization in many ways. 
1	the recent approach for editing extracted text spans may also produce improvement for our algorithm. 
13	previous research has addressed revision in single-document summaries and has suggested that revising summaries can make them more informative and correct errors. 
11	in addition to sentence fusion, compression algorithms and methods for expansion of a multiparallel corpus are other instances of such methods. 
15	jing and mckeown and jing propose a cut-and-paste strategy as a computational process of automatic abstracting and a sentence reduction strategy to produce concise sentences. 
