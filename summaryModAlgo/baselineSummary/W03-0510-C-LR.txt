for evaluation, we are using the rouge evaluation toolkit, which is a method based on ngram statistics, found to be highly correlated with human evaluations (lin and hovy, 2003a). 
it is also notable the study reported in (lin and hovy, 2003b) discussing the usefulness and limitations of automatic sentence extraction for summarization, which emphasizes the need of accurate tools for sentence extraction, as an integral part of automatic summarization systems. 
meta-evaluation of similarity metrics the question of how to know which similarity metric is best to evaluate automatic summaries/translations has been addressed by â€¢ comparing the quality of automatic items with the quality of manual references (culy and riehemann, 2003; lin and hovy, 2003b). 
