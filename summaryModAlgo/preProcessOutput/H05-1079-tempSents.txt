5	for example, two high-accuracy systems are those described in , achieving 60.4% accuracy with no task-specific information, and , which achieves 61.2% task-dependent accuracy, i.e. 
7	finally, a few efforts have tried to 42 translate sentences into formulas of first-order logic, in order to test logical entailment with a theorem prover. 
2	attempts have been made to remedy this deficit through various techniques, including modelbuilding and the addition of semantic axioms . 
9	 represents a1 and a0 into a first-order logic translation of the drs language used in discourse representation theory and uses a theorem prover and a model builder with some generic, lexical and geographical background knowledge to prove the entailment between the two texts. 
1	 ) applied or utilized lexical based word overlap measures. 
3	many previous approaches have used a logical form representation of the text and hypothesis sentences, focusing on deriving a proof by which one can infer the hypothesis logical form from the text logical form . 
4	the rte problem as presented in the pascal rte dataset is particularly attractive in that it is a reasonably simple task for human annotators with high inter-annotator agreement ), but an extremely challenging task for automated systems. 
6	these transformations are logical rules in or sequences of allowed rewrite rules in . 
8	we show comparable results from recent systems based on lexical similarity , graph alignment , weighted abduction , and a mixed system including theorem proving . 
