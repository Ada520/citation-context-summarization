on the other hand, redundancy can be exploited to identify important and accurate information for applications such as summarization and question answering (mani and bloedorn 1997; radev and mckeown 1998; radev, prager, and samn 2000; clarke, cormack, and lynam 2001; dumais et al 2002; chu-carroll et al 2003). 
co-selection measures include precision and recall of co-selected sentences, relative utility (radev et al, 2000), and kappa (siegel and castellan, 1988; carletta, 1996). 
but the interpretation of the results is not simple; studies (jing et al 1998; donaway, drummey, and mather 2000; radev, jing, and budzikowska 2000) 404 computational linguistics volume 28, number 4 show how the same summaries receive different scores under different measures or when compared to different (but presumably equivalent) ideal summaries created by humans. 
as in (radev et al, 2000), in order to create an extract of a certain length, we simply extract the top scoring sentences that add up to that length. 
in centroid-based summarization (radev et al, 2000), the sentences that contain more words from the centroid of the cluster are considered as central. 
a common approach is to measure similarity between all pairs of sentences and then use clustering to identify themes of common information (mckeown et al 1999; radev, jing, and budzikowska 2000; marcu and gerber 2001). 
among text summarization techniques, there are statistical methods and linguistic methods (radev et al, 2000; marcu et al, 1999). 
a straightforward approach for approximating sentence fusion can be found in the use of sentence extraction for multidocument summarization (carbonell and goldstein 1998; radev, jing, and budzikowska 2000; marcu and gerber 2001; lin and hovy 2002). 
other commonly used measures include kappa (carletta 1996) and relative utility (radev, jing, and budzikowska 2000), both of which take into account the performance of a summarizer that randomly picks passages from the original document to produce an extract. 
topic-oriented multi-document summarization has already been studied in other evaluation initiatives which provide testbeds to compare alternative approaches (over, 2003; goldstein et al, 2000; radev et al, 2000). 
however, this experiment differs from prior work in that we use judges to determine the relevance of sentences to sub-events rather than to evaluate summaries (radev et al, 2000). 
mead is a publicly available toolkit for multi-document summarization (radev et al, 2000; mead, 2003). 
other research rewards passages that include topic words, that is, words that have been determined to correlate well with the topic of interest to the user (for topic-oriented summaries) or with the general theme of the source text (buckley and cardie 1997; strzalkowski et al 1999; radev, jing, and budzikowska 2000). 
relative utility relative utility (ru) (radev et al, 2000) is tested on a large corpus for the first time in this project. 
a number of techniques for choosing the right sentences to extract have been proposed in the literature, ranging from word counts (luhn, 1958), key phrases (edmundson, 1969), naive bayesian classification (kupiec et al, 1995), lexical chains (barzilay and elhadad, 1997), topic signatures (hovy and lin, 1999) and cluster centroids (radev et al, 2000). 
sentence extraction techniques (luhn, 1958; radev et al, 2000), on the other hand, compute a score for each sentence based on certain features and output the most highly ranked sentences. 
mead (radev et al, 2000): mead is a centroid-based extractive summarizer that scores sentences based on sentence-level and inter-sentence features which indicate the quality of the sentence as a summary sentence. 
it allows us to distinguish the degree of importance between sentences, providing a more flexible model for evaluating sentence utility (radev et al, 2000). 
figure 7 summaries recall and precision a utility-based evaluation was also used to obtain more intuitive results than those given by precision and recall using the methods reported in (jing et al, 1998; goldstein et al, 1999; radev et al, 2000). 
first, our method focuses on subject shift of the documents from the target event rather than the sets of documents from different events (radev et al, 2000). 
for details see (radev et al, 2000). 
this is in contrast with a method proposed by radev (radev et al, 2000 ), where the centroid of a cluster is selected as the representative one. 
inspired by rst, [radev, 2000] endeavored to establish a cross-document structure theory (cst) that is more appropriate for mds. 
evaluation methods we use the relative utility (ru) method (radev et al, 2000) to compare our various summaries. 
we find that extrinsic, task-oriented evaluation method to be most easily automated, and quantifiable (radev 2000). 
the mead summarizer the mead summarizer [radev et al, 2000] [radev et al 2002] is based on sentence extraction and uses a linear combination of three features to rank the sentences in the source documents. 
the first of these, relative utility (ru) (radev et al, 2000) allows model summaries to consist of sentences with variable ranking. 
we observed the best results with maximal marginal relevance (mmr) (carbonell and goldstein, 1998) reranker and the default reranker of the system based on cross-sentence informational sub-sumption (csis) (radev, 2000). 
