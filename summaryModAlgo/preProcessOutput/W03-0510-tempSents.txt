6	meta-evaluation of similarity metrics the question of how to know which similarity metric is best to evaluate automatic summaries/translations has been addressed by ‚Ä¢ comparing the quality of automatic items with the quality of manual references . 
4	for evaluation, we are using the rouge evaluation toolkit1, which is a method based on ngram statistics, found to be highly correlated with human evaluations . 
10	another recent study investigated the extent to which extractive methods may be sufficient for summarization in the single-document case. 
9	bleu and rouge are the standard similarity metrics used in machine translation and text summarisation. 
13	the issue of subjectivity gains prominence as the compression ratio increases, i.e., the shorter the summary, the larger the number ofcorrect summaries . 
11	for evaluation, we are using the rouge evaluation toolkit, which is a method based on ngram statistics, found to be highly correlated with human evaluations . 
14	we provided more in-depth discussion of this issue in other papers . 
12	another notable development in the field is the uni-gram co-occurrence matching technique as proposed in . 
3	unigram co-occurrence metric in a recent study , we showed that the recall-based unigram cooccurrence automatic scoring metric correlates highly with human evaluation and has high recall and precision in predicting the statistical significance of results comparing with its human counterpart. 
8	these findings are additionally supported by the fact that automatic n-gram-based evaluation measures now being used to assess predominately extractive multi-document summarization systems correlate strongly with human judgments when restricted to the usage of unigrams and bigrams, but correlate weakly when longer n-grams are factored into the equation . 
7	let us imagine, for instance, that the best metric turns out to be a rouge variant that only considers unigrams to compute similarity. 
5	it is also notable the study reported in discussing the usefulness and limitations of automatic sentence extraction for summarization, which emphasizes the need of accurate tools for sentence extraction, as an integral part of automatic summarization systems. 
1	we have used rouge-1 , which gives good results with standard summaries . 
2	it is also notable the study reported in discussing the usefulness and limitations of automatic sentence extraction for text summarization, 23 single document metaù summarization algorithm summarization algo. 
