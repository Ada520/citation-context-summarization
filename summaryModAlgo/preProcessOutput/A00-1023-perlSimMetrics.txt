7	7	
7	8	0.113578333059068
7	13	0.149196989551632
7	3	0
7	10	0.394983684452636
7	4	0.151935085894083
7	11	0.32068946283777
7	1	0.104880367755267
7	5	0.118789999972276
7	6	0.385225786839278
7	12	0.0370776536781673
7	9	8.42941476113598e-07
7	2	0.272566325249781
8	7	0.113578333059068
8	8	
8	13	0.265303873137568
8	3	0
8	10	0.107004932319837
8	4	0.178931376701495
8	11	0.117267162765674
8	1	0.290839621613172
8	5	0.0907347161340324
8	6	0.0633122718070086
8	12	0
8	9	0.0322075684633118
8	2	0.113153456231666
13	7	0.149196989551632
13	8	0.265303873137568
13	13	
13	3	0.0490156780690219
13	10	0.0720128348046098
13	4	0.156226802533047
13	11	0.0988374891435862
13	1	0.851679834233513
13	5	0.664633070619563
13	6	0.0882201213715448
13	12	0.459964616387687
13	9	0.0217740062231141
13	2	0.129394787992197
3	7	0
3	8	0
3	13	0.0490156780690219
3	3	
3	10	0.11705842701243
3	4	0
3	11	0
3	1	0
3	5	0.122566484974146
3	6	0.0463499666942877
3	12	0.133779096944502
3	9	0
3	2	0.033030006425495
10	7	0.394983684452636
10	8	0.107004932319837
10	13	0.0720128348046098
10	3	0.11705842701243
10	10	
10	4	0.177644948519612
10	11	0.218891661505645
10	1	0.0788850978845969
10	5	0.0978581352628701
10	6	0.271415281085925
10	12	1.62688638401579e-05
10	9	0.0322910101965772
10	2	0.157684873817792
4	7	0.151935085894083
4	8	0.178931376701495
4	13	0.156226802533047
4	3	0
4	10	0.177644948519612
4	4	
4	11	0.157619104518849
4	1	0.131782782713278
4	5	0.150136342711555
4	6	0.145403451545195
4	12	0
4	9	0.087495666805381
4	2	0.226004102605719
11	7	0.32068946283777
11	8	0.117267162765674
11	13	0.0988374891435862
11	3	0
11	10	0.218891661505645
11	4	0.157619104518849
11	11	
11	1	0.108321965954763
11	5	0.136439324633202
11	6	0.258259774329395
11	12	0.082316787528807
11	9	0.0569012378399833
11	2	0.251385535414317
1	7	0.104880367755267
1	8	0.290839621613172
1	13	0.851679834233513
1	3	0
1	10	0.0788850978845969
1	4	0.131782782713278
1	11	0.108321965954763
1	1	
1	5	0.709211866702354
1	6	0.0746650777238949
1	12	0.504236645336405
1	9	0.0238178194863415
1	2	0.0833641869998917
5	7	0.118789999972276
5	8	0.0907347161340324
5	13	0.664633070619563
5	3	0.122566484974146
5	10	0.0978581352628701
5	4	0.150136342711555
5	11	0.136439324633202
5	1	0.709211866702354
5	5	
5	6	0.103505440582949
5	12	0.643831262058706
5	9	0.0273048970926247
5	2	0.106442776084643
6	7	0.385225786839278
6	8	0.0633122718070086
6	13	0.0882201213715448
6	3	0.0463499666942877
6	10	0.271415281085925
6	4	0.145403451545195
6	11	0.258259774329395
6	1	0.0746650777238949
6	5	0.103505440582949
6	6	
6	12	0.302014724659843
6	9	0.111884339920994
6	2	0.223090158706017
12	7	0.0370776536781673
12	8	0
12	13	0.459964616387687
12	3	0.133779096944502
12	10	1.62688638401579e-05
12	4	0
12	11	0.082316787528807
12	1	0.504236645336405
12	5	0.643831262058706
12	6	0.302014724659843
12	12	
12	9	0.110274653443213
12	2	0.173821863459024
9	7	8.42941476113598e-07
9	8	0.0322075684633118
9	13	0.0217740062231141
9	3	0
9	10	0.0322910101965772
9	4	0.087495666805381
9	11	0.0569012378399833
9	1	0.0238178194863415
9	5	0.0273048970926247
9	6	0.111884339920994
9	12	0.110274653443213
9	9	
9	2	0.212152199236064
2	7	0.272566325249781
2	8	0.113153456231666
2	13	0.129394787992197
2	3	0.033030006425495
2	10	0.157684873817792
2	4	0.226004102605719
2	11	0.251385535414317
2	1	0.0833641869998917
2	5	0.106442776084643
2	6	0.223090158706017
2	12	0.173821863459024
2	9	0.212152199236064
2	2	
7	if the expected answer types are typical named entities, information extraction engines are used to extract candidate answers. 
8	this shallow approach parallels work in question answering . 
13	examples of the use of nlp and ie in question answering include shallow parsing , semantic parsing , named entity tagging and high-level ie . 
3	high performance qa systems . 
10	in response, factoid question answering systems have evolved into two types: â€¢ use-knowledge: extract query words from the input question, perform ir against the source corpus, possibly segment resulting documents, identify a set of segments containing likely answers, apply a set of heuristics that each consults a different source of knowledge to score each candidate, rank them, and select the best . 
4	to find the answer to a question several steps must be taken, as reported in : a2 first, the question semantics needs to be captured. 
11	it is worth noticing that in our experiment, the structural support used for answer-point identification only checks the binary links involving the asking point and the candidate answer points, instead of full template matching as proposed in . 
1	examples of using nlp and ie in question answering include shallow parsing , deep parsing , and ie . 
5	2 question answering based on ie we use a qa system supported by increasingly sophisticated levels of ie . 
6	qa is different than search engines in two aspects: instead of a string of keyword search terms, the query is a natural language question, necessitating question parsing, instead of a list of documents or urls, a list of candidate answers at phrase level or sentence level are expected to be returned in response to a query, hence the need for text processing beyond keyword indexing, typically supported by natural language processing and information extraction . 
12	typically qa is supported by natural language processing and ie . 
9	who, where or how much and eventually one of the question concepts, when the stem is ambiguous , as described in . 
2	assuming that it is very likely that the answer is a named entity, describes a ne-supported q&a system that functions quite well when the expected answer type is one of the categories covered by the ne recognizer. 
