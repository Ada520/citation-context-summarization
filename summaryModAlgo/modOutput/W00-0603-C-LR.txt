4 evaluation to evaluate our learning approach, we trained aquarea$ on the same development set of stories and tested it on the same test set of stories as those used in all past work on the reading comprehension task (hirschman et al, 1999; charniak et al, 2000; riloffand thelen, 2000; wang et al, 2000). 
in prior work (hirschman et al, 1999; charniak et al, 2000; riloffand thelen, 2000) the number and type of information sources used for computation is specific to and rlifferent for each question type. 
quarc (riloff and thelen, 2000) utilizes manually generated rules that selects a sentence deemed to contain the answer based on a combination of syntactic similarity and semantic correspondence (i.e., semantic categories of nouns). 
