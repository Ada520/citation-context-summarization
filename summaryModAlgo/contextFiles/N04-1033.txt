we thus propose to adapt the statistical machine translation model (brown et al, 1993; zens and ney, 2004) for sms text normalization. 
we experimented with two levels of distortion: monotonic, where the phrasal alignment is monotonic (but word reordering is still possible within a phrase) and limited distortion, where only adjacent phrases are allowed to exchange positions (zens and ney, 2004). 
finally, we use pos features to parameterize a distortion model in a limited distortion decoder (zens and ney, 2004; tillmann and zhang, 2005). 
we use a state-of-the-art phrase-based translation system as described in (zens and ney, 2004; zens et al, 2005). 
there is, however, a large body of work using morphological analysis to define cluster-based translation models similar to ours but in a supervised manner (zens and ney, 2004), (niessen and ney, 2004). 
our approach to phrase-table smoothing contrasts to previous work (zens and ney, 2004) in which smoothed phrase probabilities are constructed from word-pair probabilities and combined in a log-linear model with an unsmoothed phrase-table. 
nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). 
for the confidence measures which will be introduced in section 5, we use a state-of-the-art phrasebased approach as described in (zens and ney, 2004). 
today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). 
above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). 
we use a state-of-the-art phrase-based translation system (zens and ney, 2004; zens et al, 2005) including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. 
the approach presented here has some resemblance to the bracketing transduction grammars (btg) of (wu, 1997), which have been applied to a phrase-based machine translation system in (zens et al, 2004). 
we extended the monotone search algorithm from (zens and ney, 2004) such that reorderings are possible. 
we use a phrase-based translation approach as described in (zens and ney, 2004). 
as described above, (zens and 57 ney, 2004) and (koehn et al, 2005) use two different variants of glass-box smoothing (which they call ‚Äúlexical smoothing‚Äù) over the phrasetable, and combine the resulting estimates with pure relativefrequency ones in a loglinear model. 
this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). 
(zens and ney, 2004) obtain p(sj|ti) from smoothed relative-frequency estimates in a wordaligned corpus. 
(zens and ney, 2004) describe a noisy-orù combination: p(sj|Àút) = 1‚àíp(¬Øsj|Àút) ‚âà 1‚àí Àúiproductdisplay i=1 (1‚àíp(sj|ti)) where ¬Øsj is the probability that sj is not in the translation of Àút, and p(sj|ti) is a lexical probability. 
several strategies to compute these probabilities have been proposed (zens et al, 2004; crego et al, 2004), but none of them takes into account the fact that, when it comes to translation, many different inflected forms of words share the same translation. 
more details about the baseline system can be found in (zens and ney, 2004; zens et al, 2005). 
we define the source and target projection of a hypothesis h by the proj operator which collects in order the words of a hypothesis along one language: projf(h) = braceleftbig fp : p‚ààuniontextui=1{jin}n‚àà[1,ni] bracerightbig proje(h) = braceleftbig ep : p‚ààuniontextui=1{lim}m‚àà[1,mi] bracerightbig if we denote by hf the set of hypotheses that have f as a source projection (that is, hf = {h : projf(h) ‚â° f}), then our translation engine seeks ÀÜe = proje(ÀÜh) where: ÀÜh = argmax h‚ààhf s(h) the function we seek to maximize s(h) is a loglinear combination of 9 components, and might be better understood as the numerator of a maximum entropy model popular in several statistical mt systems(ochandney, 2002; bertoldietal., 2004; zens and ney, 2004; simard et al, 2005; quirk et al, 2005). 
recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). 
more details about the baseline system can be found in (zens and ney, 2004; zens et al, 2005). 
